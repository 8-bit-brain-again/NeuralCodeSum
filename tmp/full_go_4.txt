04/12/2022 11:45:26 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name go --data_dir ../../data/ --model_dir ../../tmp --model_name full_go_4 --train_src train/code.original_subtoken --train_tgt train/javadoc.original --dev_src dev/code.original_subtoken --dev_tgt dev/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 20 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 32 --use_neg_dist True --nlayers 6 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True --split_decoder False ]
04/12/2022 11:45:26 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/12/2022 11:45:26 PM: [ Load and process data files ]
04/12/2022 11:45:30 PM: [ Num train examples = 69530 ]
04/12/2022 11:45:30 PM: [ Dataset weights = {3: 1.0} ]
04/12/2022 11:45:30 PM: [ Num dev examples = 8714 ]
04/12/2022 11:45:30 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/12/2022 11:45:30 PM: [ Training model from scratch... ]
04/12/2022 11:45:30 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/12/2022 11:45:30 PM: [ Build word dictionary ]
04/12/2022 11:45:32 PM: [ Num words in source = 32525 and target = 15207 ]
04/12/2022 11:45:32 PM: [ Trainable #parameters [encoder-decoder] 44.2M [total] 69.4M ]
04/12/2022 11:45:32 PM: [ Breakdown of the trainable paramters
+------------------------------------------------------------------------------+--------------+----------+
| Layer Name                                                                   | Output Shape |  Param # |
+------------------------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight                | [32525, 512] | 16652800 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight                | [15207, 512] |  7785984 |
| embedder.tgt_pos_embeddings.weight                                           |    [22, 512] |    11264 |
| encoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| generator.bias                                                               |      [15207] |    15207 |
| copy_attn.linear_in.weight                                                   |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                                  |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                                            |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                                              |          [1] |        1 |
+------------------------------------------------------------------------------+--------------+----------+ ]
04/12/2022 11:45:35 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/12/2022 11:45:35 PM: [ Make data loaders ]
04/12/2022 11:45:35 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/12/2022 11:45:35 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": true,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "go"
    ],
    "dataset_weights": {
        "3": 1.0
    },
    "dev_src": [
        "dev/code.original_subtoken"
    ],
    "dev_src_files": [
        "../../data/go/dev/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_tgt": [
        "dev/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/go/dev/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/full_go_4.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        32
    ],
    "max_src_len": 150,
    "max_tgt_len": 20,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/full_go_4.mdl",
    "model_name": "full_go_4",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 6,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 69530,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/full_go_4.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_files": [
        "../../data/go/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/go/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
04/12/2022 11:45:35 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/12/2022 11:45:35 PM: [ Starting training... ]
04/12/2022 11:50:29 PM: [ train: Epoch 1 | perplexity = 21801.88 | ml_loss = 274.61 | Time for epoch = 293.61 (s) ]
04/12/2022 11:51:38 PM: [ dev valid official: Epoch = 1 | bleu = 7.40 | rouge_l = 12.71 | Precision = 13.40 | Recall = 15.82 | F1 = 13.30 | examples = 8714 | valid time = 67.88 (s) ]
04/12/2022 11:51:38 PM: [ Best valid: bleu = 7.40 (epoch 1, 2173 updates) ]
04/12/2022 11:56:26 PM: [ train: Epoch 2 | perplexity = 10303.87 | ml_loss = 135.24 | Time for epoch = 287.96 (s) ]
04/12/2022 11:57:34 PM: [ dev valid official: Epoch = 2 | bleu = 10.10 | rouge_l = 20.87 | Precision = 27.77 | Recall = 22.91 | F1 = 22.78 | examples = 8714 | valid time = 66.44 (s) ]
04/12/2022 11:57:34 PM: [ Best valid: bleu = 10.10 (epoch 2, 4346 updates) ]
04/13/2022 12:02:26 AM: [ train: Epoch 3 | perplexity = 335.45 | ml_loss = 79.92 | Time for epoch = 290.83 (s) ]
04/13/2022 12:03:33 AM: [ dev valid official: Epoch = 3 | bleu = 10.99 | rouge_l = 22.36 | Precision = 30.25 | Recall = 23.55 | F1 = 24.19 | examples = 8714 | valid time = 66.06 (s) ]
04/13/2022 12:03:33 AM: [ Best valid: bleu = 10.99 (epoch 3, 6519 updates) ]
04/13/2022 12:08:24 AM: [ train: Epoch 4 | perplexity = 84.42 | ml_loss = 63.06 | Time for epoch = 290.42 (s) ]
04/13/2022 12:09:31 AM: [ dev valid official: Epoch = 4 | bleu = 12.86 | rouge_l = 26.89 | Precision = 36.40 | Recall = 27.97 | F1 = 29.31 | examples = 8714 | valid time = 66.10 (s) ]
04/13/2022 12:09:31 AM: [ Best valid: bleu = 12.86 (epoch 4, 8692 updates) ]
04/13/2022 12:14:18 AM: [ train: Epoch 5 | perplexity = 53.06 | ml_loss = 56.21 | Time for epoch = 285.56 (s) ]
04/13/2022 12:15:26 AM: [ dev valid official: Epoch = 5 | bleu = 14.88 | rouge_l = 30.46 | Precision = 40.28 | Recall = 31.19 | F1 = 32.66 | examples = 8714 | valid time = 66.70 (s) ]
04/13/2022 12:15:26 AM: [ Best valid: bleu = 14.88 (epoch 5, 10865 updates) ]
04/13/2022 12:20:11 AM: [ train: Epoch 6 | perplexity = 37.67 | ml_loss = 51.63 | Time for epoch = 285.29 (s) ]
04/13/2022 12:21:18 AM: [ dev valid official: Epoch = 6 | bleu = 15.29 | rouge_l = 30.78 | Precision = 37.64 | Recall = 32.98 | F1 = 32.44 | examples = 8714 | valid time = 65.30 (s) ]
04/13/2022 12:21:18 AM: [ Best valid: bleu = 15.29 (epoch 6, 13038 updates) ]
04/13/2022 12:26:16 AM: [ train: Epoch 7 | perplexity = 28.75 | ml_loss = 48.53 | Time for epoch = 297.08 (s) ]
04/13/2022 12:27:23 AM: [ dev valid official: Epoch = 7 | bleu = 17.17 | rouge_l = 33.98 | Precision = 45.42 | Recall = 33.83 | F1 = 36.16 | examples = 8714 | valid time = 65.64 (s) ]
04/13/2022 12:27:23 AM: [ Best valid: bleu = 17.17 (epoch 7, 15211 updates) ]
04/13/2022 12:32:10 AM: [ train: Epoch 8 | perplexity = 25.13 | ml_loss = 46.20 | Time for epoch = 286.66 (s) ]
04/13/2022 12:33:17 AM: [ dev valid official: Epoch = 8 | bleu = 17.34 | rouge_l = 34.27 | Precision = 46.93 | Recall = 33.64 | F1 = 36.53 | examples = 8714 | valid time = 65.66 (s) ]
04/13/2022 12:33:17 AM: [ Best valid: bleu = 17.34 (epoch 8, 17384 updates) ]
04/13/2022 12:38:05 AM: [ train: Epoch 9 | perplexity = 21.99 | ml_loss = 44.20 | Time for epoch = 287.95 (s) ]
04/13/2022 12:39:12 AM: [ dev valid official: Epoch = 9 | bleu = 17.20 | rouge_l = 34.80 | Precision = 51.70 | Recall = 33.17 | F1 = 37.74 | examples = 8714 | valid time = 65.71 (s) ]
04/13/2022 12:44:07 AM: [ train: Epoch 10 | perplexity = 18.70 | ml_loss = 42.45 | Time for epoch = 294.26 (s) ]
04/13/2022 12:45:14 AM: [ dev valid official: Epoch = 10 | bleu = 17.82 | rouge_l = 34.34 | Precision = 46.14 | Recall = 34.04 | F1 = 36.61 | examples = 8714 | valid time = 65.81 (s) ]
04/13/2022 12:45:14 AM: [ Best valid: bleu = 17.82 (epoch 10, 21730 updates) ]
04/13/2022 12:50:12 AM: [ train: Epoch 11 | perplexity = 16.57 | ml_loss = 40.86 | Time for epoch = 297.56 (s) ]
04/13/2022 12:51:19 AM: [ dev valid official: Epoch = 11 | bleu = 17.99 | rouge_l = 34.52 | Precision = 45.88 | Recall = 34.69 | F1 = 36.98 | examples = 8714 | valid time = 65.58 (s) ]
04/13/2022 12:51:19 AM: [ Best valid: bleu = 17.99 (epoch 11, 23903 updates) ]
04/13/2022 12:56:14 AM: [ train: Epoch 12 | perplexity = 15.09 | ml_loss = 39.39 | Time for epoch = 294.14 (s) ]
04/13/2022 12:57:21 AM: [ dev valid official: Epoch = 12 | bleu = 17.98 | rouge_l = 34.45 | Precision = 45.08 | Recall = 34.78 | F1 = 36.75 | examples = 8714 | valid time = 65.58 (s) ]
04/13/2022 01:02:18 AM: [ train: Epoch 13 | perplexity = 13.52 | ml_loss = 38.05 | Time for epoch = 297.09 (s) ]
04/13/2022 01:03:25 AM: [ dev valid official: Epoch = 13 | bleu = 18.72 | rouge_l = 35.92 | Precision = 50.53 | Recall = 35.00 | F1 = 38.81 | examples = 8714 | valid time = 66.16 (s) ]
04/13/2022 01:03:25 AM: [ Best valid: bleu = 18.72 (epoch 13, 28249 updates) ]
04/13/2022 01:08:10 AM: [ train: Epoch 14 | perplexity = 13.08 | ml_loss = 36.78 | Time for epoch = 284.49 (s) ]
04/13/2022 01:09:18 AM: [ dev valid official: Epoch = 14 | bleu = 18.25 | rouge_l = 35.13 | Precision = 43.78 | Recall = 36.85 | F1 = 37.38 | examples = 8714 | valid time = 65.90 (s) ]
04/13/2022 01:14:01 AM: [ train: Epoch 15 | perplexity = 12.13 | ml_loss = 35.66 | Time for epoch = 283.24 (s) ]
04/13/2022 01:15:08 AM: [ dev valid official: Epoch = 15 | bleu = 18.65 | rouge_l = 35.32 | Precision = 45.67 | Recall = 36.14 | F1 = 37.76 | examples = 8714 | valid time = 65.71 (s) ]
04/13/2022 01:19:53 AM: [ train: Epoch 16 | perplexity = 11.17 | ml_loss = 34.58 | Time for epoch = 285.64 (s) ]
04/13/2022 01:21:00 AM: [ dev valid official: Epoch = 16 | bleu = 18.62 | rouge_l = 35.51 | Precision = 48.42 | Recall = 34.94 | F1 = 38.06 | examples = 8714 | valid time = 65.56 (s) ]
04/13/2022 01:25:55 AM: [ train: Epoch 17 | perplexity = 9.83 | ml_loss = 33.49 | Time for epoch = 294.12 (s) ]
04/13/2022 01:27:02 AM: [ dev valid official: Epoch = 17 | bleu = 18.32 | rouge_l = 34.52 | Precision = 49.27 | Recall = 33.02 | F1 = 36.99 | examples = 8714 | valid time = 65.76 (s) ]
04/13/2022 01:31:52 AM: [ train: Epoch 18 | perplexity = 9.31 | ml_loss = 32.44 | Time for epoch = 289.83 (s) ]
04/13/2022 01:32:59 AM: [ dev valid official: Epoch = 18 | bleu = 17.72 | rouge_l = 33.92 | Precision = 41.36 | Recall = 36.44 | F1 = 36.15 | examples = 8714 | valid time = 65.48 (s) ]
04/13/2022 01:37:52 AM: [ train: Epoch 19 | perplexity = 8.48 | ml_loss = 31.43 | Time for epoch = 293.83 (s) ]
04/13/2022 01:38:59 AM: [ dev valid official: Epoch = 19 | bleu = 18.35 | rouge_l = 34.85 | Precision = 46.01 | Recall = 35.29 | F1 = 37.38 | examples = 8714 | valid time = 65.06 (s) ]
04/13/2022 01:43:48 AM: [ train: Epoch 20 | perplexity = 8.00 | ml_loss = 30.48 | Time for epoch = 289.46 (s) ]
04/13/2022 01:44:55 AM: [ dev valid official: Epoch = 20 | bleu = 17.52 | rouge_l = 33.68 | Precision = 40.52 | Recall = 36.73 | F1 = 35.90 | examples = 8714 | valid time = 65.70 (s) ]
04/13/2022 01:49:43 AM: [ train: Epoch 21 | perplexity = 7.52 | ml_loss = 29.54 | Time for epoch = 288.11 (s) ]
04/13/2022 01:50:50 AM: [ dev valid official: Epoch = 21 | bleu = 18.23 | rouge_l = 34.37 | Precision = 43.32 | Recall = 36.28 | F1 = 36.83 | examples = 8714 | valid time = 65.62 (s) ]
04/13/2022 01:55:34 AM: [ train: Epoch 22 | perplexity = 7.26 | ml_loss = 28.70 | Time for epoch = 283.69 (s) ]
04/13/2022 01:56:40 AM: [ dev valid official: Epoch = 22 | bleu = 18.66 | rouge_l = 34.73 | Precision = 46.88 | Recall = 34.57 | F1 = 37.29 | examples = 8714 | valid time = 64.57 (s) ]
04/13/2022 02:01:32 AM: [ train: Epoch 23 | perplexity = 6.57 | ml_loss = 27.84 | Time for epoch = 291.46 (s) ]
04/13/2022 02:02:37 AM: [ dev valid official: Epoch = 23 | bleu = 17.72 | rouge_l = 34.05 | Precision = 48.42 | Recall = 33.06 | F1 = 36.63 | examples = 8714 | valid time = 64.21 (s) ]
04/13/2022 02:07:21 AM: [ train: Epoch 24 | perplexity = 6.42 | ml_loss = 27.04 | Time for epoch = 284.11 (s) ]
04/13/2022 02:08:28 AM: [ dev valid official: Epoch = 24 | bleu = 17.56 | rouge_l = 33.54 | Precision = 44.21 | Recall = 34.13 | F1 = 36.05 | examples = 8714 | valid time = 65.58 (s) ]
04/13/2022 02:13:10 AM: [ train: Epoch 25 | perplexity = 6.13 | ml_loss = 26.27 | Time for epoch = 281.68 (s) ]
04/13/2022 02:14:17 AM: [ dev valid official: Epoch = 25 | bleu = 18.25 | rouge_l = 34.18 | Precision = 45.38 | Recall = 34.44 | F1 = 36.67 | examples = 8714 | valid time = 65.82 (s) ]
04/13/2022 02:18:58 AM: [ train: Epoch 26 | perplexity = 5.80 | ml_loss = 25.51 | Time for epoch = 281.13 (s) ]
04/13/2022 02:20:04 AM: [ dev valid official: Epoch = 26 | bleu = 18.21 | rouge_l = 34.21 | Precision = 45.87 | Recall = 34.40 | F1 = 36.78 | examples = 8714 | valid time = 64.21 (s) ]
04/13/2022 02:24:48 AM: [ train: Epoch 27 | perplexity = 5.43 | ml_loss = 24.77 | Time for epoch = 283.92 (s) ]
04/13/2022 02:25:54 AM: [ dev valid official: Epoch = 27 | bleu = 17.88 | rouge_l = 33.64 | Precision = 43.57 | Recall = 34.93 | F1 = 36.23 | examples = 8714 | valid time = 64.35 (s) ]
04/13/2022 02:30:37 AM: [ train: Epoch 28 | perplexity = 5.19 | ml_loss = 24.06 | Time for epoch = 283.03 (s) ]
04/13/2022 02:31:43 AM: [ dev valid official: Epoch = 28 | bleu = 17.43 | rouge_l = 33.44 | Precision = 44.60 | Recall = 34.04 | F1 = 36.05 | examples = 8714 | valid time = 65.21 (s) ]
04/13/2022 02:36:34 AM: [ train: Epoch 29 | perplexity = 4.77 | ml_loss = 23.35 | Time for epoch = 290.79 (s) ]
04/13/2022 02:37:42 AM: [ dev valid official: Epoch = 29 | bleu = 17.29 | rouge_l = 32.60 | Precision = 41.20 | Recall = 34.78 | F1 = 35.04 | examples = 8714 | valid time = 66.02 (s) ]
04/13/2022 02:42:32 AM: [ train: Epoch 30 | perplexity = 4.51 | ml_loss = 22.61 | Time for epoch = 290.29 (s) ]
04/13/2022 02:43:38 AM: [ dev valid official: Epoch = 30 | bleu = 17.39 | rouge_l = 33.17 | Precision = 42.75 | Recall = 34.30 | F1 = 35.46 | examples = 8714 | valid time = 65.43 (s) ]
04/13/2022 02:48:31 AM: [ train: Epoch 31 | perplexity = 4.30 | ml_loss = 21.95 | Time for epoch = 292.73 (s) ]
04/13/2022 02:49:37 AM: [ dev valid official: Epoch = 31 | bleu = 17.85 | rouge_l = 33.55 | Precision = 44.94 | Recall = 34.03 | F1 = 36.20 | examples = 8714 | valid time = 65.05 (s) ]
04/13/2022 02:54:25 AM: [ train: Epoch 32 | perplexity = 4.17 | ml_loss = 21.32 | Time for epoch = 287.22 (s) ]
04/13/2022 02:55:32 AM: [ dev valid official: Epoch = 32 | bleu = 17.52 | rouge_l = 32.57 | Precision = 41.71 | Recall = 34.14 | F1 = 34.97 | examples = 8714 | valid time = 65.74 (s) ]
04/13/2022 03:00:15 AM: [ train: Epoch 33 | perplexity = 4.04 | ml_loss = 20.68 | Time for epoch = 283.64 (s) ]
04/13/2022 03:01:22 AM: [ dev valid official: Epoch = 33 | bleu = 17.69 | rouge_l = 33.13 | Precision = 41.72 | Recall = 35.20 | F1 = 35.62 | examples = 8714 | valid time = 65.48 (s) ]
