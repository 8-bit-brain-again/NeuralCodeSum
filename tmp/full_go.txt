04/03/2022 06:06:43 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name go --data_dir ../../data/ --model_dir ../../tmp --model_name full_go --train_src train/code.original_subtoken --train_tgt train/javadoc.original --dev_src dev/code.original_subtoken --dev_tgt dev/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 50 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 32 --use_neg_dist True --nlayers 6 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True --split_decoder False ]
04/03/2022 06:06:43 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 06:06:43 PM: [ Load and process data files ]
04/03/2022 06:06:47 PM: [ Num train examples = 69555 ]
04/03/2022 06:06:47 PM: [ Dataset weights = {3: 1.0} ]
04/03/2022 06:06:48 PM: [ Num dev examples = 8714 ]
04/03/2022 06:06:48 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 06:06:48 PM: [ Training model from scratch... ]
04/03/2022 06:06:48 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 06:06:48 PM: [ Build word dictionary ]
04/03/2022 06:06:51 PM: [ Num words in source = 28951 and target = 15522 ]
04/03/2022 06:06:51 PM: [ Trainable #parameters [encoder-decoder] 44.2M [total] 67.8M ]
04/03/2022 06:06:51 PM: [ Breakdown of the trainable paramters
+------------------------------------------------------------------------------+--------------+----------+
| Layer Name                                                                   | Output Shape |  Param # |
+------------------------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight                | [28951, 512] | 14822912 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight                | [15522, 512] |  7947264 |
| embedder.tgt_pos_embeddings.weight                                           |    [52, 512] |    26624 |
| encoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| generator.bias                                                               |      [15522] |    15522 |
| copy_attn.linear_in.weight                                                   |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                                  |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                                            |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                                              |          [1] |        1 |
+------------------------------------------------------------------------------+--------------+----------+ ]
04/03/2022 06:06:54 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 06:06:54 PM: [ Make data loaders ]
04/03/2022 06:06:54 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 06:06:54 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": true,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "go"
    ],
    "dataset_weights": {
        "3": 1.0
    },
    "dev_src": [
        "dev/code.original_subtoken"
    ],
    "dev_src_files": [
        "../../data/go/dev/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_tgt": [
        "dev/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/go/dev/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/full_go.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        32
    ],
    "max_src_len": 150,
    "max_tgt_len": 50,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/full_go.mdl",
    "model_name": "full_go",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 6,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 69555,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/full_go.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_files": [
        "../../data/go/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/go/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
04/03/2022 06:06:54 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 06:06:54 PM: [ Starting training... ]
04/03/2022 06:14:15 PM: [ train: Epoch 1 | perplexity = 22026.47 | ml_loss = 682.69 | Time for epoch = 440.90 (s) ]
04/03/2022 06:19:59 PM: [ dev valid official: Epoch = 1 | bleu = 7.08 | rouge_l = 10.84 | Precision = 12.86 | Recall = 12.77 | F1 = 11.33 | examples = 8714 | valid time = 341.95 (s) ]
04/03/2022 06:19:59 PM: [ Best valid: bleu = 7.08 (epoch 1, 2174 updates) ]
04/03/2022 06:32:44 PM: [ train: Epoch 2 | perplexity = 17568.26 | ml_loss = 234.72 | Time for epoch = 763.50 (s) ]
04/03/2022 06:38:57 PM: [ dev valid official: Epoch = 2 | bleu = 3.12 | rouge_l = 8.90 | Precision = 6.32 | Recall = 20.42 | F1 = 8.80 | examples = 8714 | valid time = 369.62 (s) ]
04/03/2022 06:54:22 PM: [ train: Epoch 3 | perplexity = 1189.40 | ml_loss = 125.64 | Time for epoch = 925.62 (s) ]
04/03/2022 07:00:51 PM: [ dev valid official: Epoch = 3 | bleu = 7.24 | rouge_l = 15.85 | Precision = 19.22 | Recall = 21.56 | F1 = 16.67 | examples = 8714 | valid time = 385.16 (s) ]
04/03/2022 07:00:51 PM: [ Best valid: bleu = 7.24 (epoch 3, 6522 updates) ]
04/03/2022 07:15:09 PM: [ train: Epoch 4 | perplexity = 134.50 | ml_loss = 93.89 | Time for epoch = 856.66 (s) ]
04/03/2022 07:22:51 PM: [ dev valid official: Epoch = 4 | bleu = 13.15 | rouge_l = 27.12 | Precision = 37.11 | Recall = 28.22 | F1 = 29.18 | examples = 8714 | valid time = 459.91 (s) ]
04/03/2022 07:22:51 PM: [ Best valid: bleu = 13.15 (epoch 4, 8696 updates) ]
04/03/2022 07:38:19 PM: [ train: Epoch 5 | perplexity = 73.61 | ml_loss = 80.81 | Time for epoch = 926.64 (s) ]
04/03/2022 07:45:28 PM: [ dev valid official: Epoch = 5 | bleu = 15.36 | rouge_l = 31.82 | Precision = 47.02 | Recall = 30.72 | F1 = 34.41 | examples = 8714 | valid time = 425.73 (s) ]
04/03/2022 07:45:28 PM: [ Best valid: bleu = 15.36 (epoch 5, 10870 updates) ]
04/03/2022 07:53:33 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name go --data_dir ../../data/ --model_dir ../../tmp --model_name full_go --train_src train/code.original_subtoken --train_tgt train/javadoc.original --dev_src dev/code.original_subtoken --dev_tgt dev/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 50 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 32 --use_neg_dist True --nlayers 6 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True --split_decoder False ]
04/03/2022 07:53:33 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 07:53:33 PM: [ Load and process data files ]
04/03/2022 07:53:37 PM: [ Num train examples = 69555 ]
04/03/2022 07:53:37 PM: [ Dataset weights = {3: 1.0} ]
04/03/2022 07:53:38 PM: [ Num dev examples = 8714 ]
04/03/2022 07:53:38 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 07:53:38 PM: [ Found a checkpoint... ]
04/03/2022 07:53:38 PM: [ Loading model ../../tmp/full_go.mdl.checkpoint ]
04/03/2022 07:53:58 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 07:53:58 PM: [ Make data loaders ]
04/03/2022 07:53:58 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 07:53:58 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": true,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "go"
    ],
    "dataset_weights": {
        "3": 1.0
    },
    "dev_src": [
        "dev/code.original_subtoken"
    ],
    "dev_src_files": [
        "../../data/go/dev/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_tgt": [
        "dev/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/go/dev/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/full_go.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        32
    ],
    "max_src_len": 150,
    "max_tgt_len": 50,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/full_go.mdl",
    "model_name": "full_go",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 6,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 69555,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/full_go.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_files": [
        "../../data/go/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/go/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
04/03/2022 07:53:58 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/03/2022 07:53:58 PM: [ Starting training... ]
04/03/2022 07:58:59 PM: [ train: Epoch 6 | perplexity = 43.78 | ml_loss = 74.44 | Time for epoch = 301.82 (s) ]
04/03/2022 08:01:07 PM: [ dev valid official: Epoch = 6 | bleu = 16.21 | rouge_l = 32.48 | Precision = 43.99 | Recall = 32.74 | F1 = 34.98 | examples = 8714 | valid time = 126.06 (s) ]
04/03/2022 08:01:07 PM: [ Best valid: bleu = 16.21 (epoch 6, 13044 updates) ]
04/03/2022 08:06:07 PM: [ train: Epoch 7 | perplexity = 37.00 | ml_loss = 70.37 | Time for epoch = 299.50 (s) ]
04/03/2022 08:08:28 PM: [ dev valid official: Epoch = 7 | bleu = 16.23 | rouge_l = 32.42 | Precision = 42.60 | Recall = 33.97 | F1 = 34.76 | examples = 8714 | valid time = 140.65 (s) ]
04/03/2022 08:08:28 PM: [ Best valid: bleu = 16.23 (epoch 7, 15218 updates) ]
04/03/2022 08:13:23 PM: [ train: Epoch 8 | perplexity = 30.56 | ml_loss = 67.03 | Time for epoch = 293.78 (s) ]
04/03/2022 08:15:37 PM: [ dev valid official: Epoch = 8 | bleu = 16.75 | rouge_l = 33.20 | Precision = 43.86 | Recall = 34.54 | F1 = 35.67 | examples = 8714 | valid time = 133.14 (s) ]
04/03/2022 08:15:37 PM: [ Best valid: bleu = 16.75 (epoch 8, 17392 updates) ]
04/03/2022 08:20:38 PM: [ train: Epoch 9 | perplexity = 24.13 | ml_loss = 63.88 | Time for epoch = 300.75 (s) ]
04/03/2022 08:22:54 PM: [ dev valid official: Epoch = 9 | bleu = 17.23 | rouge_l = 33.89 | Precision = 46.67 | Recall = 33.62 | F1 = 36.36 | examples = 8714 | valid time = 134.70 (s) ]
04/03/2022 08:22:54 PM: [ Best valid: bleu = 17.23 (epoch 9, 19566 updates) ]
04/03/2022 08:27:38 PM: [ train: Epoch 10 | perplexity = 25.06 | ml_loss = 61.29 | Time for epoch = 283.72 (s) ]
04/03/2022 08:29:52 PM: [ dev valid official: Epoch = 10 | bleu = 17.91 | rouge_l = 34.91 | Precision = 49.37 | Recall = 34.10 | F1 = 37.76 | examples = 8714 | valid time = 133.17 (s) ]
04/03/2022 08:29:52 PM: [ Best valid: bleu = 17.91 (epoch 10, 21740 updates) ]
04/03/2022 08:34:43 PM: [ train: Epoch 11 | perplexity = 22.96 | ml_loss = 61.02 | Time for epoch = 290.59 (s) ]
04/03/2022 08:36:58 PM: [ dev valid official: Epoch = 11 | bleu = 17.44 | rouge_l = 34.04 | Precision = 45.18 | Recall = 35.02 | F1 = 36.65 | examples = 8714 | valid time = 134.13 (s) ]
04/03/2022 08:41:40 PM: [ train: Epoch 12 | perplexity = 22.48 | ml_loss = 59.22 | Time for epoch = 281.66 (s) ]
04/03/2022 08:43:57 PM: [ dev valid official: Epoch = 12 | bleu = 16.66 | rouge_l = 33.25 | Precision = 40.25 | Recall = 37.42 | F1 = 35.54 | examples = 8714 | valid time = 135.73 (s) ]
04/03/2022 08:48:45 PM: [ train: Epoch 13 | perplexity = 19.31 | ml_loss = 57.54 | Time for epoch = 288.09 (s) ]
04/03/2022 08:51:00 PM: [ dev valid official: Epoch = 13 | bleu = 17.80 | rouge_l = 34.99 | Precision = 45.44 | Recall = 36.36 | F1 = 37.58 | examples = 8714 | valid time = 134.16 (s) ]
04/03/2022 08:55:57 PM: [ train: Epoch 14 | perplexity = 18.07 | ml_loss = 55.95 | Time for epoch = 297.23 (s) ]
04/03/2022 08:58:20 PM: [ dev valid official: Epoch = 14 | bleu = 17.72 | rouge_l = 34.60 | Precision = 44.39 | Recall = 36.71 | F1 = 37.18 | examples = 8714 | valid time = 141.84 (s) ]
04/03/2022 09:03:17 PM: [ train: Epoch 15 | perplexity = 15.67 | ml_loss = 54.41 | Time for epoch = 296.88 (s) ]
04/03/2022 09:05:37 PM: [ dev valid official: Epoch = 15 | bleu = 18.28 | rouge_l = 35.23 | Precision = 47.40 | Recall = 35.48 | F1 = 37.94 | examples = 8714 | valid time = 139.09 (s) ]
04/03/2022 09:05:37 PM: [ Best valid: bleu = 18.28 (epoch 15, 32610 updates) ]
04/03/2022 09:10:30 PM: [ train: Epoch 16 | perplexity = 13.85 | ml_loss = 52.95 | Time for epoch = 292.14 (s) ]
04/03/2022 09:12:44 PM: [ dev valid official: Epoch = 16 | bleu = 17.73 | rouge_l = 34.62 | Precision = 43.87 | Recall = 37.02 | F1 = 37.21 | examples = 8714 | valid time = 132.66 (s) ]
04/03/2022 09:17:21 PM: [ train: Epoch 17 | perplexity = 14.12 | ml_loss = 51.60 | Time for epoch = 277.71 (s) ]
04/03/2022 09:19:30 PM: [ dev valid official: Epoch = 17 | bleu = 17.69 | rouge_l = 34.64 | Precision = 44.61 | Recall = 36.64 | F1 = 37.40 | examples = 8714 | valid time = 127.73 (s) ]
04/03/2022 09:24:17 PM: [ train: Epoch 18 | perplexity = 11.32 | ml_loss = 50.28 | Time for epoch = 286.52 (s) ]
04/03/2022 09:26:27 PM: [ dev valid official: Epoch = 18 | bleu = 17.77 | rouge_l = 34.67 | Precision = 46.23 | Recall = 35.48 | F1 = 37.41 | examples = 8714 | valid time = 129.01 (s) ]
04/03/2022 09:31:08 PM: [ train: Epoch 19 | perplexity = 11.98 | ml_loss = 49.01 | Time for epoch = 280.72 (s) ]
04/03/2022 09:33:17 PM: [ dev valid official: Epoch = 19 | bleu = 16.12 | rouge_l = 32.74 | Precision = 38.13 | Recall = 38.83 | F1 = 35.13 | examples = 8714 | valid time = 128.60 (s) ]
04/03/2022 09:38:00 PM: [ train: Epoch 20 | perplexity = 12.22 | ml_loss = 47.94 | Time for epoch = 283.14 (s) ]
04/03/2022 09:40:13 PM: [ dev valid official: Epoch = 20 | bleu = 17.23 | rouge_l = 33.51 | Precision = 42.20 | Recall = 36.01 | F1 = 36.09 | examples = 8714 | valid time = 131.81 (s) ]
04/03/2022 09:44:51 PM: [ train: Epoch 21 | perplexity = 11.30 | ml_loss = 46.88 | Time for epoch = 277.93 (s) ]
04/03/2022 09:47:01 PM: [ dev valid official: Epoch = 21 | bleu = 17.57 | rouge_l = 34.27 | Precision = 43.96 | Recall = 36.27 | F1 = 36.99 | examples = 8714 | valid time = 128.66 (s) ]
04/03/2022 09:51:52 PM: [ train: Epoch 22 | perplexity = 8.66 | ml_loss = 45.77 | Time for epoch = 291.14 (s) ]
04/03/2022 09:54:08 PM: [ dev valid official: Epoch = 22 | bleu = 17.29 | rouge_l = 34.17 | Precision = 43.15 | Recall = 36.91 | F1 = 36.98 | examples = 8714 | valid time = 134.82 (s) ]
04/03/2022 09:58:50 PM: [ train: Epoch 23 | perplexity = 10.17 | ml_loss = 44.73 | Time for epoch = 282.01 (s) ]
04/03/2022 10:01:02 PM: [ dev valid official: Epoch = 23 | bleu = 17.65 | rouge_l = 34.28 | Precision = 44.88 | Recall = 35.59 | F1 = 37.06 | examples = 8714 | valid time = 130.56 (s) ]
04/03/2022 10:06:02 PM: [ train: Epoch 24 | perplexity = 7.78 | ml_loss = 43.76 | Time for epoch = 300.12 (s) ]
04/03/2022 10:08:16 PM: [ dev valid official: Epoch = 24 | bleu = 17.79 | rouge_l = 34.47 | Precision = 45.05 | Recall = 36.18 | F1 = 37.32 | examples = 8714 | valid time = 133.02 (s) ]
04/03/2022 10:13:17 PM: [ train: Epoch 25 | perplexity = 7.29 | ml_loss = 42.74 | Time for epoch = 301.50 (s) ]
04/03/2022 10:15:32 PM: [ dev valid official: Epoch = 25 | bleu = 17.39 | rouge_l = 33.90 | Precision = 43.54 | Recall = 36.12 | F1 = 36.56 | examples = 8714 | valid time = 133.34 (s) ]
04/03/2022 10:20:14 PM: [ train: Epoch 26 | perplexity = 8.76 | ml_loss = 41.74 | Time for epoch = 282.19 (s) ]
04/03/2022 10:22:31 PM: [ dev valid official: Epoch = 26 | bleu = 17.57 | rouge_l = 34.29 | Precision = 44.09 | Recall = 36.44 | F1 = 37.14 | examples = 8714 | valid time = 136.19 (s) ]
04/03/2022 10:27:22 PM: [ train: Epoch 27 | perplexity = 7.54 | ml_loss = 40.94 | Time for epoch = 290.98 (s) ]
04/03/2022 10:29:36 PM: [ dev valid official: Epoch = 27 | bleu = 17.75 | rouge_l = 34.39 | Precision = 44.99 | Recall = 35.77 | F1 = 37.10 | examples = 8714 | valid time = 132.05 (s) ]
04/03/2022 10:34:33 PM: [ train: Epoch 28 | perplexity = 6.60 | ml_loss = 40.09 | Time for epoch = 297.24 (s) ]
04/03/2022 10:36:46 PM: [ dev valid official: Epoch = 28 | bleu = 17.22 | rouge_l = 33.79 | Precision = 43.67 | Recall = 35.84 | F1 = 36.56 | examples = 8714 | valid time = 131.61 (s) ]
04/03/2022 10:41:26 PM: [ train: Epoch 29 | perplexity = 7.40 | ml_loss = 39.27 | Time for epoch = 280.38 (s) ]
04/03/2022 10:43:38 PM: [ dev valid official: Epoch = 29 | bleu = 17.29 | rouge_l = 33.55 | Precision = 43.21 | Recall = 35.46 | F1 = 36.24 | examples = 8714 | valid time = 130.71 (s) ]
04/03/2022 10:48:31 PM: [ train: Epoch 30 | perplexity = 6.19 | ml_loss = 38.47 | Time for epoch = 293.15 (s) ]
04/03/2022 10:50:42 PM: [ dev valid official: Epoch = 30 | bleu = 17.68 | rouge_l = 34.42 | Precision = 46.08 | Recall = 34.87 | F1 = 37.10 | examples = 8714 | valid time = 130.34 (s) ]
04/03/2022 10:55:32 PM: [ train: Epoch 31 | perplexity = 6.23 | ml_loss = 37.68 | Time for epoch = 289.24 (s) ]
04/03/2022 10:57:46 PM: [ dev valid official: Epoch = 31 | bleu = 16.88 | rouge_l = 33.11 | Precision = 41.08 | Recall = 36.34 | F1 = 35.67 | examples = 8714 | valid time = 133.19 (s) ]
04/03/2022 11:02:44 PM: [ train: Epoch 32 | perplexity = 5.35 | ml_loss = 36.93 | Time for epoch = 298.09 (s) ]
04/03/2022 11:04:55 PM: [ dev valid official: Epoch = 32 | bleu = 17.16 | rouge_l = 33.62 | Precision = 42.18 | Recall = 36.37 | F1 = 36.18 | examples = 8714 | valid time = 130.39 (s) ]
04/03/2022 11:09:48 PM: [ train: Epoch 33 | perplexity = 5.09 | ml_loss = 36.15 | Time for epoch = 292.84 (s) ]
04/03/2022 11:11:58 PM: [ dev valid official: Epoch = 33 | bleu = 16.54 | rouge_l = 32.88 | Precision = 40.57 | Recall = 36.86 | F1 = 35.43 | examples = 8714 | valid time = 128.62 (s) ]
04/03/2022 11:16:28 PM: [ train: Epoch 34 | perplexity = 6.15 | ml_loss = 35.41 | Time for epoch = 270.28 (s) ]
04/03/2022 11:18:36 PM: [ dev valid official: Epoch = 34 | bleu = 17.40 | rouge_l = 33.60 | Precision = 43.91 | Recall = 35.10 | F1 = 36.35 | examples = 8714 | valid time = 126.93 (s) ]
04/03/2022 11:23:17 PM: [ train: Epoch 35 | perplexity = 5.50 | ml_loss = 34.81 | Time for epoch = 280.89 (s) ]
04/03/2022 11:25:25 PM: [ dev valid official: Epoch = 35 | bleu = 17.10 | rouge_l = 33.42 | Precision = 41.59 | Recall = 36.70 | F1 = 36.15 | examples = 8714 | valid time = 126.82 (s) ]
