04/04/2022 06:58:25 AM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name php --data_dir ../../data/ --model_dir ../../tmp --model_name full_php --train_src train/code.original_subtoken --train_tgt train/javadoc.original --dev_src dev/code.original_subtoken --dev_tgt dev/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 50 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 32 --use_neg_dist True --nlayers 6 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True --split_decoder False ]
04/04/2022 06:58:25 AM: [ ---------------------------------------------------------------------------------------------------- ]
04/04/2022 06:58:25 AM: [ Load and process data files ]
04/04/2022 06:58:28 AM: [ Num train examples = 63359 ]
04/04/2022 06:58:28 AM: [ Dataset weights = {5: 1.0} ]
04/04/2022 06:58:29 AM: [ Num dev examples = 7414 ]
04/04/2022 06:58:29 AM: [ ---------------------------------------------------------------------------------------------------- ]
04/04/2022 06:58:29 AM: [ Training model from scratch... ]
04/04/2022 06:58:29 AM: [ ---------------------------------------------------------------------------------------------------- ]
04/04/2022 06:58:29 AM: [ Build word dictionary ]
04/04/2022 06:58:30 AM: [ Num words in source = 50000 and target = 12551 ]
04/04/2022 06:58:31 AM: [ Trainable #parameters [encoder-decoder] 44.2M [total] 77M ]
04/04/2022 06:58:31 AM: [ Breakdown of the trainable paramters
+------------------------------------------------------------------------------+--------------+----------+
| Layer Name                                                                   | Output Shape |  Param # |
+------------------------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight                | [50000, 512] | 25600000 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight                | [12551, 512] |  6426112 |
| embedder.tgt_pos_embeddings.weight                                           |    [52, 512] |    26624 |
| encoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| generator.bias                                                               |      [12551] |    12551 |
| copy_attn.linear_in.weight                                                   |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                                  |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                                            |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                                              |          [1] |        1 |
+------------------------------------------------------------------------------+--------------+----------+ ]
04/04/2022 06:58:33 AM: [ ---------------------------------------------------------------------------------------------------- ]
04/04/2022 06:58:33 AM: [ Make data loaders ]
04/04/2022 06:58:33 AM: [ ---------------------------------------------------------------------------------------------------- ]
04/04/2022 06:58:33 AM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": true,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "php"
    ],
    "dataset_weights": {
        "5": 1.0
    },
    "dev_src": [
        "dev/code.original_subtoken"
    ],
    "dev_src_files": [
        "../../data/php/dev/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_tgt": [
        "dev/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/php/dev/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/full_php.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        32
    ],
    "max_src_len": 150,
    "max_tgt_len": 50,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/full_php.mdl",
    "model_name": "full_php",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 6,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 63359,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/full_php.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_files": [
        "../../data/php/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/php/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
04/04/2022 06:58:33 AM: [ ---------------------------------------------------------------------------------------------------- ]
04/04/2022 06:58:33 AM: [ Starting training... ]
04/04/2022 07:02:33 AM: [ train: Epoch 1 | perplexity = 22026.47 | ml_loss = 384.61 | Time for epoch = 240.06 (s) ]
04/04/2022 07:04:29 AM: [ dev valid official: Epoch = 1 | bleu = 2.58 | rouge_l = 5.72 | Precision = 3.13 | Recall = 21.37 | F1 = 5.14 | examples = 7414 | valid time = 114.01 (s) ]
04/04/2022 07:04:29 AM: [ Best valid: bleu = 2.58 (epoch 1, 1980 updates) ]
04/04/2022 07:08:31 AM: [ train: Epoch 2 | perplexity = 22005.81 | ml_loss = 313.86 | Time for epoch = 240.95 (s) ]
04/04/2022 07:10:20 AM: [ dev valid official: Epoch = 2 | bleu = 16.89 | rouge_l = 11.81 | Precision = 19.31 | Recall = 10.62 | F1 = 12.63 | examples = 7414 | valid time = 106.93 (s) ]
04/04/2022 07:10:20 AM: [ Best valid: bleu = 16.89 (epoch 2, 3960 updates) ]
04/04/2022 07:14:22 AM: [ train: Epoch 3 | perplexity = 14635.95 | ml_loss = 124.00 | Time for epoch = 241.31 (s) ]
04/04/2022 07:16:12 AM: [ dev valid official: Epoch = 3 | bleu = 15.52 | rouge_l = 9.73 | Precision = 13.81 | Recall = 9.45 | F1 = 10.16 | examples = 7414 | valid time = 108.41 (s) ]
04/04/2022 07:20:13 AM: [ train: Epoch 4 | perplexity = 1221.50 | ml_loss = 72.72 | Time for epoch = 240.33 (s) ]
04/04/2022 07:22:04 AM: [ dev valid official: Epoch = 4 | bleu = 15.06 | rouge_l = 19.95 | Precision = 23.71 | Recall = 23.34 | F1 = 20.77 | examples = 7414 | valid time = 109.99 (s) ]
04/04/2022 07:26:07 AM: [ train: Epoch 5 | perplexity = 158.46 | ml_loss = 56.21 | Time for epoch = 242.20 (s) ]
04/04/2022 07:27:56 AM: [ dev valid official: Epoch = 5 | bleu = 16.43 | rouge_l = 21.16 | Precision = 25.87 | Recall = 24.53 | F1 = 22.18 | examples = 7414 | valid time = 108.58 (s) ]
04/04/2022 07:32:04 AM: [ train: Epoch 6 | perplexity = 91.78 | ml_loss = 50.69 | Time for epoch = 247.30 (s) ]
04/04/2022 07:33:54 AM: [ dev valid official: Epoch = 6 | bleu = 19.35 | rouge_l = 23.00 | Precision = 32.63 | Recall = 23.28 | F1 = 24.37 | examples = 7414 | valid time = 108.09 (s) ]
04/04/2022 07:33:54 AM: [ Best valid: bleu = 19.35 (epoch 6, 11880 updates) ]
04/04/2022 07:37:49 AM: [ train: Epoch 7 | perplexity = 70.01 | ml_loss = 47.76 | Time for epoch = 235.32 (s) ]
04/04/2022 07:39:38 AM: [ dev valid official: Epoch = 7 | bleu = 17.00 | rouge_l = 20.99 | Precision = 26.65 | Recall = 23.16 | F1 = 22.01 | examples = 7414 | valid time = 107.22 (s) ]
04/04/2022 07:43:39 AM: [ train: Epoch 8 | perplexity = 56.91 | ml_loss = 45.54 | Time for epoch = 240.98 (s) ]
04/04/2022 07:45:26 AM: [ dev valid official: Epoch = 8 | bleu = 20.16 | rouge_l = 23.90 | Precision = 37.05 | Recall = 22.95 | F1 = 25.64 | examples = 7414 | valid time = 105.99 (s) ]
04/04/2022 07:45:26 AM: [ Best valid: bleu = 20.16 (epoch 8, 15840 updates) ]
04/04/2022 07:49:27 AM: [ train: Epoch 9 | perplexity = 48.17 | ml_loss = 43.73 | Time for epoch = 239.74 (s) ]
04/04/2022 07:51:15 AM: [ dev valid official: Epoch = 9 | bleu = 18.55 | rouge_l = 23.81 | Precision = 31.11 | Recall = 25.55 | F1 = 25.33 | examples = 7414 | valid time = 106.21 (s) ]
04/04/2022 07:55:13 AM: [ train: Epoch 10 | perplexity = 41.84 | ml_loss = 42.13 | Time for epoch = 237.97 (s) ]
04/04/2022 07:57:05 AM: [ dev valid official: Epoch = 10 | bleu = 18.70 | rouge_l = 23.85 | Precision = 30.03 | Recall = 26.31 | F1 = 25.36 | examples = 7414 | valid time = 110.29 (s) ]
04/04/2022 08:01:26 AM: [ train: Epoch 11 | perplexity = 36.67 | ml_loss = 40.70 | Time for epoch = 260.55 (s) ]
04/04/2022 08:03:26 AM: [ dev valid official: Epoch = 11 | bleu = 18.42 | rouge_l = 23.52 | Precision = 31.15 | Recall = 24.82 | F1 = 24.96 | examples = 7414 | valid time = 118.02 (s) ]
04/04/2022 08:07:41 AM: [ train: Epoch 12 | perplexity = 32.27 | ml_loss = 39.33 | Time for epoch = 255.50 (s) ]
04/04/2022 08:09:33 AM: [ dev valid official: Epoch = 12 | bleu = 19.85 | rouge_l = 24.92 | Precision = 35.15 | Recall = 25.57 | F1 = 26.64 | examples = 7414 | valid time = 109.95 (s) ]
04/04/2022 08:13:41 AM: [ train: Epoch 13 | perplexity = 28.88 | ml_loss = 38.08 | Time for epoch = 247.60 (s) ]
04/04/2022 08:15:33 AM: [ dev valid official: Epoch = 13 | bleu = 18.59 | rouge_l = 25.00 | Precision = 30.45 | Recall = 28.16 | F1 = 26.36 | examples = 7414 | valid time = 109.95 (s) ]
04/04/2022 08:19:35 AM: [ train: Epoch 14 | perplexity = 26.13 | ml_loss = 36.89 | Time for epoch = 242.35 (s) ]
04/04/2022 08:21:26 AM: [ dev valid official: Epoch = 14 | bleu = 20.62 | rouge_l = 25.57 | Precision = 35.94 | Recall = 26.05 | F1 = 27.41 | examples = 7414 | valid time = 108.39 (s) ]
04/04/2022 08:21:26 AM: [ Best valid: bleu = 20.62 (epoch 14, 27720 updates) ]
04/04/2022 08:25:29 AM: [ train: Epoch 15 | perplexity = 23.70 | ml_loss = 35.83 | Time for epoch = 242.04 (s) ]
04/04/2022 08:27:23 AM: [ dev valid official: Epoch = 15 | bleu = 19.41 | rouge_l = 24.39 | Precision = 30.71 | Recall = 26.76 | F1 = 25.94 | examples = 7414 | valid time = 112.25 (s) ]
04/04/2022 08:31:37 AM: [ train: Epoch 16 | perplexity = 21.57 | ml_loss = 34.75 | Time for epoch = 253.90 (s) ]
04/04/2022 08:33:40 AM: [ dev valid official: Epoch = 16 | bleu = 19.87 | rouge_l = 25.16 | Precision = 34.45 | Recall = 26.05 | F1 = 27.00 | examples = 7414 | valid time = 121.52 (s) ]
04/04/2022 08:37:46 AM: [ train: Epoch 17 | perplexity = 19.75 | ml_loss = 33.77 | Time for epoch = 245.31 (s) ]
04/04/2022 08:39:38 AM: [ dev valid official: Epoch = 17 | bleu = 19.63 | rouge_l = 24.72 | Precision = 32.98 | Recall = 26.16 | F1 = 26.46 | examples = 7414 | valid time = 109.75 (s) ]
04/04/2022 08:43:42 AM: [ train: Epoch 18 | perplexity = 18.03 | ml_loss = 32.80 | Time for epoch = 244.91 (s) ]
04/04/2022 08:45:33 AM: [ dev valid official: Epoch = 18 | bleu = 20.10 | rouge_l = 25.08 | Precision = 33.78 | Recall = 26.24 | F1 = 26.82 | examples = 7414 | valid time = 108.52 (s) ]
04/04/2022 08:49:40 AM: [ train: Epoch 19 | perplexity = 16.53 | ml_loss = 31.86 | Time for epoch = 246.56 (s) ]
04/04/2022 08:51:29 AM: [ dev valid official: Epoch = 19 | bleu = 20.14 | rouge_l = 25.27 | Precision = 33.42 | Recall = 26.64 | F1 = 26.99 | examples = 7414 | valid time = 107.39 (s) ]
04/04/2022 08:55:36 AM: [ train: Epoch 20 | perplexity = 15.33 | ml_loss = 30.96 | Time for epoch = 246.61 (s) ]
04/04/2022 08:57:26 AM: [ dev valid official: Epoch = 20 | bleu = 19.63 | rouge_l = 25.03 | Precision = 32.75 | Recall = 26.98 | F1 = 26.91 | examples = 7414 | valid time = 108.23 (s) ]
04/04/2022 09:01:26 AM: [ train: Epoch 21 | perplexity = 14.23 | ml_loss = 30.08 | Time for epoch = 240.46 (s) ]
04/04/2022 09:03:16 AM: [ dev valid official: Epoch = 21 | bleu = 19.91 | rouge_l = 24.86 | Precision = 33.26 | Recall = 26.11 | F1 = 26.57 | examples = 7414 | valid time = 107.45 (s) ]
04/04/2022 09:07:23 AM: [ train: Epoch 22 | perplexity = 13.13 | ml_loss = 29.26 | Time for epoch = 247.58 (s) ]
04/04/2022 09:09:15 AM: [ dev valid official: Epoch = 22 | bleu = 19.15 | rouge_l = 23.80 | Precision = 30.95 | Recall = 25.53 | F1 = 25.39 | examples = 7414 | valid time = 109.77 (s) ]
04/04/2022 09:13:20 AM: [ train: Epoch 23 | perplexity = 12.49 | ml_loss = 28.52 | Time for epoch = 244.84 (s) ]
04/04/2022 09:15:10 AM: [ dev valid official: Epoch = 23 | bleu = 19.82 | rouge_l = 23.75 | Precision = 33.52 | Recall = 24.37 | F1 = 25.43 | examples = 7414 | valid time = 108.26 (s) ]
04/04/2022 09:19:21 AM: [ train: Epoch 24 | perplexity = 11.49 | ml_loss = 27.74 | Time for epoch = 251.02 (s) ]
04/04/2022 09:21:13 AM: [ dev valid official: Epoch = 24 | bleu = 20.41 | rouge_l = 24.44 | Precision = 34.34 | Recall = 24.85 | F1 = 26.24 | examples = 7414 | valid time = 109.61 (s) ]
04/04/2022 09:25:23 AM: [ train: Epoch 25 | perplexity = 10.76 | ml_loss = 26.95 | Time for epoch = 249.80 (s) ]
04/04/2022 09:27:14 AM: [ dev valid official: Epoch = 25 | bleu = 19.73 | rouge_l = 24.30 | Precision = 32.76 | Recall = 25.74 | F1 = 26.08 | examples = 7414 | valid time = 109.61 (s) ]
04/04/2022 09:31:22 AM: [ train: Epoch 26 | perplexity = 10.16 | ml_loss = 26.26 | Time for epoch = 247.90 (s) ]
04/04/2022 09:33:11 AM: [ dev valid official: Epoch = 26 | bleu = 19.97 | rouge_l = 24.67 | Precision = 32.69 | Recall = 26.14 | F1 = 26.38 | examples = 7414 | valid time = 107.10 (s) ]
04/04/2022 09:37:19 AM: [ train: Epoch 27 | perplexity = 9.60 | ml_loss = 25.57 | Time for epoch = 247.51 (s) ]
04/04/2022 09:39:12 AM: [ dev valid official: Epoch = 27 | bleu = 19.50 | rouge_l = 24.03 | Precision = 31.79 | Recall = 25.77 | F1 = 25.73 | examples = 7414 | valid time = 111.04 (s) ]
04/04/2022 09:43:30 AM: [ train: Epoch 28 | perplexity = 8.87 | ml_loss = 24.92 | Time for epoch = 258.27 (s) ]
04/04/2022 09:45:24 AM: [ dev valid official: Epoch = 28 | bleu = 20.47 | rouge_l = 24.19 | Precision = 33.43 | Recall = 24.85 | F1 = 25.91 | examples = 7414 | valid time = 112.00 (s) ]
04/04/2022 09:49:40 AM: [ train: Epoch 29 | perplexity = 8.38 | ml_loss = 24.26 | Time for epoch = 255.45 (s) ]
04/04/2022 09:51:33 AM: [ dev valid official: Epoch = 29 | bleu = 19.49 | rouge_l = 23.43 | Precision = 31.15 | Recall = 24.87 | F1 = 25.03 | examples = 7414 | valid time = 110.77 (s) ]
04/04/2022 09:55:45 AM: [ train: Epoch 30 | perplexity = 8.00 | ml_loss = 23.64 | Time for epoch = 252.79 (s) ]
04/04/2022 09:57:38 AM: [ dev valid official: Epoch = 30 | bleu = 19.97 | rouge_l = 23.81 | Precision = 32.25 | Recall = 24.93 | F1 = 25.52 | examples = 7414 | valid time = 110.31 (s) ]
04/04/2022 10:01:45 AM: [ train: Epoch 31 | perplexity = 7.59 | ml_loss = 23.02 | Time for epoch = 247.37 (s) ]
04/04/2022 10:03:37 AM: [ dev valid official: Epoch = 31 | bleu = 19.39 | rouge_l = 23.40 | Precision = 31.13 | Recall = 24.90 | F1 = 24.98 | examples = 7414 | valid time = 110.86 (s) ]
04/04/2022 10:07:44 AM: [ train: Epoch 32 | perplexity = 7.20 | ml_loss = 22.44 | Time for epoch = 246.49 (s) ]
04/04/2022 10:09:37 AM: [ dev valid official: Epoch = 32 | bleu = 19.20 | rouge_l = 22.76 | Precision = 30.59 | Recall = 24.00 | F1 = 24.31 | examples = 7414 | valid time = 111.97 (s) ]
04/04/2022 10:13:53 AM: [ train: Epoch 33 | perplexity = 6.81 | ml_loss = 21.93 | Time for epoch = 255.52 (s) ]
04/04/2022 10:15:45 AM: [ dev valid official: Epoch = 33 | bleu = 18.99 | rouge_l = 23.00 | Precision = 30.27 | Recall = 24.79 | F1 = 24.61 | examples = 7414 | valid time = 111.25 (s) ]
04/04/2022 10:19:53 AM: [ train: Epoch 34 | perplexity = 6.55 | ml_loss = 21.41 | Time for epoch = 248.14 (s) ]
04/04/2022 10:21:47 AM: [ dev valid official: Epoch = 34 | bleu = 18.86 | rouge_l = 23.53 | Precision = 29.54 | Recall = 26.25 | F1 = 25.12 | examples = 7414 | valid time = 111.92 (s) ]
