04/15/2022 04:25:56 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name go --data_dir ../../data/ --model_dir ../../tmp --model_name full_go_6 --train_src train/code.original_subtoken --train_tgt train/javadoc.original --dev_src dev/code.original_subtoken --dev_tgt dev/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 300 --max_tgt_len 100 --emsize 512 --fix_embeddings False --src_vocab_size 37000 --tgt_vocab_size 27000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 32 --use_neg_dist True --nlayers 6 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True --split_decoder True ]
04/15/2022 04:25:56 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/15/2022 04:25:56 PM: [ Load and process data files ]
04/15/2022 04:26:01 PM: [ Num train examples = 69530 ]
04/15/2022 04:26:01 PM: [ Dataset weights = {3: 1.0} ]
04/15/2022 04:26:01 PM: [ Num dev examples = 8714 ]
04/15/2022 04:26:01 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/15/2022 04:26:01 PM: [ Training model from scratch... ]
04/15/2022 04:26:01 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/15/2022 04:26:01 PM: [ Build word dictionary ]
04/15/2022 04:26:04 PM: [ Num words in source = 35085 and target = 17574 ]
04/15/2022 04:26:04 PM: [ Trainable #parameters [encoder-decoder] 69.4M [total] 98.3M ]
04/15/2022 04:26:04 PM: [ Breakdown of the trainable paramters
+------------------------------------------------------------------------------+--------------+----------+
| Layer Name                                                                   | Output Shape |  Param # |
+------------------------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight                | [35085, 512] | 17963520 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight                | [17574, 512] |  8997888 |
| embedder.tgt_pos_embeddings.weight                                           |   [102, 512] |    52224 |
| encoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer_c.layer.0.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_c.layer.0.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.0.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.0.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.0.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_c.layer.0.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_c.layer.0.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.0.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.0.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.0.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_c.layer.0.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.0.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_c.layer.0.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_c.layer.0.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_c.layer.0.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_c.layer.0.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_c.layer.0.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.0.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_c.layer.0.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_c.layer.1.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_c.layer.1.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.1.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.1.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.1.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_c.layer.1.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_c.layer.1.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.1.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.1.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.1.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_c.layer.1.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.1.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_c.layer.1.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_c.layer.1.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_c.layer.1.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_c.layer.1.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_c.layer.1.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.1.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_c.layer.1.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_c.layer.2.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_c.layer.2.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.2.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.2.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.2.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_c.layer.2.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_c.layer.2.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.2.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.2.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.2.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_c.layer.2.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.2.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_c.layer.2.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_c.layer.2.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_c.layer.2.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_c.layer.2.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_c.layer.2.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.2.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_c.layer.2.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_c.layer.3.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_c.layer.3.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.3.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.3.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.3.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_c.layer.3.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_c.layer.3.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.3.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.3.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.3.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_c.layer.3.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.3.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_c.layer.3.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_c.layer.3.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_c.layer.3.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_c.layer.3.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_c.layer.3.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.3.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_c.layer.3.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_c.layer.4.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_c.layer.4.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.4.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.4.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.4.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_c.layer.4.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_c.layer.4.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.4.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.4.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.4.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_c.layer.4.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.4.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_c.layer.4.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_c.layer.4.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_c.layer.4.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_c.layer.4.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_c.layer.4.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.4.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_c.layer.4.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_c.layer.5.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_c.layer.5.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.5.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_c.layer.5.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.5.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_c.layer.5.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_c.layer.5.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_c.layer.5.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.5.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_c.layer.5.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_c.layer.5.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.5.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_c.layer.5.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_c.layer.5.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_c.layer.5.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_c.layer.5.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_c.layer.5.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_c.layer.5.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_c.layer.5.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_d.layer.0.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_d.layer.0.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.0.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.0.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.0.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_d.layer.0.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_d.layer.0.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.0.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.0.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.0.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_d.layer.0.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.0.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_d.layer.0.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_d.layer.0.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_d.layer.0.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_d.layer.0.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_d.layer.0.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.0.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_d.layer.0.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_d.layer.1.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_d.layer.1.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.1.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.1.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.1.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_d.layer.1.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_d.layer.1.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.1.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.1.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.1.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_d.layer.1.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.1.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_d.layer.1.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_d.layer.1.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_d.layer.1.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_d.layer.1.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_d.layer.1.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.1.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_d.layer.1.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_d.layer.2.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_d.layer.2.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.2.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.2.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.2.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_d.layer.2.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_d.layer.2.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.2.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.2.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.2.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_d.layer.2.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.2.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_d.layer.2.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_d.layer.2.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_d.layer.2.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_d.layer.2.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_d.layer.2.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.2.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_d.layer.2.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_d.layer.3.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_d.layer.3.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.3.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.3.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.3.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_d.layer.3.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_d.layer.3.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.3.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.3.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.3.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_d.layer.3.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.3.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_d.layer.3.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_d.layer.3.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_d.layer.3.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_d.layer.3.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_d.layer.3.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.3.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_d.layer.3.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_d.layer.4.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_d.layer.4.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.4.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.4.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.4.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_d.layer.4.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_d.layer.4.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.4.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.4.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.4.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_d.layer.4.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.4.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_d.layer.4.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_d.layer.4.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_d.layer.4.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_d.layer.4.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_d.layer.4.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.4.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_d.layer.4.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer_d.layer.5.attention.key.weight                           |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.attention.key.bias                             |        [512] |      512 |
| decoder.transformer_d.layer.5.attention.query.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.attention.query.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.5.attention.value.weight                         |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.attention.value.bias                           |        [512] |      512 |
| decoder.transformer_d.layer.5.attention.output.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.attention.output.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.5.layer_norm.weight                              |        [512] |      512 |
| decoder.transformer_d.layer.5.layer_norm.bias                                |        [512] |      512 |
| decoder.transformer_d.layer.5.context_attn.key.weight                        |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.context_attn.key.bias                          |        [512] |      512 |
| decoder.transformer_d.layer.5.context_attn.query.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.context_attn.query.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.5.context_attn.value.weight                      |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.context_attn.value.bias                        |        [512] |      512 |
| decoder.transformer_d.layer.5.context_attn.output.weight                     |   [512, 512] |   262144 |
| decoder.transformer_d.layer.5.context_attn.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.5.layer_norm_2.weight                            |        [512] |      512 |
| decoder.transformer_d.layer.5.layer_norm_2.bias                              |        [512] |      512 |
| decoder.transformer_d.layer.5.feed_forward.intermediate.weight               |  [2048, 512] |  1048576 |
| decoder.transformer_d.layer.5.feed_forward.intermediate.bias                 |       [2048] |     2048 |
| decoder.transformer_d.layer.5.feed_forward.output.weight                     |  [512, 2048] |  1048576 |
| decoder.transformer_d.layer.5.feed_forward.output.bias                       |        [512] |      512 |
| decoder.transformer_d.layer.5.feed_forward.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer_d.layer.5.feed_forward.layer_norm.bias                   |        [512] |      512 |
| decoder.fusion_sigmoid.0.weight                                              |  [512, 1024] |   524288 |
| decoder.fusion_sigmoid.0.bias                                                |        [512] |      512 |
| decoder.fusion_gate.0.weight                                                 |  [512, 1024] |   524288 |
| decoder.fusion_gate.0.bias                                                   |        [512] |      512 |
| generator.bias                                                               |      [17574] |    17574 |
| copy_attn.linear_in.weight                                                   |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                                  |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                                            |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                                              |          [1] |        1 |
+------------------------------------------------------------------------------+--------------+----------+ ]
04/15/2022 04:26:06 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/15/2022 04:26:06 PM: [ Make data loaders ]
04/15/2022 04:26:06 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/15/2022 04:26:06 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": true,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "go"
    ],
    "dataset_weights": {
        "3": 1.0
    },
    "dev_src": [
        "dev/code.original_subtoken"
    ],
    "dev_src_files": [
        "../../data/go/dev/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_tgt": [
        "dev/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/go/dev/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/full_go_6.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        32
    ],
    "max_src_len": 300,
    "max_tgt_len": 100,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/full_go_6.mdl",
    "model_name": "full_go_6",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 6,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 69530,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/full_go_6.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": true,
    "src_pos_emb": false,
    "src_vocab_size": 37000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 27000,
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_files": [
        "../../data/go/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/go/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
04/15/2022 04:26:06 PM: [ ---------------------------------------------------------------------------------------------------- ]
04/15/2022 04:26:06 PM: [ Starting training... ]
04/15/2022 04:33:29 PM: [ train: Epoch 1 | perplexity = 3300.60 | ml_loss = 155.88 | Time for epoch = 442.31 (s) ]
04/15/2022 04:39:24 PM: [ dev valid official: Epoch = 1 | bleu = 10.85 | rouge_l = 21.91 | Precision = 33.10 | Recall = 21.69 | F1 = 23.78 | examples = 8714 | valid time = 353.34 (s) ]
04/15/2022 04:39:24 PM: [ Best valid: bleu = 10.85 (epoch 1, 2173 updates) ]
04/15/2022 04:46:26 PM: [ train: Epoch 2 | perplexity = 303.38 | ml_loss = 114.92 | Time for epoch = 421.77 (s) ]
04/15/2022 04:52:15 PM: [ dev valid official: Epoch = 2 | bleu = 12.97 | rouge_l = 26.73 | Precision = 33.90 | Recall = 28.44 | F1 = 28.54 | examples = 8714 | valid time = 347.17 (s) ]
04/15/2022 04:52:15 PM: [ Best valid: bleu = 12.97 (epoch 2, 4346 updates) ]
04/15/2022 04:59:17 PM: [ train: Epoch 3 | perplexity = 121.68 | ml_loss = 97.76 | Time for epoch = 421.70 (s) ]
04/15/2022 05:05:06 PM: [ dev valid official: Epoch = 3 | bleu = 15.40 | rouge_l = 30.90 | Precision = 41.44 | Recall = 31.21 | F1 = 33.05 | examples = 8714 | valid time = 347.45 (s) ]
04/15/2022 05:05:06 PM: [ Best valid: bleu = 15.40 (epoch 3, 6519 updates) ]
04/15/2022 05:12:11 PM: [ train: Epoch 4 | perplexity = 78.97 | ml_loss = 89.34 | Time for epoch = 424.23 (s) ]
04/15/2022 05:18:04 PM: [ dev valid official: Epoch = 4 | bleu = 16.15 | rouge_l = 32.47 | Precision = 43.57 | Recall = 33.16 | F1 = 34.88 | examples = 8714 | valid time = 350.87 (s) ]
04/15/2022 05:18:04 PM: [ Best valid: bleu = 16.15 (epoch 4, 8692 updates) ]
04/15/2022 05:24:58 PM: [ train: Epoch 5 | perplexity = 63.63 | ml_loss = 84.50 | Time for epoch = 412.84 (s) ]
04/15/2022 05:30:47 PM: [ dev valid official: Epoch = 5 | bleu = 16.44 | rouge_l = 33.02 | Precision = 42.66 | Recall = 34.26 | F1 = 35.33 | examples = 8714 | valid time = 347.37 (s) ]
04/15/2022 05:30:47 PM: [ Best valid: bleu = 16.44 (epoch 5, 10865 updates) ]
04/15/2022 05:37:44 PM: [ train: Epoch 6 | perplexity = 52.43 | ml_loss = 80.98 | Time for epoch = 416.25 (s) ]
04/15/2022 05:43:35 PM: [ dev valid official: Epoch = 6 | bleu = 16.99 | rouge_l = 34.07 | Precision = 44.47 | Recall = 35.50 | F1 = 36.78 | examples = 8714 | valid time = 350.24 (s) ]
04/15/2022 05:43:35 PM: [ Best valid: bleu = 16.99 (epoch 6, 13038 updates) ]
04/15/2022 05:51:00 PM: [ train: Epoch 7 | perplexity = 40.32 | ml_loss = 77.92 | Time for epoch = 443.55 (s) ]
04/15/2022 05:56:48 PM: [ dev valid official: Epoch = 7 | bleu = 17.66 | rouge_l = 34.51 | Precision = 45.87 | Recall = 35.44 | F1 = 37.29 | examples = 8714 | valid time = 346.39 (s) ]
04/15/2022 05:56:48 PM: [ Best valid: bleu = 17.66 (epoch 7, 15211 updates) ]
04/15/2022 06:03:56 PM: [ train: Epoch 8 | perplexity = 37.51 | ml_loss = 75.40 | Time for epoch = 427.59 (s) ]
04/15/2022 06:09:48 PM: [ dev valid official: Epoch = 8 | bleu = 17.56 | rouge_l = 34.82 | Precision = 45.64 | Recall = 36.60 | F1 = 37.68 | examples = 8714 | valid time = 349.42 (s) ]
04/15/2022 06:16:51 PM: [ train: Epoch 9 | perplexity = 33.86 | ml_loss = 73.16 | Time for epoch = 423.20 (s) ]
04/15/2022 06:22:42 PM: [ dev valid official: Epoch = 9 | bleu = 17.97 | rouge_l = 35.87 | Precision = 51.66 | Recall = 35.28 | F1 = 39.17 | examples = 8714 | valid time = 349.32 (s) ]
04/15/2022 06:22:42 PM: [ Best valid: bleu = 17.97 (epoch 9, 19557 updates) ]
04/15/2022 06:30:07 PM: [ train: Epoch 10 | perplexity = 28.13 | ml_loss = 71.05 | Time for epoch = 444.45 (s) ]
04/15/2022 06:35:57 PM: [ dev valid official: Epoch = 10 | bleu = 17.63 | rouge_l = 34.30 | Precision = 46.68 | Recall = 34.87 | F1 = 37.25 | examples = 8714 | valid time = 347.54 (s) ]
04/15/2022 06:43:22 PM: [ train: Epoch 11 | perplexity = 25.06 | ml_loss = 69.07 | Time for epoch = 445.38 (s) ]
04/15/2022 06:49:12 PM: [ dev valid official: Epoch = 11 | bleu = 17.19 | rouge_l = 33.94 | Precision = 45.54 | Recall = 35.03 | F1 = 36.95 | examples = 8714 | valid time = 347.50 (s) ]
04/15/2022 06:56:30 PM: [ train: Epoch 12 | perplexity = 23.69 | ml_loss = 67.26 | Time for epoch = 438.64 (s) ]
04/15/2022 07:02:19 PM: [ dev valid official: Epoch = 12 | bleu = 18.10 | rouge_l = 35.29 | Precision = 46.86 | Recall = 36.36 | F1 = 38.32 | examples = 8714 | valid time = 346.86 (s) ]
04/15/2022 07:02:19 PM: [ Best valid: bleu = 18.10 (epoch 12, 26076 updates) ]
04/15/2022 07:09:45 PM: [ train: Epoch 13 | perplexity = 21.18 | ml_loss = 65.55 | Time for epoch = 444.70 (s) ]
04/15/2022 07:15:35 PM: [ dev valid official: Epoch = 13 | bleu = 18.07 | rouge_l = 34.89 | Precision = 45.73 | Recall = 36.57 | F1 = 37.93 | examples = 8714 | valid time = 348.92 (s) ]
04/15/2022 07:22:31 PM: [ train: Epoch 14 | perplexity = 22.15 | ml_loss = 64.00 | Time for epoch = 415.45 (s) ]
04/15/2022 07:28:21 PM: [ dev valid official: Epoch = 14 | bleu = 17.73 | rouge_l = 34.61 | Precision = 44.86 | Recall = 36.96 | F1 = 37.64 | examples = 8714 | valid time = 348.06 (s) ]
04/15/2022 07:35:13 PM: [ train: Epoch 15 | perplexity = 20.93 | ml_loss = 62.58 | Time for epoch = 412.26 (s) ]
04/15/2022 07:41:04 PM: [ dev valid official: Epoch = 15 | bleu = 17.89 | rouge_l = 34.84 | Precision = 44.49 | Recall = 37.61 | F1 = 37.99 | examples = 8714 | valid time = 349.22 (s) ]
04/15/2022 07:47:57 PM: [ train: Epoch 16 | perplexity = 19.50 | ml_loss = 61.21 | Time for epoch = 412.75 (s) ]
04/15/2022 07:53:45 PM: [ dev valid official: Epoch = 16 | bleu = 18.12 | rouge_l = 34.54 | Precision = 45.77 | Recall = 35.85 | F1 = 37.47 | examples = 8714 | valid time = 346.72 (s) ]
04/15/2022 07:53:45 PM: [ Best valid: bleu = 18.12 (epoch 16, 34768 updates) ]
04/15/2022 08:01:02 PM: [ train: Epoch 17 | perplexity = 16.06 | ml_loss = 59.84 | Time for epoch = 436.83 (s) ]
04/15/2022 08:06:50 PM: [ dev valid official: Epoch = 17 | bleu = 18.11 | rouge_l = 34.41 | Precision = 44.68 | Recall = 36.38 | F1 = 37.36 | examples = 8714 | valid time = 345.72 (s) ]
04/15/2022 08:13:55 PM: [ train: Epoch 18 | perplexity = 15.99 | ml_loss = 58.48 | Time for epoch = 425.18 (s) ]
04/15/2022 08:19:44 PM: [ dev valid official: Epoch = 18 | bleu = 18.32 | rouge_l = 34.91 | Precision = 43.38 | Recall = 38.60 | F1 = 37.82 | examples = 8714 | valid time = 346.98 (s) ]
04/15/2022 08:19:44 PM: [ Best valid: bleu = 18.32 (epoch 18, 39114 updates) ]
04/15/2022 08:27:04 PM: [ train: Epoch 19 | perplexity = 14.13 | ml_loss = 57.18 | Time for epoch = 439.67 (s) ]
04/15/2022 08:32:59 PM: [ dev valid official: Epoch = 19 | bleu = 17.89 | rouge_l = 34.23 | Precision = 44.14 | Recall = 36.33 | F1 = 36.98 | examples = 8714 | valid time = 353.07 (s) ]
04/15/2022 08:40:13 PM: [ train: Epoch 20 | perplexity = 13.39 | ml_loss = 55.90 | Time for epoch = 433.80 (s) ]
04/15/2022 08:46:04 PM: [ dev valid official: Epoch = 20 | bleu = 17.58 | rouge_l = 33.64 | Precision = 42.11 | Recall = 36.72 | F1 = 36.34 | examples = 8714 | valid time = 349.38 (s) ]
04/15/2022 08:53:12 PM: [ train: Epoch 21 | perplexity = 12.95 | ml_loss = 54.73 | Time for epoch = 427.84 (s) ]
04/15/2022 08:59:00 PM: [ dev valid official: Epoch = 21 | bleu = 17.83 | rouge_l = 33.94 | Precision = 43.57 | Recall = 36.37 | F1 = 36.70 | examples = 8714 | valid time = 345.70 (s) ]
04/15/2022 09:06:03 PM: [ train: Epoch 22 | perplexity = 13.23 | ml_loss = 53.60 | Time for epoch = 423.49 (s) ]
04/15/2022 09:11:51 PM: [ dev valid official: Epoch = 22 | bleu = 17.80 | rouge_l = 33.72 | Precision = 43.89 | Recall = 35.62 | F1 = 36.58 | examples = 8714 | valid time = 345.76 (s) ]
04/15/2022 09:19:06 PM: [ train: Epoch 23 | perplexity = 11.18 | ml_loss = 52.53 | Time for epoch = 435.66 (s) ]
04/15/2022 09:24:53 PM: [ dev valid official: Epoch = 23 | bleu = 18.21 | rouge_l = 34.41 | Precision = 44.81 | Recall = 36.45 | F1 = 37.31 | examples = 8714 | valid time = 345.39 (s) ]
04/15/2022 09:31:49 PM: [ train: Epoch 24 | perplexity = 11.82 | ml_loss = 51.49 | Time for epoch = 415.81 (s) ]
04/15/2022 09:37:36 PM: [ dev valid official: Epoch = 24 | bleu = 17.62 | rouge_l = 33.55 | Precision = 43.36 | Recall = 35.18 | F1 = 36.16 | examples = 8714 | valid time = 345.28 (s) ]
04/15/2022 09:44:26 PM: [ train: Epoch 25 | perplexity = 11.50 | ml_loss = 50.47 | Time for epoch = 409.67 (s) ]
04/15/2022 09:50:12 PM: [ dev valid official: Epoch = 25 | bleu = 17.43 | rouge_l = 33.47 | Precision = 43.22 | Recall = 35.39 | F1 = 36.12 | examples = 8714 | valid time = 344.60 (s) ]
04/15/2022 09:56:59 PM: [ train: Epoch 26 | perplexity = 11.02 | ml_loss = 49.50 | Time for epoch = 406.65 (s) ]
04/15/2022 10:02:47 PM: [ dev valid official: Epoch = 26 | bleu = 18.10 | rouge_l = 34.01 | Precision = 44.70 | Recall = 35.69 | F1 = 36.86 | examples = 8714 | valid time = 346.89 (s) ]
04/15/2022 10:09:41 PM: [ train: Epoch 27 | perplexity = 10.29 | ml_loss = 48.59 | Time for epoch = 413.08 (s) ]
04/15/2022 10:15:27 PM: [ dev valid official: Epoch = 27 | bleu = 17.52 | rouge_l = 33.34 | Precision = 41.79 | Recall = 36.59 | F1 = 36.00 | examples = 8714 | valid time = 344.22 (s) ]
04/15/2022 10:22:18 PM: [ train: Epoch 28 | perplexity = 9.98 | ml_loss = 47.64 | Time for epoch = 411.31 (s) ]
04/15/2022 10:28:04 PM: [ dev valid official: Epoch = 28 | bleu = 17.62 | rouge_l = 33.33 | Precision = 42.62 | Recall = 35.73 | F1 = 35.93 | examples = 8714 | valid time = 344.15 (s) ]
04/15/2022 10:35:15 PM: [ train: Epoch 29 | perplexity = 8.43 | ml_loss = 46.66 | Time for epoch = 431.69 (s) ]
04/15/2022 10:41:02 PM: [ dev valid official: Epoch = 29 | bleu = 17.85 | rouge_l = 33.65 | Precision = 42.70 | Recall = 35.90 | F1 = 36.19 | examples = 8714 | valid time = 345.17 (s) ]
04/15/2022 10:48:15 PM: [ train: Epoch 30 | perplexity = 8.13 | ml_loss = 45.69 | Time for epoch = 432.83 (s) ]
04/15/2022 10:54:05 PM: [ dev valid official: Epoch = 30 | bleu = 17.88 | rouge_l = 33.26 | Precision = 42.51 | Recall = 35.32 | F1 = 35.88 | examples = 8714 | valid time = 348.67 (s) ]
04/15/2022 11:01:21 PM: [ train: Epoch 31 | perplexity = 7.55 | ml_loss = 44.80 | Time for epoch = 436.18 (s) ]
04/15/2022 11:07:07 PM: [ dev valid official: Epoch = 31 | bleu = 17.94 | rouge_l = 33.19 | Precision = 41.90 | Recall = 35.72 | F1 = 35.86 | examples = 8714 | valid time = 343.53 (s) ]
04/15/2022 11:14:13 PM: [ train: Epoch 32 | perplexity = 7.56 | ml_loss = 43.91 | Time for epoch = 425.38 (s) ]
04/15/2022 11:20:02 PM: [ dev valid official: Epoch = 32 | bleu = 17.47 | rouge_l = 33.17 | Precision = 41.48 | Recall = 36.31 | F1 = 35.85 | examples = 8714 | valid time = 347.03 (s) ]
04/15/2022 11:26:55 PM: [ train: Epoch 33 | perplexity = 7.79 | ml_loss = 43.07 | Time for epoch = 413.04 (s) ]
04/15/2022 11:32:42 PM: [ dev valid official: Epoch = 33 | bleu = 18.02 | rouge_l = 33.75 | Precision = 43.26 | Recall = 36.25 | F1 = 36.61 | examples = 8714 | valid time = 344.25 (s) ]
04/15/2022 11:39:28 PM: [ train: Epoch 34 | perplexity = 7.71 | ml_loss = 42.29 | Time for epoch = 406.89 (s) ]
04/15/2022 11:45:21 PM: [ dev valid official: Epoch = 34 | bleu = 17.46 | rouge_l = 33.00 | Precision = 41.79 | Recall = 35.72 | F1 = 35.69 | examples = 8714 | valid time = 349.88 (s) ]
04/15/2022 11:52:36 PM: [ train: Epoch 35 | perplexity = 6.56 | ml_loss = 41.56 | Time for epoch = 434.83 (s) ]
04/15/2022 11:58:27 PM: [ dev valid official: Epoch = 35 | bleu = 17.01 | rouge_l = 32.73 | Precision = 40.15 | Recall = 36.93 | F1 = 35.40 | examples = 8714 | valid time = 349.39 (s) ]
04/16/2022 12:05:34 AM: [ train: Epoch 36 | perplexity = 6.49 | ml_loss = 40.72 | Time for epoch = 427.65 (s) ]
04/16/2022 12:11:23 AM: [ dev valid official: Epoch = 36 | bleu = 16.82 | rouge_l = 32.47 | Precision = 39.89 | Recall = 36.49 | F1 = 35.03 | examples = 8714 | valid time = 347.20 (s) ]
04/16/2022 12:18:37 AM: [ train: Epoch 37 | perplexity = 6.09 | ml_loss = 39.95 | Time for epoch = 433.68 (s) ]
04/16/2022 12:24:24 AM: [ dev valid official: Epoch = 37 | bleu = 17.45 | rouge_l = 32.99 | Precision = 41.09 | Recall = 36.33 | F1 = 35.61 | examples = 8714 | valid time = 345.17 (s) ]
04/16/2022 12:31:13 AM: [ train: Epoch 38 | perplexity = 6.47 | ml_loss = 39.24 | Time for epoch = 408.93 (s) ]
04/16/2022 12:37:01 AM: [ dev valid official: Epoch = 38 | bleu = 16.96 | rouge_l = 32.17 | Precision = 39.43 | Recall = 36.12 | F1 = 34.79 | examples = 8714 | valid time = 346.52 (s) ]
