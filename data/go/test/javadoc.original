must Wait Pin Ready waits up to second until connection is up pin endpoint Fatal on time out 
new Gateway Command returns the cobra command for gateway 
New Limited Buffer Reader returns a reader that reads from the given reader but limits the amount of data returned to at most n bytes 
With Abort Context specifies the context for permanently aborting the transaction 
With Prefetch is a hint to prefetch a list of keys before trying to apply If an STM transaction will unconditionally fetch a set of keys prefetching those keys will save the round trip cost from requesting each key one by one with Get 
New STM initiates a new STM instance using serializable snapshot isolation by default 
first returns the store revision from the first fetch 
cmps guards the txn from updates to read set 
cmps returns a cmp list testing no writes have happened past rev 
puts is the list of ops for all pending writes 
New STMRepeatable is deprecated 
New STMSerializable is deprecated 
New STMRead Committed is deprecated 
New Cert Pool creates x cert Pool with provided CA files 
New Cert generates TLS cert by using the given cert key and parse function 
New GRPCLogger V converts zap Logger to grpclog Logger V It discards all INFO level logging in g RPC if debug level is not enabled in zap Logger 
New GRPCLogger V From Zap Core creates grpclog Logger V from zap Core and zapcore Write Syncer It discards all INFO level logging in g RPC if debug level is not enabled in zap Logger 
Pause pauses the peer The peer will simply drops all incoming messages without returning an error 
Resume resumes a paused peer 
pick picks a chan for sending the given message The picked chan and the picked chan string name are returned 
post posts the given request It returns nil when request is sent out and processed successfully 
new Txn Resp allocates a txn response for a txn request given a path 
apply Compare applies the compare request If the comparison succeeds it returns true Otherwise returns false 
Op Compact wraps slice Compact Option to create a Compact Op 
New Priority Queue creates an etcd priority queue 
Enqueue puts a value into a queue with a given priority 
New Leader Stats generates a new Leader Stats with the given id as leader 
Succ updates the Follower Stats with a successful send 
Fail updates the Follower Stats with an unsuccessful send 
delete removes a watcher and returns the number of remaining watchers 
start Stream Writer creates a stream Write and starts a long running go routine that accepts messages and writes to the attached outgoing connection 
check Stream Support checks whether the stream type is supported in the given version 
maybe Update returns false if the given n index comes from an outdated message Otherwise it updates the progress and returns true 
maybe Decr To returns false if the given to index comes from an out of order message Otherwise it decreases the progress next index to min rejected last and returns true 
Is Paused returns whether sending log entries to this node has been paused A node may be paused because it has rejected recent Msg Apps is currently waiting for a snapshot or has reached the Max Inflight Msgs limit 
need Snapshot Abort returns true if snapshot progress s Match is equal or higher than the pending Snapshot 
add adds an inflight into inflights 
grow the inflight buffer by doubling up to inflights size We grow on demand instead of preallocating to inflights size to handle systems which have thousands of Raft groups per process 
free To frees the inflights smaller or equal to the given to flight 
Canonical URLPath returns the canonical url path for p which follows the rules the path always starts with replace multiple slashes with a single slash replace each path name element with equivalent one keep the trailing slash The function is borrowed from stdlib http clean Path in server go 
Save DBFrom saves snapshot of the database from the given reader It guarantees the save operation is atomic 
DBFile Path returns the file path for the snapshot of the database with given id If the snapshot does not exist it returns error 
Set parses a command line set of strings separated by comma Implements flag Value interface The values are set in order 
New Unique Strings Value implements string slice as flag Value interface Given value is to be separated by comma The values are set in order 
Unique Strings From Flag returns a string slice from the flag 
Unique Strings Map From Flag returns a map of strings from the flag 
Percentiles returns percentile distribution of float slice 
Verify Bootstrap sanity checks the initial config for bootstrap case and returns an error for things that should never happen 
Verify Join Existing sanity checks the initial config for join existing cluster case and returns an error for things that should never happen 
has Local Member checks that the cluster at least contains the local server 
advertise Matches Cluster confirms peer URLs match those in the cluster peer list 
Req Timeout returns timeout for request to finish 
get Status gets a copy of the current raft status 
Marshal JSON translates the raft status into JSON TODO try to simplify this by introducing ID type into raft 
Get Default Host obtains the first IP address of machine from the routing table and returns the IP address as string An IPv address is preferred to an IPv address for backward compatibility 
Used to get an address of interface 
Used to get a name of interface 
Get Default Interfaces gets names of interfaces and returns a map interface families 
parse PREFSRC returns preferred source address and output interface index RTA OIF 
ls Command Func executes the ls command 
print Ls writes a response out in a manner similar to the ls command in unix Non empty directories list their contents and files list their name 
r Print recursively prints out the nodes in the node structure 
New Lease Renewer Command returns the cobra command for lease renewer runner 
Read reads the snapshot named by snapname and returns the snapshot 
snap Names returns the filename of the snapshots in logical time order from newest to oldest If there is no available snapshots an Err No Snapshot will be returned 
Graceful Close drains http Response Body until it hits EOF and closes it This prevents TCP TLS connections from closing therefore available for reuse Borrowed from golang net context ctxhttp cancelreq go 
Get Hostname returns the hostname from request Host field It returns empty string if Host field contains invalid value e g localhost with too many colons 
Dequeue returns Enqueue d elements in FIFO order If the queue is empty Dequeue blocks until elements are available 
Get Cipher Suite returns the corresponding cipher suite and boolean value if it is supported 
post POSTs a data payload to a url Returns nil if the POST succeeds error on any failure 
XXX Oneof Funcs is for the internal use of the proto package 
XXX Oneof Funcs is for the internal use of the proto package 
XXX Oneof Funcs is for the internal use of the proto package 
XXX Oneof Funcs is for the internal use of the proto package 
send persists state to stable storage and then sends to its mailbox 
maybe Send Append sends an append RPC with new entries to the given peer if necessary Returns true if a message was sent The send If Empty argument controls whether messages with no entries will be sent empty messages are useful to convey updated Commit indexes but are undesirable when we re sending multiple messages in a batch 
send Heartbeat sends a heartbeat RPC to the given peer 
bcast Append sends RPC with entries to all peers that are not up to date according to the progress recorded in r prs 
bcast Heartbeat sends RPC without entries to all the peers 
maybe Commit attempts to advance the commit index Returns true if the commit index changed in which case the caller should call r bcast Append 
tick Election is run by followers and candidates after r election Timeout 
tick Heartbeat is run by leaders to send a Msg Beat after r heartbeat Timeout 
step Candidate is shared by State Candidate and State Pre Candidate the difference is whether they respond to Msg Vote Resp or Msg Pre Vote Resp 
restore recovers the state machine from a snapshot It restores the log and the configuration of state machine 
promotable indicates whether state machine can be promoted to leader which is true when its own id is in progress list 
check Quorum Active returns true if the quorum is active from the view of the local raft state machine Otherwise it returns false check Quorum Active also resets all Recent Active to false 
increase Uncommitted Size computes the size of the proposed entries and determines whether they would push leader over its max Uncommitted Size limit If the new entries would exceed the limit the method returns false If not the increase in uncommitted entry size is recorded and the method returns true 
reduce Uncommitted Size accounts for the newly committed entries by decreasing the uncommitted entry size limit 
new Periodic creates a new instance of Periodic compactor that purges the log older than h Duration 
 Compaction period hour compute compaction period which is hour record revisions for every of hour minute keep recording revisions with no compaction for first hour do compact with revs success contiue on for loop and move sliding window revs revs failure update revs and retry after of hour minute 
if given compaction period x is hour compact every x duration e g auto compaction mode periodic auto compaction retention m then compact every minute if given compaction period x is hour compact every hour e g auto compaction mode periodic auto compaction retention h then compact every hour 
Pause pauses periodic compactor 
Resume resumes periodic compactor 
Lock locks the mutex with a cancelable context If the context is canceled while trying to acquire the lock the mutex tries to clean its stale lock entry 
New Locker creates a sync Locker backed by an etcd mutex 
New FIFOScheduler returns a Scheduler that schedules jobs in FIFO order sequentially 
Schedule schedules a job that will be ran in FIFO order sequentially 
Stop stops the scheduler and cancels all pending jobs 
New Server returns a new agent server 
Start Serve starts serving agent server 
Stop stops serving g RPC server 
Transport communicates with etcd tester 
Register Interrupt Handler registers a new Interrupt Handler Handlers registered after interrupt handing was initiated will not be executed 
Handle Interrupts calls the handler functions on receiving a SIGINT or SIGTERM 
Txn returns the comparison if operations then operations and else operations 
Op Get returns get operation based on given key and operation options 
Op Delete returns delete operation based on given key and operation options 
Op Put returns put operation based on given key value and operation options 
Op Txn returns txn operation based on given transaction conditions 
With Sort specifies the ordering in Get request It requires With Range and or With Prefix to be specified too target specifies the target to sort by key version revisions value order can be either Sort None Sort Ascend Sort Descend 
With Prefix enables Get Delete or Watch requests to operate on the keys with matching prefix For example Get foo With Prefix can return foo foo and so on 
With Range specifies the range of Get Delete Watch requests For example Get requests with With Range end returns the keys in the range key end end Key must be lexicographically greater than start key 
With From Key specifies the range of Get Delete Watch requests to be equal or greater than the key in the argument 
with Top gets the first key over the get s prefix given a sort order 
Exist returns true if there are any files in a given directory 
search Index returns the last array index of names whose raft index section is equal to or smaller than the given index The given names MUST be sorted 
names should have been sorted based on sequence number is Valid Seq checks whether seq increases continuously 
New Listener creates a new listner 
base Config is called on initial TLS handshake start Previously Server has non empty tls Config Certificates on client hello Server calls tls Config Get Certificate iff Server s tls Config Certificates is not empty or Client supplies SNI non empty tls Client Hello Info Server Name When tls Config Certificates is always populated on initial handshake client is expected to provide a valid matching SNI to pass the TLS verification thus trigger server tls Config Get Certificate to reload TLS assets However a cert whose SAN field does not include domain names but only IP addresses has empty tls Client Hello Info Server Name thus it was never able to trigger TLS reload on initial handshake first ceritifcate object was being used never being updated Now tls Config Certificates is created empty on initial TLS client handshake in order to trigger tls Config Get Certificate and populate rest of the certificates on every new TLS connection even when client SNI is empty e g cert only includes IPs 
cafiles returns a list of CA file paths 
Server Config generates a tls Config object for use by an HTTP server 
Client Config generates a tls Config object for use by an HTTP client 
Is Closed Conn Error returns true if the error is from closing listener cmux copied from golang org x net http http go 
New Keep Alive Listener returns a listener that listens on the given address Be careful when wrap around Keep Alive Listener with another Listener if TLSInfo is not nil Some pkgs like go http might expect Listener to return TLSConn type to start TLS handshake http tldp org HOWTO TCP Keepalive HOWTO overview html 
Accept waits for and returns the next incoming TLS connection The returned connection c is a tls Conn 
New Listener creates a Listener which accepts connections from an inner Listener and wraps each connection with Server The configuration config must be non nil and must have at least one certificate 
apply V Request interprets r as a call to v store X and returns a Response interpreted from v store Event 
New Role Command returns the cobra command for role 
role Add Command Func executes the role add command 
role Get Command Func executes the role get command 
role Grant Permission Command Func executes the role grant permission command 
role Revoke Permission Command Func executes the role revoke permission command 
Dial Journal returns no error if the process can dial journal socket Returns an error if dial failed whichi indicates journald is not available e g run embedded etcd as docker daemon Reference https github com coreos go systemd blob master journal journal go 
New Cluster returns an unlaunched cluster of the given size which has been set to use static bootstrap 
New Cluster By Config returns an unlaunched cluster defined by a cluster configuration 
HTTPMembers returns a list of all active members as client Members 
wait Leader waits until given members agree on the same leader 
wait No Leader waits until given members lose leader 
is Members Equal checks whether two members equal except ID field The given wmembs should always set ID field to empty string 
must New Member return an inited member with the given name If peer TLS is set it will use https scheme to communicate between peers 
listen GRPC starts a grpc server over a unix domain socket on the member 
New Client V creates a new grpc client connection to the member 
Clone returns a member with the same server configuration The returned member will not set Peer Listeners and Client Listeners 
Launch starts a member based on Server Config Peer Listeners and Client Listeners 
Close stops the member s etcdserver and closes its connections 
Stop stops the member but the data dir of the member is preserved 
check Leader Transition waits for leader transition returning the new leader ID 
Restart starts the member using the preserved data dir 
Terminate stops the member and removes the data dir 
Metric gets the metric value for a member 
Inject Partition drops connections from m to others vice versa 
Recover Partition recovers connections from m to others vice versa 
New Cluster V returns a launched cluster with a grpc client connection for each cluster member 
Parse With Defaults will load options from the specified map or set defaults where appropriate 
Parse will load options from the specified map 
Key will parse and return the appropriately typed key for the selected signature method 
fill populates pb Response Header using etcdserver information 
add puts a watcher into receiving a broadcast if its revision at least meets the broadcast revision Returns true if added 
Watch creates a new watcher in the stream and returns its Watch ID 
new File Encoder creates a new encoder with current file offset for the page writer 
purge File is the internal implementation for Purge File which can post purged files to purgec if non nil 
Set parses a command line set of strings separated by comma Implements flag Value interface 
New Strings Value implements string slice as flag Value interface Given value is to be separated by comma 
Strings From Flag returns a string slice from the flag 
Cluster only keeps the major minor 
New Page Writer creates a new Page Writer page Bytes is the number of bytes to write per page page Offset is the starting offset of io Writer 
new Watch Hub creates a watcher Hub The capacity determines how many events we will keep in the event History Typically we only need to keep a small size of history smaller than K Ideally it should smaller than K s max throughput ms RTT 
Watch function returns a Watcher If recursive is true the first change after index under key will be sent to the event channel of the watcher If recursive is false the first change after index at key will be sent to the event channel of the watcher If index is zero watch will start from the current index 
notify function accepts an event and notify to the watchers 
clone function clones the watcher Hub and return the cloned one only clone the static content do not clone the current watchers 
is Hidden checks to see if key path is considered hidden to watch path i e the last element is hidden or it s within a hidden directory 
New Timeout Listener returns a listener that listens on the given address If read write on the accepted connection blocks longer than its time limit it will return timeout error 
just archive the first file 
start but do not wait for it to complete 
SIGQUIT to exit with stackstrace 
if started with manual TLS stores TLS assets from tester client to disk before starting etcd process 
stop proxy etcd delete data directory 
Limit Listener returns a Listener that accepts at most n simultaneous connections from the provided Listener 
allow Method verifies that the given method is one of the allowed methods and if not it writes an error to w A boolean is returned indicating whether or not the method is allowed 
New Watch Server returns a new watch server 
Get Progress Report Interval returns the current progress report interval for testing 
Set Progress Report Interval updates the current progress report interval for testing 
Filters From Request returns mvcc Filter Func from a given watch create request 
new Pipeline Handler returns a handler for handling raft messages from pipeline for Raft Prefix The handler reads out the raft message from request body and forwards it to the given raft state machine for processing 
Serve HTTP serves HTTP request to receive and process snapshot message If request sender dies without closing underlying TCP connection the handler will keep waiting for the request body until TCP keepalive finds out that the connection is broken after several minutes This is acceptable because snapshot messages sent through other TCP connections could still be received and processed this case should happen rarely so no further optimization is done 
check Cluster Compatibility From Header checks the cluster compatibility of the local member from the given header It checks whether the version of local member is compatible with the versions in the header and whether the cluster ID of local member matches the one in the header 
Key Exists returns a comparison operation that evaluates to true iff the given key exists It does this by checking if the key Version is greater than It is a useful guard in transaction delete operations 
Key Missing returns a comparison operation that evaluates to true iff the given key does not exist 
Validate Secure Endpoints scans the given endpoints against tls info returning only those endpoints that could be validated as secure 
put New KV attempts to create the given key only succeeding if the key did not yet exist 
new Sequential KV allocates a new sequential key prefix nnnnn with a given prefix and value Note a bookkeeping node prefix is also allocated 
new Ephemeral KV creates a new key value pair associated with a session lease 
new Unique Ephemeral Key creates a new unique valueless key associated with a session lease 
new Unique Ephemeral KV creates a new unique key value pair associated with a session lease 
New Update Dir Command returns the CLI command for updatedir 
updatedir Command Func executes the updatedir command 
handle Backup handles a request that intends to do a backup 
save DB copies the v backend and strips cluster information 
New Watch Command returns the cobra command for watcher runner 
New V returns a new snapshot Manager for v x snapshot 
Save fetches snapshot from remote etcd server and saves data to target path 
Status returns the snapshot file information 
Restore restores a new etcd data directory from given snapshot file 
save DB copies the database snapshot to the snapshot directory 
save WALAnd Snap creates a WAL for the initial cluster 
New Auth Store creates a new Auth Store 
New Token Provider creates a new token provider 
Cut Peer drops messages to the specified peer 
Mend Peer recovers the message dropping behavior of the given peer 
the caller of this function must have the peers mutex 
Active Peers returns a channel that closes when an initial peer connection has been established Use this to wait until the first peer connection becomes active 
taken from go s Resolve TCP code but uses configurable ctx 
resolve TCPAddrs is a convenience wrapper for net Resolve TCPAddr resolve TCPAddrs return a new set of url URLs in which all DNS hostnames are resolved 
urls Equal checks equality of url URLS between two arrays This check pass even if an URL is in hostname and opposite is in IP address 
URLStrings Equal returns true if given URLs are valid and resolved to same IP addresses Otherwise return false and error if any 
New Lease Command returns the cobra command for lease 
New Lease Grant Command returns the cobra command for lease grant 
lease Grant Command Func executes the lease grant command 
New Lease Revoke Command returns the cobra command for lease revoke 
lease Revoke Command Func executes the lease grant command 
New Lease Time To Live Command returns the cobra command for lease timetolive 
lease Time To Live Command Func executes the lease timetolive command 
New Lease List Command returns the cobra command for lease list 
lease List Command Func executes the lease list command 
New Lease Keep Alive Command returns the cobra command for lease keep alive 
lease Keep Alive Command Func executes the lease keep alive command 
Check Initial Hash KV compares initial hash values with its peers before serving any peer client traffic Only mismatch when hashes are different at requested revision with same compact revision 
New Alarm Command returns the cobra command for alarm 
alarm Disarm Command Func executes the alarm disarm command 
alarm List Command Func executes the alarm list command 
Flags returns etcd flags in string slice 
Embed Config returns etcd embed Config 
PProf Handlers returns a map of pprof handlers keyed by the HTTP path 
New Backend Quota creates a quota layer with the given storage limit 
New Cluster Proxy takes optional prefix to fetch grpc proxy member endpoints The returned channel is closed when there is grpc proxy endpoint registered and the client s context is canceled so the register loop returns 
Member List wraps member list API with following rules If advaddr is not empty and prefix is not empty return registered member lists via resolver If advaddr is not empty and prefix is not empty and registered grpc proxy members haven t been fetched return the advaddr If advaddr is not empty and prefix is empty return advaddr without forcing it to register If advaddr is empty forward to member list API 
New Handler returns an http Handler for lease renewals 
Renew HTTP renews a lease at a given primary server TODO Batch request in future 
Time To Live HTTP retrieves lease information of the given lease ID 
new Watcher Batch maps watchers to their matched events It enables quick events look up by watcher 
add puts a watcher in the group 
contains is whether the given key has a watcher in the group 
delete removes a watcher from the group 
choose selects watchers from the watcher group to update 
watcher Set By Key gets the set of watchers that receive events on the given key 
Compare on an interval gives if the interval overlaps 
successor is the next in order node in the tree 
update Max updates the maximum values for a node and its ancestors 
visit will call a node visitor on each node that overlaps the given interval 
Delete removes the node with the given interval from the tree returning true if a node is in fact removed 
Insert adds a node with the given interval into the tree 
rotate Left moves x so it is left of its right child 
replace Parent replaces x s parent with y 
Max Height is the expected maximum tree height given the number of nodes 
Visit calls a visitor function on every tree node intersecting the given interval It will visit each interval x y in ascending order sorted on x 
find the exact node for a given interval 
Find gets the Interval Value for the node matching the given interval 
Intersects returns true if there is some tree node intersecting the given interval 
Contains returns true if the interval tree s keys cover the entire given interval 
Stab returns a slice with all elements in the tree intersecting the interval 
Union merges a given interval tree into the receiver 
New Exact Read Closer returns a Read Closer that returns errors if the underlying reader does not read back exactly the requested number of bytes 
New Election returns a new election on a given key prefix 
Resume Election initializes an election with a known leader 
Campaign puts a value as eligible for the election on the prefix key Multiple sessions can participate in the election for the same prefix but only one can be the leader at a time If the context is context TODO context Background the Campaign will continue to be blocked for other keys to be deleted unless server returns a non recoverable error e g Err Compacted Otherwise until the context is not cancelled or timed out Campaign will continue to be blocked until it becomes the leader 
Proclaim lets the leader announce a new value without another election 
Resign lets a leader start a new election 
Leader returns the leader value for the current election 
Observe returns a channel that reliably observes ordered leader proposals as Get Response values on every current elected leader key It will not necessarily fetch all historical leader updates but will always post the most recent leader value The channel closes when the context is canceled or the underlying watcher is otherwise disrupted 
check whether request satisfies the quota If there is not enough space ignore request and raise the free space alarm 
New Exec Watch Command returns the CLI command for exec watch 
exec Watch Command Func executes the exec watch command 
New Listener returns a listener for raft message transfer between peers It uses timeout listener to identify broken streams promptly 
New Round Tripper returns a round Tripper used to send requests to rafthttp listener of remote peers 
new Stream Round Tripper returns a round Tripper used to send stream requests to rafthttp listener of remote peers Read write timeout is set for stream round Tripper to promptly find out broken status which minimizes the number of messages sent on broken connection 
create Post Request creates a HTTP POST request that sends raft message 
check Post Response checks the response of the HTTP POST request that sends raft message 
compare Major Minor Version returns an integer comparing two versions based on their major and minor version The result will be if a b if a b and if a b 
server Version returns the server version from the given header 
check Version Compatibility checks whether the given version is compatible with the local version 
set Peer URLs Header reports local urls for peer discovery 
add Remote From Request adds a remote peer according to an http request header 
New Keys APIWith Prefix acts like New Keys API but allows the caller to provide a custom base URL path This should only be used in very rare cases 
TTLDuration returns the Node s TTL as a time Duration object 
v Keys URL forms a URL representing the location of a key The endpoint argument represents the base URL of an etcd server The prefix is the path needed to route from the provided endpoint s path to the root of the keys API typically v keys 
Set Flags From Env parses all registered flags in the given flagset and if they are not already set it attempts to set their values from environment variables Environment variables take the name of the flag but are UPPERCASE have the given prefix and any dashes are replaced by underscores for example some flag ETCD SOME FLAG 
Set Pflags From Env is similar to Set Flags From Env However the accepted flagset type is pflag Flag Set and it does not do any logging 
Flag To Env converts flag string to upper case environment variable key string 
excerpt replaces middle part with ellipsis and returns a double quoted string safely escaped with Go syntax 
The pass functions below takes the raftpb Entry and return if the entry should be printed and the type of entry the type of the entry will used in the following print function 
The print functions below print the entry format based on there types print Internal Raft Request is used to print entry information for IRRRange IRRPut IRRDelete Range and IRRTxn entries 
evaluate Entrytype Flag evaluates entry type flag and choose proper filter filters to filter entries 
list Entries Type filters and prints entries based on the entry type flag 
new Log returns log using the given storage and default options It recovers the log to the state that it just commits and applies the latest snapshot 
new Log With Size returns a log using the given storage and max message size 
maybe Append returns false if the entries cannot be appended Otherwise it returns last index of new entries true 
find Conflict finds the index of the conflict It returns the first pair of conflicting entries between the existing entries and the given entries if there are any If there is no conflicting entries and the existing entries contains all the given entries zero will be returned If there is no conflicting entries but the given entries contains new entries the index of the first new entry will be returned An entry is considered to be conflicting if it has the same index but a different term The first entry MUST have an index equal to the argument from The index of the given entries MUST be continuously increasing 
next Ents returns all the available entries for execution If applied is smaller than the index of snapshot it returns all committed entries after the index of snapshot 
has Next Ents returns if there is any available entries for execution This is a fast check without heavy raft Log slice in raft Log next Ents 
all Entries returns all entries in the log 
is Up To Date determines if the given last Index term log is more up to date by comparing the index and term of the last entries in the existing logs If the logs have last entries with different terms then the log with the later term is more up to date If the logs end with the same term then whichever log has the larger last Index is more up to date If the logs are the same the given log is up to date 
slice returns a slice of log entries from lo through hi inclusive 
l first Index lo hi l first Index len l entries 
New Session gets the leased session for a client 
Close orphans the session and revokes the session lease 
With TTL configures the session s TTL in seconds If TTL is the default seconds TTL will be used 
With Lease specifies the existing lease ID to be used for the session This is useful in process restart scenario for example to reclaim leadership from an election prior to restart 
With Context assigns a context to the session instead of defaulting to using the client context This is useful for canceling New Session and Close operations immediately without having to close the client If the context is canceled before Close completes the session s lease will be abandoned and left to expire instead of being revoked 
add Request adds a read only reuqest into readonly struct index is the commit index of the raft state machine when it received the read only request m is the original read only request message from the local or remote node 
recv Ack notifies the readonly struct that the raft state machine received an acknowledgment of the heartbeat that attached with the read only request context 
advance advances the read only request queue kept by the readonly struct It dequeues the requests until it finds the read only request that has the same context as the given m 
last Pending Request Ctx returns the context of the last pending read only request in readonly struct 
New Server creates a new Etcd Server from the supplied configuration The configuration is considered static for the lifetime of the Etcd Server 
Start performs any initialization of the Server necessary for it to begin serving requests It must be called before Do or Process Start must be non blocking any long running server functionality should be implemented in goroutines 
start prepares and starts server in a new goroutine It is no longer safe to modify a server s fields after it has been sent to Start This function is just used for testing 
Process takes a raft message and applies it to the server s raft state machine respecting any timeout of the given context 
Report Snapshot reports snapshot sent status to the raft state machine and clears the used snapshot from the snapshot store 
Move Leader transfers the leader to the given transferee 
Transfer Leadership transfers the leader to the chosen transferee 
Stop stops the server gracefully and shuts down the running goroutine Stop should be called after a Start s otherwise it will block forever When stopping leader Stop transfers its leadership to one of its peers before stopping the server Stop terminates the Server and performs any necessary finalization Do and Process cannot be called after Stop has been invoked 
configure sends a configuration change through consensus and then waits for it to be applied to the server It will block until the change is performed or there is an error 
sync proposes a SYNC request and is non blocking This makes no guarantee that the request will be proposed or performed The request will be canceled after the given timeout 
publish registers server information into the cluster The information is the JSON representation of this server s member struct updated with the static client URLs of the server The function keeps attempting to register until it succeeds or its server is stopped 
apply takes entries received from Raft after it has been committed and applies them to the current state of the Etcd Server The given entries should not be empty 
apply Entry Normal apples an Entry Normal type raftpb request to the Etcd Server 
apply Conf Change applies a Conf Change to the server It is only invoked with a Conf Change that has already passed through Raft 
TODO non blocking snapshot 
Cut Peer drops messages to the specified peer 
monitor Versions checks the member s version every monitor Version Interval It updates the cluster version if all members agrees on a higher one It prints out log if there is a member with a higher version than the local version 
go Attach creates a goroutine on a given function and tracks it using the etcdserver waitgroup 
New Roundrobin Balanced returns a new roundrobin balanced picker 
Pick is called for every client request 
New TLSListener handshakes TLS connections and performs optional CRL checking 
accept Loop launches each TLS handshake in a separate goroutine to prevent a hanging TLS connection from blocking other connections 
Set Endpoints updates the endpoints for Resolver Group All registered resolver are updated immediately with the new endpoints 
Target constructs a endpoint target using the endpoint id of the Resolver Group 
Target constructs a endpoint resolver target 
Build creates or reuses an etcd resolver for the etcd cluster name identified by the authority part of the target 
TODO use balancer eps To Addrs 
Parse Endpoint endpoint parses an endpoint of the form http https host unix unixs path and returns a protocol tcp or unix host or filepath if a unix socket scheme http https unix unixs 
Parse Target parses a endpoint id endpoint string and returns the parsed id and endpoint If the target is malformed an error is returned 
Parse Host Port splits a host port string into the host and port parts The port part is optional 
Handle interprets r and performs an operation on s store according to r Method and other fields If r Method is POST PUT DELETE or a GET with Quorum true r will be sent through consensus before performing its respective operation Do will block until an action is performed or there is an error 
New Election Command returns the cobra command for election runner 
node To Member builds member from a key value node the child nodes of the given node MUST be sorted by key 
New Tmp Backend creates a backend implementation for testing 
new Revision creates a new instance of Revisonal compactor that purges the log older than retention revisions from the current revision 
Run runs revision based compactor 
Pause pauses revision based compactor 
Resume resumes revision based compactor 
vote Response Type maps vote and prevote message types to their corresponding responses 
Describe Message returns a concise human readable description of a Message for debugging 
Describe Entry returns a concise human readable description of an Entry for debugging 
Describe Entries calls Describe Entry for each Entry adding a newline to each 
watch Command Func executes the watch command 
Set Logger sets client side Logger 
Get Logger returns the current logutil Logger 
New creates a clientv client that wraps an in process Etcd Server Instead of making g RPC calls through sockets the client makes direct function calls to the etcd server through its api v rpc function interfaces 
maybe First Index returns the index of the first possible entry in entries if it has a snapshot 
maybe Last Index returns the last index if it has at least one unstable entry or snapshot 
maybe Term returns the term of the entry at index i if there is any 
shrink Entries Array discards the underlying array used by the entries slice if most of it isn t being used This avoids holding references to a bunch of potentially large entries that aren t needed anymore Simply clearing the entries wouldn t be safe because clients might still be using them 
u offset lo hi u offset len u entries 
Handle Metrics performs a GET request against etcd endpoint and returns metrics 
Save Snap saves the snapshot to disk and release the locked wal files since they will not be used 
New creates a new etcdv client from a given configuration 
New Ctx Client creates a client with a context but no underlying grpc connection This is useful for embedded cases that override the service interface implementations and do not need connection management 
New From URL creates a new etcdv client from a URL 
Close shuts down the client s etcd connections 
Endpoints lists the registered endpoints for the client 
Set Endpoints updates client s endpoints 
Sync synchronizes client s endpoints with the known endpoints from the etcd membership 
dial Setup Opts gives the dial opts prior to any authentication 
Dial connects to a single endpoint using the client s config 
dial With Balancer dials the client s current load balanced resolver group The scheme of the host of the provided endpoint determines the scheme used for all endpoints of the client connection 
dial configures and dials any grpc balancer target 
With Require Leader requires client requests to only succeed when the cluster has a leader 
round Robin Quorum Backoff retries against quorum between each backoff This is intended for use with a round robin load balancer 
is Halt Err returns true if the given error and context indicate no forward progress can be made even after reconnecting 
Is Conn Canceled returns true if error is from a closed g RPC connection ref https github com grpc grpc go pull 
New Lease wraps a Lease interface to filter for only keys with a prefix and remove that prefix when fetching attached keys through Time To Live 
serve Http KVAPI starts a key value server with a GET PUT API and listens 
Is Create returns true if the event tells that the key is newly created 
Err is the error value if this Watch Response holds an error 
Is Progress Notify returns true if the Watch Response is progress notification 
Watch posts a watch request to run and waits for a new watcher channel 
Request Progress requests a progress notify response be sent in all watch channels 
run is the root of the goroutines for managing a watcher client 
next Resume chooses the next resuming to register with the grpc stream Abandoned streams are marked as nil in the queue since the head must wait for its inflight registration 
dispatch Event sends a Watch Response to the appropriate watcher stream 
broadcast Response send a watch response to all watch substreams 
unicast Response sends a watch response to a specific watch substream 
serve Watch Client forwards messages from the grpc stream to run 
serve Substream forwards watch responses from run to the subscriber 
join Substreams waits for all substream goroutines to complete 
open Watch Client retries opening a watch client until success or halt manually retry in case ws nil err nil TODO remove Fail Fast false 
to PB converts an internal watch request structure to its protobuf Watch Request structure 
to PB converts an internal progress request structure to its protobuf Watch Request structure 
Contains returns whether the set contains the given value 
Contains All returns whether the set contains all given values 
Equals returns whether the contents of two sets are identical 
Values returns the values of the Set in an unspecified order 
Copy creates a new Set containing the values of the first 
Sub removes all elements in other from the set 
v Members URL add the necessary path to the provided endpoint to route requests to the default v members API 
New Migrate Command returns the cobra command for migrate 
new Raft Node initiates a raft instance and returns a committed log entry channel and error channel Proposals for log updates are sent over the provided the proposal channel All log entries are replayed over the commit channel followed by a nil message to indicate the channel is current then new log entries To shutdown close propose C and read error C 
publish Entries writes committed log entries to commit channel and returns whether all entries could be published 
open WAL returns a WAL ready for reading 
replay WAL replays WAL entries into the raft instance 
stop closes http closes all channels and stops raft 
New Watch Command returns the cobra command for watch 
watch Command Func executes the watch command 
command Args is the command arguments after spf cobra parses all watch command flags strips out special characters e g or Args is the raw arguments passed to watch command e g bin etcdctl watch foo rev bar characters are invalid arguments for spf cobra library so no need to handle such cases 
Initial State implements the Storage interface 
Set Hard State saves the current Hard State 
Entries implements the Storage interface 
Term implements the Storage interface 
Last Index implements the Storage interface 
First Index implements the Storage interface 
Snapshot implements the Storage interface 
Apply Snapshot overwrites the contents of this Storage object with those of the given snapshot 
Create Snapshot makes a snapshot which can be retrieved with Snapshot and can be used to reconstruct the state at that point If any configuration changes have been made since the last compaction the result of the last Apply Conf Change must be passed in 
Compact discards all log entries prior to compact Index It is the application s responsibility to not attempt to compact an index greater than raft Log applied 
Append the new entries to storage TODO xiangli ensure the entries are continuous and entries Index ms entries Index 
unreachable notices the picker that the given url is unreachable and it should use other possible urls 
New Endpoint Command returns the cobra command for endpoint 
ep Health Command Func executes the endpoint health command 
New Elect Command returns the cobra command for elect 
New Defrag Command returns the cobra command for Defrag 
Register Builder creates and registers a builder Since this function calls balancer Register it must be invoked at initialization time 
Build is called initially when creating cc Balancer Wrapper grpc Dial is called to this client connection Then resolved addresses will be handled via Handle Resolved Addrs 
Handle Resolved Addrs implements grpc balancer Balancer interface g RPC sends initial or updated resolved addresses from Build 
Handle Sub Conn State Change implements grpc balancer Balancer interface 
record Transition records state change happening in every sub Conn and based on that it evaluates what aggregated state should be It can only transition between Ready Connecting and Transient Failure Other states Idle and Shutdown are transitioned into by Client Conn in the beginning of the connection before any sub Conn is created Client Conn is in idle state In the end when Client Conn closes it is in Shutdown state record Transition should only be called synchronously from the same goroutine 
do Serialize handles the auth logic with permissions checked by chk for a serialized request get Returns a non nil error on authentication failure 
send filters out repeated events by discarding revisions older than the last one sent over the watch channel 
post puts a watch response on the watcher s proxy stream channel 
Origin Allowed determines whether the server will allow a given CORS origin If CORS is empty allow all 
Is Host Whitelisted returns true if the host is whitelisted If whitelist is empty allow all 
Set verifies the argument to be a valid member of the allowed values before setting the underlying flag value 
Valids returns the list of valid strings 
New Selective String Value creates a new string flag for which any one of the given strings is a valid value and any other value is an error valids will be default value Caller must be sure len valids or it will panic 
Set verifies the argument to be a valid member of the allowed values before setting the underlying flag value 
New Selective Strings Value creates a new string slice flag for which any one of the given strings is a valid value and any other value is an error 
New KV wraps a KV instance so that all requests are prefixed with a given string 
New Timeout Transport returns a transport created using the given TLS info If read write on the created connection blocks longer than its time limit it will return timeout error If read write timeout is set transport will not be able to reuse connection 
Set parses a command line set of URLs formatted like http http Implements flag Value interface 
String implements flag Value interface 
New URLs Value implements url URL slice as flag Value interface Given value is to be separated by comma 
URLs From Flag returns a slices from url got from the flag 
Start Etcd launches the etcd server and HTTP handlers for client server communication The returned Etcd Server is not guaranteed to have joined the cluster Wait on the Etcd Server Ready Notify channel to know when it completes and is ready for use 
Close gracefully shuts down all servers listeners Client requests will be terminated with request timeout After timeout enforce remaning requests be closed immediately 
configure peer handlers after rafthttp Transport started 
Get Logger returns the logger 
New Store returns a new store It is useful to create a store inside mvcc pkg It should only be used for testing externally 
append Mark Tombstone appends tombstone mark to normal revision bytes 
Is Dir Writeable checks if dir is writable by writing and removing a file to dir It returns nil if dir is writable 
Touch Dir All is similar to os Mkdir All It creates directories with permission if any directory does not exists Touch Dir All also ensures the given directory is writable 
Create Dir All is similar to Touch Dir All but returns error if the deepest directory was not empty 
Zero To End zeros a file starting from SEEK CUR to its SEEK END May temporarily shorten the length of the file 
Open returns a fresh file for writing Rename the file before calling Open again or there will be file collisions 
New Raft Logger converts zap Logger to raft Logger 
New Raft Logger From Zap Core creates raft Logger from zap Core and zapcore Write Syncer 
New Config creates a new clientv Config from a yaml file 
Register Election Handler registers the http handlers for service Election to mux The handlers forward requests to the grpc endpoint over conn 
Register Election Handler registers the http handlers for service Election to mux The handlers forward requests to the grpc endpoint over the given implementation of Election Client Note the g RPC framework executes interceptors within the g RPC handler If the passed in Election Client doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in Election Client to call the correct interceptors 
Update Capability updates the enabled Map when the cluster version increases 
New Lock Command returns the cobra command for lock 
raft Node does not have locks in Raft package 
start prepares and starts raft Node in a new goroutine It is no longer safe to modify the fields after it has been started 
for testing 
advance Ticks advances ticks of Raft node This can be used for fast forwarding election ticks in multi data center deployments thus speeding up election process 
get IDs returns an ordered set of IDs included in the given snapshot and the entries The given snapshot entries can contain two kinds of ID related entry Conf Change Add Node in which case the contained ID will be added into the set Conf Change Remove Node in which case the contained ID will be removed from the set 
create Config Change Ents creates a series of Raft entries i e Entry Conf Change to remove the set of given IDs from the cluster The ID self is not removed even if present in the set If self is not inside the given ids it creates a Raft entry to add a default member with the given self 
New Auth Command returns the cobra command for auth 
auth Enable Command Func executes the auth enable command 
auth Disable Command Func executes the auth disable command 
is Safe Retry Immutable RPC returns true when an immutable request is safe for retry immutable requests e g Get should be retried unless it s an obvious server side error e g rpctypes Err Request Too Large Returning false means retry should stop since client cannot handle itself even with retries 
is Safe Retry Mutable RPC returns true when a mutable request is safe for retry mutable requests e g Put Delete Txn should only be retried when the status code is codes Unavailable when initial connection has not been established no endpoint is up Returning false means retry should stop otherwise it violates write at most once semantics 
Retry KVClient implements a KVClient 
Retry Lease Client implements a Lease Client 
Retry Cluster Client implements a Cluster Client 
Retry Maintenance Client implements a Maintenance 
Retry Auth Client implements a Auth Client 
New Set Dir Command returns the CLI command for set Dir 
Enter waits for count processes to enter the barrier then returns 
Leave waits for count processes to leave the barrier then returns 
Handle Basic adds handlers to a mux for serving JSON etcd client requests that do not access the v store 
TODO deprecate config local log in v 
Write Error logs and writes the given Error to the Response Writer If Error is an etcd Err it is rendered to the Response Writer Otherwise it is assumed to be a Status Internal Server Error 
Member By Name returns a Member with the given name if exists If more than one member has the given name it will panic 
Peer URLs returns a list of all peer addresses The returned list is sorted in ascending lexicographical order 
Validate Configuration Change takes a proposed Conf Change and ensures that it is still valid 
Add Member adds a new Member into the cluster and saves the given member s raft Attributes into the store The given member should have empty attributes A Member with a matching id must not exist 
Remove Member removes a member from the store The given id MUST exist or the function panics 
Validate Cluster And Assign IDs validates the local cluster by matching the Peer URLs with the existing cluster If the validation succeeds it assigns the IDs from the existing cluster to the local cluster If the validation fails an error will be returned 
Range Since returns all revisions from key including to end excluding at or after the given rev The returned slice is sorted in the order of revision 
Keep finds all revisions to be kept for a Compaction at the given rev 
close Require Leader scans keep Alives for ctxs that have require leader and closes the associated channels 
reset Recv opens a new lease stream and starts sending keep alive requests 
recv Keep Alive updates a lease based on its Lease Keep Alive Response 
deadline Loop reaps any keep alive channels that have not received a response within the lease TTL 
send Keep Alive Loop sends keep alive requests for the lifetime of the given stream 
New KV wraps a KV instance so that all requests are wired through a leasing protocol 
rescind releases a lease from this client 
Lease Value compares a key s Lease ID to a value of your choosing The empty Lease ID is otherwise known as No Lease 
Value Bytes returns the byte slice holding the comparison value if any 
With Range sets the comparison to scan the range key end 
With Prefix sets the comparison to scan all keys prefixed by the key 
must Int panics if val isn t an int or int It returns an int otherwise 
must Int or Lease ID panics if val isn t a Lease ID int or int It returns an int otherwise 
Next gets the next set of updates from the etcd resolver Calls to Next should be serialized concurrent calls are not safe since there is no way to reconcile the update ordering 
use stderr as fallback 
new KV creates a Key Value pair 
new Dir creates a directory 
Is Hidden function checks if the node is a hidden node A hidden node will begin with A hidden node will not be shown via get command under a directory For example if we have foo hidden and foo not Hidden get foo will only return foo not Hidden 
Read function gets the value of the node If the receiver node is not a key value pair a Not A File error will be returned 
Write function set the value of the node to the given value If the receiver node is a directory a Not A File error will be returned 
List function return a slice of nodes under the receiver node If the receiver node is not a directory a Not A Directory error will be returned 
Get Child function returns the child node under the directory node On success it returns the file node 
Add function adds a node to the receiver node If the receiver is not a directory a Not A Directory error will be returned If there is an existing node with the same name under the directory a Already Exist error will be returned 
Remove function remove the node 
Compare function compares node index and value with provided ones second result value explains result and equals to one of Compare constants 
Clone function clone the node recursively and return the new node If the node is a directory it will clone all the content under this directory If the node is a key value pair it will clone the pair 
recover Andclean function help to do recovery Two things need to be done recovery structure delete expired nodes If the node is a directory it will help recover children s parent pointer and recursively call this function on its children We check the expire last since we need to recover the whole structure first and add all the notifications into the event history 
is Connected To Quorum Since checks whether the local member is connected to the quorum of the cluster since the given time 
is Connected Since checks whether the local member is connected to the remote member since the given time 
num Connected Since counts how many members are connected to the local member since the given time 
longest Connected chooses the member with longest active since time It returns false if nothing is active 
is Torn Entry determines whether the last entry of the WAL was partially written and corrupted because of a torn write 
Start Mock Servers On Network creates mock servers on either tcp or unix sockets 
Start At restarts mock server at given index 
Stop At stops mock server at given index 
Stop stops the mock server immediately closing all open connections and listeners 
New Check Command returns the cobra command for check 
New Check Perf Command returns the cobra command for check perf 
new Check Perf Command executes the check perf command 
New Check Datascale Command returns the cobra command for check datascale 
new Check Datascale Command executes the check datascale command 
New Get Command returns the cobra command for get 
get Command Func executes the get command 
New Get Command returns the CLI command for get 
get Command Func executes the get command 
New Member creates a Member without an ID and generates one based on the cluster name peer URLs and time This is used for bootstrapping adding new member 
Pick Peer URL chooses a random address from a given Member s Peer URLs It will panic if there is no Peer URLs available in Member 
Handle Metrics Health registers metrics and health handlers 
New Health Handler handles health requests 
TODO server NOSPACE etcdserver Err No Leader in health API 
New Remove Command returns the CLI command for rm 
rm Command Func executes the rm command 
check Intervals tests whether puts and deletes overlap for a list of ops If there is an overlap returns an error If no overlap return put and delete sets for recursive evaluation 
Report Event Received reports that an event is received This function should be called when the external systems received an event from mvcc Watcher 
Register KVHandler registers the http handlers for service KV to mux The handlers forward requests to the grpc endpoint over conn 
Register KVHandler registers the http handlers for service KV to mux The handlers forward requests to the grpc endpoint over the given implementation of KVClient Note the g RPC framework executes interceptors within the g RPC handler If the passed in KVClient doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in KVClient to call the correct interceptors 
Register Watch Handler registers the http handlers for service Watch to mux The handlers forward requests to the grpc endpoint over conn 
Register Watch Handler registers the http handlers for service Watch to mux The handlers forward requests to the grpc endpoint over the given implementation of Watch Client Note the g RPC framework executes interceptors within the g RPC handler If the passed in Watch Client doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in Watch Client to call the correct interceptors 
Register Lease Handler registers the http handlers for service Lease to mux The handlers forward requests to the grpc endpoint over conn 
Register Lease Handler registers the http handlers for service Lease to mux The handlers forward requests to the grpc endpoint over the given implementation of Lease Client Note the g RPC framework executes interceptors within the g RPC handler If the passed in Lease Client doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in Lease Client to call the correct interceptors 
Register Cluster Handler registers the http handlers for service Cluster to mux The handlers forward requests to the grpc endpoint over conn 
Register Cluster Handler registers the http handlers for service Cluster to mux The handlers forward requests to the grpc endpoint over the given implementation of Cluster Client Note the g RPC framework executes interceptors within the g RPC handler If the passed in Cluster Client doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in Cluster Client to call the correct interceptors 
Register Maintenance Handler registers the http handlers for service Maintenance to mux The handlers forward requests to the grpc endpoint over conn 
Register Maintenance Handler registers the http handlers for service Maintenance to mux The handlers forward requests to the grpc endpoint over the given implementation of Maintenance Client Note the g RPC framework executes interceptors within the g RPC handler If the passed in Maintenance Client doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in Maintenance Client to call the correct interceptors 
Register Auth Handler registers the http handlers for service Auth to mux The handlers forward requests to the grpc endpoint over conn 
Register Auth Handler registers the http handlers for service Auth to mux The handlers forward requests to the grpc endpoint over the given implementation of Auth Client Note the g RPC framework executes interceptors within the g RPC handler If the passed in Auth Client doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in Auth Client to call the correct interceptors 
start Etcd runs Start Etcd in addition to hooks needed for standalone etcd 
start Proxy launches an HTTP proxy for client communication which proxies to other etcd nodes 
identify Data Dir Or Die returns the type of the data dir Dies if the datadir is invalid 
Repair tries to repair Err Unexpected EOF in the last wal file by truncating 
open Last opens the last wal file for read and write 
ref https github com golang go blob master src io io go copy Buffer 
got Leader will force update the leadership status to having a leader 
lost Notify returns a channel that is closed if there has been a leader loss not yet followed by a leader reacquire 
new GRPCProxy Command returns the cobra command for grpc proxy 
New Member Command returns the cobra command for member 
New Member Add Command returns the cobra command for member add 
New Member Remove Command returns the cobra command for member remove 
New Member Update Command returns the cobra command for member update 
New Member List Command returns the cobra command for member list 
member Add Command Func executes the member add command 
member Remove Command Func executes the member remove command 
member Update Command Func executes the member update command 
member List Command Func executes the member list command 
Create creates a WAL ready for appending records The given metadata is recorded at the head of each WAL file and can be retrieved with Read All 
Open opens the WAL at the given snap The snap SHOULD have been previously saved to the WAL or the following Read All will fail The returned WAL is ready to read and the first record will be the one after the given snap The WAL cannot be appended to before reading out all of its previous records 
Open For Read only opens the wal files for read Write on a read only wal panics 
Read All reads out records of the current WAL If opened in write mode it must read out all records until EOF Or an error will be returned If opened in read mode it will try to read all records if possible If it cannot read out the expected snap it will return Err Snapshot Not Found If loaded snap doesn t match with the expected one it will return all the records and error Err Snapshot Mismatch TODO detect not last snap error TODO maybe loose the checking of match After Read All the WAL will be ready for appending new records 
Verify reads through the given WAL and verifies that it is not corrupted It creates a new decoder to read through the records of the given WAL It does not conflict with any open WAL but it is recommended not to call this function after opening the WAL for writing If it cannot read out the expected snap it will return Err Snapshot Not Found If the loaded snap doesn t match with the expected one it will return error Err Snapshot Mismatch 
cut closes current file written and creates a new one ready to append cut first creates a temp wal file and writes necessary headers into it Then cut atomically rename temp wal file to a wal file 
Close closes the current WAL file and directory 
notify function notifies the watcher If the watcher interests in the given path the function will return true 
Remove removes the watcher from watcher Hub The actual remove function is guaranteed to only be executed once 
Preallocate tries to allocate the space for given file This operation is only supported on linux by a few filesystems btrfs ext etc If the operation is unsupported no error will be returned Otherwise the error encountered will be returned 
mk Path Depth makes a path to a key that encodes its directory depth for fast directory listing If a depth is provided it is added to the computed depth 
mk V Node creates a V Node Extern from a V Key Value 
prev Key From Puts gets the prev key that is being put ignores the put action response 
New Weighted Report returns a report that includes both weighted and unweighted statistics 
Handle Health registers health handler on health 
New URLs Map returns a URLs Map instantiated from the given string which consists of discovery formatted names to URLs like mach http mach http mach http mach http 
New URLs Map From String Map takes a map of strings and returns a URLs Map The string values in the map can be multiple values separated by the sep string 
String turns URLs Map into discovery formatted name to URLs sorted by name 
URLs returns a list of all URLs The returned list is sorted in ascending lexicographical order 
parse parses the given string and returns a map listing the values specified for each key 
New Client Handler generates a muxed http Handler with the given parameters to serve etcd client requests 
parse Key Request converts a received http Request on keys Prefix to a server Request performing validation of supplied fields as appropriate If any validation fails an empty Request and non nil error is returned 
write Key Event trims the prefix of key path in a single Event under Store Keys Prefix serializes it and writes the resulting JSON to the given Response Writer along with the appropriate headers 
write Key Error logs and writes the given Error to the Response Writer If Error is not an etcd Err the error will be converted to an etcd error 
get Uint extracts a uint by the given key from a Form If the key does not exist in the form is returned If the key exists but the value is badly formed an error is returned If multiple values are present only the first is considered 
get Bool extracts a bool by the given key from a Form If the key does not exist in the form false is returned If the key exists but the value is badly formed an error is returned If multiple values are present only the first is considered 
trim Prefix removes a given prefix and any slash following the prefix e g trim Prefix foo foo trim Prefix foo foo 
wait Deletes efficiently waits until all keys matching the prefix and no greater than the create revision 
Add Output Paths adds output paths to the existing output paths resolving conflicts 
New Config creates a new Config populated with default values 
Validate ensures that embed Config fields are properly configured 
Peer URLs Map And Token sets up an initial peer URLs Map and cluster token for bootstrap or discovery 
Get DNSCluster Names uses DNS SRV records to get a list of initial nodes for cluster bootstrapping 
Update Default Cluster From Name updates cluster advertise URLs with if available default host if advertise URLs are default values localhost AND if listen URL is e g advertise peer URL localhost or listen peer URL then the advertise peer host would be updated with machine s default host while keeping the listen URL s port User can work around this by explicitly setting URL with It returns the default hostname if used and the error if any from getting the machine s default host TODO check whether fields are set instead of whether fields have default value 
check Bind URLs returns an error if any URL uses a domain name 
Get Cluster gets the cluster information via DNS discovery Also sees each entry as a separate instance 
Get Client looks up the client endpoints for a service and domain 
Get SRVService generates a SRV service including an optional suffix 
Read Dir returns the filenames in the given directory in sorted order 
New Journal Writer wraps io Writer to redirect log output to the local systemd journal If journald send fails it fails back to writing to the original writer The decode overhead is only s per write Reference https github com coreos pkg blob master capnslog journald formatter go 
create Merged Snapshot Message creates a snapshot message that contains raft status term conf a snapshot of v store inside raft Snapshot as byte a snapshot of v KV in the top level message as Read Closer 
get the process resident memory bytes from server metrics 
compact keyspace history to a provided revision 
defrag a given endpoint 
New User Command returns the cobra command for user 
user Add Command Func executes the user add command 
user Get Command Func executes the user get command 
user Change Password Command Func executes the user passwd command 
add Event function adds event into the event History 
scan enumerates events from the index history and stops at the first point where the key matches 
clone will be protected by a stop world lock do not need to obtain internal lock 
open Snapshot Backend renames a snapshot db to the current etcd db and opens it 
open Backend returns a backend using the current etcd db 
recover Backend Snapshot recovers the DB from a snapshot in case etcd crashes before updating the backend db after persisting raft snapshot to disk violating the invariant snapshot Metadata Index db consistent Index In this case replace the db with the snapshot db sent by the leader 
New Update Command returns the CLI command for update 
update Command Func executes the update command 
Front And Back gets the front and back elements in the queue We must grab front and back together with the protection of the lock 
Insert function insert a Request Stats into the queue and update the records 
Rate function returns the package rate and byte rate 
Clear function clear up the stats Queue 
Unique Strings returns a slice of randomly generated unique strings 
Random Strings returns a slice of randomly generated strings 
Is Key Not Found returns true if the error code is Error Code Key Not Found 
Is Role Not Found returns true if the error means role not found of v API 
Is User Not Found returns true if the error means user not found of v API 
Join Cluster will connect to the discovery service at the given url and register the server represented by the given id and config to the cluster 
Get Cluster will connect to the discovery service at the given url and retrieve a string describing the cluster 
new Proxy Func builds a proxy function from the given string which should represent a URL that can be used as a proxy It performs basic sanitization of the URL and returns any error encountered 
unary Client Interceptor returns a new retrying unary client interceptor The default configuration of the interceptor is to not retry at all This behaviour can be changed through options e g With Max on creation of the interceptor or on call through grpc Call Options 
stream Client Interceptor returns a new retrying stream client interceptor for server side streaming calls The default configuration of the interceptor is to not retry at all This behaviour can be changed through options e g With Max on creation of the interceptor or on call through grpc Call Options Retry logic is available only for Server Streams i e n streams as the internal logic needs to buffer the messages sent by the client If retry is enabled on any other streams Client Streams Bidi Streams the retry interceptor will fail the call 
is Safe Retry returns true if request is safe for retry with the given error 
with Retry Policy sets the retry policy of this call 
with Auth Retry sets enables authentication retries 
with Max sets the maximum number of retries on this call or this interceptor 
With Backoff sets the Backoff Func used to control time between retries 
Backoff Linear With Jitter waits a set period of time allowing for jitter fractional adjustment For example wait Between s and jitter can generate waits between ms and ms 
Recv Append Req updates the Server Stats in response to an Append Request from the given leader being received 
Send Append Req updates the Server Stats in response to an Append Request being sent by this server 
New Package Logger wraps capnslog Package Logger that implements Logger interface For example var default Logger Logger default Logger New Package Logger go etcd io etcd snapshot 
merge merges data from bb into bbsrc 
delete Rev Key deletes a key by revision returning false if key is missing 
is Member Bootstrapped tries to check if the given member has been bootstrapped in the given cluster 
Get Cluster From Remote Peers takes a set of URLs representing etcd peers and attempts to construct a Cluster by accessing the members endpoint on one of these URLs The first URL to provide a response is used If no URLs provide a response or a Cluster cannot be successfully created from a received response an error is returned Each request has a second timeout Because the upper limit of TTL is s second is enough for building connection and finishing request 
If logerr is true it prints out more error messages 
get Remote Peer URLs returns peer urls of remote members in the cluster The returned list is sorted in ascending lexicographical order 
get Versions returns the versions of the members in the given cluster The key of the returned map is the member s ID The value of the returned map is the semver versions string including server and cluster If it fails to get the version of a member the key will be nil 
decide Cluster Version decides the cluster version based on the versions map The returned version is the min server version in the map or nil if the min version in unknown 
is Compatible With Cluster return true if the local member has a compatible version with the current running cluster The version is considered as compatible when at least one of the other members in the cluster has a cluster version in the range of Min Cluster Version Version and no known members has a cluster version out of the range We set this rule since when the local member joins another member might be offline 
get Version returns the Versions of the given member via its peer URLs Returns the last error if it fails to get the version 
New Timeout Detector creates the Timeout Detector 
Reset resets the New Timeout Detector 
Observe observes an event for given id It returns false and exceeded duration if the interval is longer than the expectation 
New Peer Handler generates an http Handler to handle etcd peer requests 
put puts a revision to the key Index 
tombstone puts a revision pointing to a tombstone to the key Index It also creates a new empty generation in the key Index It returns Err Revision Not Found when tombstone on an empty generation 
get gets the modified created revision and version of the key that satisfies the given at Rev Rev must be higher than or equal to the given at Rev 
since returns revisions since the given rev Only the revision with the largest sub revision will be returned if multiple revisions have the same main revision 
compact compacts a key Index by removing the versions with smaller or equal revision than the given at Rev except the largest one If the largest one is a tombstone it will not be kept If a generation becomes empty during compaction it will be removed 
keep finds the revision to be kept if compact is called at given at Rev 
find Generation finds out the generation of the key Index that the given rev belongs to If the given rev is at the gap of two generations which means that the key does not exist at the given rev it returns nil 
walk walks through the revisions in the generation in descending order It passes the revision to the given function walk returns until it finishes walking all pairs the function returns false walk returns the position at where it stopped If it stopped after finishing walking will be returned 
Create Or Update User should be only used for creating the new user or when you are not sure if it is a create or update When only password is passed in we are not sure if it is a update or create 
merge applies the properties of the passed in User to the User on which it is called and returns a new User with these modifications applied Think of all Users as immutable sets of data Merge allows you to perform the set operations desired grants and revokes atomically 
merge for a role works the same as User above atomic Role application to each of the substructures 
Grant adds a set of permissions to the permission object on which it is called returning a new permission object 
Revoke removes a set of permissions to the permission object on which it is called returning a new permission object 
Grant adds a set of permissions to the permission object on which it is called returning a new permission object 
Revoke removes a set of permissions to the permission object on which it is called returning a new permission object 
cancel Watcher removes references of the watcher from the watchable Store 
sync Watchers Loop syncs the watcher in the unsynced map every ms 
sync Victims Loop tries to write precomputed watcher responses to watchers that had a blocked watcher channel 
move Victims tries to update watches with already pending event data 
sync Watchers syncs unsynced watchers by choose a set of watchers from the unsynced watcher group iterate over the set to get the minimum revision and remove compacted watchers use minimum revision to get all key value pairs and send those events to watchers remove synced watchers in set from unsynced group and move to synced group 
kvs To Events gets all events for the watchers from all key value pairs 
notify notifies the fact that given event at the given rev just happened to watchers that watch on the key of the event 
jitter Up adds random jitter to the duration This adds or subtracts time from the duration within a given jitter fraction For example for s and jitter it will return a time within s s Reference https godoc org github com grpc ecosystem go grpc middleware util backoffutils 
Check if the provided function is being called in the op options 
Unsafe Put must be called holding the lock on the tx 
Unsafe Seq Put must be called holding the lock on the tx 
Unsafe Range must be called holding the lock on the tx 
Unsafe Delete must be called holding the lock on the tx 
Unsafe For Each must be called holding the lock on the tx 
Commit commits a previous tx and begins a new writable one 
Commit And Stop commits the previous tx and does not create a new one 
Renew renews an existing lease If the given lease does not exist or has expired an error will be returned 
Attach attaches items to the lease with given ID When the lease expires the attached items will be automatically removed If the given lease does not exist an error will be returned 
revoke Expired Leases finds all leases past their expiry and sends them to epxired channel for to be revoked 
checkpoint Scheduled Leases finds all scheduled lease checkpoints that are due and submits them to the checkpointer to persist them to the consensus log 
expire Exists returns true if expiry items exist It pops only when expiry item exists next is true to indicate that it may exist in next attempt 
find Expired Leases loops leases in the lease Map until reaching expired limit and returns the expired leases that needed to be revoked 
Remaining TTL returns the last checkpointed remaining TTL of the lease TODO jpbetz do not expose this utility method 
refresh refreshes the expiry of the lease 
forever sets the expiry of lease to be forever 
Keys returns all the keys attached to the lease 
Remaining returns the remaining time of the lease 
New Compaction Command returns the cobra command for compaction 
compaction Command Func executes the compaction command 
case Sensitive Json Iterator returns a jsoniterator API that s configured to be case sensitive when unmarshalling and otherwise compatible with the encoding json standard library 
New Put Command returns the cobra command for put 
put Command Func executes the put command 
New Handler creates a new HTTP handler listening on the given transport which will proxy requests to an etcd cluster The handler will periodically update its view of the cluster 
New Readonly Handler wraps the given HTTP handler to allow only GET requests 
New Set Command returns the CLI command for set 
set Command Func executes the set command 
wait On Lowest will wait on the last key with a revision rwm my Key Revision with a given prefix If there are no keys left to wait on return true 
Get Default Interfaces fetches the device name of default routable interface 
New Snapshot Command returns the cobra command for snapshot 
New Move Leader Command returns the cobra command for move leader 
transfer Leadership Command Func executes the compaction command 
Open Dir opens a directory in windows with write access for syncing 
New Remove Dir Command returns the CLI command for rmdir 
rmdir Command Func executes the rmdir command 
New Del Command returns the cobra command for del 
del Command Func executes the del command 
TODO support separate WAL directory 
New Expect creates a new process for expect testing 
New Expect With Env creates a new process with user defined env variables for expect testing 
Expect Func returns the first line satisfying the function f 
Expect returns the first line containing the given string 
Line Count returns the number of recorded lines since the beginning of the process 
Signal sends a signal to the expect process 
TODO remove this when Fail Fast false is fixed See https github com grpc grpc go issues 
key Func returns the key of a request which is used to look up its caching response in the cache 
Add adds the response of a request to the cache if its revision is larger than the compacted revision of the cache 
Get looks up the caching response for a given request Get is also responsible for lazy eviction when accessing compacted entries 
Invalidate invalidates the cache entries that intersecting with the given range from key to endkey 
Compact invalidate all caching response before the given rev Replace with the invalidation is lazy The actual removal happens when the entries is accessed 
Set parses a command line set of URLs formatted like http http Implements flag Value interface 
String implements flag Value interface 
New Unique URLs With Exceptions implements url URL slice as flag Value interface Given value is to be separated by comma 
Unique URLs From Flag returns a slice from urls got from the flag 
Unique URLs Map From Flag returns a map from url strings got from the flag 
Hold creates the barrier key causing processes to block on Wait 
Release deletes the barrier key to unblock all waiting processes 
Wait blocks on the barrier key until it is deleted If there is no key Wait assumes Release has already been called and returns immediately 
New Lock Racer Command returns the cobra command for lock racer runner 
Election Timeout returns an election timeout duration 
Dial Etcd GRPCServer creates a raw g RPC connection to an etcd member 
Create Etcd Client Config creates a client configuration from member 
Create Etcd Client creates a client from member 
Check Compact ensures that historical data before given revision has been compacted 
Defrag runs defragmentation on this member 
Rev Hash fetches current revision and hash on this member 
Rev fetches current revision on this member 
Compact compacts member storage with given revision It blocks until it s physically done 
Is Leader returns true if this member is the current cluster leader 
Write Health Key writes a health key to this member 
Save Snapshot downloads a snapshot file from this member locally It s meant to requested remotely so that local member can store snapshot file on local disk 
Restore Snapshot restores a cluster from a given snapshot file on disk It s meant to requested remotely so that local member can load the snapshot file from local disk 
New Watcher wraps a Watcher instance so that all Watch requests are prefixed with a given string and all Watch responses have the prefix removed 
Register registers itself as a grpc proxy server by writing prefixed key with session of specified TTL in seconds The returned channel is closed when the client s context is canceled 
New Raw Node returns a new Raw Node given configuration and a list of raft peers 
Campaign causes this Raw Node to transition to candidate state 
Propose proposes data be appended to the raft log 
Propose Conf Change proposes a config change 
Apply Conf Change applies a config change to the local node 
Step advances the state machine using the given message 
Ready returns the current point in time state of this Raw Node 
Has Ready called when Raw Node user need to check if any Ready pending Checking logic in this method should be consistent with Ready contains Updates 
With Progress is a helper to introspect the Progress for this node and its peers 
Report Unreachable reports the given node is not reachable for the last send 
Report Snapshot reports the status of the sent snapshot 
Transfer Leader tries to transfer leadership to the given transferee 
Read Index requests a read state The read state will be set in ready Read State has a read index Once the application advances further than the read index any linearizable read requests issued before the read request can be processed safely The read state will have the same rctx attached 
printc URL prints the c URL equivalent request to stderr It returns an error if the body of the request cannot be read The caller MUST cancel the request if there is an error 
Fsync on HFS OSX flushes the data on to the physical drive but the drive may not write it to the persistent media for quite sometime and it may be written in out of order sequence Using F FULLFSYNC ensures that the physical drive s buffer will also get flushed to the media 
applied Cursor extracts from the Ready the highest index the client has applied once the Ready is confirmed via Advance If no information is contained in the Ready returns zero 
Start Node returns a new Node given configuration and a list of raft peers It appends a Conf Change Add Node entry for each given peer to the initial log 
Restart Node is similar to Start Node but does not take a list of peers The current membership of the cluster will be restored from the Storage If the caller has an existing state machine pass in the last log index that has been applied to it otherwise use zero 
Tick increments the internal logical clock for this Node Election timeouts and heartbeat timeouts are in units of ticks 
Step advances the state machine using msgs The ctx Err will be returned if any 
Must Sync returns true if the hard state and count of Raft entries indicate that a synchronous write to persistent storage is required 
New GRPC Health returns a new health balancer with g RPC v 
Need Update returns true if all connections are down or addresses do not include current pinned address 
dfl Signal sets the given signal to SIG DFL 
New creates a store where the given namespaces will be created as initial directories 
Index retrieves the current index of the store 
Get returns a get event If recursive is true it will return all the content under the node path If sorted is true it will sort the content by keys 
Create creates the node at node Path Create will help to create intermediate directories with no ttl If the node has already existed create will fail If any node on the path is a file create will fail 
Set creates or replace the node at node Path 
returns user readable cause of failed comparison 
Delete deletes the node at the given path If the node is a directory recursive must be true to delete it 
walk walks all the node Path and apply the walk Func on each directory 
Update updates the value ttl of the node If the node is a file the value and the ttl can be updated If the node is a directory only the ttl can be updated 
Internal Get gets the node of the given node Path 
Delete Expired Keys will delete all expired keys 
check Dir will check whether the component is a directory under parent node If it is a directory this function will return the pointer to that node If it does not exist this function will create a new directory and return the pointer to that node If it is a file this function will return error 
Save saves the static state of the store system It will not be able to save the state of watchers It will not save the parent field of the node Or there will be cyclic dependencies issue for the json package 
Recovery recovers the store system from a static state It needs to recover the parent field of the nodes It needs to delete the expired nodes since the saved time and also needs to create monitoring go routines 
Next generates a id that is unique 
New Make Mirror Command returns the cobra command for make Mirror 
Get Logger returns the logger 
setup Logging initializes etcd logging Must be called after flag parsing or finishing configuring embed Config 
New Zap Core Logger Builder generates a zap core logger builder 
New Syncer creates a Syncer 
Drop Port drops all tcp packets that are received from the given port and sent to the given port 
Set Latency adds latency in millisecond scale with random variations 
Remove Latency resets latency configurations 
New Txn Command returns the cobra command for txn 
txn Command Func executes the txn command 
New returns a new Compactor based on given mode 
print Response Key only supports to print key correctly 
Register Lock Handler registers the http handlers for service Lock to mux The handlers forward requests to the grpc endpoint over conn 
Register Lock Handler registers the http handlers for service Lock to mux The handlers forward requests to the grpc endpoint over the given implementation of Lock Client Note the g RPC framework executes interceptors within the g RPC handler If the passed in Lock Client doesn t go through the normal g RPC flow creating a g RPC client etc then it will be up to the passed in Lock Client to call the correct interceptors 
New Server returns a proxy implementation with no iptables tc dependencies The proxy layer overhead is ms 
TODO implement packet reordering from multiple TCP connections buffer packets per connection for awhile reorder before transmit https github com etcd io etcd issues https github com etcd io etcd pull issuecomment 
serve accepts incoming connections on the listener l creating a new service goroutine for each The service goroutines read requests and then call handler to reply to them 
grpc Handler Func returns an http Handler that delegates to grpc Server on incoming g RPC connections or other Handler otherwise Given in g RPC docs 
create Access Controller wraps HTTP multiplexer mutate g RPC gateway request paths check hostname whitelist client HTTP requests goes here first 
add CORSHeader adds the correct cors headers given an origin 
Wrap CORS wraps existing handler with CORS TODO deprecate this after v proxy deprecate 
fallback computes the ops to fetch all possible conflicting leasing keys for a list of ops 
IDFrom String attempts to create an ID from a base string 
acquire Directory Lock gets a lock on the directory using flock If this is not read only it will also write our pid to dir Path pid File Name for convenience 
Release deletes the pid file and releases our lock on the directory 
Encoded Size is the size of the Value Struct when encoded 
Decode uses the length of the slice to infer the length of the Value field 
Encode expects a slice of length at least v Encoded Size 
Encode To should be kept in sync with the Encode function above The reason this function exists is to avoid creating byte arrays per key value pair in table builder go 
New Merge Iterator returns a new Merge Iterator from a list of Iterators 
init Heap checks all iterators and initializes our heap and array of keys Whenever we reverse direction we need to run this 
Valid returns whether the Merge Iterator is at a valid element 
Key returns the key associated with the current iterator 
Value returns the value associated with the iterator 
Next returns the next element If it is the same as the current key ignore it 
Rewind seeks to first element or last element for reverse iterator 
Seek brings us to element with key given key 
Close implements y Iterator 
Encode encodes Pointer into byte buffer 
Decodes h from buf 
Encodes e to buf Returns number of bytes written 
New Write Batch creates a new Write Batch This provides a way to conveniently do a lot of writes batching them up as tightly as possible in a single transaction and using callbacks to avoid waiting for them to commit thus achieving good performance This API hides away the logic of creating and committing transactions Due to the nature of SSI guaratees provided by Badger blind writes can never encounter transaction conflicts Err Conflict 
Set Entry is the equivalent of Txn Set Entry 
Set is equivalent of Txn Set With Meta 
Set With TTL is equivalent of Txn Set With TTL 
Delete is equivalent of Txn Delete 
Caller to commit must hold a write lock 
Flush must be called at the end to ensure that any pending writes get committed to Badger Flush returns any error stored by Write Batch 
Error returns any errors encountered so far No commits would be run once an error is detected 
Open returns a new DB object 
Close closes a DB It s crucial to call it to ensure all the pending updates make their way to disk Calling DB Close multiple times is not safe and would cause panic 
When you create or delete a file you have to ensure the directory entry for the file is synced in order to guarantee the file is visible if the system crashes See the man page for fsync or see https github com coreos etcd issues for an example 
get Memtables returns the current memtables and get references 
get returns the value in memtable or disk for given key Note that value will include meta byte IMPORTANT We should never write an entry with an older timestamp for the same key We need to maintain this invariant to search for the latest value of a key or else we need to search in all tables and find the max version among them To maintain this invariant we also need to ensure that all versions of a key are always present in the same table from level because compaction can push any table down Update Sep To maintain the above invariant and to allow keys to be moved from one value log to another while reclaiming space during value log GC we have logically moved this need to write old versions after new versions to the badger Move keyspace Thus for normal gets we can stop going down the LSM tree once we find any version of the key note however that we will ALWAYS skip versions with ts greater than the key version However if that key has been moved then for the corresponding movekey we ll look through all the levels of the tree to ensure that we pick the highest version of the movekey present 
write Requests is called serially by only one goroutine 
batch Set applies a list of badger Entry If a request level error occurs it will be returned Check kv Batch Set entries 
batch Set Async is the asynchronous version of batch Set It accepts a callback function which is called when all the sets are complete If a request level error occurs it will be passed back via the callback err kv Batch Set Async entries func err error Check err 
ensure Room For Write is always called serially 
Write Level Table flushes memtable 
handle Flush Task must be run serially 
flush Memtable must keep running until we send it an empty flush Task If there are errors during handling the flush task we ll retry indefinitely 
This function does a filewalk calculates the size of vlog and sst files and stores it in y LSMSize and y Vlog Size 
Run Value Log GC triggers a value log garbage collection It picks value log files to perform GC based on statistics that are collected duing compactions If no such statistics are available then log files are picked in random order The process stops as soon as the first log file is encountered which does not result in garbage collection When a log file is picked it is first sampled If the sample shows that we can discard at least discard Ratio space of that file it would be rewritten If a call to Run Value Log GC results in no rewrites then an Err No Rewrite is thrown indicating that the call resulted in no file rewrites We recommend setting discard Ratio to thus indicating that a file be rewritten if half the space can be discarded This results in a lifetime value log write amplification of from original write rewrite Setting it to higher value would result in fewer space reclaims while setting it to a lower value would result in more space reclaims at the cost of increased activity on the LSM tree discard Ratio must be in the range both endpoints excluded otherwise an Err Invalid Request is returned Only one GC is allowed at a time If another value log GC is running or DB has been closed this would return an Err Rejected Note Every time GC is run it would produce a spike of activity on the LSM tree 
Size returns the size of lsm and value log files in bytes It can be used to decide how often to call Run Value Log GC 
Next would return the next integer in the sequence updating the lease by running a transaction if needed 
Release the leased sequence to avoid wasted integers This should be done right before closing the associated DB However it is valid to use the sequence after it was released causing a new lease with full bandwidth 
Get Sequence would initiate a new sequence object generating it from the stored lease if available in the database Sequence can be used to get a list of monotonically increasing integers Multiple sequences can be created by providing different keys Bandwidth sets the size of the lease determining how many Next requests can be served from memory Get Sequence is not supported on Managed DB Calling this would result in a panic 
Key Splits can be used to get rough key ranges to divide up iteration over the DB 
Flatten can be used to force compactions on the LSM tree so all the tables fall on the same level This ensures that all the versions of keys are colocated and not split across multiple levels which is necessary after a restore from backup During Flatten live compactions are stopped Ideally no writes are going on during Flatten Otherwise it would create competition between flattening the tree and new tables being created at level zero 
Drop All would drop all the data stored in Badger It does this in the following way Stop accepting new writes Pause memtable flushes and compactions Pick all tables from all levels create a changeset to delete all these tables and apply it to manifest Pick all log files from value log and delete all of them Restart value log files from zero Resume memtable flushes and compactions NOTE Drop All is resilient to concurrent writes but not to reads It is up to the user to not do any reads while Drop All is going on otherwise they may result in panics Ideally both reads and writes are paused before running Drop All and resumed after it is finished 
Drop Prefix would drop all the keys with the provided prefix It does this in the following way Stop accepting new writes Stop memtable flushes and compactions Flush out all memtables skipping over keys with the given prefix Kp Write out the value log header to memtables when flushing so we don t accidentally bring Kp back after a restart Compact L L skipping over Kp Compact rest of the levels Li Li picking tables which have Kp Resume memtable flushes compactions and writes 
Mmap uses the mmap system call to memory map a file If writable is true memory protection of the pages is set so that they may be written to as well 
Madvise uses the madvise system call to give advise about the use of memory when using a slice that is memory mapped to a file Set the readahead flag to false if page references are expected in random order 
Any deleted or invalid versions at or below ts would be discarded during compaction to reclaim disk space in LSM tree and thence value log 
has Conflict must be called while having a lock 
Set adds a key value pair to the database It will return Err Read Only Txn if update flag was set to false when creating the transaction The current transaction keeps a reference to the key and val byte slice arguments Users must not modify key and val until the end of the transaction 
Set With Meta adds a key value pair to the database along with a metadata byte This byte is stored alongside the key and can be used as an aid to interpret the value or store other contextual bits corresponding to the key value pair The current transaction keeps a reference to the key and val byte slice arguments Users must not modify key and val until the end of the transaction 
Delete deletes a key This is done by adding a delete marker for the key at commit timestamp Any reads happening before this timestamp would be unaffected Any reads after this commit would see the deletion The current transaction keeps a reference to the key byte slice argument Users must not modify the key until the end of the transaction 
Get looks for key and returns corresponding Item If key is not found Err Key Not Found is returned 
Discard discards a created transaction This method is very important and must be called Commit method calls this internally however calling this multiple times doesn t cause any issues So this can safely be called via a defer right when transaction is created NOTE If any operations are run on a discarded transaction Err Discarded Txn is returned 
Commit commits the transaction following these steps If there are no writes return immediately Check if read rows were updated since txn started If so return Err Conflict If no conflict generate a commit timestamp and update written rows commit ts Batch up all writes write them to value log and LSM tree If callback is provided Badger will return immediately after checking for conflicts Writes to the database will happen in the background If there is a conflict an error will be returned and the callback will not run If there are no conflicts the callback will be called in the background upon successful completion of writes or any error during write If error is nil the transaction is successfully committed In case of a non nil error the LSM tree won t be updated so there s no need for any rollback 
Commit With acts like Commit but takes a callback which gets run via a goroutine to avoid blocking this function The callback is guaranteed to run so it is safe to increment sync Wait Group before calling Commit With and decrementing it in the callback to block until all callbacks are run 
New Transaction creates a new transaction Badger supports concurrent execution of transactions providing serializable snapshot isolation avoiding write skews Badger achieves this by tracking the keys read and at Commit time ensuring that these read keys weren t concurrently modified by another transaction For read only transactions set update to false In this mode we don t track the rows read for any changes Thus any long running iterations done in this mode wouldn t pay this overhead Running transactions concurrently is OK However a transaction itself isn t thread safe and should only be run serially It doesn t matter if a transaction is created by one goroutine and passed down to other as long as the Txn APIs are called serially When you create a new transaction it is absolutely essential to call Discard This should be done irrespective of what the update param is set to Commit API internally runs Discard but running it twice wouldn t cause any issues txn db New Transaction false defer txn Discard Call various APIs 
View executes a function creating and managing a read only transaction for the user Error returned by the function is relayed by the View method If View is used with managed transactions it would assume a read timestamp of Max Uint 
Update executes a function creating and managing a read write transaction for the user Error returned by the function is relayed by the Update method Update cannot be used with managed transactions 
Seek brings us to the first block element that is input key 
Seek To Last brings us to the last element Valid should return true 
parse KV would allocate a new byte slice for key and for value 
New Iterator returns a new iterator of the Table 
seek From brings us to a key that is input key 
seek For Prev will reset iterator and seek to key 
Value follows the y Iterator interface 
Seek follows the y Iterator interface 
New Concat Iterator creates a new concatenated iterator 
Rewind implements y Interface 
Valid implements y Interface 
Seek brings us to element key if reversed is false Otherwise key 
Next advances our concat iterator 
Close implements y Interface 
Open Existing File opens an existing file errors if it doesn t exist 
Create Synced File creates a new file using O EXCL errors if it already existed 
Copy copies a byte slice and returns the copied slice 
Key With Ts generates a new key by appending ts to key 
Parse Ts parses the timestamp from the key bytes 
Compare Keys checks the key without timestamp and checks the timestamp if key No Ts is same a timestamp would be sorted higher than aa timestamp if we use bytes compare All keys should have timestamp 
Parse Key parses the actual key from the key bytes 
Same Key checks for key equality ignoring the version timestamp suffix 
Resize reuses the Slice s buffer or makes a new one and returns a slice in that buffer of length sz 
Fixed Duration returns a string representation of the given duration with the hours minutes and seconds 
New Closer constructs a new Closer with an initial count on the Wait Group 
New Throttle creates a new throttle with a max number of workers 
Do should be called by workers before they start working It blocks if there are already maximum number of workers working If it detects an error from previously Done workers it would return it 
Done should be called by workers when they finish working They can also pass the error status of work done 
Finish waits until all workers have finished working It would return any error passed by Done 
Open Managed returns a new DB which allows more control over setting transaction timestamps aka managed mode This is only useful for databases built on top of Badger like Dgraph and can be ignored by most users 
New Transaction At follows the same logic as DB New Transaction but uses the provided read timestamp This is only useful for databases built on top of Badger like Dgraph and can be ignored by most users 
Commit At commits the transaction following the same logic as Commit but at the given commit timestamp This will panic if not used with managed transactions This is only useful for databases built on top of Badger like Dgraph and can be ignored by most users 
Set Discard Ts sets a timestamp at or below which any invalid or deleted versions can be discarded from the LSM tree and thence from the value log to reclaim disk space Can only be used with managed transactions 
open Read Only assumes that we have a write lock on log File 
Acquire lock on mmap file if you are calling this 
iterate iterates over log file It doesn t not allocate new memory for every kv pair Therefore the kv pair is only valid for the duration of fn call 
sorted Fids returns the file id s not pending deletion sorted Assumes we have shared access to files Map 
sync function syncs content of latest value log file to disk Syncing of value log directory is not required here as it happens every time a value log file rotation happens check create Vlog File function During rotation previous value log file also gets synced to disk It only syncs file if fid vlog max Fid In some cases such as replay while openning db it might be called with fid vlog max Fid To sync irrespective of file id just call it with math Max Uint 
write is thread unsafe by design and should not be called concurrently 
Gets the log File and acquires and RLock for the mmap You must call RUnlock on the file if non nil 
Read reads the value log at a given location TODO Make this read private 
Test helper 
encoded Discard Stats returns byte representation of lf Discard Stats This will be called while storing stats in Badger DB 
populate Discard Stats populates vlog lf Discard Stats This function will be called while initializing value Log 
Backup is a wrapper function over Stream Backup to generate full and incremental backups of the DB For more control over how many goroutines are used to generate the backup or if you wish to backup only a certain range of keys use Stream Backup directly 
Backup dumps a protobuf encoded list of all entries in the database into the given writer that are newer than the specified version It returns a timestamp indicating when the entries were dumped which can be passed into a later invocation to generate an incremental dump of entries that have been added modified since the last invocation of Stream Backup This can be used to backup the data in a database at a given point in time 
Load reads a protobuf encoded list of all entries from a reader and writes them to the database This can be used to restore the database from a backup made by calling DB Backup DB Load should be called on a database that is not running any other concurrent transactions while it is running 
To List is a default implementation of Key To List It picks up all valid versions of the key skipping over deleted or expired keys 
key Range is start end including start excluding end Do ensure that the start end byte slices are owned by key Range struct 
produce KVs picks up ranges from range Ch generates KV lists and sends them to kv Chan 
Orchestrate runs Stream It picks up ranges from the SSTables then runs Num Go number of goroutines to iterate over these ranges and batch up KVs in lists It concurrently runs a single goroutine to pick these lists batch them up further and send to Output Send Orchestrate also spits logs out to Infof using provided Log Prefix Note that all calls to Output Send are serial In case any of these steps encounter an error Orchestrate would stop execution and return that error Orchestrate can be called multiple times but in serial order 
New Stream creates a new Stream 
New Stream At creates a new Stream at a particular timestamp Should only be used with managed DB 
Decr Ref decrements the refcount and possibly deletes the table 
Open Table assumes file has only one table and opens it Takes ownership of fd upon function entry Returns a table with one reference count on it decrementing which may delete the file consider t Close instead The fd has to writeable because we call Truncate on it before deleting 
Close closes the open table Releases resources back to the OS 
Parse File ID reads the file id out of a filename 
New Filename should be named Table Filepath it combines the dir with the ID to make a table filepath 
Print Histogram builds and displays the key value size histogram When key Prefix is set only the keys that have prefix key Prefix are considered for creating the histogram 
new Size Histogram returns a new instance of key Value Size Histogram with properly initialized fields 
create Histogram Bins creates bins for an histogram The bin sizes are powers of two of the form min exponent max exponent 
Update the min and max fields if value is less than or greater than the current min max value 
build Histogram builds the key value size histogram When key Prefix is set only the keys that have prefix key Prefix are considered for creating the histogram 
print Histogram prints the histogram data in a human readable format 
Init initializes a Water Mark struct MUST be called before using it 
Begin sets the last index to the given value 
Begin Many works like Begin but accepts multiple indices 
Done sets a single index as done 
Done Many works like Done but accepts multiple indices 
Set Done Until sets the maximum index that has the property that all indices less than or equal to it are done 
Wait For Mark waits until the given index is marked as done 
process is used to process the Mark channel This is not thread safe so only run one goroutine for process One is sufficient because all goroutine ops use purely memory and cpu Each index has to emit atleast one begin watermark in serial order otherwise waiters can get blocked idefinitely Example We had an watermark at and a waiter at if no watermark is emitted at index then waiter would get stuck indefinitely as it can t decide whether the task at has decided not to emit watermark or it didn t get scheduled yet 
Encode encodes the header 
Decode decodes the header 
New Table Builder makes a new Table Builder 
key Diff returns a suffix of new Key that is different from b base Key 
Add adds a key value pair to the block If do Not Restart is true we will not restart even if b counter restart Interval 
TODO vvv this was the comment on Reached Capacity Final Size returns the rough final size of the array counting the header which is not yet written TODO Look into why there is a discrepancy I suspect it is because of Write empty empty at the end The diff can vary Reached Capacity returns true if we roughly reached capacity 
block Index generates the block index for the table It is mainly a list of all the block base offsets 
Finish finishes the table by appending the index 
Errorf logs an ERROR log message to the logger specified in opts or to the global logger if no logger is specified in opts 
Infof logs an INFO message to the logger specified in opts 
Warningf logs a WARNING message to the logger specified in opts 
Warningf logs a WARNING message to the logger specified in opts 
Decr Ref decrements the refcount deallocating the Skiplist when done using it 
New Skiplist makes a new empty skiplist with a given arena size 
Returns true if key is strictly n key If n is nil this is an end marker and we return false func s Skiplist key Is After Node key byte n node bool y Assert True n s head return n nil y Compare Keys key n key 
find Near finds the node near to key If less true it finds rightmost node such that node key key if allow Equal false or node key key if allow Equal true If less false it finds leftmost node such that node key key if allow Equal false or node key key if allow Equal true Returns the node found The bool returned is true if the node has key equal to given key 
find Splice For Level returns out Before out After with out Before key key out After key The input before tells us where to start looking If we found a node with the same key then we return out Before out After Otherwise out Before key key out After key 
Put inserts the key value pair 
find Last returns the last element If head empty list we return nil All the find functions will NEVER return the head nodes 
Get gets the value associated with the key It returns a valid value if it finds equal or earlier version of the same key 
Key returns the key at the current position 
Value returns value 
Next advances to the next position 
Prev advances to the previous position 
Seek advances to the first entry with a key target 
Seek For Prev finds an entry with key target 
Seek To First seeks position at the first entry in list Final state of iterator is Valid iff list is not empty 
New Uni Iterator returns a Uni Iterator 
Next implements y Interface 
Rewind implements y Interface 
Seek implements y Interface 
as Changes returns a sequence of changes that could be used to recreate the Manifest in its present state 
open Or Create Manifest File opens a Badger manifest file if it exists or creates on if one doesn t 
add Changes writes a batch of changes atomically to the file By atomically that means when we replay the MANIFEST file we ll either replay all the changes or none of them The truth of this depends on the filesystem some might append garbage data if a system crash happens at the wrong time 
Must be called while append Lock is held 
Replay Manifest File reads the manifest file and constructs two manifest objects We need one immutable copy and one mutable copy of the manifest Easiest way is to construct two of them Also returns the last offset after a completely read manifest entry the file must be truncated at that point before further appends are made if there is a partial entry after that In normal conditions trunc Offset is the file size 
This is not a recoverable error opening the KV store fails because the MANIFEST file is just plain broken 
Check does some sanity check on one level of data or in memory index 
func s KV debug Print More s lc debug Print More debug Print More shows key ranges of each level func s levels Controller debug Print More s Lock defer s Unlock for i i s kv opt Max Levels i s levels i debug Print More func s level Handler debug Print More s RLock defer s RUnlock s elog Printf Level d s level for t range s tables y Printf s s t Smallest t Biggest y Printf n reserve File ID reserves a unique file id 
Acquire Directory Lock acquires exclusive access to a directory 
Release removes the directory lock 
Assert Truef is Assert True with extra info 
Wrapf is Wrap with extra info 
init Tables replaces s tables with given tables This is done during loading 
delete Tables remove tables idx idx 
replace Tables will replace tables left right with new Tables Note this EXCLUDES tables right You must call decr to delete the old tables after writing the update to the manifest 
try Add Level Table returns true if ok and no stalling 
get Table For Key acquires a read lock to access s tables It returns a list of table Handlers 
get returns value for a given key or the key after that If not found return nil 
append Iterators appends iterators to an array of iterators for merging Note This obtains references for the table handlers Remember to close these iterators 
overlapping Tables returns the tables that intersect with key range Returns a half interval This function should already have acquired a read lock and this is so important the caller must pass an empty parameter declaring such 
String returns a string representation of Item 
Key Copy returns a copy of the key of the item writing it to dst slice If nil is passed or capacity of dst isn t sufficient a new slice would be allocated and returned 
Value retrieves the value of the item from the value log This method must be called within a transaction Calling it outside a transaction is considered undefined behavior If an iterator is being used then Item Value is defined in the current iteration only because items are reused If you need to use a value outside a transaction please use Item Value Copy instead or copy it yourself Value might change once discard or commit is called Use Value Copy if you want to do a Set after Get 
Value Copy returns a copy of the value of the item from the value log writing it to dst slice If nil is passed or capacity of dst isn t sufficient a new slice would be allocated and returned Tip It might make sense to reuse the returned slice as dst argument for the next call This function is useful in long running iterate update transactions to avoid a write deadlock See Github issue https github com dgraph io badger issues 
Estimated Size returns the approximate size of the key value pair This can be called while iterating through a store to quickly estimate the size of a range of key value pairs without fetching the corresponding values 
Value Size returns the exact size of the value This can be called to quickly estimate the size of a value without fetching it 
New Iterator returns a new iterator Depending upon the options either only keys or both key value pairs would be fetched The keys are returned in lexicographically sorted order Using prefetch is recommended if you re doing a long running iteration for performance Multiple Iterators For a read only txn multiple iterators can be running simultaneously However for a read write txn only one can be running at one time to avoid race conditions because Txn is thread unsafe 
New Key Iterator is just like New Iterator but allows the user to iterate over all versions of a single key Internally it sets the Prefix option in provided opt and uses that prefix to additionally run bloom filter lookups before picking tables from the LSM tree 
Item returns pointer to the current key value pair This item is only valid until it Next gets called 
Valid returns false when iteration is done 
Valid For Prefix returns false when iteration is done or when the current key is not prefixed by the specified prefix 
Close would close the iterator It is important to call this when you re done with iteration 
Next would advance the iterator by one Always check it Valid after a Next to ensure you have access to a valid it Item 
parse Item is a complex function because it needs to handle both forward and reverse iteration implementation We store keys such that their versions are sorted in descending order This makes forward iteration efficient but revese iteration complicated This tradeoff is better because forward iteration is more common than reverse This function advances the iterator 
Seek would seek to the provided key if present If absent it would seek to the next smallest key greater than the provided key if iterating in the forward direction Behavior would be reversed if iterating backwards 
Get Merge Operator creates a new Merge Operator for a given key and returns a pointer to it It also fires off a goroutine that performs a compaction using the merge function that runs periodically as specified by dur 
Add records a value in Badger which will eventually be merged by a background routine into the values that were recorded by previous invocations to Add 
Get returns the latest value for the merge operator which is derived by applying the merge function to all the values added so far If Add has not been called even once Get will return Err Key Not Found 
compare And Add will check whether we can run this compact Def That it doesn t overlap with any other running compaction If it can be run it would store this run in the compact Status state 
new Arena returns a new arena 
put Node allocates a node in the arena The node is aligned on a pointer sized boundary The arena offset of the node is returned 
Put will copy val into arena To make better use of this reuse your input val buffer Returns an offset into buf User is responsible for remembering size of val We could also store this size inside arena but the encoding and decoding will incur some overhead 
get Node returns a pointer to the node located at offset If the offset is zero then the nil node pointer is returned 
get Key returns byte slice at offset 
get Val returns byte slice at offset The given size should be just the value size and should NOT include the meta bytes 
get Node Offset returns the offset of node in the arena If the node pointer is nil then the zero offset is returned 
These variables are global and have cumulative values for all kv stores 
revert To Manifest checks that all necessary table files exist and removes all table files not referenced by the manifest id Map is a set of table file id s that were read from the directory listing 
Closes the tables for cleanup in new Levels Controller We Close instead of using Decr Ref because that would delete the underlying files We ignore errors which is OK because tables are read only 
drop Tree picks all tables from all levels creates a manifest changeset applies it and then decrements the refs of these tables which would result in their deletion 
drop Prefix runs a L L compaction and then runs same level compaction on the rest of the levels For L L compaction it runs compactions normally but skips over all the keys with the provided prefix For Li Li compactions it picks up the tables which would have the prefix The tables who only have keys with this prefix are quickly dropped The ones which have other keys are run through Merge Iterator and compacted to create new tables All the mechanisms of compactions apply i e level sizes and MANIFEST are updated as in the normal flow 
Returns true if level zero may be compacted without accounting for compactions that already might be happening 
Returns true if the non zero level may be compacted del Size provides the size of the tables which are currently being compacted so that we treat them as already having started being compacted because they have been yet their size is already counted in get Total Size 
pick Compact Level determines which level to compact Based on https github com facebook rocksdb wiki Leveled Compaction 
compact Build Tables merge top Tables and bot Tables to form a list of new tables 
do Compact picks some table on level l and compacts it away to the next level 
get returns the found value if any If not found we return nil 
append Iterators appends iterators to an array of iterators for merging Note This obtains references for the table handlers Remember to close these iterators 
seek Total retrives the total of all accounts by seeking for each account key 
Range is low Ts high Ts 
Create replaces the stored snapshot with a new one using the given args 
List returns the latest snapshot taken 
Open wraps an io Read Closer around the snapshot contents 
Write appends the given bytes to the snapshot contents 
New File Snapshot Store With Logger creates a new File Snapshot Store based on a base directory The retain parameter controls how many snapshots are retained Must be at least 
New File Snapshot Store creates a new File Snapshot Store based on a base directory The retain parameter controls how many snapshots are retained Must be at least 
snapshot Name generates a name for the snapshot 
Create is used to start a new snapshot 
List returns available snapshots in the store 
get Snapshots returns all the known snapshots 
read Meta is used to read the meta data for a given named backup 
Open takes a snapshot ID and returns a Read Closer for that snapshot 
Reap Snapshots reaps any snapshots beyond the retain count 
Write is used to append to the state file We write to the buffered IO object to reduce the amount of context switches 
Close is used to indicate a successful end 
Cancel is used to indicate an unsuccessful end 
finalize is used to close all of our resources 
write Meta is used to write out the metadata we have 
New Network Transport With Config creates a new network transport with the given config struct 
New Network Transport creates a new network transport with the given dialer and listener The max Pool controls how many connections we will pool The timeout is used to apply I O deadlines For Install Snapshot we multiply the timeout by Snapshot Size Timeout Scale 
New Network Transport With Logger creates a new network transport with the given logger dialer and listener The max Pool controls how many connections we will pool The timeout is used to apply I O deadlines For Install Snapshot we multiply the timeout by Snapshot Size Timeout Scale 
setup Stream Context is used to create a new stream context This should be called with the stream lock held 
get Stream Context is used retrieve the current stream context 
Set Heartbeat Handler is used to setup a heartbeat handler as a fast pass This is to avoid head of line blocking from disk IO 
Close Streams closes the current streams 
Close is used to stop the network transport 
get Existing Conn is used to grab a pooled connection 
get Conn From Address Provider returns a connection from the server address provider if available or defaults to a connection using the target server address 
get Conn is used to get a connection from the pool 
return Conn returns a connection back to the pool 
Append Entries Pipeline returns an interface that can be used to pipeline Append Entries requests 
Append Entries implements the Transport interface 
Request Vote implements the Transport interface 
generic RPC handles a simple request response RPC 
Install Snapshot implements the Transport interface 
Encode Peer implements the Transport interface 
listen is used to handling incoming connections 
handle Conn is used to handle an inbound connection for its lifespan The handler will exit when the passed context is cancelled or the connection is closed 
handle Command is used to decode and dispatch a single command 
decode Response is used to decode an RPC response and reports whether the connection can be reused 
send RPC is used to encode and send the RPC 
new Net Pipeline is used to construct a net Pipeline from a given transport and connection 
decode Responses is a long running routine that decodes the responses sent on the connection 
Append Entries is used to pipeline a new append entries request 
Closed is used to shutdown the pipeline connection 
New Observer creates a new observer that can be registered to make observations on a Raft instance Observations will be sent on the given channel if they satisfy the given filter If blocking is true the observer will block when it can t send on the channel otherwise it may discard events 
Register Observer registers a new observer 
Deregister Observer deregisters an observer 
observe sends an observation to every observer 
New Inmem Store returns a new in memory backend Do not ever use for production Only for testing 
First Index implements the Log Store interface 
Last Index implements the Log Store interface 
Get Log implements the Log Store interface 
Store Log implements the Log Store interface 
Store Logs implements the Log Store interface 
Delete Range implements the Log Store interface 
Set implements the Stable Store interface 
Get implements the Stable Store interface 
Set Uint implements the Stable Store interface 
Get Uint implements the Stable Store interface 
New Log Cache is used to create a new Log Cache with the given capacity and backend store 
New Inmem Transport With Timeout is used to initialize a new transport and generates a random local address if none is specified The given timeout will be used to decide how long to wait for a connected peer to process the RPCs that we re sending it See also Connect and Consumer 
Append Entries Pipeline returns an interface that can be used to pipeline Append Entries requests 
Append Entries implements the Transport interface 
Request Vote implements the Transport interface 
Install Snapshot implements the Transport interface 
Encode Peer implements the Transport interface 
Connect is used to connect this transport to another transport for a given peer name This allows for local routing 
Disconnect is used to remove the ability to route to a given peer 
Disconnect All is used to remove all routes to peers 
Respond is used to respond with a response error or both 
Open is a function you can call to access the underlying snapshot and its metadata 
vote is used to respond to a verify Future This may block when responding on the notify Ch 
notify All is used to notify all the waiting verify futures if the follower believes we are still the leader 
clean Notify is used to delete notify 
Last Contact returns the time of last contact 
set Last Contact sets the last contact to the current time 
replicate is a long running routine that replicates log entries to a single follower 
replicate To is a helper to replicate used to replicate the logs up to a given last index If the follower log is behind we take care to bring them up to date 
heartbeat is used to periodically invoke Append Entries on a peer to ensure they don t time out This is done async of replicate since that routine could potentially be blocked on disk IO 
pipeline Replicate is used when we have synchronized our state with the follower and want to switch to a higher performance pipeline mode of replication We only pipeline Append Entries commands and if we ever hit an error we fall back to the standard replication which can handle more complex situations 
pipeline Send is used to send data over a pipeline It is a helper to pipeline Replicate 
pipeline Decode is used to decode the responses of pipelined requests 
setup Append Entries is used to setup an append entries request 
set Previous Log is used to setup the Prev Log Entry and Prev Log Term for an Append Entries Request given the next index to replicate 
set New Logs is used to setup the logs which should be appended for a request 
append Stats is used to emit stats about an Append Entries invocation 
handle Stale Term is used when a follower indicates that we have a stale term 
update Last Appended is used to update follower replication state after a successful Append Entries RPC TODO This isn t used during Install Snapshot but the code there is similar 
Append Entries sends the appropriate RPC to the target node 
Request Vote sends the appropriate RPC to the target node 
Install Snapshot is used to push a snapshot down to a follower The data is read from the Read Closer and streamed to the client 
Encode Peer is used to serialize a peer name 
Decode Peer is used to deserialize a peer name 
Append Entries Pipeline returns an interface that can be used to pipeline Append Entries requests 
Append Entries is used to add another request to the pipeline The send may block which is an effective form of back pressure 
Read Peers JSON consumes a legacy peers json file in the format of the old JSON peer store and creates a new style configuration structure This can be used to migrate this data or perform manual recovery when running protocol versions that can interoperate with older unversioned Raft servers This should not be used once server IDs are in use because the old peers json file didn t have support for these nor non voter suffrage types 
Read Config JSON reads a new style peers json and returns a configuration structure This can be used to perform manual recovery when running protocol versions that use server IDs 
New TCPTransport returns a Network Transport that is built on top of a TCP streaming transport layer 
New TCPTransport With Logger returns a Network Transport that is built on top of a TCP streaming transport layer with log output going to the supplied Logger 
New TCPTransport With Config returns a Network Transport that is built on top of a TCP streaming transport layer using the given config struct 
Dial implements the Stream Layer interface 
Accept implements the net Listener interface 
Addr implements the net Listener interface 
Bootstrap Cluster initializes a server s storage with the given cluster configuration This should only be called at the beginning of time for the cluster and you absolutely must make sure that you call it with the same configuration on all the Voter servers There is no need to bootstrap Nonvoter and Staging servers One sane approach is to bootstrap a single server with a configuration listing just itself as a Voter then invoke Add Voter on it to add other servers to the cluster 
Recover Cluster is used to manually force a new configuration in order to recover from a loss of quorum where the current configuration cannot be restored such as when several servers die at the same time This works by reading all the current state for this server creating a snapshot with the supplied configuration and then truncating the Raft log This is the only safe way to force a given configuration without actually altering the log to insert any new entries which could cause conflicts with other servers with different state WARNING This operation implicitly commits all entries in the Raft log so in general this is an extremely unsafe operation If you ve lost your other servers and are performing a manual recovery then you ve also lost the commit information so this is likely the best you can do but you should be aware that calling this can cause Raft log entries that were in the process of being replicated but not yet be committed to be committed Note the FSM passed here is used for the snapshot operations and will be left in a state that should not be used by the application Be sure to discard this FSM and any associated state and provide a fresh one when calling New Raft later A typical way to recover the cluster is to shut down all servers and then run Recover Cluster on every server using an identical configuration When the cluster is then restarted and election should occur and then Raft will resume normal operation If it s desired to make a particular server the leader this can be used to inject a new configuration with that server as the sole voter and then join up other new clean state peer servers using the usual APIs in order to bring the cluster back into a known state 
Has Existing State returns true if the server has any existing state logs knowledge of a current term or any snapshots 
New Raft is used to construct a new Raft node It takes a configuration as well as implementations of various interfaces that are required If we have any old state such as snapshots logs peers etc all those will be restored when creating the Raft node 
restore Snapshot attempts to restore the latest snapshots and fails if none of them can be restored This is called at initialization time and is completely unsafe to call at any other time 
Bootstrap Cluster is equivalent to non member Bootstrap Cluster but can be called on an un bootstrapped Raft instance after it has been created This should only be called at the beginning of time for the cluster and you absolutely must make sure that you call it with the same configuration on all the Voter servers There is no need to bootstrap Nonvoter and Staging servers 
Leader is used to return the current leader of the cluster It may return empty string if there is no current leader or the leader is unknown 
Apply is used to apply a command to the FSM in a highly consistent manner This returns a future that can be used to wait on the application An optional timeout can be provided to limit the amount of time we wait for the command to be started This must be run on the leader or it will fail 
Barrier is used to issue a command that blocks until all preceeding operations have been applied to the FSM It can be used to ensure the FSM reflects all queued writes An optional timeout can be provided to limit the amount of time we wait for the command to be started This must be run on the leader or it will fail 
Verify Leader is used to ensure the current node is still the leader This can be done to prevent stale reads when a new leader has potentially been elected 
Get Configuration returns the latest configuration and its associated index currently in use This may not yet be committed This must not be called on the main thread which can access the information directly 
Add Peer deprecated is used to add a new peer into the cluster This must be run on the leader or it will fail Use Add Voter Add Nonvoter instead 
Remove Peer deprecated is used to remove a peer from the cluster If the current leader is being removed it will cause a new election to occur This must be run on the leader or it will fail Use Remove Server instead 
Add Voter will add the given server to the cluster as a staging server If the server is already in the cluster as a voter this updates the server s address This must be run on the leader or it will fail The leader will promote the staging server to a voter once that server is ready If nonzero prev Index is the index of the only configuration upon which this change may be applied if another configuration entry has been added in the meantime this request will fail If nonzero timeout is how long this server should wait before the configuration change log entry is appended 
Remove Server will remove the given server from the cluster If the current leader is being removed it will cause a new election to occur This must be run on the leader or it will fail For prev Index and timeout see Add Voter 
Shutdown is used to stop the Raft background routines This is not a graceful operation Provides a future that can be used to block until all background routines have exited 
Snapshot is used to manually force Raft to take a snapshot Returns a future that can be used to block until complete and that contains a function that can be used to open the snapshot 
Restore is used to manually force Raft to consume an external snapshot such as if restoring from a backup We will use the current Raft configuration not the one from the snapshot so that we can restore into a new cluster We will also use the higher of the index of the snapshot or the current index and then add to that so we force a new state with a hole in the Raft log so that the snapshot will be sent to followers and used for any new joiners This can only be run on the leader and blocks until the restore is complete or an error occurs WARNING This operation has the leader take on the state of the snapshot and then sets itself up so that it replicates that to its followers though the install snapshot process This involves a potentially dangerous period where the leader commits ahead of its followers so should only be used for disaster recovery into a fresh cluster and should not be used in normal operations 
String returns a string representation of this Raft node 
Last Contact returns the time of last contact by a leader This only makes sense if we are currently a follower 
Stats is used to return a map of various internal stats This should only be used for informative purposes or debugging Keys are state term last log index last log term commit index applied index fsm pending last snapshot index last snapshot term latest configuration last contact and num peers The value of state is a numerical value representing a Raft State const The value of latest configuration is a string which contains the id of each server its suffrage status and its address The value of last contact is either never if there has been no contact with a leader if the node is in the leader state or the time since last contact with a leader formatted as a string The value of num peers is the number of other voting servers in the cluster not including this node If this node isn t part of the configuration then this will be All other values are uint s formatted as strings 
Logf will record a formatted message to the contained debug log 
Leader returns the node that is currently the Leader if there is no leader this function blocks until a leader is elected or a timeout occurs 
contains Node returns true if the slice nodes contains n 
Leader Plus returns the leader n additional nodes from the cluster the leader is always the first node in the returned slice 
Wait Til Upto Date blocks until all nodes in the cluster have gotten their commited Index upto the Index from the last successful call to Apply 
assert Log Entry Equal compares the raft Log entries and reports any differences to the supplied testing T instance it return true if the entries are equal false otherwise 
run FSM is a long running goroutine responsible for applying logs to the FSM This is done async of other logs since we don t want the FSM to block our internal operations 
Clone makes a deep copy of a Configuration 
Clone makes a deep copy of a configurations object 
has Vote returns true if the server identified by id is a Voter in the provided Configuration 
check Configuration tests a cluster membership configuration for common errors 
next Configuration generates a new Configuration from the current one and a configuration change request It s split from append Configuration Entry so that it can be unit tested easily 
encode Peers is used to serialize a Configuration into the old peers format This is here for backwards compatibility when operating with a mix of old servers and should be removed once we deprecate support for protocol version 
decode Peers is used to deserialize an old list of peers into a Configuration This is here for backwards compatibility with old log entries and snapshots it should be removed eventually 
encode Configuration serializes a Configuration using Msg Pack or panics on errors 
decode Configuration deserializes a Configuration using Msg Pack or panics on errors 
Start a goroutine and properly handle the race between a routine starting and incrementing and exiting and decrementing 
get Last Index returns the last index in stable storage Either from the last log or from the last snapshot 
get Last Entry returns the last index and term in stable storage Either from the last log or from the last snapshot 
resolve Directory returns a full directory path based on the supplied dir path if the supplied dir path is absolute i e it starts with then it is returned as is if it s a relative path then it is assumed to be relative to the executable and that is computed and returned if create is true then the directory path will be created if it doesn t already exist if create is false then it s upto the caller to ensure it exists and or create it as needed this won t verify that it exists 
check RPCHeader houses logic about whether this instance of Raft can process the given RPC message 
set Leader is used to modify the current leader of the cluster 
request Config Change is a helper for the above functions that make configuration change requests req describes the change For timeout see Add Voter 
run is a long running goroutine that runs the Raft FSM 
run Follower runs the FSM for a follower 
live Bootstrap attempts to seed an initial configuration for the cluster See the Raft object s member Bootstrap Cluster for more details This must only be called on the main thread and only makes sense in the follower state 
run Candidate runs the FSM for a candidate 
run Leader runs the FSM for a leader Do the setup here and drop into the leader Loop for the hot loop 
start Stop Replication will set up state and start asynchronous replication to new peers and stop replication to removed peers Before removing a peer it ll instruct the replication routines to try to replicate to the current index This must only be called from the main thread 
configuration Change Ch If Stable returns r configuration Change Ch if it s safe to process requests from it or nil otherwise This must only be called from the main thread Note that if the conditions here were to change outside of leader Loop to take this from nil to non nil we would need leader Loop to be kicked 
leader Loop is the hot loop for a leader It is invoked after all the various leader setup is done 
verify Leader must be called from the main thread for safety Causes the followers to attempt an immediate heartbeat 
check Leader Lease is used to check if we can contact a quorum of nodes within the last leader lease interval If not we need to step down as we may have lost connectivity Returns the maximum duration without contact This must only be called from the main thread 
quorum Size is used to return the quorum size This must only be called on the main thread TODO revisit usage 
restore User Snapshot is used to manually consume an external snapshot such as if restoring from a backup We will use the current Raft configuration not the one from the snapshot so that we can restore into a new cluster We will also use the higher of the index of the snapshot or the current index and then add to that so we force a new state with a hole in the Raft log so that the snapshot will be sent to followers and used for any new joiners This can only be run on the leader and returns a future that can be used to block until complete 
append Configuration Entry changes the configuration and adds a new configuration entry to the log This must only be called from the main thread 
dispatch Log is called on the leader to push a log to disk mark it as inflight and begin replication of it 
process Logs is used to apply all the committed entries that haven t been applied up to the given index limit This can be called from both leaders and followers Followers call this from Append Entries for n entries at a time and always pass future nil Leaders call this once per inflight when entries are committed They pass the future from inflights 
process Log is invoked to process the application of a single committed log entry 
process RPC is called to handle an incoming RPC request This must only be called from the main thread 
process Heartbeat is a special handler used just for heartbeat requests so that they can be fast pathed if a transport supports it This must only be called from the main thread 
append Entries is invoked when we get an append entries RPC call This must only be called from the main thread 
process Configuration Log Entry takes a log entry and updates the latest configuration if the entry results in a new configuration This must only be called from the main thread or from New Raft before any threads have begun 
request Vote is invoked when we get an request vote RPC call 
install Snapshot is invoked when we get a Install Snapshot RPC call We must be in the follower state for this since it means we are too far behind a leader for log replay This must only be called from the main thread 
set Last Contact is used to set the last contact time to now 
elect Self is used to send a Request Vote RPC to all peers and vote for ourself This has the side affecting of incrementing the current term The response channel returned is used to wait for all the responses including a vote for ourself This must only be called from the main thread 
persist Vote is used to persist our vote for safety 
set Current Term is used to set the current term in a durable manner 
set State is used to update the current state Any state transition causes the known leader to be cleared This means that leader should be set only after updating the state 
new Commitment returns an commitment struct that notifies the provided channel when log entries have been committed A new commitment struct is created each time this server becomes leader for a particular term configuration is the servers in the cluster start Index is the first index created in this term see its description above 
Called when a new cluster membership configuration is created it will be used to determine commitment from now on configuration is the servers in the cluster 
Called by leader after commit Ch is notified 
Match is called once a server completes writing entries to disk either the leader has written the new entry or a follower has replied to an Append Entries RPC The given server s disk agrees with this server s log up through the given index 
Internal helper to calculate new commit Index from match Indexes Must be called with lock held 
returns an int from a crypto random source can be used to seed a source for a math rand 
random Timeout returns a value that is between the min Val and x min Val 
generate UUID is used to generate a random UUID 
Decode reverses the encode operation on a byte slice input 
Encode writes an encoded object to a new bytes buffer 
backoff is used to compute an exponential backoff duration Base time is scaled by the current round up to some maximum scale factor 
new Apply Source will create a new source any source created with the same seed will generate the same sequence of data 
reset this source back to its initial state it ll generate the same sequence of data it initially did 
runs apply in chunks of n to the cluster use the returned Applier to Stop it 
Default Config returns a Config with usable defaults 
Validate Config is used to validate a sane configuration 
run Snapshots is a long running goroutine used to manage taking new snapshots of the FSM It runs in parallel to the FSM and main goroutines so that snapshots do not block normal operation 
should Snapshot checks if we meet the conditions to take a new snapshot 
take Snapshot is used to take a new snapshot This must only be called from the snapshot thread never the main thread This returns the ID of the new snapshot along with an error 
compact Logs takes the last inclusive index of a snapshot and trims the logs that are no longer needed 
Webpack Check will compare the current default Buffalo webpack config js against the applications webpack config js If they are different you have the option to overwrite the existing webpack config js file with the new one 
Auto figures out how to render the model based information about the request and the name of the model Auto supports automatic rendering of HTML JSON and XML Any status code give to Context Render between will be respected by Auto Other status codes are not Rules for HTML template lookup GET users users index html GET users id users show html GET users new users new html GET users id edit users edit html POST users redirect to users id or render user new html PUT users edit redirect to users id or render user edit html DELETE users id redirect to users 
Auto figures out how to render the model based information about the request and the name of the model Auto supports automatic rendering of HTML JSON and XML Any status code give to Context Render between will be respected by Auto Other status codes are not Rules for HTML template lookup GET users users index html GET users id users show html GET users new users new html GET users id edit users edit html POST users redirect to users id or render user new html PUT users edit redirect to users id or render user edit html DELETE users id redirect to users 
Validate that options are usuable 
New generator for adding VCS to an application 
Set Addr sets the servers address if it hasn t already been set 
Start the server 
Unix Socket returns a new Listener on that address 
Get a registered Error Handler for this status code If no Error Handler has been registered a default one will be returned 
Panic Handler recovers from panics gracefully and calls the error handling code for a error 
Validate that options are usuable 
Wrap TLS Server converts a standard http Server to a buffalo Server but makes sure it is run with TLS 
Wrap Listener wraps an http Server and a net Listener 
partial Feeder returns template string for the name from Template Box It should be registered as helper named partial Feeder so plush can find it with the name 
Template renders the named files using the specified content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield 
Template renders the named files using the specified content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield 
New render Engine ready to go with your Options and some defaults we think you might like 
Set Addr sets the servers address if it hasn t already been set 
Start the server 
Write To implements io Writer To It dumps the whole message into w 
App is where all routes and middleware for buffalo should be defined This is the nerve center of your application Routing middleware groups etc are declared TOP DOWN This means if you add a middleware to app after declaring a group that group will NOT have that new middleware The same is true of resource declarations as well It also means that routes are checked in the order they are declared Serve Files is a CATCH ALL route so it should always be placed last in the route declarations as it will prevent routes declared after it to never be called 
translations will load locale files set up the translator actions T and will return a middleware to use to load the correct locale for each request for more information https gobuffalo io en docs localization 
force SSL will return a middleware that will redirect an incoming request if it is not HTTPS http example com https example com This middleware does not enable SSL for your application To do that we recommend using a proxy https gobuffalo io en docs proxy for more information https github com unrolled secure 
Send a message using SMTP configuration or returns an error if something goes wrong 
New SMTPSender builds a SMTP mail based in passed config 
Param returns a param either named or query string based on the key 
Set a value onto the Context Any value set onto the Context will be automatically available in templates 
Value that has previously stored on the context 
Render a status code and render Renderer to the associated Response The request parameters will be made available to the render Renderer params Any values set onto the Context will also automatically be made available to the render Renderer To render no content pass in a nil render Renderer 
Bind the interface to the request Body The type of binding is dependent on the Content Type for the request If the type is application json it will use json New Decoder If the type is application xml it will use xml New Decoder See the github com gobuffalo buffalo binding package for more details 
Log Field adds the key value pair onto the Logger to be printed out as part of the request logging This allows you to easily add things like metrics think DB times to your request 
Log Fields adds the key value pairs onto the Logger to be printed out as part of the request logging This allows you to easily add things like metrics think DB times to your request 
Redirect a request with the given status to the given URL 
Data contains all the values set through Get Set 
File returns an uploaded file by name or an error 
Marshal JSON implements json marshaling for the context 
New generator for creating a Buffalo application 
New generator for creating a Buffalo API application 
New returns a new instance of App and adds some sane and useful defaults 
Deprecrations Check will either log or fix deprecated items in the application 
List default implementation Returns a 
Render the provided Data to the provider Writer using the Renderer Func provide 
Func renderer allows for easily building one of renderers using just a Renderer Func and not having to build a whole implementation of the Render interface 
Func renderer allows for easily building one of renderers using just a Renderer Func and not having to build a whole implementation of the Render interface 
Validate that options are usuable 
build Actions is the top level action builder it determines whether to build a new actions foo go file or append to an existing one 
build New Actions builds a brand new actions foo go file and files it with actions 
append Actions appends only actions that don t exist in actions foo go if the action already exists it is not touched 
Save the current session 
Get Once gets a value from the current session and then deletes it 
Set a value onto the current session If a value with that name already exists it will be overridden with the new value 
Clear the current session 
Get a session using a request and response 
New generator to create a grift task 
String renderer that will run the string through the github com gobuffalo plush package and return text plain as the content type 
String renderer that will run the string through the github com gobuffalo plush package and return text plain as the content type 
New generator for creating webpack asset files 
New generator to generate refresh templates 
New generator for building a Buffalo application This powers the buffalo build command and can be used to programatically build compile Buffalo applications 
Execute adds all child commands to the root command sets flags appropriately This is called by main main It only needs to happen once to the root Cmd 
Validate that options are usuable 
Validate that options are usuable 
New Message creates a new message It uses UTF and quoted printable encoding by default 
Reset resets the message so it can be reused The message keeps its previous settings so it is in the same state that after a call to New Message 
Set Header sets a value to the given header field 
Set Headers sets the message headers 
Set Address Header sets an address to the given header field 
Format Address formats an address and a name as a valid RFC address 
Set Date Header sets a date to the given header field 
Format Date formats a date as a valid RFC date 
Set Body sets the body of the message It replaces any content previously set by Set Body Set Body Writer Add Alternative or Add Alternative Writer 
Set Body Writer sets the body of the message It can be useful with the text template or html template packages 
Add Alternative adds an alternative part to the message It is commonly used to send HTML emails that default to the plain text version for backward compatibility Add Alternative appends the new part to the end of the message So the plain text part should be added before the HTML part See http en wikipedia org wiki MIME Alternative 
Add Alternative Writer adds an alternative part to the message It can be useful with the text template or html template packages 
Set Part Encoding sets the encoding of the part added to the message By default parts use the same encoding than the message 
Set Header is a file setting to set the MIME header of the message part that contains the file content Mandatory headers are automatically added if they are not set when sending the email 
Set Copy Func is a file setting to replace the function that runs when the message is sent It should copy the content of the file to the io Writer The default copy function opens the file with the given filename and copy its content to the io Writer 
Attach Reader attaches a file using an io Reader 
Attach attaches the files to the email 
Embed Reader embeds the images to the email 
Embed embeds the images to the email 
Validate Templates returns a genny Run Fn that will walk the given box and run each of the files found through each of the template validators 
Plush Validator validates the file is a valid Plush file if the extension is md html or plush 
Go Template Validator validates the file is a valid Go text template file if the extension is tmpl 
Validate that options are usuable 
Validate that options are usuable 
Validate options are useful 
Load Plugins will add listeners for any plugins that support events 
Write Header sets the status code for a response 
Write the body of the response 
Flush the response 
Close Notify implements the http Close Notifier interface 
Run all compatible checks 
only Relevant Files processes only go files excluding folders like node modules and vendor 
Go Template Engine implements the Template Engine interface for using standard Go templates 
GET maps an HTTP GET request to the path and the specified handler 
Redirect from one URL to another URL Only works for GET requests 
Mount mounts a http Handler or Buffalo app and passes through all requests to it func muxer http Handler f func res http Response Writer req http Request fmt Fprintf res s s req Method req URL String mux mux New Router mux Handle Func foo f Methods GET mux Handle Func bar f Methods POST mux Handle Func baz baz f Methods DELETE return mux a Mount admin muxer curl X DELETE http localhost admin baz baz 
Serve Files maps an path to a directory on disk to serve static files Useful for Java Script images CSS etc a Serve Files assets http Dir path to assets 
Resource maps an implementation of the Resource interface to the appropriate RESTful mappings Resource returns the App associated with this group of mappings so you can set middleware etc on that group just as if you had used the a Group functionality a Resource users Users Resource 
ANY accepts a request across any HTTP method for the specified path and routes it to the specified Handler 
Group creates a new App that inherits from it s parent App This is useful for creating groups of end points that need to share common functionality like middleware g a Group api v g Use Authorize APIMiddleware g GET users APIUsers Handler g GET users user id APIUser Show Handler 
Route Helpers returns a map of Build Path Helper for each route available in the app 
build Route Name builds a route based on the path passed 
New mailer generator It will init the mailers directory if it doesn t already exist 
New Dialer returns a new SMTP Dialer The given parameters are used to connect to the SMTP server 
Dial dials and authenticates to an SMTP server The returned Send Closer should be closed when done using it 
Dial And Send opens a connection to the SMTP server sends the given emails and closes the connection 
Request Logger Func is the default implementation of the Request Logger By default it will log a uniq request id the HTTP Method of the request the path that was requested the duration time it took to process the request the size of the response and the human size and the status code of the response 
Set allows to set a list of values into a particular key 
Add adds a flash value for a flash key if the key already has values the list for that value grows 
Persist the flash inside the session 
new Flash creates a new Flash and loads the session data inside its data 
Get returns the value of the cookie with the given name Returns http Err No Cookie if there s no cookie with that name in the request 
Set a cookie on the response which will expire after the given duration 
Set With Expiration Time sets a cookie that will expire at a specific time Note that the time is determined by the client s browser so it might not expire at the expected time for example if the client has changed the time on their computer 
Set With Path sets a cookie path on the server in which the cookie will be available on If set to the cookie will be available within the entire domain If set to foo the cookie will only be available within the foo directory and all sub directories such as foo bar of domain 
Delete sets a header that tells the browser to remove the cookie with the given name 
New Message builds a new message 
New From Data builds a new message with raw template data given 
New builds a new message with the current buffalo Context 
Close Notify return true across the channel when the connection in the browser has been severed 
New Event Source returns a new Event Source instance while ensuring that the http Response Writer is able to handle Event Source messages It also makes sure to set the proper response heads 
New Simple With Context creates a basic implementation of the Worker interface that is backed using just the standard library and goroutines 
Register Handler with the worker 
Start the worker 
Stop the worker 
Perform a job as soon as possibly using a goroutine 
Perform At performs a job at a particular time using a goroutine 
Perform In performs a job after waiting for a specified amount using a goroutine 
Validate options 
String returns a JSON representation of the Route Info 
Alias path patterns to the this route This is not the same as a redirect 
Name allows users to set custom names for the routes 
Build Path Helper Builds a route Helperfunc for a particular Route Info 
Set Addr sets the servers address if it hasn t already been set 
Start the server 
New generator for adding travis or gitlab 
Download renders a file attachment automatically setting following headers Content Type Content Length Content Disposition Content Type is set using mime Type By Extension with the filename s extension Content Type will default to application octet stream if using a filename with an unknown extension 
Download renders a file attachment automatically setting following headers Content Type Content Length Content Disposition Content Type is set using mime Type By Extension with the filename s extension Content Type will default to application octet stream if using a filename with an unknown extension 
Java Script renders the named files using the application javascript content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield 
Java Script renders the named files using the application javascript content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield If no second file is provided and an Java Script Layout is specified in the options then that layout file will be used automatically 
New returns a new generator for build actions on a Buffalo app 
Register Custom Decoder allows to define custom type decoders 
Register maps a request Content Type application json to a Binder 
Exec will bind the interface to the request Body The type of binding is dependent on the Content Type for the request If the type is application json it will use json New Decoder If the type is application xml it will use xml New Decoder The default binder is https github com monoculum formam 
Method Override is the default implementation for the Options Method Override By default it will look for a form value name method and change the request method if that is present and the original request is of type POST This is added automatically when using New Buffalo unless an alternative is defined in the Options 
Clear wipes out the current middleware stack for the App Group any middleware previously defined will be removed leaving an empty middleware stack 
Use the specified Middleware for the App When defined on an App the specified middleware will be inherited by any Group calls that are made on that on the App 
Skip a specified piece of middleware the specified Handlers This is useful for things like wrapping your application in an authorization middleware but skipping it for things the home page the login page etc a Middleware Skip Authorization Home Handler Login Handler Registration Handler 
Replace a piece of middleware with another piece of middleware Great for testing 
Routes returns a list of all of the routes defined in this application 
Lookup search a specific Path Name in the Route List and return the Route Info 
Wrap Buffalo Handler wraps a buffalo Handler to standard http Handler 
Package JSONCheck will compare the current default Buffalo package json against the applications package json If they are different you have the option to overwrite the existing package json file with the new one 
match takes an import path and replacement map 
Validate that options are usuable 
Send calls f from to msg 
Send sends emails using the given Sender 
Last checks if the name is the last of the parts 
Validate options 
Serve the application at the specified address port and listen for OS interrupt and kill signals and will attempt to stop the application gracefully This will also start the Worker process unless Worker Off is enabled 
Stop the application and attempt to gracefully shutdown 
Dep Ensure runs dep ensure v or go get u depending on app tooling to make sure that any newly changed imports are added to dep or installed 
Plain renders the named files using the text html content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield 
Plain renders the named files using the text plain content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield 
String implements fmt String 
New resource generator 
Add Body the message by receiving a renderer and rendering data first message will be used as the main message Body rest of them will be passed as alternative bodies on the email message 
Add Bodies Allows to add multiple bodies to the message it returns errors that could happen in the rendering 
Add Attachment adds the attachment to the list of attachments the Message has 
Add Embedded adds the attachment to the list of attachments the Message has and uses inline instead of attachement property 
Set Header sets the heder field and value for the message 
New generator for creating a Buffalo Web application 
New generator for creating basic asset files 
New returns a generator that performs buffalo related rx checks 
Cleanup all of the generated files 
Validate that options are usuable 
HTML renders the named files using the text html content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield 
HTML renders the named files using the text html content type and the github com gobuffalo plush package for templating If more than file is provided the second file will be considered a layout file and the first file will be the content file which will be placed into the layout using yield If no second file is provided and an HTMLLayout is specified in the options then that layout file will be used automatically 
MDTemplate Engine runs the input through github flavored markdown before sending it to the Plush engine 
Update updates the configmap with the data from the identified files 
Filter Changes determines which of the changes are relevant for config updating returning mapping of config map to key to filename to update that key from 
Get Labels from Regexp matches 
get Labels From Generic Matches returns label matches with extra labels if those have been configured in the plugin config 
Start will begin polling the config file at the path If the first load fails Start will return the error and abort Future load failures will log the failure message but continue attempting to load 
Subscribe registers the channel for messages on config reload The caller can expect a copy of the previous and current config to be sent down the subscribed channel when a new configuration is loaded 
Config returns the latest config Do not modify the config 
Set sets the config Useful for testing 
Is Member returns true if user is in org 
List Issue Comments returns comments 
List Pull Request Comments returns review comments 
List Reviews returns reviews 
List Issue Events returns issue events 
Create Comment adds a comment to a PR 
Create Review adds a review to a PR 
Create Comment Reaction adds emoji to a comment 
Create Issue Reaction adds an emoji to an issue 
Delete Comment deletes a comment 
Delete Stale Comments deletes comments flagged by is Stale 
Get Pull Request returns details about the PR 
Get Pull Request Changes returns the file modifications in a PR 
Get Ref returns the hash of a ref 
Delete Ref returns an error indicating if deletion of the given ref was successful 
Get Single Commit returns a single commit 
Create Status adds a status context to a commit 
List Statuses returns individual status contexts on a commit 
Get Combined Status returns the overall status for a commit 
Get Repo Labels gets labels in a repo 
Get Issue Labels gets labels on an issue 
Add Label adds a label 
Remove Label removes a label 
Find Issues returns f Issues 
Assign Issue adds assignees 
Get File returns the bytes of the file 
List Teams return a list of fake teams that correspond to the fake team members returned by List Team Members 
List Team Members return a fake team with a single sig lead Git Hub teammember 
Is Collaborator returns true if the user is a collaborator of the repo 
List Collaborators lists the collaborators 
Clear Milestone removes the milestone 
Set Milestone sets the milestone 
List Milestones lists milestones 
List PRCommits lists commits for a given PR 
Get Repo Projects returns the list of projects under a repo 
Get Org Projects returns the list of projects under an org 
Get Project Columns returns the list of columns for a given project 
Create Project Card creates a project card under a given column 
Delete Project Card deletes the project card of a specific issue or PR 
Move Project Card moves a specific project card to a specified column in the same project 
Team Has Member checks if a user belongs to a team 
Add Flags parses options for database configuration 
Create Database Client creates and connects a new instance of an Influx DB It is created based on the fields set in the configuration 
Push a point to the database 
New Prow Job With Annotation initializes a Prow Job out of a Prow Job Spec with annotations 
New Prow Job initializes a Prow Job out of a Prow Job Spec 
New Presubmit converts a config Presubmit into a prowapi Prow Job The prowapi Refs are configured correctly per the pr base SHA The event GUID becomes a github Event GUID label 
Presubmit Spec initializes a Prow Job Spec for a given presubmit job 
Postsubmit Spec initializes a Prow Job Spec for a given postsubmit job 
Periodic Spec initializes a Prow Job Spec for a given periodic job 
Batch Spec initializes a Prow Job Spec for a given batch job and ref spec 
Partition Active separates the provided prowjobs into pending and triggered and returns them inside channels so that they can be consumed in parallel by different goroutines Complete prowjobs are filtered out Controller loops need to handle pending jobs first so they can conform to maximum concurrency requirements that different jobs may have 
Prow Job Fields extracts logrus fields from a prowjob useful for logging 
Job URL returns the expected URL for Prow Job Status TODO fejta consider moving default Job URLTemplate and Job URLPrefix out of plank 
Cluster To Ctx converts the prow job s cluster to a cluster context 
Add Command registers new help text for a bot command 
Get takes name of the prow Job and returns the corresponding prow Job object and an error if there is any 
List takes label and field selectors and returns the list of Prow Jobs that match those selectors 
Watch returns a watch Interface that watches the requested prow Jobs 
Create takes the representation of a prow Job and creates it Returns the server s representation of the prow Job and an error if there is any 
Update takes the representation of a prow Job and updates it Returns the server s representation of the prow Job and an error if there is any 
Update Status was generated because the type contains a Status member Add a genclient no Status comment above the type to avoid generating Update Status 
Delete takes name of the prow Job and deletes it Returns an error if one occurs 
Delete Collection deletes a collection of objects 
Patch applies the patch and returns the patched prow Job 
Merge Method returns the merge method to use for a repo The default of merge is returned when not overridden 
Merge Commit Template returns a struct with Go template string s or nil 
Query returns the corresponding github search string for the tide query 
For Repo indicates if the tide query applies to the specified repo 
Org Exceptions And Repos determines which orgs and repos a set of queries cover Output is returned as a mapping from included org repos excluded in the org and a set of included repos 
Query Map creates a Query Map from Tide Queries 
For Repo returns the tide queries that apply to a repo 
Validate returns an error if the query has any errors Examples include an org name that is empty or includes a repos that are not org repo a label that is in both the labels and missing labels section a branch that is in both included and excluded branch set 
Validate returns an error if any contexts are listed more than once in the config 
Get Tide Context Policy parses the prow config to find context merge options If none are set it will use the prow jobs configured and use the default github combined status Otherwise if set it will use the branch protection setting or the listed jobs 
Is Optional checks whether a context can be ignored Will return true if context is registered as optional required contexts are registered and the context provided is not required Will return false otherwise Every context is required 
Missing Required Contexts discard the optional contexts and only look of extra required contexts that are not provided 
Validate Webhook ensures that the provided request conforms to the format of a Git Hub webhook and the payload can be validated with the provided hmac secret It returns the event type the event guid the payload of the request whether the webhook is valid or not and finally the resultant HTTP status code 
New For Config Or Die creates a new Clientset for the given config and panics if there is an error in the config 
New creates a new Clientset for the given RESTClient 
matches returns whether the provided repo intersects with repos repo has always the org repo format but repos can include both orgs and repos 
Help Provider constructs the Plugin Help for this plugin that takes into account enabled repositories Help Provider defines the type for function that construct the Plugin Help for plugins 
Handle Event handles a Git Hub PR event to determine if the needs rebase label needs to be added or removed It depends on Git Hub mergeability check to decide the need for a rebase 
Handle All checks all orgs and repos that enabled this plugin for open PRs to determine if the needs rebase label needs to be added or removed It depends on Git Hub s mergeability check to decide the need for a rebase 
take Action adds or removes the needs rebase label based on the current state of the PR has Label and mergeable It also handles adding and removing Git Hub comments notifying the PR author that a rebase is needed 
New Dry Run Prow Job Client creates a new client that uses deck as a read only proxy for Prow Job data 
Create does nothing on a dry run client 
Update does nothing on a dry run client 
Update Status does nothing on a dry run client 
Delete does nothing on a dry run client 
Delete Collection does nothing on a dry run client 
Get does nothing on a dry run client 
List reaches out to deck to retrieve the Prow Jobs on the cluster via proxy 
Retry on transport failures Does not retry on s 
Watch does nothing on a dry run client 
Patch does nothing on a dry run client 
has Synced returns true when every prowjob and pipeline informer has synced 
Run starts threads workers returning after receiving a stop signal 
run Worker dequeues to reconcile until the queue has closed 
to Key returns context namespace name 
from Key converts to Key back into its parts 
enqueue Key schedules an item for reconciliation 
reconcile ensures a tekton prowjob has a corresponding pipeline updating the prowjob s status as the pipeline progresses 
final State returns true if the prowjob has already finished 
description computes the Prow Job Status description for this condition or falling back to a default if none is provided 
prow Job Status returns the desired state and description based on the pipeline status 
pipeline Meta builds the pipeline metadata from prow job definition 
source URL returns the source URL from prow jobs repository reference 
make Pipeline Git Resource creates a pipeline git resource from prow job 
make Pipeline creates a Pipeline Run from a prow job using the Pipeline Run Spec defined in the prow job 
helper to update disk metrics copied from greenhouse 
Receive Issue calls plugin Receive Issue for all plugins 
Receive Issue Event calls plugin Receive Issue Event for all plugins 
Receive Comment calls plugin Receive Comment for all plugins 
matching Configs filters irrelevant Require Mtching Label configs from the list of all configs branch should be empty for Issues and non empty for PRs label should be omitted in the case of open and reopen actions 
Suggest Code Change returns code suggestions for a given lint Problem Returns empty string if no suggestion can be given 
Serve External Plugin Help returns a Handler Func that serves plugin help information that is provided by the specified External Plugin Help Provider 
protect protects branches specified in the presubmit and branch protection config sections 
Update Org updates all repos in the org with the specified defaults 
Update Repo updates all branches in the repo with the specified defaults 
Update Branch updates the branch with the specified configuration 
Validate ensures that the set of options are self consistent and valid 
Load Config loads options from serialized config 
Add Flags binds flags to options 
load Cluster Config loads connection configuration for the cluster we re deploying to We prefer to use in cluster configuration if possible but will fall back to using default rules otherwise 
Run uploads artifacts with the specified options forever Sends a stop message to the artifact uploader when it is interrupted 
Start creates goroutines to monitor the files that contain the secret value 
reload Secret will begin polling the secret file at the path If the first load fails Start with return the error and abort Future load failures will log the failure message but continue attempting to load 
Get Secret returns the value of a secret stored in a map 
set Secret sets a value in a map of secrets 
Get Token Generator returns a function that gets the value of a given secret 
New creates a new History struct with the specificed record Log size limit 
Record appends an entry to the recordlog specified by the pool Key 
Serve HTTP serves a JSON mapping from pool key sorted records for the pool 
Flush writes the action history to persistent storage if configured to do so 
All Records generates a map from pool key sorted records for the pool 
Make Command returns a download command 
Add Flags adds comments comments to the command help 
Check Flags looks for comments matching regexes 
Receive Comment adds matching comments to Influx DB 
New Controller constructs a new instance of the crier controller 
Run is the main path of execution for the controller loop 
run Worker executes the loop to process new items added to the queue 
process Next Item retrieves each queued item and takes the necessary handler action based off of if the item was created or deleted 
New Aggregate converts a slice of errors into an Aggregate interface which is itself an implementation of the error interface If the slice is empty this returns nil It will check if any of the element of input error list is nil to avoid nil pointer panic when call Error 
Error is part of the error interface 
Strings flattens the aggregate and any sub aggregates into a slice of strings 
New creates a Local Git and a git Client pointing at it 
Make Fake Repo creates the given repo and makes an initial commit 
Add Commit adds the files to a new commit in the repo 
Checkout New Branch does git checkout b 
Checkout does git checkout 
Rev Parse does git rev parse 
Clean All cleans all of the resources for all of the regions visible to the provided AWS session 
options For Repo gets the plugins Lgtm struct that is applicable to the indicated repo 
get Changed Files returns all the changed files for the provided pull request 
load Reviewers returns all reviewers and approvers from all OWNERS files that cover the provided filenames 
New Controller returns a new gerrit controller client 
Save Last Sync saves last sync time in Unix to a volume 
Sync looks for newly made gerrit changes and creates prowjobs according to specs 
list Changed Files lists in lexicographic order the files changed as part of a Gerrit patchset 
Process Change creates new presubmit prowjobs base off the gerrit changes 
Add Flags adds event to the command help 
Check Flags is delegated to Event Matcher 
Receive Issue Event adds issue events to Influx DB 
Upload uploads all of the data in the upload Targets map to GCS in parallel The map is keyed on GCS path under the bucket 
File Upload With Metadata returns an Upload Func which copies all data from the file on disk into GCS object and also sets the provided metadata fields on the object 
Data Upload With Metadata returns an Upload Func which copies all data from src reader into GCS and also sets the provided metadata fields onto the object 
Has Label checks if label is in the label set issue Labels 
Image Too Big checks if image is bigger than github limits 
Level From Permissions adapts a repo permissions struct to the appropriate permission level used elsewhere 
Permissions From Level adapts a repo permission level to the appropriate permissions struct used elsewhere 
new Prow Jobs returns a Prow Jobs 
List takes label and field selectors and returns the list of Prow Jobs that match those selectors 
Create takes the representation of a prow Job and creates it Returns the server s representation of the prow Job and an error if there is any 
Update takes the representation of a prow Job and updates it Returns the server s representation of the prow Job and an error if there is any 
Get Applicable returns the subset of blockers applicable to the specified branch 
Find All finds issues with label in the specified orgs repos that should block tide 
serve starts a http server and serves Jenkins logs and prometheus metrics Meant to be called inside a goroutine 
New Count Plugin counts events and number of issues in given state and for how long 
Receive Issue is a wrapper on plugin Receive Issue 
Receive Issue Event is a wrapper on plugin Receive Issue Event 
Receive Comment creates a fake commented event 
helper to update disk metrics 
New Ranch creates a new Ranch object In config path to resource file storage path to where to save restore the state data Out A Ranch object loaded from config storage or error 
Acquire checks out a type of resource in certain state without an owner and move the checked out resource to the end of the resource list In rtype name of the target resource state current state of the requested resource dest destination state of the requested resource owner requester of the resource Out A valid Resource object on success or Resource Not Found error if target type resource does not exist in target state 
Acquire By State checks out resources of a given type without an owner that matches a list of resources names In state current state of the requested resource dest destination state of the requested resource owner requester of the resource names names of resource to acquire Out A valid list of Resource object on success or Resource Not Found error if target type resource does not exist in target state 
Release unsets owner for target resource and move it to a new state In name name of the target resource dest destination state of the resource owner owner of the resource Out nil on success or Owner Not Match error if owner does not match current owner of the resource or Resource Not Found error if target named resource does not exist 
Update updates the timestamp of a target resource In name name of the target resource state current state of the resource owner current owner of the resource info information on how to use the resource Out nil on success or Owner Not Match error if owner does not match current owner of the resource or Resource Not Found error if target named resource does not exist or State Not Match error if state does not match current state of the resource 
Reset unstucks a type of stale resource to a new state In rtype type of the resource state current state of the resource expire duration before resource s last update dest destination state of expired resources Out map of resource name resource owner 
Log Status outputs current status of all resources 
Sync Config updates resource list from a file 
Metric returns a metric object with metrics filled in 
Format URL will return the GH markdown to show the image for a specific dog URL 
Trusted User returns true if user is trusted in repo Trusted users are either repo collaborators org members or trusted org members Whether repo collaborators and or a second org is trusted is configured by trigger 
run And Skip Jobs executes the config Presubmits that are requested and posts skipped statuses for the reporting jobs that are skipped 
validate Context Overlap ensures that there will be no overlap in contexts between a set of jobs running and a set to skip 
Run Requested executes the config Presubmits that are requested 
skip Requested posts skipped statuses for the config Presubmits that are requested 
Match is labeled with label 
Match is unlabeled 
New Event Matcher returns the correct Event Matcher based on description Incoming event should have the following form event Name label Name If event Name is not label then the second part can be omitted 
Add Flags injects Git Hub options into the given Flag Set 
Add Flags Without Default Git Hub Token Path injects Git Hub options into the given Flagset without setting a default for for the github Token Path allowing to use an anonymous Git Hub client 
Validate validates Git Hub options 
Git Hub Client With Log Fields returns a Git Hub client with extra logging fields 
Git Hub Client returns a Git Hub client 
Git Client returns a Git client 
to Map returns maps the file name to its coverage for faster retrieval membership check 
find Changes compares the new List of coverage against the base list and returns the result 
Create Database for the My SQLConfig 
Add Flags parses options for database configuration 
New Reporter returns a reporter client 
Should Report returns if this prowjob should be reported by the github reporter 
Report will report via reportlib 
Parse Refs parses a human provided string into the repo that should be cloned and the refs that need to be checked out once it is The format is org repo base ref base sha pull id pull sha pull ref For the base ref and pull IDs a SHA may optionally be provided or may be omitted for the latest available SHA Examples kubernetes test infra master kubernetes test infra master abcde kubernetes test infra master abcde kubernetes test infra master abcde fghij kubernetes test infra master fghij kubernetes test infra master abcde fghij gerrit test infra master abcde fghij refs changes 
date Token generates a Git Hub search query token for the specified date range See https help github com articles understanding the search syntax query for dates 
Mark marks a particular resource as currently present and advises on whether it should be deleted If Mark r returns true the TTL has expired for r and it should be deleted 
Mark Complete figures out which ARNs were in previous passes but not this one and eliminates them It should only be run after all resources have been marked 
New Job Agent is a Job Agent constructor 
Start will start the job and periodically update it 
Jobs returns a thread safe snapshot of the current job state 
Prow Jobs returns a thread safe snapshot of the current prow jobs 
Get Prow Job finds the corresponding Prowjob resource from the provided job name and build ID 
Get Job Log returns the job logs works for both kubernetes and jenkins agent types 
union Strings merges the parent and child items together 
Apply returns a policy that merges the child into the parent 
Get Org returns the org config after merging in any global policies 
Get Repo returns the repo config after merging in any org policies 
Get Branch returns the branch config after merging in any repo policies 
Get Branch Protection returns the policy for a given branch Handles merging any policies defined at repo org global levels into the branch policy 
Get Policy returns the protection policy for the branch after merging in presubmits 
Branch Requirements partitions status contexts for a given org repo branch into three buckets contexts that are always required to be present contexts that are required if present contexts that are always optional 
Update Issue Events fetches all events until we find the most recent we have in db and saves everything in database 
enqueue Key schedules an item for reconciliation 
reconcile ensures a knative build prowjob has a corresponding build updating the prowjob s status as the build progresses 
prow Job Status returns the desired state and description based on the build status 
build Env constructs the environment map for the job 
default Arguments will append each arg to the template except where the argument name is already defined 
default Env adds the map of environment variables to the container except keys already defined 
inject Environment will add raw Env to the build steps and or template arguments 
inject Source adds the custom source container to call clonerefs correctly Returns true if it added this container Does nothing if the build spec predefines Source 
injected Steps returns initial containers a final container and an additional volume 
determine Timeout decides the timeout value used for build 
make Build creates a build from the prowjob using the prowjob s buildspec 
New Issue creates a new orm Issue from a github Issue 
New Issue Event creates a new orm Issue from a github Issue 
new Labels creates a new Label for each label in the issue 
new Assignees creates a new Label for each label in the issue 
New Issue Comment creates a Comment from a github Issue Comment 
message Filter builds a filter for jobs based on the message Body matching the trigger regex of the jobs 
Is Success means the job passed 
Is Failure means the job completed with problems 
Is Aborted means something stopped the job before it could finish 
Prow Job ID extracts the Prow Job identifier for the Jenkins build in order to correlate the build with a Prow Job If the build has an empty PROW JOB ID it didn t start by prow 
Build ID extracts the build identifier used for placing and discovering build artifacts This identifier can either originate from tot or the snowflake library depending on how the Jenkins operator is configured to run We return an empty string if we are dealing with a build that does not have the Prow Job ID set explicitly as in that case the Jenkins build has not started by prow 
New Client instantiates a client with provided values url the jenkins master to connect to dry Run mutating calls such as starting aborting a build will be skipped tls Config configures client transport if set may be nil auth Config configures the client to connect to Jenkins via basic auth bearer token and optionally enables csrf protection logger creates a standard logger if nil metrics gathers prometheus metrics for the Jenkins client if set 
Crumb Request requests a CSRF protection token from Jenkins to use it in subsequent requests Required for Jenkins masters that prevent cross site request forgery exploits 
measure records metrics about the provided method path and code start needs to be recorded before doing the request 
Get Skip Metrics fetches the data found in the provided path It returns the content of the response or any errors that occurred during the request or http errors Metrics will not be gathered for this request 
Get fetches the data found in the provided path It returns the content of the response or any errors that occurred during the request or http errors 
request executes a request with the provided method and path It retries on transport failures and s measure is provided to enable or disable gathering metrics for specific requests to avoid high cardinality metrics 
do Request executes a request with the provided method and path exactly once It sets up authentication if the jenkins client is configured accordingly It s up to callers of this function to build retries and error handling 
get Job Name generates the correct job name for this job type 
get Build Path builds a path to trigger a regular build for this job 
Get Job Info retrieves Jenkins job information 
Job Parameterized tells us if the Jenkins job for this Prow Job is parameterized 
Ensure Buildable Job attempts to detect a job that hasn t yet ran and populated its parameters If detected it tries to run a build until the job parameters are processed then it aborts the build 
Launch Build launches a regular or parameterized Jenkins build depending on whether or not we have params to POST 
Build triggers a Jenkins build for the provided Prow Job The name of the Prow Job is going to be used as the Prow Job ID parameter that will help us track the build before it s scheduled by Jenkins 
Build From Spec triggers a Jenkins build for the provided Prow Job Spec prow Job ID helps us track the build before it s scheduled by Jenkins 
List Builds returns a list of all Jenkins builds for the provided jobs both scheduled and enqueued 
Get Enqueued Builds lists all enqueued builds for the provided jobs 
Get Builds lists all scheduled builds for the provided job In newer Jenkins versions this also includes enqueued builds tested in 
Abort aborts the provided Jenkins build for job 
Presubmit To Job Spec generates a downwardapi Job Spec out of a Presubmit Useful for figuring out GCS paths when parsing jobs out of a prow config 
Postsubmit To Job Spec generates a downwardapi Job Spec out of a Postsubmit Useful for figuring out GCS paths when parsing jobs out of a prow config 
Periodic To Job Spec generates a downwardapi Job Spec out of a Periodic Useful for figuring out GCS paths when parsing jobs out of a prow config 
Get Build ID calls out to tot in order to vend build identifier for the job 
list Gcs Objects get the slice of gcs objects under a given path 
Find Base Profile finds the coverage profile file from the latest healthy build stored in given gcs directory 
sort Builds converts all build from str to int and sorts all builds in descending order and returns the sorted slice 
Get All retrieves all regions from the AWS API 
New Event Client creates an Event Client struct This should be used once per webhook event 
Prune Comments fetches issue comments if they have not yet been fetched for this webhook event and then deletes any bot comments indicated by the func should Prune 
Make a small SVG badge that looks like subject status with the status text in the given color Provides a local version of the shields io service 
Format Response nicely formats a response to a generic reason 
Format Simple Response formats a response that does not warrant additional explanation in the details section 
Format ICResponse nicely formats a response to an issue comment 
Format Response Raw nicely formats a response for one does not have an issue comment 
Validate ensures that the set of options are self consistent and valid 
Add Flags adds flags to the Flag Set that populate the GCS upload options struct given 
Encode will encode the set of options in the format that is expected for the configuration environment variable 
Register Issue Handler registers a plugin s github Issue Event handler 
Register Issue Comment Handler registers a plugin s github Issue Comment Event handler 
Register Pull Request Handler registers a plugin s github Pull Request Event handler 
Register Status Event Handler registers a plugin s github Status Event handler 
Register Push Event Handler registers a plugin s github Push Event handler 
Register Review Event Handler registers a plugin s github Review Event handler 
Register Review Comment Event Handler registers a plugin s github Review Comment Event handler 
Register Generic Comment Handler registers a plugin s github Generic Comment Event handler 
New Agent bootstraps a new config Agent struct from the passed dependencies 
Initialize Comment Pruner attaches a commentpruner Event Client to the agent to handle pruning comments 
Comment Pruner will return the commentpruner Event Client attached to the agent or an error if one is not attached 
Load attempts to load config from the path It returns an error if either the file can t be read or the configuration is invalid 
Config returns the agent current Configuration 
Set attempts to set the plugins that are enabled on repos Plugins are listed as a map from repositories to the list of plugins that are enabled on them Specifying simply an org name will also work and will enable the plugin on all repos in the org 
Start starts polling path for plugin config If the first attempt fails then start returns the error Future errors will halt updates but not stop 
Generic Comment Handlers returns a map of plugin names to handlers for the repo 
Issue Handlers returns a map of plugin names to handlers for the repo 
Issue Comment Handlers returns a map of plugin names to handlers for the repo 
Pull Request Handlers returns a map of plugin names to handlers for the repo 
Review Event Handlers returns a map of plugin names to handlers for the repo 
Review Comment Event Handlers returns a map of plugin names to handlers for the repo 
Status Event Handlers returns a map of plugin names to handlers for the repo 
Push Event Handlers returns a map of plugin names to handlers for the repo 
get Plugins returns a list of plugins that are enabled on a given org repository 
Events For Plugin returns the registered events for the passed plugin 
Converts k s io hello world foo into hello world string k s io foo 
insert Link attempts to set metadata links resultstore url to view URL returns true if started metadata was updated 
Parse Config reads data stored in given config path In config Path path to the config file Out A list of Resource Config object on success or nil on error 
Validate Config validates config with existing resources In configs a list of resources configs resources a list of resources Out nil on success error on failure 
New Mason creates and initialized a new Mason object In rtypes A list of resource types to act on cleaner Count Number of cleaning threads client boskos client wait Period time to wait before a new boskos operation acquire mostly sync Period time to wait before syncing resource information to boskos Out A Pointer to a Mason Object 
Register Config Converter is used to register a new Masonable interface In name identifier for Masonable implementation fn function that will parse the configuration string and return a Masonable interface Out nil on success error otherwise 
Update Configs updates configs from storage path In storage Path the path to read the config file from Out nil on success error otherwise 
Start Mason 
Stop Mason 
Help Provider construct the pluginhelp Plugin Help for this plugin 
ensure Fork Exists ensures a fork of org repo exists for the bot 
get Patch gets the patch for the provided PR and creates a local copy of it It returns its location in the filesystem and any encountered error 
release Note Note From Parent PR gets the release note from the parent PR and formats it as per the PR template so that it can be copied to the cherry pick PR 
Validate Payload ensures that the request payload signature matches the key 
Payload Signature returns the signature that matches the payload 
find Team returns teams n for the first n in name previous Names that is in teams 
validate Team Names returns an error if any current previous names are used multiple times in the config 
configure Teams returns the ids for all expected team names creating deleting teams as necessary 
update String will return true and set have to want iff they are set and different 
update Bool will return true and set have to want iff they are set and different 
configure Org Meta will update github to have the non nil wanted metadata values 
configure Team patches the team name description privacy when values differ 
configure Team Repos updates the list of repos that the team has permissions for when necessary 
configure Team Members will add update people to the appropriate role on the team and remove anyone else 
Should Report tells if a prowjob should be reported by this reporter 
Report takes a prowjob and generate a pubsub Report Message and publish to specific Pub Sub topic based on Pub Sub related labels if they exist in this prowjob 
Run will upload files to GCS as prescribed by the options Any extra files can be passed as a parameter and will have the prefix prepended to their destination in GCS so the caller can operate relative to the base of the GCS dir 
Paths For Job determines the following for a job path in GCS under the bucket where job artifacts will be uploaded for the job this specific run of the job if any subdir is present The builder for the job is also returned for use in other path resolution 
New Default Fields Formatter returns a Default Fields Formatter if wrapped Formatter is nil logrus JSONFormatter will be used instead 
Format implements logrus Formatter s Format We allocate a new Fields map in order to not modify the caller s Entry as that is not a thread safe operation 
Find Labels returns the list of labels matching the regex 
Add Flags binds flags to options 
New Agent returns a new Git Hub OAuth Agent 
Handle Login handles Git Hub login request from front end It starts a new git oauth session and redirect user to Git Hub OAuth end point for authentication 
Handle Logout handles Git Hub logout request from front end It invalidates cookie sessions and redirect back to the front page 
Handle Redirect handles the redirection from Git Hub It exchanges the code from redirect URL for user access token The access token is then saved to the cookie and the page is redirected to the final destination in the config which should be the front end 
Handles server errors 
Deep Copy Object implements the runtime Object interface 
From Item implements the Object interface 
Get Items implements the Collection interface 
Set Items implements the Collection interface 
Deep Copy Object implements the runtime Object interface 
Serve HTTP validates an incoming webhook and puts it into the event channel 
Unmarshal Text validates the text is a valid string 
Is Assignee checks if a user is assigned to the issue 
Is Author checks if a user is the author of the issue 
Has Label checks if an issue has a given label 
Branch returns the name of the branch to which the user pushed 
prowjob State To Git Hub Status maps prowjob status to github states Git Hub states can be one of error failure pending or success https developer github com v repos statuses create a status 
truncate converts really long messages into really messages 
report Status should be called on any prowjob status changes 
TODO krzyzacy Move this logic into github reporter once we unify all reporting logic to crier 
Report is creating updating removing reports in Git Hub based on the state of the provided Prow Job 
parse Issue Comments returns a list of comments to delete a list of table entries and the ID of the comment to update If there are no table entries then don t make a new comment Otherwise if the comment to update is create a new comment 
create Comment take a Prow Job and a list of entries generated with create Entry and returns a nicely formatted comment It may fail if template execution fails 
default Looking DHCPOptions This part is a little annoying If you re running in a region with where there is no default looking DHCP option set when you create any VPC AWS will create a default looking DHCP option set for you If you then re associate or delete the VPC the option set will hang around However if you have a default looking DHCP option set even with no default VPC and create a VPC AWS will associate the VPC with the DHCP option set of the default VPC There s no signal as to whether the option set returned is the default or was created along with the VPC Because of this we just skip these during cleanup there will only ever be one default set per region 
generic Comment Action normalizes the action string to a Generic Comment Event Action or returns if the action is unrelated to the comment text For example a PR label action 
Config returns the lens s configuration 
Header renders the content of head from template html 
Callback does nothing 
Body renders the body for JUnit tests 
Format Record describes the record in a human readable manner for inclusion into build logs 
Namespace returns a copy of the client pointing at the specified namespace 
Retry on transport failures Does not retry on s 
Retry on transport failures Does not retry on s 
New Fake Client creates a client that doesn t do anything If you provide a deck URL then the client will hit that for the supported calls 
New Client In Cluster creates a Client that works from within a pod 
New Client From File reads a Cluster object at cluster Path and returns an authenticated client using the keys within 
Unmarshal Cluster Map reads a map string Cluster in yaml bytes 
Client Map From File reads the file at clusters Path and attempts to load a map of cluster aliases to authenticated clients to the respective clusters The file at clusters Path is expected to be a yaml map from strings to Cluster structs OR it may simply be a single Cluster struct which will be assigned the alias Default Cluster Alias If the file is an alias map it must include the alias Default Cluster Alias 
New Client returns an authenticated Client using the keys in the Cluster 
Get Pod is analogous to kubectl get pods NAME namespace client namespace 
List Pods is analogous to kubectl get pods selector SELECTOR namespace client namespace 
Create Prow Job creates a prowjob in the client s specified namespace Analogous to kubectl create prowjob namespace client namespace 
Get Prow Job returns the prowjob at name in the client s specified namespace Analogous to kubectl get prowjob NAME namespace client namespace 
List Prow Jobs lists prowjobs using the specified label Selector in the client s specified namespace Analogous to kubectl get prowjobs selector SELECTOR namespace client namespace 
Delete Prow Job deletes the prowjob at name in the client s specified namespace Analogous to kubectl delete prowjob NAME namespace client namespace 
Replace Prow Job will replace name with job in the client s specified namespace Analogous to kubectl replace prowjobs NAME namespace client namespace 
Create Pod creates a pod in the client s specified namespace Analogous to kubectl create pod namespace client namespace 
Get Log returns the log of the default container in the specified pod in the client s specified namespace Analogous to kubectl logs pod namespace client namespace 
Get Log Tail returns the last n bytes of the log of the specified container in the specified pod in the client s specified namespace Analogous to kubectl logs pod tail limit bytes n c container namespace client namespace 
Get Container Log returns the log of a container in the specified pod in the client s specified namespace Analogous to kubectl logs pod c container namespace client namespace 
Create Config Map creates a configmap in the client s specified namespace Analogous to kubectl create configmap namespace client namespace 
Get Config Map gets the configmap identified in the client s specified namespace Analogous to kubectl get configmap namespace client namespace 
Replace Config Map puts the configmap into name Analogous to kubectl replace configmap If config Namespace is empty the client s specified namespace is used Returns the content returned by the apiserver 
Get Disk Usage wraps syscall Statfs for usage in GCing the disk 
Get ATime the atime for a file logging errors instead of failing and returning default Time instead 
Register Lens registers new viewers 
Get Lens returns a Lens by name if it exists otherwise it returns an error 
Last NLines reads the last n lines from an artifact 
Last NLines Chunked reads the last n lines from an artifact by reading chunks of size chunk Size from the end of the artifact Best performance is achieved by argmin chunk Size INTMAX f chunk Size chunk Size n avg Line Length 
New Client creates a slack client with an API token 
Write Message adds text to channel 
Mark And Sweep looks at the provided set and removes resources older than its TTL that have been previously tagged 
List All populates a set will all available NATGateway resources 
RESTClient returns a RESTClient that is used to communicate with API server by this client implementation 
New Client creates a Boskos client for the specified URL and resource owner Clients created with this function default to retrying failed connection attempts three times with a ten second pause between each attempt 
public method Acquire asks boskos for a resource of certain type in certain state and set the resource to dest state Returns the resource on success 
Acquire Wait blocks until Acquire returns the specified resource or the provided context is cancelled or its deadline exceeded 
Acquire By State asks boskos for a resources of certain type and set the resource to dest state Returns a list of resources on success 
Acquire By State Wait blocks until Acquire By State returns the specified resource s or the provided context is cancelled or its deadline exceeded 
Release All returns all resources hold by the client back to boskos and set them to dest state 
Release One returns one of owned resources back to boskos and set it to dest state 
Update All signals update for all resources hold by the client 
Sync All signals update for all resources hold by the client 
Update One signals update for one of the resources hold by the client 
Reset will scan all boskos resources of type in state last updated before expire and set them to dest state Returns a map of resource Name owner for further actions 
Metric will query current metric for target resource type Return a common Metric object on success 
Has Resource tells if current client holds any resources 
private methods 
Dial Context connects to the address on the named network using the provided context 
is Dial Error Retriable determines whether or not a dialer should retry a failed connection attempt by examining the connection error to see if it is one of the following error types Timeout Temporary ECONNREFUSED ECONNRESET 
New Dashboard Agent creates a new user dashboard agent 
Handle Pr Status returns a http handler function that handles request to pr status endpoint The handler takes user access token stored in the cookie to query to Git Hub on behalf of the user and serve the data in return The Query handler is passed to the method so as it can be mocked in the unit test 
Query Pull Requests is a query function that returns a list of open pull requests owned by the user whose access token is consumed by the github client 
Get Head Contexts returns the status checks contexts of the head commit of the PR 
Construct Search Query returns the Git Hub search query string for PRs that are open and authored by the user passed The search is scoped to repositories that are configured with either Prow or Tide 
Load Cluster Configs loads rest Configs for creation of clients by using either a normal kube config file a custom Cluster file or both The configs are returned in a mapping of context config The default context is included in this mapping and specified as a return vaule Errors are returned if kube config is specified and invalid or if no valid contexts are found 
Parse Link headers returning a map from Rel to URL Only understands the URI and rel parameter Very limited See https tools ietf org html rfc section 
New Bundled States is the constructor for Bundled States 
Receive Event is called when something happens on an issue The state for that issue is updated 
ages return the age of each active states 
Total counts number of active state and total age in minutes to compute average 
Percentile returns given percentile for age of all active states at time t 
New Metrics creates a new set of metrics for the Jenkins operator 
New Group reads the gitattributes file in the root of the repository only 
Use load to read a gitattributes file and populate g with the commands Each line in gitattributes file is of form pattern attr attr That is a pattern followed by an attributes list separated by whitespaces 
Is Linguist Generated determines whether a file given here by its full path is included in the gitattributes linguist generated group These files are excluded from language stats and suppressed in diffs https github com github linguist generated code Unmarked paths linguist generated false are not supported 
handle is the workhorse notifying issue owner to add a sig label if there is none The algorithm return if this is not an opened labelled or unlabelled event or if the issue is closed find if the issue has a sig label find if the issue has a needs sig label if the issue has both the sig and needs sig labels remove the needs sig label and delete the comment if the issue has none of the labels add the needs sig label and comment if the issue has only the sig label do nothing if the issue has only the needs sig label do nothing 
should Prune finds comments left by this plugin 
New Disk Cache creates a Git Hub cache Round Tripper that is backed by a disk cache 
New Mem Cache creates a Git Hub cache Round Tripper that is backed by a memory cache 
New From Cache creates a Git Hub cache Round Tripper that is backed by the specified httpcache Cache implementation 
Prow V retrieves the Prow V Client 
Prow retrieves the Prow V Client 
New Owners consturcts a new Owners instance filenames is the slice of files changed 
Get Approvers returns a map from owners Files people that are approvers in them 
Get Leaf Approvers returns a map from owners Files people that are approvers in them only the leaf 
Get All Potential Approvers returns the people from relevant owners files needed to get the PR approved 
Get Reverse Map returns a map from people OWNERS files for which they are an approver 
temporary Unapproved Files returns the list of files that wouldn t be approved by the given set of approvers 
Keep Covering Approvers finds who we should keep as suggested approvers given a pre selection known Approvers must be a subset of potential Approvers 
Get Suggested Approvers solves the exact cover problem finding an approver capable of approving every OWNERS file in the PR 
Get Owners Set returns a set containing all the Owners files necessary to get the PR approved 
Get Shuffled Approvers shuffles the potential approvers so that we don t always suggest the same people 
remove Subdirs takes a set of directories as an input and removes all subdirectories E g a a b c d e d e f a d e Subdirs will not be removed if they are configured to have no parent OWNERS files or if any OWNERS file in the relative path between the subdir and the higher level dir is configured to have no parent OWNERS files 
String creates a link for the approval Use Login if you just want the name 
Intersect Sets Case runs the intersection between to sets String in a case insensitive way It returns the name with the case of one 
New Approvers create a new Approvers with no approval 
should Not Override Approval decides whether or not we should keep the original approval If someone approves a PR multiple times we only want to keep the latest approval unless a previous approval was no issue and the most recent isn t 
Add LGTMer adds a new LGTM Approver 
Remove Approver removes an approver from the list 
Add Assignees adds assignees to the list 
Get Current Approvers Set returns the set of approvers login only normalized to lower case 
Get Current Approvers Set Cased returns the set of approvers logins with the original cases 
Get No Issue Approvers Set returns the set of no issue approvers login only 
Get Files Approvers returns a map from files list of current approvers 
No Issue Approvers returns the list of people who have no issue approved the pull request They are included in the list iff they can approve one of the files 
Unapproved Files returns owners files that still need approval 
Get Files returns owners files that still need approval 
Get CCs gets the list of suggested approvers for a pull request It now considers current assignees as potential approvers Here is how it works We find suggested approvers from all potential approvers but remove those that are not useful considering current approvers and assignees This only uses leaf approvers to find the closest approvers to the changes We find a subset of suggested approvers from current approvers suggested approvers and assignees but we remove those that are not useful considering suggested approvers and current approvers This uses the full approvers list and will result in root approvers to be suggested when they are assigned We return the union of the two sets suggested and suggested assignees The goal of this second step is to only keep the assignees that are the most useful 
Requirements Met returns a bool indicating whether the PR has met all approval requirements all OWNERS files associated with the PR have been approved AND EITHER the munger config is such that an issue is not required to be associated with the PR that there is an associated issue with the PR an OWNER has indicated that the PR is trivial enough that an issue need not be associated with the PR 
Is Approved returns a bool indicating whether the PR is fully approved If a human manually added the approved label this returns true ignoring normal approval rules 
List Approvals returns the list of approvals 
List No Issue Approvals returns the list of no issue approvals 
Generate Template takes a template name and data and generates the corresponding string 
Get Message returns the comment body that we want the approve plugin to display on PRs The comment shows a list of approvers files and links needed to get the PR approved a list of approvers files with strikethroughs that already have an approver s approval a suggested list of people from each OWNERS files that can fully approve the PR how an approver can indicate their approval how an approver can cancel their approval 
get Gubernator Metadata returns a JSON string with machine readable information about approvers This MUST be kept in sync with gubernator github classifier py particularly get approvers 
Writes the golang text template at template Path to output Path using the given data 
validate runs checks to ensure the label inputs are valid It ensures that no two label names including previous names have the same lowercase value and that the description is not over characters 
Labels returns a sorted list of labels unique by name 
TODO spiffxp needs to validate labels duped across repos are identical Ensures the config does not duplicate label names between default and repo 
Labels For Target returns labels that have a given target 
Load Config reads the yaml config at path 
Get Org returns organization from org or user name Org can be organization name like kubernetes But we can also request all user s public repos via user github user name 
load Repos read what filtered repos exist under an org 
load Labels returns what labels exist in github 
Delete the label 
Create the label 
Rename the label will also update color 
Update the label color description 
classify Labels will put labels into the required archaic dead maps as appropriate 
Do Updates iterates generated update data and adds and or modifies labels on repositories Uses Add Label GH API to add missing labels And Update Label GH API to update color or name name only when case differs 
Main function Typical run with production configuration should require no parameters It expects labels file in etc config labels yaml github OAuth token in etc github oauth this token must have write access to all org s repos It uses request retrying in case of run out of GH API points It took about minutes to process all my repos with all wanted kubernetes labels Next run takes about seconds to check if all labels are correct on all repos 
parse Comma Delimited List parses values in the format org repo org repo org repo into a mapping of org to repos i e org repo repo org repo 
linkify transforms a string into a markdown anchor link I could not find a proper doc so rules here a mostly empirical 
Returns the CSS escaped label name Escaped method based on https www w org International questions qa escapes cssescapes 
Returns the text color whether black or white given the background color Details https www w org TR WCAG contrastratio 
New Cache returns a new Cache given the root directory that should be used on disk for cache storage 
Key To Path converts a cache entry key to a path on disk 
Path To Key converts a path on disk to a key assuming the path is actually under Disk Root 
file path helper 
Put copies the content reader until the end into the cache at key if content SHA is not then the contents will only be stored in the cache if the content s hex string SHA matches 
Get provides your read Handler with the contents at key 
Get Entries walks the cache dir and returns all paths that exist In the future this may be made smarter 
Delete deletes the file at key 
New GCSArtifact returns a new GCSArtifact with a given handle canonical link and path within the job 
Size returns the size of the artifact in GCS 
Read At reads len p bytes from a file in GCS at offset off 
Read At Most reads at most n bytes from a file in GCS If the file is compressed gzip in GCS n bytes of gzipped content will be downloaded and decompressed into potentially GREATER than n bytes of content 
Read All will either read the entire file or throw an error if file size is too big 
Read Tail reads the last n bytes from a file in GCS 
gzipped returns whether the file is gzip encoded in GCS 
options For Repo gets the plugins Welcome struct that is applicable to the indicated repo 
List lists all Prow Jobs in the indexer 
Prow Jobs returns an object that can list and get Prow Jobs 
List lists all Prow Jobs in the indexer for a given namespace 
Metadata From File Name guesses file metadata from the filename and a simplifed filename For example build log txt gz would be Content Type text plain charset utf Content Encoding gzip and the simplified filename would be build log txt excluding the content encoding extension 
Runs Against All Branch returns true if there are both branches and skip branches are unset 
Should Run returns true if the input branch matches given the whitelist blacklist 
Intersects checks if other Brancher would trigger for the same branch 
Should Run determines if we can know for certain that the job should run We can either know for certain that the job should or should not run based on the matcher or we can not be able to determine that fact at all 
Runs Against Changes returns true if any of the changed input paths match the run if changed regex 
Could Run determines if the postsubmit could run against a specific base ref 
Should Run determines if the postsubmit should run in response to a set of changes This is evaluated lazily if necessary 
Could Run determines if the presubmit could run against a specific base ref 
Should Run determines if the presubmit should run against a specific base ref or in response to a set of changes The latter mechanism is evaluated lazily if necessary 
Trigger Matches returns true if the comment body should trigger this presubmit This is usually a test foo string 
New Git Hub Deferred Changed Files Provider uses a closure to lazily retrieve the file changes only if they are needed We only have to fetch the changes if there is at least one Run If Changed job that is not being force run due to a retest after a failure or because it is explicitly triggered with test foo 
Get Presubmit returns the presubmit job for the provided repo and job name 
Set Presubmits updates c Presubmits to jobs after compiling and validating their regexes 
Set Postsubmits updates c Postsubmits to jobs after compiling and validating their regexes 
All Presubmits returns all prow presubmit jobs in repos if repos is empty return all presubmits 
All Postsubmits returns all prow postsubmit jobs in repos if repos is empty return all postsubmits 
All Periodics returns all prow periodic jobs 
Clear Compiled Regexes removes compiled regexes from the presubmits useful for testing when deep equality is needed between presubmits 
Empty checks if a Simple Config could be considered empty 
New Client is the constructor for Client 
Load Repo Aliases returns an up to date Repo Aliases struct for the specified repo If the repo does not have an aliases file then an empty alias map is returned with no error Note The returned Repo Aliases should be treated as read only 
Load Repo Owners returns an up to date Repo Owners struct for the specified repo Note The returned Repo Owners should be treated as read only 
Expand Alias returns members of an alias 
Expand Aliases returns members of multiple aliases duplicates are pruned 
Parse Full Config will unmarshal OWNERS file s content into a Full Config Returns an error if the content cannot be unmarshalled 
Parse Simple Config will unmarshal an OWNERS file s content into a Simple Config Returns an error if the content cannot be unmarshalled 
decode Owners Md Config will parse the yaml header if it exists and unmarshal it into a single Owners Config If no yaml header is found do nothing Returns an error if the file cannot be read or the yaml header is found but cannot be unmarshalled 
find Owners For File returns the OWNERS file path furthest down the tree for a specified file using owner Map to check for entries 
Find Approver Owners For File returns the OWNERS file path furthest down the tree for a specified file that contains an approvers section 
Find Reviewers Owners For File returns the OWNERS file path furthest down the tree for a specified file that contains a reviewers section 
Find Labels For File returns a set of labels which should be applied to PRs modifying files under the given path 
Is No Parent Owners checks if an OWNERS file path refers to an OWNERS file with No Parent Owners enabled 
entries For File returns a set of users who are assignees to the requested file The path variable should be a full path to a filename and not directory as the final directory will be discounted if enable MDYAML is true leaf Only indicates whether only the OWNERS deepest in the tree closest to the file should be returned or if all OWNERS in filepath should be returned 
Leaf Approvers returns a set of users who are the closest approvers to the requested file If pkg OWNERS has user and pkg util OWNERS has user this will only return user for the path pkg util sets file go 
Approvers returns ALL of the users who are approvers for the requested file including approvers in parent dirs OWNERS If pkg OWNERS has user and pkg util OWNERS has user this will return both user and user for the path pkg util sets file go 
Leaf Reviewers returns a set of users who are the closest reviewers to the requested file If pkg OWNERS has user and pkg util OWNERS has user this will only return user for the path pkg util sets file go 
Reviewers returns ALL of the users who are reviewers for the requested file including reviewers in parent dirs OWNERS If pkg OWNERS has user and pkg util OWNERS has user this will return both user and user for the path pkg util sets file go 
Required Reviewers returns ALL of the users who are required reviewers for the requested file including required reviewers in parent dirs OWNERS If pkg OWNERS has user and pkg util OWNERS has user this will return both user and user for the path pkg util sets file go 
Ratio returns the percentage of statements that are covered 
From Payload set the Periodic Prow Job Event from the Pub Sub message payload 
To Message generates a Pub Sub Message from a Periodic Prow Job Event 
Unmarshal Text returns an error if text secret or closed 
compile Applicable Blockades filters the specified blockades and compiles those that apply to the repo 
calculate Blocks determines if a PR should be blocked and returns the summary describing the block 
Merge Profiles merges two coverage profiles The profiles are expected to be similar that is from multiple invocations of a single binary or multiple binaries using the same codebase In particular any source files with the same path must have had identical content when building the binaries Merge Profiles expects its arguments to be sorted Profiles in alphabetical order and lines in files in the order those lines appear These are standard constraints for Go coverage profiles The resulting profile will also obey these constraints 
Merge Multiple Profiles merges more than two profiles together Merge Multiple Profiles is equivalent to calling Merge Profiles on pairs of profiles until only one profile remains 
Add Flags adds log authors authors to the command help 
Receive Issue is a wrapper on plugin Receive Issue logging the author 
Receive Issue Event is a wrapper on plugin Receive Issue Event logging the author 
Receive Comment is a wrapper on plugin Receive Comment logging the author 
Add Flags adds flags to the Flag Set that populate the wrapper options struct provided 
Validate ensures that the set of options are self consistent and valid 
process Next Item attempts to upload container logs to GCS 
handle Err checks if an error happened and makes sure we will retry later 
Command Filter builds a filter for test foo 
Aggregate Filter builds a filter that evaluates the child filters in order and returns the first match 
Filter Presubmits determines which presubmits should run and which should be skipped by evaluating the user provided filter 
Make Command returns a filter command 
Push adds event to the heap 
Pop retrieves the last added event 
New Fake Open Plugin Wrapper is the constructor for Fake Open Plugin Wrapper 
Receive Issue creates a fake opened event 
Receive Issue Event injects an extra opened event before calling plugin Receive Issue Event 
Receive Comment is a wrapper on plugin Receive Comment 
Validate ensures that the configuration options are valid 
Complete internalizes command line arguments 
Add Flags adds flags to the Flag Set that populate the GCS upload options struct given 
Set parses out a prowapi Refs from the user string The following example shows all possible fields org repo base ref base sha pull number pull sha For the base ref and every pull number the SHAs are optional and any number of them may be set or unset 
Set records the value passed 
Set parses out overrides from user input 
ensure will ensure binary is on path or return an error with install message 
output returns the trimmed output of running args or an err on non zero exit 
projects returns the list of accessible gcp projects 
select Project returns the user selected project defaulting to the current gcloud one 
current Clusters returns a name cluster map 
create Cluster causes gcloud to create a cluster in project returning the context name 
create Context has the user create a context 
context Config returns the loader and config which can create a clientconfig 
select Context allows the user to choose a context This may involve creating a cluster 
apply Create will dry run create and then pipe this to kubectl apply If we use the create verb it will fail if the secret already exists And kubectl will reject the apply verb with a secret 
Filter Presubmits determines which presubmits should run We only want to trigger jobs that should run but the pool of jobs we filter to those that should run depends on the type of trigger we just got if we get a test foo we only want to consider those jobs that match jobs will default to run unless we can determine they shouldn t if we got a retest we only want to consider those jobs that have already run and posted failing contexts to the PR or those jobs that have not yet run but would otherwise match test all jobs will default to run unless we can determine they shouldn t if we got a test all or an ok to test we want to consider any job that doesn t explicitly require a human trigger comment jobs will default to not run unless we can determine that they should If a comment that we get matches more than one of the above patterns we consider the set of matching presubmits the union of the results from the matching cases 
determine Skipped Presubmits identifies the largest set of contexts we can actually post skipped contexts for given a set of presubmits we re triggering We don t want to skip a job that posts a context that will be written to by a job we just identified for triggering or the skipped context will override the triggered one 
Diff Profiles returns the difference between two sets of coverage profiles The profiles are expected to be from a single execution of the same binary or multiple binaries if using a merged coverage profile 
Dispatch receives channels to each type of events and dispatch them to each plugins 
Plugins constantly wait for new issues events comments 
Add Flags adds ignore authors authors to the command help 
Receive Issue calls plugin Receive Issue if the author is not filtered 
Receive Issue Event calls plugin Receive Issue Event if the author is not filtered 
Receive Comment calls plugin Receive Comment if the author is not filtered 
Create Issue tries to create and return a new github issue 
Create Status creates or updates a status context on the indicated reference 
For Each PR iterates over all PRs that fit the specified criteria calling the munge function on every PR If the munge function returns a non nil error For Each PR will return immediately with a non nil error unless continue On Error is true in which case an error will be logged and the remaining PRs will be munged 
Get Collaborators returns all github users who are members or outside collaborators of the repo 
Get Combined Status retrieves the Combined Status for the specified reference 
Get Issues gets all the issues in a repo that meet the list options 
Get Repo Labels gets all the labels that valid in the specified repo 
Get User gets the github user with the specified login or the currently authenticated user To get the currently authenticated user specify a login of 
Check if the config provided through the flags take valid values 
Create logfile for systemd service in output Dir with the given journalctl output Mode 
create Full Systemd Logfile creates logfile for full systemd journal in the output Dir 
Create logfiles for systemd services in output Dir 
Copy logfiles specific to this node based on the cloud provider system services etc to a temporary directory Also create logfiles for systemd services if journalctl is present We do not expect this function to see an error 
Write a marker file to GCS named after this node to indicate logexporter s success The directory to which we write this file can then be used as a registry to quickly fetch the list of nodes on which logexporter succeeded 
Make Command returns a junit command 
MDYAMLEnabled returns a boolean denoting if the passed repo supports YAML OWNERS config headers at the top of markdown md files These function like OWNERS files but only apply to the file itself 
validate checks the following properties Org Regexp Missing Label and Grace Period must be non empty Repo does not contain a should use Org Repo At least one of PRs or Issues must be true Branch only specified if prs true Missing Label must not match Regexp 
warn Deprecated prints a deprecation warning for a particular configuration option 
Describe generates a human readable description of the behavior that this configuration specifies 
Trigger For finds the Trigger for a repo if one exists a trigger can be listed for the repo itself or for the owning organization 
Enabled Repos For Plugin returns the orgs and repos that have enabled the passed plugin 
Enabled Repos For External Plugin returns the orgs and repos that have enabled the passed external plugin 
Set Defaults sets default options for config updating 
validate Plugins will return error if there are unknown or duplicated plugins 
New Reporter returns a reporter client 
Should Report returns if this prowjob should be reported by the gerrit reporter 
Report will send the current prowjob status as a gerrit review 
Run clones the refs under the prescribed directory and optionally configures the git username and email in the repository as well 
Path For Refs determines the full path to where refs should be cloned 
git Ctx For Refs creates a git Ctx based on the provide refs and base Dir 
commands For Base Ref returns the list of commands needed to initialize and configure a local git directory as well as fetch and check out the provided base ref 
git Head Timestamp returns the timestamp of the HEAD commit as seconds from the UNIX epoch If unable to read the timestamp for any reason such as missing the git or not using a git repo it returns and an error 
git Timestamp Envs returns the list of environment variables needed to override git s author and commit timestamps when creating new commits 
git Rev Parse returns current commit from HEAD in a git tree 
commands For Pull Refs returns the list of commands needed to fetch and merge any pull refs as well as submodules These commands should be run only after the commands provided by commands For Base Ref have been run successfully Each merge commit will be created at sequential seconds after fake Timestamp It s recommended that fake Timestamp be set to the timestamp of the base ref This enables reproducible timestamps and git tree digests every time the same set of base and pull refs are used 
Produce Cov List summarizes profiles and returns the result 
pop Random randomly selects an element of set and pops it 
Add Flags injects Kubernetes options into the given Flag Set 
Validate validates Kubernetes options 
resolve loads all of the clients we need and caches them for future calls 
Prow Job Clientset returns a Prow Job clientset for use in informer factories 
Prow Job Client returns a Prow Job client 
Infrastructure Cluster Client returns a Kubernetes client for the infrastructure cluster 
Build Cluster Clients returns Pod clients for build clusters 
Age gives the time since the state has been activated 
Receive Event checks if the event matches the exit criteria Returns a new Inactive State or self and true if it changed 
Receive Event checks if the event matches the entry criteria Returns a new Active State or self and true if it changed 
Active is true if all the states are active 
Age returns the time since all states have been activated It will panic if any of the state is not active 
Receive Event will send the event to each individual state and update them if they change 
New State creates a Multi State instance based on the states Description string states Description is a comma separated list of events Events can be prepended with bang to say that the state will be activated only if this event doesn t happen or is inverted 
For Resource gives generic access to a shared informer of the matching type TODO extend this to unknown resources with a client pool 
Prow Jobs returns a Prow Job Informer 
Item To Resources Config casts an Item object to a Resources Config 
Copy returns a copy of the Type To Resources 
Make Command returns an aggregate command 
New Controller creates a new Controller from the provided clients 
increment Num Pending Jobs increments the amount of pending Prow Jobs for the given job identifier 
set Previous Report State sets the github key for Prev Report States to current state This is a work around for plank crier migration to become seamless 
Sync does one sync iteration 
Sync Metrics records metrics for the cached prowjobs 
terminate Dupes aborts presubmits that have a newer version It modifies pjs in place when it aborts TODO Dry this out need to ensure we can abstract children cancellation first 
TODO Dry this out 
TODO No need to return the pod name since we already have the prowjob in the call site 
Dump Profile dumps the profiles given to writer in go coverage format 
blocks Equal returns true if the blocks refer to the same code otherwise false It does not care about Count 
New Prow Job Informer constructs a new informer for Prow Job type Always prefer using an informer factory to get a shared informer instead of getting an independent one This reduces memory footprint and number of connections to the server 
New Filtered Prow Job Informer constructs a new informer for Prow Job type Always prefer using an informer factory to get a shared informer instead of getting an independent one This reduces memory footprint and number of connections to the server 
New constructs a Spyglass object from a Job Agent a config Agent and a storage Client 
Lenses gets all views of all artifact files matching each regexp with a registered lens 
Job Path returns a link to the GCS directory for the job specified in src 
Run Path returns the path to the GCS directory for the job run specified in src 
Run To PR returns the org repo pr tuple referenced by the provided src Returns an error if src does not reference a job with an associated PR 
Extra Links fetches started json and extracts links from metadata links 
Serve HTTP validates an incoming webhook and puts it into the event channel 
need Demux returns whether there are any external plugins that need to get the present event 
demux External dispatches the provided payload to the external plugins 
dispatch creates a new request using the provided payload and headers and dispatches the request to the provided endpoint 
Add Flags adds state and percentiles to the command help 
Check Flags configures which states to monitor 
Receive Issue Event computes age percentiles and saves them to Influx DB 
Dir Blacklist returns regular expressions matching directories to ignore when searching for OWNERS ALIAS files in a repo 
Load loads and parses the config at path 
load Config loads one or multiple config files and returns a config object 
yaml To Config converts a yaml file into a Config object 
Read File Maybe GZIP wraps ioutil Read File returning the decompressed contents if the file is gzipped or otherwise the raw contents 
merge Config merges two Job Config together It will try to merge Presubmits Postsubmits Periodics Pod Presets 
finalize Job Config mutates and fixes entries for jobspecs 
validate Component Config validates the infrastructure component configuration 
validate Job Config validates if all the jobspecs presets are valid if you are mutating the jobs please add it to finalize Job Config above 
Config Path returns the value for the component s config Path if provided explicitly or default otherwise 
Validate Controller validates the provided controller config 
default Job Base configures common parameters currently Agent and Namespace 
Set Presubmit Regexes compiles and validates all the regular expressions for the provided presubmits 
set Brancher Regexes compiles and validates all the regular expressions for the provided branch specifiers 
Set Postsubmit Regexes compiles and validates all the regular expressions for the provided postsubmits 
Body creates a view for prow job metadata 
New Boskos Handler constructs the boskos handler 
Error To Status translates error into http code 
handle Default Handler for always pass with 
handle Acquire Handler for acquire Method POST URLParams Required type string type of requested resource Required state string current state of the requested resource Required dest string destination state of the requested resource Required owner string requester of the resource 
handle Acquire By State Handler for acquirebystate Method POST URLParams Required state string current state of the requested resource Required dest string destination state of the requested resource Required owner string requester of the resource Required names string expected resources names 
handle Release Handler for release Method POST URL Params Required name string name of finished resource Required owner string owner of the resource Required dest string dest state 
handle Reset Handler for reset Method POST URL Params Required type string type of resource in interest Required state string original state Required dest string dest state for expired resource Required expire duration Str resource has not been updated since before expire 
handle Update Handler for update Method POST URLParams Required name string name of target resource Required owner string owner of the resource Required state string current state of the resource Optional user Data common User Data user data id to update 
handle Metric Handler for metric Method GET 
Dump Profile dumps the profile to the given file destination If the destination is it instead writes to stdout 
Load Profile loads a profile from the given filename If the filename is it instead reads from stdin 
New Client returns a client that talks to Git Hub It will fail if git is not in the PATH 
Set Credentials sets credentials in the client to be used for pushing to or pulling from remote repositories 
Clone clones a repository Pass the full repository name such as kubernetes test infra as the repo This function may take a long time if it is the first time cloning the repo In that case it must do a full git mirror clone For large repos this can take a while Once that is done it will do a git fetch instead of a clone which will usually take at most a few seconds 
Checkout runs git checkout 
Checkout New Branch creates a new branch and checks it out 
Merge attempts to merge commitlike into the current branch It returns true if the merge completes It returns an error if the abort fails 
Am tries to apply the patch in the given path into the current branch by performing a three way merge similar to git cherry pick It returns an error if the patch cannot be applied 
Push pushes over https to the provided owner repo branch using a password for basic auth 
Checkout Pull Request does exactly that 
Config runs git config 
retry Cmd will retry the command a few times with backoff Use this for any commands that will be talking to Git Hub such as clones or fetches 
Merge Commits Exist Between runs git log target head merged to verify if merge commits exist between target and head 
Labels And Annotations For Spec returns a minimal set of labels to add to prowjobs or its owned resources User provided extra Labels and extra Annotations values will take precedence over auto provided values 
Labels And Annotations For Job returns a standard set of labels to add to pod build etc resources 
Prow Job To Pod converts a Prow Job to a Pod that will run the tests 
Clone Log Path returns the path to the clone log file in the volume mount Clone Log Path returns the path to the clone log file in the volume mount 
clone Env encodes clonerefs Options into json and puts it into an environment variable 
ssh Volume converts a secret holding ssh keys into the corresponding volume and mount This is used by Clone Refs to attach the mount to the clonerefs container 
cookiefile Volumes converts a secret holding cookies into the corresponding volume and mount Secret can be of the form secret name base name or just secret name Here secret name refers to the kubernetes secret volume to mount and base name refers to the key in the secret where the cookies are stored The secret name pattern is equivalent to secret name secret name This is used by Clone Refs to attach the mount to the clonerefs container The returned string value is the path to the cookiefile for use with cookiefile 
Clone Refs constructs the container and volumes necessary to clone the refs requested by the Prow Job The container checks out repositories specified by the Prow Job Refs to code Mount A log of what it checked out is written to clone json in log Mount The container may need to mount SSH keys and or cookiefiles in order to access private refs Clone Refs returns a list of volumes containing these secrets required by the container 
Inject Entrypoint will make the entrypoint binary in the tools volume the container s entrypoint which will output to the log volume 
Place Entrypoint will copy entrypoint from the entrypoint image to the tools volume 
kube Env transforms a mapping of environment variables into their serialized form for a Pod Spec sorting by the name of the env vars 
Add Flags injects Kubernetes options into the given Flag Set 
Validate validates Kubernetes options 
Client returns a Kubernetes client 
handle interacts with Git Hub to drive the pull request to the proper state by adding and removing comments and labels If a PR has a WIP prefix it needs an explanatory comment and label Otherwise neither should be present 
Send Hook sends a Git Hub event of type event Type to the provided address 
TODO amwat remove this logic when we get rid of project 
Clean by janitor script 
async janitor goroutine 
Serve HTTP validates an incoming Push Pub Sub subscription and handle them 
New creates new Cloud Pub Sub Client 
Subscription creates a subscription from the Cloud Pub Sub Client 
handle Pulls pull for Pub Sub subscriptions and handle them 
Run will block listening to all subscriptions and return once the context is cancelled or one of the subscription has a unrecoverable error 
spec To Started translate a jobspec into a started struct optionally overwrite Repo Version with provided main Ref SHA 
Run will start the initupload job to upload the artifacts logs and clone status 
process Clone Log checks if clone operation successed or failed for a ref and upload clone logs as build log upon failures returns bool clone status string final main ref SHA on a successful clone error when unexpected file operation happens 
has PRChanged indicates that the code diff may have changed 
Update Issues downloads new issues and saves in database 
handle Review Event should only handle reviews that have no approval command Reviews with approval commands will be handled by handle Generic Comment Event 
Returns associated issue or if it can t find any This is really simple and could be improved later 
handle is the workhorse the will actually make updates to the PR The algorithm goes as Initially we build an approver Set Go through all comments in order of creation Issue PR comments PR review comments and PR review bodies are considered as comments If anyone said approve add them to approver Set If anyone said lgtm AND Lgtm Acts As Approve is enabled add them to approver Set If anyone created an approved review AND Review Acts As Approve is enabled add them to approver Set Then for each file we see if any approver of this file is in approver Set and keep track of files without approval An approver of a file is defined as Someone listed as an approver in an OWNERS file in the files directory OR in one of the file s parent directories Iff all files have been approved the bot will add the approved label Iff a cancel command is found that reviewer will be removed from the approver Set and the munger will remove the approved label if it has been applied 
add Approvers iterates through the list of comments on a PR and identifies all of the people that have said approve and adds them to the Approvers The function uses the latest approve or cancel comment to determine the Users intention A review in requested changes state is considered a cancel 
options For Repo gets the plugins Approve struct that is applicable to the indicated repo 
local Only Main contains logic used only when running locally and is mutually exclusive with prod Only Main 
prod Only Main contains logic only used when running deployed not locally 
copy a http Request see https go review googlesource com c go src net http server go 
handle Badge handles requests to get a badge for one or more jobs The url must look like this where jobs is a comma separated list of globs badge svg jobs glob glob Examples badge svg jobs pull kubernetes bazel build badge svg jobs pull kubernetes badge svg jobs pull kubernetes e e pull kubernetes pull kubernetes integration 
handle Job History handles requests to get the history of a given job The url must look like this for presubmits job history gcs bucket name pr logs directory job name Example job history kubernetes jenkins pr logs directory pull test infra verify gofmt For periodics or postsubmits the url must look like this job history gcs bucket name logs job name Example job history kubernetes jenkins logs ci kubernetes e e prow canary 
handle Request Job Views handles requests to get all available artifact views for a given job The url must specify a storage key type such as prowjob or gcs view key type key Examples view gcs kubernetes jenkins pr logs pull test infra pull test infra verify gofmt view prowjob echo test 
render Spyglass returns a pre rendered Spyglass page from the given source string 
handle Artifact View handles requests to load a single view for a job This is what viewers will use to call back to themselves Query params name required specifies the name of the viewer to load src required specifies the job source from which to fetch artifacts 
TODO spxtr Cache rate limit 
Cov List constructs new file Group Coverage 
summarize summarizes all items in the Group and stores the result 
Subset returns the subset obtained through applying filter 
List Directories gets a list a sub directories that contains source code 
read Request extracts the request from the Admission Review reader 
handle reads the request and writes the response 
write Response gets the response from only Update Status and writes it to w 
only Update Status returns the response to the request 
convert Suite Meta converts a junit result in gcs to a Result Store Suite 
Convert converts build metadata stored in gcp into the corresponding Result Store Invocation Target and Test 
New Health creates a new health request multiplexer and starts serving the liveness endpoint on the given port 
Serve Ready starts serving the readiness endpoint 
New Controller makes a Controller out of the given clients 
org repo number pr 
new Expected Context creates a Context with Expected state 
contexts To Strings converts a list Context to a list of string 
Sync runs one sync iteration 
filter Subpools filters non pool PRs out of the initially identified subpools deleting any pools that become empty See filter Subpool for filtering details 
filter Subpool filters PRs from an initially identified subpool returning the filtered subpool If the subpool becomes empty nil is returned to indicate that the subpool should be deleted 
filter PR indicates if a PR should be filtered out of the subpool Specifically we filter out PRs that Have known merge conflicts Have failing or missing status contexts Have pending required status contexts that are not associated with a Prow Job This ensures that the tide context indicates that the pending status is preventing merge Required Prow Job statuses are allowed to be pending because this prevents kicking PRs from the pool when Tide is retesting them 
pool PRMap collects all subpool PRs into a map containing all pooled PRs 
unsuccessful Contexts determines which contexts from the list that we care about are failed For instance we do not care about our own context If the branch Protection is set to only check for required checks we will skip all non required tests If required tests are missing from the list they will be added to the list of failed contexts 
accumulate Batch returns a list of PRs that can be merged after passing batch testing if any exist It also returns a list of PRs currently being batch tested 
accumulate returns the supplied PRs sorted into three buckets based on their accumulated state across the presubmits 
try Merge attempts merge and returns a bool indicating if we should try to merge the remaining PRs and possibly an error 
pr Changes gets the files changed by the PR either from the cache or by querying Git Hub 
prune removes any cached file changes that were not used since the last prune 
divide Pool splits up the list of pull requests and prow jobs into a group per repo and branch It only keeps Prow Jobs that match the latest branch 
head Contexts gets the status contexts for the commit with OID pr Head Ref OID First we try to get this value from the commits we got with the PR query Unfortunately the last commit ordering is determined by author date not commit date so if commits are reordered non chronologically on the PR branch the last commit isn t necessarily the logically last commit We list multiple commits with the query to increase our chance of success but if we don t find the head commit we have to ask Git Hub for it specifically this costs an API token 
Aggregate Profiles takes multiple coverage profiles and produces a new coverage profile that counts the number of profiles that hit a block at least once 
count To Boolean converts a profile containing hit counts to instead contain only s or s 
New Storage instantiates a new Storage with a Persistence Layer implementation If storage string is not empty it will read resource data from the file 
Add Resource adds a new resource 
Delete Resource deletes a resource if it exists errors otherwise 
Update Resource updates a resource if it exists errors otherwise 
Get Resource gets an existing resource errors otherwise 
Get Resources list all resources 
Sync Resources will update resources every mins It will append newly added resources to ranch Resources And try to remove newly deleted resources from ranch Resources If the newly deleted resource is currently held by a user the deletion will yield to next update cycle 
Parse Config reads in config Path and returns a list of resource objects on success 
problems In Files runs buildifier on the files It returns a map from the file to a list of problems with that file 
New Pod Log Artifact creates a new Pod Log Artifact 
Canonical Link returns a link to where pod logs are streamed 
Read At implements reading a range of bytes from the pod logs endpoint 
Read All reads all available pod logs failing if they are too large 
Read At Most reads at most n bytes 
Read Tail reads the last n bytes of the pod log 
Size gets the size of the pod log Note this function makes the same network call as reading the entire file 
modified Go Files returns a map from filename to patch string for all go files that are modified in the PR excluding vendor and generated files 
new Problems compares the list of problems with the list of past comments on the PR to decide which are new 
problems In Files runs golint on the files It returns a map from the file to a map from the line in the patch to the problem 
Added Lines returns line numbers that were added in the patch along with their line in the patch itself as a map from line to patch line https www gnu org software diffutils manual diffutils html Detailed Unified Git Hub omits the lines since that information is in the Pull Request Change object 
remove merged presets from a podspec 
undo merged presets from loaded presubmit and its children 
convert a kubernetes kubernetes job to a kubernetes security kubernetes job drop Labels should be a set of k v strings xref prow config config test go replace it will return the same job mutated or nil if the job should be removed 
these are unnecessary and make the config larger so we strip them out 
Serve PProf sets up a handler for pprof debug endpoints and starts a server for them asynchronously The contents of this function are identical to what the net http pprof package does on import for the simple case where the default mux is to be used but with a custom mux to ensure we don t serve this data from an exposed port 
monitor Disk And Evict loops monitoring the disk evicting cache entries when the disk passes either min Percent Blocks Free until the disk is above evict Until Percent Blocks Free 
difference returns a new org Repo Config that represents the set difference of the repos specified by the receiver and the parameter org Repo Configs 
union returns a new org Repo Config that represents the set union of the repos specified by the receiver and the parameter org Repo Configs 
ensure Valid Configuration enforces rules about tide and plugin config In this context a subset is the set of repos or orgs for which a specific plugin is either enabled for plugins or required for merge for tide The tide superset is every org or repo that has any configuration at all in tide Specifically every item in the tide subset must also be in the plugins subset every item in the plugins subset that is in the tide superset must also be in the tide subset For example if org repo is configured in tide to require lgtm it must have the lgtm plugin enabled if org repo is configured in tide the tide configuration must require the same set of plugins as are configured If the repository has LGTM and approve enabled the tide query must require both labels 
Set records the value passed 
clear Stale Comments deletes old comments that are no longer applicable 
determine Release Note Label returns the label to be added based on the contents of the release note section of a PR s body text 
get Release Note returns the release note from a PR body assumes that the PR body followed the PR template 
New Client creates a new client from a boskos Client interface 
Acquire gets a resource with associated leased resources 
Release One will release a resource as well as leased resources associated to it 
Update All updates all the acquired resources with a given state 
Get Git Hub Client creates a client for each token 
Get Username finds the login for each token 
Create Token Handler parses the token and create a handler 
Create Token Handlers goes through the list of token files and create handlers 
Process does the main job It tries to get the value of Remaining rate just before the token gets reset It does that more and more often as the reset date gets closer to get the most accurate value 
String returns the string representation of a prow job identifier 
Terminate Older Presubmit Jobs aborts all presubmit jobs from the given list that have a newer version It calls the cleanup callback for each job before updating its status as aborted 
Push Metrics is meant to run in a goroutine and continuously push metrics to the provided endpoint 
 Check that the status event received from the webhook is for the CNCF CLA Use the github search API to search for the PRs which match the commit hash corresponding to the status event For each issue that matches check that the PR s HEAD commit hash against the commit hash for which the status was received This is because we only care about the status associated with the last latest commit in a PR Set the corresponding CLA label if needed 
Rate Limiter creates a ratelimiting queue for a given prow controller 
find Repo will attempt to find a repo in logical locations under path It will first try to find foo bar somewhere under PWD or a PWD dir AKA if PWD is go src it will match go src foo bar go foo bar or foo bar Next it will look for the basename somewhere under PWD or a PWD dir AKA if PWD is go src it will match go src bar go bar or bar If both of these strategies fail it will return an error 
check Commit Messages will perform the actual DCO check by retrieving all commits contained within the PR with the given number All commits in the pull request must match the test Re in order to pass 
check Existing Status will retrieve the current status of the DCO context for the provided SHA 
check Existing Labels will check the provided PR for the dco sign off labels returning bool s indicating whether the yes and the no label are present 
take Action will take appropriate action on the pull request according to its current state 
 Check commit messages in the pull request for the sign off string Check the existing status context value Check the existing PR labels If signed off apply appropriate labels and status context If not signed off apply appropriate labels and status context and add a comment 
Mardkown SHAList prints the list of commits in a markdown friendly way 
should Prune finds comments left by this plugin 
Path For Spec determines the GCS path prefix for files uploaded for a specific job spec 
Alias For Spec determines the GCS path aliases for a job spec 
Root For Spec determines the root GCS path for storing artifacts about the provided job 
New Single Default Repo Path Builder returns a builder that handles the legacy path encoding where a path will contain org and repo for all but one default repo 
New Explicit Repo Path Builder returns a builder that handles the path encoding where a path will always have an explicit org repo path segment 
Register Source Or Die registers a source of auto filed issues 
Create And Sync is the main workhorse function of Issue Creator It initializes the Issue Creator asks each source for its issues to sync and syncs the issues 
load Cache loads the valid labels for the repo the currently authenticated user and the issue cache from github 
Register Flags registers options for this munger returns any that require a restart when changed 
set Intersect removes any elements from the first list that are not in the second returning the new set and the removed elements 
sync checks to see if an issue is already on github and tries to create a new issue for it if it is not True is returned iff a new issue is created 
Get AWSCreds tries to fetch AWS credentials from a resource 
stopper returns a channel that remains open until an interrupt is received 
new Pipeline Config returns a client and informer capable of mutating and monitoring the specified config 
Add Flags injects Kubernetes options into the given Flag Set 
Validate validates Kubernetes options 
Kube Client returns a Kubernetes client 
Prow Job Client returns a Kubernetes client 
resolve sym links into the actual log directory for a particular test run 
reads specified JSON file in to data 
Lists the GCS directory paths immediately under prefix 
Lists all GCS keys with given prefix 
Gets all build ids for a job 
assumes a to be sorted in descending order returns a subslice of a along with its indices inclusive 
Gets job history from the GCS bucket specified in config 
Filter Profile Paths produces a new profile that removes either everything matching or everything not matching the provided paths depending on the value of include Paths are interpreted as regular expressions If include is true paths is treated as a whitelist otherwise it is treated as a blacklist 
handle drives the pull request to the desired state If any user adds a hold directive we want to add a label if one does not already exist If they add hold cancel we want to remove the label if it exists 
handle is the generic handler for the assign plugin It uses the handler s regexp and affected Logins functions to identify the users to add and or remove and then passes the appropriate users to the handler s add and remove functions If add fails to add some of the users a response comment is created where the body of the response is generated by the handler s add Failure Response function 
Load Secrets loads multiple paths of secrets and add them in a map 
Load Single Secret reads and returns the value of a single file 
Set the bool according to the string 
New Opener returns an opener that can read GCS and local paths 
Is Not Exist will return true if the error is because the object does not exist 
Log Close will attempt a close an log any error 
Reader will open the path for reading returning an Is Not Exist error when missing 
Writer returns a writer that overwrites the path 
Init Git Hub OAuth Config creates an OAuth Client using Git Hub OAuth config and a Cookie Store to retain user credentials 
delta Displayed converts a coverage ratio delta into a string value to be displayed by coverage robot 
make Table checks each coverage change and produce the table content for coverage bot post It also report on whether any coverage fells below the given threshold 
Content For Git Hub Post constructs the message covbot posts 
Add Flags parses options for github client 
Check Flags looks for organization and project flags to configure the client 
get Git Hub Client create the github client that we use to communicate with github 
limits Check And Wait make sure we have not reached the limit or wait 
Repository Name returns github s repository name in the form of org project 
Fetch Issues from Git Hub until latest time 
has ID look for a specific id in a list of events 
Fetch Issue Events from github and return the full list until it matches latest The entire last page will be included so you can have redundancy 
Fetch Issue Comments fetches comments associated to given Issue since latest 
These are the only actions indicating the code diffs may have changed 
New Fetcher creates a new Fetcher and initializes the output channels 
fetch Recent Issues retrieves issues from DB but only fetches issues modified since last call 
fetch Recent Events And Comments retrieves events from DB but only fetches events created since last call 
Fetch retrieves all types of events and push them to output channels 
zone Is Managed checks if the zone should be managed and thus have records deleted by us 
resource Record Set Is Managed checks if the resource record should be managed and thus deleted by us 
Register Flags registers options for this munger returns any that require a restart when changed 
Issues is the main work method of Flaky Job Reporter It fetches and parses flaky job data then syncs the top issues to github with the Issue Creator 
parse Flaky Jobs parses JSON generated by the flakes bigquery metric into a sorted slice of Flaky Job 
Title yields the initial title text of the github issue 
Body returns the body text of the github issue and must contain the output of ID closed Issues is a potentially empty slice containing all closed issues authored by this bot that contain ID in their body If Body returns an empty string no issue is created 
Labels returns the labels to apply to the issue created for this flaky job on github 
Read HTTP fetches file contents from a URL with retries 
Return valid json 
handle Metric Handler for Method GET 
load Cluster Config loads connection configuration for the cluster we re deploying to We prefer to use in cluster configuration if possible but will fall back to using default rules otherwise 
Get Kubernetes Client retrieves the Kubernetes cluster client from within the cluster 
Get Kubernetes Client retrieves the Kubernetes cluster client from within the cluster 
parse Pattern parses a gitattributes pattern string into the Pattern structure The rules by which the pattern matches paths are the same as in gitignore files see https git scm com docs gitignore with a few exceptions negative patterns are forbidden patterns that match a directory do not recursively match paths inside that directory https git scm com docs gitattributes 
Validate ensures that the set of options are self consistent and valid 
Add Flags binds flags to options 
New Job Spec converts a prowapi Prow Job Spec invocation into a Job Spec 
Resolve Spec From Env will determine the Refs being tested in by parsing Prow environment variable contents 
Env For Spec returns a mapping of environment variables to their values that should be available for a job spec 
Env For Type returns the slice of environment variables to export for job Type 
get Revision From Ref returns a ref or sha from a refs object 
Get Revision From Spec returns a main ref or sha from a spec object 
help Provider provides information on the plugin 
New Group reads the generated files file in the root of the repository and any referenced path files from path from repo commands 
Use load to read a generated files config file and populate g with the commands paths from repo commands are aggregated into repo Paths It is the caller s responsibility to fetch these and load them via g load Paths 
Use load Paths to load a file of new line delimited paths such as resolving file data referenced in a paths from repo command 
Match determines whether a file given here by its full path is included in the generated files group 
Create Database creates and connects a new instance of an Influx DB It is created based on the fields set in the configuration 
merge Tags merges the default tags with the exta tags Default will be overridden if it conflicts 
tags To Where creates a where query to match tags element 
Push a point to the database This appends to current batchpoint 
Push Batch Points pushes the batch points for real 
artifact constructs an artifact handle for the given job build 
role Is Managed checks if the role should be managed and thus deleted by us In particular we want to avoid system AWS roles or roles that might support test infra 
serve starts a http server and serves prometheus metrics Meant to be called inside a goroutine 
gather metrics from plank Meant to be called inside a goroutine 
make Request renders a branch protection policy into the corresponding Git Hub api request 
make Admins returns true iff val true else nil 
make Checks renders a Context Policy into the corresponding Git Hub api object Returns nil when input policy is nil Otherwise returns non nil Contexts empty if unset and Strict iff Strict is true 
make Restrictions renders restrictions into the corresponding Git Hub api object Returns nil when input restrictions is nil Otherwise Teams and Users are both non nil empty list if unset 
make Reviews renders review policy into the corresponding Git Hub api object Returns nil if the policy is nil or approvals is nil or 
Header executes the header section of the template 
Body returns the body content for a build log or multiple build logs 
Callback is used to retrieve new log segments 
log Lines All reads all of an artifact and splits it into lines 
breaks lines into important unimportant groups 
Log View Template executes the log viewer template ready for rendering 
Deep Copy Object implements runtime Object interface 
From Item implements Object interface 
Set Items implements Collection interface 
Deep Copy Object implements Collection interface 
use Context calls kubectl config use context ctx 
current Context returns kubectl config current context 
get Credentials calls gcloud container clusters get credentials usually preserving current Context 
command creates an exec Cmd with Stderr piped to os Stderr and returns the args 
get Account returns gcloud config get value core account 
set Account calls gcloud config set core account 
describe Cluster returns details from gcloud container clusters describe 
do will get creds for the specified cluster and add them to the stdin secret 
Set appends a value onto the strslice 
split Bucket Object breaks a path into the first part the bucket and everything else the object 
dirname returns the logical parent directory of the path This is different than path Split in that we want dirname foo bar foo whereas path Split returns foo bar 
parse XML extracts a gcs Dir object from XML If this returns a nil gcs Dir the XML indicated that this was not a directory at all 
Render writes HTML representing this gcs Dir to the provided output 
Render writes HTML representing this Record to the provided output 
Render writes HTML representing this Prefix to the provided output 
Printf logs a formatted line to the logging output 
process Regex Matches processes the user command regex matches and returns the proposed project name proposed column name whether the command is to remove issue PR from project and the error message 
Set populates Projects Flag upon flag Parse 
New Client returns a new gerrit client 
Query Changes queries for all changes from all projects after last Update time returns an instance changes map 
Set Review writes a review comment base on the change id revision 
Get Branch Revision returns SHA of HEAD of a branch 
private handler implementation details 
New Type Filter Wrapper Plugin is the constructor of Type Filter Wrapper Plugin 
Add Flags adds no pull requests and no issues to the command help 
Check Flags makes sure not both PR and issues are ignored 
Receive Issue calls plugin Receive Issue if issues are not ignored 
Receive Issue Event calls plugin Receive Issue Event if issues are not ignored 
Receive Comment calls plugin Receive Comment if issues are not ignored 
Add Flags adds kube client flags to existing Flag Set 
Validate validates Kubernetes client options 
Client returns a Client Interface based on the flags provided 
new Client From Flags creates a CRD rest client from provided flags 
create RESTConfig for cluster API server pass empty config file for in cluster 
register Resource sends a request to create CRDs and waits for them to initialize 
new Dummy Client creates a in memory client representation for testing such that we do not need to use a kubernetes API Server 
Create implements Client Interface 
Update implements Client Interface 
Delete implements Client Interface 
Get implements Client Interface 
List implements Client Interface 
Create implements Client Interface 
Delete implements Client Interface 
Get implements Client Interface 
List implements Client Interface 
Trusted Pull Request returns whether or not the given PR should be tested It first checks if the author is in the org then looks for ok to test label 
build All ensures that all builds that should run and will be required are built 
Run will watch for the process being wrapped to exit and then post the status of that process and any artifacts to cloud storage 
Add Config adds a new config 
Delete Config deletes an existing config if it exists or fail otherwise 
Update Config updates a given if it exists or fail otherwise 
Get Config returns an existing if it exists errors out otherwise 
Get Configs returns all configs 
Sync Configs syncs new configs 
Adds the list of known types to the Scheme 
New Controller constructs a new controller to reconcile stauses on config change 
Run monitors the incoming configuration changes to determine when statuses need to be reconciled on PRs in flight when blocking presubmits change 
added Blocking Presubmits determines new blocking presubmits based on a config update New blocking presubmits are either brand new presubmits or extant presubmits that are now reporting Previous presubmits that reported but were optional that are no longer optional require no action as their contexts will already exist on PRs 
removed Blocking Presubmits determines stale blocking presubmits based on a config update Presubmits that are no longer blocking due to no longer reporting or being optional require no action as Tide will honor those statuses correctly 
migrated Blocking Presubmits determines blocking presubmits that have had their status contexts migrated This is a best effort evaluation as we can only track a presubmit between configuration versions by its name A presubmit migration that had its underlying job and context changed will be treated as a deletion and creation 
Load loads the set of options preferring to use JSON config from an env var but falling back to command line flags if not possible 
New Controller creates a new Controller from the provided clients 
can Execute Concurrently checks whether the provided Prow Job can be executed concurrently 
Sync does one sync iteration 
get Jenkins Jobs returns all the Jenkins jobs for all active prowjobs from the provided list It handles deduplication 
terminate Dupes aborts presubmits that have a newer version It modifies pjs in place when it aborts 
Throttle client to a rate of at most hourly Tokens requests per hour allowing burst tokens 
New Client With Fields creates a new fully operational Git Hub client With added logging fields get Token is a generator for the Git Hub access token to use bases is a variadic slice of endpoints to use in order of preference An endpoint is used when all preceding endpoints have returned a conn err This should be used when using the ghproxy Git Hub proxy cache to allow this client to bypass the cache if it is temporarily unavailable 
New Client creates a new fully operational Git Hub client 
New Dry Run Client creates a new client that will not perform mutating actions such as setting statuses or commenting but it will still query Git Hub and use up API tokens get Token is a generator the Git Hub access token to use bases is a variadic slice of endpoints to use in order of preference An endpoint is used when all preceding endpoints have returned a conn err This should be used when using the ghproxy Git Hub proxy cache to allow this client to bypass the cache if it is temporarily unavailable 
New Fake Client creates a new client that will not perform any actions at all 
Make a request with retries If ret is not nil unmarshal the response body into it Returns an error if the exit code is not one of the provided codes 
request Raw makes a request with retries and returns the response body Returns an error if the exit code is not one of the provided codes 
Retry on transport failures Retries on s retries after sleep on ratelimit exceeded and retries s a couple times This function closes the response body iff it also returns an error 
Not thread safe callers need to hold c mut 
Bot Name returns the login of the authenticated identity See https developer github com v users get the authenticated user 
Email returns the user configured email for the authenticated identity See https developer github com v users get the authenticated user 
Is Member returns whether or not the user is a member of the org See https developer github com v orgs members check membership 
List Org Hooks returns a list of hooks for the org https developer github com v orgs hooks list hooks 
List Repo Hooks returns a list of hooks for the repo https developer github com v repos hooks list hooks 
Edit Repo Hook updates an existing hook with new info events url secret https developer github com v repos hooks edit a hook 
Edit Org Hook updates an existing hook with new info events url secret https developer github com v orgs hooks edit a hook 
Create Org Hook creates a new hook for the org https developer github com v orgs hooks create a hook 
Create Repo Hook creates a new hook for the repo https developer github com v repos hooks create a hook 
Get Org returns current metadata for the org https developer github com v orgs get an organization 
Edit Org will update the metadata for this org https developer github com v orgs edit an organization 
List Org Invitations lists pending invitations to th org https developer github com v orgs members list pending organization invitations 
List Org Members list all users who are members of an organization If the authenticated user is also a member of this organization then both concealed and public members will be returned Role options are all admin and member https developer github com v orgs members members list 
Has Permission returns true if Get User Permission returns any of the roles 
Get User Permission returns the user s permission level for a repo https developer github com v repos collaborators review a users permission level 
Update Org Membership invites a user to the org and or updates their permission level If the user is not already a member this will invite them This will also change the role to from admin on either the invitation or membership setting https developer github com v orgs members add or update organization membership 
Remove Org Membership removes the user from the org https developer github com v orgs members remove organization membership 
Create Comment creates a comment on the issue See https developer github com v issues comments create a comment 
Edit Comment changes the body of comment id in org repo See https developer github com v issues comments edit a comment 
Create Comment Reaction responds emotionally to comment id in org repo See https developer github com v reactions create reaction for an issue comment 
Delete Stale Comments iterates over comments on an issue PR deleting those which the is Stale function identifies as stale If comments is nil the comments will be fetched from Git Hub 
read Paginated Results iterates over all objects in the paginated result indicated by the given url new Obj should return a new slice of the expected type accumulate should accept that populated slice for each page of results Returns an error any call to Git Hub or object marshalling fails 
read Paginated Results With Values is an override that allows control over the query string 
Get Pull Requests get all open pull requests for a repo See https developer github com v pulls list pull requests 
Get Pull Request gets a pull request See https developer github com v pulls get a single pull request 
Get Pull Request Patch gets the patch version of a pull request See https developer github com v media commits commit comparison and pull requests 
Create Pull Request creates a new pull request and returns its number if the creation is successful otherwise any error that is encountered See https developer github com v pulls create a pull request 
Update Pull Request modifies the title body open state 
Get Pull Request Changes gets a list of files modified in a pull request See https developer github com v pulls list pull requests files 
List Pull Request Comments returns all review comments on a pull request Multiple pages of comments consumes multiple API tokens See https developer github com v pulls comments list comments on a pull request 
List Reviews returns all reviews on a pull request Multiple pages of results consumes multiple API tokens See https developer github com v pulls reviews list reviews on a pull request 
Create Status creates or updates the status of a commit See https developer github com v repos statuses create a status 
List Statuses gets commit statuses for a given ref See https developer github com v repos statuses list statuses for a specific ref 
Get Repo returns the repo for the provided owner name combination See https developer github com v repos get 
Get Repos returns all repos in an org This call uses multiple API tokens when results are paginated See https developer github com v repos list organization repositories 
Get Single Commit returns a single commit See https developer github com v repos get 
Get Branches returns all branches in the repo If only Protected is true it will only return repos with protection enabled and branch Protected will be true Otherwise Protected is the default value false This call uses multiple API tokens when results are paginated See https developer github com v repos branches list branches 
Update Branch Protection configures org repo branch See https developer github com v repos branches update branch protection 
Update Repo Label updates a org repo label to new name description and color See https developer github com v issues labels update a label 
Delete Repo Label deletes a label in org repo See https developer github com v issues labels delete a label 
Get Combined Status returns the latest statuses for a given ref See https developer github com v repos statuses get the combined status for a specific ref 
get Labels is a helper function that retrieves a paginated list of labels from a github URI path 
Get Repo Labels returns the list of labels accessible to org repo See https developer github com v issues labels list all labels for this repository 
Get Issue Labels returns the list of labels currently on issue org repo number See https developer github com v issues labels list labels on an issue 
Remove Label removes label from org repo number returning an error on any failure See https developer github com v issues labels remove a label from an issue 
Assign Issue adds logins to org repo number returning an error if any login is missing after making the call See https developer github com v issues assignees add assignees to an issue 
Create Review creates a review using the draft https developer github com v pulls reviews create a pull request review 
prepare Reviewers Body separates reviewers from team reviewers and prepares a map reviewers octocat hubot other user team reviewers justice league https developer github com v pulls review requests create a review request 
Request Review tries to add the users listed in logins as requested reviewers of the specified PR If any user in the logins slice is not a contributor of the repo the entire POST will fail without adding any reviewers The Git Hub API response does not specify which user s were invalid so if we fail to request reviews from the members of logins we try to request reviews from each member individually We try first with all users in logins for efficiency in the common case See https developer github com v pulls review requests create a review request 
Unrequest Review tries to remove the users listed in logins from the requested reviewers of the specified PR The Git Hub API treats deletions of review requests differently than creations Specifically if logins contains a user that isn t a requested reviewer other users that are valid are still removed Furthermore the API response lists the set of requested reviewers after the deletion unlike request creations so we can determine if each deletion was successful The API responds with http status code no matter what the content of logins is See https developer github com v pulls review requests delete a review request 
Close Issue closes the existing open issue provided See https developer github com v issues edit an issue 
convert to a State Cannot Be Changed if appropriate or else return the original error 
Get Ref returns the SHA of the given ref such as heads master See https developer github com v git refs get a reference 
Delete Ref deletes the given ref See https developer github com v git refs delete a reference 
Find Issues uses the Git Hub search API to find issues which match a particular query Input query the same way you would into the website Order returned results with sort usually updated Control whether oldest newest is first with asc See https help github com articles searching issues and pull requests for details 
Get File uses Git Hub repo contents API to retrieve the content of a file with commit SHA If commit is empty it will grab content from repo s default branch usually master TODO krzyzacy Support retrieve a directory See https developer github com v repos contents get contents 
Query runs a Graph QL query using shurcoo L githubql s client 
Create Team adds a team with name to the org returning a struct with the new ID See https developer github com v teams create team 
Edit Team patches team ID to contain the specified other values See https developer github com v teams edit team 
Delete Team removes team ID from Git Hub See https developer github com v teams delete team 
List Teams gets a list of teams for the given org See https developer github com v teams list teams 
Update Team Membership adds the user to the team and or updates their role in that team If the user is not a member of the org Git Hub will invite them to become an outside collaborator setting their status to pending https developer github com v teams members add or update team membership 
Remove Team Membership removes the user from the team but not the org https developer github com v teams members remove team member 
List Team Members gets a list of team members for the given team id Role options are all maintainer and member https developer github com v teams members list team members 
List Team Repos gets a list of team repos for the given team id https developer github com v teams list team repos 
Update Team Repo adds the repo to the team with the provided role https developer github com v teams add or update team repository 
List Team Invitations gets a list of team members with pending invitations for the given team id https developer github com v teams members list pending team invitations 
Merge merges a PR See https developer github com v pulls merge a pull request merge button 
List Collaborators gets a list of all users who have access to a repo and can become assignees or requested reviewers See Is Collaborator for more details See https developer github com v repos collaborators 
Create Fork creates a fork for the authenticated user Forking a repository happens asynchronously Therefore we may have to wait a short period before accessing the git objects If this takes longer than minutes Git Hub recommends contacting their support See https developer github com v repos forks create a fork 
List Issue Events gets a list events from Git Hub s events API that pertain to the specified issue The events that are returned have a different format than webhook events and certain event types are excluded See https developer github com v issues events 
Is Mergeable determines if a PR can be merged Mergeability is calculated by a background job on Git Hub and is not immediately available when new commits are added so the PR must be polled until the background job completes 
Clear Milestone clears the milestone from the specified issue See https developer github com v issues edit an issue 
List Milestones list all milestones in a repo See https developer github com v issues milestones list milestones for a repository 
List PRCommits lists the commits in a pull request Git Hub API docs https developer github com v pulls list commits on a pull request 
Token is an implementation for oauth Token Source interface 
Get Repo Projects returns the list of projects in this repo See https developer github com v projects list repository projects 
Get Org Projects returns the list of projects in this org See https developer github com v projects list organization projects 
Get Project Columns returns the list of columns in a project See https developer github com v projects columns list project columns 
Create Project Card adds a project card to the specified project column See https developer github com v projects cards create a project card 
Get Column Project Card of a specific issue or PR for a specific column in a board project See https developer github com v projects cards list project cards 
Move Project Card moves a specific project card to a specified column in the same project See https developer github com v projects cards move a project card 
Delete Project Card deletes the project card of a specific issue or PR See https developer github com v projects cards delete a project card 
Team Has Member checks if a user belongs to a team 
List Artifacts gets the names of all artifacts available from the given source 
Key To Job takes a spyglass URL and returns the job Name and build ID 
prow To GCS returns the GCS key corresponding to the given prow key 
Fetch Artifacts constructs and returns Artifact objects for each artifact name in the list This includes getting any handles needed for read write operations direct artifact links etc 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Decoration Config 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new GCSConfiguration 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Jenkins Spec 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Prow Job 
Deep Copy Object is an autogenerated deepcopy function copying the receiver creating a new runtime Object 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Prow Job List 
Deep Copy Object is an autogenerated deepcopy function copying the receiver creating a new runtime Object 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Prow Job Spec 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Prow Job Status 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Pull 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Refs 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new Utility Images 
upload the result downloaded from path into project 
Apply Default applies the defaults for the Prow Job decoration If a field has a zero value it replaces that with the value set in def 
Validate ensures all the values set in the Decoration Config are valid 
Apply Default applies the defaults for the Utility Images decorations If a field has a zero value it replaces that with the value set in def 
Apply Default applies the defaults for GCSConfiguration decorations If a field has a zero value it replaces that with the value set in def 
Validate ensures all the values set in the GCSConfiguration are valid 
Set Complete marks the job as completed at time now 
Cluster Alias specifies the key in the clusters map to use This allows scheduling a prow job somewhere aside from the default build cluster 
New Resource creates a new Boskos Resource 
New Resources From Config parse the a Resource Entry into a list of resources 
User Data From Map returns a User Data from a map 
Set parses the flag value into a Comma Separated Strings 
Unmarshal JSON implements JSON Unmarshaler interface 
Extract unmarshalls a string a given struct if it exists 
User Data are used to store custom information mainly by Mason and Masonable implementation Mason used a Leased Resource keys to store information about other resources that used to create the given resource Set marshalls a struct to a string into the User Data 
Update updates existing User Data with new User Data If a key as an empty string the key will be deleted 
To Map converts a User Data to User Data Map 
From Map feels updates user data from a map 
Item To Resource casts a Item back to a Resource 
Run clones the configured refs 
add SSHKeys will start the ssh agent and add all the specified keys returning the ssh agent environment variables for reuse 
Issues is the main work function of the Triage Filer It fetches and parses cluster data then syncs the top issues to github with the Issue Creator 
Register Flags registers options for this munger returns any that require a restart when changed 
filter And Validate removes failure data that falls outside the time window and ensures that cluster data is well formed It also removes data for PR jobs so that only post submit failures are considered 
load Clusters parses and filters the json data then populates every Cluster struct with aggregated job data and totals The job data specifies all jobs that failed in a cluster and the builds that failed for each job independent of which tests the jobs or builds failed 
parse Triage Data unmarshals raw json data into a triage Data struct and creates a Build Indexer for every job 
top Clusters gets the count most important clusters from a slice of clusters based on number of build failures 
top Jobs Failed returns the top count job names sorted by number of failing builds 
Title is the string to use as the github issue title 
Body returns the body text of the github issue and must contain the output of ID closed Issues is a potentially empty slice containing all closed issues authored by this bot that contain ID in their body If Body returns an empty string no issue is created 
Labels returns the labels to apply to the issue created for this cluster on github 
New makes a new Cron object 
Queued Jobs returns a list of jobs that need to be triggered and reset trigger in job Status 
Sync Config syncs current cron Agent with current prow config which add delete jobs accordingly 
Has Job returns if a job has been scheduled in cron Agent or not 
add Job adds a cron entry for a job to cron Agent 
remove Job removes the job from cron Agent 
Update Comments downloads issue and pull request comments and save in DB 
Gather Prow Job Metrics gathers prometheus metrics for prowjobs 
Run executes the test process then writes the exit code to the marker file This function returns the status code that should be passed to os Exit 
Execute Process creates the artifact directory then executes the process as configured writing the output to the process log 
option Or Default defaults to a value if option is the zero value 
new GCSJob Source creates a new gcs Job Source from a given bucket and job Prefix 
Artifacts lists all artifacts available for the given job source 
Artifact constructs a GCS artifact from the given GCS bucket and key Uses the golang GCS library to get read handles If the artifact Name is not a valid key in the bucket a handle will still be constructed and returned but all read operations will fail dictated by behavior of golang GCS lib 
Canonical Link gets a link to the location of job specific artifacts in GCS 
Job Path gets the prefix to all artifacts in GCS in the job 
requirement Diff calculates the diff between a PR and a Tide Query This diff is defined with a string that describes some subset of the differences and an integer counting the total number of differences The diff count should always reflect the scale of the differences between the current state of the PR and the query but the message returned need not attempt to convey all of that information if some differences are more severe For instance we need to convey that a PR is open against a forbidden branch more than we need to detail which status contexts are failed against the PR To this end some differences are given a higher diff weight than others Note an empty diff can be returned if the reason that the PR does not match the Tide Query is unknown This can happen if this function s logic does not match Git Hub s and does not indicate that the PR matches the query 
Returns expected status state and description If a PR is not mergeable we have to select a Tide Query to compare it against in order to generate a diff for the status description We choose the query for the repo that the PR is closest to meeting as determined by the number of unmet violated requirements 
target URL determines the URL used for more details in the status context on Git Hub If no PR dashboard is configured we will use the administrative Prow overview 
wait Sync waits until the minimum status update period has elapsed then syncs returning the sync start time If new Pool Pending is closed while waiting indicating a shutdown request this function returns immediately without syncing 
new Build Config returns a client and informer capable of mutating and monitoring the specified config 
New Client makes a new Client with the specified token and dry run status 
retry handles rate limiting and retry logic for a github API call 
depaginate adds depagination on top of the retry and rate limiting logic provided by retry 
New Help Agent constructs a new Help Agent 
Generate Plugin Help compiles and returns the help information for all plugins 
reverse Plugin Maps inverts the Configuration Plugins and Configuration External Plugins maps and expands any org strings to org repo strings The returned values map plugin names to the set of org repo strings they are enabled on 
orgs In Config gets all the org strings not org repo in config Plugins and config External Plugins 
Round Trip coalesces concurrent GET requests for the same URI by blocking the later requests until the first request returns and then sharing the response between all requests Notes Deadlock shouldn t be possible because the map lock is always acquired before response Waiter lock if both locks are to be held and we never hold multiple response Waiter locks 
Validate ensures that the set of options are self consistent and valid 
Add Flags binds flags to options 
gets the pull commit hash from metadata 
list Job Builds concurrently lists builds for the given job prefixes that have been run on a PR 
get PRBuild Data concurrently fetches metadata on each build of each job run on a PR 
parse Pull URL parses PR history URLs Expects this format pr history org org repo repo pr pr number 
get GCSDirs For PR returns a map from bucket names set of directories containing presubmit data 
 This function takes a container or snapshot from the local image server and exports it as an image 
image Create In Pool creates a new storage volume in a given storage pool for the image No entry in the images database will be created This implies that image Createin Pool should only be called when an image already exists in the database and hence has already a storage volume in at least one storage pool 
Update a single image The operation can be nil if no progress tracking is needed Returns whether the image has been updated 
Helper to delete an image file from the local images directory 
API endpoints 
Create the network on the system The with Database flag is used to decide whether to cleanup the database if an error occurs 
The network structs and functions 
Open Node creates a new Node object The fresh hook parameter is used by the daemon to mark all known patch names as applied when a brand new database is created The legacy Patches parameter is used as a mean to apply the legacy V V V V and V non db updates during the database upgrade sequence to avoid any change in semantics wrt the old logic see PR Return the newly created Node object and a Dump of the pre clustering data if we ve migrating to a cluster aware version 
Transaction creates a new Node Tx object and transactionally executes the node level database interactions invoked by the given function If the function returns no error all database changes are committed to the node level database otherwise they are rolled back 
Open Cluster creates a new Cluster object for interacting with the dqlite database name Basename of the database file holding the data Typically db bin dialer Function used to connect to the dqlite backend via g RPC SQL address Network address of this node or empty string dir Base LXD database directory e g var lib lxd database The address and api parameters will be used to determine if the cluster database matches our version and possibly trigger a schema update If the schema update can t be performed right now because some nodes are still behind an Upgrading error is returned 
For Local Inspection With Prepared Stmts is the same as For Local Inspection but it also prepares the statements used in auto generated database code 
Set Default Timeout sets the default go dqlite driver timeout 
Transaction creates a new Cluster Tx object and transactionally executes the cluster database interactions invoked by the given function If the function returns no error all database changes are committed to the cluster database database otherwise they are rolled back If Enter Exclusive has been called before calling Transaction will block until Exit Exclusive has been called as well to release the lock 
Enter Exclusive acquires a lock on the cluster db so any successive call to Transaction will block until Exit Exclusive has been called 
Exit Exclusive runs the given transaction and then releases the lock acquired with Enter Exclusive 
Close the database facade 
Tx Commit commits the given transaction 
 db a reference to a sql DB instance q is the database query inargs is an array of interfaces containing the query arguments outfmt is an array of interfaces containing the right types of output arguments i e var arg string var arg int outfmt interface arg arg The result will be an array one per output row of arrays one per output argument of interfaces containing pointers to the actual output arguments 
Parse Remote splits remote and object 
Get Container Server returns a Container Server struct for the remote 
Get Image Server returns a Image Server struct for the remote 
Initialize App Armor specific attributes 
Returns true if App Armor stacking support is available 
Add a device to a container 
Add a device to a profile 
Create the specified image alises updating those that already exist 
Get Existing Aliases returns the intersection between a list of aliases and all the existing ones 
String returns a suitable string representation for the status code 
Images Get returns the names of all images optionally only the public ones 
Images Get Expired returns the names of all images that have expired since the given time 
Image Source Insert inserts a new image source 
Image Source Get returns the image source with the given ID 
Image Source Get Cached Fingerprint tries to find a source entry of a locally cached image that matches the given remote details server protocol and alias Return the fingerprint linked to the matching entry if any 
Image Exists returns whether an image with the given fingerprint exists 
Image Get gets an Image object from the database If strict Matching is false The fingerprint argument will be queried with a LIKE query means you can pass a shortform and will get the full fingerprint There can never be more than one image with a given fingerprint as it is enforced by a UNIQUE constraint in the schema 
Image Get From Any Project returns an image matching the given fingerprint if it exists in any project 
Fill extra image fields such as properties and alias This is called after fetching a single row from the images table 
Image Locate returns the address of an online node that has a local copy of the given image or an empty string if the image is already available on this node If the image is not available on any online node an error is returned 
Image Associate Node creates a new entry in the images nodes table for tracking that the current node has the given image 
Image Delete deletes the image with the given ID 
Image Aliases Get returns the names of the aliases of all images 
Image Alias Get returns the alias with the given name in the given project 
Image Alias Rename renames the alias with the given ID 
Image Alias Delete deletes the alias with the given name 
Image Aliases Move changes the image ID associated with an alias 
Image Alias Add inserts an alias ento the database 
Image Alias Update updates the alias with the given ID 
Image Last Access Update updates the last use date field of the image with the given fingerprint 
Image Last Access Init inits the last use date field of the image with the given fingerprint 
Image Update updates the image with the given ID 
Image Insert inserts a new image 
Image Get Pools get the names of all storage pools on which a given image exists 
Image Get Pool Names From IDs get the names of all storage pools on which a given image exists 
Image Uploaded At updates the upload date column and an image row 
Images Get On Current Node returns all images that the current LXD node instance has 
Images Get By Node ID returns all images that the LXD node instance has with the given node id 
Image Get Nodes With Image returns the addresses of online nodes which already have the image 
Image Get Nodes Without Image returns the addresses of online nodes which don t have the image 
Add a new task to the group returning its index 
Start all the tasks in the group 
Stop all tasks in the group This works by sending a cancellation signal to all tasks of the group and waiting for them to terminate If a task is idle i e not executing its task function it will terminate immediately If a task is busy executing its task function the cancellation signal will propagate through the context passed to it and the task will block waiting for the function to terminate In case the given timeout expires before all tasks complete this method exits immediately and returns an error otherwise it returns nil 
zfs Is Enabled returns whether zfs backend is supported 
zfs Tool Version Get returns the ZFS tools version 
zfs Module Version Get returns the ZFS module version 
zfs Pool Volume Create creates a ZFS dataset with a set of given properties 
zfs Pool Volume Exists verifies if a specific ZFS pool or volume exists 
Network IDs Not Pending returns a map associating each network name to its ID Pending networks are skipped 
Network Config Add adds a new entry in the networks config table 
Network Node Join adds a new entry in the networks nodes table It should only be used when a new node joins the cluster when it s safe to assume that the relevant network has already been created on the joining node and we just need to track it 
Network Create Pending creates a new pending network on the node with the given name 
Network Created sets the state of the given network to Created 
Network Errored sets the state of the given network to Errored 
Get all networks matching the given WHERE filter if given 
Network Get returns the network with the given name 
Return the names of the nodes the given network is defined on 
Network Get Interface returns the network associated with the interface with the given name 
Network Config Get returns the config map of the network with the given ID 
Network Create creates a new network 
Network Update updates the network with the given name 
Network Update Description updates the description of the network with the given ID 
Network Config Clear resets the config of the network with the given ID associated with the node with the given ID 
Network Delete deletes the network with the given name 
Network Rename renames a network 
Get Containers returns a list of containers 
Get Containers Full returns a list of containers including snapshots backups and state 
Get Container returns the container entry for the provided name 
Create Container From Backup is a convenience function to make it easier to create a container from a backup 
Create Container requests that LXD creates a new container 
Create Container From Image is a convenience function to make it easier to create a container from an existing image 
Copy Container copies a container from a remote server Additional options can be passed using Container Copy Args 
Update Container updates the container definition 
Rename Container requests that LXD renames the container 
Exec Container requests that LXD spawns a command inside the container 
Get Container File retrieves the provided path from the container 
Create Container File tells LXD to create a file in the container 
Delete Container File deletes a file in the container 
Get Container Snapshot Names returns a list of snapshot names for the container 
Get Container Snapshots returns a list of snapshots for the container 
Get Container Snapshot returns a Snapshot struct for the provided container and snapshot names 
Create Container Snapshot requests that LXD creates a new snapshot for the container 
Copy Container Snapshot copies a snapshot from a remote server into a new container Additional options can be passed using Container Copy Args 
Migrate Container Snapshot requests that LXD prepares for a snapshot migration 
Update Container Snapshot requests that LXD updates the container snapshot 
Get Container State returns a Container State entry for the provided container name 
Update Container State updates the container to match the requested state 
Get Container Logfiles returns a list of logfiles for the container 
Get Container Logfile returns the content of the requested logfile Note that it s the caller s responsibility to close the returned Read Closer 
Get Container Metadata returns container metadata 
Set Container Metadata sets the content of the container metadata file 
Get Container Template Files returns the list of names of template files for a container 
Create Container Template File creates an a template for a container 
Delete Container Template File deletes a template file for a container 
Console Container requests that LXD attaches to the console device of a container 
Get Container Console Log requests that LXD attaches to the console device of a container Note that it s the caller s responsibility to close the returned Read Closer 
Delete Container Console Log deletes the requested container s console log 
Get Container Backups returns a list of backups for the container 
Get Container Backup returns a Backup struct for the provided container and backup names 
Create Container Backup requests that LXD creates a new backup for the container 
Rename Container Backup requests that LXD renames the backup 
Delete Container Backup requests that LXD deletes the container backup 
Get Container Backup File requests the container backup content 
Camel converts to camel case foo bar Foo Bar 
Snake converts to snake case Foo Bar foo bar 
rsync Copy copies a directory using rsync with the devices option 
Rsync Send sets up the sending half of an rsync to recursively send the directory pointed to by path over the websocket 
Rsync Recv sets up the receiving half of the websocket to rsync the other half set up by Rsync Send putting the contents in the directory specified by path 
Return the names of all available patches 
Patches begin here 
Shrink a database global logs db that grew unwildly due to a bug in the release 
The lvm thinpool name and lvm vg name config keys are node specific and need to be linked to nodes 
In case any of the objects images containers snapshots are missing storage volume configuration entries let s add the defaults 
Get Connection Info returns the basic connection information used to interact with the server 
Get HTTPClient returns the http client used for the connection This can be used to set custom http options 
Do performs a Request using macaroon authentication if set 
Raw Query allows directly querying the LXD API This should only be used by internal LXD tools 
Raw Websocket allows directly connection to LXD API websockets This should only be used by internal LXD tools 
Raw Operation allows direct querying of a LXD API endpoint returning background operations 
Internal functions 
Profile To API is a convenience to convert a Profile db struct into an API profile struct 
Profiles returns a string list of profiles 
Profile Get returns the profile with the given name 
Profiles Get returns the profiles with the given names in the given project 
Profile Config gets the profile configuration map from the DB 
Profile Config Clear resets the config of the profile with the given ID 
Profile Config Add adds a config to the profile with the given ID 
Profile Containers Get gets the names of the containers associated with the profile with the given name 
Profile Cleanup Leftover removes unreferenced profiles 
Profiles Expand Config expands the given container config with the config values of the given profiles 
Profiles Expand Devices expands the given container devices with the devices defined in the given profiles 
Server handling functions Get Server returns the server status as a Server struct 
Update Server updates the server status to match the provided Server struct 
Has Extension returns true if the server supports a given API extension 
Get Server Resources returns the resources available to a given LXD server 
Use Project returns a client that will use a specific project 
Opens the node level database with the correct parameters for LXD 
Bootstrap turns a non clustered LXD instance into the first and leader node of a new LXD cluster This instance must already have its cluster https address set and be listening on the associated network address 
Accept a new node and add it to the cluster This instance must already be clustered Return an updated list raft database nodes possibly including the newly accepted node 
Join makes a non clustered LXD node join an existing cluster It s assumed that Accept was previously called against the target node which handed the raft server ID The cert parameter must contain the keypair CA material of the cluster being joined 
Rebalance the raft cluster trying to see if we have a spare online node that we can promote to database node if we are below membership Max Raft Nodes If there s such spare node return its address as well as the new list of raft nodes 
Promote makes a LXD node which is not a database node become part of the raft cluster 
Leave a cluster If the force flag is true the node will leave even if it still has containers and images The node will only leave the raft cluster and won t be removed from the database That s done by Purge Upon success return the address of the leaving node 
Purge removes a node entirely from the cluster database 
List the nodes of the cluster 
Count is a convenience for checking the current number of nodes in the cluster 
Enabled is a convenience that returns true if clustering is enabled on this node 
Check that node related preconditions are met for bootstrapping or joining a cluster 
Check that cluster related preconditions are met for bootstrapping or joining a cluster 
Check that cluster related preconditions are met for accepting a new node 
Check that cluster related preconditions are met for leaving a cluster 
Check that there is no left over cluster certificate in the LXD var dir of this node 
Config Load loads a new Config object with the current node local configuration values fetched from the database An optional list of config value triggers can be passed each config key must have at most one trigger 
Replace the current configuration with the given values 
Patch changes only the configuration keys in the given map 
HTTPSAddress is a convenience for loading the node configuration and returning the value of core https address 
Certificates Get returns all certificates from the DB as Cert Base Info objects 
Certificate Get gets an Cert Base Info object from the database The argument fingerprint will be queried with a LIKE query means you can pass a shortform and will get the full fingerprint There can never be more than one image with a given fingerprint as it is enforced by a UNIQUE constraint in the schema 
Cert Save stores a Cert Base Info object in the db it will ignore the ID field from the Cert Info 
Cert Delete deletes a certificate from the db 
Cert Update updates the certificate with the given fingerprint 
Create a new net Listener bound to the unix socket of the devlxd endpoint 
Create a raft instance and all its dependencies to be used as backend for the dqlite driver running on this LXD node If this node should not serve as dqlite node nil is returned The raft instance will use an in memory transport if clustering is not enabled on this node The cert Info parameter should contain the cluster TLS keypair and optional CA certificate The latency parameter is a coarse grain measure of how fast reliable network links are This is used to tweak the various timeouts parameters of the raft algorithm See the raft Config structure for more details A value of means use the default values from hashicorp s raft package Values closer to reduce the values of the various timeouts useful when running unit tests in memory 
Create a new raft Factory instantiating all needed raft dependencies 
Servers returns the servers that are currently part of the cluster If this raft instance is not the leader an error is returned 
Handler Func can be used to handle HTTP requests performed against the LXD API Raft Endpoint internal raft in order to join leave form the raft cluster If it returns nil it means that this node is not supposed to expose a raft endpoint over the network because it s running as a non clustered single node 
Shutdown raft and any raft related resource we have instantiated 
Create a rafthttp Dial function that connects over TLS using the given cluster and optionally CA certificate both as client and remote certificate 
Create a network raft transport that will handle connections using a rafthttp Handler 
Create a base raft configuration tweaked for a network with the given latency measure 
Helper to bootstrap the raft cluster if needed 
CPUResource returns the system CPU information 
Memory Resource returns the system memory information 
Get Operation UUIDs returns a list of operation uuids 
Get Operations returns a list of Operation struct 
Get Operation returns an Operation entry for the provided uuid 
Get Operation Websocket returns a websocket connection for the provided operation 
Delete Operation deletes cancels a running operation 
Useful functions for unreliable backends 
Detect whether LXD already uses the given storage pool 
 storage pools name volumes List all storage volumes attached to a given storage pool 
 storage pools name volumes type List all storage volumes of a given volume type for a given storage pool 
 storage pools name volumes type Create a storage volume in a given storage pool 
 storage pools name volumes type name Rename a storage volume of a given volume type in a given storage pool 
 storage pools pool volumes type name Get storage volume of a given volume type on a given storage pool 
 storage pools pool volumes type name 
 storage pools pool volumes type name 
Project URIs returns all available project URIs 
Project List returns all available projects 
Project Get returns the project with the given key 
Project Exists checks if a project with the given key exists 
Project Create adds a new project to the database 
Project Used By Ref returns entities used by projects 
Project Rename renames the project matching the given key parameters 
Project Delete deletes the project matching the given key parameters 
Password Check validates the provided password against the encoded secret 
Load Cert reads the LXD server certificate from the given var dir If a cluster certificate is found it will be loaded instead 
Write Cert writes the given material to the appropriate certificate files in the given LXD var directory 
New Daemon returns a new Daemon object with the given configuration 
Default Daemon returns a new un initialized Daemon object with default values 
Allow Project Permission is a wrapper to check access against the project its features and RBAC permission 
Convenience function around Authenticate 
Authenticate validates an incoming http Request It will check over what protocol it came what type of request it is and will validate the TLS certificate or Macaroon This does not perform authorization only validates authentication 
State creates a new State instance linked to our internal db and os 
Unix Socket returns the full path to the unix socket file that this daemon is listening on Used by tests 
Stop stops the shared daemon 
Setup external authentication 
Setup RBAC 
Setup MAAS 
Create a database connection and perform any updates needed 
Let s say we want to send the a container a including snapshots snap and snap on storage pool pool from LXD l to LXD l on storage pool pool The pool layout on l would be pool container a pool container a 
Write JSON encodes the body as JSON and sends it back to the client 
Etag Hash hashes the provided data and returns the sha 
Etag Check validates the hash of the current state with the hash provided by the client 
HTTPClient returns an http Client using the given certificate and proxy 
Check Trust State checks whether the given client certificate is trusted i e it has a valid time span and it belongs to the given list of trusted certificates 
Is Recursion Request checks whether the given HTTP request is marked with the recursion flag in its form values 
Listen Addresses returns a list of host port combinations at which this machine can be reached 
Get Listeners returns the socket activated network listeners if any The start parameter must be Systemd Listen FDs Start except in unit tests see the docstring of Systemd Listen FDs Start below 
Perform a database dump 
Execute queries 
Key Pair And CA returns a Cert Info object with a reference to the key pair and optionally CA certificate located in the given directory and having the given name prefix The naming conversion for the various files is prefix crt public key prefix key private key prefix ca CA certificate If no public private key files are found a new key pair will be generated and saved on disk If a CA certificate is found it will be returned as well as second return value otherwise it will be nil 
Public Key is a convenience to encode the underlying public key to ASCII 
Private Key is a convenience to encode the underlying private key 
Fingerprint returns the fingerprint of the public key 
 Generate a list of names for which the certificate will be valid This will include the hostname and ip address 
Gen Cert will create and populate a certificate file and a key file 
Generate Mem Cert creates client or server certificate and key pair returning them as byte arrays in memory 
Print Server Info prints out information about the server 
Launch Containers launches a set of containers 
Create Containers create the specified number of containers 
Get Containers returns containers created by the benchmark 
Start Containers starts containers created by the benchmark 
Params returns a parameters expression with the given number of placeholders E g Params Useful for IN and VALUES expressions 
Set the value of a query parameter in the given URI 
Image handling functions Get Images returns a list of available images as Image structs 
Get Image Fingerprints returns a list of available image fingerprints 
Get Image returns an Image struct for the provided fingerprint 
Get Image File downloads an image from the server returning an Image File Request struct 
Get Image Secret is a helper around Create Image Secret that returns a secret for the image 
Get Private Image is similar to Get Image but allows passing a secret download token 
Get Private Image File is similar to Get Image File but allows passing a secret download token 
Get Image Aliases returns the list of available aliases as Image Aliases Entry structs 
Get Image Alias returns an existing alias as an Image Aliases Entry struct 
Create Image requests that LXD creates copies or import a new image 
try Copy Image iterates through the source server URLs until one lets it download the image 
Copy Image copies an image from a remote server Additional options can be passed using Image Copy Args 
Update Image updates the image definition 
Delete Image requests that LXD removes an image from the store 
Refresh Image requests that LXD issues an image refresh 
Create Image Alias sets up a new image alias 
Update Image Alias updates the image alias definition 
Rename Image Alias renames an existing image alias 
Delete Image Alias removes an alias from the LXD image store 
Open the node local database object 
Ensure Schema applies all relevant schema updates to the node local database Return the initial schema version found before starting the update along with any error occurred 
Filesystem Detect returns the filesystem on which the passed in path sits 
Schema for the local database 
Schema updates begin here Copy core https address to cluster https address in case this node is clustered 
Architecture Get Local returns the local hardware architecture 
New Controller returns a new Controller using the specific MAAS server and machine 
Create Container defines a new MAAS device for the controller 
Defined Container returns true if the container is defined in MAAS 
Update Container updates the MAAS device s interfaces with the new provided state 
Rename Container renames the MAAS device for the container without releasing any allocation 
Delete Container removes the MAAS device for the container 
New From Map creates a new schema Schema with the updates specified in the given map The keys of the map are schema versions that when upgraded will trigger the associated Update value It s required that the minimum key in the map is and if key N is present then N is present too with N i e there are no missing versions NOTE the regular New constructor would be formally enough but for extra clarity we also support a map that indicates the version explicitly see also PR 
Add a new update to the schema It will be appended at the end of the existing series 
Ensure makes sure that the actual schema in the given database matches the one defined by our updates All updates are applied transactionally In case any error occurs the transaction will be rolled back and the database will remain unchanged A update will be applied only if it hasn t been before currently applied updates are tracked in the a shema table which gets automatically created If no error occurs the integer returned by this method is the initial version that the schema has been upgraded from 
Dump returns a text of SQL commands that can be used to create this schema from scratch in one go without going thorugh individual patches essentially flattening them It requires that all patches in this schema have been applied otherwise an error will be returned 
Trim the schema updates to the given version included Updates with higher versions will be discarded Any fresh schema dump previously set will be unset since it s assumed to no longer be applicable Return all updates that have been trimmed 
Exercise Update is a convenience for exercising a particular update of a schema It first creates an in memory SQLite database then it applies all updates up to the one with given version excluded and optionally executes the given hook for populating the database with test data Finally it applies the update with the given version returning the database handle for further inspection of the resulting state 
Ensure that the schema exists 
Return the highest update version currently applied Zero means that no updates have been applied yet 
Apply any pending update that was not yet applied 
Check that the given list of update version numbers doesn t have holes that is each version equal the preceding version plus 
Check that all the given updates are applied 
Format the given SQL statement in a human readable way In particular make sure that each column definition in a CREATE TABLE clause is in its own row since SQLite dumps occasionally stuff more than one column in the same line 
File Copy copies a file overwriting the target if it exists 
This uses ssize t llistxattr const char path char list size t size to handle symbolic links should it in the future be possible to set extended attributed on symlinks If path is a symbolic link the extended attributes associated with the link itself are retrieved 
Get All Xattr retrieves all extended attributes associated with a file directory or symbolic link 
Detect whether err is an errno 
Uname returns Utsname as strings 
This function recreates an rbd container including its snapshots It recreates the dependencies between the container and the snapshots create an empty rbd storage volume for each snapshot dump the contents into the empty storage volume and after each dump take a snapshot of the rbd storage volume dump the container contents into the rbd storage volume 
This function recreates an rbd container including its snapshots It recreates the dependencies between the container and the snapshots create an empty rbd storage volume for each snapshot dump the contents into the empty storage volume and after each dump take a snapshot of the rbd storage volume dump the container contents into the rbd storage volume 
Register Stmt register a SQL statement Registered statements will be prepared upfront and re used to speed up execution Return a unique registration code 
Prepare Stmts prepares all registered statements and returns an index from statement code to prepared statement object 
New Gateway creates a new Gateway for managing access to the dqlite cluster When a new gateway is created the node level database is queried to check what kind of role this node plays and if it s exposed over the network It will initialize internal data structures accordingly for example starting a dqlite driver if this node is a database node After creation the Daemon is expected to expose whatever http handlers the Handler Funcs method returns and to access the dqlite cluster using the g RPC dialer returned by the Dialer method 
Handler Funcs returns the HTTP handlers that should be added to the REST API endpoint in order to handle database related requests There are two handlers one for the internal raft endpoint and the other for internal db which handle respectively raft and g RPC SQL requests These handlers might return either because this LXD node is a non clustered node not available over the network or because it is not a database node part of the dqlite cluster 
Dial Func returns a dial function that can be used to connect to one of the dqlite nodes 
Shutdown this gateway stopping the g RPC server and possibly the raft factory 
Sync dumps the content of the database to disk This is useful for inspection purposes and it s also needed by the activateifneeded command so it can inspect the database in order to decide whether to activate the daemon or not 
Reset the gateway shutting it down and starting against from scratch using the given certificate This is used when disabling clustering on a node 
Leader Address returns the address of the current raft leader 
Initialize the gateway creating a new raft factory and g RPC server if this node is a database node and a g RPC dialer 
Wait for the raft node to become leader Should only be used by Bootstrap since we know that we ll self elect 
Return information about the LXD nodes that a currently part of the raft cluster as configured in the raft log It returns an error if this node is not the leader 
Return the addresses of the raft nodes as stored in the node level database These values might leg behind the actual values and are refreshed periodically during heartbeats 
Create a dial function that connects to the given listener 
Dqlite Log redirects dqlite s logs to our own logger 
Metadata As Map parses the Response metadata into a map 
Metadata As Operation turns the Response metadata into an Operation 
Metadata As String Slice parses the Response metadata into a slice of string 
Metadata As Struct parses the Response metadata into a provided struct 
Load reads current content of the filename and loads records 
Write writes current records to file 
Add Record adds a record to the report 
Load Config reads the configuration from the config path if the path does not exist it returns a default configuration 
Save Config writes the provided configuration to the config file 
Abs resolves a filename relative to the base directory Absolute paths are allowed When there s no base dir set the absolute path to the filename will be calculated based on either the provided base directory which might be a path of a template which includes another template or the current working directory 
Get reads the path s content from your local filesystem 
Config Path returns a joined path of the configuration directory and passed arguments 
Server Cert Path returns the path for the remote s server certificate 
New Config returns a Config optionally using default remotes 
Determine Raft Node figures out what raft node ID and address we have if any This decision is based on the value of the cluster https address config key and on the rows in the raft nodes table both stored in the node level SQLite database The following rules are applied If no cluster https address config key is set this is a non clustered node and the returned Raft Node will have ID but no address to signal that the node should setup an in memory raft cluster where the node itself is the only member and leader If cluster https address config key is set but there is no row in the raft nodes table this is a brand new clustered node that is joining a cluster and same behavior as the previous case applies If cluster https address config key is set and there is at least one row in the raft nodes table then this node is considered a raft node if cluster https address matches one of the rows in raft nodes In that case the matching db Raft Node row is returned otherwise nil 
Check if CRIU supports pre dumping and number of pre dump iterations 
The function read Criu Stats Dump reads the CRIU stats dump file in path and returns the pages written pages skipped parent error 
The function pre Dump Loop is the main logic behind the pre copy migration This function contains the actual pre dump the corresponding rsync transfer and it tells the outer loop to abort if the threshold of memory pages transferred by pre dumping has been reached 
Get Connection Info returns the basic connection information used to interact with the server 
Return a new root command 
APIExtensions Count returns the number of available API extensions 
Dot Go writes name go source file in the package of the calling function containing SQL statements that match the given schema updates The name go file contains a flattened render of all given updates and can be used to initialize brand new databases using Schema Fresh 
Select URIs returns a list of LXD API URI strings for the resource yielded by the given query The f argument must be a function that formats the entity URI using the columns yielded by the query 
Select Strings executes a statement which must yield rows with a single string column It returns the list of column values 
Insert Strings inserts a new row for each of the given strings using the given insert statement template which must define exactly one insertion column and one substitution placeholder for the values For example Insert Strings tx INSERT INTO foo name VALUES s string bar 
Execute the given query and ensure that it yields rows with a single column of the given database type For every row yielded execute the given scanner 
Caller Stack Handler returns a Handler that adds a stack trace to the context with key stack The stack trace is formated as a space separated list of call sites inside matching s The most recent call site is listed first Each call site is formatted according to format See the documentation of log stack Call Format for the list of supported formats 
Lazy Handler writes all values to the wrapped handler after evaluating any lazy functions in the record s context It is already wrapped around Stream Handler and Syslog Handler in this library you ll only need it if you write your own Handler 
Format implements fmt Formatter with support for the following verbs s source file d line number n function name v equivalent to s d It accepts the and flags for most of the verbs as follows s path of source file relative to the compile time GOPATH s full path of source file n import path qualified function name v equivalent to s d v equivalent to s d 
Callers returns a Trace for the current goroutine with element identifying the calling function 
name returns the import path qualified name of the function containing the call 
Format implements fmt Formatter by printing the Trace as square brackes surrounding a space separated list of Calls each formatted with the supplied verb and options 
Trim Below returns a slice of the Trace with all entries below pc removed 
Trim Above returns a slice of the Trace with all entries above pc removed 
Trim Below Name returns a slice of the Trace with all entries below the lowest with function name name removed 
Trim Above Name returns a slice of the Trace with all entries above the highest with function name name removed 
Trim Runtime returns a slice of the Trace with the topmost entries from the go runtime removed It considers any calls originating from files under GOROOT as part of the runtime 
Shift Owner updates uid and gid for a file when entering exiting a namespace 
Get Caps extracts the list of capabilities effective on the file 
Set Caps applies the caps for a particular root uid 
Shift ACL updates uid and gid for file ACLs when entering exiting a namespace 
Read in Progress Reader is the same as io Read 
Supported check if the given path supports project quotas 
Get Project returns the project quota ID for the given path 
Set Project sets the project quota ID for the given path 
Delete Project unsets the project id from the path and clears the quota for the project id 
Get Project Usage returns the current consumption 
Set Project Quota sets the quota on the project id 
Load a backup from the database 
Create a new backup 
Rename renames a container backup 
Delete removes a container backup 
fix Backup Storage Pool changes the pool information in the backup yaml This is done only if the provided pool doesn t exist In this case the pool of the default profile will be used 
Count returns the number of rows in the given table 
Count All returns a map associating each table name in the database with the total count of its rows 
Init TLSConfig returns a tls Config populated with default encryption parameters This is used as baseline config for both client and server certificates used by LXD 
Copy a container on a storage pool that does use a thinpool 
Copy a container on a storage pool that does not use a thinpool 
Copy an lvm container 
Copy an LVM custom volume 
Get Image Fingerprints returns a list of available image fingerprints 
Get Image returns an Image struct for the provided fingerprint 
Get Image File downloads an image from the server returning an Image File Response struct 
Get Private Image isn t relevant for the simplestreams protocol 
Get Private Image File isn t relevant for the simplestreams protocol 
Get Image Alias Names returns the list of available alias names 
Get Image Alias returns an existing alias as an Image Aliases Entry struct 
Proto Recv gets a protobuf message from a websocket 
Proto Send sends a protobuf message over a websocket 
Proto Send Control sends a migration control message over a websocket 
Load Pre Clustering Data loads all the data that before the introduction of LXD clustering used to live in the node level database This is used for performing a one off data migration when a LXD instance is upgraded from a version without clustering to a version that supports clustering since in those version all data lives in the cluster database regardless of whether clustering is actually on or off 
Import Pre Clustering Data imports the data loaded with Load Pre Clustering Data 
Insert a row in one of the nodes association tables storage pools nodes networks nodes images nodes 
The pty has been switched to raw mode so we will only ever read a single byte The buffer size is therefore uninteresting to us 
Fetch information about the containers on the given remote node using the rest API and with a timeout of seconds 
Dev Lxd Server creates an http Server capable of handling requests against the dev lxd Unix socket endpoint created inside containers 
 I also don t see that golang exports an API to get at the underlying FD but we need it to get at SO PEERCRED so let s grab it 
 As near as I can tell there is no nice way of extracting an underlying net Conn or in our case net Unix Conn from an http Request or Response Writer without hijacking it Since we want to send and receive unix creds to figure out which container this request came from we need to do this https groups google com forum topic golang nuts FWd FXJa QA 
Retry wraps a function that interacts with the database and retries it in case a transient error is hit This should by typically used to wrap transactions 
Is Retriable Error returns true if the given error might be transient and the interaction can be safely retried 
volume Used By append volume Used By fmt Sprintf s containers s version APIVersion ct 
storage Pool Volume Snapshots Get returns a list of snapshots of the form volume snapshot name 
App Armor Profile returns the current apparmor profile 
 LXD DIR storage pools pool containers snapshots 
Functions dealing with storage volumes 
Functions dealing with container storage 
And this function is why I started hating on btrfs 
Container Snapshot Rename renames a snapshot of a container 
Needed for live migration where an empty snapshot needs to be created before rsyncing into it 
btrfs Pool Volumes Delete is the recursive variant on btrfs Pool Volume Delete it first deletes subvolumes of the subvolume and then the subvolume itself 
 btrfs Snapshot creates a snapshot of source to dest the result will be readonly if readonly is True 
is Btrfs Sub Volume returns true if the given Path is a btrfs subvolume else false 
Safe Load is a wrapper around Load that does not error when invalid keys are found and just logs warnings instead Other kinds of errors are still returned 
Select Config executes a query statement against a config table which must have key and value columns By default this query returns all keys but additional WHERE filters can be specified Returns a map of key names to their associated values 
Update Config updates the given keys in the given table Config keys set to empty values will be deleted 
Insert or updates the key value rows of the given config table 
Delete the given key rows from the given config table 
Format Section properly indents a text section 
Get Projects returns a list of available Project structs 
Get Project returns a Project entry for the provided name 
Create Project defines a new container project 
Update Project updates the project to match the provided Project struct 
Rename Project renames an existing project entry 
Read behaves like io Reader Read but will retry on EAGAIN 
Write behaves like io Writer Write but will retry on EAGAIN 
New Canceler returns a new Canceler struct 
Cancelable indicates whether there are operations that support cancelation 
Cancel will attempt to cancel all ongoing operations 
Cancelable Download performs an http request and allows for it to be canceled at any time 
Return information about the cluster 
Fetch information about all node specific configuration keys set on the storage pools and networks of this cluster 
Depending on the parameters passed and on local state this endpoint will either bootstrap a new cluster if this node is not clustered yet request to join an existing cluster disable clustering on a node The client is required to be trusted 
Disable clustering on a node 
Initialize storage pools and networks on this node We pass to LXD client instances one connected to ourselves the joining node and one connected to the target cluster node to join 
Perform a request to the internal cluster accept endpoint to check if a new mode can be accepted into the cluster and obtain joining information such as the cluster private certificate 
This function is used to notify the leader that a node was removed it will decide whether to promote a new node as database node 
Used to update the cluster after a database node has been removed and possibly promote another one as database node 
Used to promote the local non database node to be a database one 
Packages returns the the AST packages in which to search for structs By default it includes the lxd db and shared api packages 
Filters parses all filtering statement defined for the given entity It returns all supported combinations of filters sorted by number of criteria 
Parse the structure declaration with the given name found in the given Go package 
Find the Struct Type node for the structure with the given name 
Extract field information from the given structure 
Profile handling functions Get Profile Names returns a list of available profile names 
Get Profiles returns a list of available Profile structs 
Get Profile returns a Profile entry for the provided name 
Create Profile defines a new container profile 
Update Profile updates the profile to match the provided Profile struct 
Rename Profile renames an existing profile entry 
Load creates a new configuration Map with the given schema and initial values It is meant to be called with a set of initial values that were set at a previous time and persisted to some storage like a database If one or more keys fail to be loaded return an Error List describing what went wrong Non failing keys are still loaded in the returned Map 
Change the values of this configuration Map Return a map of key value pairs that were actually changed If some keys fail to apply details are included in the returned Error List 
Dump the current configuration held by this Map Keys that match their default value will not be included in the dump Also if a Key has its Hidden attribute set to true it will be rendered as true for obfuscating the actual value 
Get Raw returns the value of the given key which must be of type String 
Get String returns the value of the given key which must be of type String 
Get Bool returns the value of the given key which must be of type Bool 
Get Int returns the value of the given key which must be of type Int 
Update the current values in the map using the newly provided ones Return a list of key names that were actually changed and an Error List with possible errors 
Set or change an individual key Empty string means delete this value and effectively revert it to the default Return a boolean indicating whether the value has changed and error if something went wrong 
Does Schema Table Exist return whether the schema table is present in the database 
Return all versions in the schema table in increasing order 
Return a list of SQL statements that can be used to create all tables in the database 
Create the schema table 
Insert a new version into the schema table 
Read the given file if it exists and executes all queries it contains 
New State returns a new State object with the given database and operating system components 
Helper functions 
Loader functions 
Unload is called by the garbage collector 
Create a container struct without initializing it 
Initialize storage interface for this container 
Config handling 
setup Unix Device creates the unix device and sets up the necessary low level liblxc configuration items 
Start functions 
Stop functions 
On Network Up is called by the LXD callhook when the LXC network up script is run 
setup Host Veth Device configures a nic device s host side veth settings 
Freezer functions 
Get lxc container state with second timeout If we don t get a reply assume the lxc monitor is hung 
Storage functions 
Kill this function as soon as zfs is fixed 
Mount handling 
Check if the unix device already exists 
Unix devices handling 
Network device handling 
Disk device handling 
Block I O limits 
Network I O limits 
set Network Routes applies any static routes configured from the host to the container nic 
Various container paths 
Internal MAAS handling 
get System Handler on Linux writes messages to syslog 
Fallback for old drivers which don t provide Device Minor 
Return string for minor number of nvidia device corresponding to the given pci id 
Get Logger returns a logger suitable for using as logger Log 
Set Logger installs the given logger as global logger It returns a function that can be used to restore whatever logger was installed beforehand 
Wait Record blocks until a log Record is received on the given channel It returns the emitted record or nil if no record was received within the given timeout Useful in conjunction with log Channel Handler for asynchronous testing 
Add Context will return a copy of the logger with extra context added 
New Dotted Version returns a new Version 
Parse parses a string starting with a dotted version and returns it 
String returns version as a string 
Compare returns result of comparison between two versions 
prepare Loop Dev detects and sets up a loop device for source It returns an open file descriptor to the free loop device and the path of the free loop device It s the callers responsibility to close the open file descriptor 
Create the default profile of a project 
Common logic between PUT and PATCH 
Check if a project is empty 
Add the project prefix when the given project name is not default 
Certificate handling functions Get Certificate Fingerprints returns a list of certificate fingerprints 
Get Certificates returns a list of certificates 
Get Certificate returns the certificate entry for the provided fingerprint 
Create Certificate adds a new certificate to the LXD trust store 
Update Certificate updates the certificate definition 
Delete Certificate removes a certificate from the LXD trust store 
Return a list of templates used in a container or the content of a template 
Add a container template file 
Delete a container template 
Return the full path of a container template 
Error implements the error interface 
Error List implements the error interface 
Add adds an Error with given key name value and reason 
Update Schema updates the schema go file of the cluster and node databases 
Like do Profile Update but does not update the database since it was already updated by do Profile Update itself called on the notifying node 
Profile update of a single container 
Query the db for information about containers associated with the given profile 
Cancelable Wait waits for an operation and cancel it on SIGINT SIGTERM 
Get Network Names returns a list of network names 
Get Networks returns a list of Network struct 
Get Network returns a Network entry for the provided name 
Get Network Leases returns a list of Network struct 
Get Network State returns metrics and information on the running network 
Create Network defines a new network using the provided Network struct 
Update Network updates the network to match the provided Network struct 
Rename Network renames an existing network entry 
Open the cluster database object The name argument is the name of the cluster database It defaults to db bin but can be overwritten for testing The dialer argument is a function that returns a g RPC dialer that can be used to connect to a database node using the g RPC SQL package 
Ensure Schema applies all relevant schema updates to the cluster database Before actually doing anything this function will make sure that all nodes in the cluster have a schema version and a number of API extensions that match our one If it s not the case we either return an error if some nodes have version greater than us and we need to be upgraded or return false and no error if some nodes have a lower version and we need to wait till they get upgraded and restarted 
URLEncode encodes a path and query parameters to a URL 
Is Unix Socket returns true if the given path is either a Unix socket or a symbolic link pointing at a Unix socket 
Host Path returns the host path for the provided path On a normal system this does nothing When inside of a snap environment returns the real path 
Var Path returns the provided path elements joined by a slash and appended to the end of LXD DIR which defaults to var lib lxd 
Cache Path returns the directory that LXD should its cache under If LXD DIR is set this path is LXD DIR cache otherwise it is var cache lxd 
Returns a random base encoded string from crypto rand 
File Move tries to move a file by using os Rename if that fails it tries to copy the file and remove the source 
File Copy copies a file overwriting the target if it exists 
Dir Copy copies a directory recursively overwriting the target if it exists 
String Map Has String Key returns true if any of the supplied keys are present in the map 
Deep Copy copies src to dest by using encoding gob so its not that fast 
Spawn the editor with a temporary YAML file for editing configs 
Parse a size string in bytes e g k B or GB into the number of bytes it represents Supports suffixes up to EB 
Remove Duplicates From String removes all duplicates of the string sep from the specified string s Leading and trailing occurrences of sep are NOT removed duplicate leading trailing are Performs poorly if there are multiple consecutive redundant separators 
Write Temp File creates a temp file with the specified content 
Escape Path Fstab escapes a path fstab style This ensures that getmntent r and friends can correctly parse stuff like some wacky path with spaces some wacky target with spaces 
Render Template renders a pongo template 
Every returns a Schedule that always returns the given time interval 
Only initialize the minimal information we need about a given storage type 
Currently only used for loop backed LVM storage pools Can be called without overhead since it is essentially a noop for non loop backed LVM storage pools 
Dump returns a SQL text dump of all rows across all tables similar to sqlite s dump feature 
Return a map from table names to their schema definition taking a full schema SQL text generated with schema Schema Dump 
Dump a single table returning a SQL text containing statements for its schema and data 
Project Has Profiles is a helper to check if a project has the profiles feature enabled 
Project Names returns the names of all available projects 
Project Map returns the names and ids of all available projects 
Project Has Images is a helper to check if a project has the images feature enabled 
Project Update updates the project matching the given key parameters 
Get Cluster returns information about a cluster If this client is not trusted the password must be supplied 
Update Cluster requests to bootstrap a new cluster or join an existing one 
Delete Cluster Member makes the given member leave the cluster gracefully or not depending on the force flag 
Get Cluster Member Names returns the URLs of the current members in the cluster 
Get Cluster Members returns the current members of the cluster 
Get Cluster Member returns information about the given member 
Rename Cluster Member changes the name of an existing member 
Get State returns the current state of a terminal which may be useful to restore the terminal after a signal 
Make Raw put the terminal connected to the given file descriptor into raw mode and returns the previous state of the terminal so that it can be restored 
Restore restores the terminal connected to the given file descriptor to a previous state 
Add Handler adds a function to be called whenever an event is received 
Remove Handler removes a function to be called whenever an event is received 
Disconnect must be used once done listening for events 
Compare Versions the versions of two LXD nodes A version consists of the version the node s schema and the number of API extensions it supports Return if they equal if the first version is greater than the second and if the second is greater than the first Return an error if inconsistent versions are detected for example the first node s schema is greater than the second s but the number of extensions is smaller 
Has Client Certificate will return true if a client certificate has already been generated 
Generate Client Certificate will generate the needed client crt and client key if needed 
Load Module loads the kernel module with the given name by invoking modprobe 
Parse runs the Go parser against the given package name 
Pprof Address returns the network addresss of the pprof endpoint or an empty string if there s no pprof endpoint 
Pprof Update Address updates the address for the pprof endpoint shutting it down and restarting it 
New Method return a new method code snippet for executing a certain mapping 
Generate the desired method 
Populate a field consisting of a slice of objects referencing the entity This information is available by joining a the view or table associated with the type of the referenced objects which must contain the natural key of the entity 
Storage Pools Node Config returns a map associating each storage pool name to its node specific config values i e the ones where node id is not NULL 
Storage Pool ID returns the ID of the pool with the given name 
Storage Pool Driver returns the driver of the pool with the given ID 
Storage Pool IDs Not Pending returns a map associating each storage pool name to its ID Pending storage pools are skipped 
Storage Pool Node Join adds a new entry in the storage pools nodes table It should only be used when a new node joins the cluster when it s safe to assume that the relevant pool has already been created on the joining node and we just need to track it 
Storage Pool Node Join Ceph updates internal state to reflect that node ID is joining a cluster where pool ID is a ceph pool 
Storage Pool Config Add adds a new entry in the storage pools config table 
Storage Pool Create Pending creates a new pending storage pool on the node with the given name 
Storage Pool Created sets the state of the given pool to Created 
Storage Pool Errored sets the state of the given pool to Errored 
Storage Pool Node Configs returns the node specific configuration of all nodes grouped by node name for the given pool ID If the storage pool is not defined on all nodes an error is returned 
Get all storage pools matching the given WHERE filter if given 
Storage Pools Get Drivers returns the names of all storage volumes attached to a given storage pool 
Storage Pool Get ID returns the id of a single storage pool 
Storage Pool Get returns a single storage pool 
Return the names of the nodes the given pool is defined on 
Storage Pool Config Get returns the config of a storage pool 
Storage Pool Create creates new storage pool 
Add new storage pool config 
Storage Pool Driver returns the driver of the pool with the given ID 
Storage Pool Update updates a storage pool 
Storage Pool Config Clear deletes the storage pool config 
Storage Pool Delete deletes storage pool 
Storage Pool Volumes Get Names gets the names of all storage volumes attached to a given storage pool 
Storage Pool Volumes Get returns all storage volumes attached to a given storage pool on any node 
Storage Pool Node Volumes Get returns all storage volumes attached to a given storage pool on the current node 
Returns all storage volumes attached to a given storage pool on the given node 
Storage Pool Volumes Get Type get all storage volumes attached to a given storage pool of a given volume type on the given node 
Storage Pool Volume Snapshots Get Type get all snapshots of a storage volume attached to a given storage pool of a given volume type on the given node 
Storage Pool Node Volumes Get Type returns all storage volumes attached to a given storage pool of a given volume type on the current node 
Storage Pool Volume Get Type returns a single storage volume attached to a given storage pool of a given type on the node with the given ID 
Storage Pool Node Volume Get Type gets a single storage volume attached to a given storage pool of a given type on the current node 
Storage Pool Node Volume Get Type By Project gets a single storage volume attached to a given storage pool of a given type on the current node in the given project 
Storage Pool Volume Update updates the storage volume attached to a given storage pool 
Storage Pool Volume Delete deletes the storage volume attached to a given storage pool 
Storage Pool Volume Rename renames the storage volume attached to a given storage pool 
This a convenience to replicate a certain volume change to all nodes if the underlying driver is ceph 
Storage Pool Volume Create creates a new storage volume attached to a given storage pool 
Storage Pool Volume Get Type ID returns the ID of a storage volume on a given storage pool of a given storage volume type on the given node 
Storage Pool Node Volume Get Type ID get the ID of a storage volume on a given storage pool of a given storage volume type on the current node 
Storage Pool Volume Type To Name converts a volume integer type code to its human readable name 
Devices Add adds a new device 
Devices returns the devices matching the given filters 
Patches returns the names of all patches currently applied on this node 
Patches Mark Applied marks the patch with the given name as applied on this node 
Return Go type of the given database entity 
Return the name of the Post struct for the given entity 
Return the name of the global variable holding the registration code for the given kind of statement aganst the given entity 
Return an expression evaluating if a filter should be used based on active criteria 
Return the code for a dest function to be passed as parameter to query Select Objects in order to scan a single row 
Return an index type of the form map string map string typ with one level of indexing for each given field 
Compare Configs compares two config maps and returns an error if they differ 
Copy Config creates a new map with a copy of the given config 
New Notifier builds a Notifier that can be used to notify other peers using the given policy 
Events starts a task that continuously monitors the list of cluster nodes and maintains a pool of websocket connections against all of them in order to get notified about events Whenever an event is received the given callback is invoked 
Establish a client connection to get events from the given node 
 Shift a uid from the host into the container I e 
 taken from http blog golang org slices which is under BSD licence 
 Add Safe adds an entry to the idmap set breaking apart any ranges that the new idmap intersects with in the process 
 get a uid or gid mapping from etc subxid 
 get a uid or gid mapping from proc self g u id map 
 Create a new default idmap 
 Create an idmap of the current allocation 
Only initialize the minimal information we need about a given storage type 
Initialize a full storage interface 
Functions dealing with storage pools 
User Id is an adaption from https codereview appspot com 
Group Id is an adaption from https codereview appspot com 
Extensively commented directly in the code Please leave the comments Looking at this in a couple of months noone will know why and how this works anymore 
get Profile Content generates the apparmor profile template from the given container This includes the stock lxc includes as well as stuff from raw apparmor 
Ensure that the container s policy is loaded into the kernel so the container can boot 
Ensure that the container s policy namespace is unloaded to free kernel memory This does not delete the policy from disk or cache 
Parse the profile without loading it into the kernel 
Delete the policy from cache disk 
get System Handler on Windows does nothing 
Notify Upgrade Completed sends a notification to all other nodes in the cluster that any possible pending database update has been applied and any nodes which was waiting for this node to be upgraded should re check if it s okay to move forward 
Keep Updated is a task that continuously monitor this node s version to see it it s out of date with respect to other nodes In the node is out of date and the LXD CLUSTER UPDATE environment variable is set then the task executes the executable that the variable is pointing at 
Check this node s version and possibly run LXD CLUSTER UPDATE 
New Server returns a new RBAC server instance 
Start Status Check starts a periodic status checker 
Sync Projects updates the list of projects in RBAC 
Add Project adds a new project resource to RBAC 
Delete Project adds a new project resource to RBAC 
Rename Project renames an existing project resource in RBAC 
Is Admin returns whether or not the provided user is an admin 
Has Permission returns whether or not the user has the permission to perform a certain task 
 Update configuration or if restore snapshot name is present restore the named snapshot 
Send an rsync stream of a path over a websocket 
Spawn the rsync process 
Return a TLS configuration suitable for establishing inter node network connections using the cluster certificate 
Return true if the given request is presenting the given cluster certificate 
Move a non ceph container to another cluster node 
Special case migrating a container backed by ceph across two cluster nodes 
Notification that a container was moved At the moment it s used for ceph based containers where the target node needs to create the appropriate mount points 
Used after to create the appropriate mounts point after a container has been moved 
Contains checks if a given device exists in the set and if it s identical to that provided 
Update returns the difference between two sets 
Device Names returns the name of all devices in the set sorted properly 
Debug logs a message with optional context at the DEBUG log level 
Info logs a message with optional context at the INFO log level 
Warn logs a message with optional context at the WARNING log level 
Error logs a message with optional context at the ERROR log level 
Crit logs a message with optional context at the CRITICAL log level 
Infof logs at the INFO log level using a standard printf format string 
Debugf logs at the DEBUG log level using a standard printf format string 
Warnf logs at the WARNING log level using a standard printf format string 
Errorf logs at the ERROR log level using a standard printf format string 
Critf logs at the CRITICAL log level using a standard printf format string 
Forward to the local events dispatcher an event received from another node 
 LXD DIR storage pools pool containers project name container name 
 LXD DIR storage pools pool containers snapshots snapshot name 
 LXD DIR storage pools pool images fingerprint 
 LXD DIR storage pools pool custom storage volume 
 LXD DIR storage pools pool custom snapshots custom volume name snapshot name 
Storage Progress Reader reports the read progress 
Storage Progress Writer reports the write progress 
Get LSBRelease returns a map with Linux distribution information 
Reset an auto generated source file writing a new empty file header 
Append a code snippet to a file 
Container To Args is a convenience to convert the new Container db struct into the legacy Container Args 
Container Names returns the names of all containers the given project 
Container Node Address returns the address of the node hosting the container with the given name in the given project It returns the empty string if the container is hosted on this node 
Containers List By Node Address returns the names of all containers grouped by cluster node address The node address of containers running on the local node is set to the empty string to distinguish it from remote nodes Containers whose node is down are addeded to the special address 
Container List Expanded loads all containers across all projects and expands their config and devices using the profiles they are associated to 
Containers By Node Name returns a map associating each container to the name of its node 
Snapshot IDs And Names returns a map of snapshot IDs to snapshot names for the container with the given name 
Container Node Move changes the node associated with a container It s meant to be used when moving a non running container backed by ceph from one cluster node to another 
Container Node List returns all container objects on the local node 
Container Node Project List returns all container objects on the local node within the given project 
Container Config Insert inserts a new config for the container with the given ID 
Container Remove removes the container with the given name from the database 
Container Project And Name returns the project and the name of the container with the given ID 
Container Config Clear removes any config associated with the container with the given ID 
Container Config Insert inserts a new config for the container with the given ID 
Container Config Get returns the value of the given key in the configuration of the container with the given ID 
Container Config Remove removes the given key from the config of the container with the given ID 
Container Set Stateful toggles the stateful flag of the container with the given ID 
Container Profiles Insert associates the container with the given ID with the profiles with the given names in the given project 
Container Profiles returns a list of profiles for a given container ID 
Container Config gets the container configuration map from the DB 
Legacy Containers List returns the names of all the containers of the given type NOTE this is a pre projects legacy API that is used only by patches Don t use it for new code 
Container Set State sets the the power state of the container with the given ID 
Container Update updates the description architecture and ephemeral flag of the container with the given ID 
Container Last Used Update updates the last use date field of the container with the given ID 
Container Get Snapshots returns the names of all snapshots of the container in the given project with the given name 
Container Get Snapshots Full returns all container objects for snapshots of a given container 
Container Next Snapshot returns the index the next snapshot of the container with the given name and pattern should have 
Container Pool returns the storage pool of a given container This is a non transactional variant of Cluster Tx Container Pool 
Container Pool returns the storage pool of a given container 
Container Get Backup returns the backup with the given name 
Container Get Backups returns the names of all backups of the container with the given name 
Container Backup Create creates a new backup 
Container Backup Remove removes the container backup with the given name from the database 
Container Backup Rename renames a container backup from the given current name to the new one 
Container Backups Get Expired returns a list of expired container backups 
Default OS returns a fresh uninitialized OS instance with default values 
Init our internal data structures 
Add Handler adds a function to be called whenever an event is received 
Get Websocket returns a raw websocket connection from the operation 
Remove Handler removes a function to be called whenever an event is received 
Refresh pulls the current version of the operation and updates the struct 
Wait lets you wait until the operation reaches a final state 
Add Handler adds a function to be called whenever an event is received 
Cancel Target attempts to cancel the target operation 
Get Target returns the target operation 
Wait lets you wait until the operation reaches a final state 
Up brings up all applicable LXD endpoints and starts accepting HTTP requests The endpoints will be activated in the following order and according to the following rules local endpoint unix socket If socket based activation is detected look for a unix socket among the inherited file descriptors and use it for the local endpoint or if no such file descriptor exists don t bring up the local endpoint at all If no socket based activation is detected create a unix socket using the default lxd var dir unix socket path The file mode of this socket will be set to the file owner will be set to the process UID and the file group will be set to the process GID or to the GID of the system group name specified via config Local Unix Socket Group devlxd endpoint unix socket Created using lxd var dir devlxd sock with file mode set to actual authorization will be performed by the HTTP server using the socket ucred struct remote endpoint TCP socket with TLS If socket based activation is detected look for a network socket among the inherited file descriptors and use it for the network endpoint If a network address was set via config Network Address then close any listener that was detected via socket based activation and create a new network socket bound to the given address The network endpoint socket will use TLS encryption using the certificate keypair and CA passed via config Cert cluster endpoint TCP socket with TLS If a network address was set via config Cluster Address then attach config Rest Server to it 
Up brings up all configured endpoints and starts accepting HTTP requests 
Down brings down all endpoints and stops serving HTTP requests 
Start an HTTP server for the endpoint associated with the given code 
Stop the HTTP server of the endpoint associated with the given code The associated socket will be shutdown too 
Use the listeners associated with the file descriptors passed via socket based activation 
Candid Server returns all the Candid settings needed to connect to a server 
RBACServer returns all the Candid settings needed to connect to a server 
Auto Update Interval returns the configured images auto update interval 
MAASController the configured MAAS url and key if any 
Offline Threshold returns the configured heartbeat threshold i e the number of seconds before after which an unresponsive node is considered offline 
Config Get String is a convenience for loading the cluster configuration and returning the value of a particular key It s a deprecated API meant to be used by call sites that are not interacting with the database in a transactional way 
Config Get Bool is a convenience for loading the cluster configuration and returning the value of a particular boolean key It s a deprecated API meant to be used by call sites that are not interacting with the database in a transactional way 
Config Get Int is a convenience for loading the cluster configuration and returning the value of a particular key It s a deprecated API meant to be used by call sites that are not interacting with the database in a transactional way 
Cluster Address returns the cluster addresss of the cluster endpoint or an empty string if there s no cluster endpoint 
General wrappers around Logger interface functions 
Wrappers around Logger interface functions that send a string to the Logger by running it through fmt Sprintf 
Rest Server creates an http Server capable of handling requests against the LXD REST API endpoint 
Extract the project query parameter from the given request 
Extract the given query parameter directly from the URL never from an encoded body 
Return a new db command 
Description return a human readable description of the operation type 
Permission returns the needed RBAC permission to cancel the oepration 
Operations UUIDs returns the UUIDs of all operations associated with this node 
Operation Nodes returns a list of nodes that have running operations 
Operation By UUID returns the operation with the given UUID 
Operation Add adds a new operations to the table 
Operation Remove removes the operation with the given UUID 
Operations returns all operations in the cluster filtered by the given clause 
This task function expires logs when executed It s started by the Daemon and will run once every h 
Given its relative path with respect to the LXD surce tree return the full path of a file 
Keys returns all keys defined in the schema 
Defaults returns a map of all key names in the schema along with their default values 
Get the Key associated with the given name or panic 
Assert that the Key with the given name as the given type Panic if no Key with such name exists or if it does not match the tiven type 
Tells if the given value can be assigned to this particular Value instance 
Get Storage Pool Volumes returns a list of Storage Volume entries for the provided pool 
Get Storage Pool Volume returns a Storage Volume entry for the provided pool and volume name 
Create Storage Pool Volume defines a new storage volume 
Create Storage Pool Volume Snapshot defines a new storage volume 
Get Storage Pool Volume Snapshots returns a list of snapshots for the storage volume 
Get Storage Pool Volume Snapshot returns a snapshots for the storage volume 
Update Storage Pool Volume Snapshot updates the volume to match the provided Storage Pool Volume struct 
Migrate Storage Pool Volume requests that LXD prepares for a storage volume migration 
Copy Storage Pool Volume copies an existing storage volume 
Move Storage Pool Volume renames or moves an existing storage volume 
Update Storage Pool Volume updates the volume to match the provided Storage Pool Volume struct 
Delete Storage Pool Volume deletes a storage pool 
Rename Storage Pool Volume renames a storage volume 
Report all LXD objects that are currently using the given storage pool Volumes of type custom are not reported containers alp containers alp snapshots snap images cedce b b f beba a fd aa fda eea c dd a d e profiles default 
This performs all non db related work needed to create the pool 
Helper around the low level DB API which also updates the driver names cache 
Helper around the low level DB API which also updates the driver names cache 
API functions 
Helper functions Returns the parent container name snapshot name and whether it actually was a snapshot name 
Loader functions 
Load all containers across all projects 
Load all containers of this nodes 
Load all containers of this nodes under the given project 
Heartbeat returns a task function that performs leader initiated heartbeat checks against all LXD nodes in the cluster It will update the heartbeat timestamp column of the nodes table accordingly and also notify them of the current list of database nodes 
Perform a single heartbeat request against the node with the given address 
This seems a little excessive 
Only initialize the minimal information we need about a given storage type 
Functions dealing with storage pools 
Things we don t need to care about 
Things we do have to care about 
 create temporary directory LXD DIR images lxd images create new zfs volume images fingerprint mount the zfs volume on LXD DIR images lxd images unpack the downloaded image in LXD DIR images lxd images mark new zfs volume images fingerprint readonly remove mountpoint property from zfs volume images fingerprint create read write snapshot from zfs volume images fingerprint 
Ask Bool asks a question and expect a yes no answer 
Ask Choice asks the user to select one of multiple options 
Ask Int asks the user to enter an integer between a min and max value 
Ask String asks the user to enter a string which optionally conforms to a validation function 
Ask Password asks the user to enter a password 
Ask Password Once asks the user to enter a password It s the same as Ask Password but it won t ask to enter it again 
Ask a question on the output stream and read the answer from the input stream 
Read the user s answer from the input stream trimming newline and providing a default 
 This is used for both profiles post and profile put 
The handler for the post operation 
The handler for the delete operation 
Is Root Disk Device returns true if the given device representation is configured as root disk for a container It typically get passed a specific entry of api Container Devices 
Get Root Disk Device returns the container device that is configured as root disk 
Config Key Checker returns a function that will check whether or not a provide value is valid for the associate config key Returns an error if the key is not known The checker function only performs syntactic checking of the value semantic and usage checking must be done by the caller User defined keys are always considered to be valid e g user and environment keys 
Forwarded Response takes a request directed to a node and forwards it to another node writing back the response it gegs 
Forwarded Response If Target Is Remote redirects a request to the request has a target Node parameter pointing to a node which is not the local one 
Forwarded Response If Container Is Remote redirects a request to the node running the container with the given name If the container is local nothing gets done and nil is returned 
Forwarded Response If Volume Is Remote redirects a request to the node hosting the volume with the given pool ID name and type If the container is local nothing gets done and nil is returned If more than one node has a matching volume an error is returned This is used when no target Node is specified and saves users some typing when the volume name type is unique to a node 
Forwarded Operation Response creates a response that forwards the metadata of an operation created on another node 
 Smart Error returns the right error message based on err 
Key Value extracts the key and value encoded in the given string and separated by foo bar foo bar 
Done prints the final status and prevents any update 
Update changes the status message to the provided string 
Warn shows a temporary message instead of the status 
Update Progress is a helper to update the status using an iopgress instance 
Update Op is a helper to update the status using a LXD API operation 
Image Download resolves the image fingerprint and if not in the database downloads it 
The zfs pool name config key is node specific and needs to be linked to nodes 
For ceph volumes add node specific rows for all existing nodes since any node is able to access those volumes 
Create a new net Listener bound to the unix socket of the local endpoint 
Change the file mode and ownership of the local endpoint unix socket file so access is granted only to the process user and to the given group or the process group if group is empty 
New Stmt return a new statement code snippet for running the given kind of query against the given database entity 
Generate plumbing and wiring code for the desired statement 
Output a line of code that registers the given statement and declares the associated statement code global variable 
Connect LXD lets you connect to a remote LXD daemon over HTTPs A client certificate TLSClient Cert and key TLSClient Key must be provided If connecting to a LXD daemon running in PKI mode the PKI CA TLSCA must also be provided Unless the remote server is trusted by the system CA the remote certificate must be provided TLSServer Cert 
Connect LXDUnix lets you connect to a remote LXD daemon over a local unix socket If the path argument is empty then LXD SOCKET will be used if unset LXD DIR unix socket will be used and if that one isn t set either then the path will default to var lib lxd unix socket 
Connect Public LXD lets you connect to a remote public LXD daemon over HTTPs Unless the remote server is trusted by the system CA the remote certificate must be provided TLSServer Cert 
Connect Simple Streams lets you connect to a remote Simple Streams image server over HTTPs Unless the remote server is trusted by the system CA the remote certificate must be provided TLSServer Cert 
Internal function called by Connect LXD and Connect Public LXD 
Move a container using special POST containers name target member API 
Is Active checks whether the container state indicates the container is active 
Raft Nodes returns information about all LXD nodes that are members of the dqlite Raft cluster possibly including the local node If this LXD instance is not running in clustered mode an empty list is returned 
Raft Node Address returns the address of the LXD raft node with the given ID if any matching row exists 
Raft Node First adds a the first node of the cluster It ensures that the database ID is to match the server ID of first raft log entry This method is supposed to be called when there are no rows in raft nodes and it will replace whatever existing row has ID 
Raft Node Add adds a node to the current list of LXD nodes that are part of the dqlite Raft cluster It returns the ID of the newly inserted row 
Raft Node Delete removes a node from the current list of LXD nodes that are part of the dqlite Raft cluster 
Raft Nodes Replace replaces the current list of raft nodes 
Detect CGroup support 
Configure the sqlite connection so that it s safe to access the dqlite managed sqlite file also without setting up raft 
Container List returns all available containers 
Container Get returns the container with the given key 
Container ID return the ID of the container with the given key 
Container Exists checks if a container with the given key exists 
Container Create adds a new container to the database 
Container Profiles Ref returns entities used by containers 
Container Config Ref returns entities used by containers 
Container Devices Ref returns entities used by containers 
Natural Key returns the struct fields that can be used as natural key for uniquely identifying a row in the underlying table By convention the natural key field is the one called Name unless specified otherwise with the db natural key tags 
Contains Fields checks that the mapping contains fields with the same type and name of given ones 
Field By Name returns the field with the given name if any 
Field Column Name returns the column name of the field with the given name prefixed with the entity s table name 
Filter Field By Name returns the field with the given name if that field can be used as query filter an error otherwise 
Column Fields returns the fields that map directly to a database column either on this table or on a joined one 
Scalar Fields returns the fields that map directly to a single database column on another table that can be joined to this one 
Ref Fields returns the fields that are one to many references to other tables 
Column returns the name of the database column the field maps to The type code of the field must be Type Column 
Zero Value returns the literal representing the zero value for this field The type code of the field must be Type Column 
Field Columns converts thegiven fields to list of column names separated by a comma 
Field Args converts the given fields to function arguments rendering their name and type 
Field Params converts the given fields to function parameters rendering their name 
Field Criteria converts the given fields to AND separated WHERE criteria 
 resources Get system resources 
 storage pools name resources Get resources for a specific storage pool 
Helper to initialize node specific entities on a LXD instance using the definitions from the given init Data Node object It s used both by the lxd init command and by the PUT cluster API In case of error the returned function can be used to revert the changes 
Helper to initialize LXD clustering Used by the lxd init command 
Terminal Format formats log records optimized for human readability on a terminal with color coded level output and terser human friendly timestamp This format should only be used for interactive programs or while developing TIME LEVEL MESAGE key value key value Example May DBUG remove route ns haproxy addr 
Json Format Ex formats log records as JSON objects If pretty is true records will be pretty printed If line Separated is true records will be logged with a new line between each record 
format Value formats a value for serialization 
Resolve Target is a convenience for handling the value target Node query parameter It returns the address of the given node or the empty string if the given node is the local one 
Write in Progress Writer is the same as io Write 
Update the schema and api extensions columns of the row in the nodes table that matches the given id If not such row is found an error is returned 
Return a slice of binary integer tuples Each tuple contains the schema version and number of api extensions of a node in the cluster 
Get Architectures returns the list of supported architectures 
Get Idmap Set reads the uid gid allocation 
Runtime Liblxc Version At Least checks if the system s liblxc matches the provided version requirement 
Get Exec Path returns the path to the current binary 
Connect is a convenience around lxd Connect LXD that configures the client with the correct parameters for node to node communication If notify switch is true then the user agent will be set to the special value lxd cluster notifier which can be used in some cases to distinguish between a regular client request and an internal cluster request 
Connect If Container Is Remote figures out the address of the node which is running the container with the given name If it s not the local node will connect to it and return the connected client otherwise it will just return nil 
Connect If Volume Is Remote figures out the address of the node on which the volume with the given name is defined If it s not the local node will connect to it and return the connected client otherwise it will just return nil If there is more than one node with a matching volume name an error is returned 
Setup Trust is a convenience around Container Server Create Certificate that adds the given client certificate to the trusted pool of the cluster at the given address using the given password 
Get Storage Pools returns a list of Storage Pool entries 
Get Storage Pool returns a Storage Pool entry for the provided pool name 
Create Storage Pool defines a new storage pool using the provided Storage Pool struct 
Update Storage Pool updates the pool to match the provided Storage Pool struct 
Delete Storage Pool deletes a storage pool 
Get Storage Pool Resources gets the resources available to a given storage pool 
Make sure all our directories are available 
Config fetches all LXD node level config keys 
Update Config updates the given LXD node level configuration keys in the config table Config keys set to empty values will be deleted 
Config fetches all LXD cluster config keys 
Update Config updates the given LXD cluster configuration keys in the config table Config keys set to empty values will be deleted 
Config Value Set is a convenience to set a cluster level key value config pair in a single transaction 
 storage pools List all storage pools 
 storage pools Create a storage pool 
 storage pools name Get a single storage pool 
 storage pools name Replace pool properties 
This helper makes sure that when clustered we re not changing node specific values POSSIBLY TODO for now we don t have any node specific values that can be modified If we ever get some we ll need to extend the PUT PATCH APIs to accept a target Node query parameter 
This helper deletes any node specific values from the config object since they should not be part of the calculated etag 
This helper complements a PUT PATCH request config with node specific value as taken from the db 
 storage pools name Delete storage pool 
Event handling functions Get Events connects to the LXD monitoring interface 
Logfmt Format return a formatter for a text log file 
Storage Volume Node Addresses returns the addresses of all nodes on which the volume with the given name if defined The empty string is used in place of the address of the current node 
Storage Volume Node Get returns the name of the node a storage volume is on 
Storage Volume Config Get gets the config of a storage volume 
Storage Volume Description Get gets the description of a storage volume 
Storage Volume Next Snapshot returns the index the next snapshot of the storage volume with the given name should have Note the code below doesn t deal with snapshots of snapshots To do that we ll need to weed out based on slashes in names 
Storage Volume Is Available checks that if a custom volume available for being attached Always return true for non Ceph volumes For Ceph volumes return true if the volume is either not attached to any other container or attached to containers on this node 
Storage Volume Description Update updates the description of a storage volume 
Storage Volume Config Add adds a new storage volume config into database 
Storage Volume Config Clear deletes storage volume config 
Get the IDs of all volumes with the given name and type associated with the given pool regardless of their node id column 
Storage Volume Cleanup Images removes the volumes with the given fingerprints 
Storage Volume Move To LVMThin Pool Name Key upgrades the config keys of LVM volumes 
L accumulates a single line of source code 
Returns the source code to add to the target file 
Pretty will attempt to convert any Go structure into a string suitable for logging 
Network Public Key returns the public key of the TLS certificate used by the network endpoint 
Network Private Key returns the private key of the TLS certificate used by the network endpoint 
Network Cert returns the full TLS certificate information for this endpoint 
Network Address returns the network addresss of the network endpoint or an empty string if there s no network endpoint 
Network Update Address updates the address for the network endpoint shutting it down and restarting it 
Network Update Cert updates the TLS keypair and CA used by the network endpoint If the network endpoint is active in flight requests will continue using the old certificate and only new requests will use the new one 
Create a new net Listener bound to the tcp socket of the network endpoint 
Accept waits for and returns the next incoming TLS connection then use the current TLS configuration to handle it 
Config safely swaps the underlying TLS configuration 
Start a single task executing the given function with the given schedule This is a convenience around Group and it returns two functions that can be used to control the task The first is a stop function trying to terminate the task gracefully within the given timeout and the second is a reset function to reset the task s state See Group Stop and Group Reset for more details 
Is Offline returns true if the last successful heartbeat time of the node is older than the given threshold 
Node By Address returns the node with the given network address 
Node Pending By Address returns the pending node with the given network address 
Node By Name returns the node with the given name 
Node Name returns the name of the node this method is invoked on 
Node Address returns the address of the node this method is invoked on 
Node Is Outdated returns true if there s some cluster node having an API or schema version greater than the node this method is invoked on 
Nodes Count returns the number of nodes in the LXD cluster Since there s always at least one node row even when not clustered the return value is greater than zero 
Node Rename changes the name of an existing node Return an error if a node with the same name already exists 
Nodes returns all LXD nodes part of the cluster 
Node Add adds a node to the current list of LXD nodes that are part of the cluster It returns the ID of the newly inserted row 
Node Pending toggles the pending flag for the node A node is pending when it s been accepted in the cluster but has not yet actually joined it 
Node Update updates the name an address of a node 
Node Remove removes the node with the given id 
Node Heartbeat updates the heartbeat column of the node with the given address 
Node Is Empty returns an empty string if the node with the given ID has no containers or images associated with it Otherwise it returns a message say what s left 
Node Clear removes any container or image associated with this node 
Node Offline Threshold returns the amount of time that needs to elapse after which a series of unsuccessful heartbeat will make the node be considered offline 
Node With Least Containers returns the name of the non offline node with with the least number of containers either already created or being created with an operation 
Node Update Version updates the schema and API version of the node with the given id This is used only in tests 
Transaction executes the given function within a database transaction 
Rollback a transaction after the given error occurred If the rollback succeeds the given error is returned otherwise a new error that wraps it gets generated and returned 
Profile URIs returns all available profile URIs 
Profile List returns all available profiles 
Profile Get returns the profile with the given key 
Profile Exists checks if a profile with the given key exists 
Profile Config Ref returns entities used by profiles 
Profile Devices Ref returns entities used by profiles 
Profile Used By Ref returns entities used by profiles 
Profile Create adds a new profile to the database 
Profile Rename renames the profile matching the given key parameters 
Profile Delete deletes the profile matching the given key parameters 
In Memory Network creates a fully in memory listener and dial function Each time the dial function is invoked a new pair of net Conn objects will be created using net Pipe the listener s Accept method will unblock and return one end of the pipe and the other end will be returned by the dial function 
Accept waits for and returns the next connection to the listener 
Canonical Network Address parses the given network address and returns a string of the form host port possibly filling it with the default port if it s missing 
Server TLSConfig returns a new server side tls Config generated from the give certificate info 
Network Interface Address returns the first non loopback address of any of the system network interfaces Return the empty string if none is found 
Is Address Covered detects if network address is actually covered by address in the sense that they are either the same address or address is specified using a wildcard with the same port of address 
Select Objects executes a statement which must yield rows with a specific columns schema It invokes the given Dest hook for each yielded row 
Upsert Object inserts or replaces a new row with the given column values to the given table using columns order For example Upsert Object tx cars string id brand interface ferrari The number of elements in columns must match the one in values 
Delete Object removes the row identified by the given ID The given table must have a primary key column called id It returns a flag indicating if a matching row was actually found and deleted or not 
Execute the our task function according to our schedule until the given context gets cancelled 
Is Terminal returns true if the given file descriptor is a terminal 
Get State returns the current state of a terminal which may be useful to restore the terminal after a signal 
Make Raw put the terminal connected to the given file descriptor into raw mode and returns the previous state of the terminal so that it can be restored 
Restore restores the terminal connected to the given file descriptor to a previous state 
Bind to the given unix socket path 
Check Already Running checks if the socket at the given path is already bound to a running LXD process and return an error if so FIXME We should probably rather just try a regular unix socket connection without using the client However this is the way this logic has historically behaved so let s keep it like it was 
Remove any stale socket file at the given path 
Change the file mode of the given unix socket file 
Change the ownership of the given unix socket file 
ceph OSDPool Exists checks whether a given OSD pool exists 
ceph OSDPool Destroy destroys an OSD pool A call to ceph OSDPool Destroy will destroy a pool including any storage volumes that still exist in the pool In case the OSD pool that is supposed to be deleted does not exist this command will still exit This means that if the caller wants to be sure that this call actually deleted an OSD pool it needs to check for the existence of the pool first 
ceph RBDVolume Create creates an RBD storage volume Note that the set of features is intentionally limited is intentionally limited by passing image feature explicitly This is done to ensure that the chances of a conflict between the features supported by the userspace library and the kernel module are minimized Otherwise random panics might occur 
ceph RBDVolume Exists checks whether a given RBD storage volume exists 
ceph RBDVolume Map maps a given RBD storage volume This will ensure that the RBD storage volume is accessible as a block device in the dev directory and is therefore necessary in order to mount it 
ceph RBDSnapshot Protect protects a given snapshot from being deleted This is a precondition to be able to create RBD clones from a given snapshot 
ceph RBDClone Create creates a clone from a protected RBD snapshot 
ceph RBDSnapshot List Clones list all clones of an RBD snapshot 
ceph RBDVolume Mark Deleted marks an RBD storage volume as being in zombie state An RBD storage volume that is in zombie state is not tracked in LXD s database anymore but still needs to be kept around for the sake of any dependent storage entities in the storage pool This usually happens when an RBD storage volume has protected snapshots a scenario most common when creating a sparse copy of a container or when LXD updated an image and the image still has dependent container clones 
ceph RBDVolume Unmark Deleted unmarks an RBD storage volume as being in zombie state An RBD storage volume that is in zombie is not tracked in LXD s database anymore but still needs to be kept around for the sake of any dependent storage entities in the storage pool This function is mostly used when a user has deleted the storage volume of an image from the storage pool and then triggers a container creation If LXD detects that the storage volume for the given hash already exists in the pool but is marked as zombie it will unmark it as a zombie instead of creating another storage volume for the image 
ceph RBDVolume Rename renames a given RBD storage volume Note that this usually requires that the image be unmapped under its original name then renamed and finally will be remapped again If it is not unmapped under its original name and the callers maps it under its new name the image will be mapped twice This will prevent it from being deleted 
ceph RBDVolume Rename renames a given RBD storage volume Note that if the snapshot is mapped which it usually shouldn t be this usually requires that the snapshot be unmapped under its original name then renamed and finally will be remapped again If it is not unmapped under its original name and the caller maps it under its new name the snapshot will be mapped twice This will prevent it from being deleted 
ceph RBDVolume Get Parent will return the snapshot the RBD clone was created from If the RBD storage volume is not a clone then this function will return db No Such Object Error The snapshot will be returned as osd pool name rbd volume name 
ceph RBDSnapshot Delete deletes an RBD snapshot This requires that the snapshot does not have any clones and is unmapped and unprotected 
ceph RBDVolume Copy copies an RBD storage volume This is a non sparse copy which doesn t introduce any dependency relationship between the source RBD storage volume and the target RBD storage volume The operations is similar to creating an empty RBD storage volume and rsyncing the contents of the source RBD storage volume into it 
ceph RBDVolume List Snapshots retrieves the snapshots of an RBD storage volume The format of the snapshot names is simply the part after the 
get RBDSize returns the size the RBD storage volume is supposed to be created with 
get RBDFilesystem returns the filesystem the RBD storage volume is supposed to be created with 
copy Without Snapshots Full creates a non sparse copy of a container This does not introduce a dependency relation between the source RBD storage volume and the target RBD storage volume 
copy Without Snapshots Full creates a sparse copy of a container This introduces a dependency relation between the source RBD storage volume and the target RBD storage volume 
copy With Snapshots creates a non sparse copy of a container including its snapshots This does not introduce a dependency relation between the source RBD storage volume and the target RBD storage volume 
ceph Container Delete deletes the RBD storage volume of a container including any dependencies This function takes care to delete any RBD storage entities that are marked as zombie and whose existence is solely dependent on the RBD storage volume for the container to be deleted This function will mark any storage entities of the container to be deleted as zombies in case any RBD storage entities in the storage pool have a dependency relation with it This function uses a C style convention to return error or success simply because it is more elegant and simple than the go way The function will return on error if the RBD storage volume has been deleted if the RBD storage volume has been marked as a zombie ceph Container Delete in conjunction with ceph Container Snapshot Delete recurses through an OSD storage pool to find and delete any storage entities that were kept around because of dependency relations but are not deletable 
ceph Container Snapshot Delete deletes an RBD snapshot of a container including any dependencies This function takes care to delete any RBD storage entities that are marked as zombie and whose existence is solely dependent on the RBD snapshot for the container to be deleted This function will mark any storage entities of the container to be deleted as zombies in case any RBD storage entities in the storage pool have a dependency relation with it This function uses a C style convention to return error or success simply because it is more elegant and simple than the go way The function will return on error if the RBD storage volume has been deleted if the RBD storage volume has been marked as a zombie ceph Container Snapshot Delete in conjunction with ceph Container Delete recurses through an OSD storage pool to find and delete any storage entities that were kept around because of dependency relations but are not deletable 
parse Parent splits a string describing a RBD storage entity into its components This can be used on strings like osd pool name lxd specific prefix rbd storage volume 
parse Clone splits a strings describing an RBD storage volume For example a string like osd pool name lxd specific prefix rbd storage volume will be split into osd pool name lxd specific prefix rbd storage volume 
get RBDMapped Dev Path looks at sysfs to retrieve the device path dev rbd idx for an RBD image If it doesn t find it it will map it if told to do so 
copy With Snapshots creates a non sparse copy of a container including its snapshots This does not introduce a dependency relation between the source RBD storage volume and the target RBD storage volume 
ceph RBDVolume Backup Create creates a backup of a container or snapshot 
ceph RBDGenerate UUID regenerates the XFS btrfs UUID as needed 
Get Config Cmd returns a cobra command that lets the caller see the configured auth backends in Pachyderm 
Set Config Cmd returns a cobra command that lets the caller configure auth backends in Pachyderm 
New Sharder creates a Sharder using a discovery client 
New Router creates a Router 
Pachctl Cmd creates a cobra Command which can deploy pachyderm clusters and interact with them it implements the pachctl binary 
Renew renews the caller s credentials and extends the TTL of their Pachyderm token by sending a request to Pachyderm Unlike other handlers it doesn t get assigned to a path instead it s called by the vault lease API when a token s lease is renewed It s set in Backend Secrets Revoke in backend go 
renew User Credentials extends the TTL of the Pachyderm authentication token user Token using the vault plugin s Admin credentials user Token belongs to the user who is calling vault and would like to extend their Pachyderm session 
New Local Client returns a Client that stores data on the local file system 
Add Span To Any Existing checks ctx for Jaeger tracing information and if tracing metadata is present it generates a new span for operation marks it as a child of the existing span and returns it 
Install Jaeger Tracer From Env installs a Jaeger client as then opentracing global tracer relying on environment variables to configure the client It returns the address used to initialize the global tracer if any initialization occurred 
Unary Client Interceptor returns a GRPC interceptor for non streaming GRPC RPCs 
Stream Client Interceptor returns a GRPC interceptor for non streaming GRPC RPCs 
Unary Server Interceptor returns a GRPC interceptor for non streaming GRPC RPCs 
Stream Server Interceptor returns a GRPC interceptor for non streaming GRPC RPCs 
Close And Report Traces tries to close the global tracer which in the case of the Jaeger tracer causes it to send any unreported traces to the collector 
new Writer creates a new Writer 
Range Start specifies the start of a range within the byte stream that is meaningful to the caller When this range has ended by calling Range Start again or Close and all of the necessary chunks are written the callback given during initialization will be called with Data Refs that can be used for accessing that range 
Write rolls through the data written calling c f when a chunk is found Note If making changes to this function be wary of the performance implications check before and after performance with chunker benchmarks 
 Segment needs us to identify a user before we report any events for that user We have no way of knowing if a user has previously been identified so we call this before every Track call containing user data 
Get Elapsed Time returns the elapsed time since an Exponential Back Off instance is created and is reset when Reset is called The elapsed time is computed using time Now Unix Nano 
Next Back Off 
For sets b Max Elapsed Time to max Elapsed and returns b 
Helper function used to log requests and responses from our GRPC method implementations 
Format proxies the closure in order to satisfy logrus Formatter s interface 
Pretty formats a logrus entry like so T Z INFO pfs API Inspect Repo request repo name images 
New GRPCLog Writer creates a new GRPC log writer logger specifies the underlying logger and source specifies where these logs are coming from it is added as a entry field for all log messages 
Write allows GRPCInfo Writer to implement the io Writer interface This will take g RPC logs which look something like this INFO Client Conn switching balancer to pick first strip out redundant content and print the message at the appropriate log level in logrus Any parse errors of the log message will be reported in logrus as well 
Read loads the Pachyderm config on this machine If an existing configuration cannot be found it sets up the defaults Read returns a nil Config if and only if it returns a non nil error 
Write writes the configuration in c to this machine s Pachyderm config file 
Read reads val from r 
Write writes val to r 
New Read Writer returns a new Read Writer with rw as both its source and its sink 
Cmds returns a slice containing admin commands 
Run Git Hook Server starts the webhook server 
new Logging Pipe initializes a logging Pipe 
Close closes l no more reading writing will be possible 
client Conn returns a logging Conn at the oposite end of the logging Pipe as server Conn There is no fundamental difference between the client Conn and the server Conn as communication is full duplex but distinguishing the two ends of the pipe as client and server rather than e g left and right hopefully makes the calling code easier to read 
server Conn returns a logging Conn at the opposite end of the logging Pipe of client Conn see the client Conn description for more information 
Read implements the corresponding method of net Conn 
Write implements the corresponding method of net Conn 
Dial initializes a new connection and releases a blocked call to Accept 
Accept implements the corresponding method of net Listener for Test Listener 
Close implements the corresponding method of net Listener for Test Listener Any blocked Accept operations will be unblocked and return errors 
Server runs an HTTP server with an S like API for PFS This allows you to use s clients to acccess PFS contents This returns an http Server instance It is the responsibility of the caller to start the returned server It s possible for the caller to gracefully shutdown the server if desired see the http package for details Note server errors are redirected to logrus standard log writer The log writer is never closed This should not be a problem with logrus default configuration which just writes to stdio But if the standard logger is overwritten e g to write to a socket it s possible for this to cause problems Note In s cmd you must set the access key and secret key even though this API will ignore them otherwise you ll get an opaque config error https github com s tools s cmd issues issuecomment 
Code returns the error code of err if it was returned by one of the Hash Tree methods or Unknown if err was emitted by some other function error codes are defined in interface go 
errorf is analogous to fmt Errorf but generates hash Tree Errors instead of error Strings 
Init Pach Only Env initializes this service environment This dials a GRPC connection to pachd only in a background goroutine and creates the template pach Client used by future calls to Get Pach Client This call returns immediately but Get Pach Client will block until the client is ready 
Init Service Env initializes this service environment This dials a GRPC connection to pachd and etcd in a background goroutine and creates the template pach Client used by future calls to Get Pach Client This call returns immediately but Get Pach Client and Get Etcd Client block until their respective clients are ready 
Init With Kube is like Init Service Env but also assumes that it s run inside a kubernetes cluster and tries to connect to the kubernetes API server 
Get Pach Client returns a pachd client with the same authentication credentials and cancellation as ctx ensuring that auth credentials are propagated through downstream RPCs Functions that receive RPCs should call this to convert their RPC context to a Pachyderm client and internal Pachyderm calls should accept clients returned by this call Warning Do not call this function during server setup unless it is in a goroutine A Pachyderm client is not available until the server has been setup 
Get Etcd Client returns the already connected etcd client without modification 
Get Kube Client returns the already connected Kubernetes API client without modification 
New Hasher creates a hasher 
Hash Job computes and returns the hash of a job 
Hash Pipeline computes and returns the hash of a pipeline 
Status returns the statuses of workers referenced by pipeline Rc Name pipeline Rc Name is the name of the pipeline s RC and can be gotten with ppsutil Pipeline Rc Name You can also pass for pipeline Rc Name to get all clients for all workers 
Cancel cancels a set of datums running on workers pipeline Rc Name is the name of the pipeline s RC and can be gotten with ppsutil Pipeline Rc Name 
Conns returns a slice of connections to worker servers pipeline Rc Name is the name of the pipeline s RC and can be gotten with ppsutil Pipeline Rc Name You can also pass for pipeline Rc Name to get all clients for all workers 
Clients returns a slice of worker clients for a pipeline pipeline Rc Name is the name of the pipeline s RC and can be gotten with ppsutil Pipeline Rc Name You can also pass for pipeline Rc Name to get all clients for all workers 
New Client returns a worker client for the worker at the IP address passed in 
Scrub GRPC removes GRPC error code information from err if it came from GRPC and returns it unchanged otherwise 
Run Fixed Args wraps a function in a function that checks its exact argument count 
Run Bounded Args wraps a function in a function that checks its argument count is within a range 
Run makes a new cobra run function that wraps the given function 
Error And Exit errors with the given format and args and then exits 
Parse Commit takes an argument of the form repo 
Parse Commits converts all arguments to pfs Commit structs using the semantics of Parse Commit 
Parse Branch takes an argument of the form repo 
Parse Branches converts all arguments to pfs Commit structs using the semantics of Parse Branch 
Parse File takes an argument of the form repo 
Parse Files converts all arguments to pfs Commit structs using the semantics of Parse File 
Set adds a string to r 
Create Alias generates a nested command tree for the invocation specified which should be space delimited as on the command line The Use field of cmd should specify alias instead of the command name as that will be filled in based on each invocation Similarly for the Example field alias will be replaced with the full command path These commands can later be merged into the final Command tree using Merge Commands below 
Merge Commands merges several command aliases generated by Create Alias above into a single coherent cobra command tree with root command root Because Create Alias generates empty commands to preserve the right hierarchy we go through a little extra effort to allow intermediate docs commands to be preserved in the final command structure 
Set Docs Usage sets the usage string for a docs style command Docs commands have no functionality except to output some docs and related commands and should not specify a Run attribute 
The master process is responsible for creating deleting workers as pipelines are created removed 
make Cron Commits makes commits to a single cron input s repo It s a helper function called by monitor Pipeline 
Writer implements the corresponding method in the Client interface 
Reader implements the corresponding method in the Client interface 
Delete implements the corresponding method in the Client interface 
Walk implements the corresponding method in the Client interface 
Exists implements the corresponding method in the Client interface 
Full ID prints repo Name Commit ID 
Get Block encodes a hash into a readable format in the form of a Block 
Health implements the Health method for health Server 
clean canonicalizes path for internal use leading slash and no trailing slash Also clean the result with internal Default 
split is like path Split but uses this library s defaults for canonical paths 
Validate Path checks if a file path is legal 
Match Datum checks if a datum matches a filter To match each string in filter must correspond match at least datum s Path or Hash Order of filter and data is irrelevant 
New Cache Server creates a new Cache Server 
authorize Pipeline Op checks if the user indicated by ctx is authorized to perform operation on the pipeline in info 
list Job is the internal implementation of List Job shared between List Job and List Job Stream When List Job is removed this should be inlined into List Job Stream 
list Datum contains our internal implementation of List Datum which is shared between List Datum and List Datum Stream When List Datum is removed this should be inlined into List Datum Stream 
hard Stop Pipeline does essentially the same thing as Stop Pipeline deletes the pipeline s branch provenance deletes any open commits deletes any k s workers but does it immediately This is to avoid races between operations that will do subsequent work e g Update Pipeline and Delete Pipeline and the PPS master 
sudo is a helper function that copies pach Client grants it PPS s superuser token and calls f with the superuser client This helps isolate PPS s use of its superuser token so that it s not widely copied and is unlikely to leak authority to parts of the code that aren t supposed to have it Note that because the argument to f is a superuser client it should not be used to make any calls with unvalidated user input Any such use could be exploited to make PPS a confused deputy 
make Pipeline Info Commit is a helper for Create Pipeline that creates a commit with pipeline Info in Spec Repo in PFS It s called in both the case where a user is updating a pipeline and the case where a user is creating a new pipeline 
set Pipeline Defaults sets the default values for a pipeline info 
inspect Pipeline contains the functional implementation of Inspect Pipeline Many functions Get Logs List Pipeline Create Job need to inspect a pipeline so they call this instead of making an RPC 
Collect Active Objects And Tags collects all objects tags that are not deleted or eligible for garbage collection 
increment GCGeneration increments the GC generation number in etcd 
New Debug Server creates a new server that serves the debug api over GRPC 
Health health checks pachd it returns an error if pachd isn t healthy 
In test mode we use unique names for cache groups since we might want to run multiple block servers locally which would conflict if groups had the same name We also do not report stats to prometheus 
watch GC watches for GC runs and invalidate all cache when GC happens 
write Internal contains the essential implementation of write Proto data is a serialized proto but does not retry 
split Key splits a key into the format we want and also postpends the generation number 
New Writer returns a new Writer it will flush when it gets term Height many lines including the header line The header line will be reprinted term Height many lines have been written New Streaming Writer will panic if it s given a header that doesn t end in n 
Write writes a line to the tabwriter 
Print Repo Header prints a repo header 
Print Repo Info pretty prints repo info 
Print Detailed Repo Info pretty prints detailed repo info 
Print Branch pretty prints a Branch 
Print Commit Info pretty prints commit info 
Print Detailed Commit Info pretty prints detailed commit info 
Print File Info pretty prints file info If recurse is false and directory size is display instead If fast is true and file size is display instead 
Print Detailed File Info pretty prints detailed file info 
Compact Print Branch renders b as a compact string e g myrepo 
Compact Print Commit renders c as a compact string e g myrepo 
Compact Print File renders f as a compact string e g myrepo 
Parse parses s for git ancestry references It supports special characters both of which are supported by git Note in git and have different meanings on commits that have multiple parent commits In Pachyderm there s only parent possible so they have identical meanings We support both simply for familiarity sake Parse Ancestry returns the base reference and how many ancestors back to go For example foo foo foo foo foo foo all examples apply with in place of as well 
Add adds an ancestry reference to the given string 
Retry Notify calls notify function with the error and wait duration for each failed attempt before sleep 
New Cache creates a new cache 
Put puts an id hashtree pair in the cache and reads the hashtree from the passed in io Reader 
Get does a filtered write of id s hashtree to the passed in io Writer 
Delete deletes a hashtree from the cache 
Merge does a filtered merge of the hashtrees in the cache The results are written to the passed in Writer The base field is used as the base hashtree if it is non nil 
Print Job Info pretty prints job info 
Print Pipeline Info pretty prints pipeline info 
Print Worker Status pretty prints a worker status 
Print Detailed Job Info pretty prints detailed job info 
Print Detailed Pipeline Info pretty prints detailed pipeline info 
Print Datum Info pretty prints file info If recurse is false and directory size is display instead If fast is true and file size is display instead 
Print Detailed Datum Info pretty prints detailed info about a datum 
Print File values for a pfs file 
Shorthand Input renders a pps Input as a short readable string 
update Lease extracts the duration of the lease governing secret an AWS secret IIUC because the AWS backend issues dynamic secrets there is no tokens associated with them and vault Secret Token TTL can be ignored 
Retrieve returns nil if it successfully retrieved the value Error is returned if the value were not obtainable or empty 
Is Expired returns if the credentials are no longer valid and need to be retrieved 
unsafe Assign Roles should be run 
New Branch creates a pfs Branch 
New Commit creates a pfs Commit 
New Commit Provenance creates a pfs Commit Provenance 
New File creates a pfs File 
Create Repo creates a new Repo object in pfs with the given name Repos are the top level data object in pfs and should be used to store data of a similar type For example rather than having a single Repo for an entire project you might have separate Repos for logs metrics database dumps etc 
Inspect Repo returns info about a specific Repo 
List Repo returns info about all Repos provenance specifies a set of provenance repos only repos which have ALL of the specified repos as provenance will be returned unless provenance is nil in which case it is ignored 
Delete Repo deletes a repo and reclaims the storage space it was using Note that as of we do not reclaim the blocks that the Repo was referencing this is because they may also be referenced by other Repos and deleting them would make those Repos inaccessible This will be resolved in later versions If force is set to true the repo will be removed regardless of errors This argument should be used with care 
Build Commit builds a commit in a single call from an existing Hash Tree that has already been written to the object store Note this is a more advanced pattern for creating commits that s mostly used internally 
Start Commit Parent begins the process of committing data to a Repo Once started you can write to the Commit with Put File and when all the data has been written you must finish the Commit with Finish Commit NOTE data is not persisted until Finish Commit is called branch is a more convenient way to build linear chains of commits When a commit is started with a non empty branch the value of branch becomes an alias for the created Commit This enables a more intuitive access pattern When the commit is started on a branch the previous head of the branch is used as the parent of the commit parent Commit specifies the parent Commit upon creation the new Commit will appear identical to the parent Commit data can safely be added to the new commit without affecting the contents of the parent Commit You may pass as parent Commit in which case the new Commit will have no parent and will initially appear empty 
Finish Commit ends the process of committing data to a Repo and persists the Commit Once a Commit is finished the data becomes immutable and future attempts to write to it with Put File will error 
Inspect Commit returns info about a specific Commit 
Block Commit returns info about a specific Commit but blocks until that commit has been finished 
List Commit lists commits If only repo is given all commits in the repo are returned If to is given only the ancestors of to including to itself are considered If from is given only the descendents of from including from itself are considered number determines how many commits are returned If number is all commits that match the aforementioned criteria are returned 
List Commit F lists commits calling f with each commit If only repo is given all commits in the repo are returned If to is given only the ancestors of to including to itself are considered If from is given only the descendents of from including from itself are considered number determines how many commits are returned If number is all commits that match the aforementioned criteria are returned 
List Commit By Repo lists all commits in a repo 
Create Branch creates a new branch 
Inspect Branch returns information on a specific PFS branch 
List Branch lists the active branches on a Repo 
Set Branch sets a commit and its ancestors as a branch Set Branch is deprecated in favor of Commit Branch 
Delete Branch deletes a branch but leaves the commits themselves intact In other words those commits can still be accessed via commit IDs and other branches they happen to be on 
Delete Commit deletes a commit 
Flush Commit returns an iterator that returns commits that have the specified commits as provenance Note that the iterator can block if jobs have not successfully completed This in effect waits for all of the jobs that are triggered by a set of commits to complete If to Repos is not nil then only the commits up to and including those repos will be considered otherwise all repos are considered Note that it s never necessary to call Flush Commit to run jobs they ll run no matter what Flush Commit just allows you to wait for them to complete and see their output once they do 
Flush Commit F calls f with commits that have the specified commits as provenance Note that it can block if jobs have not successfully completed This in effect waits for all of the jobs that are triggered by a set of commits to complete If to Repos is not nil then only the commits up to and including those repos will be considered otherwise all repos are considered Note that it s never necessary to call Flush Commit to run jobs they ll run no matter what Flush Commit F just allows you to wait for them to complete and see their output once they do 
Flush Commit All returns commits that have the specified commits as provenance Note that it can block if jobs have not successfully completed This in effect waits for all of the jobs that are triggered by a set of commits to complete If to Repos is not nil then only the commits up to and including those repos will be considered otherwise all repos are considered Note that it s never necessary to call Flush Commit to run jobs they ll run no matter what Flush Commit All just allows you to wait for them to complete and see their output once they do 
Subscribe Commit is like List Commit but it keeps listening for commits as they come in 
Subscribe Commit F is like List Commit but it calls a callback function with the results rather than returning an iterator 
Put Object Async puts a value into the object store asynchronously 
Put Object puts a value into the object store and tags it with or more tags 
Put Object Split is the same as Put Object except that the data is splitted into several smaller objects This is primarily useful if you d like to be able to resume upload 
Get Object gets an object out of the object store by hash 
Get Object Reader returns a reader for an object in object store by hash 
Read Object gets an object by hash and returns it directly as byte 
Get Objects gets several objects out of the object store by hash 
Read Objects gets several objects by hash and returns them directly as byte 
Tag Object applies a tag to an existing object 
List Object lists objects stored in pfs 
Inspect Object returns info about an Object 
Get Tag gets an object out of the object store by tag 
Get Tag Reader returns a reader for an object in object store by tag 
Read Tag gets an object by tag and returns it directly as byte 
List Tag lists tags stored in pfs 
Compact forces compaction of objects 
New Put File Client returns a new client for putting files into pfs in a single request 
Put File Writer writes a file to PFS NOTE Put File Writer returns an io Write Closer you must call Close on it when you are done writing 
Put File Split Writer writes a multiple files to PFS by splitting up the data that is written to it NOTE Put File Split Writer returns an io Write Closer you must call Close on it when you are done writing 
Put File writes a file to PFS from a reader 
Put File Overwrite is like Put File but it overwrites the file rather than appending to it overwrite Index allows you to specify the index of the object starting from which you d like to overwrite If you want to overwrite the entire file specify an index of 
Put File Split writes a file to PFS from a reader delimiter is used to tell PFS how to break the input into blocks 
Put File URL puts a file using the content found at a URL The URL is sent to the server which performs the request recursive allow for recursive scraping of some types URLs for example on s urls 
Close must be called after you re done using a put File Client Further requests will throw errors 
Put File Writer writes a file to PFS NOTE Put File Writer returns an io Write Closer you must call Close on it when you are done writing 
Put File Split Writer writes a multiple files to PFS by splitting up the data that is written to it NOTE Put File Split Writer returns an io Write Closer you must call Close on it when you are done writing 
Put File writes a file to PFS from a reader 
Put File Split writes a file to PFS from a reader delimiter is used to tell PFS how to break the input into blocks 
Put File URL puts a file using the content found at a URL The URL is sent to the server which performs the request recursive allow for recursive scraping of some types URLs for example on s urls 
Copy File copys a file from one pfs location to another It can be used on directories or regular files 
Get File returns the contents of a file at a specific Commit offset specifies a number of bytes that should be skipped in the beginning of the file size limits the total amount of data returned note you will get fewer bytes than size if you pass a value larger than the size of the file If size is set to then all of the data will be returned 
Get File Reader returns a reader for the contents of a file at a specific Commit offset specifies a number of bytes that should be skipped in the beginning of the file size limits the total amount of data returned note you will get fewer bytes than size if you pass a value larger than the size of the file If size is set to then all of the data will be returned 
Get File Read Seeker returns a reader for the contents of a file at a specific Commit that permits Seeking to different points in the file 
Inspect File returns info about a specific file 
List File returns info about all files in a Commit under path 
List File History returns info about all files and their history in a Commit under path 
List File F returns info about all files in a Commit under path calling f with each File Info 
Glob File returns files that match a given glob pattern in a given commit The pattern is documented here https golang org pkg path filepath Match 
Glob File F returns files that match a given glob pattern in a given commit calling f with each File Info The pattern is documented here https golang org pkg path filepath Match 
Diff File returns the difference between paths old path may be omitted in which case the parent of the new path will be used Diff File return values unless it returns an error the first value is files present under new path the second is files present under old path files which are under both paths and have identical content are omitted 
Walk walks the pfs filesystem rooted at path walk Fn will be called for each file found under path in lexicographical order This includes both regular files and directories 
Delete File deletes a file from a Commit Delete File leaves a tombstone in the Commit assuming the file isn t written to later attempting to get the file from the finished commit will result in not found error The file will of course remain intact in the Commit s parent 
Write performs a write 
Close closes the writer 
Object gets the pfs object for this writer This can only be called when the writer is closed the put object call is complete 
Pretty Print Version returns a version string optionally tagged with metadata For example or rc if version Additional is rc 
Pretty Print Version No Additional returns a version string without version Additional 
Walk the command tree wrap any examples in a block quote with shell highlighting 
err Missing Field returns a logical response error that prints a consistent error message for when a required field is missing 
validate Fields verifies that no bad arguments were given to the request 
put Config parses and returns the configuration data from the storage backend 
get Config parses and returns the configuration data from the storage backend 
get String Field extracts key from req and either returns the value as a string or an error response vault path handlers seem to return Error Response rather than actual errors for malformed requests 
Serve serves stuff 
New Puller creates a new Puller struct 
Pull clones an entire repo at a certain commit root is the local path you want to clone to file Info is the file dir we are puuling pipes causes the function to create named pipes in place of files thus lazily downloading the data as it s needed empty Files causes the function to create empty files with no content it s mutually exclusive with pipes tree is a hashtree to mirror the pulled content into it may be left nil tree Root is the root the data is mirrored to within tree 
Pull Diff is like Pull except that it materializes a Diff of the content rather than a the actual content If new Only is true then only new files will be downloaded and they will be downloaded under root Otherwise new and old files will be downloaded under root new and root old respectively 
Pull Tree pulls from a raw Hash Tree rather than a repo 
Clean Up cleans up blocked syscalls for pipes that were never opened And returns the total number of bytes that have been pulled pushed It also returns any errors that might have been encountered while trying to read data for the pipes Clean Up should be called after all code that might access pipes has completed running it should not be called concurrently 
Push puts files under root into an open commit 
Push Obj pushes data from commit to an object store 
Push File makes sure that pfs File has the same content as os File 
Dump writes debug information from the server to w 
Profile writes a pprof profile for pachd to w 
Binary writes the running pachd binary to w 
Register Cache Stats creates a new wrapper for groupcache stats that implements the prometheus Collector interface and registers it 
wait until more than n bytes have been written 
cancel indicates that an error has occurred which will prevent any further calls to Write it causes all calls to wait to return 
Run Workload runs a test workload against a Pachyderm cluster 
create Repo creates a new repo in the cluster 
advance Commit either starts or finishes a commit depending on the state of the cluster 
put File puts a file with random contents into a random open commit or exits early if there are none 
Rand String returns a random alphabetical string of size n 
New Reader returns a Reader which generates strings of characters 
New DBHash Tree creates a database bolt backed hashtree 
Deserialize DBHash Tree deserializes a hashtree into a database bolt backed hashtree 
Get gets a hashtree node 
Get gets a hashtree node 
iter Dir iterates through the nodes under path it errors with Path Not Found if path doesn t exist it errors with Path Conflict if path exists but isn t a directory 
List executes a callback for each file under a directory or a file if the path is a file 
List All retrieves all the files under a directory or a file if the path is a file 
List executes a callback for each file under a directory or a file if the path is a file 
Glob executes a callback for each path that matches the glob pattern 
Glob executes a callback for each path that matches the glob pattern 
FSSize gets the size of the hashtree 
Walk executes a callback against every node in the subtree of path 
Walk executes a callback against every node in the subtree of path 
Diff returns the diff of two hashtrees at particular paths 
Serialize serializes a binary version of the hashtree 
Deserialize deserializes a hashtree 
Copy returns a copy of the hashtree 
Destroy cleans up the on disk structures for the hashtree 
visit visits every ancestor of path excluding path itself leaf to root i e end of path to beginning and calls update on each node along the way For example if visit is called with path path to file then update Fn is called as follows update node at path to or nil path to file update node at path or nil path to update node at or nil path This is useful for propagating changes to size upwards 
Put File appends data to a file and creates the file if it doesn t exist 
Put File Overwrite is the same as Put File except that instead of appending the objects to the end of the given file the objects are inserted to the given index and the existing objects starting from the given index are removed 
Put Dir Header Footer implements the hashtree Put Dir Header Footer interface method 
Put File Header Footer implements the Hash Tree Put File Header Footer method 
Put Dir creates a directory or does nothing if one exists 
delete Dir deletes a directory and all the children under it 
Delete File deletes a regular file or directory along with its children 
New Reader creates a new hashtree reader 
Read reads the next merge node 
New Writer creates a new hashtree writer 
Write writes the next merge node 
Copy copies a hashtree reader in a writer 
Index returns the index for a hashtree writer 
Get Range From Index returns a subtree byte range in a serialized hashtree based on a passed in prefix 
New Filter creates a filter for a hashtree shard 
Path To Tree computes the hashtree shard for a path 
Merge merges a collection of hashtree readers into a hashtree writer 
Hash File Node computes the hash of node and writes the result into node Hash Exported so that PFS can compute the hash of synthetic nodes filenodes that inherit headers footers from their parent directories 
Hash updates all of the hashes and node size metadata it also checks for conflicts 
Is Glob checks if the pattern contains a glob character 
Glob Literal Prefix returns the prefix before the first glob character 
Get Hash Tree Object is a convenience function to deserialize a Hash Tree from an object in the object store 
Get Hash Tree Tag is a convenience function to deserialize a Hash Tree from an tagged object in the object store 
Put Hash Tree is a convenience function for putting a Hash Tree to an object store 
New Child Cursor creates a new child cursor 
Next gets the next key value pair 
New Ordered creates a new ordered hashtree 
Mkdir All puts all of the parent directories of a given path into the hashtree 
Put Dir puts a directory in the hashtree 
Put File puts a file in the hashtree 
Serialize serializes an ordered hashtree 
New Unordered creates a new unordered hashtree 
Put File puts a file in the hashtree 
Ordered converts an unordered hashtree into an ordered hashtree 
Revoke revokes the caller s credentials by sending a request to Pachyderm Unlike other handlers it doesn t get assigned to a path instead it s called by the vault lease API when a token s lease expires or is revoked It s set in Backend Secrets Revoke in backend go 
revoke User Credentials revokes the Pachyderm authentication token user Token using the vault plugin s Admin credentials 
New APIServer creates a new APIServer for the given Version 
Get Server Version gets the server Version given the grpc Client Conn 
String returns a string representation of the Version 
get Pipeline Info gets the Pipeline Info proto describing the pipeline that this worker is part of get Pipeline Info has the side effect of adding auth to the passed pach Client which is necessary to get the Pipeline Info from pfs 
insert Str inserts s into ss preserving sorting it assumes that ss is sorted If a copy is necessary because cap ss is too small only does one copy unlike append append ss idx new S ss idx This is because directory nodes may include a large number of children This is used to preserve the order in Directory Node Children which must be maintained so that equivalent directories have the same hash Returns true if new S was added to ss and false otherwise if new S is already in ss 
remove Str removes s from ss preserving the sorted order of ss for removing child strings from Directory Nodes 
Public Cert To PEM serializes the public x cert in cert to a PEM formatted block 
Key To PEM serializes the private key in cert to a PEM formatted block if it s an RSA key or nil otherwise all certs returned by Generate Self Signed Cert use RSA keys 
Generate Self Signed Cert generates a self signed TLS cert for the domain name address with a private key Other attributes of the subject can be set in name and ip addresses can be set in ip Addresses 
Activate Cmd returns a cobra Command to activate Pachyderm s auth system 
Deactivate Cmd returns a cobra Command to delete all ACLs tokens and admins deactivating Pachyderm s auth system 
Login Cmd returns a cobra Command to login to a Pachyderm cluster with your Git Hub account Any resources that have been restricted to the email address registered with your Git Hub account will subsequently be accessible 
Logout Cmd returns a cobra Command that deletes your local Pachyderm credential logging you out of your cluster Note that this is not necessary to do before logging in as another user but is useful for testing 
Whoami Cmd returns a cobra Command that deletes your local Pachyderm credential logging you out of your cluster Note that this is not necessary to do before logging in as another user but is useful for testing 
Check Cmd returns a cobra command that sends an Authorize RPC to Pachd to determine whether the specified user has access to the specified repo 
Get Cmd returns a cobra command that gets either the ACL for a Pachyderm repo or another user s scope of access to that repo 
Set Scope Cmd returns a cobra command that lets a user set the level of access that another user has to a repo 
List Admins Cmd returns a cobra command that lists the current cluster admins 
Modify Admins Cmd returns a cobra command that modifies the set of current cluster admins 
Get Auth Token Cmd returns a cobra command that lets a user get a pachyderm token on behalf of themselves or another user 
Use Auth Token Cmd returns a cobra command that lets a user get a pachyderm token on behalf of themselves or another user 
Cmds returns a list of cobra commands for authenticating and authorizing users in an auth enabled Pachyderm cluster 
Parse Scope parses the string s to a scope for example parsing a command line argument 
Is Err Not Activated checks if an error is a Err Not Activated 
Is Err Partially Activated checks if an error is a Err Partially Activated 
Is Err Not Signed In returns true if err is a Err Not Signed In 
Is Err No Metadata returns true if err is an Err No Metadata uses string comparison to work across RPC boundaries 
Is Err Bad Token returns true if err is a Err Bad Token 
Is Err Not Authorized checks if an error is a Err Not Authorized 
Is Err Invalid Principal returns true if err is an Err Invalid Principal 
Is Err Too Short TTL returns true if err is a Err Too Short TTL 
New Datum Factory creates a datum Factory for an input 
New Collection creates a new collection 
Path returns the full path of a key in the etcd namespace 
See the documentation for Index for details 
See the documentation for Index for details 
Giving a value an index and the key of the item return the path under which the new index item should be stored 
Giving a value a multi index and the key of the item return the paths under which the multi index items should be stored 
Upsert is like Update but key is not required to be present 
get is an internal wrapper around etcd Client Get that wraps the call in a trace 
List Prefix returns keys and values that begin with prefix f will be called with each key val will contain the value for the key You can break out of iteration by returning errutil Err Break 
List returns objects sorted based on the options passed in f will be called with each key val will contain the corresponding value Val is not an argument to f because that would require f to perform a cast before it could be used You can break out of iteration by returning errutil Err Break 
Watch a collection returning the current content of the collection as well as any future additions 
Watch By Index watches items in a collection that match a particular index 
Watch One watches a given item The first value returned from the watch will be the current value of the item 
Watch One F watches a given item and executes a callback function each time an event occurs The first value returned from the watch will be the current value of the item 
generate User Credentials uses the vault plugin s Admin credentials to generate a new Pachyderm authentication token for username i e the user who is currently requesting a Pachyderm token from Vault 
New Cache creates a new cache 
Put puts a key value pair in the cache and reads the value from an io Reader 
Get gets a key s value by returning an io Read Closer that should be closed when done 
Keys returns the keys in sorted order 
Delete deletes a key value pair 
Clear clears the cache 
New HTTPServer returns a Pachyderm HTTP server 
New Deploy Server creates a deploy server 
note this is not a standard s error 
note this is not a standard s error 
Cmds returns a slice containing debug commands 
Export a tarball of the images needed by a deployment 
Import a tarball of the images needed by a deployment such as the one created by Export and push those images to the registry specific in opts 
Datum Tag Prefix hashes a pipeline salt to a string of a fixed size for use as the prefix for datum output trees This prefix allows us to do garbage collection correctly 
New PFSInput returns a new PFS input It only includes required options 
New PFSInput Opts returns a new PFS input It includes all options 
New Cross Input returns an input which is the cross product of other inputs That means that all combination of datums will be seen by the job pipeline 
New Union Input returns an input which is the union of other inputs That means that all datums from any of the inputs will be seen individually by the job pipeline 
New Cron Input returns an input which will trigger based on a timed schedule It uses cron syntax to specify the schedule The input will be exposed to jobs as pfs name timestamp The timestamp uses the RFC format e g T Z 
New Job Input creates a pps Job Input 
New Pipeline Input creates a new pps Pipeline Input 
Create Job creates and runs a job in PPS This function is mostly useful internally users should generally run work by creating pipelines as well 
Inspect Job returns info about a specific job block State will cause the call to block until the job reaches a terminal state failure or success 
Inspect Job Output Commit returns info about a job that created a commit block State will cause the call to block until the job reaches a terminal state failure or success 
List Job returns info about all jobs If pipeline Name is non empty then only jobs that were started by the named pipeline will be returned If input Commit is non nil then only jobs which took the specific commits as inputs will be returned The order of the input Commits doesn t matter If output Commit is non nil then only the job which created that commit as output will be returned 
List Job F returns info about all jobs calling f with each Job Info If f returns an error iteration of jobs will stop and List Job F will return that error unless the error is errutil Err Break in which case it will return nil If pipeline Name is non empty then only jobs that were started by the named pipeline will be returned If input Commit is non nil then only jobs which took the specific commits as inputs will be returned The order of the input Commits doesn t matter If output Commit is non nil then only the job which created that commit as output will be returned 
Flush Job calls f with all the jobs which were triggered by commits If to Pipelines is non nil then only the jobs between commits and those pipelines in the DAG will be returned 
Flush Job All returns all the jobs which were triggered by commits If to Pipelines is non nil then only the jobs between commits and those pipelines in the DAG will be returned 
Delete Job deletes a job 
Stop Job stops a job 
Restart Datum restarts a datum that s being processed as part of a job datum Filter is a slice of strings which are matched against either the Path or Hash of the datum the order of the strings in datum Filter is irrelevant 
List Datum returns info about all datums in a Job 
List Datum F returns info about all datums in a Job calling f with each datum info 
Inspect Datum returns info about a single datum 
Next retrieves the next relevant log message from pachd 
Err retrieves any errors encountered in the course of calling Next 
Get Logs gets logs from a job logs includes stdout and stderr pipeline Name job ID data and datum ID are all filters To forego any filter simply pass an empty value though one of pipeline Name and job ID must be set Responses are written to messages 
Create Pipeline creates a new pipeline pipelines are the main computation object in PPS they create a flow of data from a set of input Repos to an output Repo which has the same name as the pipeline Whenever new data is committed to one of the input repos the pipelines will create jobs to bring the output Repo up to data image is the Docker image to run the jobs in cmd is the command passed to the Docker run invocation NOTE as with Docker cmd is not run inside a shell that means that things like wildcard globbing pipes and file redirects and will not work To get that behavior you should have your command be a shell of your choice and pass a shell script to stdin stdin is a slice of lines that are sent to your command on stdin Lines need not end in newline characters parallelism is how many copies of your container should run in parallel You may pass for parallelism in which case PPS will set the parallelism based on available resources input specifies a set of Repos that will be visible to the jobs during runtime commits to these repos will cause the pipeline to create new jobs to process them update indicates that you want to update an existing pipeline 
Inspect Pipeline returns info about a specific pipeline 
List Pipeline returns info about all pipelines 
Delete Pipeline deletes a pipeline along with its output Repo 
Start Pipeline restarts a stopped pipeline 
Stop Pipeline prevents a pipeline from processing things it can be restarted with Start Pipeline 
Rerun Pipeline reruns a pipeline over a given set of commits Exclude and include are filters that either include or exclude the ancestors of the given commits A commit is considered the ancestor of itself The behavior is the same as that of List Commit 
Create Pipeline Service creates a new pipeline service 
Garbage Collect garbage collects unused data Currently GC needs to be run while no data is being added or removed which among other things implies that there shouldn t be jobs actively running Pfs Garbage collection uses bloom filters to keep track of live objects because it can store more objects than can be indexed in memory This means that there is a chance for unreferenced objects to not be GCed this chance increases as the number of objects in the system increases You can tradeoff using more memory to get a lower chance of collisions the default value is MB and collisions should be unlikely until you have million objects 
Get Datum Total Time sums the timing stats from a Datum Info 
Mount pfs to mount Point opts may be left nil 
New Buf Pool creates a new Buf Pool that returns buffers of the given size 
Storage Root From Env gets the storage root based on environment variables 
Block Path From Env gets the path to an object storage block based on environment variables 
New Google Client creates a google client with the given bucket name 
New Google Client From Secret creates a google client by reading credentials from a mounted Google Secret You may pass for bucket in which case it will read the bucket from the secret 
New Google Client From Env creates a Google client based on environment variables 
New Microsoft Client creates a microsoft client container Azure Blob Container name account Name Azure Storage Account name account Key Azure Storage Account key 
New Microsoft Client From Secret creates a microsoft client by reading credentials from a mounted Microsoft Secret You may pass for container in which case it will read the container from the secret 
New Microsoft Client From Env creates a Microsoft client based on environment variables 
New Minio Client creates an s compatible client with the following credentials endpoint S compatible endpoint bucket S bucket name id AWS access key id secret AWS secret access key secure Set to true if connection is secure is S V Set to true if client follows S V 
New Amazon Client creates an amazon client with the following credentials bucket S bucket name distribution cloudfront distribution ID id AWS access key id secret AWS secret access key token AWS access token region AWS region 
New Minio Client From Secret constructs an s compatible client by reading credentials from a mounted Amazon Secret You may pass for bucket in which case it will read the bucket from the secret 
New Minio Client From Env creates a Minio client based on environment variables 
New Amazon Client From Secret constructs an amazon client by reading credentials from a mounted Amazon Secret You may pass for bucket in which case it will read the bucket from the secret 
New Amazon Client From Env creates a Amazon client based on environment variables 
New Client From URLAnd Secret constructs a client by parsing URL and then constructing the correct client for that URL using secrets 
Parse URL parses an URL into Object Store URL 
New Client From Env creates a client based on environment variables 
New Exponential Back Off Config creates an exponential back off config with longer wait times than the default 
Close closes the Reader Closer contained in b 
Close closes the Write Closer contained in b 
Is Retryable determines if an operation should be retried given an error 
Run Stdin runs the command with the given stdin and arguments 
Run IODir Path runs the command with the given IO and arguments in the given directory specified by dir Path 
Log Req is like log Logger Log but it assumes that it s being called from the top level of a GRPC method implementation and correspondingly extracts the method name from the parent stack frame 
Log Resp is like log Logger Log However It assumes that it s being called from a defer statement in a GRPC method and correspondingly extracts the method name from the grandparent stack frame It logs Not Activated Error at Debug Level instead of Error Level as in most cases this error is expected and logging it frequently may confuse users 
New Auth Server returns an implementation of authclient APIServer 
activation State returns none if auth is totally inactive partial if auth Activate has been called but hasn t finished or failed and full if auth Activate has been called and succeeded When the activation state is partial users cannot authenticate the only functioning auth API calls are Activate to retry activation and Deactivate to give up and revert to the none state 
Retrieve the PPS master token or generate it and put it in etcd TODO This is a hack It avoids the need to return superuser tokens from Get Auth Token essentially PPS and Auth communicate through etcd instead of an API but we should define an internal API and use that instead 
Git Hub Token To Username takes a OAuth access token issued by Git Hub and uses it discover the username of the user who obtained the code or verify that the code belongs to github Username This is how Pachyderm currently implements authorization in a production cluster 
expired Cluster Admin Check enforces that if the cluster s enterprise token is expired only admins may log in 
get One Time Password contains the implementation of Get One Time Password but is also called directly by handle SAMLREsponse It generates a short lived authentication code for username writes it to a authentication Codes and returns it 
get Scope is a helper function for the Get Scope GRPC API as well is Authorized and other authorization checks e g checking if a user is an OWNER to determine if they can modify an ACL 
set Groups For User Internal is a helper function used by Set Groups For User and also by handle SAMLResponse which updates group membership information based on signed SAML assertions This does no auth checks so the caller must do all relevant authorization 
get Groups is a helper function used primarily by the GRPC API Get Groups but also by Authorize and is Admin 
hash Token converts a token to a cryptographic hash We don t want to store tokens verbatim in the database as then whoever that has access to the database has access to all tokens 
get Auth Token extracts the auth token embedded in ctx if there is on 
canonicalize Subjects applies canonicalize Subject to a list 
canonicalize Subject establishes the type of subject by looking for one of pachyderm s subject prefixes and then canonicalizes the subject based on that If subject has no prefix they are assumed to be a Git Hub user TODO msteffen We d like to require that subjects always have a prefix but this behavior hasn t been implemented in the dash yet 
canonicalize Git Hub Username corrects user for case errors by looking up the corresponding user s Git Hub profile and extracting their login ID from that user should not have any subject prefixes as they are required to be a Git Hub user 
Matches checks that a string matches a regular expression 
One Of Matches checks whether one element of a slice matches a regular expression 
Equal checks equality of two values 
Not Equal checks inequality of two values 
Elements Equal Or Err returns nil if the elements of the slice expecteds are exactly the elements of the slice actuals ignoring order i e setwise equal and an error otherwise Unlike other require functions this returns an error so that if the caller is polling e g List Commit or List Admins they can wrap Elements Equal Or Err in a retry loop Also like Elements Equal treat nil and the empty slice as equivalent for convenience 
Elements Equal Under Fn checks that the elements of the slice expecteds are exactly the images of every element of the slice actuals under f ignoring order i e expecteds and map f actuals are setwise equal but respecting duplicates This is useful for cases where Elements Equal doesn t quite work e g because the type in expecteds actuals contains a pointer or actuals contains superfluous data which you wish to discard Like Elements Equal treat nil and the empty slice as equivalent for convenience 
Elements Equal checks that the elements of the slice expecteds are exactly the elements of the slice actuals ignoring order i e setwise equal but respecting duplicates Note that if the elements of expecteds and actuals are pointers Elements Equal will unwrap the pointers before comparing them so that the output of e g List Commit which returns pfs Commit can easily be verfied Also treat nil and the empty slice as equivalent so that callers can pass nil for expecteds 
one Of Equals is a helper function for Equal One Of One Of Equals and None Equals that simply returns a bool indicating whether elem is in slice slice Name is used for errors 
Equal One Of checks if a value is equal to one of the elements of a slice Note that if expecteds and actual are a slice of pointers and a pointer respectively then the pointers are unwrapped before comparison so this functions works for e g pfs Commit and pfs Commit 
None Equals checks one element of a slice equals a value Like Equals One Of None Equals unwraps pointers 
No Error checks for no error 
No Error Within T checks that f finishes within time t and does not emit an error 
No Error Within TRetry checks that f finishes within time t and does not emit an error Unlike No Error Within T if f does error it will retry it 
Yes Error checks for an error 
Not Nil checks a value is non nil 
Nil checks a value is nil 
False checks a value is false 
New STM intiates a new STM operation It uses a serializable model 
New Dryrun STM intiates a new STM operation but the final commit is skipped It uses a serializable model 
new STMRepeatable initiates new repeatable read transaction reads within the same transaction attempt to always return the same data 
new STMSerializable initiates a new serialized transaction reads within the same transaction attempt to return data from the revision of the first read 
new STMRead Committed initiates a new read committed transaction 
cmps guards the txn from updates to read set 
puts is the list of ops for all pending writes 
commit always goes through when read committed 
fetch TTL contains the essential implementation of TTL Note that iface should either be the receiver s or a containing stm Serializeable the only reason iface is passed as a separate argument is because fetch TTL calls iface fetch and the implementation of fetch is different for stm and stm Serializeable Passing the interface ensures the correct version of fetch is called 
Pipelines returns a Collection of pipelines 
Jobs returns a Collection of jobs 
New Ticker returns a new Ticker containing a channel that will send the time at times specified by the Back Off argument Ticker is guaranteed to tick at least once The channel is closed when Stop method is called or Back Off stops 
custom Check Retry is a fork of etcd s Default Check Retry except that it issues more retries before giving up Because Pachyderm often starts before etcd is ready retrying Pachd s connection to etcd in a tight loop s is often much faster than waiting for kubernetes to restart the pachd pod 
node To Map translates the contents of a node into a map node To Map can be called on the same map with successive results from watch to accumulate a value node To Map returns true if out was modified 
fill Default Resource Requests sets any of opts Block Cache Size opts Pachd Non Cache Mem Request opts Pachd CPURequest opts Etcd CPURequest opts Etcd Mem Request that are unset in opts to the appropriate default persistent Disk Backend just used to determine if this is a local deployment and if so make the resource requests smaller 
Service Account returns a kubernetes service account for use with Pachyderm 
Cluster Role returns a Cluster Role that should be bound to the Pachyderm service account 
Role Binding returns a Role Binding that binds Pachyderm s Role to its Service Account 
Get Backend Secret Volume And Mount returns a properly configured Volume and Volume Mount object given a backend The backend needs to be one of the constants defined in pfs server 
Get Secret Env Vars returns the environment variable specs for the storage secret 
Pachd Deployment returns a pachd k s Deployment 
Pachd Service returns a pachd service 
Githook Service returns a k s service that exposes a public IP 
Etcd Deployment returns an etcd k s Deployment 
Etcd Storage Class creates a storage class used for dynamic volume provisioning Currently dynamic volume provisioning only works on AWS and GCE 
Etcd Volume creates a persistent volume backed by a volume with name name 
Etcd Volume Claim creates a persistent volume claim of size GB Note that if you re controlling Etcd with a Stateful Set this is unnecessary the stateful set controller will create PVCs automatically 
Etcd Node Port Service returns a Node Port etcd service This will let non etcd pods talk to etcd 
Etcd Headless Service returns a headless etcd service which is only for DNS resolution 
Etcd Stateful Set returns a stateful set that manages an etcd cluster 
Dash Deployment creates a Deployment for the pachyderm dashboard 
Dash Service creates a Service for the pachyderm dashboard 
Minio Secret creates an amazon secret with the following parameters bucket S bucket name id S access key id secret S secret access key endpoint S compatible endpoint secure set to true for a secure connection is S V Set to true if client follows S V 
Write Secret writes a JSON encoded k s secret to the given writer The secret uses the given map as data 
Amazon Secret creates an amazon secret with the following parameters region AWS region bucket S bucket name id AWS access key id secret AWS secret access key token AWS access token distribution cloudfront distribution 
Amazon Vault Secret creates an amazon secret with the following parameters region AWS region bucket S bucket name vault Address address hostport of vault vault Role pachd s role in vault vault Token pachd s vault token distribution cloudfront distribution 
Amazon IAMRole Secret creates an amazon secret with the following parameters region AWS region bucket S bucket name distribution cloudfront distribution 
Google Secret creates a google secret with a bucket name 
Microsoft Secret creates a microsoft secret with following parameters container Azure blob container id Azure storage account name secret Azure storage account key 
Write Dashboard Assets writes the k s config for deploying the Pachyderm dashboard to encoder 
Write Assets writes the assets to encoder 
Write TLSSecret creates a new TLS secret in the kubernetes manifest equivalent to one generate by kubectl create secret tls This will be mounted by the pachd pod and used as its TLS public certificate and private key 
Write Local Assets writes assets to a local backend 
Write Custom Assets writes assets to a custom combination of object store and persistent disk 
Write Amazon Assets writes assets to an amazon backend 
Write Google Assets writes assets to a google backend 
Write Microsoft Assets writes assets to a microsoft backend 
Images returns a list of all the images that are used by a pachyderm deployment 
Add Registry switches the registry that an image is targeting unless registry is blank 
with Canonical Randomization Factor is a utility function used by all New XYZBackoff functions to clamp b Randomization Factor to either or 
New s Back Off returns a backoff that s slightly more aggressive than New Exponential Back Off The Max Elapsed time for this backoff is s and the initial backoff is ms instead of Therefore this will retry at most times and then fail depending on RPC timeout and may be more useful for interactive RPCs than the default timeout of s 
Reset the interval back to the initial retry interval and restarts the timer 
Next Back Off calculates the next backoff interval using the formula Randomized interval Retry Interval Randomization Factor Retry Interval 
Get Elapsed Time returns the elapsed time since an Exponential Back Off instance is created and is reset when Reset is called The elapsed time is computed using time Now Unix Nano 
Increments the current interval by multiplying it with the multiplier 
Returns a random value from the following interval randomization Factor current Interval randomization Factor current Interval 
Factory is the function that the Pachyderm Vault plugin exports to let Vault create refresh revoke Pachyderm tokens 
New APIServer creates an APIServer 
New Block APIServer creates a Block APIServer using the credentials it finds in the environment 
Local Storage creates a local chunk storage instance Useful for storage layer tests 
wait Job waits for the job in job Info to finish and then it collects the output from the job s workers and merges it into a commit and may merge stats into a commit in the stats branch as well 
delete Job is identical to update Job State except that job Ptr points to a job that should be deleted rather than marked failed Jobs may be deleted if their output commit is deleted 
write XML serializes a struct to a response as XML 
clean canonicalizes path for a Pachyderm hashtree 
New From Address constructs a new APIClient for the server at addr 
With Max Concurrent Streams instructs the New functions to create client that can have at most streams concurrent streams open with pachd at a time 
With Root CAs instructs the New functions to create client that uses the given signed x certificates as the trusted root certificates instead of the system certs Introduced to pass certs provided via command line flags 
With Additional Root CAs instructs the New functions to additionally trust the given base encoded signed x certificates as root certificates Introduced to pass certs in the Pachyderm config 
With Dial Timeout instructs the New functions to use t as the deadline to connect to pachd 
With Additional Pachd Cert instructs the New functions to additionally trust the signed cert mounted in Pachd s cert volume This is used by Pachd when connecting to itself if no cert is present the clients cert pool will not be modified so that if no other options have been passed pachd will connect to itself over an insecure connection 
get User Machine Addr And Opts is a helper for New On User Machine that uses environment variables config files etc to figure out which address a user running a command should connect to 
New On User Machine constructs a new APIClient using env vars that may be set on a user s machine i e PACHD ADDRESS as well as HOME pachyderm config if it exists This is primarily intended to be used with the pachctl binary but may also be useful in tests TODO msteffen this logic is fairly linux unix specific and makes the pachyderm client library incompatible with Windows We may want to move this and similar logic into src server and have it call a New From Options constructor 
New In Cluster constructs a new APIClient using env vars that Kubernetes creates This should be used to access Pachyderm from within a Kubernetes cluster with Pachyderm running on it 
Close the connection to g RPC 
Delete All deletes everything in the cluster Use with caution there is no undo 
Set Max Concurrent Streams Sets the maximum number of concurrent streams the client can have It is not safe to call this operations while operations are outstanding 
Default Dial Options is a helper returning a slice of grpc Dial options such that grpc Dial is synchronous the call doesn t return until the connection has been established and it s safe to send RPCs 
Add Metadata adds necessary metadata including authentication credentials to the context ctx preserving any metadata that is present in either the incoming or outgoing metadata of ctx 
Ctx is a convenience function that returns adds Pachyderm authn metadata to context Background 
With Ctx returns a new APIClient that uses ctx for requests it sends Note that the new APIClient will still use the authentication token and metrics metadata of this client so this is only useful for propagating other context associated metadata 
New DLock attempts to acquire a distributed lock that locks a given prefix in the data store 
Datum ID computes the id for a datum this value is used in List Datum and Inspect Datum 
Logf logs the line Sprintf format String args but formatted as a json message and annotated with all of the metadata stored in loginfo Note this is not thread safe as it modifies fields of logger template 
New APIServer creates an APIServer for a given pipeline 
Run user error code and return the combined output of stdout and stderr 
Hash Datum computes and returns the hash of datum pipeline with a pipeline specific prefix 
Hash Datum computes and returns the hash of datum pipeline for version with a pipeline specific prefix 
Status returns the status of the current worker 
Cancel cancels the currently running datum 
Get Chunk returns the merged datum hashtrees of a particular chunk if available 
cancel Ctx If Job Fails watches job ID s Job Ptr and if its state is changed to a terminal state KILLED FAILED or SUCCESS cancel the job Ctx so we kill any user processes 
worker does the following claims filesystem shards as they become available watches for new jobs job Infos in the jobs collection claims chunks from the chunk layout it finds in the chunks collection claims those chunks with acquire Datums processes the chunks with process Datums merges the chunks with merge Datums 
process Datums processes datums from low to high in df if a datum fails it returns the id of the failed datum it also may return a variety of errors such as network errors 
merge Stats merges y into x 
merge Chunk merges the datum hashtrees into a chunk hashtree and stores it 
lookup Docker User looks up users given the argument to a Dockerfile USER directive According to Docker s docs this directive looks like USER user group or USER UID GID 
Cmds returns a slice containing pfs commands 
Is Commit Not Found Err returns true if err has an error message that matches Err Commit Not Found 
Is Commit Deleted Err returns true if err has an error message that matches Err Commit Deleted 
Is Commit Finished Err returns true of err has an error message that matches Err Commit Finished 
Is Repo Not Found Err returns true if err is an error message about a repo not being found 
Is Branch Not Found Err returns true if err is an error message about a branch not being found 
Is File Not Found Err returns true if err is an error message about a PFS file not being found 
Version returns the version of pachd as a string 
validate Repo Name determines if a repo name is valid 
new Driver is used to create a new Driver instance 
check Is Authorized returns an error if the current user in pach Client has authorization scope s for repo r 
make commit makes a new commit in branch with the parent parent and the direct provenance provenance Note that parent must not be nil but the only required field is parent Repo parent ID may be set to in which case the parent commit is inferred from parent Repo and branch If both parent ID and branch are set parent ID determines the parent commit but branch is still moved to point at the new commit to the new commit If neither parent ID nor branch are set the new commit will have no parent If only parent ID is set and it contains a branch then the new commit s parent will be the HEAD of that branch but the branch will not be moved 
write Finished Commit writes these changes to etcd it closes the input commit i e it writes any changes made to it and removes it from the open commits if the commit is the new HEAD of master it updates the repo size 
propagate Commit selectively starts commits in or downstream of branch in order to restore the invariant that branch provenance matches HEAD commit provenance B Head is provenant on A Head branch B is provenant on branch A and A Head nil The implementation assumes that the invariant already holds for all branches upstream of branch but not necessarily for branch itself Despite the name branch does not need a HEAD commit to propagate though one may be created In other words propagate Commit scans all branches b downstream that are equal to or downstream of branch and if the HEAD of b downstream isn t provenant on the HEADs of b downstream s provenance propagate Commit starts a new HEAD commit in b downstream that is For example propagate Commit starts downstream output commits which trigger PPS jobs when new input commits arrive on branch when branch s HEAD is deleted or when branch is newly created i e in Create Pipeline 
inspect Commit takes a Commit and returns the corresponding Commit Info As a side effect this function also replaces the ID in the given commit with a real commit ID 
resolve Commit contains the essential implementation of inspect Commit it converts commit which may be a commit ID or branch reference plus and or to a repo commit ID It accepts an STM so that it can be used in a transaction and avoids an inconsistent call to d inspect Commit 
create Branch creates a new branch or updates an existing branch must be one or the other Most importantly it sets branch Direct Provenance to provenance and then for all downstream branches restores the invariant b b Provenance b Provenance where b b Direct Provenance This invariant is assumed to hold for all branches upstream of branch but not for branch itself once b Provenance has been set 
scratch Commit Prefix returns an etcd prefix that s used to temporarily store the state of a file in an open commit Once the commit is finished the scratch space is removed 
scratch File Prefix returns an etcd prefix that s used to temporarily store the state of a file in an open commit Once the commit is finished the scratch space is removed 
header Dir To Put File Records is a helper for copy File that handles copying header footer directories Copy uses essentially the same codepath as put File it converts hashtree node s to Put File Records and then uses apply Write to put the records back in the target hashtree In put File the only way to create a header Dir is with Put File Split Put File Record with Split true Rather than split the put File codepath by adding a special case to apply Write that was valid for copy File but invalid for put File we use heaader Dir To Put File Records to convert a Directory Node to a Put File Record Split true which apply Write will correctly convert back to a header dir in the target hashtree via the regular put File codepath 
get Tree For File is like get Tree For Commit except that it can handle open commits It takes a file instead of a commit so that it can apply the changes for that path to the tree before it returns it 
this is a helper function to check if the given provenance has provenance on an input branch 
If full is false exclude potentially large fields such as Objects and Children 
node To File Info Header Footer is like node To File Info but handles the case which currently only occurs in input commits where files have a header that is stored in their parent directory 
file History calls f with File Infos for the file starting with how it looked at the referenced commit and then all past versions that are different 
Put the tree into the blob store Only write the records to etcd if the commit does exist and is open To check that a key exists in etcd we assert that its Create Revision is greater than zero 
Read Row parses the pgdump file and populates the header and the footer It returns EOF when done and at that time both the Header and Footer will be populated Both header and footer are required If either are missing an error is returned 
New Reporter creates a new reporter and kicks off the loop to report cluster metrics 
Report User Action pushes the action into a queue for reporting and reports the start finish and error conditions 
Helper method called by Start Finish Report And Flush User Action Like those functions it is used by the pachctl binary and runs on users machines TODO msteffen Wrap config parsing in a library 
Finish Report And Flush User Action immediately reports the metric but does not block execution It returns a wait function which waits or times out after s It is used by the pachctl binary and runs on users machines 
Read reads from the byte stream produced by the set of Data Refs 
Unfortunately Go s pre defined format strings for parsing RFC compliant timestamps aren t exhaustive This method attempts to parse a larger set of of ISO compatible timestampts which are themselves a subset of RFC timestamps 
Activate Cmd returns a cobra Command to activate the enterprise features of Pachyderm within a Pachyderm cluster All repos will go from publicly accessible to accessible only by the owner who can subsequently add users 
Get State Cmd returns a cobra Command to activate the enterprise features of Pachyderm within a Pachyderm cluster All repos will go from publicly accessible to accessible only by the owner who can subsequently add users 
Cmds returns pachctl commands related to Pachyderm Enterprise 
New Configuration creates a generic configuration from a specific type of configuration 
Repos returns a collection of repos 
Put File Records returns a collection of put File Records 
Commits returns a collection of commits 
Branches returns a collection of branches 
Open Commits returns a collection of open commits 
New DAG creates a DAG and populates it with the given nodes 
New Node adds a node to d 
Sorted returns all nodes in a topologically sorted order 
Leaves returns a slice containing all leaves in d 
Ancestors returns a slice containing all ancestors of a node id in d which are a descendant of at least one of the nodes in from 
Descendants returns a slice containing all descendants of a node id in d which are an ancestor of at least one of the nodes in to 
Ghosts returns nodes that were referenced as parents but never created 
New Port Forwarder creates a new port forwarder 
Run starts the port forwarder Returns after initialization is begun returning any initialization errors 
Run For Daemon creates a port forwarder for the pachd daemon 
Run For SAMLACS creates a port forwarder for SAML ACS 
Run For Dash UI creates a port forwarder for the dash UI 
Run For Dash Web Socket creates a port forwarder for the dash websocket 
Run For PFS creates a port forwarder for PFS over HTTP 
Run For S Gateway creates a port forwarder for the s gateway 
Lock uses pidfiles to ensure that only one port forwarder is running across one or more pachctl instances 
Close shuts down port forwarding 
Unmarshal unmarshals the item in an event into a protobuf message 
Unmarshal Prev unmarshals the prev item in an event into a protobuf message 
New Watcher watches a given etcd prefix for events 
Make Watcher returns a Watcher that uses the given event channel and done channel internally to deliver events and signal closure respectively 
Check Type checks to make sure val has the same type as template unless template is nil in which case it always returns nil 
New Pool creates a new connection pool with connections to pods in the given service 
Do allows you to do something with a grpc Client Conn Errors returned from f will be returned by Do 
Close closes all connections stored in the pool it returns an error if any of the calls to Close error 
Cmds returns a slice containing pps commands 
build Image builds a new docker image 
push Image pushes a docker image 
is Docker Using Keychain checks if the user has a configuration that is not readable by our current docker client library TODO ys remove if when this issue is addressed https github com fsouza go dockerclient issues 
Creates a new minio Client structure and returns 
Creates a new minio Client S V structure and returns 
Creates a new minio writer and a go routine to upload objects to minio server 
This will block till upload is done 
Pipeline Repo creates a pfs repo for a given pipeline 
Pipeline Rc Name generates the name of the k s replication controller that manages a pipeline s workers 
Get Requests Resource List From Pipeline returns a list of resources that the pipeline minimally requires 
Get Limits Resource List From Pipeline returns a list of resources that the pipeline maximally is limited to 
get Num Nodes attempts to retrieve the number of nodes in the current k s cluster 
Get Expected Num Workers computes the expected number of workers that pachyderm will start given the Parallelism Spec spec This is only exported for testing 
Get Expected Num Hashtrees computes the expected number of hashtrees that Pachyderm will create given the Hashtree Spec spec 
Get Pipeline Info retrieves and returns a valid Pipeline Info from PFS It does the PFS read unmarshalling of bytes as well as filling in missing fields 
Fail Pipeline updates the pipeline s state to failed and sets the failure reason 
Job Input fills in the commits for a Job Info 
Pipeline Req From Info converts a Pipeline Info into a Create Pipeline Request 
New Pipeline Manifest Reader creates a new manifest reader from a path 
Next Create Pipeline Request gets the next request from the manifest reader 
Describe Syntax Error describes a syntax error encountered parsing json 
Is Terminal returns true if state indicates that the job is done i e the state will not change later SUCCESS FAILURE KILLED and false otherwise 
Update Job State performs the operations involved with a job state transition 
fetch Raw IDPMetadata is a helper of validate Config below It takes the URL of a SAML Id P s Metadata service queries it parses the result and returns it as a struct the crewjam saml library can use This code is heavily based on the crewjam saml samlsp Middleware constructor 
update Config validates config and if it valides successfully loads it into the api Server s config cache The caller should already hold a config Mu and a saml SPMu as this updates a saml SP 
handle SAMLResponse Internal is a helper function called by handle SAMLResponse 
handle SAMLResponse is the HTTP handler for Pachyderm s ACS which receives signed SAML assertions from this cluster s SAML ID provider if one is configured 
New returns a new uuid 
Code returns the HTTP error code associated with h 
Pretty Print Code renders h as error code description e g OK 
New HTTPError returns a new HTTPError where the HTTP error code is code and the error message is based on format Str and args 
New Storage creates a new Storage 
New Reader creates an io Read Closer for a chunk bryce The whole chunk is in memory right now Could be a problem with concurrency particularly the merge process May want to handle concurrency here pass in multiple data refs 
New Writer creates an io Write Closer for a stream of bytes to be chunked Chunks are created based on the content then hashed and deduplicated uploaded to object storage The callback arguments are the chunk hash and content 
Delete All deletes all of the chunks in object storage 
Chunk splits a piece of data up this is useful for splitting up data that s bigger than Max Msg Size 
Chunk Reader splits a reader into reasonably sized chunks for the purpose of transmitting the chunks over g RPC For each chunk it calls the given function 
New Streaming Bytes Reader returns an io Reader for a Streaming Bytes Client 
Write To Streaming Bytes Server writes the data from the io Reader to the Streaming Bytes Server 
Write From Streaming Bytes Client writes from the Streaming Bytes Client to the io Writer 
New APIServer creates an APIServer 
New Sidecar APIServer creates an APIServer that has limited functionalities and is meant to be run as a worker sidecar It cannot for instance create pipelines 
New Enterprise Server returns an implementation of ec APIServer 
validate Activation Code checks the validity of an activation code 
Activate implements the Activate RPC 
Get State returns the current state of the cluster s Pachyderm Enterprise key ACTIVE EXPIRED or NONE 
Deactivate deletes the current cluster s enterprise token and puts the cluster in the NONE enterprise state It also deletes all data in the cluster to avoid invalid cluster states This call only makes sense for testing 
Command returns the Cmd struct to execute the named program with the given arguments It sets only the Path and Args in the returned structure If name contains no path separators Command uses Look Path to resolve name to a complete path if possible Otherwise it uses name directly as Path The returned Cmd s Args field is constructed from the command name followed by the elements of arg so arg should not include the command name itself For example Command echo hello Args is always name not the possibly resolved Path 
Command Context is like Command but includes a context The provided context is used to kill the process by calling os Process Kill if the context becomes done before the command completes on its own 
Run starts the specified command and waits for it to complete The returned error is nil if the command runs has no problems copying stdin stdout and stderr and exits with a zero exit status If the command starts but does not complete successfully the error is of type Exit Error Other error types may be returned for other situations 
look Extensions finds windows executable by its dir and path It uses Look Path to try appropriate extensions look Extensions does not search PATH instead it converts prog into prog 
Start starts the specified command but does not wait for it to complete The Wait method will return the exit code and release associated resources once the command exits 
Wait waits for the command to exit and waits for any copying to stdin or copying from stdout or stderr to complete The command must have been started by Start The returned error is nil if the command runs has no problems copying stdin stdout and stderr and exits with a zero exit status If the command fails to run or doesn t complete successfully the error is of type Exit Error Other error types may be returned for I O problems If c Stdin is not an os File Wait also waits for the I O loop copying from c Stdin into the process s standard input to complete Wait releases any resources associated with the Cmd 
Wait IO is a helper function and the reason we forked this package from stdlib This way we can manually close IO when c Process Wait has already been called once 
Output runs the command and returns its standard output Any returned error will usually be of type Exit Error If c Stderr was nil Output populates Exit Error Stderr 
Combined Output runs the command and returns its combined standard output and standard error 
Stdin Pipe returns a pipe that will be connected to the command s standard input when the command starts The pipe will be closed automatically after Wait sees the command exit A caller need only call Close to force the pipe to close sooner For example if the command being run will not exit until standard input is closed the caller must close the pipe 
safe Close closes c being careful not to race with any calls to c Write See golang org issue and Test Echo File Race in exec test go In theory other calls could also be excluded by writing appropriate wrappers like c Write s implementation below but since c is most commonly used as a Write Closer Write is the main one to worry about See also for which this is a partial fix for this specific instance The idea is that we return a Write Closer and so the caller can be relied upon not to call Write and Close simultaneously but it s less obvious that cmd Wait calls Close and that the caller must not call Write and cmd Wait simultaneously In fact that seems too onerous So we change the use of Close in cmd Wait to use safe Close which will synchronize with any Write It s important that we know this won t block forever waiting for the operations being excluded At the point where this is called the invoked command has exited and the parent copy of the read side of the pipe has also been closed so there should really be no read side of the pipe left Any active writes should return very shortly with an EPIPE making it reasonable to wait for them Technically it is possible that the child forked a sub process or otherwise handed off the read side of the pipe before exiting and the current holder is not reading from the pipe and the pipe is full in which case the close here might block waiting for the write to complete That s probably OK It s a small enough problem to be outweighed by eliminating the race here 
Stdout Pipe returns a pipe that will be connected to the command s standard output when the command starts Wait will close the pipe after seeing the command exit so most callers need not close the pipe themselves however an implication is that it is incorrect to call Wait before all reads from the pipe have completed For the same reason it is incorrect to call Run when using Stdout Pipe See the example for idiomatic usage 
dedup Env Case is dedup Env with a case option for testing If case Insensitive is true the case of keys is ignored 
Visit Input visits each input recursively in ascending order root last 
Input Name computes the name of an Input 
Sort Input sorts an Input 
Input Branches returns the branches in an Input 
Validate Git Clone URL returns an error if the provided URL is invalid 
contains Empty is a helper function used for validation particularly for validating that creds arguments aren t empty 
deploy Cmds returns the set of cobra Commands used to deploy pachyderm 
Cmds returns a list of cobra commands for deploying Pachyderm clusters 
Main runs the common functionality needed in a go main function app Env will be populated and passed to do default Env can be nil if there is an error os Exit will be called 
New APIServer returns a new admin APIServer 
Unescape HTML returns s with and unescaped 
Ago pretty prints the amount of time that has passed since timestamp as a human readable string 
Time Difference pretty prints the duration of time between from and to as a human reabable string 
Duration pretty prints a duration in a human readable way 
Inspect Cluster retrieves cluster state 
Extract all cluster state call f with each operation 
Extract All cluster state as a slice of operations 
Extract Writer extracts all cluster state and marshals it to w 
Extract URL extracts all cluster state and marshalls it to object storage 
Extract Pipeline extracts a single pipeline 
Restore cluster state from an extract series of operations 
Restore Reader restores cluster state from a reader containing marshaled ops Such as those written by Extract Writer 
Restore From restores state from another cluster which can be access through other C 
Restore URL restures cluster state from object storage 
 Parses a new Evaluable Expression from the given expression string Returns an error if the given expression has invalid syntax 
 Similar to New Evaluable Expression except that instead of a string an already tokenized expression is given This is useful in cases where you may be generating an expression automatically or using some other parser e g to parse from a query language 
 Similar to New Evaluable Expression except enables the use of user defined functions Functions passed into this will be available to the expression 
 Same as Eval but automatically wraps a map of parameters into a govalute Parameters structure 
 Runs the entire expression using the given parameters e g If the expression contains a reference to the variable foo it will be taken from parameters Get foo 
 Returns an array representing the variables contained in this Evaluable Expression 
 Returns true if this operator is contained by the given array of candidate symbols False otherwise 
 Generally used when formatting type check errors We could store the stringified symbol somewhere else and not require a duplicated codeblock to translate Operator Symbol to string but that would require more memory and another field somewhere Adding operators is rare enough that we just stringify it here instead 
 Returns a string representing this expression as if it were written in SQL This function assumes that all parameters exist within the same table and that the table essentially represents a serialized object of some sort e g hibernate If your data model is more normalized you may need to consider iterating through each actual token given by Tokens to create your query 
 Get Token Kind String returns a string that describes the given Token Kind e g when passed the NUMERIC Token Kind this returns the string NUMERIC 
 Returns the string that was read until the given condition was false or whitespace was broken Returns false if the stream ended before whitespace was broken or condition was met 
 Checks to see if any optimizations can be performed on the given tokens which form a complete valid expression The returns slice will represent the optimized or unmodified list of tokens to use 
 Checks the balance of tokens which have multiple parts such as parenthesis 
 Attempts to parse the candidate as a Time Tries a series of standardized date formats returns the Time if one applies otherwise returns false through the second return 
 Given a planner creates a function which will evaluate a specific precedence level of operators and link it to other precedent s which recurse to parse other precedence levels 
 Creates a evaluation Stage List object which represents an execution plan or tree which is used to completely evaluate a set of tokens at evaluation time The three stages of evaluation can be thought of as parsing strings to tokens then tokens to a stage list then evaluation with parameters 
 The most usual method of parsing an evaluation stage for a given precedence Most stages use the same logic 
 A special case where functions need to be of higher precedence than values and need a special wrapped execution stage operator 
 A truly special precedence function this handles all the lowest case errata of the process including literals parmeters clauses and prefixes 
 Maps a given symbol to a set of typechecks to be used during runtime 
 During stage planning stages of equal precedence are parsed such that they ll be evaluated in reverse order For commutative operators like or it s no big deal But for order specific operators it ruins the expected result 
 Performs a mirror on a subtree of stages This mirror functionally inverts the order of execution for all members of the stages list That list is assumed to be a root to leaf ordered list of evaluation stages where each is a right hand stage of the last 
 Recurses through all operators in the entire tree eliding operators where both sides are literals 
 Elides a specific stage if possible Returns the unmodified root stage if it cannot or should not be elided Otherwise returns a new stage representing the condensed value from the elided stages 
 Addition usually means between numbers but can also mean string concat String concat needs one or both of the sides to be a string 
 Comparison can either be between numbers or lexicographic between two strings but never between the two 
Ignore Fields returns an Option that ignores exported fields of the given names on a single struct type The struct type is specified by passing in a value of that type The name may be a dot delimited string e g Foo Bar to ignore a specific sub field that is embedded or nested within the parent struct This does not handle unexported fields use Ignore Unexported instead 
Ignore Types returns an Option that ignores all values assignable to certain types which are specified by passing in a value of each type 
Ignore Interfaces returns an Option that ignores all values or references of values assignable to certain interface types These interfaces are specified by passing in an anonymous struct with the interface types embedded in it For example to ignore sync Locker pass in struct sync Locker 
Ignore Unexported returns an Option that only ignores the immediate unexported fields of a struct including anonymous fields of unexported types In particular unexported fields within the struct s exported fields of struct types including anonymous fields will not be ignored unless the type of the field itself is also passed to Ignore Unexported Avoid ignoring unexported fields of a type which you do not control i e a type from another repository as changes to the implementation of such types may change how the comparison behaves Prefer a custom Comparer instead 
Ignore Slice Elements returns an Option that ignores elements of V The discard function must be of the form func T bool which is used to ignore slice elements of type V where V is assignable to T Elements are ignored if the function reports true 
Ignore Map Entries returns an Option that ignores entries of map K V The discard function must be of the form func T R bool which is used to ignore map entries of type K and V where K and V are assignable to T and R Entries are ignored if the function reports true 
Append Ellipsis appends a new ellipsis node to the list if none already exists at the end If cs is non zero it coalesces the statistics with the previous diff Stats 
String prints a humanly readable summary of coalesced records Example diff Stats Name Field Num Ignored String ignored fields 
Is Type reports whether the reflect Type is of the specified function type 
Name Of returns the name of the function value 
Pointer Of returns a Pointer from v which must be a reflect Ptr reflect Slice or reflect Map 
Sort Slices returns a Transformer option that sorts all V The less function must be of the form func T T bool which is used to sort any slice with element type V that is assignable to T The less function must be Deterministic less x y less x y Irreflexive less x x Transitive if less x y and less y z then less x z The less function does not have to be total That is if less x y and less y x for two elements x and y their relative order is maintained Sort Slices can be used in conjunction with Equate Empty 
Sort Maps returns a Transformer option that flattens map K V types to be a sorted struct K V The less function must be of the form func T T bool which is used to sort any map with key K that is assignable to T Flattening the map into a slice has the property that cmp Equal is able to use Comparers on K or the K Equal method if it exists The less function must be Deterministic less x y less x y Irreflexive less x x Transitive if less x y and less y z then less x z Total if x y then either less x y or less y x Sort Maps can be used in conjunction with Equate Empty 
String returns a human readable string representing the edit script where Identity Unique X Unique Y and Modified are represented by the X Y and M characters respectively 
stats returns a histogram of the number of each type of edit operation 
Difference reports whether two lists of lengths nx and ny are equal given the definition of equality provided as f This function returns an edit script which is a sequence of operations needed to convert one list into the other The following invariants for the edit script are maintained eq es Dist nx es Len X ny es Len Y This algorithm is not guaranteed to be an optimal solution i e one that produces an edit script with a minimal Levenshtein distance This algorithm favors performance over optimality The exact output is not guaranteed to be stable and may change over time 
connect appends any necessary Identity Modified Unique X or Unique Y types to the edit script to connect p point to dst 
Equate Approx returns a Comparer option that determines float or float values to be equal if they are within a relative fraction or absolute margin This option is not used when either x or y is Na N or infinite The fraction determines that the difference of two values must be within the smaller fraction of the two values while the margin determines that the two values must be within some absolute margin To express only a fraction or only a margin use for the other parameter The fraction and margin must be non negative The mathematical expression used is equivalent to x y max fraction min x y margin Equate Approx can be used in conjunction with Equate Na Ns 
Equate Na Ns returns a Comparer option that determines float and float Na N values to be equal Equate Na Ns can be used in conjunction with Equate Approx 
Index returns the ith step in the Path and supports negative indexing A negative index starts counting from the tail of the Path such that refers to the last step refers to the second to last step and so on If index is invalid this returns a non nil Path Step that reports a nil Type 
String returns the simplified path to a node The simplified path only contains struct field accesses For example My Map My Slices My Field 
Go String returns the path to a specific node using Go syntax For example root My Map key mypkg My Struct My Slices My Field 
Key is the index key it may return if in a split state 
String provides a full report of the differences detected as a structured literal in pseudo Go syntax String may only be called after the entire tree has been traversed 
Format Type prints the type as if it were wrapping s This may return s as is depending on the current type and Type Mode mode 
Format Value prints the reflect Value taking extra care to avoid descending into pointers already in m As pointers are visited m is also updated 
format Map Key formats v as if it were a map key The result is guaranteed to be a single line 
format String prints s as a double quoted or backtick quoted string 
format Hex prints u as a hexadecimal integer in Go notation 
format Pointer prints the address of the pointer 
Visit inserts pointer v into the visited map and reports whether it had already been visited before 
Acyclic Transformer returns a Transformer with a filter applied that ensures that the transformer cannot be recursively applied upon its own output An example use case is a transformer that splits a string by lines Acyclic Transformer Split Lines func s string string return strings Split s n Had this been an unfiltered Transformer instead this would result in an infinite cycle converting a string to string to string and so on 
retrieve Unexported Field uses unsafe to forcibly retrieve any field from a struct such that the value has read write permissions The parent struct v must be addressable while f must be a Struct Field describing the field to retrieve 
filter Field returns a new Option where opt is only evaluated on paths that include a specific exported field on a single struct type The struct type is specified by passing in a value of that type The name may be a dot delimited string e g Foo Bar to select a specific sub field that is embedded or nested within the parent struct 
insert inserts a sequence of field accesses into the tree 
match Prefix reports whether any selector in the field Tree matches the start of path p 
canonical Name returns a list of identifiers where any struct field access through an embedded field is expanded to include the names of the embedded types themselves For example suppose field Foo is not directly in the parent struct but actually from an embedded struct of type Bar Then the canonical name of Foo is actually Bar Foo Suppose field Foo is not directly in the parent struct but actually a field in two different embedded structs of types Bar and Baz Then the selector Foo causes a panic since it is ambiguous which one it refers to The user must specify either Bar Foo or Baz Foo 
Filter Path returns a new Option where opt is only evaluated if filter f returns true for the current Path in the value tree This filter is called even if a slice element or map entry is missing and provides an opportunity to ignore such cases The filter function must be symmetric such that the filter result is identical regardless of whether the missing value is from x or y The option passed in may be an Ignore Transformer Comparer Options or a previously filtered Option 
Filter Values returns a new Option where opt is only evaluated if filter f which is a function of the form func T T bool returns true for the current pair of values being compared If either value is invalid or the type of the values is not assignable to T then this filter implicitly returns false The filter function must be symmetric i e agnostic to the order of the inputs and deterministic i e produces the same result when given the same inputs If T is an interface it is possible that f is called with two values with different concrete types that both implement T The option passed in may be an Ignore Transformer Comparer Options or a previously filtered Option 
Transformer returns an Option that applies a transformation function that converts values of a certain type into that of another The transformer f must be a function func T R that converts values of type T to those of type R and is implicitly filtered to input values assignable to T The transformer must not mutate T in any way To help prevent some cases of infinite recursive cycles applying the same transform to the output of itself e g in the case where the input and output types are the same an implicit filter is added such that a transformer is applicable only if that exact transformer is not already in the tail of the Path since the last non Transform step For situations where the implicit filter is still insufficient consider using cmpopts Acyclic Transformer which adds a filter to prevent the transformer from being recursively applied upon itself The name is a user provided label that is used as the Transform Name in the transformation Path Step and eventually shown in the Diff output The name must be a valid identifier or qualified identifier in Go syntax If empty an arbitrary name is used 
Comparer returns an Option that determines whether two values are equal to each other The comparer f must be a function func T T bool and is implicitly filtered to input values assignable to T If T is an interface it is possible that f is called with two values of different concrete types that both implement T The equality function must be Symmetric equal x y equal y x Deterministic equal x y equal x y Pure equal x y does not modify x or y 
Allow Unexported returns an Option that forcibly allows operations on unexported fields in certain structs which are specified by passing in a value of each struct type Users of this option must understand that comparing on unexported fields from external packages is not safe since changes in the internal implementation of some external package may cause the result of Equal to unexpectedly change However it may be valid to use this option on types defined in an internal package where the semantic meaning of an unexported field is in the control of the user In many cases a custom Comparer should be used instead that defines equality as a function of the public API of a type rather than the underlying unexported implementation For example the reflect Type documentation defines equality to be determined by the operator on the interface essentially performing a shallow pointer comparison and most attempts to compare regexp Regexp types are interested in only checking that the regular expression strings are equal Both of these are accomplished using Comparers Comparer func x y reflect Type bool return x y Comparer func x y regexp Regexp bool return x String y String In other cases the cmpopts Ignore Unexported option can be used to ignore all unexported fields on specified struct types 
Reporter is an Option that can be passed to Equal When Equal traverses the value trees it calls Push Step as it descends into each node in the tree and Pop Step as it ascend out of the node The leaves of the tree are either compared determined to be equal or not equal or ignored and reported as such by calling the Report method 
normalize Option normalizes the input options such that all Options groups are flattened and groups with a single element are reduced to that element Only core Options and Options containing core Options are allowed 
flatten Options copies all options in src to dst as a flat list Only core Options and Options containing core Options are allowed 
Can Format Diff Slice reports whether we support custom formatting for nodes that are slices of primitive kinds or strings 
Format Diff Slice prints a diff for the slices or strings represented by v This provides custom tailored logic to make printing of differences in textual strings and slices of primitive kinds more readable 
format ASCII formats s as an ASCII string This is useful for printing binary strings in a semi legible way 
coalesce Adjacent Edits coalesces the list of edits into groups of adjacent equal or unequal counts 
coalesce Intervening Identical coalesces sufficiently short window Size equal groups into adjacent unequal groups that currently result in a dual inserted removed printout This acts as a high pass filter to smooth out high frequency changes within the window Size 
Sort Keys sorts a list of map keys deduplicating keys if necessary The type of each value must be comparable 
is Less is a generic function for sorting arbitrary map keys The inputs must be of the same type and must be comparable 
Format Diff converts a value Node tree into a text Node tree where the later is a textual representation of the differences detected in the former 
coalesce Adjacent Records coalesces the list of records into groups of adjacent equal or unequal counts 
Equal reports whether x and y are equal by recursively applying the following rules in the given order to x and y and all of their sub values Let S be the set of all Ignore Transformer and Comparer options that remain after applying all path filters value filters and type filters If at least one Ignore exists in S then the comparison is ignored If the number of Transformer and Comparer options in S is greater than one then Equal panics because it is ambiguous which option to use If S contains a single Transformer then use that to transform the current values and recursively call Equal on the output values If S contains a single Comparer then use that to compare the current values Otherwise evaluation proceeds to the next rule If the values have an Equal method of the form T Equal T bool or T Equal I bool where T is assignable to I then use the result of x Equal y even if x or y is nil Otherwise no such method exists and evaluation proceeds to the next rule Lastly try to compare x and y based on their basic kinds Simple kinds like booleans integers floats complex numbers strings and channels are compared using the equivalent of the operator in Go Functions are only equal if they are both nil otherwise they are unequal Structs are equal if recursively calling Equal on all fields report equal If a struct contains unexported fields Equal panics unless an Ignore option e g cmpopts Ignore Unexported ignores that field or the Allow Unexported option explicitly permits comparing the unexported field Slices are equal if they are both nil or both non nil where recursively calling Equal on all non ignored slice or array elements report equal Empty non nil slices and nil slices are not equal to equate empty slices consider using cmpopts Equate Empty Maps are equal if they are both nil or both non nil where recursively calling Equal on all non ignored map entries report equal Map keys are equal according to the operator To use custom comparisons for map keys consider using cmpopts Sort Maps Empty non nil maps and nil maps are not equal to equate empty maps consider using cmpopts Equate Empty Pointers and interfaces are equal if they are both nil or both non nil where they have the same underlying concrete type and recursively calling Equal on the underlying values reports equal 
Diff returns a human readable report of the differences between two values It returns an empty string if and only if Equal returns true for the same input values and options The output is displayed as a literal in pseudo Go syntax At the start of each line a prefix indicates an element removed from x a prefix to indicates an element added to y and the lack of a prefix indicates an element common to both x and y If possible the output uses fmt Stringer String or error Error methods to produce more humanly readable outputs In such cases the string is prefixed with either an s or e character respectively to indicate that the method was called Do not depend on this output being stable If you need the ability to programmatically interpret the difference consider using a custom Reporter 
stateless Compare compares two values and returns the result This function is stateless in that it does not alter the current result or output to any registered reporters 
sanitize Value converts nil interfaces of type T to those of type R assuming that T is assignable to R Otherwise it returns the input value as is 
Check scans the Path for any recursive transformers and panics when any recursive transformers are detected Note that the presence of a recursive Transformer does not necessarily imply an infinite cycle As such this check only activates after some minimal number of path steps 
Next increments the state and reports whether a check should be performed Checks occur every Nth function call where N is a triangular number See https en wikipedia org wiki Triangular number This sequence ensures that the cost of checks drops significantly as the number of functions calls grows larger 
make Addressable returns a value that is always addressable It returns the input verbatim if it is already addressable otherwise it creates a new value and returns an addressable copy 
String adds a string valued key value pair to a Span Log Fields record 
Bool adds a bool valued key value pair to a Span Log Fields record 
Int adds an int valued key value pair to a Span Log Fields record 
Int adds an int valued key value pair to a Span Log Fields record 
Int adds an int valued key value pair to a Span Log Fields record 
Uint adds a uint valued key value pair to a Span Log Fields record 
Uint adds a uint valued key value pair to a Span Log Fields record 
Float adds a float valued key value pair to a Span Log Fields record 
Float adds a float valued key value pair to a Span Log Fields record 
Error adds an error with the key error to a Span Log Fields record 
Object adds an object valued key value pair to a Span Log Fields record 
Marshal passes a Field instance through to the appropriate field type specific method of an Encoder 
Value returns the field s value as interface 
String returns a string representation of the key and value 
Apply satisfies the Start Span Option interface 
Apply satisfies the Start Span Option interface 
Apply satisfies the Start Span Option interface 
Apply satisfies the Start Span Option interface 
Set applies the tag to an existing Span 
Inject implements the Injector interface 
Extract implements the Extractor interface 
To Log Record converts a deprecated Log Data to a non deprecated Log Record 
New returns a Mock Tracer opentracing Tracer implementation that s intended to facilitate tests of Open Tracing instrumentation 
Finished Spans returns all spans that have been Finish ed since the Mock Tracer was constructed or since the last call to its Reset method 
Reset clears the internally accumulated finished spans Note that any extant Mock Spans will still append to finished Spans when they Finish even after a call to Reset 
Start Span belongs to the Tracer interface 
Register Injector registers injector for given format 
Register Extractor registers extractor for given format 
Inject belongs to the Tracer interface 
Extract belongs to the Tracer interface 
Context With Span returns a new context Context that holds a reference to span s Span Context 
Span From Context returns the Span previously associated with ctx or nil if no such Span could be found NOTE context Context Span Context the former is Go s intra process context propagation mechanism and the latter houses Open Tracing s per Span identity and baggage information 
Start Span From Context starts and returns a Span with operation Name using any Span found within ctx as a Child Of Ref If no such parent could be found Start Span From Context creates a root parentless Span The second return value is a context Context object built around the returned Span Example usage Some Function ctx context Context sp ctx opentracing Start Span From Context ctx Some Function defer sp Finish 
Set adds a string tag to the span 
Set adds a string tag to the span 
Set adds a uint tag to the span 
Set adds a uint tag to the span 
Add adds a bool tag to the span 
Set String records IP v host address of the peer as a separated tuple to the span E g 
Start Span defers to Tracer Start Span See Global Tracer 
Interleaved KVTo Fields converts key Values a la Span Log KV to a Field slice a la Span Log Fields 
Foreach Key conforms to the Text Map Reader interface 
Emit String belongs to the log Encoder interface 
Emit Lazy Logger belongs to the log Encoder interface 
Run APIChecks runs a test suite to check a Tracer against the Open Tracing API It is provided a function that will be executed to create and destroy a tracer for each test in the suite and the given APICheck Option functional options opts 
Check Baggage Values returns an option that sets whether to check for propagation of baggage values 
Check Extract returns an option that sets whether to check if extracting contexts from carriers works 
Check Inject returns an option that sets whether to check if injecting contexts works 
Check Everything returns an option that enables all API checks 
Use Probe returns an option that specifies an APICheck Probe implementation to use 
With Baggage Item creates a new context with an extra baggage item 
Tags returns a copy of tags accumulated by the span so far 
Tag returns a single tag 
Logs returns a copy of logs accumulated in the span so far 
Context belongs to the Span interface 
Set Tag belongs to the Span interface 
Set Baggage Item belongs to the Span interface 
Baggage Item belongs to the Span interface 
Finish belongs to the Span interface 
Finish With Options belongs to the Span interface 
String allows printing span for debugging 
Log Fields belongs to the Span interface 
The caller MUST NOT hold s Lock 
Log KV belongs to the Span interface This implementations coerces all values to strings though that is not something all implementations need to do Indeed a motivated person can and probably should have this do a typed switch on the values 
Log Event belongs to the Span interface 
Log Event With Payload belongs to the Span interface 
Set Operation Name belongs to the Span interface 
new Open Shift Client Config Loading Rules is a modified copy of openshift origin pkg cmd cli config New Open Shift Client Config Loading Rules New Open Shift Client Config Loading Rules returns file priority loading rules for Open Shift config value if KUBECONFIG env var has a value use it Otherwise kube config file 
Client Config is a modified copy of k s io kubernetes pkg client unversioned clientcmd Deferred Loading Client Config Client Config Client Config implements Client Config 
Client Config is a modified copy of k s io kubernetes pkg client unversioned clientcmd Direct Client Config Client Config Client Config implements Client Config 
get Server Identification Partial Config is a modified copy of k s io kubernetes pkg client unversioned clientcmd get Server Identification Partial Config clientauth Info object contain both user identification and server identification We want different precedence orders for both so we have to split the objects and merge them separately we want this order of precedence for the server identification config Cluster Info the final result of command line flags and merged kubeconfig files config Auth Info auth path this file can contain information that conflicts with and we want to win the priority load the kubernetes auth file as a default 
get User Identification Partial Config is a modified copy of k s io kubernetes pkg client unversioned clientcmd get User Identification Partial Config clientauth Info object contain both user identification and server identification We want different precedence orders for both so we have to split the objects and merge them separately we want this order of precedence for user identifcation config Auth Info minus auth path the final result of command line flags and merged kubeconfig files config Auth Info auth path this file can contain information that conflicts with and we want to win the priority if there is not enough information to idenfity the user load try the kubernetes auth file if there is not enough information to identify the user prompt if possible 
can Identify User is a modified copy of k s io kubernetes pkg client unversioned clientcmd can Identify User 
Confirm Usable is a modified copy of k s io kubernetes pkg client unversioned clientcmd Direct Client Config Confirm Usable Confirm Usable looks a particular context and determines if that particular part of the config is useable There might still be errors in the config but no errors in the sections requested or referenced It does not return early so that it can find as many errors as possible 
get Context is a modified copy of k s io kubernetes pkg client unversioned clientcmd Direct Client Config get Context 
validate Cluster Info is a modified copy of k s io kubernetes pkg client unversioned clientcmd Direct Client Config validate Cluster Info validate Cluster Info looks for conflicts and errors in the cluster info 
validate Auth Info is a modified copy of k s io kubernetes pkg client unversioned clientcmd Direct Client Config validate Auth Info validate Auth Info looks for conflicts and errors in the auth info 
get Auth Info is a modified copy of k s io kubernetes pkg client unversioned clientcmd Direct Client Config get Auth Info 
get Cluster is a modified copy of k s io kubernetes pkg client unversioned clientcmd Direct Client Config get Cluster 
new Aggregate is a modified copy of k s io apimachinery pkg util errors New Aggregate New Aggregate converts a slice of errors into an Aggregate interface which is itself an implementation of the error interface If the slice is empty this returns nil It will check if any of the element of input error list is nil to avoid nil pointer panic when call Error 
Load is a modified copy of k s io kubernetes pkg client unversioned clientcmd Client Config Loading Rules Load Load starts by running the Migration Rules and then takes the loading rules and returns a Config object based on following rules if the Explicit Path return the unmerged explicit file Otherwise return a merged config based on the Precedence slice A missing Explicit Path file produces an error Empty filenames or other missing files are ignored Read errors or files with non deserializable content produce errors The first file to set a particular map key wins and map key s value is never changed BUT if you set a struct value that is NOT contained inside of map the value WILL be changed This results in some odd looking logic to merge in one direction merge in the other and then merge the two It also means that if two files specify a red user only values from the first file s red user are used Even non conflicting entries from the second file s red user are discarded Relative paths inside of the kubeconfig files are resolved against the kubeconfig file s parent folder and only absolute file paths are returned 
load From File is a modified copy of k s io kubernetes pkg client unversioned clientcmd Load From File Load From File takes a filename and deserializes the contents into Config object 
load is a modified copy of k s io kubernetes pkg client unversioned clientcmd Load Load takes a byte slice and deserializes the contents into Config object Encapsulates deserialization without assuming the source is a file 
resolve Local Paths is a modified copy of k s io kubernetes pkg client unversioned clientcmd Client Config Loading Rules resolve Local Paths Resolve Local Paths resolves all relative paths in the config object with respect to the stanza s Location Of Origin this cannot be done directly inside of Load From File because doing so there would make it impossible to load a file without modification of its contents 
resolve Paths is a modified copy of k s io kubernetes pkg client unversioned clientcmd Client Config Loading Rules resolve Paths Resolve Paths updates the given refs to be absolute paths relative to the given base directory 
rest Client For is a modified copy of k s io kubernets pkg client restclient RESTClient For RESTClient For returns a RESTClient that satisfies the requested attributes on a client Config object Note that a RESTClient may require fields that are optional when initializing a Client A RESTClient created by this method is generic it expects to operate on an API that follows the Kubernetes conventions but may not be the Kubernetes API 
default Server URL is a modified copy of k s io kubernets pkg client restclient Default Server URL Default Server URL converts a host host port or URL string to the default base server API path to use with a Client at a given API version following the standard conventions for a Kubernetes API 
default Server URLFor is a modified copy of k s io kubernets pkg client restclient default Server URLFor default Server Url For is shared between Is Config Transport TLS and RESTClient For It requires Host and Version to be set prior to being called 
is Config Transport TLS is a modified copy of k s io kubernets pkg client restclient Is Config Transport TLS Is Config Transport TLS returns true if and only if the provided config will result in a protected connection to the server when it is passed to restclient RESTClient For Use to determine when to send credentials over the wire Note the Insecure flag is ignored when testing for this value so MITM attacks are still possible 
transport New is a modified copy of k s io kubernetes pkg client transport New New returns an http Round Tripper that will provide the authentication or transport level security defined by the provided Config 
new Proxier With No Proxy CIDR is a modified copy of k s io apimachinery pkg util net New Proxier With No Proxy CIDR New Proxier With No Proxy CIDR constructs a Proxier function that respects CIDRs in NO PROXY and delegates if no matching CIDRs are found 
tls Cache Get is a modified copy of k s io kubernetes pkg client transport tls Transport Cache get 
load TLSFiles is a modified copy of k s io kubernetes pkg client transport load TLSFiles load TLSFiles copies the data from the Cert File Key File and CAFile fields into the Cert Data Key Data and CAFile fields or returns an error If no error is returned all three fields are either populated or were empty to start 
Has CA is a modified copy of k s io kubernetes pkg client transport Config Has CA Has CA returns whether the configuration has a certificate authority or not 
Has Cert Auth is a modified copy of k s io kubernetes pkg client transport Config Has Cert Auth Has Cert Auth returns whether the configuration has certificate authentication or not 
clientcmd New Config is a modified copy of k s io kubernetes pkg client unversioned clientcmd api New Config New Config is a convenience function that returns a new Config object with non nil maps 
new Image Source returns a types Image Source for the specified image reference The caller must call Close on the returned Image Source It would be great if we were able to stream the input tar as it is being sent but Docker sends the top level manifest which determines which paths to look for at the end so in we will need to seek back and re read several times We could perhaps expect an exact sequence assume that the first plaintext file is the config and that the following len Root FS files are the layers but that feels way too brittle 
manifest Schema From Components builds a new manifest Schema from the supplied data 
OCIConfig returns the image configuration as per OCI v image spec Information about layers in the resulting configuration isn t guaranteed to be returned to due how old image manifests work docker v s especially 
Config Blob returns the blob described by Config Info iff Config Info Digest nil otherwise The result is cached it is OK to call this however often you need 
Inspect returns various information for skopeo inspect parsed from the manifest and configuration 
Updated Image returns a types Image modified according to options This does not change the state of the original Image object 
Based on docker distribution manifest schema config builder go 
configured Signature Storage Base reads configuration to find an appropriate signature storage URL for ref for write access if write 
registries Dir Path returns a path to registries d 
load And Merge Config loads configuration files in dir Path 
config signature Top Level returns an URL string configured in config for ref for write access if write the top level of the storage namespaced by repo Full Name etc or if no signature storage should be used 
ns signature Top Level returns an URL string configured in ns for ref for write access if write or if nothing has been configured 
signature Storage URL returns an URL usable for acessing signature index in base with known manifest Digest or nil if not applicable Returns nil iff base nil NOTE Keep this in sync with docs signature protocols md 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
Validate Policy Configuration Scope checks that scope is a valid name for a signature Policy Transport Scopes keys i e a valid Policy Configuration Identity or Policy Configuration Namespaces return value It is acceptable to allow an invalid value which will never be matched it can only cause user confusion scope passed to this function will not be that value is always allowed 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Open Shift Image Reference 
New Reference returns an Open Shift reference for a reference Named Tagged 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image WARNING This may not do the right thing for a manifest list see image From Source for details 
this is cloned from docker go connections because upstream docker has changed it and make deps here fails otherwise We ll drop this once we upgrade to docker x deps 
docker Cert Dir returns a path to a directory to be consumed by tlsclientconfig Setup Certificates depending on ctx and host Port 
new Docker Client From Ref returns a new docker Client instance for ref Hostname a host a specified in the Docker image reference not canonicalized to docker Registry write specifies whether the client will be used for write access in particular passed to lookaside go toplevel From Section 
new Docker Client returns a new docker Client instance for the given registry and reference The reference is used to query the registry configuration and can either be a registry e g registry com a repository e g registry com some namespace repo Please note that new Docker Client does not set all members of docker Client e g username and password those must be set by callers if necessary 
Check Auth validates the credentials by attempting to log into the registry returns an error if an error occurred while making the http request or the status code received was 
Search Registry queries a registry for images that contain image in their name The limit is the max number of results desired Note The limit value doesn t work with all registries for example registry access redhat com returns all the results without limiting it to the limit value 
make Request creates and executes a http Request with the specified parameters adding authentication and TLS options for the Docker client The host name and schema is taken from the client or autodetected and the path is relative to it i e the path usually starts with v 
make Request To Resolved URL creates and executes a http Request with the specified parameters adding authentication and TLS options for the Docker client stream Len if not specifies the length of the data expected on stream make Request should generally be preferred TODO runcom too many arguments here use a struct 
do Http uses the clients internal TLS configuration for doing the provided HTTP request It returns the response and an error on failure 
we re using the challenges from the v ping response and not the one from the destination URL in this request because docker does that as well gcr io is sending without a WWW Authenticate header in the real request debugging https github com containers image pull issuecomment and follows up 
detect Properties Helper performs the work of detect Properties which executes it at most once 
detect Properties detects various properties of the registry See the docker Client documentation for members which are affected by this 
get Extensions Signatures returns signatures from the X Registry Supports Signatures API extension using the original data structures 
Setup Certificates opens all crt cert and key files in dir and appends loads certs and key pairs as appropriate to tlsc 
New Transport Creates a default transport 
normalize Registries removes trailing slashes from registries which is a common pitfall when configuring registries e g docker io library 
Reads the global registry file from the filesystem Returns a byte array 
Loads the registry configuration file from the filesystem and then unmarshals it Returns the unmarshalled object 
Get Registries returns an array of strings that contain the names of the registries as defined in the system wide registries file it returns an empty array if none are defined 
Get Insecure Registries returns an array of strings that contain the names of the insecure registries as defined in the system wide registries file it returns an empty array if none are defined 
Registries Conf Path is the path to the system wide registry configuration file 
New Optional Bool converts the input bool into either Optional Bool True or Optional Bool False The function is meant to avoid boilerplate code of users 
change Context State changes pc state or fails if the state is unexpected 
New Policy Context sets up and initializes a context for the specified policy The policy must not be modified while the context exists FIXME make a deep copy If this function succeeds the caller should call Policy Context Destroy when done 
Destroy should be called when the user of the context is done with it 
policy Identity Log Name returns a string description of the image identity for policy purposes ONLY use this for log messages not for any decisions 
requirements For Image Ref selects the appropriate requirements for ref 
Get Signatures With Accepted Author returns those signatures from an image for which the policy accepts the author and which have been successfully verified NOTE This may legitimately return an empty list and no error if the image has no signatures or only invalid signatures WARNING This makes the signature contents acceptable for futher processing but it does not necessarily mean that the contents of the signature are consistent with local policy For example Do not use a an existence of an accepted signature to determine whether to run a container based on this image use Is Running Image Allowed instead Just because a signature is accepted does not automatically mean the contents of the signature are authorized to run code as root or to affect system or cluster configuration 
Is Running Image Allowed returns true iff the policy allows running the image If it returns false err must be non nil and should be an Policy Requirement Error if evaluation succeeded but the result was rejection WARNING This validates signatures and the manifest but does not download or validate the layers Users must validate that the layers match their expected digests 
Parse Image Name converts a URL like image name to a types Image Reference 
Blob Info From OCI Descriptor returns a types Blob Info based on the input OCI descriptor 
OCI From Manifest creates an OCI manifest instance from a manifest blob 
OCI From Components creates an OCI manifest instance from the supplied data 
Layer Infos returns a list of Layer Infos of layers referenced by this image in order the root layer first and then successive layered layers The Digest field is guaranteed to be provided Size may be WARNING The list may contain duplicates and they are semantically relevant 
Update Layer Infos replaces the original layers with the specified Blob Infos size digest urls in order the root layer first and then successive layered layers 
Inspect returns various information for skopeo inspect parsed from the manifest and configuration 
Image ID computes an ID which can uniquely identify this image by its contents 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Docker Image Reference 
new Reference returns a docker Reference for a named reference 
Policy Configuration Identity returns a string representation of the reference suitable for policy lookup This MUST reflect user intent not e g after processing of third party redirects or aliases The value SHOULD be fully explicit about its semantics with no hidden defaults AND canonical i e various references with exactly the same semantics should return the same configuration identity It is fine for the return value to be equal to String Within Transport and it is desirable but not required guaranteed that it will be a valid input to Transport Parse Reference Returns if configuration identities for these references are not supported 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image WARNING This may not do the right thing for a manifest list see image From Source for details 
Delete Image deletes the named image from the registry if supported 
tag Or Digest returns a tag or digest from the reference 
new Digesting Reader returns an io Reader implementation with contents of source which will eventually return a non EOF error or set validation Succeeded validation Failed to true if the source stream does does not match expected Digest neither is set if EOF is never reached 
Image copies image from src Ref to dest Ref using policy Context to validate source image admissibility It returns the manifest which was written to the new copy of the image 
Image copies a single on manifest list image unparsed Image using policy Context to validate source image admissibility 
Printf writes a formatted string to c report Writer Note that the method name Printf is not entirely arbitrary go tool vet has a built in list of functions methods whatever object they are for which have their format strings checked for other names we would have to pass a parameter to every go tool vet invocation 
update Embedded Docker Reference handles the Docker reference embedded in Docker schema manifests 
is TTY returns true if the io Writer is a file and a tty 
copy Layers copies layers from ic src ic c raw Source to dest using and updating ic manifest Updates if necessary and ic can Modify Manifest 
layer Digests Differ return true iff the digests in a and b differ ignoring sizes and possible other fields 
copy Updated Config And Manifest updates the image per ic manifest Updates if necessary stores the resulting config and manifest to the destination and returns the stored manifest 
new Progress Pool creates a mpb Progress and a cleanup function The caller must eventually call the returned cleanup function after the pool will no longer be updated 
create Progress Bar creates a mpb Bar in pool Note that if the copier s report Writer is ioutil Discard the progress bar s output will be discarded 
copy Config copies config json if any from src to dest 
copy Layer copies a layer with src Info with known Digest and possibly known Size in src to dest perhaps compressing it if can Compress and returns a complete blob Info of the copied layer and a value for Layer Diff IDs if diff IDIs Needed 
copy Layer From Stream is an implementation detail of copy Layer mostly providing a separate defer scope it copies a blob with src Info with known Digest and possibly known Size from src Stream to dest perhaps compressing the stream if can Compress and returns a complete blob Info of the copied blob and perhaps a chan diff IDResult if diff IDIs Needed to be read by the caller 
diff IDComputation Goroutine reads all input from layer Stream uncompresses using decompressor if necessary and sends its digest and status if any to dest 
compute Diff ID reads all input from layer Stream uncompresses it using decompressor if necessary and returns its digest 
copy Blob From Stream copies a blob with src Info with known Digest and possibly known Size from src Stream to dest perhaps sending a copy to an io Writer if get Original Layer Copy Writer nil perhaps compressing it if can Compress and returns a complete blob Info of the copied blob 
compress Goroutine reads all input from src and writes its compressed equivalent to dest 
New Docker Client initializes a new API client based on the passed System Context 
default Policy Path returns a path to the default policy of the system 
New Policy From File returns a policy configured in the specified file 
New Policy From Bytes returns a policy parsed from the specified blob Use this function instead of calling json Unmarshal directly 
Unmarshal JSON implements the json Unmarshaler interface 
Unmarshal JSON implements the json Unmarshaler interface 
Unmarshal JSON implements the json Unmarshaler interface 
Unmarshal JSON implements the json Unmarshaler interface 
new Policy Requirement From JSON parses JSON data into a Policy Requirement implementation 
Unmarshal JSON implements the json Unmarshaler interface 
Unmarshal JSON implements the json Unmarshaler interface 
new PRSigned By returns a new pr Signed By if parameters are valid 
new PRSigned By Key Path is New PRSigned By Key Path except it returns the private type 
New PRSigned By Key Path returns a new signed By Policy Requirement using a Key Path 
new PRSigned By Key Data is New PRSigned By Key Data except it returns the private type 
New PRSigned By Key Data returns a new signed By Policy Requirement using a Key Data 
Unmarshal JSON implements the json Unmarshaler interface 
Is Valid returns true iff kt is a recognized value 
Unmarshal JSON implements the json Unmarshaler interface 
new PRSigned Base Layer is New PRSigned Base Layer except it returns the private type 
Unmarshal JSON implements the json Unmarshaler interface 
new Policy Reference Match From JSON parses JSON data into a Policy Reference Match implementation 
Unmarshal JSON implements the json Unmarshaler interface 
Unmarshal JSON implements the json Unmarshaler interface 
Unmarshal JSON implements the json Unmarshaler interface 
new PRMExact Reference is New PRMExact Reference except it resturns the private type 
Unmarshal JSON implements the json Unmarshaler interface 
new PRMExact Repository is New PRMExact Repository except it resturns the private type 
Unmarshal JSON implements the json Unmarshaler interface 
new Image Source sets up an image for reading 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
get Blob And Layer reads the data blob or filesystem layer which matches the digest and size if given 
Get Manifest reads the image s manifest 
Layer Infos For Copy returns the list of layer blobs that make up the root filesystem of the image after they ve been decompressed 
build Layer Infos For Copy builds a Layer Infos For Copy return value based on manifest Infos from the original manifest but using layer data which we can actually produce physical Infos for non empty layers and image Gzipped Empty Layer for empty ones This is split basically only to allow easily unit testing the part that has no dependencies on the external environment 
Get Signatures parses the image s signatures blob into a slice of byte slices 
new Image Destination sets us up to write a new image caching blobs in a temporary directory until it s time to Commit the image 
Put Blob writes contents of stream and returns data representing the result input Info Digest can be optionally provided if known it is not mandatory for the implementation to verify it input Info Size is the expected length of stream if known input Info Media Type describes the blob format if known May update cache WARNING The contents of stream are being verified on the fly Until stream Read returns io EOF the contents of the data SHOULD NOT be available to any other readers for download using the supplied digest If stream Read at any time ESPECIALLY at end of input returns an error Put Blob MUST fail and delete any data stored so far 
Try Reusing Blob checks whether the transport already contains or can efficiently reuse a blob and if so applies it to the current destination e g if the blob is a filesystem layer this signifies that the changes it describes need to be applied again when composing a filesystem tree info Digest must not be empty If can Substitute Try Reusing Blob can use an equivalent equivalent of the desired blob in that case the returned info may not match the input If the blob has been succesfully reused returns true info nil info must contain at least a digest and size If the transport can not reuse the requested blob Try Reusing Blob returns false nil it returns a non nil error only on an unexpected failure May use and or update cache 
compute ID computes a recommended image ID based on information we have so far If the manifest is not of a type that we recognize we return an empty value indicating that since we don t have a recommendation a random ID should be used if one needs to be allocated 
get Config Blob exists only to let us retrieve the configuration blob so that the manifest package can dig information out of it for Inspect 
Put Manifest writes the manifest to the destination 
Put Signatures records the image s signatures for committing as a single data blob 
get Size adds up the sizes of the image s data blobs which includes the configuration blob the signatures and the uncompressed sizes of all of the image s layers 
new Image creates an image that also knows its size 
new Image Source returns a types Image Source for the specified image reference The caller must call Close on the returned Image Source 
Candidate Locations returns a prioritized limited number of blobs and their locations that could possibly be reused within the specified transport scope if they still exist which is not guaranteed If can Substitute the returned cadidates will match the submitted digest exactly if can Substitute data from previous Record Digest Uncompressed Pair calls is used to also look up variants of the blob which have the same uncompressed digest 
new GPGSigning Mechanism In Directory returns a new GPG Open PGP signing mechanism using optional Dir if not empty The caller must call Close on the returned Signing Mechanism 
new Ephemeral GPGSigning Mechanism returns a new GPG Open PGP signing mechanism which recognizes only public keys from the supplied blob and returns the identities of these keys The caller must call Close on the returned Signing Mechanism 
import Keys From Bytes imports public keys from the supplied blob and returns their identities The blob is assumed to have an appropriate format the caller is expected to know which one 
Sign creates a non detached signature of input using key Identity Fails with a Signing Not Supported Error if the mechanism does not support signing 
Verify parses unverified Signature and returns the content and the signer s identity 
Untrusted Signature Contents returns UNTRUSTED contents of the signature WITHOUT ANY VERIFICATION along with a short identifier of the key used for signing WARNING The short key identifier which correponds to Key ID for Open PGP keys is NOT the same as a key identity used in other calls ot this interface and the values may have no recognizable relationship if the public key is not available 
new Image Source returns an Image Source for reading from an existing directory new Image Source untars the file and saves it in a temp directory 
Load Manifest Descriptor loads the manifest 
Close removes resources associated with an initialized Image Source if any Close deletes the temporary directory at dst 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Get Signatures returns the image s signatures It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve signatures for when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
append adds s to the end of os only if it is not included already 
determine Manifest Conversion updates ic manifest Updates to convert manifest to a supported MIME type if necessary and ic can Modify Manifest Note that the conversion will only happen later through ic src Updated Image Returns the preferred manifest MIME type whether we are converting to it or using it unmodified and a list of other possible alternatives in order 
is Multi Image returns true if img is a list of images 
lock Path obtains the path Lock for path The caller must call unlock Path eventually 
unlock Path releases the path Lock for path 
view returns runs the specified fn within a read only transaction on the database 
update returns runs the specified fn within a read write transaction on the database 
uncompressed Digest implements Blob Info Cache Uncompressed Digest within the provided read only transaction 
Uncompressed Digest returns an uncompressed digest corresponding to any Digest May return any Digest if it is known to be uncompressed Returns if nothing is known about the digest it may be compressed or uncompressed 
Record Digest Uncompressed Pair records that the uncompressed version of any Digest is uncompressed It s allowed for any Digest uncompressed WARNING Only call this for LOCALLY VERIFIED data don t record a digest pair just because some remote author claims so e g because a manifest config pair exists otherwise the cache could be poisoned and allow substituting unexpected blobs Eventually the Diff IDs in image config could detect the substitution but that may be too late and not all image formats contain that data 
Record Known Location records that a blob with the specified digest exists within the specified transport scope scope and can be reused given the opaque location data 
append Replacement Candiates creates prioritize Candidate With Time values for digest in scope Bucket and returns the result of appending them to candidates 
Candidate Locations returns a prioritized limited number of blobs and their locations that could possibly be reused within the specified transport scope if they still exist which is not guaranteed If can Substitute the returned cadidates will match the submitted digest exactly if can Substitute data from previous Record Digest Uncompressed Pair calls is used to also look up variants of the blob which have the same uncompressed digest 
Temporary Directory For Big Files returns a directory for temporary big files On non Windows systems it avoids the use of os Temp Dir because the default temporary directory usually falls under tmp which on systemd based systems could be the unsuitable tmpfs filesystem 
gpg Untrusted Signature Contents returns UNTRUSTED contents of the signature WITHOUT ANY VERIFICATION along with a short identifier of the key used for signing WARNING The short key identifier which correponds to Key ID for Open PGP keys is NOT the same as a key identity used in other calls ot this interface and the values may have no recognizable relationship if the public key is not available 
new Image Destination returns an Image Destination for writing to an existing directory 
Put Blob writes contents of stream and returns data representing the result input Info Digest can be optionally provided if known it is not mandatory for the implementation to verify it input Info Size is the expected length of stream if known input Info Media Type describes the blob format if known May update cache WARNING The contents of stream are being verified on the fly Until stream Read returns io EOF the contents of the data SHOULD NOT be available to any other readers for download using the supplied digest If stream Read at any time ESPECIALLY at end of input returns an error Put Blob MUST fail and delete any data stored so far 
Try Reusing Blob checks whether the transport already contains or can efficiently reuse a blob and if so applies it to the current destination e g if the blob is a filesystem layer this signifies that the changes it describes need to be applied again when composing a filesystem tree info Digest must not be empty If can Substitute Try Reusing Blob can use an equivalent equivalent of the desired blob in that case the returned info may not match the input If the blob has been succesfully reused returns true info nil info must contain at least a digest and size If the transport can not reuse the requested blob Try Reusing Blob returns false nil it returns a non nil error only on an unexpected failure May use and or update cache 
Put Manifest writes manifest to the destination FIXME This should also receive a MIME type if known to differentiate between schema versions If the destination is in principle available refuses this manifest type e g it does not recognize the schema but may accept a different manifest type the returned error must be an Manifest Type Rejected Error 
Commit marks the process of storing the image as successful and asks for the image to be persisted WARNING This does not have any transactional semantics Uploaded data MAY be visible to others before Commit is called Uploaded data MAY be removed or MAY remain around if Close is called without Commit i e rollback is allowed but not guaranteed 
index Exists checks whether the index location specified in the OCI reference exists The implementation is opinionated since in case of unexpected errors false is returned 
create Signature creates a new signature of manifest using key Identity 
manifest Instance From Blob returns a generic Manifest implementation for manblob mt in src If manblob is a manifest list it implicitly chooses an appropriate image from the list 
manifest Layer Infos To Blob Infos extracts a types Blob Info from a manifest Layer Info 
Commit marks the process of storing the image as successful and asks for the image to be persisted WARNING This does not have any transactional semantics Uploaded data MAY be visible to others before Commit is called Uploaded data MAY be removed or MAY remain around if Close is called without Commit i e rollback is allowed but not guaranteed 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an OCI Image Reference 
New Reference returns an OCI reference for a directory and a image We do not expose an API supplying the resolved Dir we could but recomputing it is generally cheap enough that we prefer being confident about the properties of resolved Dir 
String Within Transport returns a string representation of the reference which MUST be such that reference Transport Parse Reference reference String Within Transport returns an equivalent reference NOTE The returned string is not promised to be equal to the original input to Parse Reference e g default attribute values omitted by the user may be filled in in the return value or vice versa WARNING Do not use the return value in the UI to describe an image it does not contain the Transport Name prefix 
Policy Configuration Namespaces returns a list of other policy configuration namespaces to search for if explicit configuration for Policy Configuration Identity is not set The list will be processed in order terminating on first match and an implicit is always checked at the end It is STRONGLY recommended for the first element if any to be a prefix of Policy Configuration Identity and each following element to be a prefix of the element preceding it 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image WARNING This may not do the right thing for a manifest list see image From Source for details 
get Index returns a pointer to the index references by this oci Reference If an error occurs opening an index nil is returned together with an error 
Load Manifest Descriptor loads the manifest descriptor to be used to retrieve the image name when pulling an image 
blob Path returns a path for a blob within a directory using OCI image layout conventions 
Sign Docker Manifest returns a signature for manifest as the specified docker Reference using mech and key Identity 
Verify Docker Manifest Signature checks that unverified Signature uses expected Key Identity to sign unverified Manifest as expected Docker Reference using mech 
new Openshift Client creates a new openshift Client for the specified reference 
do Request performs a correctly authenticated request to a specified path and returns response body or an error object 
get Image loads the specified image object 
convert Docker Image Reference takes an image API Docker Image Reference value and returns a reference we can actually use currently Open Shift stores the cluster internal service IPs here which are unusable from the outside 
new Image Source creates a new Image Source for the specified reference The caller must call Close on the returned Image Source 
Close removes resources associated with an initialized Image Source if any 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Get Signatures returns the image s signatures It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve signatures for when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
ensure Image Is Resolved sets up s docker and s image Stream Image Name 
new Image Destination creates a new Image Destination for the specified reference 
Try Reusing Blob checks whether the transport already contains or can efficiently reuse a blob and if so applies it to the current destination e g if the blob is a filesystem layer this signifies that the changes it describes need to be applied again when composing a filesystem tree info Digest must not be empty If can Substitute Try Reusing Blob can use an equivalent equivalent of the desired blob in that case the returned info may not match the input If the blob has been succesfully reused returns true info nil info must contain at least a digest and size If the transport can not reuse the requested blob Try Reusing Blob returns false nil it returns a non nil error only on an unexpected failure May use and or update cache 
Put Manifest writes manifest to the destination FIXME This should also receive a MIME type if known to differentiate between schema versions If the destination is in principle available refuses this manifest type e g it does not recognize the schema but may accept a different manifest type the returned error must be an Manifest Type Rejected Error 
Commit marks the process of storing the image as successful and asks for the image to be persisted WARNING This does not have any transactional semantics Uploaded data MAY be visible to others before Commit is called Uploaded data MAY be removed or MAY remain around if Close is called without Commit i e rollback is allowed but not guaranteed 
new Untrusted Signature returns an untrusted Signature object with the specified primary contents and appropriate metadata 
Marshal JSON implements the json Marshaler interface 
Unmarshal JSON implements the json Unmarshaler interface 
strict Unmarshal JSON is Unmarshal JSON except that it may return the internal json Format Error error type Splitting it into a separate function allows us to do the json Format Error Invalid Signature Error in a single place the caller 
Sign formats the signature and returns a blob signed using mech and key Identity If it seems surprising that this is a method on untrusted Signature note that there isn t a good reason to think that a key used by the user is trusted by any component of the system just because it is a private key actually the presence of a private key on the system increases the likelihood of an a successful attack on that private key on that particular system 
verify And Extract Signature verifies that unverified Signature has been signed and that its principial components match expected values both as specified by rules and returns it 
Get Untrusted Signature Information Without Verifying extracts information available in an untrusted signature WITHOUT doing any cryptographic verification This may be useful when debugging signature verification failures or when managing a set of signatures on a single image WARNING Do not use the contents of this for ANY security decisions and be VERY CAREFUL about showing this information to humans in any way which suggest that these values are probably reliable There is NO REASON to expect the values to be correct or not intentionally misleading including things like Verified by authority 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
Validate Policy Configuration Scope checks that scope is a valid name for a signature Policy Transport Scopes keys i e a valid Policy Configuration Identity or Policy Configuration Namespaces return value It is acceptable to allow an invalid value which will never be matched it can only cause user confusion scope passed to this function will not be that value is always allowed 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
New Reference returns a docker daemon reference for either the supplied image ID config digest or the supplied reference which must satisfy reference Is Name Only 
String Within Transport returns a string representation of the reference which MUST be such that reference Transport Parse Reference reference String Within Transport returns an equivalent reference NOTE The returned string is not promised to be equal to the original input to Parse Reference e g default attribute values omitted by the user may be filled in in the return value or vice versa WARNING Do not use the return value in the UI to describe an image it does not contain the Transport Name prefix instead see transports Image Name 
Policy Configuration Identity returns a string representation of the reference suitable for policy lookup This MUST reflect user intent not e g after processing of third party redirects or aliases The value SHOULD be fully explicit about its semantics with no hidden defaults AND canonical i e various references with exactly the same semantics should return the same configuration identity It is fine for the return value to be equal to String Within Transport and it is desirable but not required guaranteed that it will be a valid input to Transport Parse Reference Returns if configuration identities for these references are not supported 
Policy Configuration Namespaces returns a list of other policy configuration namespaces to search for if explicit configuration for Policy Configuration Identity is not set The list will be processed in order terminating on first match and an implicit is always checked at the end It is STRONGLY recommended for the first element if any to be a prefix of Policy Configuration Identity and each following element to be a prefix of the element preceding it 
Rewrite Reference will substitute the provided reference prefix to the endpoints location from the ref and creates a new named reference from it The function errors if the newly created reference is not parsable 
parse Location parses the input string performs some sanity checks and returns the sanitized input string An error is returned if the input string is empty or if contains an http s prefix 
get V Registries transforms v registries in the config into an array of v registries of type Registry 
post Process Registries checks the consistency of all registries e g set the Prefix to Location if not set and applies conflict checks It returns an array of cleaned registries and error in case of conflicts 
get Config Path returns the system registries config path if specified Otherwise system Registries Conf Path is returned 
Get Registries loads and returns the registries specified in the config Note the parsed content of registry config files is cached For reloading use Invalidate Cache and re call Get Registries 
Find Unqualified Search Registries returns all registries that are configured for unqualified image search i e with Registry Search true 
ref Matches Prefix returns true iff ref which is a registry repository namespace repository or image reference as formatted by reference Domain reference Named Name or reference Reference String note that this requires the name to start with an explicit hostname matches a Registry Prefix value This is split from the caller primarily to make testing easier 
Find Registry returns the Registry with the longest prefix for ref which is a registry repository namespace repository or image reference as formatted by reference Domain reference Named Name or reference Reference String note that this requires the name to start with an explicit hostname If no Registry prefixes the image nil is returned 
Reads the global registry file from the filesystem Returns a byte array 
Loads the registry configuration file from the filesystem and then unmarshals it Returns the unmarshalled object 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
From Source returns a types Image Closer implementation for the default instance of source If source is a manifest list Manifest still returns the manifest list but other methods transparently return data from an appropriate image instance The caller must call Close on the returned Image Closer From Source takes ownership of the input Image Source and will call src Close when the image is closed This does not prevent callers from using both the Image and Image Source objects simultaneously but it means that they only need to the Image NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image instead of calling this function 
From Unparsed Image returns a types Image implementation for unparsed If unparsed represents a manifest list Manifest still returns the manifest list but other methods transparently return data from an appropriate single image The Image must not be used after the underlying Image Source is Close d 
Manifest overrides the Unparsed Image Manifest to always use the fields which we have already fetched 
Config Update updates the image s default configuration and adds annotations which will be visible in source images created using this reference 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image WARNING This may not do the right thing for a manifest list see image From Source for details 
new Image Source returns an Image Source for reading from an existing directory 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Get Signatures returns the image s signatures It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve signatures for when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
manifest OCI From Components builds a new manifest OCI from the supplied data 
OCIConfig returns the image configuration as per OCI v image spec Information about layers in the resulting configuration isn t guaranteed to be returned to due how old image manifests work docker v s especially 
Updated Image returns a types Image modified according to options This does not change the state of the original Image object 
parse Image And Docker Reference converts an image and a reference string into two parsed entities failing on any error and handling unidentified images 
parse Docker References converts two reference strings into parsed entities failing on any error 
Image Name converts a types Image Reference into an URL like image name which MUST be such that Parse Image Name Image Name reference returns an equivalent reference This is the generally recommended way to refer to images in the UI NOTE The returned string is not promised to be equal to the original input to Parse Image Name e g default attribute values omitted by the user may be filled in in the return value or vice versa 
List Names returns a list of non deprecated transport names Deprecated transports can be used but are not presented to users 
Validate Policy Configuration Scope checks that scope is a valid name for a signature Policy Transport Scopes keys i e a valid Policy Configuration Identity or Policy Configuration Namespaces return value It is acceptable to allow an invalid value which will never be matched it can only cause user confusion scope passed to this function will not be that value is always allowed 
New Reference returns an OSTree reference for a specified repo and image 
String Within Transport returns a string representation of the reference which MUST be such that reference Transport Parse Reference reference String Within Transport returns an equivalent reference NOTE The returned string is not promised to be equal to the original input to Parse Reference e g default attribute values omitted by the user may be filled in in the return value or vice versa WARNING Do not use the return value in the UI to describe an image it does not contain the Transport Name prefix 
Policy Configuration Namespaces returns a list of other policy configuration namespaces to search for if explicit configuration for Policy Configuration Identity is not set The list will be processed in order terminating on first match and an implicit is always checked at the end It is STRONGLY recommended for the first element if any to be a prefix of Policy Configuration Identity and each following element to be a prefix of the element preceding it 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image 
New Image Source returns a types Image Source for this reference The caller must call Close on the returned Image Source 
New Image Destination returns a types Image Destination for this reference The caller must call Close on the returned Image Destination 
signature Path returns a path for a signature within a ostree using our conventions 
paranoid Unmarshal JSONObject unmarshals data as a JSON object but failing on the slightest unexpected aspect including duplicated keys unrecognized keys and non matching types Uses field Resolver to determine the destination for a field value which should return a pointer to the destination if valid or nil if the key is rejected The field Resolver approach is useful for decoding the Policy Transports map using it for structs is a bit lazy we could use reflection to automate this Later 
paranoid Unmarshal JSONObject unmarshals data as a JSON object but failing on the slightest unexpected aspect including duplicated keys unrecognized keys and non matching types Each of the fields in exact Fields must be present exactly once and none other fields are accepted 
Validate Image Name returns nil if the image name is empty or matches the open containers image name specs In any other case an error is returned 
Split Path And Image tries to split the provided OCI reference into the OCI path and image Neither path nor image parts are validated at this stage 
Validate OCIPath takes the OCI path and validates it 
Validate Scope validates a policy configuration scope for an OCI transport 
Blob Info From Schema Descriptor returns a types Blob Info based on the input schema descriptor 
Schema From Manifest creates a Schema manifest instance from a manifest blob 
Schema From Components creates an Schema manifest instance from the supplied data 
Layer Infos returns a list of Layer Infos of layers referenced by this image in order the root layer first and then successive layered layers The Digest field is guaranteed to be provided Size may be WARNING The list may contain duplicates and they are semantically relevant 
Update Layer Infos replaces the original layers with the specified Blob Infos size digest urls in order the root layer first and then successive layered layers 
Inspect returns various information for skopeo inspect parsed from the manifest and configuration 
Image ID computes an ID which can uniquely identify this image by its contents 
Set Authentication stores the username and password in the auth json file 
Get Authentication returns the registry credentials stored in either auth json file or docker config json If an entry is not found empty strings are returned for the username and password 
Remove Authentication deletes the credentials stored in auth json 
Remove All Authentication deletes all the credentials stored in auth json 
get Path gets the path of the auth json file The path can be overriden by the user if the overwrite path flag is set If the flag is not set and XDG RUNTIME DIR is set the auth json file is saved in XDG RUNTIME DIR containers Otherwise the auth json file is stored in run containers UID 
read JSONFile unmarshals the authentications stored in the auth json file and returns it or returns an empty docker Config File data structure if auth json does not exist if the file exists and is empty read JSONFile returns an error 
modify JSON writes to auth json if the docker Config File has been updated 
find Authentication looks for auth of registry in path 
convert To Hostname converts a registry url which has http https prepended to just an hostname Copied from github com docker docker registry auth go 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Get Signatures returns the image s signatures It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve signatures for when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Layer Infos For Copy returns updated layer info that should be used when reading in preference to values in the manifest if specified 
New Destination returns a tarfile Destination for the specified io Writer 
Add Repo Tags adds the specified tags to the destination s repo Tags 
Put Blob writes contents of stream and returns data representing the result with all data filled in input Info Digest can be optionally provided if known it is not mandatory for the implementation to verify it input Info Size is the expected length of stream if known May update cache WARNING The contents of stream are being verified on the fly Until stream Read returns io EOF the contents of the data SHOULD NOT be available to any other readers for download using the supplied digest If stream Read at any time ESPECIALLY at end of input returns an error Put Blob MUST fail and delete any data stored so far 
Try Reusing Blob checks whether the transport already contains or can efficiently reuse a blob and if so applies it to the current destination e g if the blob is a filesystem layer this signifies that the changes it describes need to be applied again when composing a filesystem tree info Digest must not be empty If can Substitute Try Reusing Blob can use an equivalent equivalent of the desired blob in that case the returned info may not match the input If the blob has been succesfully reused returns true info nil info must contain at least a digest and size If the transport can not reuse the requested blob Try Reusing Blob returns false nil it returns a non nil error only on an unexpected failure May use and or update cache 
Put Manifest writes manifest to the destination FIXME This should also receive a MIME type if known to differentiate between schema versions If the destination is in principle available refuses this manifest type e g it does not recognize the schema but may accept a different manifest type the returned error must be an Manifest Type Rejected Error 
write Legacy Layer Metadata writes legacy VERSION and configuration files for all layers 
send Symlink sends a symlink into the tar stream 
send Bytes sends a path into the tar stream 
send File sends a file into the tar stream 
Put Signatures adds the given signatures to the docker tarfile currently not supported MUST be called after Put Manifest signatures reference manifest contents 
Commit finishes writing data to the underlying io Writer It is the caller s responsibility to close it if necessary 
image Matches Repo returns true iff image Names contains an element with the same repo as ref 
Resolve the reference s name to an image ID in the store if there s already one present with the same name or ID and return the image 
Return a Transport object that defaults to using the same store that we used to build this reference object 
Return a name with a tag prefixed with the graph root and driver name to disambiguate between images which may be present in multiple stores and share only their names 
Also accept policy that s tied to the combination of the graph root and driver name to apply to all images stored in the Store and to just the graph root in case we re using multiple drivers in the same directory for some reason 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image WARNING This may not do the right thing for a manifest list see image From Source for details 
Docker Reference Identity returns a string representation of the reference suitable for policy lookup as a backend for Image Reference Policy Configuration Identity The reference must satisfy reference Is Name Only 
Docker Reference Namespaces returns a list of other policy configuration namespaces to search as a backend for Image Reference Policy Configuration Identity The reference must satisfy reference Is Name Only 
Gzip Decompressor is a Decompressor Func for the gzip compression algorithm 
Bzip Decompressor is a Decompressor Func for the bzip compression algorithm 
Xz Decompressor is a Decompressor Func for the xz compression algorithm 
Detect Compression returns a Decompressor Func if the input is recognized as a compressed format nil otherwise Because it consumes the start of input other consumers must use the returned io Reader instead to also read from the beginning 
Auto Decompress takes a stream and returns an uncompressed version of the same stream The caller must call Close on the returned stream even if the input does not need or does not even support closing 
new Image Destination creates a new Image Destination for the specified image reference 
Supports Signatures returns an error to be displayed to the user if the destination certainly can t store signatures Note It is still possible for Put Signatures to fail if Supports Signatures returns nil 
Put Blob writes contents of stream and returns data representing the result with all data filled in input Info Digest can be optionally provided if known it is not mandatory for the implementation to verify it input Info Size is the expected length of stream if known May update cache WARNING The contents of stream are being verified on the fly Until stream Read returns io EOF the contents of the data SHOULD NOT be available to any other readers for download using the supplied digest If stream Read at any time ESPECIALLY at end of input returns an error Put Blob MUST fail and delete any data stored so far 
blob Exists returns true iff repo contains a blob with digest and if so also its size If the destination does not contain the blob or it is unknown blob Exists ordinarily returns false nil it returns a non nil error only on an unexpected failure 
mount Blob tries to mount blob src Digest from src Repo to the current destination 
Try Reusing Blob checks whether the transport already contains or can efficiently reuse a blob and if so applies it to the current destination e g if the blob is a filesystem layer this signifies that the changes it describes need to be applied again when composing a filesystem tree info Digest must not be empty If can Substitute Try Reusing Blob can use an equivalent equivalent of the desired blob in that case the returned info may not match the input If the blob has been succesfully reused returns true info nil info must contain at least a digest and size If the transport can not reuse the requested blob Try Reusing Blob returns false nil it returns a non nil error only on an unexpected failure May use and or update cache 
Put Manifest writes manifest to the destination FIXME This should also receive a MIME type if known to differentiate between schema versions If the destination is in principle available refuses this manifest type e g it does not recognize the schema but may accept a different manifest type the returned error must be an Manifest Type Rejected Error 
is Manifest Invalid Error returns true iff err from client Handle Error Reponse is a manifest invalid error 
put Signatures To Lookaside implements Put Signatures from the lookaside location configured in s c signature Base which is not nil 
put One Signature stores one signature to url NOTE Keep this in sync with docs signature protocols md 
delete One Signature deletes a signature from url if it exists If it successfully determines that the signature does not exist returns true nil NOTE Keep this in sync with docs signature protocols md 
put Signatures To APIExtension implements Put Signatures using the X Registry Supports Signatures API extension 
bic Transport Scope returns a BICTransport Scope appropriate for ref 
new BICLocation Reference returns a BICLocation Reference appropriate for ref 
parse BICLocation Reference returns a repository for encoded lr 
TODO We could add support for multiple images in a single archive so that people could use docker archive opensuse tar opensuse leap as the source of an image To do for both the New Source From File and New Source From Stream functions New Source From File returns a tarfile Source for the specified path 
New Source From Stream returns a tarfile Source for the specified input Stream which can be either compressed or uncompressed The caller can close the input Stream immediately after New Source From File returns 
open Tar Component returns a Read Closer for the specific file within the archive This is linear scan we assume that the tar file will have a fairly small amount of files layers and that filesystem caching will make the repeated seeking over the uncompressed tar Path cheap enough The caller should call Close on the returned stream 
find Tar Component returns a header and a reader matching path within input File or nil nil nil if not found 
read Tar Component returns full contents of component Path 
ensure Cached Data Is Present loads data necessary for any of the public accessors 
load Tar Manifest loads and decodes the manifest json 
Close removes resources associated with an initialized Source if any 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Get Signatures returns the image s signatures It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve signatures for when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
new Image Destination returns a types Image Destination for the specified image reference 
image Load Goroutine accepts tar stream on reader sends it to c and reports error or success by writing to status Channel 
Close removes resources associated with an initialized Image Destination if any 
Commit marks the process of storing the image as successful and asks for the image to be persisted WARNING This does not have any transactional semantics Uploaded data MAY be visible to others before Commit is called Uploaded data MAY be removed or MAY remain around if Close is called without Commit i e rollback is allowed but not guaranteed 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
New Reference returns an OCI reference for a file and a image 
String Within Transport returns a string representation of the reference which MUST be such that reference Transport Parse Reference reference String Within Transport returns an equivalent reference 
Policy Configuration Namespaces returns a list of other policy configuration namespaces to search for if explicit configuration for Policy Configuration Identity is not set 
Delete Image deletes the named image from the registry if supported 
create OCIRef creates the oci reference of the image 
creates the temporary directory and copies the tarred content to it 
destructively Prioritize Replacement Candidates With Max is destructively Prioritize Replacement Candidates with a parameter for the number of entries to limit only to make testing simpler 
Destructively Prioritize Replacement Candidates consumes AND DESTROYS an array of possible replacement candidates with their last known existence times the primary digest the user actually asked for and the corresponding uncompressed digest if known possibly equal to the primary digest and returns an appropriately prioritized and or trimmed result suitable for a return value from types Blob Info Cache Candidate Locations WARNING The array of candidates is destructively modified The implementation of this function could of course make a copy but all Candidate Locations implementations build the slice of candidates only for the single purpose of calling this function anyway 
new Image Destination returns an Image Destination for writing to an existing ostree 
Close removes resources associated with an initialized Image Destination if any 
Put Blob writes contents of stream and returns data representing the result input Info Digest can be optionally provided if known it is not mandatory for the implementation to verify it input Info Size is the expected length of stream if known input Info Media Type describes the blob format if known May update cache WARNING The contents of stream are being verified on the fly Until stream Read returns io EOF the contents of the data SHOULD NOT be available to any other readers for download using the supplied digest If stream Read at any time ESPECIALLY at end of input returns an error Put Blob MUST fail and delete any data stored so far 
Try Reusing Blob checks whether the transport already contains or can efficiently reuse a blob and if so applies it to the current destination e g if the blob is a filesystem layer this signifies that the changes it describes need to be applied again when composing a filesystem tree info Digest must not be empty If can Substitute Try Reusing Blob can use an equivalent equivalent of the desired blob in that case the returned info may not match the input If the blob has been succesfully reused returns true info nil info must contain at least a digest and size If the transport can not reuse the requested blob Try Reusing Blob returns false nil it returns a non nil error only on an unexpected failure May use and or update cache 
Put Manifest writes manifest to the destination FIXME This should also receive a MIME type if known to differentiate between schema versions If the destination is in principle available refuses this manifest type e g it does not recognize the schema but may accept a different manifest type the returned error must be an Manifest Type Rejected Error 
Resolve Path To Fully Explicit returns the input path converted to an absolute no symlinks cleaned up path To do so all elements of the input path must exist as a special case the final component may be a non existent name but not a symlink pointing to a non existent name This is intended as a a helper for implementations of types Image Reference Policy Configuration Identity etc 
resolve Existing Path To Fully Explicit is the same as Resolve Path To Fully Explicit but without the special case for missing final component 
new Image Destination returns an Image Destination for writing to a directory 
Put Manifest writes manifest to the destination FIXME This should also receive a MIME type if known to differentiate between schema versions If the destination is in principle available refuses this manifest type e g it does not recognize the schema but may accept a different manifest type the returned error must be an Manifest Type Rejected Error 
returns true if directory is empty 
deletes the contents of a directory 
new Image returns a new Image interface type after setting up a client to the registry hosting the given image The caller must call Close on the returned Image 
Get Repository Tags list all tags available in the repository The tag provided inside the Image Reference will be ignored This is a backward compatible shim method which calls the module level Get Repository Tags 
Get Repository Tags list all tags available in the repository The tag provided inside the Image Reference will be ignored 
blob Info Cache Dir returns a path to a blob info cache appropripate for sys and euid euid is used so that sudo does not write root owned files into the unprivileged users home directory 
Default Cache returns the default Blob Info Cache implementation appropriate for sys 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Docker Image Reference 
String Within Transport returns a string representation of the reference which MUST be such that reference Transport Parse Reference reference String Within Transport returns an equivalent reference NOTE The returned string is not promised to be equal to the original input to Parse Reference e g default attribute values omitted by the user may be filled in in the return value or vice versa WARNING Do not use the return value in the UI to describe an image it does not contain the Transport Name prefix 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image WARNING This may not do the right thing for a manifest list see image From Source for details 
New Image Source returns a types Image Source for this reference The caller must call Close on the returned Image Source 
New Image Destination returns a types Image Destination for this reference The caller must call Close on the returned Image Destination 
Delete Image deletes the named image from the registry if supported 
New returns a Blob Info Cache implementation which is in memory only This is primarily intended for tests but also used as a fallback if blobinfocache Default Cache can t determine or set up the location for a persistent cache Most users should use blobinfocache Default Cache instead of calling this directly Manual users of types Image Source Image Destination might also use this instead of a persistent cache 
Uncompressed Digest returns an uncompressed digest corresponding to any Digest May return any Digest if it is known to be uncompressed Returns if nothing is known about the digest it may be compressed or uncompressed 
uncompressed Digest Locked implements types Blob Info Cache Uncompressed Digest but must be called only with mem mutex held 
Record Digest Uncompressed Pair records that the uncompressed version of any Digest is uncompressed It s allowed for any Digest uncompressed WARNING Only call this for LOCALLY VERIFIED data don t record a digest pair just because some remote author claims so e g because a manifest config pair exists otherwise the cache could be poisoned and allow substituting unexpected blobs Eventually the Diff IDs in image config could detect the substitution but that may be too late and not all image formats contain that data 
Record Known Location records that a blob with the specified digest exists within the specified transport scope scope and can be reused given the opaque location data 
append Replacement Candiates creates prioritize Candidate With Time values for transport scope digest and returns the result of appending them to candidates 
Candidate Locations returns a prioritized limited number of blobs and their locations that could possibly be reused within the specified transport scope if they still exist which is not guaranteed If can Substitute the returned cadidates will match the submitted digest exactly if can Substitute data from previous Record Digest Uncompressed Pair calls is used to also look up variants of the blob which have the same uncompressed digest 
Unparsed Instance returns a types Unparsed Image implementation for source instance Digest If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list The Unparsed Image must not be used after the underlying Image Source is Close d 
Manifest is like Image Source Get Manifest but the result is cached it is OK to call this however often you need 
expected Manifest Digest returns a the expected value of the manifest digest and an indicator whether it is known The bool return value seems redundant with digest it is used explicitly to refuse unexpected situations when the digest exists but is 
Signatures is like Image Source Get Signatures but the result is cached it is OK to call this however often you need 
new GPGSigning Mechanism In Directory returns a new GPG Open PGP signing mechanism using optional Dir if not empty The caller must call Close on the returned Signing Mechanism 
new Ephemeral GPGSigning Mechanism returns a new GPG Open PGP signing mechanism which recognizes only public keys from the supplied blob and returns the identities of these keys The caller must call Close on the returned Signing Mechanism 
new GPGMEContext returns a new gpgme Context using optional Dir if not empty 
import Keys From Bytes imports public keys from the supplied blob and returns their identities The blob is assumed to have an appropriate format the caller is expected to know which one NOTE This may modify long term state e g key storage in a directory underlying the mechanism but we do not make this public it can only be used through new Ephemeral GPGSigning Mechanism 
Sign creates a non detached signature of input using key Identity Fails with a Signing Not Supported Error if the mechanism does not support signing 
Verify parses unverified Signature and returns the content and the signer s identity 
new Image Destination returns an Image Destination for writing to an existing directory 
Close removes resources associated with an initialized Image Destination if any Close deletes the temp directory of the oci archive image 
Supports Signatures returns an error to be displayed to the user if the destination certainly can t store signatures 
Put Blob writes contents of stream and returns data representing the result input Info Digest can be optionally provided if known it is not mandatory for the implementation to verify it input Info Size is the expected length of stream if known input Info Media Type describes the blob format if known May update cache WARNING The contents of stream are being verified on the fly Until stream Read returns io EOF the contents of the data SHOULD NOT be available to any other readers for download using the supplied digest If stream Read at any time ESPECIALLY at end of input returns an error Put Blob MUST fail and delete any data stored so far 
Try Reusing Blob checks whether the transport already contains or can efficiently reuse a blob and if so applies it to the current destination e g if the blob is a filesystem layer this signifies that the changes it describes need to be applied again when composing a filesystem tree info Digest must not be empty If can Substitute Try Reusing Blob can use an equivalent equivalent of the desired blob in that case the returned info may not match the input If the blob has been succesfully reused returns true info nil info must contain at least a digest and size If the transport can not reuse the requested blob Try Reusing Blob returns false nil it returns a non nil error only on an unexpected failure May use and or update cache 
Put Manifest writes manifest to the destination 
Commit marks the process of storing the image as successful and asks for the image to be persisted after the directory is made it is tarred up into a file and the directory is deleted 
tar converts the directory at src and saves it to dst 
Parse Store Reference takes a name or an ID tries to figure out which it is relative to the given store and returns it in a reference object 
Parse Reference takes a name and a tag or digest and or ID name 
choose Digest From Manifest List parses blob as a schema manifest list and returns the digest of the image appropriate for the current environment 
Choose Manifest Instance From Manifest List returns a digest of a manifest appropriate for the current system from the manifest available from src 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Get Signatures returns the image s signatures It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve signatures for when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
Layer Infos For Copy returns updated layer info that should be used when copying in preference to values in the manifest if specified 
manifest Schema From Components builds a new manifest Schema from the supplied data 
OCIConfig returns the image configuration as per OCI v image spec Information about layers in the resulting configuration isn t guaranteed to be returned to due how old image manifests work docker v s especially 
Embedded Docker Reference Conflicts whether a Docker reference embedded in the manifest if any conflicts with destination ref It returns false if the manifest does not embed a Docker reference This embedding unfortunately happens for Docker schema please do not add support for this in any new formats 
Inspect returns various information for skopeo inspect parsed from the manifest and configuration 
Updated Image Needs Layer Diff IDs returns true iff Updated Image options needs Information Only Layer Diff IDs This is a horribly specific interface but computing Information Only Layer Diff IDs can be very expensive to compute most importantly it forces us to download the full layers even if they are already present at the destination 
Updated Image returns a types Image modified according to options This does not change the state of the original Image object 
Based on github com docker docker distribution pull v go 
new Image Source creates a new Image Source for the specified image reference ref The following steps will be done during the instance creation Lookup the registry within the configured location in sys System Registries Conf Path If there is no configured registry available we fallback to the provided docker reference ref References which contain a configured prefix will be automatically rewritten to the correct target reference For example if the configured prefix example com foo location example com and the image will be pulled from the ref example com foo image then the resulting pull will effectively point to example com image If the rewritten reference succeeds it will be used as the docker Ref in the client If the rewrite fails the function immediately returns an error Each mirror will be used in the configured order to test the availability of the image manifest on the remote location For example if the manifest is not reachable due to connectivity issues then the next mirror will be tested instead If no mirror is configured or contains the target manifest then the initial ref will be tested as fallback The creation of the new docker Image Source only succeeds if a remote location with the available manifest was found A cleanup call to Close is needed if the caller is done using the returned Image Source 
simplify Content Type drops parameters from a HTTP media type see https tools ietf org html rfc section Alternatively an empty string is returned unchanged and invalid values are simplified to an empty string 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
ensure Manifest Is Loaded sets s cached Manifest and s cached Manifest MIMEType Image Source implementations are not required or expected to do any caching but because our signatures are attached to the manifest digest we need to ensure that the digest of the manifest returned by Get Manifest ctx nil and used by Get Signatures ctx nil are consistent otherwise we would get spurious signature verification failures when pulling while a tag is being updated 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Get Signatures returns the image s signatures It may use a remote slow service If instance Digest is not nil it contains a digest of the specific manifest instance to retrieve signatures for when the primary manifest is a manifest list this never happens if the primary manifest is not a manifest list e g if the source never returns manifest lists 
manifest Digest returns a digest of the manifest from instance Digest if non nil or from the supplied reference or finally from a fetched manifest 
get Signatures From Lookaside implements Get Signatures from the lookaside location configured in s c signature Base which is not nil 
get One Signature downloads one signature from url If it successfully determines that the signature does not exist returns with missing set to true and error set to nil NOTE Keep this in sync with docs signature protocols md 
get Signatures From APIExtension implements Get Signatures using the X Registry Supports Signatures API extension 
delete Image deletes the named image from the registry if supported 
Manifest is like Image Source Get Manifest but the result is cached it is OK to call this however often you need 
Signatures is like Image Source Get Signatures but the result is cached it is OK to call this however often you need 
Layer Infos For Copy returns an updated set of layer blob information which may not match the manifest The Digest field is guaranteed to be provided Size may be WARNING The list may contain duplicates and they are semantically relevant 
Schema From Manifest creates a Schema manifest instance from a manifest blob NOTE The instance is not necessary a literal representation of the original blob layers with duplicate IDs are eliminated 
Schema From Components creates an Schema manifest instance from the supplied data 
initialize initializes Extracted V Compatibility and verifies invariants so that the rest of this code can assume a minimally healthy manifest 
Layer Infos returns a list of Layer Infos of layers referenced by this image in order the root layer first and then successive layered layers The Digest field is guaranteed to be provided Size may be WARNING The list may contain duplicates and they are semantically relevant 
Update Layer Infos replaces the original layers with the specified Blob Infos size digest urls in order the root layer first and then successive layered layers 
Serialize returns the manifest in a blob format NOTE Serialize does not in general reproduce the original blob if this object was loaded from one even if no modifications were made 
fix Manifest Layers after validating the supplied manifest to use correctly formatted IDs and to not have non consecutive ID collisions in m History modifies manifest to only have one entry for each layer ID in m History deleting the older duplicates both from m History and m FSLayers Note that even after this succeeds m FSLayers may contain duplicate entries for Dockerfile operations which change the configuration but not the filesystem 
Inspect returns various information for skopeo inspect parsed from the manifest and configuration 
To Schema Config builds a schema style configuration blob using the supplied diff IDs 
Image ID computes an ID which can uniquely identify this image by its contents 
Guess MIMEType guesses MIME type of a manifest and returns it if it is recognized or if unknown or unrecognized FIXME We should in general prefer out of band MIME type instead of blindly parsing the manifest but we may not have such metadata available e g when the manifest is a local file 
Digest returns the a digest of a docker manifest with any necessary implied transformations like stripping v s signatures 
Matches Digest returns true iff the manifest matches expected Digest Error may be set if this returns false Note that this is not doing Constant Time Compare by the time we get here the cryptographic signature must already have been verified or we are not using a cryptographic channel and the attacker can modify the digest along with the manifest blob 
Add Dummy V S Signature adds an JWS signature with a temporary key i e useless to a v s manifest This is useful to make the manifest acceptable to a Docker Registry even though nothing needs or wants the JWS signature 
Normalized MIMEType returns the effective MIME type of a manifest MIME type returned by a server centralizing various workarounds 
From Blob returns a Manifest instance for the specified manifest blob and the corresponding MIME type 
layer Infos To Strings converts a list of layer infos presumably obtained from a Manifest Layer Infos method call into a format suitable for inclusion in a types Image Inspect Info structure 
Parse Reference converts a string which should not start with the Image Transport Name prefix into an Image Reference 
Validate Policy Configuration Scope checks that scope is a valid name for a signature Policy Transport Scopes keys i e a valid Policy Configuration Identity or Policy Configuration Namespaces return value It is acceptable to allow an invalid value which will never be matched it can only cause user confusion scope passed to this function will not be that value is always allowed 
There is no directory Parse Reference because it is rather pointless Callers who need a transport independent interface will go through dir Transport Parse Reference callers who intentionally deal with directories can use directory New Reference New Reference returns a directory reference for a specified path We do not expose an API supplying the resolved Path we could but recomputing it is generally cheap enough that we prefer being confident about the properties of resolved Path 
Policy Configuration Namespaces returns a list of other policy configuration namespaces to search for if explicit configuration for Policy Configuration Identity is not set The list will be processed in order terminating on first match and an implicit is always checked at the end It is STRONGLY recommended for the first element if any to be a prefix of Policy Configuration Identity and each following element to be a prefix of the element preceding it 
New Image returns a types Image Closer for this reference possibly specialized for this Image Transport The caller must call Close on the returned Image Closer NOTE If any kind of signature verification should happen build an Unparsed Image from the value returned by New Image Source verify that Unparsed Image and convert it into a real Image via image From Unparsed Image WARNING This may not do the right thing for a manifest list see image From Source for details 
New Image Source returns a types Image Source for this reference The caller must call Close on the returned Image Source 
New Image Destination returns a types Image Destination for this reference The caller must call Close on the returned Image Destination 
layer Path returns a path for a layer tarball within a directory using our conventions 
signature Path returns a path for a signature within a directory using our conventions 
new Image Source returns an Image Source for reading from an existing directory 
Close removes resources associated with an initialized Image Source if any 
Get Manifest returns the image s manifest along with its MIME type which may be empty when it can t be determined but the manifest is available It may use a remote slow service 
Get Blob returns a stream for the specified blob and the blob s size or if unknown The Digest field in Blob Info is guaranteed to be provided Size may be and Media Type may be optionally provided May update Blob Info Cache preferably after it knows for certain that a blob truly exists at a specific location 
Layer Infos For Copy returns the list of layer blobs that make up the root filesystem of the image after they ve been decompressed 
New creates a new Pool of workers that starts with n workers You must provide a constructor function that creates new Worker types and when you change the size of the pool the constructor will be called to create each new Worker 
New Func creates a new Pool of workers where each worker will process using the provided func 
 Process will use the Pool to process a payload and synchronously return the result Process can be called safely by any goroutines but will panic if the Pool has been stopped 
Process Timed will use the Pool to process a payload and synchronously return the result If the timeout occurs before the job has finished the worker will be interrupted and Err Job Timed Out will be returned Process Timed can be called safely by any goroutines 
Set Size changes the total number of workers in the Pool This can be called by any goroutine at any time unless the Pool has been stopped in which case a panic will occur 
Get Size returns the current size of the pool 
Get Perspective Transform calculates a perspective transform from four pairs of the corresponding points Parameters src Coordinates of quadrangle vertices in the source image dst Coordinates of the corresponding quadrangle vertices in the destination image Returns the computed matrix 
Warp Perspective applies a perspective transformation to an image Parameters src input image dst output image map Matrix x transformation matrix flags combination of interpolation methods In the C version it is flags CV INTER LINEAR CV WARP FILL OUTLIERS by default fill Val In the C version it is fillval by default 
 Returns a Seq of countours in an image detected according to the parameters Caller must Release the Seq returned 
cv Draw Contours Cv Arr img Cv Seq contour Cv Scalar external Color Cv Scalar hole Color int max Level int thickness int line Type 
Cv Seq cv Approx Poly const void src seq int header size Cv Mem Storage storage int method double eps int recursive 
cv Arc Length const void curve Cv Slice slice CV WHOLE SEQ int is closed 
double cv Contour Area const Cv Arr contour Cv Slice slice CV WHOLE SEQ int oriented 
 points can be either Cv Seq or Cv Mat 
Finds a rotated rectangle of the minimum area enclosing the input D point set points can be either Cv Seq or Cv Mat 
Calculates up right bounding rectangle of point set points can be either Cv Seq or Cv Mat 
 KMeans finds centers of k clusters in data and groups input samples around the clusters It returns a matrix that stores the cluster indices for every sample and a matrix that stores the cluster centers 
 Decode Image Mem decodes an image from an in memory byte buffer 
 From Image converts a go image Image to an opencv Ipl Image 
 From Image Unsafe create an opencv Ipl Image that shares the buffer with the go image RGBA image All changes made from opencv might affect go 
 To Image converts a opencv Ipl Image to an go image Image 
Convert Mat which defined by SWIG to mat Dense The reason is the latter is much easier to handle in Go Gcv Mat is assumed to be dimensional matrix 
Convert mat Dense to Mat 
Returns the Top Left Point of the rectangle 
Returns the Bottom Right Point of the rectangle 
returns a new Cv Point 
Returns a Point 
returns a new Cv Point 
Returns a Point 
Returns a Cv Box D 
Finds box vertices 
 Equivalent to the C constant CV WHOLE SEQ 
 Val returns an array with the scalars values 
 Basic GUI functions this function is used to set some external parameters in case of X Window 
 wait for key event infinitely delay or for delay milliseconds 
 create window 
 Set and Get Property of the window 
 display image within window highgui windows remember their content 
 resize move window 
 get native window handle HWND in case of Win and Widget in case of X Window 
 window track bar create trackbar and display it on top of given window set callback 
export go Trackbar Callback 
 retrieve or set trackbar position 
 assign callback for mouse events 
export go Mouse Callback 
 window destroy destroy window and all the trackers associated with it 
 load image from file iscolor can be a combination of above flags where CV LOAD IMAGE UNCHANGED overrides the other flags using CV LOAD IMAGE ANYCOLOR alone is equivalent to CV LOAD IMAGE UNCHANGED unless CV LOAD IMAGE ANYDEPTH is specified images are converted to bit 
 save image to file 
 decode image stored in the buffer 
 encode image and store the result as a byte vector single row u C matrix 
 utility function convert one image to another with optional vertical flip 
 start capturing frames from video file 
 start capturing frames from camera index camera index domain offset CV CAP 
 grab a frame return on success on fail this function is thought to be fast 
 get the frame grabbed with cv Grab Frame This function may apply some frame processing like frame decompression flipping etc DO NOT RELEASE or MODIFY the retrieved frame 
 Just a combination of cv Grab Frame and cv Retrieve Frame DO NOT RELEASE or MODIFY the retrieved frame 
 stop capturing reading and free resources 
 retrieve or set capture properties 
Return the type of the capturer eg CV CAP V W CV CAP UNICAP which is unknown if created with CV CAP ANY 
Prototype for CV FOURCC so that swig can generate wrapper without mixing up the define 
 initialize video file writer 
 write frame to video file 
 close video file writer 
Gcv Init Camera Matrix D takes one by N matrix and one by N Matrix as input Each column in the input matrix represents a point in real world obj Pts or in image img Pts Return the camera matrix 
Gcv Rodrigues takes a D column vector and apply cv Rodrigues to it 
 Array allocation deallocation initialization and access to elements 
 Allocates and initializes Ipl Image header 
 Inializes Ipl Image header 
 Creates IPL image header and data 
Merge creates one multichannel array out of several single channel ones 
Split divides a multi channel array into several single channel arrays 
Add Weighted calculates the weighted sum of two images 
 Set Data assigns user data to the image header 
 Releases i e deallocates IPL image header 
 Releases IPL image header and data 
 Creates a copy of IPL image width Step may differ 
 Sets a Channel Of Interest only a few functions support COI use cv Copy to extract the selected channel and or put it back 
 Retrieves image Channel Of Interest 
 Sets image ROI region of interest COI is not changed 
 Retrieves image ROI 
 Reshape changes shape of the image without copying data A value of means that channels or rows remain unchanged 
 Get D return a specific element from a dimensional matrix 
 Get D return a specific element from a dimensional matrix 
 Get D return a specific element from a dimensional matrix 
 Sets every element of an array to a given value 
 Set D sets a particular element in the image 
 Set D sets a particular element in the image 
 Set D sets a particular element in the image 
 Get Mat returns the matrix header for an image 
 Allocates and initalizes Cv Mat header 
 Allocates and initializes Cv Mat header and allocates data 
 Initializes Cv Mat header 
 Set Data assigns user data to the matrix header 
 Releases Cv Mat header and deallocates matrix data reference counting is used for data 
 Creates an exact copy of the input matrix except may be step value 
 Reshape changes shape of the matrix without copying data A value of means that channels or rows remain unchanged 
 Makes a new matrix from rect subrectangle of input array No data is copied 
 define cv Get Sub Arr cv Get Sub Rect Selects row span of the input array arr start row delta row end row end row is not included into the span 
 Selects column span of the input array arr start col end col end col is not included into the span 
 Select a diagonal of the input array diag means the main diagonal means a diagonal above the main one below the main one The diagonal will be represented as a column nx matrix 
 Get D return a specific element from a dimensional matrix 
 Get D return a specific element from a dimensional matrix 
 Get D return a specific element from a dimensional matrix 
 Set D sets a particular element in them matrix 
 Set D sets a particular element in them matrix 
 Set D sets a particular element in them matrix 
 Get Image returns the image header for the matrix 
 low level scalar raw data conversion functions 
 Allocates and initializes Cv Mat ND header 
 Allocates and initializes Cv Mat ND header and allocates data 
 Initializes preallocated Cv Mat ND header 
 Releases Cv Mat ND 
 Creates a copy of Cv Mat ND except may be steps 
 Allocates and initializes Cv Sparse Mat header and allocates data 
 Releases Cv Sparse Mat 
 Creates a copy of Cv Sparse Mat except may be zero items 
 Initializes sparse array iterator returns the first node or NULL if the array is empty 
returns next sparse array node or NULL if there is no more nodes 
 matrix iterator used for n ary operations on dense arrays P Returns width and height of array in elements 
 Copies source array to destination array 
CVAPI void cv Set Zero Cv Arr arr define cv Zero cv Set Zero Arithmetic logic and comparison operations Logic operations Inverts every bit of an array 
Calculates the per element bit wise conjunction of two arrays 
Calculates the per element bit wise conjunction of two arrays with a mask 
Calculates the per element bit wise conjunction of an array and a scalar 
Calculates the per element bit wise conjunction of an array and a scalar with a mask 
Calculates the per element bit wise disjunction of two arrays 
Calculates the per element bit wise disjunction of two arrays with a mask 
Calculates the per element bit wise disjunction of an array and a scalar 
Calculates the per element bit wise disjunction of an array and a scalar with a mask 
Calculates the per element bit wise exclusive or operation on two arrays 
Calculates the per element bit wise exclusive or operation on two arrays with a mask 
Calculates the per element bit wise exclusive or operation on an array and a scalar 
Calculates the per element bit wise exclusive or operation on an array and a scalar with a mask 
 Math operations Calculates the per element sum of two arrays dst src src 
Calculates the per element sum of two arrays with a mask dst src src 
Calculates the per element sum of an array and a scalar dst src value 
Calculates the per element sum of an array and a scalar with a mask dst src value 
Calculates the per element difference between two arrays dst src src 
Calculates the per element difference between two arrays with a mask dst src src 
Calculates the per element difference between an array and a scalar dst src value 
Calculates the per element difference between an array and a scalar with a mask dst src value 
Calculates the per element difference between a scalar and an array dst value src 
Calculates the per element difference between a scalar and an array with a mask dst value src 
Calculates the per element absolute difference between two arrays 
Calculates the per element absolute difference between an array and a scalar 
 Matrix operations Array Statistics Cv Scalar cv Avg const Cv Arr arr const Cv Arr mask NULL 
cv Equalize Hist const Cv Arr src Cv Arr dst 
Mean Std Dev With Mask calculates mean and standard deviation of pixel values with mask 
Creates a new sequence 
Adds an element to the sequence end Returns a pointer to the element added 
Removes element from the sequence end Copies the element into the paramter element 
Adds an element to the sequence beginning Returns a pointer to the element added 
Removes element from the sequence beginning Copies the element into the paramter element 
Gets a pointer to the element at the index 
Removes an element from the middle of a sequence 
 Drawing Draws connected connected or antialiased line segment connecting two points color Scalar 
void cv Init Font Cv Font font int font face double hscale double vscale double shear int thickness int line type 
void cv Put Text Cv Arr img const char text Cv Point org const Cv Font font Cv Scalar color 
 Smoothes array removes noise 
CVAPI void cv Smooth const Cv Arr src Cv Arr dst int smoothtype CV DEFAULT CV GAUSSIAN int param CV DEFAULT int param CV DEFAULT double param CV DEFAULT double param CV DEFAULT Laplace The function calculates the Laplacian 
CVAPI void cv Laplace const Cv Arr src Cv Arr dst int aperture size CV DEFAULT Convert Scale converts one image to another with optional linear transformation 
CVAPI void cv Convert Scale const Cv Arr src Cv Arr dst double scale CV DEFAULT double shift CV DEFAULT Converts input array pixels from one color space to another 
CVAPI void cv Cvt Color const Cv Arr src Cv Arr dst int code Runs canny edge detector 
CVAPI void cv Canny const Cv Arr image Cv Arr edges double threshold double threshold int aperture size CV DEFAULT Calculates the first second third or mixed image derivatives using an extended Sobel operator 
 Inpaints the selected region in the image 
 Applies a fixed level threshold to each array element 
 Applies an adaptive threshold to an array 
 Returns a structuring element of the specified size and shape for morphological operations 
CVAPI Ipl Conv Kernel cv Create Structuring Element Ex int cols int rows int anchor x int anchor y int shape int values NULL Releases the structuring element 
CVAPI void cv Release Structuring Element Ipl Conv Kernel element Dilates an image by using a specific structuring element 
CVAPI void cv Dilate const Cv Arr src Cv Arr dst Ipl Conv Kernel element NULL int iterations Erodes an image by using a specific structuring element 
 Performs advanced morphological transformations 
Delay set delay between retry default is ms 
Back Off Delay is a Delay Type which increases delay between consecutive retries 
Error method return string representation of Error It is an implementation of error interface 
Arguments adds the arguments to the args 
Body String sets the request body to the given string 
Body Bytes sets the request body to the given buffer 
Body sets the request body to the given reader 
Option sets the given option 
Header sets the given header 
Send sends the request and return the response 
Exec sends the request a request and decodes the response 
Next waits for the next record and returns that 
Cancel cancels the given subscription 
File List entries at the given path using the Unix FS commands 
ID gets information about a given peer Arguments peer peer ID of the node to look up If no peer is specified return information about the local peer 
Cat the content at the given path Callers need to drain and close the returned reader after usage 
List entries at the given path 
Pin the given path 
Pins returns a map of the pin hashes to their info currently just the pin type one of Direct Pin Recursive Pin or Indirect Pin A map is returned instead of a slice because it is easier to do existence lookup by map key than unordered array searching The map is likely to be more useful to a client than a flat list 
returns ipfs version and commit sha 
Object Stat gets stats for the DAG object named by key It returns the stats of the requested Object or an error 
Object Stat gets stats for the DAG object named by key It returns the stats of the requested Object or an error 
Swarm Peers gets all the swarm peers 
Swarm Connect opens a swarm connection to a specific address 
Dag Put Options applies the given options to a Dag Put Settings instance 
Pin is an option for Dag Put which specifies whether to pin the added dags Default is false 
Input Enc is an option for Dag Put which specifies the input encoding of the data Default is json most formats codecs support raw 
Kind is an option for Dag Put which specifies the format that the dag will be added as Default is cbor 
Hash is an option for Dag Put which specifies the hash function to use 
Add No Pin adds a file to ipfs without pinning it Deprecated Use Add with option functions instead 
Add With Opts adds a file to ipfs with some additional options Deprecated Use Add with option functions instead 
Add Dir adds a directory recursively with all of the files under it 
Publish updates a mutable name to point to a given value 
Publish With Details is used for fine grained control over record publishing 
Resolve gets resolves the string provided to an ipns name If asked to resolve an empty string resolve instead resolves the node s own ipns value 
Resolve Value resolves a Plan Value as a single value based on the supplied bindvars 
Resolve Rows resolves a Plan Value as rows based on the supplied bindvars 
Generate Query generates a query by substituting the specified bind Variables The extras parameter specifies special parameters that can perform custom encoding 
Encode Value encodes one bind variable value into the query 
Lex returns the next token form the Tokenizer This function is used by go yacc 
skip Statement scans until the EOF or end of statement is encountered 
reset clears any internal state 
Preview analyzes the beginning of the query using a simpler and faster textual comparison to identify the statement type 
New Plan Value builds a sqltypes Plan Value from an Expr 
String In is a convenience function that returns true if str matches any of the values 
New Tracked Buffer creates a new Tracked Buffer 
New String Arena creates an arena of the specified size 
New String copies a byte slice into the arena and returns it as a string If the arena is full it returns a traditional go string 
Space Left returns the amount of space left in the arena 
String force casts a byte to a string USE AT YOUR OWN RISK 
Instructions for creating new types If a type needs to satisfy an interface declare that function along with that interface This will help users identify the list of types to which they can assert those interfaces If the member of a type has a string with a predefined list of values declare those values as const following the type For interfaces that define dummy functions to consolidate a set of types define the function as i Type Name This will help avoid name collisions Parse parses the SQL in full and returns a Statement which is the AST representation of the query If a DDL statement is partially parsed but still contains a syntax error the error is ignored and the DDL is returned anyway 
Parse Strict DDL is the same as Parse except it errors on partially parsed DDL statements 
Parse Next parses a single SQL statement from the tokenizer returning a Statement which is the AST representation of the query The tokenizer will always read up to the end of the statement allowing for the next call to Parse Next to parse any subsequent SQL statements When there are no more statements to parse a error of io EOF is returned 
Append appends the SQLNode to the buffer 
Format formats the node 
Format formats the node 
Format formats the node 
Format formats the node 
Expr From Value converts the given Value into an Expr or returns an error 
Format formats the node 
Format formats the node 
Backtick produces a backticked literal given an input string 
New Value builds a Value using typ and val If the value and typ don t match it returns an error 
String returns a printable version of the value 
Encode SQL encodes the value into an SQL statement Can be binary 
Encode SQL performs the SQL encoding for Insert Values 
Encode SQL generates the where clause constraints for the tuple equality 
Walk Statement is the top level walk function If it encounters a Select it switches to a mode where variables are deduped 
Walk Select normalizes the AST in Select mode 
Get Bindvars returns a map of the bind vars referenced in the statement TODO sougou This function gets called again from vtgate planbuilder Ideally this should be done only once 
Bind Variables Equal compares two maps of bind variables 
New constructs a new Secure instance with supplied options 
Special implementation for Negroni but could be used elsewhere 
From Auth Header is a Token Extractor that takes a give request and extracts the JWT token from the Authorization header 
From Parameter returns a function that extracts the token from the specified query string parameter 
From First returns a function that runs multiple token extractors and takes the first token it finds 
get the initial RPC containing all of our subscriptions to send to new peers 
New Floodsub With Protocols returns a new floodsub enabled Pub Sub objecting using the protocols specified in ps 
New Flood Sub returns a new Pub Sub object using the Flood Sub Router 
New LRUBlacklist creates a new LRUBlacklist with capacity cap 
New Random Sub returns a new Pub Sub object using Random Sub Router as the router 
New Gossip Sub returns a new Pub Sub object using Gossip Sub Router as the router 
New Pub Sub returns a new Pub Sub management object 
With Validate Throttle sets the upper bound on the number of active validation goroutines 
With Message Signing enables or disables message signing enabled by default 
With Message Author sets the author for outbound messages to the given peer ID defaults to the host s ID If message signing is enabled the private key must be available in the host s peerstore 
With Strict Signature Verification is an option to enable or disable strict message signing When enabled which is the default unsigned messages will be discarded 
With Blacklist provides an implementation of the blacklist the default is a Map Blacklist 
process Loop handles all inputs arriving on the channels 
handle Remove Subscription removes Subscription sub from bookeeping If this was the last Subscription for a given topic it will also announce that this node is not subscribing to this topic anymore Only called from process Loop 
handle Add Subscription adds a Subscription for a particular topic If it is the first Subscription for the topic it will announce that this node subscribes to the topic Only called from process Loop 
announce announces whether or not this node is interested in a given topic Only called from process Loop 
notify Subs sends a given message to all corresponding subscribers Only called from process Loop 
seen Message returns whether we already saw this message before 
subscribed To Message returns whether we are subscribed to one of the topics of a given message 
msg ID returns a unique ID of the passed Message 
push Msg pushes a message performing validation as necessary 
validate performs validation and only sends the message if all validators succeed 
fast path for single topic validation that avoids the extra goroutine 
get Validators returns all validators that apply to a given message 
Subscribe returns a new Subscription for the given topic Note that subscription is not an instanteneous operation It may take some time before the subscription is processed by the pubsub main loop and propagated to our peers 
Subscribe By Topic Descriptor lets you subscribe a topic using a pb Topic Descriptor 
Get Topics returns the topics this node is subscribed to 
Publish publishes data to the given topic 
List Peers returns a list of peers we are connected to in the given topic 
With Validator Timeout is an option that sets the topic validator timeout 
With Validator Concurrency is an option that sets topic validator throttle 
Register Topic Validator registers a validator for topic 
Unregister Topic Validator removes a validator from a topic Returns an error if there was no validator registered with the topic 
Default Metric Prefix is the default mapping for metrics to statsd keys It uses a tchannel prefix for all stats 
Metric With Prefix is the default mapping for metrics to statsd keys 
write Clean writes v after replacing special characters s with 
New Client returns a json Client used to make outbound JSON calls 
Call makes a JSON call with retries 
TODO prashantv Clean up json Call interfaces 
Call Peer makes a JSON call using the given peer 
Call SC makes a JSON call using the given subchannel 
Read Response reads a http Response from the given readers 
write Headers writes out the HTTP headers as arg and creates the arg writer 
Response Writer returns a http Response Writer that will write to an underlying writer It also returns a function that should be called once the handler has completed 
Write Headers writes the given key value pairs using the following encoding len k v len 
Read Headers reads key value pairs encoded using Write Headers 
New TCPRaw Relay creates a relay that just pipes data from one connection to another directly 
Unmarshal Text implements encoding text Unmarshaler This allows Fail Strategy to be specified as a string in many file formats e g JSON YAML TOML 
New Client creates a new Hyperbahn client using the given channel config is the environment specific configuration for Hyperbahn such as the list of initial nodes opts are optional and are used to customize the client 
parse Config parses the configuration options e g Initial Nodes File 
add Peer adds a peer to the Hyperbahn subchannel TODO prashant Start connections to the peers in the background 
Advertise advertises the service with Hyperbahn and returns any errors on initial advertisement Advertise can register multiple services hosted on the same endpoint If the advertisement succeeds a goroutine is started to re advertise periodically 
verify Handler ensures that the given t is a function with the following signature func json Context Arg Type Res Type error 
Register registers the specified methods specified as a map from method name to the JSON handler function The handler functions should have the following signature func context Context Arg Type Res Type error 
Handle deserializes the JSON arguments and calls the underlying handler 
Start starts the test server called by the Client and other upstream servers 
Port returns the actual port the server listens to 
Set Strategy sets customized peer selection strategy 
Add adds a peer to the list if it does not exist or returns any existing peer 
Get New returns a new previously unselected peer from the peer list or nil if no new unselected peer can be found 
Get returns a peer from the peer list or nil if none can be found will avoid previously selected peers if possible 
Remove removes a peer from the peer list It returns an error if the peer cannot be found Remove does not affect connections to the peer in any way 
Get Or Add returns a peer for the given host Port creating one if it doesn t yet exist 
Copy returns a copy of the Peer List as a map from host Port to peer 
Len returns the length of the Peer List 
exists checks if a hostport exists in the peer list 
get Peer Score is called to find the peer and its score from a host port key Note that at least a Read lock must be held to call this function 
on Peer Change is called when there is a change that may cause the peer s score to change The new score is calculated and the peer heap is updated with the new score if the score changes 
update Peer is called to update the score of the peer given the existing score Note that a Write lock must be held to call this function 
get Conn treats inbound and outbound connections as a single virtual list that can be indexed The peer must be read locked 
get Active Conn will randomly select an active connection TODO prashant Should we clear inactive connections TODO prashant Do we want some sort of scoring for connections 
Get Connection returns an active connection to this peer If no active connections are found it will create a new outbound connection and return it 
get Connection Relay gets a connection and uses the given timeout to lazily create a context if a new connection is required 
can Remove returns whether this peer can be safely removed from the root peer list 
add Connection adds an active connection to the peer s connection list If a connection is not active returns Err Invalid Connection State 
remove Connection will check remove the connection if it exists on conns Ptr and returns whether it removed the connection 
connection State Changed is called when one of the peers connections states changes All non active connections are removed from the peer The connection will still be tracked by the channel until it s completely closed 
Connect adds a new outbound connection to the peer 
Begin Call starts a new call to this specific peer returning an Outbound Call that can be used to write the arguments of the call 
Num Connections returns the number of inbound and outbound connections for this peer 
Num Pending Outbound returns the number of pending outbound calls 
is Ephemeral Host Port returns if host Port is the default ephemeral host Port 
Get returns the value stored for the given key 
Set sets the value for a given key 
Clear All clears all the keys 
Tracer returns the Open Tracing Tracer for this channel If no tracer was provided in the configuration returns opentracing Global Tracer Note that this approach allows opentracing Global Tracer to be initialized after the channel is created 
New Channel creates a new Channel The new channel can be used to send outbound requests to peers but will not listen or handling incoming requests until one of Listen And Serve or Serve is called The local service name should be passed to service Name 
Serve serves incoming requests using the provided listener The local peer info is set synchronously but the actual socket listening is done in a separate goroutine 
Listen And Serve listens on the given address and serves incoming requests The port may be in which case the channel will use an OS assigned port This method does not block as the handling of connections is done in a goroutine 
Register registers a handler for a method The handler is registered with the service name used when the Channel was created To register a handler with a different service name obtain a Sub Channel for that service with Get Sub Channel and Register a handler under that You may also use Set Handler on a Sub Channel to set up a catch all Handler for that service See the docs for Set Handler for more information Register panics if the channel was constructed with an alternate root handler 
Peer Info returns the current peer info for the channel 
Get Sub Channel returns a Sub Channel for the given service name If the subchannel does not exist it is created 
Begin Call starts a new call to a remote peer returning an Outbound Call that can be used to write the arguments of the call 
serve runs the listener to accept and manage new incoming connections blocking until the channel is closed 
Ping sends a ping message to the given host Port and waits for a response 
Stats Tags returns the common tags that should be used when reporting stats It returns a new map for each call 
Connect creates a new outbound connection to host Port 
exchange Updated updates the peer heap 
update Peer updates the score of the peer and update it s position in heap as well 
add Connection adds the connection to the channel s list of connection if the channel is in a valid state to accept this connection It returns whether the connection was added 
remove Closed Conn removes a connection if it s closed Until a connection is fully closed the channel must keep track of it 
connection Close State Change is called when a connection s close state changes 
State returns the current channel state 
Close starts a graceful Close for the channel This does not happen immediately This call closes the Listener and starts closing connections When all incoming connections are drained the connection blocks new outgoing calls When all connections are drained the channel s state is updated to Closed 
New Reader returns a reader that reads typed values from the reader 
Read Uint reads a uint 
Read String reads a string of length n 
Read Len String reads a uint length prefixed string 
Register function adds JSON and Thrift handlers to the server channel ch 
Run executes the trace behavior 
Get returns a relay timer that has not started Timers must be started explicitly using the Start function 
Put returns a relay Timer back to the pool 
Start starts a timer with the given duration for the specified ID 
Stop stops the timer and returns whether the timer was stopped It returns the same behaviour as https golang org pkg time Timer Stop This method is safe for concurrent use and is typically used to check whether a timer was stopped possibly with other goroutines or when the timer fires 
Release releases a timer back to the timer pool The timer MUST have run or be stopped before Release is called 
New Logger returns a Logger that writes to the given writer 
New TCPFrame Relay relays frames from one connection to another It reads and writes frames using the TChannel frame functions 
New Tally Reporter takes a tally Scope and wraps it so it ca be used as a Stats Reporter The list of metrics emitted is documented on https tchannel readthedocs io en latest metrics The metrics emitted are similar to YARPC the tags emitted are source dest procedure and retry count 
Create a sub scope for this set of known tags 
Isolated is a Sub Channel Option that creates an isolated subchannel 
Begin Call starts a new call to a remote peer returning an Outbound Call that can be used to write the arguments of the call 
Isolated returns whether this subchannel is an isolated subchannel 
Register registers a handler on the subchannel for the given method This function panics if the Handler for the Sub Channel was overwritten with Set Handler 
Get Handlers returns all handlers registered on this subchannel by method name This function panics if the Handler for the Sub Channel was overwritten with Set Handler 
Stats Tags returns the stats tags for this subchannel 
Register a new subchannel for the given service Name 
Get subchannel if we have one 
Get Or Add a subchannel for the given service Name on the map 
Discover queries Hyperbahn for a list of peers that are currently advertised with the specified service name 
Start begins a Crossdock client in the background 
Listen initializes the server 
Write Request writes a http Request to the given writers 
Read Request reads a http Request from the given readers 
New Read Buffer With Size returns a Read Buffer with a given capacity 
Read Byte returns the next byte from the buffer 
Read Bytes returns the next n bytes from the buffer 
Read String returns a string of size n from the buffer 
Read Uint returns the next value in the buffer as a uint 
Read Uint returns the next value in the buffer as a uint 
Read Uint returns the next value in the buffer as a uint 
Read Uvarint reads an unsigned varint from the buffer 
Read Len String reads an bit length preceded string value 
Read Len String reads a bit length preceded string value 
Fill From fills the buffer from a reader 
Wrap initializes the buffer to read from the given byte slice 
Write Single Byte writes a single byte to the buffer 
Write Bytes writes a slice of bytes to the buffer 
Write Uint writes a big endian encoded uint value to the buffer 
Write Uint writes a big endian uint value to the buffer 
Write Uint writes a big endian uint to the buffer 
Write Uvarint writes an unsigned varint to the buffer 
Write String writes a string to the buffer 
Write Len String writes an bit length preceded string 
Write Len String writes a bit length preceded string 
Defer Byte reserves space in the buffer for a single byte and returns a reference that can be used to update that byte later 
Defer Bytes reserves space in the buffer for a fixed sequence of bytes and returns a reference that can be used to update those bytes 
Flush To flushes the written buffer to the given writer 
Reset resets the buffer to an empty state ready for writing 
Wrap initializes the buffer to wrap the given byte slice 
Update updates the uint in the buffer 
Update updates the uint in the buffer 
Update updates the uint in the buffer 
Update updates the bytes in the buffer 
Update String updates the bytes in the buffer from a string 
The Arg Reader will handle fragmentation as needed Once the argument has been read the Arg Reader must be closed 
finish finishes the fragment updating the final checksum and fragment flags 
new Writable Chunk creates a new writable chunk around a checksum and a buffer to hold data 
write As Fits writes as many bytes from the given slice as fits into the chunk 
new Fragmenting Writer creates a new fragmenting writer 
Arg Writer returns an Arg Writer to write an argument The Arg Writer will handle fragmentation as needed Once the argument is written the Arg Writer must be closed 
Begin Argument tells the writer that the caller is starting a new argument Must not be called while an existing argument is in place 
Write writes argument data breaking it into fragments as needed 
Flush flushes the current fragment and starts a new fragment and chunk 
Close ends the current argument 
begin Call begins an outbound call on the connection 
handle Call Res handles an incoming call req message forwarding the frame to the response channel waiting for it 
create Stats Tags creates the common stats tags if they are not already created 
write Method writes the method arg to the call 
Arg Reader returns an Arg Reader to read the second argument The Read Closer must be closed once the argument has been read 
handle Error handles an error coming back from the peer If the error is a protocol level error the entire connection will be closed If the error is a request specific error it will be written to the request s response channel and converted into a System Error returned from the next reader or access call The return value is whether the frame should be released immediately 
done Reading shuts down the message exchange for this call For outgoing calls the last message is reading the call response 
go generate stringer type req Res Reader State 
new Fragment creates a new fragment for marshaling into 
flush Fragment sends a fragment to the peer over the connection 
failed marks the writer as having failed 
arg Reader returns an Arg Reader to read arg 
arg Reader returns an Arg Reader to read arg 
arg Reader returns an Arg Reader to read arg 
arg Reader returns an Arg Reader that can be used to read an argument The Read Closer must be closed once the argument has been read 
recv Next Fragment receives the next fragment from the underlying message exchange 
release Previous Frament releases the last fragment returned by the reader if it s still around This operation is idempotent 
failed indicates the reader failed 
parse Inbound Fragment parses an incoming fragment based on the given message 
New Context returns a Context that can be used to make Thrift calls 
With Headers returns a Context that can be used to make a call with request headers 
health Check will do periodic pings on the connection to check the state of the connection We accept conn ID on the stack so can more easily debug panics or leaked goroutines 
Set Timeout sets the timeout for the Context 
Add Header adds a single application header to the Context 
Set Headers sets the application headers for this Context If there is a Parent Context its headers will be ignored after the call to this method 
Set Shard Key sets the Shard Key call option sk transport header 
Set Format sets the Format call option as transport header 
Set Routing Key sets the Routing Key call options rk transport header 
Set Routing Delegate sets the Routing Delegate call options rd transport header 
Set Connect Timeout sets the Connection Timeout for this context The context timeout applies to the whole call while the connect timeout only applies to creating a new connection 
Set Retry Options sets Retry Options in the context 
Set Timeout Per Attempt sets Timeout Per Attempt in Retry Options 
Set Parent Context sets the parent for the Context 
Build returns a Context With Headers that can be used to make calls 
override Headers sets headers if the call options contains non default values 
Read reads from the reader into the byte slice 
Read JSON deserializes JSON from the underlying reader into data 
New Arg Writer wraps the result of calling Arg XWriter to provider a simpler interface for writing arguments 
Write writes the given bytes to the underlying writer 
Write JSON writes the given object as JSON 
Register registers pprof endpoints on the given registrar under pprof The pprof endpoint uses as http and is a tunnel to the default serve mux 
Count returns the number of non tombstone items in the relay 
Get checks for a relay item by ID returning the item and a bool indicating whether the item was found 
Add adds a relay item 
Delete removes a relay Item completely without leaving a tombstone It returns the deleted item along with a bool indicating whether we completed a relayed call 
Entomb sets the tomb bit on a relay Item and schedules a garbage collection It returns the entombed item along with a bool indicating whether we completed a relayed call 
New Relayer constructs a Relayer 
Relay is called for each frame that is read on the connection 
Receive receives frames intended for this connection It returns whether the frame was sent and a reason for failure if it failed 
Handle all frames except message Type Call Req 
add Relay Item adds a relay item to either outbound or inbound 
fail Relay Item tombs the relay item so that future frames for this call are not forwarded We keep the relay item tombed rather than delete it to ensure that future frames do not cause error logs 
Write Struct writes the given Thrift struct to a writer It pools TProtocols 
Read Struct reads the given Thrift struct It pools TProtocols 
Ensure Empty ensures that the specified reader is empty If the reader is not empty it returns an error with the specified stage in the message 
New Server returns a new Server that can recieve Thrift calls or raw calls 
Advertise advertises with Hyperbahn 
handle Call Req handles an incoming call request registering a message exchange to receive further fragments for that call and dispatching it in another goroutine 
handle Call Req Continue handles the continuation of a call request forwarding it to the request channel for that request where it can be pulled during defragmentation 
create Stats Tags creates the common stats tags if they are not already created 
dispatch Inbound ispatches an inbound call to the appropriate handler 
Call Options returns a Call Options struct suitable for forwarding a request 
Reads the entire method name arg from the request stream 
Response provides access to the Inbound Call Response object which can be used to write back to the calling peer 
Send System Error returns a system error response to the peer The call is considered complete after this method is called and no further data can be written 
Set Application Error marks the response as being an application error This method can only be called before any arguments have been sent to the calling peer 
Arg Writer returns a Write Closer that can be used to write the second argument The returned writer must be closed once the write is complete 
done Sending shuts down the message exchange for this call For incoming calls the last message is sending the call response 
new State parses the type information for a parsed Thrift file and returns the state 
root Type recurses through typedefs and returns the underlying type 
check Include will check if the type is an included type and if so return the state and type from the state for that file 
is Result Pointer returns whether the result for this method is a pointer 
go Type returns the Go type name for the given thrift type 
go Type Prefix returns the Go type name for the given thrift type with the prefix 
New Context returns a new root context used to make TChannel requests 
new Incoming Context creates a new context for an incoming call with the given span 
Current Call returns the current incoming call or nil if this is not an incoming call context 
Parameters Key 
Parameters Key Value 
New returns a rand Rand that is threadsafe 
Health returns true as default Health endpoint 
Parameters Hr 
Headers gets application headers out of the context 
Response Headers returns the response headers 
Set Response Headers sets the response headers 
Child creates a child context with a separate container for headers 
Wrap wraps an existing context Context into a Context With Headers If the underlying context has headers they are preserved 
Wrap With Headers returns a Context that can be used to make a call with request headers If the parent ctx is already an instance of Context With Headers its existing headers will be ignored In order to merge new headers with parent headers use Context Builder 
Without Headers hides any TChannel headers from the given context 
Notify will store the error and notify all waiters on c that there s an error 
check Error is called before waiting on the mex channels It returns any existing errors timeout cancellation connection errors 
forward Peer Frame forwards a frame from a peer to the message exchange where it can be pulled by whatever application thread is handling the exchange 
recv Peer Frame waits for a new frame from the peer or until the context expires or is cancelled 
recv Peer Frame Of Type waits for a new frame of a given type from the peer failing if the next frame received is not of that type If an error frame is returned then the error Message is returned as the error 
shutdown shuts down the message exchange removing it from the message exchange set so that it cannot receive more messages from the peer The receive channel remains open however in case there are concurrent goroutines sending to it 
new Message Exchange Set creates a new message Exchange Set with a given name 
add Exchange adds an exchange it must be called with the mexset locked 
new Exchange creates and adds a new message exchange to this set 
delete Exchange will delete msg ID and return whether it was found or whether it was timed out This method must be called with the lock 
remove Exchange removes a message exchange from the set if it exists 
expire Exchange is similar to remove Exchange but it marks the exchange as expired 
forward Peer Frame forwards a frame from the peer to the appropriate message exchange 
copy Exchanges returns a copy of the exchanges if the exchange is active The caller must lock the mexset 
stop Exchanges stops all message exchanges to unblock all waiters on the mex This should only be called on connection failures 
Marshal JSON returns a id NNN msg Type MMM size SSS representation 
New Frame allocates a new frame with the given payload capacity 
Read Body takes in a previously read frame header and only reads in the body based on the size specified in the header This allows callers to defer the frame allocation till the body needs to be read 
Read In reads the frame from the given io Reader Deprecated Only maintained for backwards compatibility Callers should use Read Body instead 
Write Out writes the frame to the given io Writer 
Can Retry returns whether an error can be retried for the given retry option 
Has Retries will return true if there are more retries left 
Since Start returns the time since the start of the request If there is no request state then the fallback is returned 
Add Selected Peer adds a given peer to the set of selected peers 
Run With Retry will take a function that makes the TChannel call and will rerun it as specifed in the Retry Options in the Context 
get Host returns the host part of a host port If no is found it returns the original string Note This hand rolled loop is faster than using strings Index Byte 
Checksum Size returns the size in bytes of the checksum calculation 
New creates a new Checksum of the given type 
parse Templates returns a list of Templates that must be rendered given the template files 
New String Slice Flag creates a new string slice flag The default value is always nil 
with State Funcs adds functions to the template that are dependent upon state 
Introspect State returns the Runtime State for this channel Note this is purely for debugging and monitoring and may slow down your Channel 
Introspect Others returns the Channel Info for all other channels in this process 
Report Info returns Channel Info for a channel 
Introspect State returns the runtime state of the 
Introspect State returns the runtime state of the subchannels 
Introspect State returns the runtime state for this peer 
Introspect State returns the runtime state for this connection 
Introspect State returns the runtime state for this relayer 
Introspect State returns the runtime state for this relay Items 
Introspect State returns the runtime state for this messsage exchange set 
Introspect List returns the list of peers hostport score in this peer list 
Introspect Num Connections returns the number of connections returns the number of connections Note like other introspection APIs this is not a stable API 
register Internal registers the following internal handlers which return runtime state gometa introspect TChannel internal state gometa runtime Golang runtime stats 
New Context returns a Context that can be used to make JSON calls 
Read Args reads the Args from the given call 
Write Response writes the given Res to the Inbound Call Response 
Wrap wraps a Handler as a tchannel Handler that can be passed to tchannel Register 
init From Open Tracing initializes injectable Span fields from an Open Tracing Span assuming the tracing implementation supports Zipkin style span IDs 
Current Span extracts Open Tracing Span from the Context and if found tries to extract zipkin style trace span IDs from it using Zipkin Span Format carrier If there is no Open Tracing Span in the Context an empty span is returned 
start Outbound Span creates a new tracing span to represent the outbound RPC call If the context already contains a span it will be used as a parent otherwise a new root span is created If the tracer supports Zipkin style trace IDs then call call Req Tracing is initialized with those IDs Otherwise it is assigned random values 
Inject Outbound Span retrieves Open Tracing Span from response where it is stored when the outbound call is initiated The tracing API is used to serialize the span into the application headers which will propagate tracing context to the server Returns modified headers containing serialized tracing context Sometimes caller pass a shared instance of the headers map so instead of modifying it we clone it into the new map assuming that Tracer actually injects some tracing keys 
extract Inbound Span attempts to create a new Open Tracing Span for inbound request using only trace IDs stored in the frame s tracing field It only works if the tracer understand Zipkin style trace IDs If such attempt fails another attempt will be made from the higher level function Extract Inbound Span once the application headers are read from the wire 
Extract Inbound Span is a higher level version of extract Inbound Span If the lower level attempt to create a span from incoming request was successful e g when then Tracer supports Zipkin style trace IDs then the application headers are only used to read the Baggage and add it to the existing span Otherwise the standard Open Tracing API supported by all tracers is used to deserialize the tracing context from the application headers and start a new server side span Once the span is started it is wrapped in a new Context which is returned 
Tracer From Registrar returns an Open Tracing Tracer embedded in the Registrar assuming that Registrar has a Tracer method Otherwise it returns default Global Tracer 
int To IP converts an integer IP representation into a byte net IP struct 
service Peer To Host Port converts a Hyperbahn Service Peer into a host Port string 
New Statsd Reporter returns a Stats Reporter that reports to statsd on the given addr 
Unmarshal Text implements Text Un Marshaler from encoding 
Push implements heap Push interface 
Pop implements heap Pop interface 
update Peer updates the score for the given peer 
remove Peer remove peer at specific index 
push Peer pushes the new peer into the heap 
Add Peer adds a peer to the peer heap 
New Client returns a Client that makes calls over the given tchannel to the given Hyperbahn service 
read Response reads the response struct into resp and returns response headers whether there was an application error unexpected error 
Add adds a peer to the root peer list if it does not exist or return an existing peer if it exists 
Get Or Add returns a peer for the given host Port creating one if it doesn t yet exist 
Get returns a peer for the given host Port if it exists 
This is based on the standard library s fnv a implementation We copy it for a couple of reasons Avoid allocations to create a hash Hash Avoid converting the byte to a string another allocation since the Hash interface only supports writing bytes 
With Timeout sets the timeout to use for each call 
Extends Service Prefix returns a package selector if any for the extended service 
Methods returns the methods on this service not including methods from inherited services 
Inherited Methods returns names for inherited methods on this service 
Arguments returns the argument declarations for this method 
Arg List returns the argument list for the function 
Call List creates the call to a function satisfying Interface from an Args struct 
Ret Type returns the go return type of the method 
Wrap Result wraps the result variable before being used in the result struct 
Return With takes the result name and the error name and generates the return expression 
Declaration returns the declaration for this field 
camel Case takes a name with underscores such as my arg and returns camel Case e g my Arg if public Name is true then it returns Upper Camel Case This method will also fix common initialisms e g ID API etc 
start Idle Sweep starts a poller that checks for idle connections at given intervals 
Start runs the goroutine responsible for checking idle connections 
Stop kills the poller checking for idle connections 
Resolve With Go Path will resolve the filename relative to GOPATH and returns the first file that exists or an error otherwise 
set Extends will set the Extends Service for all services It is done after all files are parsed as services may extend those found in an included file 
Handle calls f ctx call 
Registers a handler 
Finds the handler matching the given service and method See https github com golang go issues for the reason that method is byte instead of a string 
Set implements Set of opentracing Text Map Writer 
Foreach Key conforms to the Text Map Reader interface 
New Client returns a new Client that can make calls to a benchmark server 
score Addr scores how likely the given addr is to be a remote address and returns the IP to use when listening Any address which receives a negative score should not be used Scores are calculated as for any unknown IP addreseses for IPv addresses for non local addresses extra for up interaces 
Listen IP returns the IP to bind to in Listen It tries to find an IP that can be used by other machines to reach this machine 
Parameters Msg 
Wrap returns a new Listener around the provided net Listener The returned Listener has a guarantee that when Close returns it will no longer accept any new connections See https github com uber tchannel go issues 
Accept waits for and returns the next connection to the listener 
Close closes the listener Any blocked Accept operations will be unblocked and return errors 
Read Args V reads arg and arg from a reader 
Write Args writes the given arguments to the call and returns the response args 
Call makes a call to the given host Port with the given arguments and returns the response args 
Call SC makes a call using the given subcahnnel 
Call V makes a call and does not attempt any retries 
New Real Relay creates a TChannel relay 
New Server returns a server that can serve thrift services over TChannel 
Register registers the given TChan Server to be called on any incoming call for its services TODO prashant Replace Register call with this call 
Register Health Handler uses the user specified function f for the Health endpoint 
Set Context Fn sets the function used to convert a context Context to a thrift Context Note This API may change and is only intended to bridge different contexts 
Handle handles an incoming TChannel call and forwards it to the correct handler 
Metrics Key is a string representation of the error code that s suitable for inclusion in metrics tags 
New System Error defines a new System Error with a code and message 
New Wrapped System Error defines a new System Error wrapping an existing error 
Error returns the code and message conforming to the error interface 
Get Context Error converts the context error to a tchannel error 
Get System Error Code returns the code to report for the given error If the error is a System Error we can get the code directly Otherwise treat it as an unexpected error 
Get System Error Message returns the message to report for the given error If the error is a System Error we can get the underlying message Otherwise use the Error method 
go generate stringer type connection State 
ping sends a ping message and waits for a ping response 
handle Ping Res calls registered ping handlers 
handle Ping Req responds to the ping Req message with a ping Res 
send Message sends a standalone message typically a control message 
recv Message blocks waiting for a standalone response message typically a control message 
Send System Error sends an error frame for the given system error 
connection Error handles a connection level error 
with State Lock performs an action with the connection state mutex locked 
with State RLock performs an action with the connection state mutex rlocked 
read Frames is the loop that reads frames from the network connection and dispatches to the appropriate handler Run within its own goroutine to prevent overlapping reads on the socket Most handlers simply send the incoming frame to a channel the init handlers are a notable exception since we cannot process new frames until the initialization is complete 
write Frames is the main loop that pulls frames from the send channel and writes them to the connection 
update Last Activity marks when the last message was received sent on the channel This is used for monitoring idle connections and timing them out 
has Pending Calls returns whether there s any pending inbound or outbound calls on this connection 
check Exchanges is called whenever an exchange is removed and when Close is called 
close Network closes the network connection and all network related channels This should only be done in response to a fatal connection or protocol error or after all pending frames have been sent 
get Last Activity Time returns the timestamp of the last frame read or written excluding pings If no frames were transmitted yet it will return the time this connection was created 
Validate validates that the given spec is supported by thrift gen 
fuzz Interval returns a fuzzed version of the interval based on Full Jitter as described here http www awsarchitectureblog com backoff html 
log Failed Registration Retry logs either a warning or info depending on the number of consecutive Failures If consecutive Failures max Advertise Failures then we log a warning 
advertise Loop readvertises the service approximately every minute with some fuzzing 
initial Advertise will do the initial Advertise call to Hyperbahn with additional retries on top of the built in TChannel retries It will use exponential backoff between each of the call attempts 
Parameters Query 
TODO Consider pooling lazy Call Req and using pointers to the struct 
Service returns the name of the destination service for this call Req 
TTL returns the time to live for this call Req 
Set TTL overwrites the frame s TTL 
finishes Call checks whether this frame is the last one we should expect for this RPC req res 
Flat returns all the strings in the set sorted and de duplicated 
Map applies a function that processes individual strings to the strings in ps and returns a new Platform Strings with the result Empty strings returned by the function are dropped 
Map Slice applies a function that processes slices of strings to the strings in ps and returns a new Platform Strings with the results 
Expr From Value converts a value into an expression that can be written into a Bazel build file The following types of values can be converted bools integers floats strings slices arrays converted to lists maps converted to select expressions keys must be rules in 
Get Proto Config returns the proto language configuration If the proto extension was not run it will return nil 
infer Proto Mode sets Proto Config Mode based on the directory name and the contents of f If the proto mode is set explicitly this function does not change it If this is a vendor directory or go proto library is loaded from another file proto rule generation is disabled TODO jayconrod this logic is archaic now that rules are generated by separate language extensions Proto rule generation should be independent from Go 
Map Expr Strings applies a function to string sub expressions within e An expression containing the results with the same structure as e is returned 
Flatten Expr takes an expression that may have been generated from Platform Strings and returns its values in a flat sorted de duplicated list Comments are accumulated and de duplicated across duplicate expressions If the expression could not have been generted by Platform Strings the expression will be returned unmodified 
extract Platform Strings Exprs matches an expression and attempts to extract sub expressions in platform Strings Exprs The sub expressions can then be merged with corresponding sub expressions Any field in the returned structure may be nil An error is returned if the given expression does not follow the pattern described by platform Strings Exprs 
make Platform Strings Expr constructs a single expression from the sub expressions in ps 
String returns OS Arch or OS Arch if both are set This must match the names of config setting rules in 
Find searches from the given dir and up for the WORKSPACE file returning the directory containing it or an error if none found in the tree 
move Locations fixes labels within location and locations expansions 
run Gazelle invokes gazelle with bazel run In full Mode gazelle will run in the entire repository In fast Mode gazelle will only run in the given directories 
restore Build Files In Repo copies BUILD in and BUILD bazel in files and copies them to BUILD and BUILD bazel 
Fix Loads removes loads of unused go rules and adds loads of newly used rules This should be called after Fix File and Merge File since symbols may be introduced that aren t loaded This function calls File Sync before processing loads 
fix Load updates a load statement with the given symbols If load is nil a new load may be created and returned Symbols in kinds will be added to the load if they re not already present Known symbols not in kinds will be removed if present Other symbols will be preserved If load is empty nil is returned 
new Load Index returns the index in stmts where a new load statement should be inserted after is a list of function names that the load should not be inserted before 
Check Gazelle Loaded searches the given WORKSPACE file for a repository named bazel gazelle If no such repository is found and the repo is not declared with a directive and at least one load statement mentions the repository a descriptive error will be returned This should be called after modifications have been made to WORKSPACE i e after Fix Loads before writing it to disk 
remove Legacy Go Repository removes loads of go repository from 
Compare returns an integer comparing two versions lexicographically 
Parse Version parses a version of the form abcd Non negative integer components are separated by dots An arbitrary suffix may appear after which is ignored 
Empty File creates a File wrapped around an empty syntax tree 
Load File loads a build file from disk parses it and scans for rules and load statements The syntax tree within the returned File will be modified by editing methods This function returns I O and parse errors without modification It s safe to use os Is Not Exist and similar predicates 
Load Workspace File is similar to Load File but parses the file as a WORKSPACE file 
Load Macro File loads a bzl file from disk parses it then scans for the load statements and the rules called from the given Starlark function If there is no matching function name then a new function with that name will be created The function s syntax tree will be returned within File and can be modified by Sync and Save calls 
Empty Macro File creates a bzl file at the given path and within the file creates a Starlark function with the provided name The function can then be modified by Sync and Save calls 
Load Data parses a build file from a byte slice and scans it for rules and load statements The syntax tree within the returned File will be modified by editing methods 
Load Workspace Data is similar to Load Data but parses the data as a WORKSPACE file 
Load Macro Data parses a bzl file from a byte slice and scans for the load statements and the rules called from the given Starlark function If there is no matching function name then a new function will be created and added to the File the next time Sync is called The function s syntax tree will be returned within File and can be modified by Sync and Save calls 
Scan AST creates a File wrapped around the given syntax tree This tree will be modified by editing methods 
Scan ASTBody creates a File wrapped around the given syntax tree It will also scan the AST for a function matching the given def Name and if the function does not exist it will create a new one and mark it to be added to the File the next time Sync is called 
Match Build File Name looks for a file in files that has a name from names If there is at least one matching file a path will be returned by joining dir and the first matching name If there are no matching files the empty string is returned 
Sync Macro File syncs the file s syntax tree with another file s This is useful for keeping multiple macro definitions from the same bzl file in sync 
Macro Name returns the name of the macro function that this file is editing or an empty string if a macro function is not being edited 
Sync writes all changes back to the wrapped syntax tree This should be called after editing operations before reading the syntax tree again 
Format formats the build file in a form that can be written to disk This method calls Sync internally 
Save writes the build file to disk This method calls Sync internally 
Has Default Visibility returns whether the File contains a package rule with a default visibility attribute Rules generated by Gazelle should not have their own visibility attributes if this is the case 
New Load creates a new empty load statement for the given file name 
Symbols returns a list of symbols this statement loads 
Has returns true if sym is loaded by this statement 
Add inserts a new symbol into the load statement This has no effect if the symbol is already loaded Symbols will be sorted so the order doesn t matter 
Remove deletes a symbol from the load statement This has no effect if the symbol is not loaded 
Insert marks this statement for insertion at the given index If multiple statements are inserted at the same index they will be inserted in the order Insert is called 
New Rule creates a new empty rule with the given kind and name 
Set Kind changes the kind of rule this is 
Attr Keys returns a sorted list of attribute keys used in this rule 
Attr returns the value of the named attribute nil is returned when the attribute is not set 
Attr String returns the value of the named attribute if it is a scalar string is returned if the attribute is not set or is not a string 
Attr Strings returns the string values of an attribute if it is a list nil is returned if the attribute is not set or is not a list Non string values within the list won t be returned 
Del Attr removes the named attribute from the rule 
Set Attr adds or replaces the named attribute with an expression produced by Expr From Value 
Private Attr Keys returns a sorted list of private attribute names 
Set Private Attr associates a value with a key Unlike Set Attr this value is not converted to a build syntax tree and will not be written to a build file 
Insert marks this statement for insertion at the end of the file Multiple statements will be inserted in the order Insert is called 
Is Empty returns true when the rule contains none of the attributes in attrs for its kind attrs should contain attributes that make the rule buildable like srcs or deps and not descriptive attributes like name or visibility 
Should Keep returns whether e is marked with a keep comment Kept expressions should not be removed or modified 
Check Internal Visibility overrides the given visibility if the package is internal 
New constructs a new label from components 
Parse reads a label from a string See https docs bazel build versions master build ref html lexi 
Abs computes an absolute label one with a repository and package name from this label If this label is already absolute it is returned unchanged 
Rel attempts to compute a relative label from this label If this label is already relative or is in a different package this label may be returned unchanged 
Equal returns whether two labels are exactly the same It does not return true for different labels that refer to the same target 
Contains returns whether other is contained by the package of l or a sub package Neither label may be relative 
Import Path To Bazel Repo Name converts a Go import path into a bazel repo name following the guidelines in http bazel io docs be functions html workspace 
is Semver Prefix reports whether v is a semantic version prefix v or v not v The caller is assumed to have checked that semver Is Valid v is true 
Process go googleapis case 
Walk traverses the directory tree rooted at c Repo Root Walk visits subdirectories in depth first post order When Walk visits a directory it lists the files and subdirectories within that directory If a build file is present Walk reads the build file and applies any directives to the configuration a copy of the parent directory s configuration is made and the copy is modified After visiting subdirectories the callback wf may be called depending on the mode c is the root configuration to start with This includes changes made by command line flags but not by the root build file This configuration should not be modified cexts is a list of configuration extensions When visiting a directory before visiting subdirectories Walk makes a copy of the parent configuration and Configure for each extension on the copy If Walk sees a directive that is not listed in Known Directives of any extension an error will be logged dirs is a list of absolute canonical file system paths of directories to visit mode determines whether subdirectories of dirs should be visited recursively when the wf callback should be called and when the update argument to the wf callback should be set wf is a function that may be called in each directory 
build Update Rel Map builds a table of prefixes used to determine which directories to update and visit root and dirs must be absolute canonical file paths Each entry in dirs must be a subdirectory of root The caller is responsible for checking this build Update Rel Map returns a map from slash separated paths relative to the root directory for the root itself to a boolean indicating whether the directory should be updated 
should Call returns true if Walk should call the callback in the directory rel 
should Update returns true if Walk should pass true to the callback s update parameter in the directory rel This indicates the build file should be updated 
should Visit returns true if Walk should visit the subdirectory rel 
Decide if symlink dir base should be followed 
Merge Rules copies information from src into dst usually discarding information in dst when they have the same attributes If dst is marked with a keep comment either above the rule or as a suffix nothing will be changed If src has an attribute that is not in dst it will be copied into dst If src and dst have the same attribute and the attribute is mergeable and the attribute in dst is not marked with a keep comment values in the dst attribute not marked with a keep comment will be dropped and values from src will be copied in If dst has an attribute not in src and the attribute is mergeable and not marked with a keep comment values in the attribute not marked with a keep comment will be dropped If the attribute is empty afterward it will be deleted 
merge Exprs combines information from src and dst and returns a merged expression dst may be modified during this process The returned expression may be different from dst when a structural change is needed The following kinds of expressions are recognized nil strings can only be merged with strings lists of strings a call to select with a dict argument The dict keys must be strings and the values must be lists of strings a list of strings combined with a select call using The list must be the left operand An error is returned if the expressions can t be merged for example because they are not in one of the above formats 
Squash Rules copies information from src into dst without discarding information in dst Squash Rules detects duplicate elements in lists and dictionaries but it doesn t sort elements after squashing If squashing fails because the expression is not understood an error is returned and neither rule is modified 
Merge File combines information from newly generated rules with matching rules in an existing build file Merge File can also delete rules which are empty after merging old File is the file to merge It must not be nil empty Rules is a list of stub rules with no attributes other than name which were not generated These are merged with matching rules The merged rules are deleted if they contain no attributes that make them buildable e g srcs deps anything in rule Kind Info Non Empty Attrs gen Rules is a list of newly generated rules These are merged with matching rules A rule matches if it has the same kind and name or if some other attribute in rule Kind Info Match Attrs matches e g importpath in go library Elements of gen Rules that don t match any existing rule are appended to the end of old File phase indicates whether this is a pre or post resolve merge Different attributes rule Kind Info Mergeable Attrs or Resolve Attrs will be merged kinds maps rule kinds e g go library to metadata that helps merge rules of that kind When a generated and existing rule are merged each attribute is merged separately If an attribute is mergeable according to Kind Info values from the existing attribute are replaced by values from the generated attribute Comments are preserved on values that are present in both versions of the attribute If at attribute is not mergeable the generated version of the attribute will be added if no existing attribute is present otherwise the existing attribute will be preserved Note that keep comments affect merging If a value within an existing attribute is marked with a keep comment it will not be removed If an attribute is marked with a keep comment it will not be merged If a rule is marked with a keep comment the whole rule will not be modified 
substitute Rule replaces local labels those beginning with referring to targets in the same package according to a substitution map This is used to update generated rules before merging when the corresponding existing rules have different names If substitute Rule replaces a string it returns a new expression it will not modify the original expression 
Match searches for a rule that can be merged with x in rules A rule is considered a match if its kind is equal to x s kind AND either its name is equal OR at least one of the attributes in match Attrs is equal If there are no matches nil and nil are returned If a rule has the same name but a different kind nill and an error are returned If there is exactly one match the rule and nil are returned If there are multiple matches match will attempt to disambiguate based on the quality of the match name match is best then attribute match in the order that attributes are listed If disambiguation is successful the rule and nil are returned Otherwise nil and an error are returned 
run Client performs the main work of the client It attempts to connect to the server via a UNIX domain socket If the server is not running it starts the server and tries again The server does all the work so the client just waits for the server to complete then exits 
TODO jayconrod annotation directives will apply to an individual rule They must appear in the block of comments above that rule Parse Directives scans f for Gazelle directives The full list of directives is returned Errors are reported for unrecognized directives and directives out of place after the first statement 
Update Repo returns an object describing a repository at the most recent commit or version tag This function uses Remote Cache to retrieve information about the repository Depending on how the Remote Cache was initialized and used earlier some information may already be locally available Frequently though information will be fetched over the network so this function may be slow 
New Remote Cache creates a new Remote Cache with a set of known repositories The Root and Remote methods will return information about repositories listed here without accessing the network However the Head method will still access the network for these repositories to retrieve information about new versions A cleanup function is also returned The caller must call this when Remote Cache is no longer needed Remote Cache may write files to a temporary directory This will delete them 
Root returns the portion of an import path that corresponds to the root directory of the repository containing the given import path For example given golang org x tools go loader this will return golang org x tools The workspace name of the repository is also returned This may be a custom name set in WORKSPACE or it may be a generated name based on the root path 
Remote returns the VCS name and the remote URL for a repository with the given root import path This is suitable for creating new repository rules 
Head returns the most recent commit id on the default branch and latest version tag for the given remote repository The tag is returned if no latest version was found TODO jayconrod support VCS other than git TODO jayconrod support version tags is always returned 
Mod returns the module path for the module that contains the package named by import Path The name of the go repository rule for the module is also returned For example calling Mod on github com foo bar v baz would give the module path github com foo bar v and the name com github foo bar v If a known repository could provide import Path because its importpath is a prefix of import Path Mod will assume that it does This may give inaccurate results if import Path is in an undeclared nested module Run gazelle update repos from file go mod first for best results If no known repository could provide import Path Mod will run go list to find the module The special patterns that Root uses are ignored Results are cached Use GOPROXY for faster results 
get retrieves a value associated with the given key from the cache ok will be true if the key exists in the cache even if it s in the process of being fetched 
ensure retreives a value associated with the given key from the cache If the key does not exist in the cache the load function will be called and its result will be associated with the key The load function will not be called more than once for any key 
Has Prefix returns whether the slash separated path p has the given prefix Unlike strings Has Prefix this function respects component boundaries so home foo is not a prefix is home foobar baz If the prefix is empty this function always returns true 
Trim Prefix returns p without the provided prefix If p doesn t start with prefix it returns p unchanged Unlike strings Has Prefix this function respects component boundaries assuming slash separated paths so Trim Prefix foo bar foo returns baz 
Rel Base Name returns the base name for rel a slash separated path relative to the repository root If rel is empty Rel Base Name returns the base name of prefix If prefix is empty Rel Base Name returns the base name of root the absolute file path of the repository root directory If that s empty to then Rel Base Name returns root 
Clone creates a copy of the configuration for use in a subdirectory Note that the Exts map is copied but its contents are not Configurer Configure should do this if needed 
Is Valid Build File Name returns true if a file with the given base name should be treated as a build file 
check returns true if at least one of the tag groups is satisfied 
check returns true if all of the tags are true Tags that start with are negated but is not allowed Go release tags e g go are ignored If the group contains an os or arch tag but the os or arch parameters are empty check returns false even if the tag is negated 
file Name Info returns information that can be inferred from the name of a file It does not read data from the file 
other File Info returns information about a non go file It will parse part of the file to determine build tags If the file can t be read an error will be logged and partial information will be returned 
go File Info returns information about a go file It will parse part of the file to determine the package name imports and build constraints If the file can t be read an error will be logged and partial information will be returned This function is intended to match go build Context Import TODD extract canonical import path 
save Cgo extracts CFLAGS CPPFLAGS CXXFLAGS and LDFLAGS directives from a comment above a C import This is intended to match logic in go build Context save Cgo 
split Quoted splits the string s around each instance of one or more consecutive white space characters while taking into account quotes and escaping and returns an array of substrings of s or an empty list if s contains only white space Single quotes and double quotes are recognized to prevent splitting within the quoted region and are removed from the resulting substrings If a quote in s isn t closed err will be set and r will have the unclosed argument as the last element The backslash is used for escaping For example the following string a b c d e f g Would be parsed as string a b c d ef g Copied from go build split Quoted 
expand Src Dir expands any occurrence of SRCDIR making sure the result is safe for the shell Copied from go build expand Src Dir 
Copied from go build safe Cgo Name 
read Tags reads and extracts build tags from the block of comments and blank lines at the start of a file which is separated from the rest of the file by a blank line Each string in the returned slice is the trimmed text of a line after a build prefix Based on go build Context should Build 
check Constraints determines whether build constraints are satisfied on a given platform The first few arguments describe the platform generic Tags is the set of build tags that are true on all platforms os and arch are the platform GOOS and GOARCH strings If os or arch is empty check Constraints will return false in the presence of OS and architecture constraints even if they are negated The remaining arguments describe the file being tested All of these may be empty or nil os Suffix and arch Suffix are filename suffixes file Tags is a list tags from build comments found near the top of the file cgo Tags is an extra set of tags in a cgo directive 
is Ignored Tag returns whether the tag is cgo or is a release tag Release tags match the pattern go Gazelle won t consider whether an ignored tag is satisfied when evaluating build constraints for a file 
proto File Info extracts metadata from a proto file The proto extension already parses these and stores metadata in proto File Info so this is just processing relevant options 
Find Rule With Override searches the current configuration for user specified dependency resolution overrides Overrides specified later in configuration files in deeper directories or closer to the end of the file are returned first If no override is found label No Label is returned 
New Rule Index creates a new index kind To Resolver is a map from rule kinds for example go library to Resolvers that support those kinds 
Add Rule adds a rule r to the index The rule will only be indexed if there is a known resolver for the rule s kind and Resolver Imports returns a non nil slice Add Rule may only be called before Finish 
Finish constructs the import index and performs any other necessary indexing actions after all rules have been added This step is necessary because a rule may be indexed differently based on what rules are added later Finish must be called after all Add Rule calls and before any Find Rules By Import calls 
build Import Index constructs the map used by Find Rules By Import 
Find Rules By Import attempts to resolve an import string to a rule record imp is the import to resolve which includes the target language lang is the language of the rule with the dependency for example in go proto library imp will have Proto Lang and lang will be Go Lang from is the rule which is doing the dependency This is used to check vendoring visibility and to check for self imports Find Rules By Import returns a list of rules since any number of rules may provide the same import Callers may need to resolve ambiguities using language specific heuristics 
Is Self Import returns true if the result s label matches the given label or the result s rule transitively embeds the rule with the given label Self imports cause cyclic dependencies so the caller may want to omit the dependency or report an error 
apply Kind Mappings returns a copy of Load Info that includes c Kind Map 
append Or Merge Kind Mapping adds Load Info for the given replacement 
Rule Name returns a name for a proto library derived from the given strings For each string Rule Name will look for a non empty suffix of identifier characters and then append proto to that 
build Package extracts metadata from the proto files in a directory and constructs possibly several packages then selects a package to generate a proto library rule for 
select Package chooses a package to generate rules for 
go Package Name guesses the identifier in package declarations at the top of the pb go files that will be generated for this package is returned if the package name cannot be determined TODO jayconrod remove all Go specific functionality This is here temporarily for compatibility 
generate Proto creates a new proto library rule for a package The rule may be empty if there are no sources 
generate Empty generates a list of proto library rules that may be deleted This is generated from existing proto library rules with srcs lists that don t match any static or generated files 
Based on https developers google com protocol buffers docs reference proto spec 
Import Repo Rules reads the lock file of a vendoring tool and returns a list of equivalent repository rules that can be merged into a WORKSPACE file The format of the file is inferred from its basename 
Merge Rules merges a list of generated repo rules with the already defined repo rules and then updates each rule s underlying file If the generated rule matches an existing one then it inherits the file where the existing rule was defined If the rule is new then its file is set as the dest File parameter A list of the updated files is returned 
Generate Rule returns a repository rule for the given repository that can be written in a WORKSPACE file 
Find External Repo attempts to locate the directory where Bazel has fetched the external repository with the given name An error is returned if the repository directory cannot be located 
List Repositories extracts metadata about repositories declared in a file 
migrate Library Embed converts library attributes to embed attributes preserving comments This only applies to Go rules and only if there is no keep comment on library and no existing embed attribute 
migrate Grpc Compilers converts go grpc library rules into go proto library rules with a compilers attribute 
squash Cgo Library removes cgo library rules with the default name and merges their attributes with go library with the default name If no go library rule exists a new one will be created Note that the library attribute is disregarded so cgo library and go library attributes will be squashed even if the cgo library was unlinked Merge File will remove unused values and attributes later 
flatten Srcs transforms srcs attributes structured as concatenations of lists and selects generated from Platform Strings see extract Platform Strings Exprs for matching details into a sorted de duplicated list Comments are accumulated and de duplicated across duplicate expressions 
remove Legacy Proto removes uses of the old proto rules It deletes loads from go proto library bzl It deletes proto filegroups It removes go proto library attributes which are no longer recognized New rules are generated in place of the deleted rules but attributes and comments are not migrated 
remove Legacy Gazelle removes loads of the gazelle macro from 
select Packages selects one Go packages out of the buildable packages found in a directory If multiple packages are found it returns the package whose name matches the directory if such a package exists 
options transforms package relative paths in cgo options into repository root relative paths that Bazel can understand For example if a cgo file in foo declares an include flag in its copts Ibar this method will transform that flag into Ifoo bar 
Add Builtin registers a builtin kind with its info 
Mapped Kind records the fact that the given mapping was applied while processing the given package 
Resolver returns a resolver for the given rule and package and a bool indicating whether one was found Empty string may be passed for pkg Rel which results in consulting the builtin kinds only 
sort Expr Labels sorts lists of strings using the same order as buildifier Buildifier also sorts string lists but not those involved with select expressions This function is intended to be used with bzl Walk 
check Rules Go Version checks whether a compatible version of rules go is being used in the workspace A message will be logged if an incompatible version is found Note that we can t always determine the version of rules go in use Also if we find an incompatible version we shouldn t bail out since the incompatibility may not matter in the current workspace 
preprocess Tags adds some tags which are on by default before they are used to match files 
set Build Tags sets generic Tags by parsing as a comma separated list An error will be returned for tags that wouldn t be recognized by go build preprocess Tags should be called before this 
check Prefix checks that a string may be used as a prefix We forbid local relative imports and those beginning with We allow the empty string but generated rules must not have an empty importpath 
split Directive splits a comma separated directive value into its component parts trimming each of any whitespace characters 
copy Go Mod To Temp copies to given go mod file to a temporary directory go list tends to mutate go mod files but gazelle shouldn t do that 
find Go Tool attempts to locate the go executable If GOROOT is set we ll prefer the one in there otherwise we ll rely on PATH If the wrapper script generated by the gazelle rule is invoked by Bazel it will set GOROOT to the configured SDK We don t want to rely on the host SDK in that situation 
add File adds the file described by info to a target in the package p if the file is buildable cgo tells whether any go file in the package contains cgo code This affects whether C files are added to targets An error is returned if a file is buildable but invalid for example a test go file containing cgo code Files that are not buildable will not be added to any target for example txt files 
is Buildable returns true if anything in the package is buildable This is true if the package has Go code that satisfies build constraints on any platform or has proto files not in legacy mode 
first Go File returns the name of a go file if the package contains at least one go file or otherwise 
get Platform Strings Add Function returns a function used to add strings to a platform Strings Builder under the same set of constraints This is a performance optimization to avoid evaluating constraints repeatedly 
start Server starts a new server process This is called by the client 
run Server performs the main work of the server Once started the server will Copy BUILD in and BUILD bazel in files to BUILD and BUILD bazel Watch for file system writes in the whole repository Listen for clients on a UNIX domain socket When the server accepts a connection it runs Gazelle On the first run it runs Gazelle on the entire repository On subsequent runs it runs Gazelle only in directories that have changed The server stops after being idle for a while It can also be stopped with SIGINT or SIGTERM 
watch Dir listens for file system changes in root and its subdirectories The record function is called with directories whose contents have changed New directories are watched recursively The returned cancel function may be called to stop watching 
list Dirs returns a slice containing all the subdirectories under dir including dir itself 
should Ignore returns whether a write to the given file should be ignored because they were caused by gazelle or autogazelle or something unrelated to the build 
record Write records that a directory has been modified and that its build file should be updated the next time gazelle runs 
get And Clear Written Dirs retrieves a list of directories that have been modified since the last time get And Clear Written Dirs was called 
 Start starts the passed in exec Cmd command It wraps the command in a gexec Session 
 Exit Code returns the wrapped command s exit code If the command hasn t exited yet Exit Code returns 
 Wait waits until the wrapped command exits It can be passed an optional timeout If the command does not exit within the timeout Wait will trigger a test failure 
 Signal sends the running command the passed in signal It does not wait for the process to exit 
 Kill sends a SIGKILL signal to all the processes started by Run and waits for them to exit The timeout specified is applied to each process killed 
 Kill sends a SIGTERM signal to all the processes started by Run and waits for them to exit The timeout specified is applied to each process killed 
 Kill sends a SIGKILL signal to all the processes started by Run It does not wait for the processes to exit 
 Terminate sends a SIGTERM signal to all the processes started by Run It does not wait for the processes to exit 
 Signal sends the passed in signal to all the processes started by Run It does not wait for the processes to exit 
 Interrupt sends the SIGINT signal to all the processes started by Run It does not wait for the processes to exit 
Combine Handler takes variadic list of handlers and produces one handler that calls each handler in order 
Verify Request returns a handler that verifies that a request uses the specified method to connect to the specified path You may also pass in an optional raw Query string which is tested against the request s req URL Raw Query For path you may pass in a string in which case strict equality will be applied Alternatively you can pass in a matcher Contain Substring foo and Match Regexp foo a f for example 
Verify Content Type returns a handler that verifies that a request has a Content Type header set to the specified value 
Verify Mime Type returns a handler that verifies that a request has a specified mime type set in Content Type header 
Verify Basic Auth returns a handler that verifies the request contains a Basic Auth Authorization header matching the passed in username and password 
Verify Header returns a handler that verifies the request contains the passed in headers The passed in header keys are first canonicalized via http Canonical Header Key The request must contain all the passed in headers but it is allowed to have additional headers beyond the passed in set 
Verify Header KV returns a handler that verifies the request contains a header matching the passed in key and values recall that a http Header is a mapping from string key to string values It is a convenience wrapper around Verify Header that allows you to avoid having to create an http Header object 
Verify Body returns a handler that verifies that the body of the request matches the passed in byte array It does this using Equal 
Verify JSON returns a handler that verifies that the body of the request is a valid JSON representation matching the passed in JSON string It does this using Gomega s Match JSON method Verify JSON also verifies that the request s content type is application json 
Verify JSONRepresenting is similar to Verify JSON Instead of taking a JSON string however it takes an arbitrary JSON encodable object and verifies that the requests s body is a JSON representation that matches the object 
Verify Form returns a handler that verifies a request contains the specified form values The request must contain all of the specified values but it is allowed to have additional form values beyond the passed in set 
Verify Form KV returns a handler that verifies a request contains a form key with the specified values It is a convenience wrapper around Verify Form that lets you avoid having to create a url Values object 
Verify Proto Representing returns a handler that verifies that the body of the request is a valid protobuf representation of the passed message Verify Proto Representing also verifies that the request s content type is application x protobuf 
 Respond With returns a handler that responds to a request with the specified status code and body 
 Respond With JSONEncoded returns a handler that responds to a request with the specified status code and a body containing the JSON encoding of the passed in object 
 Respond With JSONEncoded Ptr behaves like Respond With JSONEncoded but takes a pointer to a status code and object 
Respond With Proto returns a handler that responds to a request with the specified status code and a body containing the protobuf serialization of the provided message Also Respond With Proto can be given an optional http Header The headers defined therein will be added to the response headers 
Register Fail Handler With T ensures that the given types TWith Helper and fail handler are used globally 
Intercept Gomega Failures runs a given callback and returns an array of failure messages generated by any Gomega assertions within the callback This is accomplished by temporarily replacing the global fail handler with a fail handler that simply annotates failures The original fail handler is reset when Intercept Gomega Failures returns This is most useful when testing custom matchers but can also be used to check on a value using a Gomega assertion without causing a test failure 
Expect With Offset wraps an actual value allowing assertions to be made on it Expect With Offset foo To Equal foo Unlike Expect and Expect With Offset takes an additional integer argument this is used to modify the call stack offset when computing line numbers This is most useful in helper functions that make assertions If you want Gomega s error message to refer to the calling line in the test as opposed to the line in the helper function set the first argument of Expect With Offset appropriately 
Eventually With Offset operates like Eventually but takes an additional initial argument to indicate an offset in the call stack This is useful when building helper functions that contain matchers To learn more read about Expect With Offset 
Consistently With Offset operates like Consistnetly but takes an additional initial argument to indicate an offset in the call stack This is useful when building helper functions that contain matchers To learn more read about Expect With Offset 
Expect is used to make assertions See documentation for Expect 
Eventually is used to make asynchronous assertions See documentation for Eventually 
Consistently is used to make asynchronous assertions See documentation for Consistently 
 Generates a formatted matcher success failure message of the form 
 Pretty prints the passed in object at the passed in indentation level 
 Indent String takes a string and indents each line by the specified amount 
 Returns true when the string is entirely made of printable runes false otherwise 
 The Exit matcher operates on a session 
Match Fields succeeds if each element of a struct matches the field matcher associated with it It can ignore extra fields and or missing fields actual struct A int B bool C string A B bool true false C foo Expect actual To Match Fields Ignore Extras Fields A Equal B Consist Of true false Expect actual To Match Fields Ignore Missing Fields A Equal B Consist Of true false C Equal foo D Equal extra 
 Say is a Gomega matcher that operates on gbytes Buffers 
Receive succeeds if there is a value to be received on actual Actual must be a channel and cannot be a send only channel anything else is an error Receive returns immediately and never blocks If there is nothing on the channel c then Expect c Should Receive will fail and c Should Not Receive will pass If the channel c is closed then Expect c Should Receive will fail and c Should Not Receive will pass If there is something on the channel c ready to be read then Expect c Should Receive will pass and c Should Not Receive will fail If you have a go routine running in the background that will write to channel c you can Eventually c Should Receive This will timeout if nothing gets sent to c you can modify the timeout interval as you normally do with Eventually A similar use case is to assert that no go routine writes to a channel for a period of time You can do this with Consistently Consistently c Should Not Receive You can pass Receive a matcher If you do so it will match the received object against the matcher For example Expect c Should Receive Equal foo When given a matcher Receive will always fail if there is nothing to be received on the channel Passing Receive a matcher is especially useful when paired with Eventually Eventually c Should Receive Contain Substring bar will repeatedly attempt to pull values out of c until a value matching bar is received Finally if you want to have a reference to the value sent to the channel you can pass the Receive matcher a pointer to a variable of the appropriate type var my Thing thing Eventually thing Chan Should Receive my Thing Expect my Thing Sprocket Should Equal foo Expect my Thing Is Valid Should Be True 
Match Regexp succeeds if actual is a string or stringer that matches the passed in regexp Optional arguments can be provided to construct a regexp via fmt Sprintf 
Contain Substring succeeds if actual is a string or stringer that contains the passed in substring Optional arguments can be provided to construct the substring via fmt Sprintf 
Have Prefix succeeds if actual is a string or stringer that contains the passed in string as a prefix Optional arguments can be provided to construct via fmt Sprintf 
Have Suffix succeeds if actual is a string or stringer that contains the passed in string as a suffix Optional arguments can be provided to construct via fmt Sprintf 
Have Key With Value succeeds if actual is a map with the passed in key and value By default Have Key With Value uses Equal to perform the match however a matcher can be passed in instead Expect map string string Foo Bar Baz Foo Duck Should Have Key With Value Foo Bar Expect map string string Foo Bar Baz Foo Duck Should Have Key With Value Match Regexp Foo Bar 
Be Numerically performs numerical assertions in a type agnostic way Actual and expected should be numbers though the specific type of number is irrelevant float float uint etc There are six self explanatory supported comparators Expect Should Be Numerically Expect Should Be Numerically Expect Should Be Numerically Expect Should Be Numerically Expect Should Be Numerically Expect Should Be Numerically 
Be Temporally compares time Time s like Be Numerically Actual and expected must be time Time The comparators are the same as for Be Numerically Expect time Now Should Be Temporally time Time Expect time Now Should Be Temporally time Now time Second 
And succeeds only if all of the given matchers succeed The matchers are tried in order and will fail fast if one doesn t succeed Expect hi To And Have Len Equal hi And Or Not and With Transform allow matchers to be composed into complex expressions 
Or succeeds if any of the given matchers succeed The matchers are tried in order and will return immediately upon the first successful match Expect hi To Or Have Len Have Len And Or Not and With Transform allow matchers to be composed into complex expressions 
Not negates the given matcher it succeeds if the given matcher fails Expect To Not Equal And Or Not and With Transform allow matchers to be composed into complex expressions 
With Transform applies the transform to the actual value and matches it against matcher The given transform must be a function of one parameter that returns one value var plus func i int int return i Expect To With Transform plus Equal And Or Not and With Transform allow matchers to be composed into complex expressions 
 Build uses go build to compile the package at package Path The resulting binary is saved off in a temporary directory A path pointing to this binary is returned 
 Build With Environment is identical to Build but allows you to specify env vars to be set at build time 
 Build In is identical to Build but allows you to specify a custom GOPATH the first argument 
 You should call Cleanup Build Artifacts before your test ends to clean up any temporary artifacts generated by gexec In Ginkgo this is typically done in an After Suite callback 
Timeout Closer returns an io Closer that wraps the passed in io Closer If the underlying Closer fails to close within the alloted timeout Err Timeout is returned 
Timeout Reader returns an io Reader that wraps the passed in io Reader If the underlying Reader fails to read within the alloted timeout Err Timeout is returned 
Timeout Writer returns an io Writer that wraps the passed in io Writer If the underlying Writer fails to write within the alloted timeout Err Timeout is returned 
 Buffer With Bytes returns a new gbytes Buffer seeded with the passed in bytes 
 Buffer Reader returns a new gbytes Buffer that wraps a reader The reader s contents are read into the Buffer via io Copy 
 Write implements the io Writer interface 
 Read implements the io Reader interface It advances the cursor as it reads 
 Close signifies that the buffer will no longer be written to 
 Closed returns true if the buffer has been closed 
 Contents returns all data ever written to the buffer 
 Detect takes a regular expression and returns a channel 
 Cancel Detects cancels any pending detects and cleans up their goroutines You should always call this when you re done with a set of Detect channels 
Create a Nested Error with the given path If err is a Nested Error prepend the path to it If err is an Aggregate Error recursively Nest each error 
Error is part of the error interface 
Match All Elements succeeds if every element of a slice matches the element matcher it maps to through the id function and every element matcher is matched id Fn func element interface string return fmt Sprintf v element Expect string a b To Match All Elements id Fn Elements a Equal a b Equal b 
Match Elements succeeds if each element of a slice matches the element matcher it maps to through the id function It can ignore extra elements and or missing elements id Fn func element interface string return fmt Sprintf v element Expect string a b c To Match Elements id Fn Ignore Extras Elements a Equal a b Equal b Expect string a c To Match Elements id Fn Ignore Missing Elements a Equal a b Equal b c Equal c d Equal d 
Set Mock Service return a new Mock Service and set as a servicemanager 
Open dials to the Mongo DB database and return the connection represented by the type Storage addr is a Mongo DB connection URI and dbname is the name of the database This function returns a pointer to a Storage or a non nil error in case of any failure 
Uses id or address this is only used because previously we didn t have iaas id in node metadata 
Write writes and flushes the data 
Hijack will hijack the underlying TCP connection if available in the Response Writer 
List Deploys returns the list of deploy that match a given filter 
Deploy runs a deployment of an application It will first try to run an archive based deploy if opts Archive URL is not empty and then fallback to the Git based deployment 
title event list path events method GET produce application json responses OK No content 
title kind list path events kinds method GET produce application json responses OK No content 
title event info path events uuid method GET produce application json responses OK Invalid uuid Unauthorized Not found 
title event cancel path events uuid cancel method POST produce application json responses OK Invalid uuid or empty reason Unauthorized Not found 
title event block list path events blocks method GET produce application json responses OK No content Unauthorized 
title add event block path events blocks method POST consume application x www form urlencoded responses OK Invalid data or empty reason Unauthorized 
title remove event block path events blocks uuid method DELETE responses OK Invalid uuid Unauthorized Active block with provided uuid not found 
title user quota path users email quota method GET produce application json responses OK Unauthorized User not found 
title update user quota path users email quota method PUT consume application x www form urlencoded responses Quota updated Invalid data Unauthorized Limit lower than allocated value User not found 
title update application quota path apps appname quota method PUT consume application x www form urlencoded responses Quota updated Invalid data Unauthorized Limit lower than allocated Application not found 
Add All binds a path to GET POST PUT and DELETE methods 
Return timeout in seconds 
Register Handler inserts a handler on a list of handlers for version 
Register Handler Version inserts a handler on a list of handlers 
Run Server starts tsuru API server The dry parameter indicates whether the server should run in dry mode not starting the HTTP listener for testing purposes 
validate TLSCertificate checks if c is ready for use in a production env When c is not a good one returns a non nil error describing the problem otherwise returns nil indicating success A good certificate should be issued even though indirectly when providing intermediates by roots within the issuing time boundary and match the Common Name or SAN extension with the server s hostname defined by host entry in the API config file See x Verify to more detailed info 
Check check the status of registered checkers matching names and return a list of results 
title profile index handler path debug pprof method GET responses Ok Unauthorized 
title profile cmdline handler path debug pprof cmdline method GET responses Ok Unauthorized 
title profile handler path debug pprof profile method GET responses Ok Unauthorized 
title profile symbol handler path debug pprof symbol method GET responses Ok Unauthorized 
title profile trace handler path debug pprof trace method GET responses Ok Unauthorized 
Discover Repository Path finds the path of the repository from a given directory It returns the path to the repository or an an empty string and a non nil error if it can t find the repository 
Open Repository opens a repository by its filepath You can use Discover Repository Path to discover the repository from any directory and use the result of this call as parameter for Open Repository Open Repository will return an error if the given path does not appear to be a git repository 
Remote URL returns the URL of a remote by its name Or an error if the remote is not declared 
title token list path tokens method GET produce application json responses List tokens No content Unauthorized 
title token info path tokens token id method GET produce application json responses Get token Unauthorized 
title token create path tokens method POST produce application json responses Token created Unauthorized Token already exists 
title token update path tokens token id method PUT produce application json responses Token updated Unauthorized Token not found 
title token delete path tokens token id method DELETE produce application json responses Token created Unauthorized Token not found 
title role create path roles method POST consume application x www form urlencoded responses Role created Invalid data Unauthorized Role already exists 
title remove role path roles name method DELETE responses Role removed Unauthorized Role not found Role with users 
title role list path roles method GET produce application json responses OK Unauthorized 
title role info path roles name method GET produce application json responses OK Unauthorized Role not found 
title add permissions path roles name permissions method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized Permission not allowed 
title remove permission path roles name permissions permission method DELETE responses Permission removed Unauthorized Not found 
title assign role to user path roles name user method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized Role not found 
title list permissions path permissions method GET produce application json responses Ok Unauthorized 
title add default role path role default method POST consme application x www form urlencoded responses Ok Invalid data Unauthorized 
title list default roles path role default method GET produce application json responses Ok Unauthorized 
title updates a role path roles method PUT responses Ok Invalid data Unauthorized 
title assign role to token path roles name token method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized Role or team token not found 
List lists all Apps in the indexer 
Apps returns an object that can list and get Apps 
List lists all Apps in the indexer for a given namespace 
Register Machine registers an iaas Machine as an Machine and a host on the current running Docker Machine It expects all data needed to Marshal the host driver to be available on Custom Data 
Stream JSONResponse supports the JSON streaming format from the tsuru API 
Drop Database drop database of any given name 
Collection returns a collection by its name If the collection does not exist Mongo DB will create it 
This method loads basic config and returns a copy of the config object 
Set Logger defines a new logger for the current target See the builtin log package for more details 
Error writes the given values to the Target logger 
Errorf writes the formatted string to the Target logger 
Fatal writes the given values to the Target logger 
Debugf writes the formatted string to the Target logger 
Get Std Logger returns a standard Logger instance useful for configuring log in external packages 
Namespace returns the namespace to be used by Custom Resources 
recreate Containers relaunch all node containers in the cluster for the given Docker Provisioner logging progress to the given writer It assumes that the given writer is thread safe 
Check provisioner configs 
Check Docker configs 
Check Schedulers It verifies your scheduler configuration and validates related confs 
Check Router It verifies your router configuration and validates related confs 
title plan create path plans method POST consume application x www form urlencoded responses Plan created Invalid data Unauthorized Plan already exists 
title plan list path plans method GET produce application json responses OK No content 
title remove plan path plans name method DELETE responses Plan removed Unauthorized Plan not found 
Get Build Image returns the image name from app or plaftorm the platform image will be returned if there are no containers the container have an empty image name the deploy number is multiple of in all other cases the app image name will be returned 
title pool list path pools method GET produce application json responses OK No content Unauthorized 
title pool create path pools method POST consume application x www form urlencoded responses Pool created Invalid data Unauthorized Pool already exists 
title remove pool path pools name method DELETE responses Pool removed Unauthorized Pool still has apps Pool not found 
title add team too pool path pools name team method POST consume application x www form urlencoded responses Pool updated Unauthorized Invalid data Pool not found 
title pool update path pools name method PUT consume application x www form urlencoded responses Pool updated Unauthorized Pool not found Default pool already defined 
title pool constraints list path constraints method GET produce application json responses OK No content Unauthorized 
title set a pool constraint path constraints method PUT consume application x www form urlencoded responses OK Unauthorized 
Available returns true if the unit is available It will return true whenever the unit itself is available even when the application process is not 
Get gets the named provisioner from the registry 
Registry returns the list of registered provisioners 
Error is the string representation of a provisioning error 
title user create path users method POST consume application x www form urlencoded responses User created Invalid data Unauthorized Forbidden User already exists 
title login path auth login method POST consume application x www form urlencoded produce application json responses Ok Invalid data Unauthorized Forbidden Not found 
title logout path users tokens method DELETE responses Ok 
title change password path users password method PUT consume application x www form urlencoded responses Ok Invalid data Unauthorized Forbidden Not found 
title reset password path users email password method POST responses Ok Invalid data Unauthorized Forbidden Not found 
title team update path teams name method PUT consume application x www form urlencoded responses Team updated Invalid data Unauthorized Team not found 
title team create path teams method POST consume application x www form urlencoded responses Team created Invalid data Unauthorized Team already exists 
title remove team path teams name method DELETE responses Team removed Unauthorized Forbidden Not found 
title team list path teams method GET produce application json responses List teams No content Unauthorized 
title team info path teams name method GET produce application json responses Info team Not found Unauthorized 
title add key path users keys method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized Key already exists 
title remove key path users keys key method DELETE responses Ok Invalid data Unauthorized Not found 
title list keys path users keys method GET produce application json responses OK Invalid data Unauthorized 
title remove user path users method DELETE responses User removed Unauthorized Not found 
title get auth scheme path auth scheme method GET produce application json responses OK 
title regenerate token path users api key method POST produce application json responses OK Unauthorized User not found 
title show token path users api key method GET produce application json responses OK Unauthorized User not found 
title user list path users method GET produce application json responses OK Unauthorized 
title user info path users info method GET produce application json responses OK Unauthorized 
title add platform path platforms method POST consume multipart form data produce application x json stream responses Platform created Invalid data Unauthorized 
title update platform path platforms name method PUT produce application x json stream responses Platform updated Unauthorized Not found 
title remove platform path platforms name method DELETE responses Platform removed Unauthorized Not found 
title platform list path platforms method GET produce application json responses List platforms No content Unauthorized 
title platform info path platforms name method GET produce application json responses Platform info Unauthorized Not Found 
title rollback platform path platforms name rollback method POST produce application x json stream responses OK Bad Request Unauthorized Not found 
title move container path docker container id move method POST consume application x www form urlencoded produce application x json stream responses Ok Invalid data Unauthorized Not found 
title move containers path docker containers move method POST consume application x www form urlencoded produce application x json stream responses Ok Invalid data Unauthorized Not found 
title logs config path docker logs method GET produce application json responses Ok Unauthorized 
title logs config set path docker logs method POST consume application x www form urlencoded produce application x json stream responses Ok Invalid data Unauthorized 
validate Version checks whether current version is greater or equal to supported version 
Read Target returns the current target as defined in the TSURU TARGET environment variable or in the target file 
Write Target writes the given endpoint to the target file 
Write On Target List writes the given target in the target list file 
This method loads basic config and returns a copy of the config object 
title app build path apps appname build method POST consume application x www form urlencoded responses OK Invalid data Forbidden Not found 
Build Health Check creates a healthcheck function for the given router Name It will call the Health Check method in the router only if it s also a Health Checker for each instance of it including the main instance and all custom routers 
Conn reads the tsuru config and calls storage Open to get a database connection Most tsuru packages should probably use this function storage Open is intended for use when supporting more than one database 
Apps returns the apps collection from Mongo DB 
Pools Constraints return the pool constraints collection 
Users returns the users collection from Mongo DB 
SAMLRequests returns the saml requests from Mongo DB 
App Log Collection returns the logs collection for one app from Mongo DB 
Create App Log Collection creates a new capped collection to store logs for an app 
Logs Collections returns logs collections for all apps from Mongo DB 
Archive Build Cmds build a image using the archive method 
Archive Deploy Cmds is a legacy command to deploys an unit using the archive method 
Deploy Cmds deploys an unit builded by tsuru 
run With Agent Cmds returns the list of commands that should be passed when the provisioner will run a unit using tsuru unit agent to start This will only be called for legacy containers that have not been re deployed since the introduction of independent units per process in 
new Apps returns a Apps 
Get takes name of the app and returns the corresponding app object and an error if there is any 
List takes label and field selectors and returns the list of Apps that match those selectors 
Create takes the representation of a app and creates it Returns the server s representation of the app and an error if there is any 
Update takes the representation of a app and updates it Returns the server s representation of the app and an error if there is any 
Delete takes name of the app and deletes it Returns an error if one occurs 
Commits commits the container creating an image in Docker It then returns the image identifier for usage in future container creation 
Parse Token extracts token from a header type token or token 
process Tags removes duplicates and trims spaces from each tag 
aggregate Containers By aggregates and counts how many containers exist each node that matches received filters 
choose Node To Add finds which is the node with the minimum number of containers and returns it 
choose Container To Remove finds a container from the the node with maximum number of containers and returns it 
Find the host with the minimum good to add a new container and maximum good to remove a container value for the pair number of containers for app process number of containers in host 
title router list path routers method GET produce application json responses OK No content 
title add app router path app app routers method POST produce application json responses OK App or router not found Invalid request 
title delete app router path app app routers router method DELETE produce application json responses OK App or router not found 
title list app routers path app app routers method GET produce application json responses OK No content App not found 
Get gets the named router from the registry 
Default returns the default router 
Store stores the app name related with the router name 
title service list path services method GET produce application json responses List services No content Unauthorized 
title service create path services method POST consume application x www form urlencoded responses Service created Invalid data Unauthorized Service already exists 
title service update path services name method PUT consume application x www form urlencoded responses Service updated Invalid data Unauthorized Forbidden team is not the owner Service not found 
title service delete path services name method DELETE responses Service removed Unauthorized Forbidden team is not the owner or service with instances Service not found 
title service proxy path services proxy service service method responses Unauthorized Service not found 
title grant access to a service path services service team team method PUT responses Service updated Team not found Unauthorized Service not found Team already has access to this service 
title change service documentation path services name doc consume application x www form urlencoded method PUT responses Documentation updated Unauthorized Forbidden team is not the owner or service with instances 
New Simple Clientset returns a clientset that will respond with the provided objects It s backed by a very simple object tracker that processes creates updates and deletions as is without applying any validations and or defaults It shouldn t be considered a replacement for a real clientset and is mostly useful in simple unit tests 
Tsuru V retrieves the Tsuru V Client 
Tsuru retrieves the Tsuru V Client 
title healthcheck path healthcheck method GET responses OK Internal server error 
New App Informer constructs a new informer for App type Always prefer using an informer factory to get a shared informer instead of getting an independent one This reduces memory footprint and number of connections to the server 
New Filtered App Informer constructs a new informer for App type Always prefer using an informer factory to get a shared informer instead of getting an independent one This reduces memory footprint and number of connections to the server 
Get takes name of the app and returns the corresponding app object and an error if there is any 
List takes label and field selectors and returns the list of Apps that match those selectors 
Watch returns a watch Interface that watches the requested apps 
Create takes the representation of a app and creates it Returns the server s representation of the app and an error if there is any 
Update takes the representation of a app and updates it Returns the server s representation of the app and an error if there is any 
Delete takes name of the app and deletes it Returns an error if one occurs 
Delete Collection deletes a collection of objects 
Patch applies the patch and returns the patched app 
New Shared Informer Factory constructs a new instance of shared Informer Factory 
New Filtered Shared Informer Factory constructs a new instance of shared Informer Factory Listers obtained via this Shared Informer Factory will be subject to the same filters as specified here 
title webhook list path events webhooks method GET produce application json responses List webhooks No content 
title webhook info path events webhooks name method GET produce application json responses Get webhook Not found Unauthorized 
title webhook create path events webhooks method POST responses Webhook created Unauthorized Invalid webhook Webhook already exists 
title webhook update path events webhooks name method PUT responses Webhook updated Unauthorized Invalid webhook Webhook not found 
Proxy is not implemented for OSB API implementations 
Unbind Unit is a no op for OSB API implementations 
Create implements Create method of Plan Service interface 
Remove implements Remove method of Plan Service interface 
ensure Default creates and stores an autogenerated plan in case of no plans exists 
Delete Instance deletes the service instance from the database 
To Info returns the service instance as a struct compatible with the return of the service info api call 
Update changes informations of the service instance 
Bind App makes the bind between the service instance and an app 
Bind Unit makes the bind between the binder and an unit 
Unbind App makes the unbind between the service instance and an app 
Status returns the service instance status 
Proxy Instance is a proxy between tsuru and the service instance This method allow customized service instance methods 
Inc implements Inc method from Quota Service interface 
Set Limit redefines the limit of the app The new limit must be bigger than or equal to the current number of units in the app The new limit may be smaller than which means that the app should have an unlimited number of units Set Limit implements Set Limit method from Quota Service interface 
Set redefines the inuse units of the app This new value must be smaller than or equal to the current limit of the app It also must be a non negative number Set implements Set method from Quota Service interface 
Get implements Get method from Quota Service interface 
title add install host path install hosts method POST consume application x www form urlencoded produce application json responses Host added Unauthorized 
title install host info path install hosts name method GET produce application json responses OK Unauthorized Not Found 
title list install hosts path install hosts method GET produce application json responses OK Unauthorized 
Migrate Unique Collection only exists because old versions of tsuru allowed the insertion of incorrect duplicated entries in the db routers collection This migration tries its best to fix the inconsistencies in this collection and fails if that s not possible 
Remove Image removes an image manifest from a remote registry v server returning an error in case of failure 
Remove App Images removes all app images from a remote registry v server returning an error in case of failure 
Create implements Create method of Platform Service interface 
List implements List method of Platform Service interface 
Find By Name implements Find By Name method of Platform Service interface 
Update implements Update method of Platform Service interface 
Remove implements Remove method of Platform Service interface 
Rollback implements Rollback method of Platform Service interface 
title index path method GET responses OK 
Get Pool By Name finds a pool by name 
title app shell path apps name shell method GET produce Websocket connection upgrade responses Switch Protocol to websocket 
Manager returns the current configured manager as defined in the configuration file 
Register registers a new repository manager that can be later configured and used 
start starts the sync process on a different goroutine 
Shutdown shutdowns bind Syncer waiting for the current sync to complete 
Get For Provisioner gets the builder required by the provisioner 
get gets the named builder from the registry 
Registry returns the list of registered builders 
Register Queue Task registers the internal bs queue task for later execution 
title docker healing history path docker healing method GET produce application json responses Ok No content Invalid data Unauthorized 
Apps returns a App Informer 
merged from https github com kubernetes kubernetes blob f c e acd f a e cb a c pkg quota evaluator core pods go L and https github com kubernetes kubernetes blob e fb acee b afbc fc aea b e c pkg printers internalversion printers go L 
title dump goroutines path debug goroutines method GET responses Ok 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new App 
Deep Copy Object is an autogenerated deepcopy function copying the receiver creating a new runtime Object 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new App List 
Deep Copy Object is an autogenerated deepcopy function copying the receiver creating a new runtime Object 
Deep Copy Into is an autogenerated deepcopy function copying the receiver writing into out in must be non nil 
Deep Copy is an autogenerated deepcopy function copying the receiver creating a new App Spec 
title service broker list path brokers method GET produce application json responses List service brokers No content Unauthorized 
title Add service broker path brokers method POST responses Service broker created Unauthorized Broker already exists 
title Update service broker path brokers broker method PUT responses Service broker updated Unauthorized Not Found 
Write writes and logs the data 
title create provisioner cluster path provisioner clusters method POST consume application x www form urlencoded produce application x json stream responses Ok Invalid data Unauthorized Pool does not exist Cluster already exists 
title list provisioner clusters path provisioner clusters method GET consume application x www form urlencoded produce application json responses Ok No Content Unauthorized 
title delete provisioner cluster path provisioner clusters name method DELETE consume application x www form urlencoded produce application x json stream responses Ok Unauthorized Cluster not found 
title list provisioners path provisioner method GET produce application json responses Ok No Content Unauthorized 
title add node path node method POST consume application x www form urlencoded produce application x json stream responses Ok Unauthorized Not found 
title remove node path provisioner node address method DELETE responses Ok Unauthorized Not found 
title list nodes path provisioner node method GET produce application json responses Ok No content 
title update nodes path provisioner node method PUT consume application x www form urlencoded responses Ok Invalid data Unauthorized Not found 
title list units by node path provisioner node address containers method GET produce application json responses Ok No content Unauthorized Not found 
title list units by app path docker node apps appname containers method GET produce application json responses Ok No content Unauthorized Not found 
title node healing info path healing node method GET produce application json responses Ok Unauthorized 
title node healing update path healing node method POST consume application x www form urlencoded responses Ok Unauthorized 
title remove node healing path healing node method DELETE produce application json responses Ok Unauthorized 
title rebalance units in nodes path node rebalance method POST consume application x www form urlencoded produce application x json stream responses Ok Invalid data Unauthorized 
title node info path node address method GET produce application json responses Ok Unauthorized Not found 
Reset Password actually resets the password of the user It needs the token string The new password will be a random string that will be then sent to the user email 
title app deploy path apps appname deploy method POST consume application x www form urlencoded responses OK Invalid data Forbidden Not found 
title deploy diff path apps appname diff method POST consume application x www form urlencoded responses OK Invalid data Forbidden Not found 
title deploy list path deploys method GET produce application json responses OK No content 
title deploy info path deploys deploy method GET produce application json responses OK Unauthorized Not found 
title rebuild path apps appname deploy rebuild method POST consume application x www form urlencoded produce application x json stream responses OK Invalid data Forbidden Not found 
title rollback update path apps appname deploy rollback update method PUT consume application x www form urlencoded responses Rollback updated Invalid data Forbidden 
Build Health Check creates a healthcheck function for the given provider Name It will call the Health Check method in the provider only if it s also a Health Checker for each instance of it including the main instance and all custom Iaa Ses 
get Brokered Service retrieves the service information from a service that is offered by a broker name is in the format broker service Name Broker Sep service 
title machine list path iaas machines method GET produce application json responses OK Unauthorized 
title machine destroy path iaas machines machine id method DELETE responses OK Invalid data Unauthorized Not found 
title machine template list path iaas templates method GET produce application json responses OK Unauthorized 
title template create path iaas templates method POST consume application x www form urlencoded responses Template created Invalid data Unauthorized Existent template 
title template destroy path iaas templates template name method DELETE responses OK Unauthorized Not found 
title template update path iaas templates template name method PUT consume application x www form urlencoded responses OK Invalid data Unauthorized Not found 
RESTClient returns a RESTClient that is used to communicate with API server by this client implementation 
Adds the list of known types to the given scheme 
title saml metadata path auth saml method GET produce application xml responses Ok Invalid data 
title saml callback path auth saml method POST responses Ok Invalid data 
title volume list path volumes method GET produce application json responses List volumes No content Unauthorized 
title volume info path volumes name method GET produce application json responses Show volume Unauthorized Volume not found 
title volume create path volumes method POST produce application json responses Volume created Unauthorized Volume already exists 
title volume update path volumes name method POST produce application json responses Volume updated Unauthorized Volume not found 
title volume plan list path volumeplans method GET produce application json responses List volume plans Unauthorized 
title volume delete path volumes name method DELETE produce application json responses Volume deleted Unauthorized Volume not found 
title volume bind path volumes name bind method POST produce application json responses Volume binded Unauthorized Volume not found Volume bind already exists 
title get autoscale config path autoscale config method GET produce application json responses Ok Unauthorized 
title autoscale rules list path autoscale rules method GET produce application json responses Ok No content Unauthorized 
title autoscale set rule path autoscale rules method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized 
title delete autoscale rule path autoscale rules id method DELETE responses Ok Unauthorized Not found 
title list autoscale history path autoscale method GET produce application json responses Ok No content Unauthorized 
title autoscale run path autoscale run method POST produce application x json stream responses Ok Unauthorized 
title service instance create path services service instances method POST consume application x www form urlencoded responses Service created Invalid data Unauthorized Service already exists 
title service instance update path services service instances instance method PUT consume application x www form urlencoded responses Service instance updated Invalid data Unauthorized Service instance not found 
title remove service instance path services name instances instance method DELETE produce application x json stream responses Service removed Bad request Unauthorized Service instance not found 
title service instance list path services instances method GET produce application json responses List services instances No content Unauthorized 
title service instance status path services service instances instance status method GET responses List services instances Unauthorized Service instance not found 
title service instance info path services service instances instance method GET produce application json responses OK Unauthorized Service instance not found 
title service info path services name method GET produce application json responses OK 
title service doc path services name doc method GET responses OK Unauthorized Not found 
title service plans path services name plans method GET produce application json responses OK Unauthorized Service not found 
title service instance proxy path services service proxy instance method responses Unauthorized Instance not found 
title grant access to service instance path services service instances permission instance team consume application x www form urlencoded method PUT responses Access granted Unauthorized Service instance not found 
Register registers an item as shutdownable 
Do shutdowns All registered Shutdownable items 
Platform List Images Or Default returns basic Image Name when platform is empty for backwards compatibility 
Info returns the additional info about a service instance The api should be prepared to receive the request like below GET resources name 
Plans returns the service plans The api should be prepared to receive the request like below GET resources plans 
Proxy is a proxy between tsuru and the service This method allow customized service methods 
Migrate Apps CRDs creates the necessary CRDs for every application on a Kubernetes cluster This is done by re provisioning the App on the cluster 
Register register a new migration for later execution with the Run functions 
Register Optional register a new migration that will not run automatically when calling the Run funcition 
Run runs all registered non optional migrations if no Name is informed Migrations are executed in the order that they were registered If Name is informed an optional migration with the given name is executed 
Units returns the list of units 
Marshal JSON marshals the app in json format 
Acquire Application Lock acquires an application lock by setting the lock field in the database This method is already called by a connection middleware on requests with app or appname params that have side effects 
Same as Acquire Application Lock but it keeps trying to acquire the lock until timeout is reached 
Release Application Lock releases a lock hold on an app currently it s called by a middleware however ideally it should be called individually by each handler since they might be doing operations in background 
Get By Name queries the database to find an app identified by the given name 
Create App creates a new app Creating a new app is a process composed of the following steps Save the app in the database Create the git repository using the repository manager Provision the app using the provisioner 
Update changes informations of the application 
unbind takes all service instances that are bound to the app and unbind them This method is used by Destroy before destroying the app it unbinds all service instances Refer to Destroy docs for more details 
Delete deletes an app 
Add Units creates n new units within the provisioner saves new units in the database and enqueues the apprc serialization 
Remove Units removes n units from the app It s a process composed of multiple steps Remove units from the provisioner Update quota 
Set Unit Status changes the status of the given unit 
Update Node Status updates the status of the given node and its units returning a map which units were found during the update 
available returns true if at least one of N units is started or unreachable 
Grant allows a team to have access to an app It returns an error if the team already have access to the app 
Revoke removes the access from a team It returns an error if the team do not have access to the app 
Get Teams returns a slice of teams that have access to the app 
set Env sets the given environment variable in the app 
get Env returns the environment variable if it s declared in the app It will return an error if the variable is not defined in this app 
validate New checks app name format pool and plan 
validate checks app pool and plan 
Instance Envs returns a map of environment variables that belongs to the given service and service instance 
Run executes the command in app units sourcing apprc before running the command 
Get Units returns the internal list of units converted to bind Unit 
Get UUID returns the app v UUID An UUID will be generated if it does not exist 
Envs returns a map representing the apps environment variables 
Set Envs saves a list of environment variables in the app 
Unset Envs removes environment variables from an app serializing the remaining list of environment variables to all units of the app 
Add CName adds a CName to app It updates the attribute calls the Set CName function on the provisioner and saves the app in the database returning an error when it cannot save the change in the database or add the CName on the provisioner 
Log adds a log message to the app Specifying a good source is good so the user can filter where the message come from 
Last Logs returns a list of the last lines log of the app matching the fields in the log instance received as an example 
List returns the list of apps filtered through the filter parameter 
Swap calls the Router Swap and updates the app CName in the database 
Start starts the app calling the provisioner Start method and changing the units state to Status Started 
Get Db Driver returns the DB driver that was registered with a specific name 
Get Current Db Driver returns the DB driver specified in the configuration file If this configuration was omitted it returns the default DB driver 
title api info path info method GET produce application json responses OK 
Proxy is a proxy between tsuru and the service This method allow customized service methods 
title remove app path apps name method DELETE produce application x json stream responses App removed Unauthorized Not found 
title app list path apps method GET produce application json responses List apps No content Unauthorized 
title app info path apps name method GET produce application json responses OK Unauthorized Not found 
title app create path apps method POST consume application x www form urlencoded produce application json responses App created Invalid data Unauthorized Quota exceeded App already exists 
title app update path apps name method PUT consume application x www form urlencoded produce application x json stream responses App updated Invalid new pool Unauthorized Not found 
title set unit status path apps app units unit method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized App or unit not found 
title set node status path node status method POST consume application x www form urlencoded produce application json responses Ok Invalid data Unauthorized App or unit not found 
title grant access to app path apps app teams team method PUT responses Access granted Unauthorized App or team not found Grant already exists 
title revoke access to app path apps app teams team method DELETE responses Access revoked Unauthorized Forbidden App or team not found 
title run commands path apps app run consume application x www form urlencoded produce application x json stream method POST responses Ok Unauthorized App not found 
title get envs path apps app env method GET produce application x json stream responses OK Unauthorized App not found 
title set envs path apps app env method POST consume application x www form urlencoded produce application x json stream responses Envs updated Invalid data Unauthorized App not found 
title unset envs path apps app env method DELETE produce application x json stream responses Envs removed Invalid data Unauthorized App not found 
title set cname path apps app cname method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized App not found 
title app log path apps app log method GET produce application x json stream responses Ok Invalid data Unauthorized App not found 
title bind service instance path services service instances instance app method PUT consume application x www form urlencoded produce application x json stream responses Ok Invalid data Unauthorized App not found 
title unbind service instance path services service instances instance app method DELETE produce application x json stream responses Ok Invalid data Unauthorized App not found 
title app restart path apps app restart method POST consume application x www form urlencoded produce application x json stream responses Ok Unauthorized App not found 
title app sleep path apps app sleep method POST consume application x www form urlencoded produce application x json stream responses Ok Invalid data Unauthorized App not found 
title app log path apps app log method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized App not found 
title app swap path swap method POST consume application x www form urlencoded responses Ok Invalid data Unauthorized App not found App locked Number of units or platform don t match 
title app unlock path apps app lock method DELETE produce application json responses Ok Unauthorized App not found 
title register unit path apps app units register method POST consume application x www form urlencoded produce application json responses Ok Unauthorized App not found 
title metric envs path apps app metric envs method GET produce application json responses Ok Unauthorized App not found 
title rebuild routes path apps app routes method POST produce application json responses Ok Unauthorized App not found 
title set app certificate path apps app certificate method PUT consume application x www form urlencoded responses Ok Invalid data Unauthorized App not found 
title list app certificates path apps app certificate method GET consume application x www form urlencoded responses Ok Unauthorized App not found 
New For Config creates a new Clientset for the given config 
New For Config Or Die creates a new Clientset for the given config and panics if there is an error in the config 
New creates a new Clientset for the given RESTClient 
title remove node container list path docker nodecontainers method GET produce application json responses Ok Unauthorized 
title node container info path docker nodecontainers name method GET produce application json responses Ok Unauthorized Not found 
title node container update path docker nodecontainers name method POST consume application x www form urlencoded responses Ok Invald data Unauthorized Not found 
title remove node container path docker nodecontainers name method DELETE responses Ok Unauthorized Not found 
Get App From Unit ID returns app from unit id 
Validate Length checks whether the given data match the given rules It checks if the value has more or equal min chars and less or equal max chars If you don t want to check both just pass a zero value Validate Length value Checks if value has at most characters Validate Length value Checks if value has at least characters Validate Length value Checks if value has at least characters and at most characters 
New Pipeline creates a new pipeline instance with the given list of actions 
Result returns the result of the last action 
Execute executes the pipeline The execution starts in the forward phase calling the Forward function of all actions If none of the Forward calls return error the pipeline execution ends in the forward phase and is committed If any of the Forward calls fails the executor switches to the backward phase roll back and call the Backward function for each action completed It does not call the Backward function of the action that has failed After rolling back all completed actions it returns the original error returned by the action that failed 
Traverses recursively both values assigning src s fields values to dst The map argument tracks comparisons that have already been seen which allows short circuiting on recursive types 
Map sets fields values in dst from src src can be a map with string keys or a struct dst must be the opposite if src is a map dst must be a valid pointer to struct If src is a struct dst must be map string interface It won t merge unexported private fields and will do recursively any exported field If dst is a map keys will be src fields names in lower camel case Missing key in src that doesn t match a field in dst will be skipped This doesn t apply if dst is a map This is separated method from Merge because it is cleaner and it keeps sane semantics merging equal types mapping different restricted types 
Map With Overwrite will do the same as Map except that non empty dst attributes will be overridden by non empty src attribute values Deprecated Use Map with With Override 
Traverses recursively both values assigning src s fields values to dst The map argument tracks comparisons that have already been seen which allows short circuiting on recursive types 
Merge will fill any empty for value type attributes on the dst struct using corresponding src attributes if they themselves are not empty dst and src must be valid same type structs and dst must be a pointer to struct It won t merge unexported private fields and will do recursively any exported field 
Merge With Overwrite will do the same as Merge except that non empty dst attributes will be overriden by non empty src attribute values Deprecated use Merge with With Override 
Decode Json Payload reads the request body and decodes the JSON using json Unmarshal 
Base Url returns a new URL object with the Host and Scheme taken from the request without the trailing slash in the host 
Url For returns the URL object from Uri Base with the Path set to path and the query string built with query Params 
Get Cors Info derives Cors Info from Request 
Middleware Func makes Cors Middleware implement the Middleware interface 
Middleware Func makes Recorder Middleware implement the Middleware interface 
Record the status code 
Make sure the local Write is called 
Call the parent Close Notify Provided in order to implement the http Close Notifier interface 
Make sure the local Write Header is called and call the parent Write Provided in order to implement the http Response Writer interface 
Make Router returns the router app Given a set of Routes it dispatches the request to the Handler Func of the first route that matches The order of the Routes matters 
Handle the REST routing and run the user code 
This is run for each new request perf is important 
This is run at init time only 
This validates the Routes and prepares the Trie data structure It must be called once the Routes are defined and before trying to find Routes The order matters if multiple Routes match the first defined will be used 
return the result that has the route defined the earliest 
Return the first matching Route and the corresponding parameters for a given URL object 
Parse the url string complete or just the path and return the first matching Route and the corresponding parameters 
Middleware Func makes Content Type Checker Middleware implement the Middleware interface 
Error produces an error response in JSON with the following structure Error My error message The standard plain text net http Error helper can still be called like this http Error w error message code 
Provided in order to implement the http Close Notifier interface 
Middleware Func makes Access Log Apache Middleware implement the Middleware interface 
Convert the Apache access log format into a text template 
Execute the text template with the data derived from the request and return a string 
As stored by the auth middlewares 
If qs exists then return it with a leadin apache log style 
When the request entered the timer middleware 
If remote Addr is set then return is without the port number apache log style 
As recorded by the recorder middleware 
As mesured by the timer middleware 
As recorded by the recorder middleware 
Middleware Func makes Json Indent Middleware implement the Middleware interface 
Replace the parent Encode Json to provide indentation 
Call the parent Write Header 
Call the parent Close Notify Provided in order to implement the http Close Notifier interface 
Make sure the local Write Header is called and call the parent Write Provided in order to implement the http Response Writer interface 
Make Path generates the path corresponding to this Route and the provided path parameters This is used for reverse route resolution 
Head is a shortcut method that instantiates a HEAD route See the Route object the parameters definitions Equivalent to Route HEAD path Exp handler Func 
Middleware Func makes Recover Middleware implement the Middleware interface 
Wrap Middlewares calls the Middleware Func methods in the reverse order and returns an Handler Func ready to be executed This can be used to wrap a set of middlewares post routing on a per Route basis 
Handle the transition between net http and go json rest objects It intanciates the rest Request and rest Response Writer 
Middleware Func makes Timer Middleware implement the Middleware interface 
Middleware Func makes Gzip Middleware implement the Middleware interface 
Set the right headers for gzip encoded responses 
Call the parent Close Notify Provided in order to implement the http Close Notifier interface 
Provided in order to implement the http Hijacker interface 
Make sure the local Write Header is called and encode the payload if necessary Provided in order to implement the http Response Writer interface 
Middleware Func makes Auth Basic Middleware implement the Middleware interface 
Middleware Func makes Timer Middleware implement the Middleware interface 
Private function for now 
Insert the route in the Trie following or creating the nodes corresponding to the path 
Private function for now 
Given a path and an http method return all the matching routes 
Same as Find Routes but return in addition a boolean indicating if the path was matched Useful to return 
Given a path and whatever the http method return all the matching routes 
Use pushes one or multiple middlewares to the stack for middlewares maintained in the Api object 
Make Handler wraps all the Middlewares of the stack and the App together and returns an http Handler ready to be used If the Middleware stack is empty the App is used directly If the App is nil a Handler Func that does nothing is used instead 
Middleware Func makes Powered By Middleware implement the Middleware interface 
Middleware Func makes Status Middleware implement the Middleware interface 
Get Status computes and returns a Status object based on the request informations accumulated since the start of the process 
Middleware Func returns a Handler Func that implements the middleware 
Overwrite the Content Type to be text javascript 
Make sure the local Write is called 
Make sure the local Write Header is called and call the parent Flush Provided in order to implement the http Flusher interface 
Call the parent Close Notify Provided in order to implement the http Close Notifier interface 
Middleware Func makes Access Log Json Middleware implement the Middleware interface 
Init validates the provided config 
Fetch the binary from S 
Run executes overseer if an error is encountered overseer fallsback to running the program directly unless Required is set 
sanity Check returns true if a check was performed 
convert your main into a prog state prog is run in a child process 
then create another main which runs the upgrades main is run in the initial process 
non blocking trigger close 
fetch Loop is run in a goroutine 
not a real fork 
Init validates the provided config 
Fetch the binary from the provided Repository 
Init sets the Path and Interval options 
Fetch file from the specified Path 
Init validates the provided config 
Fetch the binary from the provided URL 
New Config returns a new configuration instance with sane defaults 
Validate checks a Config instance It will return a sarama Configuration Error if the specified values don t make sense 
New Client creates a new client instance 
Async Close implements Partition Consumer 
Close implements Partition Consumer 
Mark Offset implements Partition Consumer 
New Consumer initializes a new consumer 
New Consumer From Client initializes a new consumer from an existing client Please note that clients cannot be shared between consumers due to Kafka internals they can only be re used which requires the user to call Close on the first consumer before using this method again to initialize another one Attempts to use a client with more than one consumer at a time will return errors 
Mark Partition Offset marks an offset of the provided topic partition as processed See Mark Offset for additional explanation 
Mark Offsets marks stashed offsets as processed See Mark Offset for additional explanation 
Reset Offset marks the provided message as processed alongside a metadata string that represents the state of the partition consumer at that point in time The metadata string can be used by another consumer to restore that state so it can resume consumption Difference between Reset Offset and Mark Offset is that it allows to rewind to an earlier offset 
Reset Partition Offset marks an offset of the provided topic partition as processed See Reset Offset for additional explanation 
Commit Offsets allows to manually commit previously marked offsets By default there is no need to call this function as the consumer will commit offsets automatically using the Config Consumer Offsets Commit Interval setting Please be aware that calling this function during an internal rebalance cycle may return broker errors e g sarama Err Unknown Member Id or sarama Err Illegal Generation 
Close safely closes the consumer and releases all resources 
heartbeat loop triggered by the main Loop 
topic watcher loop triggered by the main Loop 
commit loop triggered by the main Loop 
Releases the consumer and commits offsets called from rebalance and Close 
 Performs a heartbeat part of the main Loop 
Performs a rebalance part of the main Loop 
Performs the subscription part of the main Loop 
 Send a request to the broker to join group on rebalance 
Send a request to the broker to sync the group on rebalance Returns a list of topics and partitions to consume 
Fetches latest committed offsets for all subscriptions 
Send a request to the broker to leave the group on failes rebalance and on Close 
Mark Offset stashes the provided message offset 
Mark Partition Offset stashes the offset for the provided topic partition combination 
Reset Offset stashes the provided message offset See Reset Partition Offset for explanation 
Offsets returns the latest stashed offsets by topic partition 
Actual is used to build a cluster based on instances on the cloud provider 
Expected is used to build a cluster expected to be on the cloud provider 
Apply is used to create the expected resources on the cloud provider 
Delete is used to delete the instances on the cloud provider 
Get Reconciler gets the correct Reconciler for the cloud provider currenty used 
Get Version returns Kubicorn version 
Get Version JSON returns Kubicorn version in JSON format 
Actual returns the actual resource group in Azure if it exists 
Expected will return the expected resource group as it would be defined in Azure 
Create Cmd represents create command 
Run Create is the starting point when a user runs the create command 
New Centos Cluster creates a simple Cent OS Amazon cluster 
Cluster Model maps cluster info to Digital Ocean Resources 
New Controller Ubuntu Cluster creates a simple Ubuntu Amazon cluster 
Read From Resource reads a file from different sources at the moment suppoted resources are http http local file system POSIX 
Swalker Write is a convenience wrapper around swalker Write that automatically converts value to an appropriate int uint or bool type based on the destination field s type if appropriate 
New Centos Cluster creates a basic Cent OS Digital Ocean cluster 
New Sdk is used to create a Sdk client to connect to the cloud provider 
New Ubuntu Cluster creates a basic Azure cluster profile to bootstrap Kubernetes 
Provider Config is a convenience method that will attempt to return a Control Plane Provider Config for a cluster This is useful for managing the legacy API in a clean way This will ignore errors from json Unmarshal and will simply return an empty config 
Set Provider Config is a convenience method that will attempt to set a provider config on a particular cluster Just like it s counterpart Provider Config this makes working with the legacy API much easier 
Machine Provider Configs will return all Machine Provider Configs for a cluster 
Set Machine Provider Config will attempt to match a provider config to a machine set on the Name field If a match cannot be made we warn and move on 
New Cluster will initialize a new Cluster 
Deploy Controller Cmd represents the apply command 
New Retrier creates a new Retrier using given properties 
Run Retry runs a retryable function 
Must Generate Random Bytes generates random bytes or panics if it can t 
Generate Random Bytes 
Generate random number in n 
Generate random number in n 
Explain Cmd represents the explain command 
Time Ordered UUID generates a time ordered UUID Top b are timestamp bottom b are random 
Get Config Cmd represents the apply command 
Prompt Cmd represents the kubicorn interactive prompt 
Run Annotated annotates a task with a description and a sequence of symbols indicating task activity until it terminates 
logs a sequence of symbols one for each tick indicating task activity until a quit is received 
List Cmd represents the list command 
New Ubuntu Cluster creates a simple Ubuntu Amazon cluster 
New Controller Ubuntu Cluster creates a simple Ubuntu Amazon cluster 
New Sdk constructs a new Openstack SDK for the specified region The following environment variable list is looked up in the user environment in order to authenticate to the cloud operator OS AUTH URL OS USERNAME OS USERID OS PASSWORD OS TENANT ID OS TENANT NAME OS DOMAIN ID OS DOMAIN NAME Note that only a susbset of these has to be set since most variables derive from one another to allow using either names or ids 
Edit Cmd represents edit command 
Remove Key removes an existing key from keyring 
Remove Key Using File removes an existing key from keyring given a file 
Actual calls DO firewall Api and returns the actual state of firewall in the cloud 
Expected returns the Firewall structure of what is Expected 
Apply will compare the actual and expected firewall config if needed it will create the firewall 
Delete removes the firewall 
Delete Cmd represents the delete command 
New State Store returns cluster Storer object based on type 
Performs a git commit and push of the current cluster changes 
Apply Cmd represents the apply command 
get Git Hub Url will build a query able URL from a bootstrap script that we can parse in at runtime Example URL https raw githubusercontent com kubicorn bootstrap master amazon k s centos master sh 
Prompt Cmd represents the kubicorn interactive prompt 
Expand Path returns working directory path 
Completion Cmd represents the completion command 
Adopt Cmd represents the adopt command 
Str Env Def get environment variable or some default def 
Int Env Def get environment variable or some default def 
Bool Env Def get environemnt variable and return bool 
read From FS reads file from a local path and returns as string 
Version Cmd represents the version command 
New Signal Handler creates a new Handler using given properties 
Register starts handling signals 
New Sdk is used to create a Sdk client to connect to the cloud provider 
New Ubuntu Cluster creates a simple Ubuntu Openstack cluster 
read From HTTP reads file from a http url it s up the caller to make sure source Path has been tested against url Parse Request URI 
Beginning Of Hour beginning of hour 
Beginning Of Day beginning of day 
Beginning Of Week beginning of week 
Beginning Of Month beginning of month 
Beginning Of Quarter beginning of quarter 
Beginning Of Year Beginning Of Year beginning of year 
End Of Minute end of minute 
End Of Hour end of hour 
End Of Day end of day 
End Of Week end of week 
End Of Month end of month 
End Of Quarter end of quarter 
End Of Year end of year 
Sunday sunday 
Parse parse string to time 
Must Parse must parse string to time or it will panic 
Between check time between the begin end time or not 
Parse parse string to time 
Parse In Location parse string to time in location 
Must Parse must parse string to time or will panic 
Must Parse In Location must parse string to time in location or will panic 
Between check now between the begin end time or not 
Log implements the Log method required by Backend 
New Channel Memory Backend creates a simple in memory logging backend which utilizes a go channel for communication Start will automatically be called by this function 
Start launches the internal goroutine which starts processing data from the input channel 
Flush waits until all records in the buffered channel have been processed 
Stop signals the internal goroutine to exit and waits until it have 
Log implements the Log method required by Backend 
Formatted returns the formatted log record string 
Message returns the log record message 
Set Backend overrides any previously defined backend for this logger 
Must Get Logger is like Get Logger but panics if the logger can t be created It simplifies safe initialization of a global logger for eg a package 
Reset restores the internal state of the logging library 
Is Enabled For returns true if the logger is enabled for the given level 
Fatal is equivalent to l Critical fmt Sprint followed by a call to os Exit 
Fatalf is equivalent to l Critical followed by a call to os Exit 
Panic is equivalent to l Critical fmt Sprint followed by a call to panic 
Panicf is equivalent to l Critical followed by a call to panic 
Criticalf logs a message using CRITICAL as log level 
Warningf logs a message using WARNING as log level 
Noticef logs a message using NOTICE as log level 
Infof logs a message using INFO as log level 
New Log Backend creates a new Log Backend 
set Console Text Attribute sets the attributes of characters written to the console screen buffer by the Write File or Write Console function See http msdn microsoft com en us library windows desktop ms v vs aspx 
Set Formatter sets the default formatter for all new backends A backend will fetch this value once it is needed to format a record Note that backends will cache the formatter after the first point For now make sure to set the formatter before logging 
New String Formatter returns a new Formatter which outputs the log record as a string based on the verbs specified in the format string The verbs General id Sequence number for log message uint pid Process id int time Time when log occurred time Time level Log level Level module Module string program Basename of os Args string message Message string longfile Full file name and line number a b c d go shortfile Final file name element and line number d go callpath Callpath like main a b c c meaning recursive call meaning truncated path color ANSI color based on log level For normal types the output can be customized by using the verbs defined in the fmt package eg id d to make the id output be d as the format string For time Time use the same layout as time Format to change the time format when output eg T Z For the color verb the output can be adjusted to either use bold colors i e color bold or to reset the ANSI attributes i e color reset Note that if you use the color verb explicitly be sure to reset it or else the color state will persist past your log message e g color bold time level s color reset message will just colorize the time and level leaving the message uncolored For the callpath verb the output can be adjusted to limit the printing the stack depth i e callpath will print a b c Colors on Windows is unfortunately not supported right now and is currently a no op There s also a couple of experimental verbs These are exposed to get feedback and needs a bit of tinkering Hence they might change in the future Experimental longpkg Full package path eg github com go logging shortpkg Base package path eg go logging longfunc Full function name eg little Endian Put Uint shortfunc Base function name eg Put Uint callpath Call function path eg main a b c 
Must String Formatter is equivalent to New String Formatter with a call to panic on error 
format Func Name tries to extract certain part of the runtime formatted function name to some pre defined variation This function is known to not work properly if the package path or name contains a dot 
Log implements the Log function required by the Backend interface 
Log Level returns the log level from a string representation 
Add Module Level wraps a log backend with knobs to have different log levels for different modules 
Get Level returns the log level for the given module 
Set Level sets the log level for the given module 
Is Enabled For will return true if logging is enabled for the given module 
Multi Logger creates a logger which contain multiple loggers 
Log passes the log record to all backends 
Get Level returns the highest level enabled by all backends 
Set Level propagates the same level to all backends 
Is Enabled For returns true if any of the backends are enabled for it 
New Log Backend creates a new Log Backend 
Log implements the Backend interface 
Convert Colors takes a list of ints representing colors for log levels and converts them into strings for ANSI color formatting 
New Syslog Backend connects to the syslog daemon using UNIX sockets with the given prefix If prefix is not given the prefix will be derived from the launched command 
New Syslog Backend Priority is the same as New Syslog Backend but with custom syslog priority like syslog LOG LOCAL syslog LOG DEBUG etc 
Log implements the Backend interface 
Set Backend replaces the backend currently set with the given new logging backend 
New Commander returns a new commander with the specified top level flags and command name The Usage function for the top Level Flags will be set as well 
Register adds a subcommand to the supported subcommands in the specified group Help output is sorted and arranged by group name The empty string is an acceptable group name such subcommands are explained first before named groups 
Important Flag marks a top level flag as important which means it will be printed out as part of the output of an ordinary help subcommand All flags important or not are printed by the flags subcommand 
Execute should be called once the top level flags on a Commander have been initialized It finds the correct subcommand and executes it and returns an Exit Status with the result On a usage error an appropriate message is printed to os Stderr and Exit Usage Error is returned The additional args are provided as is to the Execute method of the selected Command 
explain prints a brief description of all the subcommands and the important top level flags 
explain Group explains all the subcommands for a particular group 
explain Cmd prints a brief description of a single command 
dealias recursivly dealiases a command until a non aliased command is reached 
Execute should be called once the default flags have been initialized by flag Parse It finds the correct subcommand and executes it and returns an Exit Status with the result On a usage error an appropriate message is printed to os Stderr and Exit Usage Error is returned The additional args are provided as is to the Execute method of the selected Command It is a wrapper around Default Commander Execute 
Read reads an io Reader and returns a configuration representation This representation can be queried with Get Value 
Load From Data accepts raw data directly from memory and returns a new configuration representation Note that the configuration is written to the system temporary folder so your file should not contain sensitive information 
Load From Reader accepts raw data directly from a reader and returns a new configuration representation You must use Reload Data to reload You cannot append files a configfile read this way 
Reload Data reloads configuration file from memory 
Append Files appends more files to Config File and reload automatically 
Get Key List returns the list of all keys in give section in the same order in the file It returns nil if given section does not exist 
Save Config Data writes configuration to a writer 
Save Config File writes configuration file to local file system 
Find finds exactly one element by CSS selector 
Find By XPath finds exactly one element by XPath selector 
Find By Link finds exactly one anchor element by its text content 
Find By Label finds exactly one element by associated label text 
Find By Button finds exactly one button element with the provided text Supports button input type button and input type submit 
Find By Name finds exactly element with the provided name attribute 
Find By Class finds exactly one element with a given CSS class 
Find By ID finds exactly one element that has the given ID 
First finds the first element by CSS selector 
First By XPath finds the first element by XPath selector 
First By Link finds the first anchor element by its text content 
First By Label finds the first element by associated label text 
First By Button finds the first button element with the provided text Supports button input type button and input type submit 
First By Name finds the first element with the provided name attribute 
All finds zero or more elements by CSS selector 
All By XPath finds zero or more elements by XPath selector 
All By Link finds zero or more anchor elements by their text content 
All By Label finds zero or more elements by associated label text 
All By Button finds zero or more button elements with the provided text Supports button input type button and input type submit 
All By Name finds zero or more elements with the provided name attribute 
All By Class finds zero or more elements with a given CSS class 
All By ID finds zero or more elements with a given ID 
First By Class finds the first element with a given CSS class 
Timeout provides an Option for specifying a timeout in seconds 
Chrome Options is used to pass additional options to Chrome via Chrome Driver 
HTTPClient provides an Option for specifying a http Client 
New Page opens a Page using the provided Web Driver URL This method takes the same Options as Web Driver New Page Unlike Web Driver New Page this method will respect the HTTPClient Option if provided 
Join Page creates a Page using existing session URL This method takes Options but respects only the HTTPClient Option if provided 
Destroy closes any open browsers by ending the session 
Reset deletes all cookies set for the current domain and navigates to a blank page Unlike Destroy Reset will permit the page to be re used after it is called Reset is faster than Destroy but any cookies from domains outside the current domain will remain after a page is reset 
Navigate navigates to the provided URL 
Get Cookies returns all cookies on the page 
Set Cookie sets a cookie on the page 
Delete Cookie deletes a cookie on the page by name 
Clear Cookies deletes all cookies on the page 
URL returns the current page URL 
Size sets the current page size in pixels 
Screenshot takes a screenshot and saves it to the provided filename The provided filename may be an absolute or relative path 
Title returns the page title 
HTML returns the current contents of the DOM for the entire page 
Run Script runs the Java Script provided in the body Any keys present in the arguments map will be available as variables in the body Values provided in arguments are converted into javascript objects If the body returns a value it will be unmarshalled into the result argument Simple example var number int page Run Script return test map string interface test number fmt Println number 
Popup Text returns the current alert confirm or prompt popup text 
Enter Popup Text enters text into an open prompt popup 
Confirm Popup confirms an alert confirm or prompt popup 
Cancel Popup cancels an alert confirm or prompt popup 
Switch To Parent Frame focuses on the immediate parent frame of a frame selected by Selection Frame After switching all new and existing selections will refer to the parent frame All further Page methods will apply to this frame as well This method is not supported by Phantom JS Please use Switch To Root Frame instead 
Switch To Root Frame focuses on the original default page frame before any calls to Selection Frame were made After switching all new and existing selections will refer to the root frame All further Page methods will apply to this frame as well 
Switch To Window switches to the first available window with the provided name Java Script window name attribute 
Next Window switches to the next available window 
Close Window closes the active window 
Window Count returns the number of available windows 
Log Types returns all of the valid log types that may be used with a Log Reader 
Read New Logs returns new log messages of the provided log type For example page Read New Logs browser returns browser console logs such as Java Script logs and errors Only logs since the last call to Read New Logs are returned Valid log types may be obtained using the Log Types method 
Read All Logs returns all log messages of the provided log type For example page Read All Logs browser returns browser console logs such as Java Script logs and errors All logs since the session was created are returned Valid log types may be obtained using the Log Types method 
Move Mouse By moves the mouse by the provided offset 
Double Click double clicks the left mouse button at the current mouse position 
Click performs the provided Click event using the provided Button at the current mouse position 
Set Implicit Wait sets the implicit wait timeout in ms 
Set Page Load sets the page load timeout in ms 
Set Script Timeout sets the script timeout in ms 
New Web Driver returns an instance of a Web Driver specified by a templated URL and command The URL should be the location of the Web Driver Wire Protocol web service brought up by the command The command should be provided as a list of arguments each of which are templated The Timeout Option specifies how many seconds to wait for the web service to become available The default timeout is seconds The HTTPClient Option specifies a http Client to use for all Web Driver communications The default client is http Default Client Any other provided Options are treated as default Options for new pages Valid template parameters are Host local address to bind to usually Port arbitrary free port on the local address Address Host Port Selenium JAR example command string java jar selenium server jar port Port agouti New Web Driver http Address wd hub command 
New Page returns a Page that corresponds to a new Web Driver session Provided Options configure the page For instance to disable Java Script capabilities agouti New Capabilities Without javascript Enabled driver New Page agouti Desired capabilities For Selenium a Browser Option or a Desired Option with Capabilities that specify a Browser must be provided For instance selenium Driver New Page agouti Browser safari Specific Options such as Browser have precedence over Capabilities specified by the Desired Option The HTTPClient Option will be ignored if passed to this function New pages will always use the http Client provided to their Web Driver or http Default Client if none was provided 
Click clicks on all of the elements that the selection refers to 
Double Click double clicks on all of the elements that the selection refers to 
Fill fills all of the fields the selection refers to with the provided text 
Upload File uploads the provided file to all selected input type file The provided filename may be a relative or absolute path Returns an error if elements of any other type are in the selection 
Select may be called on a selection of any number of select elements to select any option elements under those select elements that match the provided text 
Tap performs the provided Tap event on each element in the selection 
Touch performs the provided Touch event at the location of each element in the selection 
Flick Finger performs a flick touch action by the provided offset and at the provided speed on exactly one element 
Scroll Finger performs a scroll touch action by the provided offset on exactly one element 
At finds an element at the provided index It only applies to the immediate selection meaning that the returned selection may still refer to multiple elements if any parent of the immediate selection is also a Multi Selection 
New Capabilities returns a Capabilities instance with any provided features enabled 
With enables the provided feature ex trust All SSLCertificates 
Without disables the provided feature ex javascript Enabled 
JSON returns a JSON string representing the desired capabilities 
Have Title passes when the expected title is equivalent to the title of the provided page 
Have URL passes when the expected URL is equivalent to the current URL of the provided page 
Have Popup Text passes when the expected text is equivalent to the text contents of an open alert confirm or prompt popup 
Have Logged Error passes when all of the expected log messages are logged as errors in the browser console If no message is provided this matcher will pass if any error message has been logged When negated this matcher will only fail if all of the provided messages are logged 
Text returns the entirety of the text content for exactly one element 
Active returns true if the single element that the selection refers to is active 
Attribute returns an attribute value for exactly one element 
CSS returns a CSS style property value for exactly one element 
Selected returns true if all of the elements that the selection refers to are selected 
Visible returns true if all of the elements that the selection refers to are visible 
Enabled returns true if all of the elements that the selection refers to are enabled 
Have Count passes when the expected element count is equal to the actual number of elements in the selection 
Have Attribute passes when the expected attribute and value are present on the element This matcher will fail if the provided selection refers to more than one element 
Have CSS passes when the expected CSS property and value are present on the element This matcher only matches exact calculated CSS values though there is support for parsing colors Example blue and f will both match rgba This matcher will fail if the provided selection refers to more than one element 
Phantom JS returns an instance of a Phantom JS Web Driver Provided Options will apply as default arguments for new pages New pages will accept invalid SSL certificates by default This may be disabled using the Reject Invalid SSL Option The Reject Invalid SSL Option must be provided to the Phantom JS function and not the New Page method for this Option to take effect on any Phantom JS page 
Edge Driver returns an instance of a Edge Driver Web Driver Provided Options will apply as default arguments for new pages New pages will accept invalid SSL certificates by default This may be disabled using the Reject Invalid SSL Option 
Selendroid returns an instance of a Selendroid Web Driver Provided Options will apply as default arguments for new pages New pages will accept invalid SSL certificates by default This may be disabled using the Reject Invalid SSL Option The jar File is a relative or absolute path to Selendroid JAR file Selendroid will return nil if an invalid path is provided 
Sauce Labs opens a Sauce Labs session and returns a Page Does not support Sauce Connect This method takes the same Options as New Page Passing the Desired Option will completely override the provided name platform browser and version 
Gecko Driver returns an instance of a geckodriver Web Driver which supports gecko based brwoser like Firefox Provided Options will apply as default arguments for new pages See https github com mozilla geckodriver for geckodriver details 
Switch To Frame focuses on the frame specified by the selection All new and existing selections will refer to the new frame All further Page methods will apply to this frame as well 
Elements returns a api Element that can be used to send direct commands to Web Driver elements See https code google com p selenium wiki Json Wire Protocol 
Count returns the number of elements that the selection refers to 
Equals Element returns whether or not two selections of exactly one element refer to the same element 
Mouse To Element moves the mouse over exactly one element in the selection 
Validate checks that the minimum fields are provided Deprecated This map be deleted after the native library replaces Ruby deps and should not be used outside of this library 
logging Middleware logs requests to the proxy 
chain Handlers takes a set of middleware and joins them together into a single Middleware making it much simpler to compose middleware together 
HTTPReverse Proxy provides a default setup for proxying internal components within the framework 
Check Installation checks installation of all of the tools 
Check Version checks installation of a given binary using semver compatible comparisions 
Get Version For Binary gets the version of a given Ruby binary 
get User finds a user 
Login handles the login API call to the User Service 
Deal with the login request 
Deal with the logout request 
Show the current user if logged in otherwise display a login form 
Run the web application 
Given specifies a provider state Optional 
Upon Receiving specifies the name of the test case This becomes the name of the consumer provider pair in the Pact file Mandatory 
With Request specifies the details of the HTTP request that will be used to confirm that the Provider provides an API listening on the given interface Mandatory 
Will Respond With specifies the details of the HTTP response that will be used to confirm that the Provider must satisfy Mandatory 
Checks to see if someone has tried to submit a JSON string for an object which is no longer supported 
By Username finds a user by their username 
By ID finds a user by their ID 
Simple authentication middleware 
User Login logs a user in returning an auth token and the user object 
Get User fetches a user if authenticated and exists 
new Client creates a new Pact client manager with the provided services 
New Client creates a new Pact client manager with defaults 
Start Server starts a remote Pact Mock Server 
List Servers lists all known Mock Servers 
Stop Server stops a remote Pact Mock Server 
Remove All Servers stops all remote Pact Mock Servers 
Verify Provider runs the verification process against a running Provider TODO extract refactor the stdout error streaems from these functions 
Update Message Pact adds a pact message to a contract file 
Publish Pacts publishes a set of pacts to a pact broker 
Reify Message takes a structured object potentially containing nested Matchers and returns an object with just the example generated content The object may be a simple JSON primitive e g string or number or a complex object 
Get a port given a URL 
Get the address given a URL 
sanitise Ruby Response removes Ruby isms from the response content making the output much more human readable 
Stop a Service and returns the exit status 
Start a Service and log its output 
New Service creates a new Publish Service with default settings Arguments allowed provider base url pact urls provider states url provider states setup url broker username broker password publish verification results provider app version custom provider headers 
New Service creates a new Message Service with default settings Named Arguments allowed consumer provider pact dir 
Validate checks all things are well and constructs the CLI args to the message service 
Publish sends the Pacts to a broker optionally tagging them 
Validate checks that the minimum fields are provided Deprecated This map be deleted after the native library replaces Ruby deps and should not be used outside of this library 
Validate checks that the minimum fields are provided Deprecated This map be deleted after the native library replaces Ruby deps and should not be used outside of this library 
Find Port In Range Iterate through CSV or Range of ports to find open port Valid inputs are Do not combine list and range 
Each Like specifies that a given element in a JSON body can be repeated min Required times Number needs to be or greater 
Term specifies that the matching should generate a value and also match using a regular expression 
Unmarshal JSON is a custom JSON parser for Map Matcher It treats the matchers as strings 
Takes an object and converts it to a JSON representation 
match recursively traverses the provided type and outputs a matcher string for it that is compatible with the Pact dsl 
pluck Params converts a pact tag into a pact Params struct Supported Tag Formats Minimum Slice Size pact min String Reg Ex pact example regex d d d 
Add Message creates a new asynchronous consumer expectation 
Add Interaction creates a new Pact interaction initialising all required things Will automatically start a Mock Service if none running 
Setup starts the Pact Mock Server This is usually called before each test suite begins Add Interaction will automatically call this if no Mock Server has been started 
Configure logging 
Teardown stops the Pact Mock Server This usually is called on completion of each test suite 
Verify runs the current test case against a Mock Service Will cleanup interactions between tests within a suite 
Write Pact should be called writes when all tests have been performed for a given Consumer Provider pair It will write out the Pact to the configured file 
Verify Provider Raw reads the provided pact files and runs verification against a running Provider API providing raw response from the Verification process Order of events Before Each state Handlers request Filter pre execute provider post After Each 
Verify Provider accepts an instance of testing T running the provider verification with granular test reporting and automatic failure reporting for nice simple tests 
After Each Middleware is invoked after any other and is the last function to be called prior to returning to the test suite It is therefore not invoked on setup 
state Handler Middleware responds to the various states that are given during provider verification statehandler accepts a state object from the verifier and executes any state handlers associated with the provider It will not execute further middleware if it is the designted state request 
Verify Message Provider accepts an instance of testing T running provider message verification with granular test reporting and automatic failure reporting for nice simple tests A Message Producer is analagous to Consumer in the HTTP Interaction model It is the initiator of an interaction and expects something on the other end of the interaction to respond just in this case not immediately 
Verify Message Provider Raw runs provider message verification A Message Producer is analagous to Consumer in the HTTP Interaction model It is the initiator of an interaction and expects something on the other end of the interaction to respond just in this case not immediately 
Verify Message Consumer Raw creates a new Pact message interaction to build a testable interaction A Message Consumer is analagous to a Provider in the HTTP Interaction model It is the receiver of an interaction and needs to be able to handle whatever request was provided 
Verify Message Consumer is a test convience function for Verify Message Consumer Raw accepting an instance of testing T 
Start Server starts a remote Pact Mock Server 
Stop Server stops a remote Pact Mock Server 
Remove All Servers stops all remote Pact Mock Servers 
Verify Provider runs the verification process against a running Provider 
Reify Message takes a structured object potentially containing nested Matchers and returns an object with just the example generated content The object may be a simple JSON primitive e g string or number or a complex object 
New Service creates a new Mock Service with default settings 
Setup the Management services 
add Service Monitor watches a channel to add services into operation 
remove Service Monitor watches a channel to remove services from operation 
Stop a Service and returns the exit status 
List all Service PIDs 
Command creates an os command to be run 
Start a Service and log its output 
call sends a message to the Pact service 
Delete Interactions removes any previous Mock Service Interactions 
Add Interaction adds a new Pact Mock Service interaction 
Write Pact writes the pact file to disk 
Given specifies a provider state Optional 
Expects To Receive specifies the content it is expecting to be given from the Provider The function must be able to handle this message for the interaction to succeed 
With Metadata specifies message implementation specific metadata to go with the content 
As Type specifies that the content sent through to the consumer handler should be sent as the given type 
Simple authentication middleware 
User Login is the login route 
Get User fetches a user if authenticated and exists 
Validate checks all things are well and constructs the CLI args to the message service 
New Service creates a new Verification Service with default settings Arguments allowed provider base url pact urls provider states url provider states setup url broker username broker password publish verification results provider app version custom provider headers 
Region returns the service region infering it from S domain 
New Returns a new S domain defaults to Default Domain if empty 
Bucket returns a bucket on s Bucket Config is initialized to Default Config 
Get Reader provides a reader and downloads data using parallel ranged get requests Data from the requests are ordered and written sequentially Data integrity is verified via the option specified in c Header data from the downloaded object is also returned useful for reading object metadata Default Config is used if c is nil Callers should call Close on r to ensure that all resources are released To specify an object version in a versioned bucket the version ID may be included in the path as a url parameter See http docs aws amazon com Amazon S latest dev Retrieving Object Versions html 
Put Writer provides a writer to upload data as multipart upload requests Each header in h is added to the HTTP request header This is useful for specifying options such as server side encryption in metadata as well as custom user metadata Default Config is used if c is nil Callers should call Close on w to ensure that all resources are released 
url returns a parsed url to the given path c must not be nil 
Delete deletes the key at path If the path does not exist Delete returns nil no error 
Set Logger wraps the standard library log package It allows the internal logging of s gof r to be set to a desired output and format Setting debug to true enables debug logging output s gof r does not log output by default 
Initialize internal logger to log to no op ioutil Discard by default 
Instance Keys Requests the AWS keys from the instance based metadata on EC Assumes only one IAM role 
Env Keys Reads the AWS keys from the environment 
Client With Timeout is an http client optimized for high throughput to S It times out more agressively than the default http client in net http as well as setting deadlines on the TCP connection 
Sign signs the http Request 
get AWSKeys gets the AWS Keys from environment variables or the instance based metadata on EC Environment variables are attempted first followed by the instance based credentials 
find unix home directory 
add canned acl to http Header 
Sends an S multipart upload initiation request See http docs amazonwebservices com Amazon S latest dev mpuoverview html The initial request returns an Upload Id that we use to identify subsequent PUT requests 
Calls put Part up to n Try times to recover from transient errors 
uploads a part checking the etag against the calculated value 
Try to abort multipart upload Do not error on failure 
Md functions 
Put md file in md subdirectory of bucket where the file is stored e g the md for https mybucket s amazonaws com gof r will be stored in https mybucket s amazonaws com md gof r md 
returns true unless part Size is large enough to achieve max Obj Size with remaining parts 
Gather Info gathers information about the specified struct 
Check Disallowed checks that no environment variables with the prefix are set that we don t know how or want to parse This is likely only meaningful with a non empty prefix 
Process populates the specified struct based on environment variables 
Must Process is the same as Process but panics if an error occurs 
to Type Description converts Go types into a human readable description 
Usage writes usage information to stderr using the default header and table format 
Usagef writes usage information to the specified io Writer using the specifed template specification 
Usaget writes usage information to the specified io Writer using the specified template 
Scan implements the Scanner interface 
Value implements the driver Valuer interface 
New Time creates a new Time 
Time From Ptr creates a new Time that will be null if t is nil 
Value Or Zero returns the inner value if valid otherwise zero 
Marshal JSON implements json Marshaler It will encode null if this time is null 
Unmarshal JSON implements json Unmarshaler It supports string object e g pq Null Time and friends and null input 
Set Valid changes this Time s value and sets it to be non null 
Ptr returns a pointer to this Time s value or a nil pointer if this Time is null 
New Bool creates a new Bool 
Bool From Ptr creates a new Bool that will be null if f is nil 
Unmarshal JSON implements json Unmarshaler It supports number and null input will not be considered a null Bool It also supports unmarshalling a sql Null Bool 
Unmarshal Text implements encoding Text Unmarshaler It will unmarshal to a null Bool if the input is a blank or not an integer It will return an error if the input is not an integer blank or null 
Marshal JSON implements json Marshaler It will encode null if this Bool is null 
Set Valid changes this Bool s value and also sets it to be non null 
New String creates a new String 
Unmarshal JSON implements json Unmarshaler It supports string and null input Blank string input produces a null String It also supports unmarshalling a sql Null String 
Marshal Text implements encoding Text Marshaler It will encode a blank string when this String is null 
Unmarshal Text implements encoding Text Unmarshaler It will unmarshal to a null String if the input is a blank string 
Set Valid changes this String s value and also sets it to be non null 
String From Ptr creates a new String that be null if s is nil 
Marshal JSON implements json Marshaler It will encode null if this String is null 
New Int creates a new Int 
Int From Ptr creates a new Int that be null if i is nil 
Unmarshal JSON implements json Unmarshaler It supports number and null input will be considered a null Int It also supports unmarshalling a sql Null Int 
Marshal Text implements encoding Text Marshaler It will encode a zero if this Int is null 
Set Valid changes this Int s value and also sets it to be non null 
Unmarshal Text implements encoding Text Unmarshaler It will unmarshal to a null Int if the input is a blank or not an integer It will return an error if the input is not an integer blank or null 
Marshal Text implements encoding Text Marshaler It will encode a zero if this Bool is null 
Set Valid changes this Float s value and also sets it to be non null 
Time From Ptr creates a new Time that will be null if t is nil or t is the zero value 
Marshal JSON implements json Marshaler It will encode the zero value of time Time if this time is invalid 
Unmarshal JSON implements json Unmarshaler It supports number and null input will not be considered a null Float It also supports unmarshalling a sql Null Float 
Unmarshal Text implements encoding Text Unmarshaler It will unmarshal to a null Float if the input is a blank or not an integer It will return an error if the input is not an integer blank or null 
Marshal JSON implements json Marshaler It will encode null if this Float is null 
new Gossip Channel returns a named usable channel It delegates receiving duties to the passed Gossiper 
Gossip Unicast implements Gossip relaying msg to dst which must be a member of the channel 
Gossip Broadcast implements Gossip relaying update to all members of the channel 
Send relays data into the channel topology via random neighbours 
Send Down relays data into the channel topology via conn 
Gob Encode gob encodes each item and returns the resulting byte slice 
new Token Bucket returns a bucket containing capacity tokens refilled at a rate of one token per token Interval 
Blocks until there is a token available Not safe for concurrent use by multiple goroutines 
Determine the historic token timestamp representing a full bucket 
Prefix Range End allows Get Delete and Watch requests to operate on all keys with a matching prefix Pass the prefix to this function and use the result as the Range End value 
new Local Peer returns a usable Local Peer 
Connections returns all the connections that the local peer is aware of 
Connection To returns the connection to the named peer if any TODO pb Weave Net invokes router Ourself Connection To it may be better to provide that on Router directly 
Connections To returns all known connections to the named peers TODO pb Weave Net invokes router Ourself Connections To it may be better to provide that on Router directly 
create Connection creates a new connection originating from local Addr to peer Addr If accept New Peer is false peer Addr must already be a member of the mesh 
ACTOR client API Synchronous 
Asynchronous 
Synchronous 
ACTOR server 
helpers 
If the connection is successful it will end up in the local peer s connections map 
Send Protocol Msg implements Protocol Sender 
ACTOR methods NB The conn fields are only written by the connection actor process which is the caller of the Connection Action funs Hence we do not need locks for reading and only need write locks for fields read by other processes Non blocking 
ACTOR server 
Helpers 
New Status returns a Status object taken as a snapshot from the router 
make Peer Status Slice takes a snapshot of the state of peers 
make Unicast Route Status Slice takes a snapshot of the unicast routes in routes 
make Broadcast Route Status Slice takes a snapshot of the broadcast routes in routes 
make Local Connection Status Slice takes a snapshot of the active local connections in the Connection Maker 
make Trusted Subnets Slice makes a human readable copy of the trusted Subnets 
Range implements g RPC KVServer Range gets the keys in the range from the store 
Put implements g RPC KVServer Put puts the given key into the store A put request increases the revision of the store and generates one event in the event history 
Delete implements g RPC KVServer Delete deletes the given range from the store A delete request increase the revision of the store and generates one event in the event history 
Txn implements g RPC KVServer Txn processes all the requests in one transaction A txn request increases the revision of the store and generates events with the same revision in the event history It is not allowed to modify the same key several times within one txn 
Compact implements g RPC KVServer Compact compacts the event history in s User should compact the event history periodically or it will grow infinitely 
From public API method to proposalc 
From committed entryc back to public API method etcdserver v demo server go apply V Result 
apply Compare applies the compare request It returns the revision at which the comparison happens If the comparison succeeds the it returns true Otherwise it returns false 
Descriptions returns descriptions for all known peers 
On GC adds a new function to be set of functions that will be executed on all subsequent GC runs receiving the GC d peer 
On Invalidate Short IDs adds a new function to a set of functions that will be executed on all subsequent GC runs when the mapping from short IDs to peers has changed 
Choose an available short ID at random 
fetch With Default will use reference fields of the passed peer object to look up and return an existing matching peer If no matching peer is found the passed peer is saved and returned 
Fetch returns a peer matching the passed name without incrementing its refcount If no matching peer is found Fetch returns nil 
Like fetch but increments local refcount 
Fetch By Short ID returns a peer matching the passed short ID If no matching peer is found Fetch By Short ID returns nil 
Dereference decrements the refcount of the matching peer TODO pb this is an awkward way to use the mutex consider refactoring 
Merge an incoming update with our own topology We add peers hitherto unknown to us and update peers for which the update contains a more recent version than known to us The return value is a a representation of the received update and b an improved update containing just these new updated elements 
Garbage Collect takes a lock triggers a GC and invokes the accumulated GC callbacks 
new Routes returns a usable Routes based on the Local Peer and existing Peers 
On Change appends callback to the functions that will be called whenever the routes are recalculated 
Unicast returns the next hop on the unicast route to the named peer based on established and symmetric connections 
Unicast All returns the next hop on the unicast route to the named peer based on all connections 
Broadcast returns the set of peer names that should be notified when we receive a broadcast message originating from the named peer based on established and symmetric connections 
Broadcast All returns the set of peer names that should be notified when we receive a broadcast message originating from the named peer based on all connections 
Random Neighbours chooses min log n peers n neighbouring peers neighbours with a random distribution that is topology sensitive favouring neighbours at the end of bottleneck links We determine the latter based on the unicast routing table If a neighbour appears as the value more frequently than others meaning that we reach a higher proportion of peers via that neighbour than other neighbours then it is chosen with a higher probability Note that we choose log n peers neighbours not peers Consequently on sparsely connected peers this function returns a higher proportion of neighbours than elsewhere In extremis on peers with fewer than log n peers neighbours all neighbours are returned 
Calculate all the routes for the question if we want to send a packet to Peer X what is the next hop When we sniff a packet we determine the destination peer ourself Consequently we can relay the packet via any arbitrary peers the intermediate peers do not have to have any knowledge of the MAC address at all Thus there s no need to exchange knowledge of MAC addresses nor any constraints on the routes that we construct 
Calculate the route to answer the question if we receive a broadcast originally from Peer X which peers should we pass the frames on to When the topology is stable and thus all peers perform route calculations based on the same data the algorithm ensures that broadcasts reach every peer exactly once This is largely due to properties of the Peer Routes algorithm In particular For All X Y Z in Peers X Routes Y X Routes Z X Routes Z X Routes Y For All X Y Z in Peers Y Z X Routes Y X Routes Z X Routes Y u P Y Has Symmetric Connection To P X Routes Z where is the subset relationship on keys of the returned map 
New Peer returns a Peer which can be used as a net Packet Conn Clients must Register a mesh Gossip before calling Read From or Write To Clients should aggressively consume from Read From 
Register injects the mesh Gossip and enables full duplex communication Clients should consume from Read From without blocking 
Read From implements net Packet Conn Clients should consume from Read From without blocking 
Write To implements net Packet Conn 
Local Addr implements net Packet Conn 
On Gossip implements mesh Gossiper The buf is a single pkt 
On Gossip Broadcast implements mesh Gossiper The buf is a single pkt 
On Gossip Unicast implements mesh Gossiper The buf is a single pkt 
GRPCServer converts a metcd Server to a grpc Server 
New Server returns a Server that partially implements the etcd V API It uses the passed mesh components to act as the Raft transport For the moment it blocks until the mesh has min Peer Count peers This responsibility should rather be given to the caller The server can be terminated by certain conditions in the cluster If that happens terminatedc signaled and the server is invalid 
New Default Server is like New Server but we take care of creating a mesh Router and meshconn Peer for you with sane defaults If you need more fine grained control create the components yourself and use New Server 
Peer Name From User Input parses Peer Name from a user provided string 
Peer Name From String parses Peer Name from a generic string 
bytes encodes Peer Name as a byte slice 
Peer Name From String parses Peer Name from a generic string 
New Router returns a new router It must be started 
New Gossip returns a usable Gossip Channel from the router TODO pb rename 
Relay all pending gossip data for each channel via random neighbours 
Relay all pending gossip data for each channel via conn 
for testing 
Broadcast Topology Update is invoked whenever there is a change to the mesh topology and broadcasts the new set of peers to the mesh 
On Gossip Unicast implements Gossiper but always returns an error as a router should only receive gossip broadcasts of Topology Gossip Data 
On Gossip Broadcast receives broadcasts of Topology Gossip Data It returns the received update unchanged 
Gossip yields the current topology as Gossip Data 
On Gossip receives broadcasts of Topology Gossip Data It returns an improved version of the received update See peers Apply Update 
Merge implements Gossip Data 
Encode implements Gossip Data 
Construct an empty state object ready to receive updates This is suitable to use at program start Other peers will populate us with data 
Encode serializes our complete state to a slice of byte slices In this simple example we use a single gob encoded buffer see https golang org pkg encoding gob 
Merge merges the other Gossip Data into this one and returns our resulting complete state 
Merge the set into our state abiding increment only semantics Return a non nil mesh Gossip Data representation of the received set 
Merge the set into our state abiding increment only semantics Return any key values that have been mutated or nil if nothing changed 
Merge the set into our state abiding increment only semantics Return our resulting complete state 
On Gossip Broadcast implements Gossiper 
On Gossip should return everything new I ve just learnt surrogate Gossiper doesn t understand the content of messages but it can eliminate simple duplicates 
Merge implements Gossip Data 
Generate Key Pair is used during encrypted protocol introduction 
Form Session Key is used during encrypted protocol introduction 
New TCPCrypto State returns a valid TCPCrypto State 
Send implements TCPSender by encoding the msg 
Send implements TCPSender by writing the size of the msg as a big endian uint before the msg msgs larger than Max TCPMsg Size are rejected 
Send implements TCPSender by sealing and sending the msg as is 
Receive implements TCPReciever by Gob decoding into a byte slice directly 
Receive implements TCPReceiver by making a length limited read into a byte buffer 
Receive implements TCPReceiver by reading from the wrapped TCPReceiver and unboxing the encrypted message returning the decoded message 
Construct a peer with empty state Be sure to register a channel later so we can make outbound communication 
Increment the counter by one 
Return a copy of our complete state 
Merge the gossiped data represented by buf into our state Return the state information that was modified 
Merge the gossiped data represented by buf into our state Return the state information that was modified 
Merge the gossiped data represented by buf into our state 
make Raft Peer converts a net Addr into a raft Peer All peers must perform the Addr to Peer mapping in the same way The etcd Raft implementation tracks the committed entry for each node ID and panics if it discovers a node has lost previously committed entries In effect it assumes commitment implies durability But our storage is explicitly non durable So whenever a node restarts we need to give it a brand new ID That is the peer UID 
String returns the peer name and nickname 
Routes calculates the routing table from this peer to all peers reachable from it returning a next hop map of Peer Name X Peer Name Y which says in order to send a message to X the peer should send the message to its neighbour Y Because currently we do not have weightings on the connections between peers there is no need to use a minimum spanning tree algorithm Instead we employ the simpler and cheaper breadth first widening The computation is deterministic which ensures that when it is performed on the same data by different peers they get the same result This is important since otherwise we risk message loss or routing cycles When the established And Symmetric flag is set only connections that are marked as established and are symmetric i e where both sides indicate they have a connection to the other are considered When a non nil stop At peer is supplied the widening stops when it reaches that peer The boolean return indicates whether that has happened NB This function should generally be invoked while holding a read lock on Peers and Local Peer 
Apply f to all peers reachable by peer If established And Symmetric is true only peers with established bidirectional connections will be selected The exclude maps is treated as a set of remote peers to blacklist 
Parse Peer UID parses a decimal peer UID from a string 
Swap implements sort Interface 
Less implements sort Interface 
Do Intro executes the protocol introduction 
The V procotol consists of the protocol identification version header followed by a stream of gobified values The first value is the encoded features map never encrypted The subsequent values are the messages on the connection encrypted for an encrypted connection For an encrypted connection the public key is passed in the Public Key feature as a string of hex digits 
In the V protocol the intro fields are sent unencrypted So we restrict them to an established subset of fields that are assumed to be safe 
The V procotol consists of the protocol identification version header followed by A single encryption flag byte for no encryption for encryption When the connection is encrypted bytes follow containing the public key Then a stream of length prefixed messages which are encrypted for an encrypted connection The first message contains the encoded features map so in contrast to V it will be encrypted on an encrypted connection 
new Connection Maker returns a usable Connection Maker seeded with peers making outbound connections from local Addr and listening on port If discovery is true Connection Maker will attempt to initiate new connections with peers it s not directly connected to 
Initiate Connections creates new connections to the provided peers specified in host port format If replace is true any existing direct peers are forgotten TODO pb Weave Net invokes router Connection Maker Initiate Connections it may be better to provide that on Router directly 
Forget Connections removes direct connections to the provided peers specified in host port format TODO pb Weave Net invokes router Connection Maker Forget Connections it may be better to provide that on Router directly 
Targets takes a snapshot of the targets direct peers either just the ones we are still trying or all of them Note these are the same things that Initiate Connections and Forget Connections talks about but a method to retrieve Connections would obviously return the current connections 
connection Aborted marks the target identified by address as broken and puts it in the Target Waiting state 
connection Created registers the passed connection and marks the target identified by conn Remote TCPAddr as established and puts it in the Target Connected state 
connection Terminated unregisters the passed connection and marks the target identified by conn Remote TCPAddr as Waiting 
The delay at the nth retry is a random value in the range i i i i where i Initial Interval n 
New Gossip Sender constructs a usable Gossip Sender 
Send accumulates the Gossip Data and will send it eventually Send and Broadcast accumulate into different buckets 
Broadcast accumulates the Gossip Data under the given src Name and will send it eventually Send and Broadcast accumulate into different buckets 
Flush sends all pending data and returns true if anything was sent since the previous flush For testing 
New Gossip Senders returns a usable Gossip Senders leveraging the Protocol Sender TODO pb is stop chan the best way to do that 
Sender yields the Gossip Sender for the named channel It will use the factory function if no sender yet exists 
Flush flushes all managed senders Used for testing 
Find the path to package main by looking at the root Caller 
Create creates a channel and returns a token for use by the client The client ID is an application provided string used to identify the client 
Send sends a message on the channel associated with client ID 
Send JSON is a helper function that sends a JSON encoded value on the channel associated with client ID 
remap Error fixes any APIError referencing xmpp into one referencing channel 
Fully Qualified App ID returns the fully qualified application ID This may contain a partition prefix e g s for High Replication apps or a domain prefix e g example com 
Namespaced Context wraps a Context to support namespaces 
proto To Item converts a protocol buffer item to a Go struct 
If err is an appengine Multi Error return its first element Otherwise return err 
Get gets the item for the given key Err Cache Miss is returned for a memcache cache miss The key must be at most bytes in length 
Get Multi is a batch version of Get The returned map from keys to items may have fewer elements than the input slice due to memcache cache misses Each key must be at most bytes in length 
Delete deletes the item for the given key Err Cache Miss is returned if the specified item can not be found The key must be at most bytes in length 
Delete Multi is a batch version of Delete If any keys cannot be found an appengine Multi Error is returned Each key must be at most bytes in length 
Increment atomically increments the decimal value in the given key by delta and returns the new value The value must fit in a uint Overflow wraps around and underflow is capped to zero The provided delta may be negative If the key doesn t exist in memcache the provided initial value is used to atomically populate it before the delta is applied The key must be at most bytes in length 
Increment Existing works like Increment but assumes that the key already exists in memcache and doesn t take an initial value Increment Existing can save work if calculating the initial value is expensive An error is returned if the specified item can not be found 
set sets the given items using the given conflict resolution policy appengine Multi Error may be returned 
Set writes the given item unconditionally 
Set Multi is a batch version of Set appengine Multi Error may be returned 
Add writes the given item if no value already exists for its key Err Not Stored is returned if that condition is not met 
Add Multi is a batch version of Add appengine Multi Error may be returned 
Compare And Swap writes the given item that was previously returned by Get if the value was neither modified or evicted between the Get and the Compare And Swap calls The item s Key should not change between calls but all other item fields may differ Err CASConflict is returned if the value was modified in between the calls Err Not Stored is returned if the value was evicted in between the calls 
Compare And Swap Multi is a batch version of Compare And Swap appengine Multi Error may be returned 
Get gets the item for the given key and decodes the obtained value into v Err Cache Miss is returned for a memcache cache miss The key must be at most bytes in length 
Set writes the given item unconditionally 
Set Multi is a batch version of Set appengine Multi Error may be returned 
Add writes the given item if no value already exists for its key Err Not Stored is returned if that condition is not met 
Add Multi is a batch version of Add appengine Multi Error may be returned 
Compare And Swap writes the given item that was previously returned by Get if the value was neither modified or evicted between the Get and the Compare And Swap calls The item s Key should not change between calls but all other item fields may differ Err CASConflict is returned if the value was modified in between the calls Err Not Stored is returned if the value was evicted in between the calls 
Compare And Swap Multi is a batch version of Compare And Swap appengine Multi Error may be returned 
Stats retrieves the current memcache statistics 
Flush flushes all items from memcache 
 Run In Background makes an API call that triggers an ah background request 
Run In Background runs f in a background goroutine in this process f is provided a context that may outlast the context provided to Run In Background This is only valid to invoke from a service set to basic or manual scaling 
List returns the names of modules belonging to this application 
Num Instances returns the number of instances of the given module version If either argument is the empty string it means the default 
Set Num Instances sets the number of instances of the given module version to the specified value If either module or version are the empty string it means the default 
Versions returns the names of the versions that belong to the specified module If module is the empty string it means the default module 
Default Version returns the default version of the specified module If module is the empty string it means the default module 
Start starts the specified version of the specified module If either module or version are the empty string it means the default 
Stop stops the specified version of the specified module If either module or version are the empty string it means the default 
Ancestor returns a derivative query with an ancestor filter The ancestor should not be nil 
Eventual Consistency returns a derivative query that returns eventually consistent results It only has an effect on ancestor queries 
Filter returns a derivative query with a field based filter The filter Str argument must be a field name followed by optional space followed by an operator one of or Fields are compared against the provided value using the operator Multiple filters are AND ed together 
Order returns a derivative query with a field based sort order Orders are applied in the order they are added The default order is ascending to sort in descending order prefix the field Name with a minus sign 
Project returns a derivative query that yields only the given fields It cannot be used with Keys Only 
Distinct returns a derivative query that yields de duplicated entities with respect to the set of projected fields It is only used for projection queries Distinct cannot be used with Distinct On 
Distinct On returns a derivative query that yields de duplicated entities with respect to the set of the specified fields It is only used for projection queries The field list should be a subset of the projected field list Distinct On cannot be used with Distinct 
Keys Only returns a derivative query that yields only keys not keys and entities It cannot be used with projection queries 
Limit returns a derivative query that has a limit on the number of results returned A negative value means unlimited 
Offset returns a derivative query that has an offset of how many keys to skip over before returning results A negative value is invalid 
Batch Size returns a derivative query to fetch the supplied number of results at once This value should be greater than zero and equal to or less than the Limit 
Start returns a derivative query with the given start point 
End returns a derivative query with the given end point 
to Proto converts the query to a protocol buffer 
Count returns the number of results for the query The running time and number of API calls made by Count scale linearly with the sum of the query s offset and limit Unless the result count is expected to be small it is best to specify a limit otherwise Count will continue until it finishes counting or the provided context expires 
call Next issues a datastore v Next RPC to advance a cursor such as that returned by a query with more results 
Get All runs the query in the given context and returns all keys that match that query as well as appending the values to dst dst must have type S or S or P for some struct type S or some non interface non pointer type P such that P or P implements Property Load Saver As a special case Property List is an invalid type for dst even though a Property List is a slice of structs It is treated as invalid to avoid being mistakenly passed when Property List was intended The keys returned by Get All will be in a correspondence with the entities added to dst If q is a keys only query Get All ignores dst and only returns the keys The running time and number of API calls made by Get All scale linearly with the sum of the query s offset and limit Unless the result count is expected to be small it is best to specify a limit otherwise Get All will continue until it finishes collecting results or the provided context expires 
Run runs the query in the given context 
Next returns the key of the next result When there are no more results Done is returned as the error If the query is not keys only and dst is non nil it also loads the entity stored for that key into the struct pointer or Property Load Saver dst with the same semantics and possible errors as for the Get function 
Cursor returns a cursor for the iterator s current location 
String returns a base string representation of a cursor 
Decode decodes a cursor from its base string representation 
value To Proto converts a named value to a newly allocated Property The returned error string is empty on success 
save Entity saves an Entity Proto into a Property Load Saver or struct pointer 
Load loads all of the provided fields into l It does not first reset l to an empty slice 
Deprecated Do not use 
Deprecated Do not use 
Deprecated Do not use 
Namespace returns a replacement context that operates within the given namespace 
typeof returns the type of the given name which may be of the form x or p X 
dot returns the type of typ name making its decision using the type information in cfg 
typecheck type checks the AST f assuming the information in cfg It returns two maps with type information typeof maps AST nodes to type information in gofmt string form assign maps type strings to lists of expressions that were assigned to values of another type that were assigned to that type 
Typecheck is the recursive form of typecheck It is like typecheck but adds to the information in typeof instead of allocating a new map 
Convert between function type strings and lists of types Using strings makes this a little harder but it makes a lot of the rest of the code easier This will all go away when we can use go typechecker directly split Func splits func x y z a b c into x y z and a b c 
join Func is the inverse of split Func 
split splits int float into int float and splits into 
Enabled returns whether an API s capabilities are enabled The wildcard capability matches every capability of an API If the underlying RPC fails if the package is unknown for example false is returned and information is written to the application log 
Load loads all of the provided properties into l It does not first reset l to an empty slice 
valid Property Name returns whether name consists of one or more valid Go identifiers joined by 
get Struct Codec returns the struct Codec for the given struct type 
get Struct Codec Locked implements get Struct Codec The struct Codecs Mutex must be held when calling this function 
Load Struct loads the properties from p to dst dst must be a struct pointer 
Save Struct returns the properties from src as a slice of Properties src must be a struct pointer 
Serving URL returns a URL that will serve an image from Blobstore 
Delete Serving URL deletes the serving URL for an image 
Current OAuth returns the user associated with the OAuth consumer making this request If the OAuth consumer did not make a valid OAuth request or the scopes is non empty and the current user does not have at least one of the scopes this method will return an error 
OAuth Consumer Key returns the OAuth consumer key provided with the current request This method will return an error if the OAuth request was invalid 
app ID returns appid or domain com appid 
String returns a displayable name for the user 
Login URL returns a URL that when visited prompts the user to sign in then redirects the user to the URL specified by dest 
Login URLFederated is like Login URL but accepts a user s Open ID identifier 
Logout URL returns a URL that when visited signs the user out then redirects the user to the URL specified by dest 
map Package turns appengine into google golang org appengine etc 
ctx may be nil 
New Client returns a client for the given host All communication will be performed over SSL unless the host is localhost 
New Context returns a copy of parent that will cause App Engine API calls to be sent to the client s remote host 
New Remote Context returns a context that gives access to the production APIs for the application at the given host All communication will be performed over SSL unless the host is localhost 
Debugf formats its arguments according to the format analogous to fmt Printf and records the text as a log message at Debug level The message will be associated with the request linked with the provided context 
guestbook Key returns the key used for all guestbook entries 
to Retry Parameter converts Retry Options to pb Task Queue Retry Parameters 
New POSTTask creates a Task that will POST to a path with the given form data 
Parse Request Headers parses the special HTTP request headers available to push task request handlers This function silently ignores values of the wrong format 
Add adds the task to a named queue An empty queue name means that the default queue will be used Add returns an equivalent Task with defaults filled in including setting the task s Name field to the chosen name if the original was empty 
Add Multi adds multiple tasks to a named queue An empty queue name means that the default queue will be used Add Multi returns a slice of equivalent tasks with defaults filled in including setting each task s Name field to the chosen name if the original was empty If a given task is badly formed or could not be added an appengine Multi Error is returned 
Delete deletes a task from a named queue 
Delete Multi deletes multiple tasks from a named queue If a given task could not be deleted an appengine Multi Error is returned Each task is deleted independently one may fail to delete while the others are sucessfully deleted 
Lease leases tasks from a queue lease Time is in seconds The number of tasks fetched will be at most max Tasks 
Lease By Tag leases tasks from a queue grouped by tag If tag is empty then the returned tasks are grouped by the tag of the task with earliest ETA lease Time is in seconds The number of tasks fetched will be at most max Tasks 
Purge removes all tasks from a queue 
Modify Lease modifies the lease of a task Used to request more processing time or to abandon processing lease Time is in seconds and must not be negative 
Queue Stats retrieves statistics about queues 
Is Timeout Error reports whether err is a timeout error 
file Key finds a stable representation of the caller s file path For calls from package main strip all leading path entries leaving just the filename For calls from anywhere else strip GOPATH src leaving just the package path and file path 
Func declares a new Function The second argument must be a function with a first argument of type context Context This function must be called at program initialization time That means it must be called in a global variable declaration or from an init function This restriction is necessary because the instance that delays a function call may not be the one that executes it Only the code executed at program initialization time is guaranteed to have been run by an instance before it receives a request 
Task creates a Task that will invoke the function Its parameters may be tweaked before adding it to a queue Users should not modify the Path or Payload fields of the returned Task 
Request returns the special task queue HTTP request headers for the current task queue handler Returns an error if called from outside a delay Func 
With Context returns a copy of the parent context and associates it with an in flight HTTP request This function is cheap 
Valid returns whether a Geo Point is within latitude and longitude 
With APICall Func returns a copy of the parent context that will cause API calls to invoke f instead of their normal operation This is intended for advanced users only 
APICall performs an API call This is not intended for general use it is exported for use in conjunction with With APICall Func 
Module Hostname returns a hostname of a module instance If module is the empty string it refers to the module of the current instance If version is empty it refers to the version of the current instance if valid or the default version of the module of the current instance If instance is empty Module Hostname returns the load balancing hostname 
Access Token generates an OAuth access token for the specified scopes on behalf of service account of this application This token will expire after the returned time 
Public Certificates retrieves the public certificates for the app They can be used to verify a signature returned by Sign Bytes 
Service Account returns a string representing the service account name in the form of an email address typically app id 
Sign Bytes signs bytes using a private key unique to your application 
fetch fetches read Buffer Size bytes starting at the given offset On success the data is saved as r buf 
seek seeks to the given offset with an effective whence equal to SEEK SET It discards the read buffer if the invariant cannot be maintained 
key To Proto converts a Key to a Reference proto 
multi Key To Proto is a batch version of key To Proto 
multi Valid is a batch version of Key valid It returns an error not a bool 
It s unfortunate that the two semantically equivalent concepts pb Reference and pb Property Value Reference Value aren t the same type For example the two have different protobuf field numbers reference Value To Key is the same as proto To Key except the input is a Property Value Reference Value instead of a Reference 
key To Reference Value is the same as key To Proto except the output is a Property Value Reference Value instead of a Reference 
check Multi Arg checks that v has type S S I or P for some struct type S for some interface type I or some non interface non pointer type P such that P or P implements Property Load Saver It returns what category the slice s elements are and the reflect Type that represents S I or P As a special case Property List is an invalid type for v 
Get Multi is a batch version of Get dst must be a S S I or P for some struct type S some interface type I or some non interface non pointer type P such that P or P implements Property Load Saver If an I each element must be a valid dst for Get it must be a struct pointer or implement Property Load Saver As a special case Property List is an invalid type for dst even though a Property List is a slice of structs It is treated as invalid to avoid being mistakenly passed when Property List was intended 
Put saves the entity src into the datastore with key k src must be a struct pointer or implement Property Load Saver if a struct pointer then any unexported fields of that struct will be skipped If k is an incomplete key the returned key will be a unique key generated by the datastore 
Put Multi is a batch version of Put src must satisfy the same conditions as the dst argument to Get Multi 
Delete deletes the entity for the given key 
Delete Multi is a batch version of Delete 
Client returns an http Client using a default urlfetch Transport This client will have the default deadline of seconds and will check the validity of SSL certificates Any deadline of the provided context will be used for requests through this client if the client does not have a deadline then a second default is used 
url String returns a valid string given a URL This function is necessary because the String method of URL doesn t correctly handle URLs with non empty Opaque values See http code google com p go issues detail id 
Round Trip issues a single HTTP request and returns its response Per the http Round Tripper interface Round Trip only returns an error if there was an unsupported request or the URL Fetch proxy fails Note that HTTP response codes such as xx etc are not errors as far as the transport is concerned and will be returned with err set to nil 
deploy calls the provided command to deploy the app from the temporary directory 
Next returns the next log record 
proto To App Logs takes as input an array of pointers to Log Lines the internal Protocol Buffer representation of a single application level log and converts it to an array of App Logs the external representation of an application level log 
proto To Record converts a Request Log the internal Protocol Buffer representation of a single request level log to a Record its corresponding external representation 
Run starts a query for log records which contain request and application level log information 
run takes the query Result produced by a call to Run and updates it with more Records The updated Result contains a new set of logs as well as an offset to where more logs can be found We also convert the items in the response from their internal representations to external versions of the same structs 
Current returns the currently logged in user or nil if the user is not signed in 
Is Admin returns true if the current user is signed in and is currently registered as an administrator of the application 
is Err Field Mismatch returns whether err is a datastore Err Field Mismatch The blobstore stores blob metadata in the datastore When loading that metadata it may contain fields that we don t care about datastore Get will return datastore Err Field Mismatch in that case so we ignore that specific error 
Stat returns the Blob Info for a provided blob Key If no blob was found for that key Stat returns datastore Err No Such Entity 
Send sets the headers on response to instruct App Engine to send a blob as the response body This is more efficient than reading and writing it out manually and isn t subject to normal response size limits 
Upload URL creates an upload URL for the form that the user will fill out passing the application path to load when the POST of the form is completed These URLs expire and should not be reused The opts parameter may be nil 
Delete deletes a blob 
Delete Multi deletes multiple blobs 
Parse Upload parses the synthetic POST request that your app gets from App Engine after a user s successful upload of blobs Given the request Parse Upload returns a map of the blobs received keyed by HTML form element name and other non blob POST parameters 
New Reader returns a reader for a blob It always succeeds if the blob does not exist then an error will be reported upon first read 
Blob Key For File returns a Blob Key for a Google Storage file The filename should be of the form gs bucket name object name 
Handle arranges for f to be called for incoming XMPP messages Only messages of type chat or normal will be handled 
Send sends a message If any failures occur with specific recipients the error will be an appengine Multi Error 
Invite sends an invitation If the from address is an empty string the default yourapp 
Send sends a presence update 
Get Presence retrieves a user s presence If the from address is an empty string the default yourapp 
Get Presence Multi retrieves multiple users presence If the from address is an empty string the default yourapp 
Dial connects to the address addr on the network protocol The address format is host port where host may be a hostname or an IP address Known protocols are tcp and udp The returned connection satisfies net Conn and is valid while ctx is valid if the connection is to be used after ctx becomes invalid invoke Set Context with the new context 
Dial Timeout is like Dial but takes a timeout The timeout includes name resolution if required 
Lookup IP returns the given host s IP addresses 
new Struct FLS returns a Field Load Saver for the struct pointer p 
Save Struct returns the fields from src as a slice of Field src must be a struct pointer 
Namespaces returns all the datastore namespaces 
Kinds returns the names of all the kinds in the current namespace 
key Names returns a slice of the provided keys names string IDs 
Kind Properties returns all the indexed properties for the given kind The properties are returned as a map of property names to a slice of the representation types The representation types for the supported Go property types are INT signed integers and time Time DOUBLE float and float BOOLEAN bool STRING string byte and Byte String POINT appengine Geo Point REFERENCE Key USER not used in the Go runtime 
TODO dsymonds Do we need to support default values like Python 
Run In Transaction runs f in a transaction It calls f with a transaction context tc that f should use for all App Engine operations If f returns nil Run In Transaction attempts to commit the transaction returning nil if it succeeds If the commit fails due to a conflicting transaction Run In Transaction retries f each time with a new transaction context It gives up and returns Err Concurrent Transaction after three failed attempts The number of attempts can be configured by specifying Transaction Options Attempts If f returns non nil then any datastore changes will not be applied and Run In Transaction returns that same error The function f is not retried Note that when f returns the transaction is not yet committed Calling code must be careful not to assume that any of f s changes have been committed until Run In Transaction returns nil Since f may be called multiple times f should usually be idempotent datastore Get is not idempotent when unmarshaling slice fields Nested transactions are not supported c may not be a transaction context 
walk Before After is like walk but calls before x before traversing x s children and after x afterward 
imports returns true if f imports path 
import Spec returns the import spec if f imports path or nil otherwise 
decl Imports reports whether gen contains an import of path 
is Pkg Dot returns true if t is the expression pkg name where pkg is an imported identifier 
is Ptr Pkg Dot returns true if f is the expression pkg name where pkg is an imported identifier 
is Top Name returns true if n is a top level unresolved identifier with the given name 
is Name returns true if n is an identifier with the given name 
is Call returns true if t is a call to pkg name 
If n is an ast Ident is Ident returns it otherwise is Ident returns nil 
refers To returns true if n is a reference to the same object as x 
is Empty String returns true if n is an empty string literal 
count Uses returns the number of uses of the identifier x in scope 
rewrite Uses replaces all uses of the identifier x and x in scope with f x Pos and fnot x Pos 
assigns To returns true if any of the code in scope assigns to or takes the address of x 
new Pkg Dot returns an ast Expr referring to pkg name at position pos 
rename Top renames all references to the top level name old It returns true if it makes any changes 
match Len returns the length of the longest prefix shared by x and y 
delete Import deletes the import path from the file f if present 
rewrite Import rewrites any import of path old Path to path new Path 
from Context returns the App Engine context or nil if ctx is not derived from an App Engine context 
Default Ticket returns a ticket used for background context or dev appserver 
flush Log attempts to flush any pending logs to the appserver It should not be called concurrently 
Dial connects to the address addr on the network protocol The address format is host port where host may be a hostname or an IP address Known protocols are tcp and udp The returned connection satisfies net Conn and is valid while ctx is valid if the connection is to be used after ctx becomes invalid invoke Set Context with the new context 
Dial Timeout is like Dial but takes a timeout The timeout includes name resolution if required 
Lookup IP returns the given host s IP addresses 
with Deadline is like context With Deadline except it ignores the zero deadline 
Keep Alive signals that the connection is still in use It may be called to prevent the socket being closed due to inactivity 
Register Transaction Setter registers a function that sets transaction information in a protocol buffer message f should be a function with two arguments the first being a protocol buffer type and the second being datastore Transaction 
apply Transaction applies the transaction t to message pb by using the relevant setter passed to Register Transaction Setter 
analyze checks the app for building with the given build tags and returns has Main app files and a map of full directory import names to original import names 
build Context returns the context for building the source 
bundle bundles the app into the named tar File stdout 
synthesize Main generates a new main func and writes it to the tarball 
imports returns a map of all import directories recursively used by the app The return value maps full directory names to original import names 
find In Gopath searches the gopath for the named import directory 
copy Tree copies src Dir to tar file dst Dir ignoring skip Files 
copy File copies src to tar file dst 
check Main verifies that there is a single main function It also returns a list of all Go source files in the app 
is Main returns whether the given function declaration is a main function Such a function must be called main not have a receiver and have no arguments or return types 
read File reads and parses the Go source code file and returns whether it has a main function 
set Val sets v to the value p Value 
init Field is similar to reflect s Value Field By Index in that it returns the nested struct field corresponding to index but it initialises any nil pointers encountered when traversing the structure 
load Entity loads an Entity Proto into Property Load Saver or struct pointer 
valid Index Name Or Doc ID is the Go equivalent of Python s Validate Visible Printable Ascii Not Reserved 
Open opens the index with the given name The index is created if it does not already exist The name is a human readable ASCII string It must contain no whitespace characters and not start with 
Put saves src to the index If id is empty a new ID is allocated by the service and returned If id is not empty any existing index entry for that ID is replaced The ID is a human readable ASCII string It must contain no whitespace characters and not start with src must be a non nil struct pointer or implement the Field Load Saver interface 
Put Multi is like Put but is more efficient for adding multiple documents to the index at once Up to documents can be added at once Err Too Many Documents is returned if you try to add more ids can either be an empty slice which means new IDs will be allocated for each of the documents added or a slice the same size as srcs The error may be an instance of appengine Multi Error in which case it will be the same size as srcs and the individual errors inside will correspond with the items in srcs 
Get loads the document with the given ID into dst The ID is a human readable ASCII string It must be non empty contain no whitespace characters and not start with dst must be a non nil struct pointer or implement the Field Load Saver interface Err Field Mismatch is returned when a field is to be loaded into a different type than the one it was stored from or when a field is missing or unexported in the destination struct Err Field Mismatch is only returned if dst is a struct pointer It is up to the callee to decide whether this error is fatal recoverable or ignorable 
Delete deletes a document from the index 
Delete Multi deletes multiple documents from the index The returned error may be an instance of appengine Multi Error in which case it will be the same size as srcs and the individual errors inside will correspond with the items in srcs 
Search searches the index for the given query 
fetch More retrieves more results if there are no errors or pending results 
Next returns the ID of the next result When there are no more results Done is returned as the error dst must be a non nil struct pointer implement the Field Load Saver interface or be a nil interface value If a non nil dst is provided it will be filled with the indexed fields dst is ignored if this iterator was created with an IDs Only option 
Cursor returns the cursor associated with the current document that is the document most recently returned by a call to Next Passing this cursor in a future call to Search will cause those results to commence with the first document after the current document 
Facets returns the facets found within the search results if any facets were requested in the Search Options 
save Doc converts from a struct pointer or Field Load Saver Field Metadata Load Saver to the Document protobuf 
load Doc converts from protobufs to a struct pointer or Field Load Saver Field Metadata Load Saver The src param provides the document s stored fields and facets and any document metadata An additional slice of fields exprs may optionally be provided to contain any derived expressions requested by the developer 
Default Bucket Name returns the name of this application s default Google Cloud Storage bucket 
valid returns whether the key is valid 
Equal returns whether two keys are equal 
root returns the furthest ancestor of a key which may be itself 
marshal marshals the key s string representation to the buffer 
String returns a string representation of the key 
Encode returns an opaque representation of the key suitable for use in HTML and URLs This is compatible with the Python and Java runtimes 
Decode Key decodes a key from the opaque representation returned by Encode 
New Incomplete Key creates a new incomplete key kind cannot be empty 
New Key creates a new key kind cannot be empty Either one or both of string ID and int ID must be zero If both are zero the key returned is incomplete parent must either be a complete key or nil 
Allocate IDs returns a range of n integer IDs with the given kind and parent combination kind cannot be empty parent may be nil The IDs in the range returned will not be used by the datastore s automatic ID sequence generator and may be used with New Key without conflict The range is inclusive at the low end and exclusive at the high end In other words valid int IDs x satisfy low x x high If no error is returned low n high 
Allocate IDRange allocates a range of IDs with specific endpoints The range is inclusive at both the low and high end Once these IDs have been allocated you can manually assign them to newly created entities The Datastore s automatic ID allocator never assigns a key that has already been allocated either through automatic ID allocation or through an explicit Allocate IDs call As a result entities written to the given key range will never be overwritten However writing entities with manually assigned keys in this range may overwrite existing entities or new entities written by a separate request depending on the error returned Use this only if you have an existing numeric ID range that you want to reserve for example bulk loading entities that already have IDs If you don t care about which IDs you receive use Allocate IDs instead Allocate IDRange returns nil if the range is successfully allocated If one or more entities with an ID in the given range already exist it returns a Key Range Collision Error If the Datastore has already cached IDs in this range e g from a previous call to Allocate IDRange it returns a Key Range Contention Error Errors of other types indicate problems with arguments or an error returned directly from the Datastore 
Deprecated Do not use 
Is Over Quota reports whether err represents an API call failure due to insufficient available quota 
from Context returns the App Engine context or nil if ctx is not derived from an App Engine context 
This is only for classic App Engine adapters 
Send sends an email message 
Send To Admins sends an email message to the application s administrators 
Parse parses go test output from reader r and returns a report with the results An optional pkg Name can be given which is used in case a package result line is missing 
Failures counts the number of failed tests in this report 
JUnit Report XML writes a JUnit xml representation of the given report to w in the format described at http windyroad org dl Open Source JUnit xsd 
This is the main entrypoint for decoding all types from binary form This function calls decode Reflect Binary and generally those functions should only call this one for the prefix bytes are consumed here when present CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true NOTE Keep the code structure similar to decode Reflect Binary Slice 
CONTRACT rv Can Addr is true 
 consume for skipping struct fields Read everything without doing anything with it Report errors if they occur 
Read field key 
Error if typ doesn t match rt 
Read typ byte 
Read a uvarint that encodes the number of nil items to skip NOTE Currently does not support any number besides not nil and nil All other values will error 
Copy into Prefix Bytes 
This function should be used to register all interfaces that will be encoded decoded by go amino Usage amino Register Interface My Interface nil nil 
This function should be used to register concrete types that will appear in interface fields elements to be encoded decoded by go amino Usage amino Register Concrete My Struct com tendermint My Struct nil 
Print Types writes all registered types in a markdown style table The table s header is Type Name Prefix Notes Where Type is the golang type name and Name is the name the type was registered with 
A heuristic to guess the size of a registered type and return it as a string If the size is not fixed it returns variable 
iinfo Type Info for the interface for which we must decode a concrete type with prefix bytes pb 
Constructs a Type Info automatically not from registration 
Find all conflicting prefixes for concrete types that implement the interface Implement in quotes because we only consider the pointer for extra safety 
Ensure that prefix conflicting implementing concrete types are all registered in the priority list Returns an error if a disamb conflict is found 
 String 
 Misc 
 cdc encode Reflect Binary This is the main entrypoint for encoding all types in binary form This function calls encode Reflect Binary and generally those functions should only call this one for the prefix bytes are only written here The value may be a nil interface but not a nil pointer The following contracts apply to all similar encode methods CONTRACT rv is not a pointer CONTRACT rv is valid 
CONTRACT info Type Elem Kind reflect Uint 
 Misc Write field key 
 cdc decode Reflect JSON CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true 
CONTRACT rv Can Addr is true 
decode Interface JSON helps unravel the type name and the stored data which are expected in the form type canonical concrete type name value 
 encode see binary encode go and json encode go decode see binary decode go and json decode go Misc 
CONTRACT by the time this is called len bz n Returns true so you can write one liners 
Dereference pointer recursively drv the final non pointer value which may be invalid is Ptr whether rv Kind reflect Ptr is Nil Ptr whether a nil pointer at any level 
Dereference pointer recursively or return zero value drv the final non pointer value which is never invalid is Ptr whether rv Kind reflect Ptr is Nil Ptr whether a nil pointer at any level 
Returns is Default Value true iff is ultimately nil or empty after recursive dereferencing If is Default Value false erv is set to the non nil non default dereferenced value A zero empty struct is not considered default for this function 
Returns the default value of a type For a time type or a pointer s to time the default value is not zero or nil but the time value of 
construct Concrete Type creates the concrete value as well as the corresponding settable value for it Return irv Set which should be set on caller s interface rv 
CONTRACT rt Kind reflect Ptr 
 func scan List bz byte indent string s string n int err error Read element Typ if len bz err errors New EOF while reading list element typ return var typ amino Typ bz if typ x F err errors New Invalid list element typ byte s fmt Sprintf X bz if slide bz n err nil return Read number of elements var num n uint int num n binary Uvarint bz if n n err errors New error decoding list length uvarint s Cyan fmt Sprintf X bz n if slide bz n n err nil return fmt Printf s s of v with v items n indent s typ num Read elements var s string for i i int num i Maybe read nil byte if typ x if len bz err errors New EOF while reading list nil byte return var nb bz slide bz n switch nb case x s fmt Printf s not nil n indent case x s Is nil NOTE reverse logic fmt Printf s is nil n indent continue default err fmt Errorf Unexpected nil pointer byte X nb return Read element s n err scan Any typ Typ bz indent if slide bz n n concat s s err nil return return func scan Interface bz byte indent string s string n int err error db has Db pb typ is Nil n err amino Decode Disamb Prefix Bytes bz if slide bz n n err nil return pb pb if is Nil s Magenta else if has Db s Magenta fmt Sprintf X X db Bytes pb Bytes else s Magenta fmt Sprintf X pb Bytes if is Nil fmt Printf s s nil interface n indent s else if has Db fmt Printf s s disamb X prefix X typ v n indent s db Bytes pb Bytes typ else fmt Printf s s prefix X typ v n indent s pb Bytes typ s n err scan Any typ bz indent if slide bz n n concat s s err nil return return Misc 
 cdc encode Reflect JSON This is the main entrypoint for encoding all types in json form This function calls encode Reflect JSON and generally those functions should only call this one for the disfix wrapper is only written here NOTE Unlike encode Reflect Binary rv may be a pointer CONTRACT rv is valid 
TODO TEST 
 Misc CONTRACT rv implements json Marshaler 
For json omitempty Returns true for zero values but also non nil zero length slices and strings 
 Signed 
 Unsigned 
Encode Uvarint is used to encode golang s int int int by default unless specified differently by the binary fixed binary fixed or binary zigzag binary zigzag tags It matches protobufs varint encoding 
 Other 
NOTE UNSAFE 
NOTE UNSAFE 
Encode Time writes the number of seconds int and nanoseconds int with millisecond resolution since January UTC to the Writer as an UInt Milliseconds are used to ease compatibility with Javascript which does not support finer resolution 
 Signed 
 Unsigned 
 Other 
NOTE UNSAFE 
NOTE UNSAFE 
Decode Time decodes seconds int and nanoseconds int since January UTC and returns the corresponding time If nanoseconds is not in the range or if seconds is too large the behavior is undefined TODO return error if behavior is undefined 
 Deep Copy Deeply copies an object If anything implements Deep Copy any along the way the result of that function will be used Otherwise if it implements Marshal Amino any error and Unmarshal Amino any error the pair will be used to copy If Marshal Amino or Unmarshal Amino returns an error this function will panic 
 misc Call Deep Copy method if possible 
Call Marshal Amino and Unmarshal Amino to copy if possible Panics if Marshal Amino or Unmarshal Amino return an error CONTRACT src and dst are of equal types 
 Codec methods Marshal Binary Length Prefixed encodes the object o according to the Amino spec but prefixed by a uvarint encoding of the object to encode Use Marshal Binary Bare if you don t want byte length prefixing For consistency Marshal Binary Length Prefixed will first dereference pointers before encoding Marshal Binary Length Prefixed will panic if o is a nil pointer or if o is invalid 
Marshal Binary Length Prefixed Writer writes the bytes as would be returned from Marshal Binary Length Prefixed to the writer w 
Panics if error 
Marshal Binary Bare encodes the object o according to the Amino spec Marshal Binary Bare doesn t prefix the byte length of the encoding so the caller must handle framing 
Panics if error 
Like Unmarshal Binary Bare but will first decode the byte length prefix Unmarshal Binary Length Prefixed will panic if ptr is a nil pointer Returns an error if not all of bz is consumed 
Like Unmarshal Binary Bare but will first read the byte length prefix Unmarshal Binary Length Prefixed Reader will panic if ptr is a nil pointer If max Size is there is no limit not recommended 
Panics if error 
Unmarshal Binary Bare will panic if ptr is a nil pointer 
Panics if error 
Must Marshal JSON panics if an error occurs Besides tha behaves exactly like Marshal JSON 
Must Unmarshal JSON panics if an error occurs Besides tha behaves exactly like Unmarshal JSON 
Marshal JSONIndent calls json Indent on the output of cdc Marshal JSON using the given prefix and indent string 
Dial To makes a un secure TELNET client connection to the the address specified by addr If a secure connection is desired use Dial To TLS instead 
Dial To TLS makes a secure TELNETS client connection to the the address specified by addr 
Read receives n bytes sent from the server to the client and returns into p Note that Read can only be used for receiving TELNET and TELNETS data from the server TELNET and TELNETS command codes cannot be received using this method as Read deals with TELNET and TELNETS unescaping and when appropriate filters out TELNET and TELNETS command codes Read makes Client fit the io Reader interface 
Write sends n bytes from p to the server Note that Write can only be used for sending TELNET and TELNETS data to the server TELNET and TELNETS command codes cannot be sent using this method as Write deals with TELNET and TELNETS escaping and will properly escape anything written with it Write makes Conn fit the io Writer interface 
new Data Reader creates a new Data Reader reading from r 
Read reads the TELNET escaped data from the wrapped io Reader and un escapes it into data 
Listen And Serve TLS acts identically to Listen And Serve except that it uses the TELNET protocol over TLS From a TELNET protocol point of view it allows for secured telnet also known as TELNETS which by default listens to port Of course this port can be overridden using the addr argument For a very simple example package main import github com reiver go telnet func main 
Listen And Serve TLS acts identically to Listen And Serve except that it uses the TELNET protocol over TLS From a TELNET protocol point of view it allows for secured telnet also known as TELNETS which by default listens to port 
new Data Writer creates a new internal Data Writer writing to w w receives what is written to the internal Data Writer but escaped according to the TELNET and TELNETS protocol I e byte IAC gets encoded as For example if the following it written to the internal Data Writer s Write method byte then conceptually the following is written to w s Write method byte Notice that each in the original byte array became s in a row internal Data Writer takes care of all this for you so you do not have to do it 
Write writes the TELNET and TELNETS escaped data for of the data in data to the wrapped io Writer 
Produce makes Producer Func fit the Producer interface 
Promote Handler Func turns a Handler Func into a Handler 
Serve accepts an incoming TELNET or TELNETS client connection on the net Listener listener 
Listen And Serve listens on the TCP network address server Addr and then spawns a call to the Serve TELNET method on the server Handler to serve each incoming connection For a simple example package main import github com reiver go telnet func main var handler telnet Handler telnet Echo Handler server telnet Server Addr Handler handler err server Listen And Serve if nil err 
Serve accepts an incoming TELNET client connection on the net Listener listener 
Fail prints usage information to stderr and exits with non zero status 
Write Usage writes usage information to the given writer 
Write Help writes the usage string followed by the full help string for each option 
Must Parse processes command line arguments and exits upon failure 
Parse processes command line arguments and stores them in dest 
walk Fields calls a function for each field of a struct recursively expanding struct fields 
New Parser constructs a parser from a list of destination structs 
Parse processes the given command line option storing the results in the field of the structs from which New Parser was constructed 
process goes through arguments one by one parses them and assigns the result to the underlying struct field 
is Flag returns true if a token is a flag such as v or user but not or 
parse a value as the appropriate type and store it in the struct 
can Parse returns true if the type can be parsed from a string 
is Boolean returns true if the type can be parsed from a single string 
New From Map returns a new tree containing the keys from an existing map 
Insert is used to add a newentry or update an existing entry Returns if updated 
Delete is used to delete a key returning the previous value and if it was deleted 
Delete Prefix is used to delete the subtree under a prefix Returns how many nodes were deleted Use this to delete large subtrees efficiently 
delete does a recursive deletion 
Get is used to lookup a specific key returning the value and if it was found 
Longest Prefix is like Get but instead of an exact match it will return the longest prefix match 
Minimum is used to return the minimum value in the tree 
Walk Prefix is used to walk the tree under a prefix 
Walk Path is used to walk the tree but only visiting nodes from the root down to a given leaf Where Walk Prefix walks all the entries under the given prefix this walks the entries above the given prefix 
recursive Walk is used to do a pre order walk of a node recursively Returns true if the walk should be aborted 
To Map is used to walk the tree and convert it into a map 
get IP type and calculate IP number calculates index too if exists 
read byte 
read unsigned bit integer 
read unsigned bit integer 
read string 
initialize the component with the database path 
populate record with message 
main query 
for debugging purposes 
Main draws a left hand and ear of a gopher Afterwards it returns the filename This should only be used during testing 
Draw a left hand and ear of a gopher using a gc thanks to https github com golang samples gopher vector 
Rectangle draws a rectangle using a path between x y and x y 
Rounded Rectangle draws a rectangle using a path between x y and x y 
Ellipse draws an ellipse using a path with center cx cy and radius rx ry 
Circle draws a circle using a path with center cx cy and radius 
Save To Pdf File creates and saves a pdf document to a file 
Move To starts a new path at x y position 
Cubic Curve To adds a cubic bezier curve to the current path 
Arc To adds an arc to the path 
String returns a debug text view of the path 
Returns new Path with flipped y axes 
New Glyph Cache initializes a Glyph Cache 
Fetch fetches a glyph from the cache calling render Glyph first if it doesn t already exist 
render Glyph renders a glyph then caches and returns it 
Copy Returns a copy of a Glyph 
Fill copies a glyph from the cache and fills it 
Main draws vertically spaced lines and returns the filename This should only be used during testing 
Draw vertically spaced lines 
Do the same thing as fmt Sprintf except it uses the optimal precition for floats for f and for F eg opti Sprintf f fmt Sprintf f opti Sprintf f fmt Sprintf f opti Sprintf f fmt Sprintf f opti Sprintf f fmt Sprintf f opti Sprintf F fmt Sprintf f 
TODO needs test since it is not quiet right 
Paint satisfies the Painter interface by painting ss onto an image RGBA 
Set Color sets the color to paint the spans 
New RGBAPainter creates a new RGBAPainter for the given image 
New Graphic Context creates a new Graphic context from an image 
Fill String draws the text at point 
Fill String At draws the text at the specified point x y 
Get String Bounds returns the approximate pixel bounds of the string s at x y The the left edge of the em square of the first character of s and the baseline intersect at in the returned coordinates Therefore the top and left coordinates may well be negative 
Stroke String draws the contour of the text at point 
recalc recalculates scale and bounds values from the font size screen resolution and font metrics and invalidates the glyph cache 
Set Font sets the font used to draw text 
Set Font Size sets the font size in points as in a point font 
Stroke strokes the paths with the color specified by Set Stroke Color 
Fill fills the paths with the color specified by Set Fill Color 
Fill Stroke first fills the paths and than strokes them 
Fill String draws the text at point 
Fill String At draws the text at the specified point x y 
Stroke String draws the contour of the text at point 
Stroke String At draws the contour of the text at point x y 
Draw Image draws the raster image in the current canvas 
Clear Rect fills the specified rectangle with a default transparent color 
NOTE following two functions and soe other further below copied from dwra d img gl TODO move them all to common draw dbase Create String Path creates a path from the string s at x y and returns the string width The text is placed so that the left edge of the em square of the first character of s and the baseline intersect at x y The majority of the affected pixels will be above and to the right of the point but some may be below or to the left For example drawing a string that starts with a J in an italic font may affect pixels below and left of the point 
 private funcitons 
Add text element to svg and returns its expected width 
Creates new group from current context attach it to svg and return 
creates new mask attached to svg 
Embed svg font definition to svg tree itself Or update existing if already exists for curent font data 
Trace Quad generate lines subdividing the curve using a Liner flattening threshold helps determines the flattening expectation of the curve 
Get Font Name gets the current Font Data with font Size as a string 
Create a new Graphic context from an image 
New Folder Font Cache creates Folder Font Cache 
Load a font from cache if exists otherwise it will load the font from file 
Store a font to this cache 
New Sync Folder Font Cache creates Sync Folder Font Cache 
Load a font from cache if exists otherwise it will load the font from file 
Store a font to this cache 
Main draws a rotated face of the gopher Afterwards it returns the filename This should only be used during testing 
Draw a gopher head not rotated 
New Pdf creates a new pdf document with the draw d fontfolder adds a page and set fill color to white 
rgb converts a color used by draw d into int used by gofpdf 
clear Rect draws a white rectangle 
New Graphic Context creates a new pdf Graphic Context 
Draw Image draws an image as PNG TODO add type tp as parameter to argument list 
Clear draws a white rectangle over the whole page 
Clear Rect draws a white rectangle over the specified area Samples line 
Get String Bounds returns the approximate pixel bounds of the string s at x y The left edge of the em square of the first character of s and the baseline intersect at in the returned coordinates Therefore the top and left coordinates may well be negative 
Create String Path creates a path from the string s at x y and returns the string width 
Fill String At draws a string at x y 
Stroke strokes the paths with the color specified by Set Stroke Color 
Fill fills the paths with the color specified by Set Fill Color 
Fill Stroke first fills the paths and than strokes them 
draw fills and or strokes paths 
overwrite Stack Graphic Context methods Set Stroke Color sets the stroke color 
Set Fill Color sets the fill and text color 
Set Font Data sets the current font used to draw text Always use this method as Set Font is unsupported by the pdf graphic context It is mandatory to call this method at least once before printing text or the resulting document will not be valid It is necessary to generate a font definition file first with the makefont utility It is not necessary to call this function for the core PDF fonts courier helvetica times zapfdingbats go get github com jung kurt gofpdf makefont http godoc org github com jung kurt gofpdf Fpdf Add Font 
Set Font Size sets the font size in points as in a point font TODO resolve this with Img Graphic Context now done with gc Current Scale 
Set Line Dash sets the line dash pattern 
Set Line Width sets the line width 
Set Line Cap sets the line cap round but or square 
Set Line Join sets the line cap round bevel or miter 
Transformations Scale generally scales the following text drawings and images sx and sy are the scaling factors for width and height This must be placed between gc Save and gc Restore otherwise the pdf is invalid 
Rotate rotates the following text drawings and images Angle is specified in radians and measured clockwise from the o clock position This must be placed between gc Save and gc Restore otherwise the pdf is invalid 
Translate moves the following text drawings and images horizontally and vertically by the amounts specified by tx and ty This must be placed between gc Save and gc Restore otherwise the pdf is invalid 
Restore restores the current context stack transformation color Restoring the font is not supported 
Main draws Hello World and returns the filename This should only be used during testing 
Draw Hello World 
Save To Png File create and save an image to a file using PNG format 
Load From Png File Open a png file 
Resource returns a resource filename for testing 
Output returns the output filename for testing 
Main draws the tiger 
Draw a tiger 
Main draws geometry and returns the filename This should only be used during testing 
Bubble draws a text balloon 
Curve Rectangle draws a rectangle with bezier curves not rounded rectangle 
Dash draws a line with a dash pattern 
Arc draws an arc with a positive angle clockwise 
Cubic Curve draws a cubic curve with its control points 
Fill String draws a filled and stroked string And filles stroked path created from string Which may have different unselectable output in non raster gc implementations 
Fill Stroke first fills and afterwards strokes a path 
Fill Style demonstrates the difference between even odd and non zero winding rule 
Path Transform scales a path differently in horizontal and vertical direction 
Star draws many lines from a center 
Draw all figures in a nice x grid 
Convert Path converts a paths to the pdf api 
Main draws the different line caps and joins This should only be used during testing 
Draw a line with an angle with specified line cap and join 
Draw Contour draws the given closed contour at the given sub pixel offset 
Flatten convert curves into straight segments keeping join segments info 
 Testing Equals tests if a two transformation are equal A tolerance is applied when comparing matrix elements 
New Graphic Context creates a new Graphic context from an image 
New Graphic Context With Painter creates a new Graphic context from an image and a Painter see Freetype go 
Clear fills the current canvas with a default transparent color 
Clear Rect fills the current canvas with a default transparent color at the specified rectangle 
Draw Image draws an image into dest using an affine transformation matrix an op and a filter 
Draw Image draws the raster image in the current canvas 
Stroke strokes the paths with the color specified by Set Stroke Color 
Fill fills the paths with the color specified by Set Fill Color 
Fill Stroke first fills the paths and than strokes them 
Main draws the image frame and returns the filename This should only be used during testing 
Draw the image frame with certain parameters 
Draw the droid on a certain position 
Checksum String S returns the checksum of the input data without creating a copy with the specific seed 
Checksum String S returns the checksum of the input data without creating a copy with the specific seed 
New S creates a new hash Hash computing the bit xx Hash checksum starting with the specific seed 
Sum appends the current hash to b and returns the resulting slice It does not change the underlying hash state 
New S creates a new hash Hash computing the bit xx Hash checksum starting with the specific seed 
Sum appends the current hash to b and returns the resulting slice It does not change the underlying hash state 
borrowed from cespare 
Checksum S returns the checksum of the input bytes with the specific seed 
Checksum S returns the bit xxhash checksum for a single input 
Get Executable Path returns the absolute path to the currently running executable It is used internally by the godaemon package and exported publicly because it s useful outside of the package too 
Get Executable Path returns the absolute path to the currently running executable It is used internally by the godaemon package and exported publicly because it s useful outside of the package too 
Get Executable Path returns the absolute path to the currently running executable It is used internally by the godaemon package and exported publicly because it s useful outside of the package too 
Readlink returns the file pointed to by the given soft link or an error of type Path Error otherwise This mimics the os Readlink function but works around a bug we ve seen in Cent OS kernel on x where the underlying OS function readlink returns a wrong number of bytes for the result see man readlink Here we don t rely blindly on that value if there s a zero byte among that number of bytes then we keep only up to that point NOTE We chose not to use os Readlink and then search on its result to avoid an extra overhead of converting back to byte The function to search for a byte over the string itself strings Index Byte is only available starting with Go Also we re not searching at every iteration to save some CPU time even though that could mean extra iterations for systems affected with this bug But it s wiser to optimize for the general case i e those not affected 
Get Executable Path returns the absolute path to the currently running executable It is used internally by the godaemon package and exported publicly because it s useful outside of the package too 
 Make Daemon turns the process into a daemon But given the lack of Go s support for fork Make Daemon is forced to run the process all over again from the start Hence this should probably be your first call after main begins unless you understand the effects of calling from somewhere else Keep in mind that the PID changes after this function is called given that it only returns in the child the parent will exit without returning 
Stage returns the stage of daemonizing i e it allows you to know whether you re currently working in the parent first child or the final daemon This is useless after the call to Make Daemon cause that call will only return for the daemon stage However you can still use Stage to tell whether you ve daemonized or not in case you have a running path that may exclude the call to Make Daemon 
Returns the current stage in the daemonization process that s kept in an environment variable The variable is instrumented with a digital signature to avoid misbehavior if it was present in the user s environment The original value is restored after the last stage so that there s no final effect on the environment the application receives 
New returns plain glg instance 
Get returns singleton glg instance 
Set Mode sets glg logging mode 
Set Level Mode set glg logging mode per level 
Set Prefix set Print logger prefix 
Get Current Mode returns current logging mode 
Init Writer is initialize glg writer 
Set Writer sets writer to glg std writers 
Set Level Color sets the color for each level 
Set Level Writer sets writer to glg std writer per logging level 
Add Std Level adds std log level and returns LEVEL 
Enable Color enables color output 
Enable Level Color enables color output 
Disable Level Color disables color output 
Raw String returns raw log string exclude time tags 
Tag String To Level converts level string to Glg LEVEL 
File Writer generates os File io Writer 
HTTPLogger is simple http access logger 
HTTPLogger Func is simple http access logger 
HTTPLogger is simple http access logger 
HTTPLogger Func is simple http access logger 
Log writes std log event 
Logf writes std log event with format 
Log Func outputs Log level log returned from the function 
Log writes std log event 
Logf writes std log event with format 
Log Func outputs Log level log returned from the function 
Info outputs Info level log 
Infof outputs formatted Info level log 
Info Func outputs Info level log returned from the function 
Info outputs Info level log 
Infof outputs formatted Info level log 
Info Func outputs Info level log returned from the function 
Success outputs Success level log 
Successf outputs formatted Success level log 
Success Func outputs Success level log returned from the function 
Success outputs Success level log 
Successf outputs formatted Success level log 
Success Func outputs Success level log returned from the function 
Debug outputs Debug level log 
Debugf outputs formatted Debug level log 
Debug Func outputs Debug level log returned from the function 
Debug outputs Debug level log 
Debugf outputs formatted Debug level log 
Debug Func outputs Debug level log returned from the function 
Warn outputs Warn level log 
Warnf outputs formatted Warn level log 
Warn Func outputs Warn level log returned from the function 
Warn outputs Warn level log 
Warnf outputs formatted Warn level log 
Warn Func outputs Warn level log returned from the function 
Custom Log outputs custom level log 
Custom Logf outputs formatted custom level log 
Custom Log Func outputs custom level log returned from the function 
Custom Log outputs custom level log 
Custom Logf outputs formatted custom level log 
Custom Log Func outputs custom level log returned from the function 
Print outputs Print log 
Printf outputs formatted Print log 
Print Func outputs Print log returned from the function 
Print outputs Print log 
Println outputs fixed line Print log 
Printf outputs formatted Print log 
Print Func outputs Print log returned from the function 
Error outputs Error log 
Errorf outputs formatted Error log 
Error Func outputs Error level log returned from the function 
Error outputs Error log 
Errorf outputs formatted Error log 
Error Func outputs Error level log returned from the function 
Fail outputs Failed log 
Failf outputs formatted Failed log 
Fail Func outputs Fail level log returned from the function 
Fail outputs Failed log 
Failf outputs formatted Failed log 
Fail Func outputs Fail level log returned from the function 
Fatal outputs Failed log and exit program 
Fatalf outputs formatted Failed log and exit program 
is Mode Enable returns the level has already turned on the logging 
Wrap returns a wrapped version of w that provides the exact same interface as w Specifically if w implements any combination of http Flusher http Close Notifier http Hijacker io Reader From The wrapped version will implement the exact same combination If no hooks are set the wrapped version also behaves exactly as w Hooks targeting methods not supported by w are ignored Any other hooks will intercept the method they target and may modify the call s arguments and or return values The Capture Metrics implementation serves as a working example for how the hooks can be used 
Wrap returns a wrapped version of w that provides the exact same interface as w Specifically if w implements any combination of http Flusher http Close Notifier http Hijacker io Reader From http Pusher The wrapped version will implement the exact same combination If no hooks are set the wrapped version also behaves exactly as w Hooks targeting methods not supported by w are ignored Any other hooks will intercept the method they target and may modify the call s arguments and or return values The Capture Metrics implementation serves as a working example for how the hooks can be used 
Capture Metrics wraps the given hnd executes it with the given w and r and returns the metrics it captured from it 
Capture Metrics Fn wraps w and calls fn with the wrapped w and returns the resulting metrics This is very similar to Capture Metrics which is just sugar on top of this func but is a more usable interface if your application doesn t use the Go http Handler interface 
Get value by key insert the key if not exist 
has Child wherether the from node has children 
Save saves the cedar to an io Writer where data Type is either json or gob 
Save To File saves the cedar to a file where data Type is either json or gob 
Load loads the cedar from an io Writer where data Type is either json or gob 
Load From File loads the cedar from a file where data Type is either json or gob 
Status reports the following statistics of the cedar keys number of keys that are in the cedar nodes number of trie nodes slots in the base array has been taken size the size of the base array used by the cedar capacity the capicity of the base array used by the cedar 
Jump travels from a node from to another node to by following the path path For example if the following keys were inserted id key abc ab abcd then Jump byte ab nil reach ab from root Jump byte c nil reach abc from ab Jump byte cd nil reach abcd from ab 
Key returns the key of the node with the given id It will return Err No Path if the node does not exist 
Value returns the value of the node with the given id It will return Err No Value if the node does not have a value 
Insert adds a key value pair into the cedar It will return Err Invalid Value if value or Value Limit 
Update increases the value associated with the key The key will be inserted if it is not in the cedar It will return Err Invalid Value if the updated value or Value Limit 
Delete removes a key value pair from the cedar It will return Err No Path if the key has not been added 
Get returns the value associated with the given key It is equivalent to id err Jump key value err Value id Thus it may return Err No Path or Err No Value 
Prefix Match returns a list of at most num nodes which match the prefix of the key If num is it returns all matches For example if the following keys were inserted id key abc ab abcd then Prefix Match byte abc match ab Prefix Match byte abcd match ab abc abcd 
Prefix Predict returns a list of at most num nodes which has the key as their prefix These nodes are ordered by their keys If num is it returns all matches For example if the following keys were inserted id key abc ab abcd then Prefix Predict byte ab predict ab abc Prefix Predict byte ab predict ab abc abcd 
Set parses and updates v from the given version string Implements flag Value 
Compare tests if v is less than equal to or greater than version B returning or respectively 
Slice converts the comparable parts of the semver into a slice of integers 
Bump Major increments the Major field by and resets all other fields to their default values 
Bump Minor increments the Minor field by and resets all other fields to their default values 
Bump Patch increments the Patch field by and resets all other fields to their default values 
validate Identifier makes sure the provided identifier satisfies semver spec 
 op root key idx range filter scan 
new Stream returns a new stream 
add Subscriber will create a new subscriber on a stream 
New will create a server and setup defaults 
Close shuts down the server closes all of the streams and connections 
Create Stream will create a new stream and register it 
Remove Stream will remove a stream 
Stream Exists checks whether a stream by a given id exists 
Publish sends a mesage to every client in a stream ID 
New Client creates a new client 
Subscribe to a data stream 
Subscribe Chan sends all events to the provided channel 
Subscribe Raw to an sse endpoint 
Unsubscribe unsubscribes a channel 
New Event Stream Reader creates an instance of Event Stream Reader 
Read Event scans the Event Stream for events 
HTTPHandler serves new connections with events for a given stream 
Add event to eventlog 
Replay events to a subscriber 
read Config reads user Config from path and a private key It expects to find the key at the same location by replacing path extention with key func read Config name string user Config error 
write Config writes uc to a file specified by path creating paret dirs along the way If file does not exists it will be created with mod This function does not store uc key func write Config path string uc user Config error 
read Key reads a private rsa key from path The key is expected to be in PEM format 
write Key writes k to the specified path in PEM format If file does not exists it will be created with mod 
any Key reads the key from file or generates a new one if gen true It returns an error if filename exists but cannot be read A newly generated key is also stored to filename 
same Dir returns filename path placing it in the same dir as existing file 
print Account outputs account into into w using tabwriter 
tmpl executes the given template text on data writing the result to w 
print Usage prints usage Template to w 
Name returns the command s name the first word in the usage line 
is Local Address works by checking if the address is under private CIDR blocks List of private CIDR blocks can be seen on https en wikipedia org wiki Private network https en wikipedia org wiki Link local address 
From Request return client s real public IP address from http request headers 
Do executes DOMStorage clear against the provided context 
Do executes DOMStorage disable against the provided context 
Do executes DOMStorage get DOMStorage Items against the provided context returns entries 
Remove DOMStorage Item no description See https chromedevtools github io devtools protocol tot DOMStorage method remove DOMStorage Item parameters storage ID key 
Do executes DOMStorage remove DOMStorage Item against the provided context 
Set DOMStorage Item no description See https chromedevtools github io devtools protocol tot DOMStorage method set DOMStorage Item parameters storage ID key value 
Do executes DOMStorage set DOMStorage Item against the provided context 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Deliver Push Message no description See https chromedevtools github io devtools protocol tot Service Worker method deliver Push Message parameters origin registration ID data 
Do executes Service Worker deliver Push Message against the provided context 
Dispatch Sync Event no description See https chromedevtools github io devtools protocol tot Service Worker method dispatch Sync Event parameters origin registration ID tag last Chance 
Do executes Service Worker dispatch Sync Event against the provided context 
Do executes Service Worker inspect Worker against the provided context 
Do executes Service Worker set Force Update On Page Load against the provided context 
Do executes Service Worker skip Waiting against the provided context 
Do executes Service Worker start Worker against the provided context 
Do executes Service Worker stop All Workers against the provided context 
Do executes Service Worker stop Worker against the provided context 
Do executes Service Worker unregister against the provided context 
Do executes Service Worker update Registration against the provided context 
Do executes Tethering bind against the provided context 
Do executes Tethering unbind against the provided context 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Error satisfies the error interface 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Do executes Animation get Current Time against the provided context returns current Time Current time of the page 
Do executes Animation get Playback Rate against the provided context returns playback Rate Playback rate for animations on page 
Do executes Animation release Animations against the provided context 
Do executes Animation resolve Animation against the provided context returns remote Object Corresponding remote object 
Seek Animations seek a set of animations to a particular time within each animation See https chromedevtools github io devtools protocol tot Animation method seek Animations parameters animations List of animation ids to seek current Time Set the current time of each animation 
Do executes Animation seek Animations against the provided context 
Set Paused sets the paused state of a set of animations See https chromedevtools github io devtools protocol tot Animation method set Paused parameters animations Animations to set the pause state of paused Paused state to set to 
Do executes Animation set Paused against the provided context 
Do executes Animation set Playback Rate against the provided context 
Set Timing sets the timing of an animation node See https chromedevtools github io devtools protocol tot Animation method set Timing parameters animation ID Animation id duration Duration of the animation delay Delay of the animation 
Do executes Animation set Timing against the provided context 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Do executes Memory get DOMCounters against the provided context returns documents nodes js Event Listeners 
Do executes Memory prepare For Leak Detection against the provided context 
Do executes Memory forcibly Purge Java Script Memory against the provided context 
Do executes Memory set Pressure Notifications Suppressed against the provided context 
Do executes Memory simulate Pressure Notification against the provided context 
With Sampling Interval average number of bytes between samples 
With Suppress Randomness do not randomize intervals between samples 
Do executes Memory start Sampling against the provided context 
Do executes Memory stop Sampling against the provided context 
Do executes Memory get All Time Sampling Profile against the provided context returns profile 
Do executes Memory get Browser Sampling Profile against the provided context returns profile 
Do executes Memory get Sampling Profile against the provided context returns profile 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Do executes Device Orientation clear Device Orientation Override against the provided context 
Set Device Orientation Override overrides the Device Orientation See https chromedevtools github io devtools protocol tot Device Orientation method set Device Orientation Override parameters alpha Mock alpha beta Mock beta gamma Mock gamma 
Do executes Device Orientation set Device Orientation Override against the provided context 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Do executes Web Audio get Realtime Data against the provided context returns realtime Data 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Do executes Log start Violations Report against the provided context 
Do executes Log stop Violations Report against the provided context 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
String returns the Modifier as string value 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
With Node ID identifier of the node to get the partial accessibility tree for 
With Backend Node ID identifier of the backend node to get the partial accessibility tree for 
With Object ID Java Script object id of the node wrapper to get the partial accessibility tree for 
With Fetch Relatives whether to fetch this nodes ancestors siblings and children Defaults to true 
Do executes Accessibility get Partial AXTree against the provided context returns nodes The Accessibility AXNode for this DOM node if it exists plus its ancestors siblings and children if requested 
Do executes Accessibility get Full AXTree against the provided context returns nodes 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Do executes Performance set Time Domain against the provided context 
Do executes Performance get Metrics against the provided context returns metrics Current values for run time metrics 
Do executes Layer Tree compositing Reasons against the provided context returns compositing Reasons A list of strings specifying reasons for the given layer to become composited 
Do executes Layer Tree load Snapshot against the provided context returns snapshot ID The id of the snapshot 
Do executes Layer Tree make Snapshot against the provided context returns snapshot ID The id of the layer snapshot 
With Min Repeat Count the maximum number of times to replay the snapshot if not specified 
With Min Duration the minimum duration in seconds to replay the snapshot 
With Clip Rect the clip rectangle to apply when replaying the snapshot 
Do executes Layer Tree profile Snapshot against the provided context returns timings The array of paint profiles one per run 
Do executes Layer Tree release Snapshot against the provided context 
With From Step the first step to replay from replay from the very start if not specified 
With To Step the last step to replay to replay till the end if not specified 
With Scale the scale to apply while replaying defaults to 
Do executes Layer Tree replay Snapshot against the provided context returns data URL A data URL for resulting image 
Do executes Layer Tree snapshot Command Log against the provided context returns command Log The array of canvas function calls 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Marshal Easy JSON satisfies easyjson Marshaler 
Unmarshal Easy JSON satisfies easyjson Unmarshaler 
Unmarshal JSON satisfies json Unmarshaler 
Clear Object Store clears all entries from an object store See https chromedevtools github io devtools protocol tot Indexed DB method clear Object Store parameters security Origin Security origin database Name Database name object Store Name Object store name 
Do executes Indexed DB clear Object Store against the provided context 
Delete Database deletes a database See https chromedevtools github io devtools protocol tot Indexed DB method delete Database parameters security Origin Security origin database Name Database name 
Do executes Indexed DB delete Database against the provided context 
Delete Object Store Entries delete a range of entries from an object store See https chromedevtools github io devtools protocol tot Indexed DB method delete Object Store Entries parameters security Origin database Name object Store Name key Range Range of entry keys to delete 
Do executes Indexed DB delete Object Store Entries against the provided context 
Request Data requests data from object store or index See https chromedevtools github io devtools protocol tot Indexed DB method request Data parameters security Origin Security origin database Name Database name object Store Name Object store name index Name Index name empty string for object store data requests skip Count Number of records to skip page Size Number of records to fetch 
With Key Range key range 
Do executes Indexed DB request Data against the provided context returns object Store Data Entries Array of object store data entries has More If true there are more entries to fetch in the given range 
Get Metadata gets metadata of an object store See https chromedevtools github io devtools protocol tot Indexed DB method get Metadata parameters security Origin Security origin database Name Database name object Store Name Object store name 
Do executes Indexed DB get Metadata against the provided context returns entries Count the entries count key Generator Value the current value of key generator to become the next inserted key into the object store Valid if object Store auto Increment is true 
Request Database requests database with given name in given frame See https chromedevtools github io devtools protocol tot Indexed DB method request Database parameters security Origin Security origin database Name Database name 
Do executes Indexed DB request Database against the provided context returns database With Object Stores Database with an array of object stores 
Do executes Indexed DB request Database Names against the provided context returns database Names Database names for origin 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
Marshal JSON supports json Marshaler interface 
Unmarshal JSON supports json Unmarshaler interface 
