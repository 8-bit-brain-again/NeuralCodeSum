func mustWaitPinReady ( t * testing . T , cli * clientv3 . Client ) { _ , err := cli . Get ( ctx , " " ) cancel ( ) if err != nil { t . Fatal ( err ) } } 
func newGatewayCommand ( ) * cobra . Command { lpc := & cobra . Command { Use : " " , Short : " " , } lpc . AddCommand ( newGatewayStartCommand ( ) ) return lpc } 
func NewLimitedBufferReader ( r io . Reader , n int ) io . Reader { return & limitedBufferReader { r : r , n : n , } } 
func WithAbortContext ( ctx context . Context ) stmOption { return func ( so * stmOptions ) { so . ctx = ctx } } 
func WithPrefetch ( keys ... string ) stmOption { return func ( so * stmOptions ) { so . prefetch = append ( so . prefetch , keys ... ) } } 
func NewSTM ( c * v3 . Client , apply func ( STM ) error , so ... stmOption ) ( * v3 . TxnResponse , error ) { opts := & stmOptions { ctx : c . Ctx ( ) } for _ , f := range so { f ( opts ) } if len ( opts . prefetch ) != 0 { f := apply apply = func ( s STM ) error { s . Get ( opts . prefetch ... ) return f ( s ) } } return runSTM ( mkSTM ( c , opts ) , apply ) } 
func ( rs readSet ) first ( ) int64 { ret := int64 ( math . MaxInt64 - 1 ) for _ , resp := range rs { if rev := resp . Header . Revision ; rev < ret { ret = rev } } return ret } 
func ( rs readSet ) cmps ( ) [ ] v3 . Cmp { cmps := make ( [ ] v3 . Cmp , 0 , len ( rs ) ) for k , rk := range rs { cmps = append ( cmps , isKeyCurrent ( k , rk ) ) } return cmps } 
func ( ws writeSet ) cmps ( rev int64 ) [ ] v3 . Cmp { cmps := make ( [ ] v3 . Cmp , 0 , len ( ws ) ) for key := range ws { cmps = append ( cmps , v3 . Compare ( v3 . ModRevision ( key ) , " " , rev ) ) } return cmps } 
func ( ws writeSet ) puts ( ) [ ] v3 . Op { puts := make ( [ ] v3 . Op , 0 , len ( ws ) ) for _ , v := range ws { puts = append ( puts , v . op ) } return puts } 
func NewSTMRepeatable ( ctx context . Context , c * v3 . Client , apply func ( STM ) error ) ( * v3 . TxnResponse , error ) { return NewSTM ( c , apply , WithAbortContext ( ctx ) , WithIsolation ( RepeatableReads ) ) } 
func NewSTMSerializable ( ctx context . Context , c * v3 . Client , apply func ( STM ) error ) ( * v3 . TxnResponse , error ) { return NewSTM ( c , apply , WithAbortContext ( ctx ) , WithIsolation ( Serializable ) ) } 
func NewSTMReadCommitted ( ctx context . Context , c * v3 . Client , apply func ( STM ) error ) ( * v3 . TxnResponse , error ) { return NewSTM ( c , apply , WithAbortContext ( ctx ) , WithIsolation ( ReadCommitted ) ) } 
func NewCertPool ( CAFiles [ ] string ) ( * x509 . CertPool , error ) { certPool := x509 . NewCertPool ( ) for _ , CAFile := range CAFiles { pemByte , err := ioutil . ReadFile ( CAFile ) if err != nil { return nil , err } for { var block * pem . Block block , pemByte = pem . Decode ( pemByte ) if block == nil { break } cert , err := x509 . ParseCertificate ( block . Bytes ) if err != nil { return nil , err } certPool . AddCert ( cert ) } } return certPool , nil } 
func NewCert ( certfile , keyfile string , parseFunc func ( [ ] byte , [ ] byte ) ( tls . Certificate , error ) ) ( * tls . Certificate , error ) { cert , err := ioutil . ReadFile ( certfile ) if err != nil { return nil , err } key , err := ioutil . ReadFile ( keyfile ) if err != nil { return nil , err } if parseFunc == nil { parseFunc = tls . X509KeyPair } tlsCert , err := parseFunc ( cert , key ) if err != nil { return nil , err } return & tlsCert , nil } 
func NewGRPCLoggerV2 ( lcfg zap . Config ) ( grpclog . LoggerV2 , error ) { lg , err := lcfg . Build ( zap . AddCallerSkip ( 1 ) ) if err != nil { return nil , err } return & zapGRPCLogger { lg : lg , sugar : lg . Sugar ( ) } , nil } 
func NewGRPCLoggerV2FromZapCore ( cr zapcore . Core , syncer zapcore . WriteSyncer ) grpclog . LoggerV2 { return & zapGRPCLogger { lg : lg , sugar : lg . Sugar ( ) } } 
func ( p * peer ) Pause ( ) { p . mu . Lock ( ) defer p . mu . Unlock ( ) p . paused = true p . msgAppReader . pause ( ) p . msgAppV2Reader . pause ( ) } 
func ( p * peer ) Resume ( ) { p . mu . Lock ( ) defer p . mu . Unlock ( ) p . paused = false p . msgAppReader . resume ( ) p . msgAppV2Reader . resume ( ) } 
func ( p * peer ) pick ( m raftpb . Message ) ( writec chan <- raftpb . Message , picked string ) { var ok bool } else if writec , ok = p . msgAppV2Writer . writec ( ) ; ok && isMsgApp ( m ) { return writec , streamAppV2 } else if writec , ok = p . writer . writec ( ) ; ok { return writec , streamMsg } return p . pipeline . msgc , pipelineMsg } 
func ( s * snapshotSender ) post ( req * http . Request ) ( err error ) { ctx , cancel := context . WithCancel ( context . Background ( ) ) req = req . WithContext ( ctx ) defer cancel ( ) type responseAndError struct { resp * http . Response body [ ] byte err error } result := make ( chan responseAndError , 1 ) go func ( ) { resp , err := s . tr . pipelineRt . RoundTrip ( req ) if err != nil { result <- responseAndError { resp , nil , err } return } body , err := ioutil . ReadAll ( resp . Body ) result <- responseAndError { resp , body , err } } ( ) select { case <- s . stopc : return errStopped case r := <- result : if r . err != nil { return r . err } return checkPostResponse ( r . resp , r . body , req , s . to ) } } 
func newTxnResp ( rt * pb . TxnRequest , txnPath [ ] bool ) ( txnResp * pb . TxnResponse , txnCount int ) { reqs := rt . Success if ! txnPath [ 0 ] { reqs = rt . Failure } resps := make ( [ ] * pb . ResponseOp , len ( reqs ) ) txnResp = & pb . TxnResponse { Responses : resps , Succeeded : txnPath [ 0 ] , Header : & pb . ResponseHeader { } , } for i , req := range reqs { switch tv := req . Request . ( type ) { case * pb . RequestOp_RequestRange : resps [ i ] = & pb . ResponseOp { Response : & pb . ResponseOp_ResponseRange { } } case * pb . RequestOp_RequestPut : resps [ i ] = & pb . ResponseOp { Response : & pb . ResponseOp_ResponsePut { } } case * pb . RequestOp_RequestDeleteRange : resps [ i ] = & pb . ResponseOp { Response : & pb . ResponseOp_ResponseDeleteRange { } } case * pb . RequestOp_RequestTxn : resp , txns := newTxnResp ( tv . RequestTxn , txnPath [ 1 : ] ) resps [ i ] = & pb . ResponseOp { Response : & pb . ResponseOp_ResponseTxn { ResponseTxn : resp } } txnPath = txnPath [ 1 + txns : ] txnCount += txns + 1 default : } } return txnResp , txnCount } 
func applyCompare ( rv mvcc . ReadView , c * pb . Compare ) bool { if err != nil { return false } if len ( rr . KVs ) == 0 { if c . Target == pb . Compare_VALUE { } return compareKV ( c , mvccpb . KeyValue { } ) } for _ , kv := range rr . KVs { if ! compareKV ( c , kv ) { return false } } return true } 
func OpCompact ( rev int64 , opts ... CompactOption ) CompactOp { ret := CompactOp { revision : rev } ret . applyCompactOpts ( opts ) return ret } 
func NewPriorityQueue ( client * v3 . Client , key string ) * PriorityQueue { return & PriorityQueue { client , context . TODO ( ) , key + " " } } 
func ( q * PriorityQueue ) Enqueue ( val string , pr uint16 ) error { prefix := fmt . Sprintf ( " " , q . key , pr ) _ , err := newSequentialKV ( q . client , prefix , val ) return err } 
func NewLeaderStats ( id string ) * LeaderStats { return & LeaderStats { leaderStats : leaderStats { Leader : id , Followers : make ( map [ string ] * FollowerStats ) , } , } } 
func ( fs * FollowerStats ) Succ ( d time . Duration ) { fs . Lock ( ) defer fs . Unlock ( ) total := float64 ( fs . Counts . Success ) * fs . Latency . Average totalSquare := float64 ( fs . Counts . Success ) * fs . Latency . averageSquare fs . Counts . Success ++ fs . Latency . Current = float64 ( d ) / ( 1000000.0 ) if fs . Latency . Current > fs . Latency . Maximum { fs . Latency . Maximum = fs . Latency . Current } if fs . Latency . Current < fs . Latency . Minimum { fs . Latency . Minimum = fs . Latency . Current } fs . Latency . Average = ( total + fs . Latency . Current ) / float64 ( fs . Counts . Success ) fs . Latency . averageSquare = ( totalSquare + fs . Latency . Current * fs . Latency . Current ) / float64 ( fs . Counts . Success ) } 
func ( fs * FollowerStats ) Fail ( ) { fs . Lock ( ) defer fs . Unlock ( ) fs . Counts . Fail ++ } 
func ( wbs * watchBroadcasts ) delete ( w * watcher ) int { wbs . mu . Lock ( ) defer wbs . mu . Unlock ( ) wb , ok := wbs . watchers [ w ] if ! ok { panic ( " " ) } delete ( wbs . watchers , w ) wb . delete ( w ) if wb . empty ( ) { delete ( wbs . bcasts , wb ) wb . stop ( ) } return len ( wbs . bcasts ) } 
func startStreamWriter ( lg * zap . Logger , local , id types . ID , status * peerStatus , fs * stats . FollowerStats , r Raft ) * streamWriter { w := & streamWriter { lg : lg , localID : local , peerID : id , status : status , fs : fs , r : r , msgc : make ( chan raftpb . Message , streamBufSize ) , connc : make ( chan * outgoingConn ) , stopc : make ( chan struct { } ) , done : make ( chan struct { } ) , } go w . run ( ) return w } 
func checkStreamSupport ( v * semver . Version , t streamType ) bool { nv := & semver . Version { Major : v . Major , Minor : v . Minor } for _ , s := range supportedStream [ nv . String ( ) ] { if s == t { return true } } return false } 
func ( pr * Progress ) maybeUpdate ( n uint64 ) bool { var updated bool if pr . Match < n { pr . Match = n updated = true pr . resume ( ) } if pr . Next < n + 1 { pr . Next = n + 1 } return updated } 
func ( pr * Progress ) maybeDecrTo ( rejected , last uint64 ) bool { if pr . State == ProgressStateReplicate { } return true } } if pr . Next = min ( rejected , last + 1 ) ; pr . Next < 1 { pr . Next = 1 } pr . resume ( ) return true } 
func ( pr * Progress ) IsPaused ( ) bool { switch pr . State { case ProgressStateProbe : return pr . Paused case ProgressStateReplicate : return pr . ins . full ( ) case ProgressStateSnapshot : return true default : panic ( " " ) } } 
func ( pr * Progress ) needSnapshotAbort ( ) bool { return pr . State == ProgressStateSnapshot && pr . Match >= pr . PendingSnapshot } 
func ( in * inflights ) add ( inflight uint64 ) { if in . full ( ) { panic ( " " ) } next := in . start + in . count size := in . size if next >= size { next -= size } if next >= len ( in . buffer ) { in . growBuf ( ) } in . buffer [ next ] = inflight in . count ++ } 
func ( in * inflights ) growBuf ( ) { newSize := len ( in . buffer ) * 2 if newSize == 0 { newSize = 1 } else if newSize > in . size { newSize = in . size } newBuffer := make ( [ ] uint64 , newSize ) copy ( newBuffer , in . buffer ) in . buffer = newBuffer } 
func ( in * inflights ) freeTo ( to uint64 ) { if in . count == 0 || to < in . buffer [ in . start ] { } idx := in . start var i int for i = 0 ; i < in . count ; i ++ { if to < in . buffer [ idx ] { } if idx ++ ; idx >= size { idx -= size } } in . start = idx if in . count == 0 { } } 
func CanonicalURLPath ( p string ) string { if p == " " { return " " } if p [ 0 ] != '/' { p = " " + p } np := path . Clean ( p ) } return np } 
func ( s * Snapshotter ) SaveDBFrom ( r io . Reader , id uint64 ) ( int64 , error ) { start := time . Now ( ) f , err := ioutil . TempFile ( s . dir , " " ) if err != nil { return 0 , err } var n int64 n , err = io . Copy ( f , r ) if err == nil { fsyncStart := time . Now ( ) err = fileutil . Fsync ( f ) snapDBFsyncSec . Observe ( time . Since ( fsyncStart ) . Seconds ( ) ) } f . Close ( ) if err != nil { os . Remove ( f . Name ( ) ) return n , err } fn := s . dbFilePath ( id ) if fileutil . Exist ( fn ) { os . Remove ( f . Name ( ) ) return n , nil } err = os . Rename ( f . Name ( ) , fn ) if err != nil { os . Remove ( f . Name ( ) ) return n , err } if s . lg != nil { s . lg . Info ( " " , zap . String ( " " , fn ) , zap . Int64 ( " " , n ) , zap . String ( " " , humanize . Bytes ( uint64 ( n ) ) ) , ) } else { plog . Infof ( " " , n ) } snapDBSaveSec . Observe ( time . Since ( start ) . Seconds ( ) ) return n , nil } 
func ( s * Snapshotter ) DBFilePath ( id uint64 ) ( string , error ) { if _ , err := fileutil . ReadDir ( s . dir ) ; err != nil { return " " , err } fn := s . dbFilePath ( id ) if fileutil . Exist ( fn ) { return fn , nil } if s . lg != nil { s . lg . Warn ( " " , zap . Uint64 ( " " , id ) , zap . String ( " " , fn ) , zap . Error ( ErrNoDBSnapshot ) , ) } return " " , ErrNoDBSnapshot } 
func ( us * UniqueStringsValue ) Set ( s string ) error { us . Values = make ( map [ string ] struct { } ) for _ , v := range strings . Split ( s , " " ) { us . Values [ v ] = struct { } { } } return nil } 
func NewUniqueStringsValue ( s string ) ( us * UniqueStringsValue ) { us = & UniqueStringsValue { Values : make ( map [ string ] struct { } ) } if s == " " { return us } if err := us . Set ( s ) ; err != nil { plog . Panicf ( " " , err ) } return us } 
func UniqueStringsFromFlag ( fs * flag . FlagSet , flagName string ) [ ] string { return ( * fs . Lookup ( flagName ) . Value . ( * UniqueStringsValue ) ) . stringSlice ( ) } 
func UniqueStringsMapFromFlag ( fs * flag . FlagSet , flagName string ) map [ string ] struct { } { return ( * fs . Lookup ( flagName ) . Value . ( * UniqueStringsValue ) ) . Values } 
func Percentiles ( nums [ ] float64 ) ( pcs [ ] float64 , data [ ] float64 ) { return pctls , percentiles ( nums ) } 
func ( c * ServerConfig ) VerifyBootstrap ( ) error { if err := c . hasLocalMember ( ) ; err != nil { return err } if err := c . advertiseMatchesCluster ( ) ; err != nil { return err } if checkDuplicateURL ( c . InitialPeerURLsMap ) { return fmt . Errorf ( " " , c . InitialPeerURLsMap ) } if c . InitialPeerURLsMap . String ( ) == " " && c . DiscoveryURL == " " { return fmt . Errorf ( " " ) } return nil } 
func ( c * ServerConfig ) VerifyJoinExisting ( ) error { } if checkDuplicateURL ( c . InitialPeerURLsMap ) { return fmt . Errorf ( " " , c . InitialPeerURLsMap ) } if c . DiscoveryURL != " " { return fmt . Errorf ( " " ) } return nil } 
func ( c * ServerConfig ) hasLocalMember ( ) error { if urls := c . InitialPeerURLsMap [ c . Name ] ; urls == nil { return fmt . Errorf ( " " , c . Name ) } return nil } 
func ( c * ServerConfig ) advertiseMatchesCluster ( ) error { urls , apurls := c . InitialPeerURLsMap [ c . Name ] , c . PeerURLs . StringSlice ( ) urls . Sort ( ) sort . Strings ( apurls ) ctx , cancel := context . WithTimeout ( context . TODO ( ) , 30 * time . Second ) defer cancel ( ) ok , err := netutil . URLStringsEqual ( ctx , c . Logger , apurls , urls . StringSlice ( ) ) if ok { return nil } initMap , apMap := make ( map [ string ] struct { } ) , make ( map [ string ] struct { } ) for _ , url := range c . PeerURLs { apMap [ url . String ( ) ] = struct { } { } } for _ , url := range c . InitialPeerURLsMap [ c . Name ] { initMap [ url . String ( ) ] = struct { } { } } missing := [ ] string { } for url := range initMap { if _ , ok := apMap [ url ] ; ! ok { missing = append ( missing , url ) } } if len ( missing ) > 0 { for i := range missing { missing [ i ] = c . Name + " " + missing [ i ] } mstr := strings . Join ( missing , " " ) apStr := strings . Join ( apurls , " " ) return fmt . Errorf ( " " , mstr , apStr , err ) } for url := range apMap { if _ , ok := initMap [ url ] ; ! ok { missing = append ( missing , url ) } } if len ( missing ) > 0 { mstr := strings . Join ( missing , " " ) umap := types . URLsMap ( map [ string ] types . URLs { c . Name : c . PeerURLs } ) return fmt . Errorf ( " " , mstr , umap . String ( ) ) } umap := types . URLsMap ( map [ string ] types . URLs { c . Name : c . PeerURLs } ) return fmt . Errorf ( " " , apStr , umap . String ( ) , err ) } 
func ( c * ServerConfig ) ReqTimeout ( ) time . Duration { } 
func getStatus ( r * raft ) Status { s := getStatusWithoutProgress ( r ) if s . RaftState == StateLeader { s . Progress = getProgressCopy ( r ) } return s } 
func ( s Status ) MarshalJSON ( ) ( [ ] byte , error ) { j := fmt . Sprintf ( `{"id":"%x","term":%d,"vote":"%x","commit":%d,"lead":"%x","raftState":%q,"applied":%d,"progress":{` , s . ID , s . Term , s . Vote , s . Commit , s . Lead , s . RaftState , s . Applied ) if len ( s . Progress ) == 0 { j += " " } else { for k , v := range s . Progress { subj := fmt . Sprintf ( `"%x":{"match":%d,"next":%d,"state":%q},` , k , v . Match , v . Next , v . State ) j += subj } } j += fmt . Sprintf ( `"leadtransferee":"%x"}` , s . LeadTransferee ) return [ ] byte ( j ) , nil } 
func GetDefaultHost ( ) ( string , error ) { rmsgs , rerr := getDefaultRoutes ( ) if rerr != nil { return " " , rerr } } delete ( rmsgs , syscall . AF_INET ) } for family := range rmsgs { families = append ( families , int ( family ) ) } sort . Ints ( families ) for _ , f := range families { family := uint8 ( f ) if host , err := chooseHost ( family , rmsgs [ family ] ) ; host != " " || err != nil { return host , err } } return " " , errNoDefaultHost } 
func getIfaceAddr ( idx uint32 , family uint8 ) ( * syscall . NetlinkMessage , error ) { dat , err := syscall . NetlinkRIB ( syscall . RTM_GETADDR , int ( family ) ) if err != nil { return nil , err } msgs , msgErr := syscall . ParseNetlinkMessage ( dat ) if msgErr != nil { return nil , msgErr } ifaddrmsg := syscall . IfAddrmsg { } for _ , m := range msgs { if m . Header . Type != syscall . RTM_NEWADDR { continue } buf := bytes . NewBuffer ( m . Data [ : syscall . SizeofIfAddrmsg ] ) if rerr := binary . Read ( buf , cpuutil . ByteOrder ( ) , & ifaddrmsg ) ; rerr != nil { continue } if ifaddrmsg . Index == idx { return & m , nil } } return nil , fmt . Errorf ( " " , idx ) } 
func getIfaceLink ( idx uint32 ) ( * syscall . NetlinkMessage , error ) { dat , err := syscall . NetlinkRIB ( syscall . RTM_GETLINK , syscall . AF_UNSPEC ) if err != nil { return nil , err } msgs , msgErr := syscall . ParseNetlinkMessage ( dat ) if msgErr != nil { return nil , msgErr } ifinfomsg := syscall . IfInfomsg { } for _ , m := range msgs { if m . Header . Type != syscall . RTM_NEWLINK { continue } buf := bytes . NewBuffer ( m . Data [ : syscall . SizeofIfInfomsg ] ) if rerr := binary . Read ( buf , cpuutil . ByteOrder ( ) , & ifinfomsg ) ; rerr != nil { continue } if ifinfomsg . Index == int32 ( idx ) { return & m , nil } } return nil , fmt . Errorf ( " " , idx ) } 
func GetDefaultInterfaces ( ) ( map [ string ] uint8 , error ) { interfaces := make ( map [ string ] uint8 ) rmsgs , rerr := getDefaultRoutes ( ) if rerr != nil { return interfaces , rerr } for family , rmsg := range rmsgs { _ , oif , err := parsePREFSRC ( rmsg ) if err != nil { return interfaces , err } ifmsg , ierr := getIfaceLink ( oif ) if ierr != nil { return interfaces , ierr } attrs , aerr := syscall . ParseNetlinkRouteAttr ( ifmsg ) if aerr != nil { return interfaces , aerr } for _ , attr := range attrs { if attr . Attr . Type == syscall . IFLA_IFNAME { } } } if len ( interfaces ) > 0 { return interfaces , nil } return interfaces , errNoDefaultInterface } 
func parsePREFSRC ( m * syscall . NetlinkMessage ) ( host string , oif uint32 , err error ) { var attrs [ ] syscall . NetlinkRouteAttr attrs , err = syscall . ParseNetlinkRouteAttr ( m ) if err != nil { return " " , 0 , err } for _ , attr := range attrs { if attr . Attr . Type == syscall . RTA_PREFSRC { host = net . IP ( attr . Value ) . String ( ) } if attr . Attr . Type == syscall . RTA_OIF { oif = cpuutil . ByteOrder ( ) . Uint32 ( attr . Value ) } if host != " " && oif != uint32 ( 0 ) { break } } if oif == 0 { err = errNoDefaultRoute } return host , oif , err } 
func lsCommandFunc ( c * cli . Context , ki client . KeysAPI ) { key := " " if len ( c . Args ( ) ) != 0 { key = c . Args ( ) [ 0 ] } sort := c . Bool ( " " ) recursive := c . Bool ( " " ) quorum := c . Bool ( " " ) ctx , cancel := contextWithTotalTimeout ( c ) resp , err := ki . Get ( ctx , key , & client . GetOptions { Sort : sort , Recursive : recursive , Quorum : quorum } ) cancel ( ) if err != nil { handleError ( c , ExitServerError , err ) } printLs ( c , resp ) } 
func printLs ( c * cli . Context , resp * client . Response ) { if c . GlobalString ( " " ) == " " { if ! resp . Node . Dir { fmt . Println ( resp . Node . Key ) } for _ , node := range resp . Node . Nodes { rPrint ( c , node ) } } else { } } 
func rPrint ( c * cli . Context , n * client . Node ) { if n . Dir && c . Bool ( " " ) { fmt . Println ( fmt . Sprintf ( " " , n . Key ) ) } else { fmt . Println ( n . Key ) } for _ , node := range n . Nodes { rPrint ( c , node ) } } 
func NewLeaseRenewerCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : runLeaseRenewerFunc , } cmd . Flags ( ) . Int64Var ( & leaseTTL , " " , 5 , " " ) return cmd } 
func Read ( lg * zap . Logger , snapname string ) ( * raftpb . Snapshot , error ) { b , err := ioutil . ReadFile ( snapname ) if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , snapname ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , snapname , err ) } return nil , err } if len ( b ) == 0 { if lg != nil { lg . Warn ( " " , zap . String ( " " , snapname ) ) } else { plog . Errorf ( " " ) } return nil , ErrEmptySnapshot } var serializedSnap snappb . Snapshot if err = serializedSnap . Unmarshal ( b ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , snapname ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , snapname , err ) } return nil , err } if len ( serializedSnap . Data ) == 0 || serializedSnap . Crc == 0 { if lg != nil { lg . Warn ( " " , zap . String ( " " , snapname ) ) } else { plog . Errorf ( " " ) } return nil , ErrEmptySnapshot } crc := crc32 . Update ( 0 , crcTable , serializedSnap . Data ) if crc != serializedSnap . Crc { if lg != nil { lg . Warn ( " " , zap . String ( " " , snapname ) , zap . Uint32 ( " " , serializedSnap . Crc ) , zap . Uint32 ( " " , crc ) , ) } else { plog . Errorf ( " " , snapname ) } return nil , ErrCRCMismatch } var snap raftpb . Snapshot if err = snap . Unmarshal ( serializedSnap . Data ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , snapname ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , snapname , err ) } return nil , err } return & snap , nil } 
func ( s * Snapshotter ) snapNames ( ) ( [ ] string , error ) { dir , err := os . Open ( s . dir ) if err != nil { return nil , err } defer dir . Close ( ) names , err := dir . Readdirnames ( - 1 ) if err != nil { return nil , err } snaps := checkSuffix ( s . lg , names ) if len ( snaps ) == 0 { return nil , ErrNoSnapshot } sort . Sort ( sort . Reverse ( sort . StringSlice ( snaps ) ) ) return snaps , nil } 
func GracefulClose ( resp * http . Response ) { io . Copy ( ioutil . Discard , resp . Body ) resp . Body . Close ( ) } 
func GetHostname ( req * http . Request ) string { if req == nil { return " " } h , _ , err := net . SplitHostPort ( req . Host ) if err != nil { return req . Host } return h } 
func ( q * Queue ) Dequeue ( ) ( string , error ) { if err != nil { return " " , err } kv , err := claimFirstKey ( q . client , resp . Kvs ) if err != nil { return " " , err } else if kv != nil { return string ( kv . Value ) , nil } else if resp . More { } if err != nil { return " " , err } ok , err := deleteRevKey ( q . client , string ( ev . Kv . Key ) , ev . Kv . ModRevision ) if err != nil { return " " , err } else if ! ok { return q . Dequeue ( ) } return string ( ev . Kv . Value ) , err } 
func GetCipherSuite ( s string ) ( uint16 , bool ) { v , ok := cipherSuites [ s ] return v , ok } 
func ( p * pipeline ) post ( data [ ] byte ) ( err error ) { u := p . picker . pick ( ) req := createPostRequest ( u , RaftPrefix , bytes . NewBuffer ( data ) , " " , p . tr . URLs , p . tr . ID , p . tr . ClusterID ) done := make ( chan struct { } , 1 ) ctx , cancel := context . WithCancel ( context . Background ( ) ) req = req . WithContext ( ctx ) go func ( ) { select { case <- done : case <- p . stopc : waitSchedule ( ) cancel ( ) } } ( ) resp , err := p . tr . pipelineRt . RoundTrip ( req ) done <- struct { } { } if err != nil { p . picker . unreachable ( u ) return err } defer resp . Body . Close ( ) b , err := ioutil . ReadAll ( resp . Body ) if err != nil { p . picker . unreachable ( u ) return err } err = checkPostResponse ( resp , b , req , p . peerID ) if err != nil { p . picker . unreachable ( u ) } return err } return nil } 
func ( * RequestOp ) XXX_OneofFuncs ( ) ( func ( msg proto . Message , b * proto . Buffer ) error , func ( msg proto . Message , tag , wire int , b * proto . Buffer ) ( bool , error ) , func ( msg proto . Message ) ( n int ) , [ ] interface { } ) { return _RequestOp_OneofMarshaler , _RequestOp_OneofUnmarshaler , _RequestOp_OneofSizer , [ ] interface { } { ( * RequestOp_RequestRange ) ( nil ) , ( * RequestOp_RequestPut ) ( nil ) , ( * RequestOp_RequestDeleteRange ) ( nil ) , ( * RequestOp_RequestTxn ) ( nil ) , } } 
func ( * ResponseOp ) XXX_OneofFuncs ( ) ( func ( msg proto . Message , b * proto . Buffer ) error , func ( msg proto . Message , tag , wire int , b * proto . Buffer ) ( bool , error ) , func ( msg proto . Message ) ( n int ) , [ ] interface { } ) { return _ResponseOp_OneofMarshaler , _ResponseOp_OneofUnmarshaler , _ResponseOp_OneofSizer , [ ] interface { } { ( * ResponseOp_ResponseRange ) ( nil ) , ( * ResponseOp_ResponsePut ) ( nil ) , ( * ResponseOp_ResponseDeleteRange ) ( nil ) , ( * ResponseOp_ResponseTxn ) ( nil ) , } } 
func ( * Compare ) XXX_OneofFuncs ( ) ( func ( msg proto . Message , b * proto . Buffer ) error , func ( msg proto . Message , tag , wire int , b * proto . Buffer ) ( bool , error ) , func ( msg proto . Message ) ( n int ) , [ ] interface { } ) { return _Compare_OneofMarshaler , _Compare_OneofUnmarshaler , _Compare_OneofSizer , [ ] interface { } { ( * Compare_Version ) ( nil ) , ( * Compare_CreateRevision ) ( nil ) , ( * Compare_ModRevision ) ( nil ) , ( * Compare_Value ) ( nil ) , ( * Compare_Lease ) ( nil ) , } } 
func ( * WatchRequest ) XXX_OneofFuncs ( ) ( func ( msg proto . Message , b * proto . Buffer ) error , func ( msg proto . Message , tag , wire int , b * proto . Buffer ) ( bool , error ) , func ( msg proto . Message ) ( n int ) , [ ] interface { } ) { return _WatchRequest_OneofMarshaler , _WatchRequest_OneofUnmarshaler , _WatchRequest_OneofSizer , [ ] interface { } { ( * WatchRequest_CreateRequest ) ( nil ) , ( * WatchRequest_CancelRequest ) ( nil ) , ( * WatchRequest_ProgressRequest ) ( nil ) , } } 
func ( r * raft ) send ( m pb . Message ) { m . From = r . id if m . Type == pb . MsgVote || m . Type == pb . MsgVoteResp || m . Type == pb . MsgPreVote || m . Type == pb . MsgPreVoteResp { if m . Term == 0 { } } else { if m . Term != 0 { panic ( fmt . Sprintf ( " " , m . Type , m . Term ) ) } } } r . msgs = append ( r . msgs , m ) } 
func ( r * raft ) maybeSendAppend ( to uint64 , sendIfEmpty bool ) bool { pr := r . getProgress ( to ) if pr . IsPaused ( ) { return false } m := pb . Message { } m . To = to term , errt := r . raftLog . term ( pr . Next - 1 ) ents , erre := r . raftLog . entries ( pr . Next , r . maxMsgSize ) if len ( ents ) == 0 && ! sendIfEmpty { return false } if errt != nil || erre != nil { return false } m . Type = pb . MsgSnap snapshot , err := r . raftLog . snapshot ( ) if err != nil { if err == ErrSnapshotTemporarilyUnavailable { r . logger . Debugf ( " " , r . id , to ) return false } panic ( err ) } if IsEmptySnap ( snapshot ) { panic ( " " ) } m . Snapshot = snapshot sindex , sterm := snapshot . Metadata . Index , snapshot . Metadata . Term r . logger . Debugf ( " " , r . id , r . raftLog . firstIndex ( ) , r . raftLog . committed , sindex , sterm , to , pr ) pr . becomeSnapshot ( sindex ) r . logger . Debugf ( " " , r . id , to , pr ) } else { m . Type = pb . MsgApp m . Index = pr . Next - 1 m . LogTerm = term m . Entries = ents m . Commit = r . raftLog . committed if n := len ( m . Entries ) ; n != 0 { switch pr . State { pr . optimisticUpdate ( last ) pr . ins . add ( last ) case ProgressStateProbe : pr . pause ( ) default : r . logger . Panicf ( " " , r . id , pr . State ) } } } r . send ( m ) return true } 
func ( r * raft ) sendHeartbeat ( to uint64 , ctx [ ] byte ) { m := pb . Message { To : to , Type : pb . MsgHeartbeat , Commit : commit , Context : ctx , } r . send ( m ) } 
func ( r * raft ) bcastAppend ( ) { r . forEachProgress ( func ( id uint64 , _ * Progress ) { if id == r . id { return } r . sendAppend ( id ) } ) } 
func ( r * raft ) bcastHeartbeat ( ) { lastCtx := r . readOnly . lastPendingRequestCtx ( ) if len ( lastCtx ) == 0 { r . bcastHeartbeatWithCtx ( nil ) } else { r . bcastHeartbeatWithCtx ( [ ] byte ( lastCtx ) ) } } 
func ( r * raft ) maybeCommit ( ) bool { } r . matchBuf = r . matchBuf [ : len ( r . prs ) ] idx := 0 for _ , p := range r . prs { r . matchBuf [ idx ] = p . Match idx ++ } sort . Sort ( & r . matchBuf ) mci := r . matchBuf [ len ( r . matchBuf ) - r . quorum ( ) ] return r . raftLog . maybeCommit ( mci , r . Term ) } 
func ( r * raft ) tickElection ( ) { r . electionElapsed ++ if r . promotable ( ) && r . pastElectionTimeout ( ) { r . electionElapsed = 0 r . Step ( pb . Message { From : r . id , Type : pb . MsgHup } ) } } 
func ( r * raft ) tickHeartbeat ( ) { r . heartbeatElapsed ++ r . electionElapsed ++ if r . electionElapsed >= r . electionTimeout { r . electionElapsed = 0 if r . checkQuorum { r . Step ( pb . Message { From : r . id , Type : pb . MsgCheckQuorum } ) } } } if r . state != StateLeader { return } if r . heartbeatElapsed >= r . heartbeatTimeout { r . heartbeatElapsed = 0 r . Step ( pb . Message { From : r . id , Type : pb . MsgBeat } ) } } 
func stepCandidate ( r * raft , m pb . Message ) error { if r . state == StatePreCandidate { myVoteRespType = pb . MsgPreVoteResp } else { myVoteRespType = pb . MsgVoteResp } switch m . Type { case pb . MsgProp : r . logger . Infof ( " " , r . id , r . Term ) return ErrProposalDropped case pb . MsgApp : r . becomeFollower ( m . Term , m . From ) r . handleAppendEntries ( m ) case pb . MsgHeartbeat : r . becomeFollower ( m . Term , m . From ) r . handleHeartbeat ( m ) case pb . MsgSnap : r . becomeFollower ( m . Term , m . From ) r . handleSnapshot ( m ) case myVoteRespType : gr := r . poll ( m . From , m . Type , ! m . Reject ) r . logger . Infof ( " " , r . id , r . quorum ( ) , gr , m . Type , len ( r . votes ) - gr ) switch r . quorum ( ) { case gr : if r . state == StatePreCandidate { r . campaign ( campaignElection ) } else { r . becomeLeader ( ) r . bcastAppend ( ) } case len ( r . votes ) - gr : } case pb . MsgTimeoutNow : r . logger . Debugf ( " " , r . id , r . Term , r . state , m . From ) } return nil } 
func ( r * raft ) restore ( s pb . Snapshot ) bool { if s . Metadata . Index <= r . raftLog . committed { return false } if r . raftLog . matchTerm ( s . Metadata . Index , s . Metadata . Term ) { r . logger . Infof ( " " , r . id , r . raftLog . committed , r . raftLog . lastIndex ( ) , r . raftLog . lastTerm ( ) , s . Metadata . Index , s . Metadata . Term ) r . raftLog . commitTo ( s . Metadata . Index ) return false } return false } } } r . logger . Infof ( " " , r . id , r . raftLog . committed , r . raftLog . lastIndex ( ) , r . raftLog . lastTerm ( ) , s . Metadata . Index , s . Metadata . Term ) r . raftLog . restore ( s ) r . prs = make ( map [ uint64 ] * Progress ) r . learnerPrs = make ( map [ uint64 ] * Progress ) r . restoreNode ( s . Metadata . ConfState . Nodes , false ) r . restoreNode ( s . Metadata . ConfState . Learners , true ) return true } 
func ( r * raft ) promotable ( ) bool { _ , ok := r . prs [ r . id ] return ok } 
func ( r * raft ) checkQuorumActive ( ) bool { var act int r . forEachProgress ( func ( id uint64 , pr * Progress ) { if id == r . id { return } if pr . RecentActive && ! pr . IsLearner { act ++ } pr . RecentActive = false } ) return act >= r . quorum ( ) } 
func ( r * raft ) increaseUncommittedSize ( ents [ ] pb . Entry ) bool { var s uint64 for _ , e := range ents { s += uint64 ( PayloadSize ( e ) ) } if r . uncommittedSize > 0 && r . uncommittedSize + s > r . maxUncommittedSize { } r . uncommittedSize += s return true } 
func ( r * raft ) reduceUncommittedSize ( ents [ ] pb . Entry ) { if r . uncommittedSize == 0 { } var s uint64 for _ , e := range ents { s += uint64 ( PayloadSize ( e ) ) } if s > r . uncommittedSize { } else { r . uncommittedSize -= s } } 
func newPeriodic ( lg * zap . Logger , clock clockwork . Clock , h time . Duration , rg RevGetter , c Compactable ) * Periodic { pc := & Periodic { lg : lg , clock : clock , period : h , rg : rg , c : c , revs : make ( [ ] int64 , 0 ) , } pc . ctx , pc . cancel = context . WithCancel ( context . Background ( ) ) return pc } 
func ( pc * Periodic ) Run ( ) { compactInterval := pc . getCompactInterval ( ) retryInterval := pc . getRetryInterval ( ) retentions := pc . getRetentions ( ) go func ( ) { lastSuccess := pc . clock . Now ( ) baseInterval := pc . period for { pc . revs = append ( pc . revs , pc . rg . Rev ( ) ) if len ( pc . revs ) > retentions { pc . revs = pc . revs [ 1 : ] } select { case <- pc . ctx . Done ( ) : return case <- pc . clock . After ( retryInterval ) : pc . mu . Lock ( ) p := pc . paused pc . mu . Unlock ( ) if p { continue } } if pc . clock . Now ( ) . Sub ( lastSuccess ) < baseInterval { continue } } rev := pc . revs [ 0 ] if pc . lg != nil { pc . lg . Info ( " " , zap . Int64 ( " " , rev ) , zap . Duration ( " " , pc . period ) , ) } else { plog . Noticef ( " " , rev , pc . period ) } _ , err := pc . c . Compact ( pc . ctx , & pb . CompactionRequest { Revision : rev } ) if err == nil || err == mvcc . ErrCompacted { if pc . lg != nil { pc . lg . Info ( " " , zap . Int64 ( " " , rev ) , zap . Duration ( " " , pc . period ) , zap . Duration ( " " , time . Since ( lastSuccess ) ) , ) } else { plog . Noticef ( " " , rev ) } lastSuccess = pc . clock . Now ( ) } else { if pc . lg != nil { pc . lg . Warn ( " " , zap . Int64 ( " " , rev ) , zap . Duration ( " " , pc . period ) , zap . Duration ( " " , retryInterval ) , zap . Error ( err ) , ) } else { plog . Noticef ( " " , rev , err ) plog . Noticef ( " " , retryInterval ) } } } } ( ) } 
func ( pc * Periodic ) getCompactInterval ( ) time . Duration { itv := pc . period if itv > time . Hour { itv = time . Hour } return itv } 
func ( pc * Periodic ) Pause ( ) { pc . mu . Lock ( ) pc . paused = true pc . mu . Unlock ( ) } 
func ( pc * Periodic ) Resume ( ) { pc . mu . Lock ( ) pc . paused = false pc . mu . Unlock ( ) } 
func ( m * Mutex ) Lock ( ctx context . Context ) error { s := m . s client := m . s . Client ( ) m . myKey = fmt . Sprintf ( " " , m . pfx , s . Lease ( ) ) cmp := v3 . Compare ( v3 . CreateRevision ( m . myKey ) , " " , 0 ) resp , err := client . Txn ( ctx ) . If ( cmp ) . Then ( put , getOwner ) . Else ( get , getOwner ) . Commit ( ) if err != nil { return err } m . myRev = resp . Header . Revision if ! resp . Succeeded { m . myRev = resp . Responses [ 0 ] . GetResponseRange ( ) . Kvs [ 0 ] . CreateRevision } if len ( ownerKey ) == 0 || ownerKey [ 0 ] . CreateRevision == m . myRev { m . hdr = resp . Header return nil } } else { m . hdr = hdr } return werr } 
func NewLocker ( s * Session , pfx string ) sync . Locker { return & lockerMutex { NewMutex ( s , pfx ) } } 
func NewFIFOScheduler ( ) Scheduler { f := & fifo { resume : make ( chan struct { } , 1 ) , donec : make ( chan struct { } , 1 ) , } f . finishCond = sync . NewCond ( & f . mu ) f . ctx , f . cancel = context . WithCancel ( context . Background ( ) ) go f . run ( ) return f } 
func ( f * fifo ) Schedule ( j Job ) { f . mu . Lock ( ) defer f . mu . Unlock ( ) if f . cancel == nil { panic ( " " ) } if len ( f . pendings ) == 0 { select { case f . resume <- struct { } { } : default : } } f . pendings = append ( f . pendings , j ) } 
func ( f * fifo ) Stop ( ) { f . mu . Lock ( ) f . cancel ( ) f . cancel = nil f . mu . Unlock ( ) <- f . donec } 
func NewServer ( lg * zap . Logger , network string , address string , ) * Server { return & Server { lg : lg , network : network , address : address , last : rpcpb . Operation_NOT_STARTED , advertiseClientPortToProxy : make ( map [ int ] proxy . Server ) , advertisePeerPortToProxy : make ( map [ int ] proxy . Server ) , } } 
func ( srv * Server ) StartServe ( ) error { var err error srv . ln , err = net . Listen ( srv . network , srv . address ) if err != nil { return err } var opts [ ] grpc . ServerOption opts = append ( opts , grpc . MaxRecvMsgSize ( int ( maxRequestBytes + grpcOverheadBytes ) ) ) opts = append ( opts , grpc . MaxSendMsgSize ( maxSendBytes ) ) opts = append ( opts , grpc . MaxConcurrentStreams ( maxStreams ) ) srv . grpcServer = grpc . NewServer ( opts ... ) rpcpb . RegisterTransportServer ( srv . grpcServer , srv ) srv . lg . Info ( " " , zap . String ( " " , srv . address ) , zap . String ( " " , srv . ln . Addr ( ) . String ( ) ) , ) err = srv . grpcServer . Serve ( srv . ln ) if err != nil && strings . Contains ( err . Error ( ) , " " ) { srv . lg . Info ( " " , zap . String ( " " , srv . address ) , zap . Error ( err ) , ) } else { srv . lg . Warn ( " " , zap . String ( " " , srv . address ) , zap . Error ( err ) , ) } return err } 
func ( srv * Server ) Stop ( ) { srv . lg . Info ( " " , zap . String ( " " , srv . address ) ) srv . grpcServer . Stop ( ) srv . lg . Info ( " " , zap . String ( " " , srv . address ) ) } 
func ( srv * Server ) Transport ( stream rpcpb . Transport_TransportServer ) ( err error ) { errc := make ( chan error ) go func ( ) { for { var req * rpcpb . Request req , err = stream . Recv ( ) if err != nil { errc <- err } if req . Member != nil { srv . Member = req . Member } if req . Tester != nil { srv . Tester = req . Tester } var resp * rpcpb . Response resp , err = srv . handleTesterRequest ( req ) if err != nil { errc <- err } if err = stream . Send ( resp ) ; err != nil { errc <- err } } } ( ) select { case err = <- errc : case <- stream . Context ( ) . Done ( ) : err = stream . Context ( ) . Err ( ) } return err } 
func RegisterInterruptHandler ( h InterruptHandler ) { interruptRegisterMu . Lock ( ) defer interruptRegisterMu . Unlock ( ) interruptHandlers = append ( interruptHandlers , h ) } 
func HandleInterrupts ( lg * zap . Logger ) { notifier := make ( chan os . Signal , 1 ) signal . Notify ( notifier , syscall . SIGINT , syscall . SIGTERM ) go func ( ) { sig := <- notifier interruptRegisterMu . Lock ( ) ihs := make ( [ ] InterruptHandler , len ( interruptHandlers ) ) copy ( ihs , interruptHandlers ) interruptRegisterMu . Unlock ( ) interruptExitMu . Lock ( ) if lg != nil { lg . Info ( " " , zap . String ( " " , sig . String ( ) ) ) } else { plog . Noticef ( " " , sig ) } for _ , h := range ihs { h ( ) } signal . Stop ( notifier ) pid := syscall . Getpid ( ) } setDflSignal ( sig . ( syscall . Signal ) ) syscall . Kill ( pid , sig . ( syscall . Signal ) ) } ( ) } 
func ( op Op ) Txn ( ) ( [ ] Cmp , [ ] Op , [ ] Op ) { return op . cmps , op . thenOps , op . elseOps } 
func OpGet ( key string , opts ... OpOption ) Op { } ret := Op { t : tRange , key : [ ] byte ( key ) } ret . applyOpts ( opts ) return ret } 
func OpDelete ( key string , opts ... OpOption ) Op { } ret := Op { t : tDeleteRange , key : [ ] byte ( key ) } ret . applyOpts ( opts ) switch { case ret . leaseID != 0 : panic ( " " ) case ret . limit != 0 : panic ( " " ) case ret . rev != 0 : panic ( " " ) case ret . sort != nil : panic ( " " ) case ret . serializable : panic ( " " ) case ret . countOnly : panic ( " " ) case ret . minModRev != 0 , ret . maxModRev != 0 : panic ( " " ) case ret . minCreateRev != 0 , ret . maxCreateRev != 0 : panic ( " " ) case ret . filterDelete , ret . filterPut : panic ( " " ) case ret . createdNotify : panic ( " " ) } return ret } 
func OpPut ( key , val string , opts ... OpOption ) Op { ret := Op { t : tPut , key : [ ] byte ( key ) , val : [ ] byte ( val ) } ret . applyOpts ( opts ) switch { case ret . end != nil : panic ( " " ) case ret . limit != 0 : panic ( " " ) case ret . rev != 0 : panic ( " " ) case ret . sort != nil : panic ( " " ) case ret . serializable : panic ( " " ) case ret . countOnly : panic ( " " ) case ret . minModRev != 0 , ret . maxModRev != 0 : panic ( " " ) case ret . minCreateRev != 0 , ret . maxCreateRev != 0 : panic ( " " ) case ret . filterDelete , ret . filterPut : panic ( " " ) case ret . createdNotify : panic ( " " ) } return ret } 
func OpTxn ( cmps [ ] Cmp , thenOps [ ] Op , elseOps [ ] Op ) Op { return Op { t : tTxn , cmps : cmps , thenOps : thenOps , elseOps : elseOps } } 
func WithSort ( target SortTarget , order SortOrder ) OpOption { return func ( op * Op ) { if target == SortByKey && order == SortAscend { } op . sort = & SortOption { target , order } } } 
func WithPrefix ( ) OpOption { return func ( op * Op ) { if len ( op . key ) == 0 { op . key , op . end = [ ] byte { 0 } , [ ] byte { 0 } return } op . end = getPrefix ( op . key ) } } 
func WithRange ( endKey string ) OpOption { return func ( op * Op ) { op . end = [ ] byte ( endKey ) } } 
func WithFromKey ( ) OpOption { return func ( op * Op ) { if len ( op . key ) == 0 { op . key = [ ] byte { 0 } } op . end = [ ] byte ( " \x00 " ) } } 
func withTop ( target SortTarget , order SortOrder ) [ ] OpOption { return [ ] OpOption { WithPrefix ( ) , WithSort ( target , order ) , WithLimit ( 1 ) } } 
func Exist ( dir string ) bool { names , err := fileutil . ReadDir ( dir , fileutil . WithExt ( " " ) ) if err != nil { return false } return len ( names ) != 0 } 
func searchIndex ( lg * zap . Logger , names [ ] string , index uint64 ) ( int , bool ) { for i := len ( names ) - 1 ; i >= 0 ; i -- { name := names [ i ] _ , curIndex , err := parseWALName ( name ) if err != nil { if lg != nil { lg . Panic ( " " , zap . String ( " " , name ) , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } if index >= curIndex { return i , true } } return - 1 , false } 
func isValidSeq ( lg * zap . Logger , names [ ] string ) bool { var lastSeq uint64 for _ , name := range names { curSeq , _ , err := parseWALName ( name ) if err != nil { if lg != nil { lg . Panic ( " " , zap . String ( " " , name ) , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } if lastSeq != 0 && lastSeq != curSeq - 1 { return false } lastSeq = curSeq } return true } 
func NewListener ( addr , scheme string , tlsinfo * TLSInfo ) ( l net . Listener , err error ) { if l , err = newListener ( addr , scheme ) ; err != nil { return nil , err } return wrapTLS ( scheme , tlsinfo , l ) } 
func ( info TLSInfo ) baseConfig ( ) ( * tls . Config , error ) { if info . KeyFile == " " || info . CertFile == " " { return nil , fmt . Errorf ( " " , info . KeyFile , info . CertFile ) } if info . Logger == nil { info . Logger = zap . NewNop ( ) } _ , err := tlsutil . NewCert ( info . CertFile , info . KeyFile , info . parseFunc ) if err != nil { return nil , err } cfg := & tls . Config { MinVersion : tls . VersionTLS12 , ServerName : info . ServerName , } if len ( info . CipherSuites ) > 0 { cfg . CipherSuites = info . CipherSuites } if info . AllowedCN != " " { cfg . VerifyPeerCertificate = func ( rawCerts [ ] [ ] byte , verifiedChains [ ] [ ] * x509 . Certificate ) error { for _ , chains := range verifiedChains { if len ( chains ) != 0 { if info . AllowedCN == chains [ 0 ] . Subject . CommonName { return nil } } } return errors . New ( " " ) } } if os . IsNotExist ( err ) { if info . Logger != nil { info . Logger . Warn ( " " , zap . String ( " " , info . CertFile ) , zap . String ( " " , info . KeyFile ) , zap . Error ( err ) , ) } } else if err != nil { if info . Logger != nil { info . Logger . Warn ( " " , zap . String ( " " , info . CertFile ) , zap . String ( " " , info . KeyFile ) , zap . Error ( err ) , ) } } return cert , err } cfg . GetClientCertificate = func ( unused * tls . CertificateRequestInfo ) ( cert * tls . Certificate , err error ) { cert , err = tlsutil . NewCert ( info . CertFile , info . KeyFile , info . parseFunc ) if os . IsNotExist ( err ) { if info . Logger != nil { info . Logger . Warn ( " " , zap . String ( " " , info . CertFile ) , zap . String ( " " , info . KeyFile ) , zap . Error ( err ) , ) } } else if err != nil { if info . Logger != nil { info . Logger . Warn ( " " , zap . String ( " " , info . CertFile ) , zap . String ( " " , info . KeyFile ) , zap . Error ( err ) , ) } } return cert , err } return cfg , nil } 
func ( info TLSInfo ) cafiles ( ) [ ] string { cs := make ( [ ] string , 0 ) if info . TrustedCAFile != " " { cs = append ( cs , info . TrustedCAFile ) } return cs } 
func ( info TLSInfo ) ServerConfig ( ) ( * tls . Config , error ) { cfg , err := info . baseConfig ( ) if err != nil { return nil , err } cfg . ClientAuth = tls . NoClientCert if info . TrustedCAFile != " " || info . ClientCertAuth { cfg . ClientAuth = tls . RequireAndVerifyClientCert } cs := info . cafiles ( ) if len ( cs ) > 0 { cp , err := tlsutil . NewCertPool ( cs ) if err != nil { return nil , err } cfg . ClientCAs = cp } return cfg , nil } 
func ( info TLSInfo ) ClientConfig ( ) ( * tls . Config , error ) { var cfg * tls . Config var err error if ! info . Empty ( ) { cfg , err = info . baseConfig ( ) if err != nil { return nil , err } } else { cfg = & tls . Config { ServerName : info . ServerName } } cfg . InsecureSkipVerify = info . InsecureSkipVerify cs := info . cafiles ( ) if len ( cs ) > 0 { cfg . RootCAs , err = tlsutil . NewCertPool ( cs ) if err != nil { return nil , err } } if info . selfCert { cfg . InsecureSkipVerify = true } if info . EmptyCN { hasNonEmptyCN := false cn := " " tlsutil . NewCert ( info . CertFile , info . KeyFile , func ( certPEMBlock [ ] byte , keyPEMBlock [ ] byte ) ( tls . Certificate , error ) { var block * pem . Block block , _ = pem . Decode ( certPEMBlock ) cert , err := x509 . ParseCertificate ( block . Bytes ) if err != nil { return tls . Certificate { } , err } if len ( cert . Subject . CommonName ) != 0 { hasNonEmptyCN = true cn = cert . Subject . CommonName } return tls . X509KeyPair ( certPEMBlock , keyPEMBlock ) } ) if hasNonEmptyCN { return nil , fmt . Errorf ( " " , cn ) } } return cfg , nil } 
func IsClosedConnError ( err error ) bool { } 
func NewKeepAliveListener ( l net . Listener , scheme string , tlscfg * tls . Config ) ( net . Listener , error ) { if scheme == " " { if tlscfg == nil { return nil , fmt . Errorf ( " " ) } return newTLSKeepaliveListener ( l , tlscfg ) , nil } return & keepaliveListener { Listener : l , } , nil } 
func ( l * tlsKeepaliveListener ) Accept ( ) ( c net . Conn , err error ) { c , err = l . Listener . Accept ( ) if err != nil { return } kac := c . ( keepAliveConn ) kac . SetKeepAlivePeriod ( 30 * time . Second ) c = tls . Server ( c , l . config ) return c , nil } 
func newTLSKeepaliveListener ( inner net . Listener , config * tls . Config ) net . Listener { l := & tlsKeepaliveListener { } l . Listener = inner l . config = config return l } 
func ( s * EtcdServer ) applyV2Request ( r * RequestV2 ) Response { defer warnOfExpensiveRequest ( s . getLogger ( ) , time . Now ( ) , r , nil , nil ) switch r . Method { case " " : return s . applyV2 . Post ( r ) case " " : return s . applyV2 . Put ( r ) case " " : return s . applyV2 . Delete ( r ) case " " : return s . applyV2 . QGet ( r ) case " " : return s . applyV2 . Sync ( r ) default : } } 
func NewRoleCommand ( ) * cobra . Command { ac := & cobra . Command { Use : " " , Short : " " , } ac . AddCommand ( newRoleAddCommand ( ) ) ac . AddCommand ( newRoleDeleteCommand ( ) ) ac . AddCommand ( newRoleGetCommand ( ) ) ac . AddCommand ( newRoleListCommand ( ) ) ac . AddCommand ( newRoleGrantPermissionCommand ( ) ) ac . AddCommand ( newRoleRevokePermissionCommand ( ) ) return ac } 
func roleAddCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } resp , err := mustClientFromCmd ( cmd ) . Auth . RoleAdd ( context . TODO ( ) , args [ 0 ] ) if err != nil { ExitWithError ( ExitError , err ) } display . RoleAdd ( args [ 0 ] , * resp ) } 
func roleGetCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } name := args [ 0 ] resp , err := mustClientFromCmd ( cmd ) . Auth . RoleGet ( context . TODO ( ) , name ) if err != nil { ExitWithError ( ExitError , err ) } display . RoleGet ( name , * resp ) } 
func roleGrantPermissionCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) < 3 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } perm , err := clientv3 . StrToPermissionType ( args [ 1 ] ) if err != nil { ExitWithError ( ExitBadArgs , err ) } key , rangeEnd := permRange ( args [ 2 : ] ) resp , err := mustClientFromCmd ( cmd ) . Auth . RoleGrantPermission ( context . TODO ( ) , args [ 0 ] , key , rangeEnd , perm ) if err != nil { ExitWithError ( ExitError , err ) } display . RoleGrantPermission ( args [ 0 ] , * resp ) } 
func roleRevokePermissionCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) < 2 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } key , rangeEnd := permRange ( args [ 1 : ] ) resp , err := mustClientFromCmd ( cmd ) . Auth . RoleRevokePermission ( context . TODO ( ) , args [ 0 ] , key , rangeEnd ) if err != nil { ExitWithError ( ExitError , err ) } display . RoleRevokePermission ( args [ 0 ] , args [ 1 ] , rangeEnd , * resp ) } 
func DialJournal ( ) error { conn , err := net . Dial ( " " , " " ) if conn != nil { defer conn . Close ( ) } return err } 
func NewCluster ( t testing . TB , size int ) * cluster { return newCluster ( t , & ClusterConfig { Size : size } ) } 
func NewClusterByConfig ( t testing . TB , cfg * ClusterConfig ) * cluster { return newCluster ( t , cfg ) } 
func ( c * cluster ) HTTPMembers ( ) [ ] client . Member { ms := [ ] client . Member { } for _ , m := range c . Members { pScheme := schemeFromTLSInfo ( m . PeerTLSInfo ) cScheme := schemeFromTLSInfo ( m . ClientTLSInfo ) cm := client . Member { Name : m . Name } for _ , ln := range m . PeerListeners { cm . PeerURLs = append ( cm . PeerURLs , pScheme + " " + ln . Addr ( ) . String ( ) ) } for _ , ln := range m . ClientListeners { cm . ClientURLs = append ( cm . ClientURLs , cScheme + " " + ln . Addr ( ) . String ( ) ) } ms = append ( ms , cm ) } return ms } 
func ( c * cluster ) waitLeader ( t testing . TB , membs [ ] * member ) int { possibleLead := make ( map [ uint64 ] bool ) var lead uint64 for _ , m := range membs { possibleLead [ uint64 ( m . s . ID ( ) ) ] = true } cc := MustNewHTTPClient ( t , getMembersURLs ( membs ) , nil ) kapi := client . NewKeysAPI ( cc ) _ , err := kapi . Get ( ctx , " " , & client . GetOptions { Quorum : true } ) cancel ( ) if err == nil || strings . Contains ( err . Error ( ) , " " ) { break } } for lead == 0 || ! possibleLead [ lead ] { lead = 0 for _ , m := range membs { select { case <- m . s . StopNotify ( ) : continue default : } if lead != 0 && lead != m . s . Lead ( ) { lead = 0 time . Sleep ( 10 * tickDuration ) break } lead = m . s . Lead ( ) } } for i , m := range membs { if uint64 ( m . s . ID ( ) ) == lead { return i } } return - 1 } 
func ( c * cluster ) waitNoLeader ( membs [ ] * member ) { noLeader := false for ! noLeader { noLeader = true for _ , m := range membs { select { case <- m . s . StopNotify ( ) : continue default : } if m . s . Lead ( ) != 0 { noLeader = false time . Sleep ( 10 * tickDuration ) break } } } } 
func isMembersEqual ( membs [ ] client . Member , wmembs [ ] client . Member ) bool { sort . Sort ( SortableMemberSliceByPeerURLs ( membs ) ) sort . Sort ( SortableMemberSliceByPeerURLs ( wmembs ) ) for i := range membs { membs [ i ] . ID = " " } return reflect . DeepEqual ( membs , wmembs ) } 
func mustNewMember ( t testing . TB , mcfg memberConfig ) * member { var err error m := & member { } peerScheme := schemeFromTLSInfo ( mcfg . peerTLS ) clientScheme := schemeFromTLSInfo ( mcfg . clientTLS ) pln := newLocalListener ( t ) m . PeerListeners = [ ] net . Listener { pln } m . PeerURLs , err = types . NewURLs ( [ ] string { peerScheme + " " + pln . Addr ( ) . String ( ) } ) if err != nil { t . Fatal ( err ) } m . PeerTLSInfo = mcfg . peerTLS cln := newLocalListener ( t ) m . ClientListeners = [ ] net . Listener { cln } m . ClientURLs , err = types . NewURLs ( [ ] string { clientScheme + " " + cln . Addr ( ) . String ( ) } ) if err != nil { t . Fatal ( err ) } m . ClientTLSInfo = mcfg . clientTLS m . Name = mcfg . name m . DataDir , err = ioutil . TempDir ( os . TempDir ( ) , " " ) if err != nil { t . Fatal ( err ) } clusterStr := fmt . Sprintf ( " " , mcfg . name , peerScheme , pln . Addr ( ) . String ( ) ) m . InitialPeerURLsMap , err = types . NewURLsMap ( clusterStr ) if err != nil { t . Fatal ( err ) } m . InitialClusterToken = clusterName m . NewCluster = true m . BootstrapTimeout = 10 * time . Millisecond if m . PeerTLSInfo != nil { m . ServerConfig . PeerTLSInfo = * m . PeerTLSInfo } m . ElectionTicks = electionTicks m . InitialElectionTickAdvance = true m . TickMs = uint ( tickDuration / time . Millisecond ) m . QuotaBackendBytes = mcfg . quotaBackendBytes m . MaxTxnOps = mcfg . maxTxnOps if m . MaxTxnOps == 0 { m . MaxTxnOps = embed . DefaultMaxTxnOps } m . MaxRequestBytes = mcfg . maxRequestBytes if m . MaxRequestBytes == 0 { m . MaxRequestBytes = embed . DefaultMaxRequestBytes } m . SnapshotCount = etcdserver . DefaultSnapshotCount if mcfg . snapshotCount != 0 { m . SnapshotCount = mcfg . snapshotCount } m . SnapshotCatchUpEntries = etcdserver . DefaultSnapshotCatchUpEntries if mcfg . snapshotCatchUpEntries != 0 { m . SnapshotCatchUpEntries = mcfg . snapshotCatchUpEntries } if mcfg . authToken != " " { m . AuthToken = mcfg . authToken } m . BcryptCost = uint ( bcrypt . MinCost ) m . grpcServerOpts = [ ] grpc . ServerOption { } if mcfg . grpcKeepAliveMinTime > time . Duration ( 0 ) { m . grpcServerOpts = append ( m . grpcServerOpts , grpc . KeepaliveEnforcementPolicy ( keepalive . EnforcementPolicy { MinTime : mcfg . grpcKeepAliveMinTime , PermitWithoutStream : false , } ) ) } if mcfg . grpcKeepAliveInterval > time . Duration ( 0 ) && mcfg . grpcKeepAliveTimeout > time . Duration ( 0 ) { m . grpcServerOpts = append ( m . grpcServerOpts , grpc . KeepaliveParams ( keepalive . ServerParameters { Time : mcfg . grpcKeepAliveInterval , Timeout : mcfg . grpcKeepAliveTimeout , } ) ) } m . clientMaxCallSendMsgSize = mcfg . clientMaxCallSendMsgSize m . clientMaxCallRecvMsgSize = mcfg . clientMaxCallRecvMsgSize m . useIP = mcfg . useIP m . LeaseCheckpointInterval = mcfg . leaseCheckpointInterval m . InitialCorruptCheck = true lcfg := logutil . DefaultZapLoggerConfig m . LoggerConfig = & lcfg m . LoggerConfig . OutputPaths = [ ] string { " " } m . LoggerConfig . ErrorOutputPaths = [ ] string { " " } if os . Getenv ( " " ) != " " { m . LoggerConfig . OutputPaths = [ ] string { " " } m . LoggerConfig . ErrorOutputPaths = [ ] string { " " } } m . Logger , err = m . LoggerConfig . Build ( ) if err != nil { t . Fatal ( err ) } return m } 
func ( m * member ) listenGRPC ( ) error { if m . useIP { } l , err := transport . NewUnixListener ( m . grpcAddr ) if err != nil { return fmt . Errorf ( " " , m . grpcAddr , err ) } m . grpcBridge , err = newBridge ( m . grpcAddr ) if err != nil { l . Close ( ) return err } m . grpcAddr = schemeFromTLSInfo ( m . ClientTLSInfo ) + " " + m . grpcBridge . inaddr m . grpcListener = l return nil } 
func NewClientV3 ( m * member ) ( * clientv3 . Client , error ) { if m . grpcAddr == " " { return nil , fmt . Errorf ( " " ) } cfg := clientv3 . Config { Endpoints : [ ] string { m . grpcAddr } , DialTimeout : 5 * time . Second , DialOptions : [ ] grpc . DialOption { grpc . WithBlock ( ) } , MaxCallSendMsgSize : m . clientMaxCallSendMsgSize , MaxCallRecvMsgSize : m . clientMaxCallRecvMsgSize , } if m . ClientTLSInfo != nil { tls , err := m . ClientTLSInfo . ClientConfig ( ) if err != nil { return nil , err } cfg . TLS = tls } if m . DialOptions != nil { cfg . DialOptions = append ( cfg . DialOptions , m . DialOptions ... ) } return newClientV3 ( cfg ) } 
func ( m * member ) Clone ( t testing . TB ) * member { mm := & member { } mm . ServerConfig = m . ServerConfig var err error clientURLStrs := m . ClientURLs . StringSlice ( ) mm . ClientURLs , err = types . NewURLs ( clientURLStrs ) if err != nil { } peerURLStrs := m . PeerURLs . StringSlice ( ) mm . PeerURLs , err = types . NewURLs ( peerURLStrs ) if err != nil { } clusterStr := m . InitialPeerURLsMap . String ( ) mm . InitialPeerURLsMap , err = types . NewURLsMap ( clusterStr ) if err != nil { } mm . InitialClusterToken = m . InitialClusterToken mm . ElectionTicks = m . ElectionTicks mm . PeerTLSInfo = m . PeerTLSInfo mm . ClientTLSInfo = m . ClientTLSInfo return mm } 
func ( m * member ) Launch ( ) error { lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , ) var err error if m . s , err = etcdserver . NewServer ( m . ServerConfig ) ; err != nil { return fmt . Errorf ( " " , err ) } m . s . SyncTicker = time . NewTicker ( 500 * time . Millisecond ) m . s . Start ( ) var peerTLScfg * tls . Config if m . PeerTLSInfo != nil && ! m . PeerTLSInfo . Empty ( ) { if peerTLScfg , err = m . PeerTLSInfo . ServerConfig ( ) ; err != nil { return err } } if m . grpcListener != nil { var ( tlscfg * tls . Config ) if m . ClientTLSInfo != nil && ! m . ClientTLSInfo . Empty ( ) { tlscfg , err = m . ClientTLSInfo . ServerConfig ( ) if err != nil { return err } } m . grpcServer = v3rpc . Server ( m . s , tlscfg , m . grpcServerOpts ... ) m . grpcServerPeer = v3rpc . Server ( m . s , peerTLScfg ) m . serverClient = v3client . New ( m . s ) lockpb . RegisterLockServer ( m . grpcServer , v3lock . NewLockServer ( m . serverClient ) ) epb . RegisterElectionServer ( m . grpcServer , v3election . NewElectionServer ( m . serverClient ) ) go m . grpcServer . Serve ( m . grpcListener ) } m . raftHandler = & testutil . PauseableHandler { Next : etcdhttp . NewPeerHandler ( m . Logger , m . s ) } h := ( http . Handler ) ( m . raftHandler ) if m . grpcListener != nil { h = http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { if r . ProtoMajor == 2 && strings . Contains ( r . Header . Get ( " " ) , " " ) { m . grpcServerPeer . ServeHTTP ( w , r ) } else { m . raftHandler . ServeHTTP ( w , r ) } } ) } for _ , ln := range m . PeerListeners { cm := cmux . New ( ln ) if m . grpcServer != nil { grpcl := cm . Match ( cmux . HTTP2 ( ) ) go m . grpcServerPeer . Serve ( grpcl ) } if peerTLScfg != nil { if ll , err = transport . NewTLSListener ( ll , m . PeerTLSInfo ) ; err != nil { return err } } hs := & httptest . Server { Listener : ll , Config : & http . Server { Handler : h , TLSConfig : peerTLScfg , ErrorLog : log . New ( ioutil . Discard , " " , 0 ) , } , TLS : peerTLScfg , } hs . Start ( ) donec := make ( chan struct { } ) go func ( ) { defer close ( donec ) cm . Serve ( ) } ( ) closer := func ( ) { ll . Close ( ) hs . CloseClientConnections ( ) hs . Close ( ) <- donec } m . serverClosers = append ( m . serverClosers , closer ) } for _ , ln := range m . ClientListeners { hs := & httptest . Server { Listener : ln , Config : & http . Server { Handler : v2http . NewClientHandler ( m . Logger , m . s , m . ServerConfig . ReqTimeout ( ) , ) , ErrorLog : log . New ( ioutil . Discard , " " , 0 ) , } , } if m . ClientTLSInfo == nil { hs . Start ( ) } else { info := m . ClientTLSInfo hs . TLS , err = info . ServerConfig ( ) if err != nil { return err } if err != nil { return err } hs . TLS . Certificates = [ ] tls . Certificate { * tlsCert } hs . StartTLS ( ) } closer := func ( ) { ln . Close ( ) hs . CloseClientConnections ( ) hs . Close ( ) } m . serverClosers = append ( m . serverClosers , closer ) } lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , ) return nil } 
func ( m * member ) Close ( ) { if m . grpcBridge != nil { m . grpcBridge . Close ( ) m . grpcBridge = nil } if m . serverClient != nil { m . serverClient . Close ( ) m . serverClient = nil } if m . grpcServer != nil { m . grpcServer . Stop ( ) m . grpcServer . GracefulStop ( ) m . grpcServer = nil m . grpcServerPeer . Stop ( ) m . grpcServerPeer . GracefulStop ( ) m . grpcServerPeer = nil } m . s . HardStop ( ) for _ , f := range m . serverClosers { f ( ) } } 
func ( m * member ) Stop ( t testing . TB ) { lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , ) m . Close ( ) m . serverClosers = nil lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , ) } 
func checkLeaderTransition ( m * member , oldLead uint64 ) uint64 { interval := time . Duration ( m . s . Cfg . TickMs ) * time . Millisecond for m . s . Lead ( ) == 0 || ( m . s . Lead ( ) == oldLead ) { time . Sleep ( interval ) } return m . s . Lead ( ) } 
func ( m * member ) Restart ( t testing . TB ) error { lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , ) newPeerListeners := make ( [ ] net . Listener , 0 ) for _ , ln := range m . PeerListeners { newPeerListeners = append ( newPeerListeners , NewListenerWithAddr ( t , ln . Addr ( ) . String ( ) ) ) } m . PeerListeners = newPeerListeners newClientListeners := make ( [ ] net . Listener , 0 ) for _ , ln := range m . ClientListeners { newClientListeners = append ( newClientListeners , NewListenerWithAddr ( t , ln . Addr ( ) . String ( ) ) ) } m . ClientListeners = newClientListeners if m . grpcListener != nil { if err := m . listenGRPC ( ) ; err != nil { t . Fatal ( err ) } } err := m . Launch ( ) lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , zap . Error ( err ) , ) return err } 
func ( m * member ) Terminate ( t testing . TB ) { lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , ) m . Close ( ) if ! m . keepDataDirTerminate { if err := os . RemoveAll ( m . ServerConfig . DataDir ) ; err != nil { t . Fatal ( err ) } } lg . Info ( " " , zap . String ( " " , m . Name ) , zap . Strings ( " " , m . PeerURLs . StringSlice ( ) ) , zap . Strings ( " " , m . ClientURLs . StringSlice ( ) ) , zap . String ( " " , m . grpcAddr ) , ) } 
func ( m * member ) Metric ( metricName string ) ( string , error ) { cfgtls := transport . TLSInfo { } tr , err := transport . NewTimeoutTransport ( cfgtls , time . Second , time . Second , time . Second ) if err != nil { return " " , err } cli := & http . Client { Transport : tr } resp , err := cli . Get ( m . ClientURLs [ 0 ] . String ( ) + " " ) if err != nil { return " " , err } defer resp . Body . Close ( ) b , rerr := ioutil . ReadAll ( resp . Body ) if rerr != nil { return " " , rerr } lines := strings . Split ( string ( b ) , " \n " ) for _ , l := range lines { if strings . HasPrefix ( l , metricName ) { return strings . Split ( l , " " ) [ 1 ] , nil } } return " " , nil } 
func ( m * member ) InjectPartition ( t testing . TB , others ... * member ) { for _ , other := range others { m . s . CutPeer ( other . s . ID ( ) ) other . s . CutPeer ( m . s . ID ( ) ) } } 
func ( m * member ) RecoverPartition ( t testing . TB , others ... * member ) { for _ , other := range others { m . s . MendPeer ( other . s . ID ( ) ) other . s . MendPeer ( m . s . ID ( ) ) } } 
func NewClusterV3 ( t testing . TB , cfg * ClusterConfig ) * ClusterV3 { cfg . UseGRPC = true if os . Getenv ( " " ) != " " { clientv3 . SetLogger ( grpclog . NewLoggerV2WithVerbosity ( os . Stderr , os . Stderr , os . Stderr , 4 ) ) } clus := & ClusterV3 { cluster : NewClusterByConfig ( t , cfg ) , } clus . Launch ( t ) if ! cfg . SkipCreatingClient { for _ , m := range clus . Members { client , err := NewClientV3 ( m ) if err != nil { t . Fatalf ( " " , err ) } clus . clients = append ( clus . clients , client ) } } return clus } 
func ( opts * jwtOptions ) ParseWithDefaults ( optMap map [ string ] string ) error { if opts . TTL == 0 && optMap [ optTTL ] == " " { opts . TTL = DefaultTTL } return opts . Parse ( optMap ) } 
func ( opts * jwtOptions ) Parse ( optMap map [ string ] string ) error { var err error if ttl := optMap [ optTTL ] ; ttl != " " { opts . TTL , err = time . ParseDuration ( ttl ) if err != nil { return err } } if file := optMap [ optPublicKey ] ; file != " " { opts . PublicKey , err = ioutil . ReadFile ( file ) if err != nil { return err } } if file := optMap [ optPrivateKey ] ; file != " " { opts . PrivateKey , err = ioutil . ReadFile ( file ) if err != nil { return err } } opts . SignMethod = jwt . GetSigningMethod ( method ) if opts . SignMethod == nil { return ErrInvalidAuthMethod } return nil } 
func ( opts * jwtOptions ) Key ( ) ( interface { } , error ) { switch opts . SignMethod . ( type ) { case * jwt . SigningMethodRSA , * jwt . SigningMethodRSAPSS : return opts . rsaKey ( ) case * jwt . SigningMethodECDSA : return opts . ecKey ( ) case * jwt . SigningMethodHMAC : return opts . hmacKey ( ) default : return nil , fmt . Errorf ( " " , opts . SignMethod ) } } 
func ( h * header ) fill ( rh * pb . ResponseHeader ) { if rh == nil { plog . Panic ( " " ) } rh . ClusterId = uint64 ( h . clusterID ) rh . MemberId = uint64 ( h . memberID ) rh . RaftTerm = h . sg . Term ( ) if rh . Revision == 0 { rh . Revision = h . rev ( ) } } 
func ( wb * watchBroadcast ) add ( w * watcher ) bool { wb . mu . Lock ( ) defer wb . mu . Unlock ( ) if wb . nextrev > w . nextrev || ( wb . nextrev == 0 && w . nextrev != 0 ) { } if wb . responses == 0 { return true } if ! ok { return false } wb . receivers [ w ] = struct { } { } watchersCoalescing . Inc ( ) return true } 
func ( ws * watchStream ) Watch ( id WatchID , key , end [ ] byte , startRev int64 , fcs ... FilterFunc ) ( WatchID , error ) { } ws . mu . Lock ( ) defer ws . mu . Unlock ( ) if ws . closed { return - 1 , ErrEmptyWatcherRange } if id == AutoWatchID { for ws . watchers [ ws . nextID ] != nil { ws . nextID ++ } id = ws . nextID ws . nextID ++ } else if _ , ok := ws . watchers [ id ] ; ok { return - 1 , ErrWatcherDuplicateID } w , c := ws . watchable . watch ( key , end , startRev , id , ws . ch , fcs ... ) ws . cancels [ id ] = c ws . watchers [ id ] = w return id , nil } 
func newFileEncoder ( f * os . File , prevCrc uint32 ) ( * encoder , error ) { offset , err := f . Seek ( 0 , io . SeekCurrent ) if err != nil { return nil , err } return newEncoder ( f , prevCrc , int ( offset ) ) , nil } 
func purgeFile ( lg * zap . Logger , dirname string , suffix string , max uint , interval time . Duration , stop <- chan struct { } , purgec chan <- string ) <- chan error { errC := make ( chan error , 1 ) go func ( ) { for { fnames , err := ReadDir ( dirname ) if err != nil { errC <- err return } newfnames := make ( [ ] string , 0 ) for _ , fname := range fnames { if strings . HasSuffix ( fname , suffix ) { newfnames = append ( newfnames , fname ) } } sort . Strings ( newfnames ) fnames = newfnames for len ( newfnames ) > int ( max ) { f := filepath . Join ( dirname , newfnames [ 0 ] ) l , err := TryLockFile ( f , os . O_WRONLY , PrivateFileMode ) if err != nil { break } if err = os . Remove ( f ) ; err != nil { errC <- err return } if err = l . Close ( ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , l . Name ( ) ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , l . Name ( ) , err ) } errC <- err return } if lg != nil { lg . Info ( " " , zap . String ( " " , f ) ) } else { plog . Infof ( " " , f ) } newfnames = newfnames [ 1 : ] } if purgec != nil { for i := 0 ; i < len ( fnames ) - len ( newfnames ) ; i ++ { purgec <- fnames [ i ] } } select { case <- time . After ( interval ) : case <- stop : return } } } ( ) return errC } 
func ( ss * StringsValue ) Set ( s string ) error { * ss = strings . Split ( s , " " ) return nil } 
func NewStringsValue ( s string ) ( ss * StringsValue ) { if s == " " { return & StringsValue { } } ss = new ( StringsValue ) if err := ss . Set ( s ) ; err != nil { plog . Panicf ( " " , err ) } return ss } 
func StringsFromFlag ( fs * flag . FlagSet , flagName string ) [ ] string { return [ ] string ( * fs . Lookup ( flagName ) . Value . ( * StringsValue ) ) } 
func Cluster ( v string ) string { vs := strings . Split ( v , " " ) if len ( vs ) <= 2 { return v } return fmt . Sprintf ( " " , vs [ 0 ] , vs [ 1 ] ) } 
func NewPageWriter ( w io . Writer , pageBytes , pageOffset int ) * PageWriter { return & PageWriter { w : w , pageOffset : pageOffset , pageBytes : pageBytes , buf : make ( [ ] byte , defaultBufferBytes + pageBytes ) , bufWatermarkBytes : defaultBufferBytes , } } 
func newWatchHub ( capacity int ) * watcherHub { return & watcherHub { watchers : make ( map [ string ] * list . List ) , EventHistory : newEventHistory ( capacity ) , } } 
func ( wh * watcherHub ) watch ( key string , recursive , stream bool , index , storeIndex uint64 ) ( Watcher , * v2error . Error ) { reportWatchRequest ( ) event , err := wh . EventHistory . scan ( key , recursive , index ) if err != nil { err . Index = storeIndex return nil , err } w := & watcher { eventChan : make ( chan * Event , 100 ) , wh . mutex . Lock ( ) defer wh . mutex . Unlock ( ) ne . EtcdIndex = storeIndex w . eventChan <- ne return w , nil } l , ok := wh . watchers [ key ] var elem * list . Element if ok { } else { elem = l . PushBack ( w ) wh . watchers [ key ] = l } w . remove = func ( ) { if w . removed { } w . removed = true l . Remove ( elem ) atomic . AddInt64 ( & wh . count , - 1 ) reportWatcherRemoved ( ) if l . Len ( ) == 0 { delete ( wh . watchers , key ) } } atomic . AddInt64 ( & wh . count , 1 ) reportWatcherAdded ( ) return w , nil } 
func ( wh * watcherHub ) notify ( e * Event ) { e = wh . EventHistory . addEvent ( e ) segments := strings . Split ( e . Node . Key , " " ) currPath := " " } } 
func ( wh * watcherHub ) clone ( ) * watcherHub { clonedHistory := wh . EventHistory . clone ( ) return & watcherHub { EventHistory : clonedHistory , } } 
func isHidden ( watchPath , keyPath string ) bool { } return strings . Contains ( afterPath , " " ) } 
func NewTimeoutListener ( addr string , scheme string , tlsinfo * TLSInfo , rdtimeoutd , wtimeoutd time . Duration ) ( net . Listener , error ) { ln , err := newListener ( addr , scheme ) if err != nil { return nil , err } ln = & rwTimeoutListener { Listener : ln , rdtimeoutd : rdtimeoutd , wtimeoutd : wtimeoutd , } if ln , err = wrapTLS ( scheme , tlsinfo , ln ) ; err != nil { return nil , err } return ln , nil } 
func ( srv * Server ) createEtcdLogFile ( ) error { var err error srv . etcdLogFile , err = os . Create ( srv . Member . Etcd . LogOutputs [ 0 ] ) if err != nil { return err } srv . lg . Info ( " " , zap . String ( " " , srv . Member . Etcd . LogOutputs [ 0 ] ) ) return nil } 
func ( srv * Server ) runEtcd ( ) error { errc := make ( chan error ) go func ( ) { time . Sleep ( 5 * time . Second ) } ( ) if srv . etcdCmd != nil { srv . lg . Info ( " " , zap . String ( " " , srv . etcdCmd . Path ) , ) err := srv . etcdCmd . Start ( ) perr := <- errc srv . lg . Info ( " " , zap . String ( " " , srv . etcdCmd . Path ) , zap . Errors ( " " , [ ] error { err , perr } ) , ) if err != nil { return err } return perr } select { case <- srv . etcdServer . Server . ReadyNotify ( ) : srv . lg . Info ( " " ) case <- time . After ( time . Minute ) : srv . etcdServer . Close ( ) return fmt . Errorf ( " " , <- srv . etcdServer . Err ( ) ) } return <- errc } 
func ( srv * Server ) stopEtcd ( sig os . Signal ) error { srv . stopProxy ( ) if srv . etcdCmd != nil { srv . lg . Info ( " " , zap . String ( " " , srv . etcdCmd . Path ) , zap . String ( " " , sig . String ( ) ) , ) err := srv . etcdCmd . Process . Signal ( sig ) if err != nil { return err } errc := make ( chan error ) go func ( ) { _ , ew := srv . etcdCmd . Process . Wait ( ) errc <- ew close ( errc ) } ( ) select { case <- time . After ( 5 * time . Second ) : srv . etcdCmd . Process . Kill ( ) case e := <- errc : return e } err = <- errc srv . lg . Info ( " " , zap . String ( " " , srv . etcdCmd . Path ) , zap . String ( " " , sig . String ( ) ) , zap . Error ( err ) , ) return err } srv . lg . Info ( " " ) srv . etcdServer . Server . HardStop ( ) srv . etcdServer . Close ( ) srv . lg . Info ( " " ) return nil } 
func ( srv * Server ) saveTLSAssets ( ) error { if srv . Member . PeerCertPath != " " { if srv . Member . PeerCertData == " " { return fmt . Errorf ( " " , srv . Member . PeerCertPath ) } if err := ioutil . WriteFile ( srv . Member . PeerCertPath , [ ] byte ( srv . Member . PeerCertData ) , 0644 ) ; err != nil { return err } } if srv . Member . PeerKeyPath != " " { if srv . Member . PeerKeyData == " " { return fmt . Errorf ( " " , srv . Member . PeerKeyPath ) } if err := ioutil . WriteFile ( srv . Member . PeerKeyPath , [ ] byte ( srv . Member . PeerKeyData ) , 0644 ) ; err != nil { return err } } if srv . Member . PeerTrustedCAPath != " " { if srv . Member . PeerTrustedCAData == " " { return fmt . Errorf ( " " , srv . Member . PeerTrustedCAPath ) } if err := ioutil . WriteFile ( srv . Member . PeerTrustedCAPath , [ ] byte ( srv . Member . PeerTrustedCAData ) , 0644 ) ; err != nil { return err } } if srv . Member . PeerCertPath != " " && srv . Member . PeerKeyPath != " " && srv . Member . PeerTrustedCAPath != " " { srv . lg . Info ( " " , zap . String ( " " , srv . Member . PeerCertPath ) , zap . String ( " " , srv . Member . PeerKeyPath ) , zap . String ( " " , srv . Member . PeerTrustedCAPath ) , ) } if srv . Member . ClientCertPath != " " { if srv . Member . ClientCertData == " " { return fmt . Errorf ( " " , srv . Member . ClientCertPath ) } if err := ioutil . WriteFile ( srv . Member . ClientCertPath , [ ] byte ( srv . Member . ClientCertData ) , 0644 ) ; err != nil { return err } } if srv . Member . ClientKeyPath != " " { if srv . Member . ClientKeyData == " " { return fmt . Errorf ( " " , srv . Member . ClientKeyPath ) } if err := ioutil . WriteFile ( srv . Member . ClientKeyPath , [ ] byte ( srv . Member . ClientKeyData ) , 0644 ) ; err != nil { return err } } if srv . Member . ClientTrustedCAPath != " " { if srv . Member . ClientTrustedCAData == " " { return fmt . Errorf ( " " , srv . Member . ClientTrustedCAPath ) } if err := ioutil . WriteFile ( srv . Member . ClientTrustedCAPath , [ ] byte ( srv . Member . ClientTrustedCAData ) , 0644 ) ; err != nil { return err } } if srv . Member . ClientCertPath != " " && srv . Member . ClientKeyPath != " " && srv . Member . ClientTrustedCAPath != " " { srv . lg . Info ( " " , zap . String ( " " , srv . Member . ClientCertPath ) , zap . String ( " " , srv . Member . ClientKeyPath ) , zap . String ( " " , srv . Member . ClientTrustedCAPath ) , ) } return nil } 
func ( srv * Server ) handle_SIGQUIT_ETCD_AND_REMOVE_DATA_AND_STOP_AGENT ( ) ( * rpcpb . Response , error ) { err := srv . stopEtcd ( syscall . SIGQUIT ) if err != nil { return nil , err } if srv . etcdServer != nil { srv . etcdServer . GetLogger ( ) . Sync ( ) } else { srv . etcdLogFile . Sync ( ) srv . etcdLogFile . Close ( ) } err = os . RemoveAll ( srv . Member . BaseDir ) if err != nil { return nil , err } srv . lg . Info ( " " , zap . String ( " " , srv . Member . BaseDir ) ) return & rpcpb . Response { Success : true , Status : " " , } , nil } 
func LimitListener ( l net . Listener , n int ) net . Listener { return & limitListener { l , make ( chan struct { } , n ) } } 
func allowMethod ( w http . ResponseWriter , m string , ms ... string ) bool { for _ , meth := range ms { if m == meth { return true } } w . Header ( ) . Set ( " " , strings . Join ( ms , " " ) ) http . Error ( w , " " , http . StatusMethodNotAllowed ) return false } 
func NewWatchServer ( s * etcdserver . EtcdServer ) pb . WatchServer { return & watchServer { lg : s . Cfg . Logger , clusterID : int64 ( s . Cluster ( ) . ID ( ) ) , memberID : int64 ( s . ID ( ) ) , maxRequestBytes : int ( s . Cfg . MaxRequestBytes + grpcOverheadBytes ) , sg : s , watchable : s . Watchable ( ) , ag : s , } } 
func GetProgressReportInterval ( ) time . Duration { progressReportIntervalMu . RLock ( ) interval := progressReportInterval progressReportIntervalMu . RUnlock ( ) return interval + jitter } 
func SetProgressReportInterval ( newTimeout time . Duration ) { progressReportIntervalMu . Lock ( ) progressReportInterval = newTimeout progressReportIntervalMu . Unlock ( ) } 
func FiltersFromRequest ( creq * pb . WatchCreateRequest ) [ ] mvcc . FilterFunc { filters := make ( [ ] mvcc . FilterFunc , 0 , len ( creq . Filters ) ) for _ , ft := range creq . Filters { switch ft { case pb . WatchCreateRequest_NOPUT : filters = append ( filters , filterNoPut ) case pb . WatchCreateRequest_NODELETE : filters = append ( filters , filterNoDelete ) default : } } return filters } 
func newPipelineHandler ( t * Transport , r Raft , cid types . ID ) http . Handler { return & pipelineHandler { lg : t . Logger , localID : t . ID , tr : t , r : r , cid : cid , } } 
func ( h * snapshotHandler ) ServeHTTP ( w http . ResponseWriter , r * http . Request ) { start := time . Now ( ) if r . Method != " " { w . Header ( ) . Set ( " " , " " ) http . Error ( w , " " , http . StatusMethodNotAllowed ) snapshotReceiveFailures . WithLabelValues ( unknownSnapshotSender ) . Inc ( ) return } w . Header ( ) . Set ( " " , h . cid . String ( ) ) if err := checkClusterCompatibilityFromHeader ( h . lg , h . localID , r . Header , h . cid ) ; err != nil { http . Error ( w , err . Error ( ) , http . StatusPreconditionFailed ) snapshotReceiveFailures . WithLabelValues ( unknownSnapshotSender ) . Inc ( ) return } addRemoteFromRequest ( h . tr , r ) dec := & messageDecoder { r : r . Body } from := types . ID ( m . From ) . String ( ) if err != nil { msg := fmt . Sprintf ( " " , err ) if h . lg != nil { h . lg . Warn ( " " , zap . String ( " " , h . localID . String ( ) ) , zap . String ( " " , from ) , zap . Error ( err ) , ) } else { plog . Error ( msg ) } http . Error ( w , msg , http . StatusBadRequest ) recvFailures . WithLabelValues ( r . RemoteAddr ) . Inc ( ) snapshotReceiveFailures . WithLabelValues ( from ) . Inc ( ) return } msgSize := m . Size ( ) receivedBytes . WithLabelValues ( from ) . Add ( float64 ( msgSize ) ) if m . Type != raftpb . MsgSnap { if h . lg != nil { h . lg . Warn ( " " , zap . String ( " " , h . localID . String ( ) ) , zap . String ( " " , from ) , zap . String ( " " , m . Type . String ( ) ) , ) } else { plog . Errorf ( " " , m . Type ) } http . Error ( w , " " , http . StatusBadRequest ) snapshotReceiveFailures . WithLabelValues ( from ) . Inc ( ) return } if h . lg != nil { h . lg . Info ( " " , zap . String ( " " , h . localID . String ( ) ) , zap . String ( " " , from ) , zap . Uint64 ( " " , m . Snapshot . Metadata . Index ) , zap . Int ( " " , msgSize ) , zap . String ( " " , humanize . Bytes ( uint64 ( msgSize ) ) ) , ) } else { plog . Infof ( " " , m . Snapshot . Metadata . Index , types . ID ( m . From ) ) } if err != nil { msg := fmt . Sprintf ( " " , err ) if h . lg != nil { h . lg . Warn ( " " , zap . String ( " " , h . localID . String ( ) ) , zap . String ( " " , from ) , zap . Uint64 ( " " , m . Snapshot . Metadata . Index ) , zap . Error ( err ) , ) } else { plog . Error ( msg ) } http . Error ( w , msg , http . StatusInternalServerError ) snapshotReceiveFailures . WithLabelValues ( from ) . Inc ( ) return } receivedBytes . WithLabelValues ( from ) . Add ( float64 ( n ) ) if h . lg != nil { h . lg . Info ( " " , zap . String ( " " , h . localID . String ( ) ) , zap . String ( " " , from ) , zap . Uint64 ( " " , m . Snapshot . Metadata . Index ) , zap . Int64 ( " " , n ) , zap . String ( " " , humanize . Bytes ( uint64 ( n ) ) ) , ) } else { plog . Infof ( " " , m . Snapshot . Metadata . Index , types . ID ( m . From ) ) } if err := h . r . Process ( context . TODO ( ) , m ) ; err != nil { switch v := err . ( type ) { default : msg := fmt . Sprintf ( " " , err ) if h . lg != nil { h . lg . Warn ( " " , zap . String ( " " , h . localID . String ( ) ) , zap . String ( " " , from ) , zap . Error ( err ) , ) } else { plog . Error ( msg ) } http . Error ( w , msg , http . StatusInternalServerError ) snapshotReceiveFailures . WithLabelValues ( from ) . Inc ( ) } return } snapshotReceive . WithLabelValues ( from ) . Inc ( ) snapshotReceiveSeconds . WithLabelValues ( from ) . Observe ( time . Since ( start ) . Seconds ( ) ) } 
func checkClusterCompatibilityFromHeader ( lg * zap . Logger , localID types . ID , header http . Header , cid types . ID ) error { remoteName := header . Get ( " " ) remoteServer := serverVersion ( header ) remoteVs := " " if remoteServer != nil { remoteVs = remoteServer . String ( ) } remoteMinClusterVer := minClusterVersion ( header ) remoteMinClusterVs := " " if remoteMinClusterVer != nil { remoteMinClusterVs = remoteMinClusterVer . String ( ) } localServer , localMinCluster , err := checkVersionCompatibility ( remoteName , remoteServer , remoteMinClusterVer ) localVs := " " if localServer != nil { localVs = localServer . String ( ) } localMinClusterVs := " " if localMinCluster != nil { localMinClusterVs = localMinCluster . String ( ) } if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , localID . String ( ) ) , zap . String ( " " , cid . String ( ) ) , zap . String ( " " , localVs ) , zap . String ( " " , localMinClusterVs ) , zap . String ( " " , remoteName ) , zap . String ( " " , remoteVs ) , zap . String ( " " , remoteMinClusterVs ) , zap . Error ( err ) , ) } else { plog . Errorf ( " " , err ) } return errIncompatibleVersion } if gcid := header . Get ( " " ) ; gcid != cid . String ( ) { if lg != nil { lg . Warn ( " " , zap . String ( " " , localID . String ( ) ) , zap . String ( " " , cid . String ( ) ) , zap . String ( " " , localVs ) , zap . String ( " " , localMinClusterVs ) , zap . String ( " " , remoteName ) , zap . String ( " " , remoteVs ) , zap . String ( " " , remoteMinClusterVs ) , zap . String ( " " , gcid ) , ) } else { plog . Errorf ( " " , gcid , cid ) } return errClusterIDMismatch } return nil } 
func KeyExists ( key string ) clientv3 . Cmp { return clientv3 . Compare ( clientv3 . Version ( key ) , " " , 0 ) } 
func KeyMissing ( key string ) clientv3 . Cmp { return clientv3 . Compare ( clientv3 . Version ( key ) , " " , 0 ) } 
func ValidateSecureEndpoints ( tlsInfo TLSInfo , eps [ ] string ) ( [ ] string , error ) { t , err := NewTransport ( tlsInfo , 5 * time . Second ) if err != nil { return nil , err } var errs [ ] string var endpoints [ ] string for _ , ep := range eps { if ! strings . HasPrefix ( ep , " " ) { errs = append ( errs , fmt . Sprintf ( " " , ep ) ) continue } conn , cerr := t . Dial ( " " , ep [ len ( " " ) : ] ) if cerr != nil { errs = append ( errs , fmt . Sprintf ( " " , ep , cerr ) ) continue } conn . Close ( ) endpoints = append ( endpoints , ep ) } if len ( errs ) != 0 { err = fmt . Errorf ( " " , strings . Join ( errs , " " ) ) } return endpoints , err } 
func putNewKV ( kv v3 . KV , key , val string , leaseID v3 . LeaseID ) ( int64 , error ) { cmp := v3 . Compare ( v3 . Version ( key ) , " " , 0 ) req := v3 . OpPut ( key , val , v3 . WithLease ( leaseID ) ) txnresp , err := kv . Txn ( context . TODO ( ) ) . If ( cmp ) . Then ( req ) . Commit ( ) if err != nil { return 0 , err } if ! txnresp . Succeeded { return 0 , ErrKeyExists } return txnresp . Header . Revision , nil } 
func newSequentialKV ( kv v3 . KV , prefix , val string ) ( * RemoteKV , error ) { resp , err := kv . Get ( context . TODO ( ) , prefix , v3 . WithLastKey ( ) ... ) if err != nil { return nil , err } if len ( resp . Kvs ) != 0 { fields := strings . Split ( string ( resp . Kvs [ 0 ] . Key ) , " " ) _ , serr := fmt . Sscanf ( fields [ len ( fields ) - 1 ] , " " , & newSeqNum ) if serr != nil { return nil , serr } newSeqNum ++ } newKey := fmt . Sprintf ( " " , prefix , newSeqNum ) reqPrefix := v3 . OpPut ( baseKey , " " ) reqnewKey := v3 . OpPut ( newKey , val ) txn := kv . Txn ( context . TODO ( ) ) txnresp , err := txn . If ( cmp ) . Then ( reqPrefix , reqnewKey ) . Commit ( ) if err != nil { return nil , err } if ! txnresp . Succeeded { return newSequentialKV ( kv , prefix , val ) } return & RemoteKV { kv , newKey , txnresp . Header . Revision , val } , nil } 
func newEphemeralKV ( s * concurrency . Session , key , val string ) ( * EphemeralKV , error ) { k , err := newKV ( s . Client ( ) , key , val , s . Lease ( ) ) if err != nil { return nil , err } return & EphemeralKV { * k } , nil } 
func newUniqueEphemeralKey ( s * concurrency . Session , prefix string ) ( * EphemeralKV , error ) { return newUniqueEphemeralKV ( s , prefix , " " ) } 
func newUniqueEphemeralKV ( s * concurrency . Session , prefix , val string ) ( ek * EphemeralKV , err error ) { for { newKey := fmt . Sprintf ( " " , prefix , time . Now ( ) . UnixNano ( ) ) ek , err = newEphemeralKV ( s , newKey , val ) if err == nil || err != ErrKeyExists { break } } return ek , err } 
func NewUpdateDirCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Flags : [ ] cli . Flag { cli . IntFlag { Name : " " , Value : 0 , Usage : " " } , } , Action : func ( c * cli . Context ) error { updatedirCommandFunc ( c , mustNewKeyAPI ( c ) ) return nil } , } } 
func updatedirCommandFunc ( c * cli . Context , ki client . KeysAPI ) { if len ( c . Args ( ) ) == 0 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } key := c . Args ( ) [ 0 ] ttl := c . Int ( " " ) ctx , cancel := contextWithTotalTimeout ( c ) resp , err := ki . Set ( ctx , key , " " , & client . SetOptions { TTL : time . Duration ( ttl ) * time . Second , Dir : true , PrevExist : client . PrevExist } ) cancel ( ) if err != nil { handleError ( c , ExitServerError , err ) } if c . GlobalString ( " " ) != " " { printResponseKey ( resp , c . GlobalString ( " " ) ) } } 
func handleBackup ( c * cli . Context ) error { var srcWAL string var destWAL string withV3 := c . Bool ( " " ) srcSnap := filepath . Join ( c . String ( " " ) , " " , " " ) destSnap := filepath . Join ( c . String ( " " ) , " " , " " ) if c . String ( " " ) != " " { srcWAL = c . String ( " " ) } else { srcWAL = filepath . Join ( c . String ( " " ) , " " , " " ) } if c . String ( " " ) != " " { destWAL = c . String ( " " ) } else { destWAL = filepath . Join ( c . String ( " " ) , " " , " " ) } if err := fileutil . CreateDirAll ( destSnap ) ; err != nil { log . Fatalf ( " " , destSnap , err ) } walsnap := saveSnap ( destSnap , srcSnap ) metadata , state , ents := loadWAL ( srcWAL , walsnap , withV3 ) saveDB ( filepath . Join ( destSnap , " " ) , filepath . Join ( srcSnap , " " ) , state . Commit , withV3 ) idgen := idutil . NewGenerator ( 0 , time . Now ( ) ) metadata . NodeID = idgen . Next ( ) metadata . ClusterID = idgen . Next ( ) neww , err := wal . Create ( zap . NewExample ( ) , destWAL , pbutil . MustMarshal ( & metadata ) ) if err != nil { log . Fatal ( err ) } defer neww . Close ( ) if err := neww . Save ( state , ents ) ; err != nil { log . Fatal ( err ) } if err := neww . SaveSnapshot ( walsnap ) ; err != nil { log . Fatal ( err ) } return nil } 
func saveDB ( destDB , srcDB string , idx uint64 , v3 bool ) { ch := make ( chan * bolt . DB , 1 ) go func ( ) { db , err := bolt . Open ( srcDB , 0444 , & bolt . Options { ReadOnly : true } ) if err != nil { log . Fatal ( err ) } ch <- db } ( ) select { case src = <- ch : case <- time . After ( time . Second ) : log . Println ( " " , srcDB ) src = <- ch } defer src . Close ( ) tx , err := src . Begin ( false ) if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if _ , err := tx . WriteTo ( dest ) ; err != nil { log . Fatal ( err ) } dest . Close ( ) if err := tx . Rollback ( ) ; err != nil { log . Fatal ( err ) } } db , err := bolt . Open ( destDB , 0644 , & bolt . Options { } ) if err != nil { log . Fatal ( err ) } tx , err := db . Begin ( true ) if err != nil { log . Fatal ( err ) } } binary . BigEndian . PutUint64 ( idxBytes , idx ) b , err := tx . CreateBucketIfNotExists ( [ ] byte ( " " ) ) if err != nil { log . Fatal ( err ) } b . Put ( [ ] byte ( " " ) , idxBytes ) } if err := tx . Commit ( ) ; err != nil { log . Fatal ( err ) } if err := db . Close ( ) ; err != nil { log . Fatal ( err ) } } 
func NewWatchCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : runWatcherFunc , } cmd . Flags ( ) . DurationVar ( & runningTime , " " , 60 , " " ) cmd . Flags ( ) . StringVar ( & watchPrefix , " " , " " , " " ) cmd . Flags ( ) . IntVar ( & noOfPrefixes , " " , 10 , " " ) cmd . Flags ( ) . IntVar ( & watchPerPrefix , " " , 10 , " " ) cmd . Flags ( ) . IntVar ( & totalKeys , " " , 1000 , " " ) return cmd } 
func NewV3 ( lg * zap . Logger ) Manager { if lg == nil { lg = zap . NewExample ( ) } return & v3Manager { lg : lg } } 
func ( s * v3Manager ) Save ( ctx context . Context , cfg clientv3 . Config , dbPath string ) error { if len ( cfg . Endpoints ) != 1 { return fmt . Errorf ( " " , cfg . Endpoints ) } cli , err := clientv3 . New ( cfg ) if err != nil { return err } defer cli . Close ( ) partpath := dbPath + " " defer os . RemoveAll ( partpath ) var f * os . File f , err = os . OpenFile ( partpath , os . O_WRONLY | os . O_CREATE | os . O_TRUNC , fileutil . PrivateFileMode ) if err != nil { return fmt . Errorf ( " " , partpath , err ) } s . lg . Info ( " " , zap . String ( " " , partpath ) , ) now := time . Now ( ) var rd io . ReadCloser rd , err = cli . Snapshot ( ctx ) if err != nil { return err } s . lg . Info ( " " , zap . String ( " " , cfg . Endpoints [ 0 ] ) , ) if _ , err = io . Copy ( f , rd ) ; err != nil { return err } if err = fileutil . Fsync ( f ) ; err != nil { return err } if err = f . Close ( ) ; err != nil { return err } s . lg . Info ( " " , zap . String ( " " , cfg . Endpoints [ 0 ] ) , zap . Duration ( " " , time . Since ( now ) ) , ) if err = os . Rename ( partpath , dbPath ) ; err != nil { return fmt . Errorf ( " " , partpath , dbPath , err ) } s . lg . Info ( " " , zap . String ( " " , dbPath ) ) return nil } 
func ( s * v3Manager ) Status ( dbPath string ) ( ds Status , err error ) { if _ , err = os . Stat ( dbPath ) ; err != nil { return ds , err } db , err := bolt . Open ( dbPath , 0400 , & bolt . Options { ReadOnly : true } ) if err != nil { return ds , err } defer db . Close ( ) h := crc32 . New ( crc32 . MakeTable ( crc32 . Castagnoli ) ) if err = db . View ( func ( tx * bolt . Tx ) error { for dbErr := range tx . Check ( ) { dbErrStrings = append ( dbErrStrings , dbErr . Error ( ) ) } if len ( dbErrStrings ) > 0 { return fmt . Errorf ( " \n " + strings . Join ( dbErrStrings , " \n " ) , len ( dbErrStrings ) ) } ds . TotalSize = tx . Size ( ) c := tx . Cursor ( ) for next , _ := c . First ( ) ; next != nil ; next , _ = c . Next ( ) { b := tx . Bucket ( next ) if b == nil { return fmt . Errorf ( " " , string ( next ) ) } h . Write ( next ) iskeyb := ( string ( next ) == " " ) b . ForEach ( func ( k , v [ ] byte ) error { h . Write ( k ) h . Write ( v ) if iskeyb { rev := bytesToRev ( k ) ds . Revision = rev . main } ds . TotalKey ++ return nil } ) } return nil } ) ; err != nil { return ds , err } ds . Hash = h . Sum32 ( ) return ds , nil } 
func ( s * v3Manager ) Restore ( cfg RestoreConfig ) error { pURLs , err := types . NewURLs ( cfg . PeerURLs ) if err != nil { return err } var ics types . URLsMap ics , err = types . NewURLsMap ( cfg . InitialCluster ) if err != nil { return err } srv := etcdserver . ServerConfig { Logger : s . lg , Name : cfg . Name , PeerURLs : pURLs , InitialPeerURLsMap : ics , InitialClusterToken : cfg . InitialClusterToken , } if err = srv . VerifyBootstrap ( ) ; err != nil { return err } s . cl , err = membership . NewClusterFromURLsMap ( s . lg , cfg . InitialClusterToken , ics ) if err != nil { return err } dataDir := cfg . OutputDataDir if dataDir == " " { dataDir = cfg . Name + " " } if fileutil . Exist ( dataDir ) { return fmt . Errorf ( " " , dataDir ) } walDir := cfg . OutputWALDir if walDir == " " { walDir = filepath . Join ( dataDir , " " , " " ) } else if fileutil . Exist ( walDir ) { return fmt . Errorf ( " " , walDir ) } s . name = cfg . Name s . dbPath = cfg . SnapshotPath s . walDir = walDir s . snapDir = filepath . Join ( dataDir , " " , " " ) s . skipHashCheck = cfg . SkipHashCheck s . lg . Info ( " " , zap . String ( " " , s . dbPath ) , zap . String ( " " , s . walDir ) , zap . String ( " " , dataDir ) , zap . String ( " " , s . snapDir ) , ) if err = s . saveDB ( ) ; err != nil { return err } if err = s . saveWALAndSnap ( ) ; err != nil { return err } s . lg . Info ( " " , zap . String ( " " , s . dbPath ) , zap . String ( " " , s . walDir ) , zap . String ( " " , dataDir ) , zap . String ( " " , s . snapDir ) , ) return nil } 
func ( s * v3Manager ) saveDB ( ) error { f , ferr := os . OpenFile ( s . dbPath , os . O_RDONLY , 0600 ) if ferr != nil { return ferr } defer f . Close ( ) } sha := make ( [ ] byte , sha256 . Size ) if _ , err := f . Read ( sha ) ; err != nil { return err } if _ , err := f . Seek ( 0 , io . SeekStart ) ; err != nil { return err } if err := fileutil . CreateDirAll ( s . snapDir ) ; err != nil { return err } dbpath := filepath . Join ( s . snapDir , " " ) db , dberr := os . OpenFile ( dbpath , os . O_RDWR | os . O_CREATE , 0600 ) if dberr != nil { return dberr } if _ , err := io . Copy ( db , f ) ; err != nil { return err } if serr != nil { return serr } hasHash := ( off % 512 ) == sha256 . Size if hasHash { if err := db . Truncate ( off - sha256 . Size ) ; err != nil { return err } } if ! hasHash && ! s . skipHashCheck { return fmt . Errorf ( " " ) } if hasHash && ! s . skipHashCheck { } h := sha256 . New ( ) if _ , err := io . Copy ( h , db ) ; err != nil { return err } dbsha := h . Sum ( nil ) if ! reflect . DeepEqual ( sha , dbsha ) { return fmt . Errorf ( " " , sha , dbsha ) } } commit := len ( s . cl . Members ( ) ) mvs := mvcc . NewStore ( s . lg , be , lessor , ( * initIndex ) ( & commit ) ) txn := mvs . Write ( ) btx := be . BatchTx ( ) del := func ( k , v [ ] byte ) error { txn . DeleteRange ( k , nil ) return nil } mvs . Commit ( ) mvs . Close ( ) be . Close ( ) return nil } 
func ( s * v3Manager ) saveWALAndSnap ( ) error { if err := fileutil . CreateDirAll ( s . walDir ) ; err != nil { return err } s . cl . SetStore ( st ) for _ , m := range s . cl . Members ( ) { s . cl . AddMember ( m ) } m := s . cl . MemberByName ( s . name ) md := & etcdserverpb . Metadata { NodeID : uint64 ( m . ID ) , ClusterID : uint64 ( s . cl . ID ( ) ) } metadata , merr := md . Marshal ( ) if merr != nil { return merr } w , walerr := wal . Create ( s . lg , s . walDir , metadata ) if walerr != nil { return walerr } defer w . Close ( ) peers := make ( [ ] raft . Peer , len ( s . cl . MemberIDs ( ) ) ) for i , id := range s . cl . MemberIDs ( ) { ctx , err := json . Marshal ( ( * s . cl ) . Member ( id ) ) if err != nil { return err } peers [ i ] = raft . Peer { ID : uint64 ( id ) , Context : ctx } } ents := make ( [ ] raftpb . Entry , len ( peers ) ) nodeIDs := make ( [ ] uint64 , len ( peers ) ) for i , p := range peers { nodeIDs [ i ] = p . ID cc := raftpb . ConfChange { Type : raftpb . ConfChangeAddNode , NodeID : p . ID , Context : p . Context , } d , err := cc . Marshal ( ) if err != nil { return err } ents [ i ] = raftpb . Entry { Type : raftpb . EntryConfChange , Term : 1 , Index : uint64 ( i + 1 ) , Data : d , } } commit , term := uint64 ( len ( ents ) ) , uint64 ( 1 ) if err := w . Save ( raftpb . HardState { Term : term , Vote : peers [ 0 ] . ID , Commit : commit , } , ents ) ; err != nil { return err } b , berr := st . Save ( ) if berr != nil { return berr } raftSnap := raftpb . Snapshot { Data : b , Metadata : raftpb . SnapshotMetadata { Index : commit , Term : term , ConfState : raftpb . ConfState { Nodes : nodeIDs , } , } , } sn := snap . New ( s . lg , s . snapDir ) if err := sn . SaveSnap ( raftSnap ) ; err != nil { return err } return w . SaveSnapshot ( walpb . Snapshot { Index : commit , Term : term } ) } 
func NewAuthStore ( lg * zap . Logger , be backend . Backend , tp TokenProvider , bcryptCost int ) * authStore { if bcryptCost < bcrypt . MinCost || bcryptCost > bcrypt . MaxCost { if lg != nil { lg . Warn ( " " , zap . Int ( " " , bcrypt . MinCost ) , zap . Int ( " " , bcrypt . MaxCost ) , zap . Int ( " " , bcrypt . DefaultCost ) , zap . Int ( " " , bcryptCost ) ) } else { plog . Warningf ( " " , bcrypt . DefaultCost , bcryptCost ) } bcryptCost = bcrypt . DefaultCost } tx := be . BatchTx ( ) tx . Lock ( ) tx . UnsafeCreateBucket ( authBucketName ) tx . UnsafeCreateBucket ( authUsersBucketName ) tx . UnsafeCreateBucket ( authRolesBucketName ) enabled := false _ , vs := tx . UnsafeRange ( authBucketName , enableFlagKey , nil , 0 ) if len ( vs ) == 1 { if bytes . Equal ( vs [ 0 ] , authEnabled ) { enabled = true } } as := & authStore { revision : getRevision ( tx ) , lg : lg , be : be , enabled : enabled , rangePermCache : make ( map [ string ] * unifiedRangePermissions ) , tokenProvider : tp , bcryptCost : bcryptCost , } if enabled { as . tokenProvider . enable ( ) } if as . Revision ( ) == 0 { as . commitRevision ( tx ) } tx . Unlock ( ) be . ForceCommit ( ) return as } 
func NewTokenProvider ( lg * zap . Logger , tokenOpts string , indexWaiter func ( uint64 ) <- chan struct { } ) ( TokenProvider , error ) { tokenType , typeSpecificOpts , err := decomposeOpts ( lg , tokenOpts ) if err != nil { return nil , ErrInvalidAuthOpts } switch tokenType { case tokenTypeSimple : if lg != nil { lg . Warn ( " " ) } else { plog . Warningf ( " " ) } return newTokenProviderSimple ( lg , indexWaiter ) , nil case tokenTypeJWT : return newTokenProviderJWT ( lg , typeSpecificOpts ) case " " : return newTokenProviderNop ( ) default : if lg != nil { lg . Warn ( " " , zap . String ( " " , tokenType ) , zap . Error ( ErrInvalidAuthOpts ) , ) } else { plog . Errorf ( " " , tokenType ) } return nil , ErrInvalidAuthOpts } } 
func ( t * Transport ) CutPeer ( id types . ID ) { t . mu . RLock ( ) p , pok := t . peers [ id ] g , gok := t . remotes [ id ] t . mu . RUnlock ( ) if pok { p . ( Pausable ) . Pause ( ) } if gok { g . Pause ( ) } } 
func ( t * Transport ) MendPeer ( id types . ID ) { t . mu . RLock ( ) p , pok := t . peers [ id ] g , gok := t . remotes [ id ] t . mu . RUnlock ( ) if pok { p . ( Pausable ) . Resume ( ) } if gok { g . Resume ( ) } } 
func ( t * Transport ) removePeer ( id types . ID ) { if peer , ok := t . peers [ id ] ; ok { peer . stop ( ) } else { if t . Logger != nil { t . Logger . Panic ( " " , zap . String ( " " , id . String ( ) ) ) } else { plog . Panicf ( " " , id ) } } delete ( t . peers , id ) delete ( t . LeaderStats . Followers , id . String ( ) ) t . pipelineProber . Remove ( id . String ( ) ) t . streamProber . Remove ( id . String ( ) ) if t . Logger != nil { t . Logger . Info ( " " , zap . String ( " " , t . ID . String ( ) ) , zap . String ( " " , id . String ( ) ) , ) } else { plog . Infof ( " " , id ) } } 
func ( t * Transport ) ActivePeers ( ) ( cnt int ) { t . mu . RLock ( ) defer t . mu . RUnlock ( ) for _ , p := range t . peers { if ! p . activeSince ( ) . IsZero ( ) { cnt ++ } } return cnt } 
func resolveTCPAddrDefault ( ctx context . Context , addr string ) ( * net . TCPAddr , error ) { host , port , serr := net . SplitHostPort ( addr ) if serr != nil { return nil , serr } portnum , perr := net . DefaultResolver . LookupPort ( ctx , " " , port ) if perr != nil { return nil , perr } var ips [ ] net . IPAddr if ip := net . ParseIP ( host ) ; ip != nil { ips = [ ] net . IPAddr { { IP : ip } } } else { if err != nil { return nil , err } ips = ipss } return & net . TCPAddr { IP : ip . IP , Port : portnum , Zone : ip . Zone } , nil } 
func resolveTCPAddrs ( ctx context . Context , lg * zap . Logger , urls [ ] [ ] url . URL ) ( [ ] [ ] url . URL , error ) { newurls := make ( [ ] [ ] url . URL , 0 ) for _ , us := range urls { nus := make ( [ ] url . URL , len ( us ) ) for i , u := range us { nu , err := url . Parse ( u . String ( ) ) if err != nil { return nil , fmt . Errorf ( " " , u . String ( ) , err ) } nus [ i ] = * nu } for i , u := range nus { h , err := resolveURL ( ctx , lg , u ) if err != nil { return nil , fmt . Errorf ( " " , u . String ( ) , err ) } if h != " " { nus [ i ] . Host = h } } newurls = append ( newurls , nus ) } return newurls , nil } 
func urlsEqual ( ctx context . Context , lg * zap . Logger , a [ ] url . URL , b [ ] url . URL ) ( bool , error ) { if len ( a ) != len ( b ) { return false , fmt . Errorf ( " " , urlsToStrings ( a ) , urlsToStrings ( b ) ) } urls , err := resolveTCPAddrs ( ctx , lg , [ ] [ ] url . URL { a , b } ) if err != nil { return false , err } preva , prevb := a , b a , b = urls [ 0 ] , urls [ 1 ] sort . Sort ( types . URLs ( a ) ) sort . Sort ( types . URLs ( b ) ) for i := range a { if ! reflect . DeepEqual ( a [ i ] , b [ i ] ) { return false , fmt . Errorf ( " " , a [ i ] . String ( ) , preva [ i ] . String ( ) , b [ i ] . String ( ) , prevb [ i ] . String ( ) , ) } } return true , nil } 
func URLStringsEqual ( ctx context . Context , lg * zap . Logger , a [ ] string , b [ ] string ) ( bool , error ) { if len ( a ) != len ( b ) { return false , fmt . Errorf ( " " , a , b ) } urlsA := make ( [ ] url . URL , 0 ) for _ , str := range a { u , err := url . Parse ( str ) if err != nil { return false , fmt . Errorf ( " " , str ) } urlsA = append ( urlsA , * u ) } urlsB := make ( [ ] url . URL , 0 ) for _ , str := range b { u , err := url . Parse ( str ) if err != nil { return false , fmt . Errorf ( " " , str ) } urlsB = append ( urlsB , * u ) } if lg == nil { lg , _ = zap . NewProduction ( ) if lg == nil { lg = zap . NewExample ( ) } } return urlsEqual ( ctx , lg , urlsA , urlsB ) } 
func NewLeaseCommand ( ) * cobra . Command { lc := & cobra . Command { Use : " " , Short : " " , } lc . AddCommand ( NewLeaseGrantCommand ( ) ) lc . AddCommand ( NewLeaseRevokeCommand ( ) ) lc . AddCommand ( NewLeaseTimeToLiveCommand ( ) ) lc . AddCommand ( NewLeaseListCommand ( ) ) lc . AddCommand ( NewLeaseKeepAliveCommand ( ) ) return lc } 
func NewLeaseGrantCommand ( ) * cobra . Command { lc := & cobra . Command { Use : " " , Short : " " , Run : leaseGrantCommandFunc , } return lc } 
func leaseGrantCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } ttl , err := strconv . ParseInt ( args [ 0 ] , 10 , 64 ) if err != nil { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " , err ) ) } ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . Grant ( ctx , ttl ) cancel ( ) if err != nil { ExitWithError ( ExitError , fmt . Errorf ( " " , err ) ) } display . Grant ( * resp ) } 
func NewLeaseRevokeCommand ( ) * cobra . Command { lc := & cobra . Command { Use : " " , Short : " " , Run : leaseRevokeCommandFunc , } return lc } 
func leaseRevokeCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } id := leaseFromArgs ( args [ 0 ] ) ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . Revoke ( ctx , id ) cancel ( ) if err != nil { ExitWithError ( ExitError , fmt . Errorf ( " " , err ) ) } display . Revoke ( id , * resp ) } 
func NewLeaseTimeToLiveCommand ( ) * cobra . Command { lc := & cobra . Command { Use : " " , Short : " " , Run : leaseTimeToLiveCommandFunc , } lc . Flags ( ) . BoolVar ( & timeToLiveKeys , " " , false , " " ) return lc } 
func leaseTimeToLiveCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } var opts [ ] v3 . LeaseOption if timeToLiveKeys { opts = append ( opts , v3 . WithAttachedKeys ( ) ) } resp , rerr := mustClientFromCmd ( cmd ) . TimeToLive ( context . TODO ( ) , leaseFromArgs ( args [ 0 ] ) , opts ... ) if rerr != nil { ExitWithError ( ExitBadConnection , rerr ) } display . TimeToLive ( * resp , timeToLiveKeys ) } 
func NewLeaseListCommand ( ) * cobra . Command { lc := & cobra . Command { Use : " " , Short : " " , Run : leaseListCommandFunc , } return lc } 
func leaseListCommandFunc ( cmd * cobra . Command , args [ ] string ) { resp , rerr := mustClientFromCmd ( cmd ) . Leases ( context . TODO ( ) ) if rerr != nil { ExitWithError ( ExitBadConnection , rerr ) } display . Leases ( * resp ) } 
func NewLeaseKeepAliveCommand ( ) * cobra . Command { lc := & cobra . Command { Use : " " , Short : " " , Run : leaseKeepAliveCommandFunc , } lc . Flags ( ) . BoolVar ( & leaseKeepAliveOnce , " " , false , " " ) return lc } 
func leaseKeepAliveCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } id := leaseFromArgs ( args [ 0 ] ) if leaseKeepAliveOnce { respc , kerr := mustClientFromCmd ( cmd ) . KeepAliveOnce ( context . TODO ( ) , id ) if kerr != nil { ExitWithError ( ExitBadConnection , kerr ) } display . KeepAlive ( * respc ) return } respc , kerr := mustClientFromCmd ( cmd ) . KeepAlive ( context . TODO ( ) , id ) if kerr != nil { ExitWithError ( ExitBadConnection , kerr ) } for resp := range respc { display . KeepAlive ( * resp ) } if _ , ok := ( display ) . ( * simplePrinter ) ; ok { fmt . Printf ( " \n " , id ) } } 
func ( s * EtcdServer ) CheckInitialHashKV ( ) error { if ! s . Cfg . InitialCorruptCheck { return nil } lg := s . getLogger ( ) if lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . Duration ( " " , s . Cfg . ReqTimeout ( ) ) , ) } else { plog . Infof ( " " , s . ID ( ) , s . Cfg . ReqTimeout ( ) ) } h , rev , crev , err := s . kv . HashByRev ( 0 ) if err != nil { return fmt . Errorf ( " " , s . ID ( ) , err ) } peers := s . getPeerHashKVs ( rev ) mismatch := 0 for _ , p := range peers { if p . resp != nil { peerID := types . ID ( p . resp . Header . MemberId ) fields := [ ] zap . Field { zap . String ( " " , s . ID ( ) . String ( ) ) , zap . Int64 ( " " , rev ) , zap . Int64 ( " " , crev ) , zap . Uint32 ( " " , h ) , zap . String ( " " , peerID . String ( ) ) , zap . Strings ( " " , p . eps ) , zap . Int64 ( " " , p . resp . Header . Revision ) , zap . Int64 ( " " , p . resp . CompactRevision ) , zap . Uint32 ( " " , p . resp . Hash ) , } if h != p . resp . Hash { if crev == p . resp . CompactRevision { if lg != nil { lg . Warn ( " " , fields ... ) } else { plog . Errorf ( " " , s . ID ( ) , h , peerID , p . resp . Hash , rev , p . resp . Header . Revision , crev ) } mismatch ++ } else { if lg != nil { lg . Warn ( " " , fields ... ) } else { plog . Warningf ( " " , s . ID ( ) , peerID , p . resp . CompactRevision , rev ) } } } continue } if p . err != nil { switch p . err { case rpctypes . ErrFutureRev : if lg != nil { lg . Warn ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . Int64 ( " " , rev ) , zap . Int64 ( " " , crev ) , zap . Uint32 ( " " , h ) , zap . String ( " " , p . id . String ( ) ) , zap . Strings ( " " , p . eps ) , zap . Error ( err ) , ) } else { plog . Warningf ( " " , s . ID ( ) , p . eps , rev , p . err . Error ( ) ) } case rpctypes . ErrCompacted : if lg != nil { lg . Warn ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . Int64 ( " " , rev ) , zap . Int64 ( " " , crev ) , zap . Uint32 ( " " , h ) , zap . String ( " " , p . id . String ( ) ) , zap . Strings ( " " , p . eps ) , zap . Error ( err ) , ) } else { plog . Warningf ( " " , s . ID ( ) , p . eps , rev , p . err . Error ( ) ) } } } } if mismatch > 0 { return fmt . Errorf ( " " , s . ID ( ) ) } if lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , ) } else { plog . Infof ( " " , s . ID ( ) ) } return nil } 
func NewAlarmCommand ( ) * cobra . Command { ac := & cobra . Command { Use : " " , Short : " " , } ac . AddCommand ( NewAlarmDisarmCommand ( ) ) ac . AddCommand ( NewAlarmListCommand ( ) ) return ac } 
func alarmDisarmCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 0 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . AlarmDisarm ( ctx , & v3 . AlarmMember { } ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . Alarm ( * resp ) } 
func alarmListCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 0 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . AlarmList ( ctx ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . Alarm ( * resp ) } 
func ( e * Etcd ) Flags ( ) ( fs [ ] string ) { tp := reflect . TypeOf ( * e ) vo := reflect . ValueOf ( * e ) for _ , name := range etcdFields { field , ok := tp . FieldByName ( name ) if ! ok { panic ( fmt . Errorf ( " " , name ) ) } fv := reflect . Indirect ( vo ) . FieldByName ( name ) var sv string switch fv . Type ( ) . Kind ( ) { case reflect . String : sv = fv . String ( ) case reflect . Slice : n := fv . Len ( ) sl := make ( [ ] string , n ) for i := 0 ; i < n ; i ++ { sl [ i ] = fv . Index ( i ) . String ( ) } sv = strings . Join ( sl , " " ) case reflect . Int64 : sv = fmt . Sprintf ( " " , fv . Int ( ) ) case reflect . Bool : sv = fmt . Sprintf ( " " , fv . Bool ( ) ) default : panic ( fmt . Errorf ( " " , name , fv . Type ( ) . Kind ( ) ) ) } fname := field . Tag . Get ( " " ) } if sv != " " { fs = append ( fs , fmt . Sprintf ( " " , fname , sv ) ) } } return fs } 
func ( e * Etcd ) EmbedConfig ( ) ( cfg * embed . Config , err error ) { var lcURLs types . URLs lcURLs , err = types . NewURLs ( e . ListenClientURLs ) if err != nil { return nil , err } var acURLs types . URLs acURLs , err = types . NewURLs ( e . AdvertiseClientURLs ) if err != nil { return nil , err } var lpURLs types . URLs lpURLs , err = types . NewURLs ( e . ListenPeerURLs ) if err != nil { return nil , err } var apURLs types . URLs apURLs , err = types . NewURLs ( e . AdvertisePeerURLs ) if err != nil { return nil , err } cfg = embed . NewConfig ( ) cfg . Name = e . Name cfg . Dir = e . DataDir cfg . WalDir = e . WALDir cfg . TickMs = uint ( e . HeartbeatIntervalMs ) cfg . ElectionMs = uint ( e . ElectionTimeoutMs ) cfg . LCUrls = lcURLs cfg . ACUrls = acURLs cfg . ClientAutoTLS = e . ClientAutoTLS cfg . ClientTLSInfo = transport . TLSInfo { ClientCertAuth : e . ClientCertAuth , CertFile : e . ClientCertFile , KeyFile : e . ClientKeyFile , TrustedCAFile : e . ClientTrustedCAFile , } cfg . LPUrls = lpURLs cfg . APUrls = apURLs cfg . PeerAutoTLS = e . PeerAutoTLS cfg . PeerTLSInfo = transport . TLSInfo { ClientCertAuth : e . PeerClientCertAuth , CertFile : e . PeerCertFile , KeyFile : e . PeerKeyFile , TrustedCAFile : e . PeerTrustedCAFile , } cfg . InitialCluster = e . InitialCluster cfg . ClusterState = e . InitialClusterState cfg . InitialClusterToken = e . InitialClusterToken cfg . SnapshotCount = uint64 ( e . SnapshotCount ) cfg . QuotaBackendBytes = e . QuotaBackendBytes cfg . PreVote = e . PreVote cfg . ExperimentalInitialCorruptCheck = e . InitialCorruptCheck cfg . Logger = e . Logger cfg . LogOutputs = e . LogOutputs cfg . Debug = e . Debug return cfg , nil } 
func PProfHandlers ( ) map [ string ] http . Handler { } m := make ( map [ string ] http . Handler ) m [ HTTPPrefixPProf + " " ] = http . HandlerFunc ( pprof . Index ) m [ HTTPPrefixPProf + " " ] = http . HandlerFunc ( pprof . Profile ) m [ HTTPPrefixPProf + " " ] = http . HandlerFunc ( pprof . Symbol ) m [ HTTPPrefixPProf + " " ] = http . HandlerFunc ( pprof . Cmdline ) m [ HTTPPrefixPProf + " " ] = http . HandlerFunc ( pprof . Trace ) m [ HTTPPrefixPProf + " " ] = pprof . Handler ( " " ) m [ HTTPPrefixPProf + " " ] = pprof . Handler ( " " ) m [ HTTPPrefixPProf + " " ] = pprof . Handler ( " " ) m [ HTTPPrefixPProf + " " ] = pprof . Handler ( " " ) m [ HTTPPrefixPProf + " " ] = pprof . Handler ( " " ) return m } 
func NewBackendQuota ( s * EtcdServer , name string ) Quota { lg := s . getLogger ( ) quotaBackendBytes . Set ( float64 ( s . Cfg . QuotaBackendBytes ) ) if s . Cfg . QuotaBackendBytes < 0 { } else { plog . Warningf ( " " ) } } ) return & passthroughQuota { } } if s . Cfg . QuotaBackendBytes == 0 { } } ) quotaBackendBytes . Set ( float64 ( DefaultQuotaBytes ) ) return & backendQuota { s , DefaultQuotaBytes } } quotaLogOnce . Do ( func ( ) { if s . Cfg . QuotaBackendBytes > MaxQuotaBytes { if lg != nil { lg . Warn ( " " , zap . String ( " " , name ) , zap . Int64 ( " " , s . Cfg . QuotaBackendBytes ) , zap . String ( " " , humanize . Bytes ( uint64 ( s . Cfg . QuotaBackendBytes ) ) ) , zap . Int64 ( " " , MaxQuotaBytes ) , zap . String ( " " , maxQuotaSize ) , ) } else { plog . Warningf ( " " , s . Cfg . QuotaBackendBytes , MaxQuotaBytes ) } } if lg != nil { lg . Info ( " " , zap . String ( " " , name ) , zap . Int64 ( " " , s . Cfg . QuotaBackendBytes ) , zap . String ( " " , humanize . Bytes ( uint64 ( s . Cfg . QuotaBackendBytes ) ) ) , ) } } ) return & backendQuota { s , s . Cfg . QuotaBackendBytes } } 
func NewClusterProxy ( c * clientv3 . Client , advaddr string , prefix string ) ( pb . ClusterServer , <- chan struct { } ) { cp := & clusterProxy { clus : c . Cluster , ctx : c . Ctx ( ) , gr : & naming . GRPCResolver { Client : c } , advaddr : advaddr , prefix : prefix , umap : make ( map [ string ] gnaming . Update ) , } donec := make ( chan struct { } ) if advaddr != " " && prefix != " " { go func ( ) { defer close ( donec ) cp . resolve ( prefix ) } ( ) return cp , donec } close ( donec ) return cp , donec } 
func ( cp * clusterProxy ) MemberList ( ctx context . Context , r * pb . MemberListRequest ) ( * pb . MemberListResponse , error ) { if cp . advaddr != " " { if cp . prefix != " " { mbs , err := cp . membersFromUpdates ( ) if err != nil { return nil , err } if len ( mbs ) > 0 { return & pb . MemberListResponse { Members : mbs } , nil } } return & pb . MemberListResponse { Members : [ ] * pb . Member { { Name : hostname , ClientURLs : [ ] string { cp . advaddr } } } } , nil } mresp , err := cp . clus . MemberList ( ctx ) if err != nil { return nil , err } resp := ( pb . MemberListResponse ) ( * mresp ) return & resp , err } 
func NewHandler ( l lease . Lessor , waitch func ( ) <- chan struct { } ) http . Handler { return & leaseHandler { l , waitch } } 
func RenewHTTP ( ctx context . Context , id lease . LeaseID , url string , rt http . RoundTripper ) ( int64 , error ) { if err != nil { return - 1 , err } cc := & http . Client { Transport : rt } req , err := http . NewRequest ( " " , url , bytes . NewReader ( lreq ) ) if err != nil { return - 1 , err } req . Header . Set ( " " , " " ) req . Cancel = ctx . Done ( ) resp , err := cc . Do ( req ) if err != nil { return - 1 , err } b , err := readResponse ( resp ) if err != nil { return - 1 , err } if resp . StatusCode == http . StatusRequestTimeout { return - 1 , ErrLeaseHTTPTimeout } if resp . StatusCode == http . StatusNotFound { return - 1 , lease . ErrLeaseNotFound } if resp . StatusCode != http . StatusOK { return - 1 , fmt . Errorf ( " " , string ( b ) ) } lresp := & pb . LeaseKeepAliveResponse { } if err := lresp . Unmarshal ( b ) ; err != nil { return - 1 , fmt . Errorf ( `lease: %v. data = "%s"` , err , string ( b ) ) } if lresp . ID != int64 ( id ) { return - 1 , fmt . Errorf ( " " ) } return lresp . TTL , nil } 
func TimeToLiveHTTP ( ctx context . Context , id lease . LeaseID , keys bool , url string , rt http . RoundTripper ) ( * leasepb . LeaseInternalResponse , error ) { if err != nil { return nil , err } req , err := http . NewRequest ( " " , url , bytes . NewReader ( lreq ) ) if err != nil { return nil , err } req . Header . Set ( " " , " " ) req = req . WithContext ( ctx ) cc := & http . Client { Transport : rt } var b [ ] byte if err != nil { return nil , err } b , err = readResponse ( resp ) if err != nil { return nil , err } if resp . StatusCode == http . StatusRequestTimeout { return nil , ErrLeaseHTTPTimeout } if resp . StatusCode == http . StatusNotFound { return nil , lease . ErrLeaseNotFound } if resp . StatusCode != http . StatusOK { return nil , fmt . Errorf ( " " , string ( b ) ) } lresp := & leasepb . LeaseInternalResponse { } if err := lresp . Unmarshal ( b ) ; err != nil { return nil , fmt . Errorf ( `lease: %v. data = "%s"` , err , string ( b ) ) } if lresp . LeaseTimeToLiveResponse . ID != int64 ( id ) { return nil , fmt . Errorf ( " " ) } return lresp , nil } 
func newWatcherBatch ( wg * watcherGroup , evs [ ] mvccpb . Event ) watcherBatch { if len ( wg . watchers ) == 0 { return nil } wb := make ( watcherBatch ) for _ , ev := range evs { for w := range wg . watcherSetByKey ( string ( ev . Kv . Key ) ) { if ev . Kv . ModRevision >= w . minRev { } } } return wb } 
func ( wg * watcherGroup ) add ( wa * watcher ) { wg . watchers . add ( wa ) if wa . end == nil { wg . keyWatchers . add ( wa ) return } if iv := wg . ranges . Find ( ivl ) ; iv != nil { iv . Val . ( watcherSet ) . add ( wa ) return } ws . add ( wa ) wg . ranges . Insert ( ivl , ws ) } 
func ( wg * watcherGroup ) contains ( key string ) bool { _ , ok := wg . keyWatchers [ key ] return ok || wg . ranges . Intersects ( adt . NewStringAffinePoint ( key ) ) } 
func ( wg * watcherGroup ) delete ( wa * watcher ) bool { if _ , ok := wg . watchers [ wa ] ; ! ok { return false } wg . watchers . delete ( wa ) if wa . end == nil { wg . keyWatchers . delete ( wa ) return true } ivl := adt . NewStringAffineInterval ( string ( wa . key ) , string ( wa . end ) ) iv := wg . ranges . Find ( ivl ) if iv == nil { return false } ws := iv . Val . ( watcherSet ) delete ( ws , wa ) if len ( ws ) == 0 { } } return true } 
func ( wg * watcherGroup ) choose ( maxWatchers int , curRev , compactRev int64 ) ( * watcherGroup , int64 ) { if len ( wg . watchers ) < maxWatchers { return wg , wg . chooseAll ( curRev , compactRev ) } ret := newWatcherGroup ( ) for w := range wg . watchers { if maxWatchers <= 0 { break } maxWatchers -- ret . add ( w ) } return & ret , ret . chooseAll ( curRev , compactRev ) } 
func ( wg * watcherGroup ) watcherSetByKey ( key string ) watcherSet { wkeys := wg . keyWatchers [ key ] wranges := wg . ranges . Stab ( adt . NewStringAffinePoint ( key ) ) case len ( wranges ) == 0 && len ( wkeys ) == 0 : return nil case len ( wranges ) == 1 && len ( wkeys ) == 0 : return wranges [ 0 ] . Val . ( watcherSet ) } ret . union ( wg . keyWatchers [ key ] ) for _ , item := range wranges { ret . union ( item . Val . ( watcherSet ) ) } return ret } 
func ( ivl * Interval ) Compare ( c Comparable ) int { ivl2 := c . ( * Interval ) ivbCmpBegin := ivl . Begin . Compare ( ivl2 . Begin ) ivbCmpEnd := ivl . Begin . Compare ( ivl2 . End ) iveCmpBegin := ivl . End . Compare ( ivl2 . Begin ) } } return 0 } 
func ( x * intervalNode ) successor ( ) * intervalNode { if x . right != nil { return x . right . min ( ) } y := x . parent for y != nil && x == y . right { x = y y = y . parent } return y } 
func ( x * intervalNode ) updateMax ( ) { for x != nil { oldmax := x . max max := x . iv . Ivl . End if x . left != nil && x . left . max . Compare ( max ) > 0 { max = x . left . max } if x . right != nil && x . right . max . Compare ( max ) > 0 { max = x . right . max } if oldmax . Compare ( max ) == 0 { break } x . max = max x = x . parent } } 
func ( x * intervalNode ) visit ( iv * Interval , nv nodeVisitor ) bool { if x == nil { return true } v := iv . Compare ( & x . iv . Ivl ) switch { case v < 0 : if ! x . left . visit ( iv , nv ) { return false } case v > 0 : maxiv := Interval { x . iv . Ivl . Begin , x . max } if maxiv . Compare ( iv ) == 0 { if ! x . left . visit ( iv , nv ) || ! x . right . visit ( iv , nv ) { return false } } default : if ! x . left . visit ( iv , nv ) || ! nv ( x ) || ! x . right . visit ( iv , nv ) { return false } } return true } 
func ( ivt * IntervalTree ) Delete ( ivl Interval ) bool { z := ivt . find ( ivl ) if z == nil { return false } y := z if z . left != nil && z . right != nil { y = z . successor ( ) } x := y . left if x == nil { x = y . right } if x != nil { x . parent = y . parent } if y . parent == nil { ivt . root = x } else { if y == y . parent . left { y . parent . left = x } else { y . parent . right = x } y . parent . updateMax ( ) } if y != z { z . iv = y . iv z . updateMax ( ) } if y . color ( ) == black && x != nil { ivt . deleteFixup ( x ) } ivt . count -- return true } 
func ( ivt * IntervalTree ) Insert ( ivl Interval , val interface { } ) { var y * intervalNode z := & intervalNode { iv : IntervalValue { ivl , val } , max : ivl . End , c : red } x := ivt . root for x != nil { y = x if z . iv . Ivl . Begin . Compare ( x . iv . Ivl . Begin ) < 0 { x = x . left } else { x = x . right } } z . parent = y if y == nil { ivt . root = z } else { if z . iv . Ivl . Begin . Compare ( y . iv . Ivl . Begin ) < 0 { y . left = z } else { y . right = z } y . updateMax ( ) } z . c = red ivt . insertFixup ( z ) ivt . count ++ } 
func ( ivt * IntervalTree ) rotateLeft ( x * intervalNode ) { y := x . right x . right = y . left if y . left != nil { y . left . parent = x } x . updateMax ( ) ivt . replaceParent ( x , y ) y . left = x y . updateMax ( ) } 
func ( ivt * IntervalTree ) replaceParent ( x * intervalNode , y * intervalNode ) { y . parent = x . parent if x . parent == nil { ivt . root = y } else { if x == x . parent . left { x . parent . left = y } else { x . parent . right = y } x . parent . updateMax ( ) } x . parent = y } 
func ( ivt * IntervalTree ) MaxHeight ( ) int { return int ( ( 2 * math . Log2 ( float64 ( ivt . Len ( ) + 1 ) ) ) + 0.5 ) } 
func ( ivt * IntervalTree ) Visit ( ivl Interval , ivv IntervalVisitor ) { ivt . root . visit ( & ivl , func ( n * intervalNode ) bool { return ivv ( & n . iv ) } ) } 
func ( ivt * IntervalTree ) find ( ivl Interval ) ( ret * intervalNode ) { f := func ( n * intervalNode ) bool { if n . iv . Ivl != ivl { return true } ret = n return false } ivt . root . visit ( & ivl , f ) return ret } 
func ( ivt * IntervalTree ) Find ( ivl Interval ) ( ret * IntervalValue ) { n := ivt . find ( ivl ) if n == nil { return nil } return & n . iv } 
func ( ivt * IntervalTree ) Intersects ( iv Interval ) bool { x := ivt . root for x != nil && iv . Compare ( & x . iv . Ivl ) != 0 { if x . left != nil && x . left . max . Compare ( iv . Begin ) > 0 { x = x . left } else { x = x . right } } return x != nil } 
func ( ivt * IntervalTree ) Contains ( ivl Interval ) bool { var maxEnd , minBegin Comparable isContiguous := true ivt . Visit ( ivl , func ( n * IntervalValue ) bool { if minBegin == nil { minBegin = n . Ivl . Begin maxEnd = n . Ivl . End return true } if maxEnd . Compare ( n . Ivl . Begin ) < 0 { isContiguous = false return false } if n . Ivl . End . Compare ( maxEnd ) > 0 { maxEnd = n . Ivl . End } return true } ) return isContiguous && minBegin != nil && maxEnd . Compare ( ivl . End ) >= 0 && minBegin . Compare ( ivl . Begin ) <= 0 } 
func ( ivt * IntervalTree ) Stab ( iv Interval ) ( ivs [ ] * IntervalValue ) { if ivt . count == 0 { return nil } f := func ( n * IntervalValue ) bool { ivs = append ( ivs , n ) ; return true } ivt . Visit ( iv , f ) return ivs } 
func ( ivt * IntervalTree ) Union ( inIvt IntervalTree , ivl Interval ) { f := func ( n * IntervalValue ) bool { ivt . Insert ( n . Ivl , n . Val ) return true } inIvt . Visit ( ivl , f ) } 
func NewExactReadCloser ( rc io . ReadCloser , totalBytes int64 ) io . ReadCloser { return & exactReadCloser { rc : rc , totalBytes : totalBytes } } 
func NewElection ( s * Session , pfx string ) * Election { return & Election { session : s , keyPrefix : pfx + " " } } 
func ResumeElection ( s * Session , pfx string , leaderKey string , leaderRev int64 ) * Election { return & Election { keyPrefix : pfx , session : s , leaderKey : leaderKey , leaderRev : leaderRev , leaderSession : s , } } 
func ( e * Election ) Campaign ( ctx context . Context , val string ) error { s := e . session client := e . session . Client ( ) k := fmt . Sprintf ( " " , e . keyPrefix , s . Lease ( ) ) txn := client . Txn ( ctx ) . If ( v3 . Compare ( v3 . CreateRevision ( k ) , " " , 0 ) ) txn = txn . Then ( v3 . OpPut ( k , val , v3 . WithLease ( s . Lease ( ) ) ) ) txn = txn . Else ( v3 . OpGet ( k ) ) resp , err := txn . Commit ( ) if err != nil { return err } e . leaderKey , e . leaderRev , e . leaderSession = k , resp . Header . Revision , s if ! resp . Succeeded { kv := resp . Responses [ 0 ] . GetResponseRange ( ) . Kvs [ 0 ] e . leaderRev = kv . CreateRevision if string ( kv . Value ) != val { if err = e . Proclaim ( ctx , val ) ; err != nil { e . Resign ( ctx ) return err } } } _ , err = waitDeletes ( ctx , client , e . keyPrefix , e . leaderRev - 1 ) if err != nil { default : e . leaderSession = nil } return err } e . hdr = resp . Header return nil } 
func ( e * Election ) Proclaim ( ctx context . Context , val string ) error { if e . leaderSession == nil { return ErrElectionNotLeader } client := e . session . Client ( ) cmp := v3 . Compare ( v3 . CreateRevision ( e . leaderKey ) , " " , e . leaderRev ) txn := client . Txn ( ctx ) . If ( cmp ) txn = txn . Then ( v3 . OpPut ( e . leaderKey , val , v3 . WithLease ( e . leaderSession . Lease ( ) ) ) ) tresp , terr := txn . Commit ( ) if terr != nil { return terr } if ! tresp . Succeeded { e . leaderKey = " " return ErrElectionNotLeader } e . hdr = tresp . Header return nil } 
func ( e * Election ) Resign ( ctx context . Context ) ( err error ) { if e . leaderSession == nil { return nil } client := e . session . Client ( ) cmp := v3 . Compare ( v3 . CreateRevision ( e . leaderKey ) , " " , e . leaderRev ) resp , err := client . Txn ( ctx ) . If ( cmp ) . Then ( v3 . OpDelete ( e . leaderKey ) ) . Commit ( ) if err == nil { e . hdr = resp . Header } e . leaderKey = " " e . leaderSession = nil return err } 
func ( e * Election ) Leader ( ctx context . Context ) ( * v3 . GetResponse , error ) { client := e . session . Client ( ) resp , err := client . Get ( ctx , e . keyPrefix , v3 . WithFirstCreate ( ) ... ) if err != nil { return nil , err } else if len ( resp . Kvs ) == 0 { } return resp , nil } 
func ( e * Election ) Observe ( ctx context . Context ) <- chan v3 . GetResponse { retc := make ( chan v3 . GetResponse ) go e . observe ( ctx , retc ) return retc } 
func ( qa * quotaAlarmer ) check ( ctx context . Context , r interface { } ) error { if qa . q . Available ( r ) { return nil } req := & pb . AlarmRequest { MemberID : uint64 ( qa . id ) , Action : pb . AlarmRequest_ACTIVATE , Alarm : pb . AlarmType_NOSPACE , } qa . a . Alarm ( ctx , req ) return rpctypes . ErrGRPCNoSpace } 
func NewExecWatchCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Flags : [ ] cli . Flag { cli . IntFlag { Name : " " , Value : 0 , Usage : " " } , cli . BoolFlag { Name : " " , Usage : " " } , } , Action : func ( c * cli . Context ) error { execWatchCommandFunc ( c , mustNewKeyAPI ( c ) ) return nil } , } } 
func execWatchCommandFunc ( c * cli . Context , ki client . KeysAPI ) { args := c . Args ( ) argslen := len ( args ) if argslen < 2 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } var ( key string cmdArgs [ ] string ) foundSep := false for i := range args { if args [ i ] == " " && i != 0 { foundSep = true break } } if foundSep { key = args [ 0 ] cmdArgs = args [ 2 : ] } else { cmdArgs = args [ : argslen - 1 ] } index := 0 if c . Int ( " " ) != 0 { index = c . Int ( " " ) } recursive := c . Bool ( " " ) sigch := make ( chan os . Signal , 1 ) signal . Notify ( sigch , os . Interrupt ) go func ( ) { <- sigch os . Exit ( 0 ) } ( ) w := ki . Watcher ( key , & client . WatcherOptions { AfterIndex : uint64 ( index ) , Recursive : recursive } ) for { resp , err := w . Next ( context . TODO ( ) ) if err != nil { handleError ( c , ExitServerError , err ) } if resp . Node . Dir { fmt . Fprintf ( os . Stderr , " \n " , resp . Node . Key ) continue } cmd := exec . Command ( cmdArgs [ 0 ] , cmdArgs [ 1 : ] ... ) cmd . Env = environResponse ( resp , os . Environ ( ) ) cmd . Stdout = os . Stdout cmd . Stderr = os . Stderr go func ( ) { err := cmd . Start ( ) if err != nil { fmt . Fprintf ( os . Stderr , err . Error ( ) ) os . Exit ( 1 ) } cmd . Wait ( ) } ( ) } } 
func NewListener ( u url . URL , tlsinfo * transport . TLSInfo ) ( net . Listener , error ) { return transport . NewTimeoutListener ( u . Host , u . Scheme , tlsinfo , ConnReadTimeout , ConnWriteTimeout ) } 
func NewRoundTripper ( tlsInfo transport . TLSInfo , dialTimeout time . Duration ) ( http . RoundTripper , error ) { } 
func newStreamRoundTripper ( tlsInfo transport . TLSInfo , dialTimeout time . Duration ) ( http . RoundTripper , error ) { return transport . NewTimeoutTransport ( tlsInfo , dialTimeout , ConnReadTimeout , ConnWriteTimeout ) } 
func createPostRequest ( u url . URL , path string , body io . Reader , ct string , urls types . URLs , from , cid types . ID ) * http . Request { uu := u uu . Path = path req , err := http . NewRequest ( " " , uu . String ( ) , body ) if err != nil { plog . Panicf ( " " , err ) } req . Header . Set ( " " , ct ) req . Header . Set ( " " , from . String ( ) ) req . Header . Set ( " " , version . Version ) req . Header . Set ( " " , version . MinClusterVersion ) req . Header . Set ( " " , cid . String ( ) ) setPeerURLsHeader ( req , urls ) return req } 
func checkPostResponse ( resp * http . Response , body [ ] byte , req * http . Request , to types . ID ) error { switch resp . StatusCode { case http . StatusPreconditionFailed : switch strings . TrimSuffix ( string ( body ) , " \n " ) { case errIncompatibleVersion . Error ( ) : plog . Errorf ( " " , to ) return errIncompatibleVersion case errClusterIDMismatch . Error ( ) : plog . Errorf ( " " , to , resp . Header . Get ( " " ) , req . Header . Get ( " " ) ) return errClusterIDMismatch default : return fmt . Errorf ( " " , string ( body ) ) } case http . StatusForbidden : return errMemberRemoved case http . StatusNoContent : return nil default : return fmt . Errorf ( " " , http . StatusText ( resp . StatusCode ) , req . URL . String ( ) ) } } 
func compareMajorMinorVersion ( a , b * semver . Version ) int { na := & semver . Version { Major : a . Major , Minor : a . Minor } nb := & semver . Version { Major : b . Major , Minor : b . Minor } switch { case na . LessThan ( * nb ) : return - 1 case nb . LessThan ( * na ) : return 1 default : return 0 } } 
func serverVersion ( h http . Header ) * semver . Version { verStr := h . Get ( " " ) } return semver . Must ( semver . NewVersion ( verStr ) ) } 
func checkVersionCompatibility ( name string , server , minCluster * semver . Version ) ( localServer * semver . Version , localMinCluster * semver . Version , err error ) { localServer = semver . Must ( semver . NewVersion ( version . Version ) ) localMinCluster = semver . Must ( semver . NewVersion ( version . MinClusterVersion ) ) if compareMajorMinorVersion ( server , localMinCluster ) == - 1 { return localServer , localMinCluster , fmt . Errorf ( " " , name , server , localServer ) } if compareMajorMinorVersion ( minCluster , localServer ) == 1 { return localServer , localMinCluster , fmt . Errorf ( " " , name , server , localServer ) } return localServer , localMinCluster , nil } 
func setPeerURLsHeader ( req * http . Request , urls types . URLs ) { if urls == nil { } peerURLs := make ( [ ] string , urls . Len ( ) ) for i := range urls { peerURLs [ i ] = urls [ i ] . String ( ) } req . Header . Set ( " " , strings . Join ( peerURLs , " " ) ) } 
func addRemoteFromRequest ( tr Transporter , r * http . Request ) { if from , err := types . IDFromString ( r . Header . Get ( " " ) ) ; err == nil { if urls := r . Header . Get ( " " ) ; urls != " " { tr . AddRemote ( from , strings . Split ( urls , " " ) ) } } } 
func NewKeysAPIWithPrefix ( c Client , p string ) KeysAPI { return & httpKeysAPI { client : c , prefix : p , } } 
func ( n * Node ) TTLDuration ( ) time . Duration { return time . Duration ( n . TTL ) * time . Second } 
func v2KeysURL ( ep url . URL , prefix , key string ) * url . URL { } if key != " " && key [ 0 ] != '/' { key = " " + key } ep . Path = pathutil . CanonicalURLPath ( ep . Path + prefix + key ) return & ep } 
func SetFlagsFromEnv ( prefix string , fs * flag . FlagSet ) error { var err error alreadySet := make ( map [ string ] bool ) fs . Visit ( func ( f * flag . Flag ) { alreadySet [ FlagToEnv ( prefix , f . Name ) ] = true } ) usedEnvKey := make ( map [ string ] bool ) fs . VisitAll ( func ( f * flag . Flag ) { if serr := setFlagFromEnv ( fs , prefix , f . Name , usedEnvKey , alreadySet , true ) ; serr != nil { err = serr } } ) verifyEnv ( prefix , usedEnvKey , alreadySet ) return err } 
func SetPflagsFromEnv ( prefix string , fs * pflag . FlagSet ) error { var err error alreadySet := make ( map [ string ] bool ) usedEnvKey := make ( map [ string ] bool ) fs . VisitAll ( func ( f * pflag . Flag ) { if f . Changed { alreadySet [ FlagToEnv ( prefix , f . Name ) ] = true } if serr := setFlagFromEnv ( fs , prefix , f . Name , usedEnvKey , alreadySet , false ) ; serr != nil { err = serr } } ) verifyEnv ( prefix , usedEnvKey , alreadySet ) return err } 
func FlagToEnv ( prefix , name string ) string { return prefix + " " + strings . ToUpper ( strings . Replace ( name , " " , " " , - 1 ) ) } 
func excerpt ( str string , pre , suf int ) string { if pre + suf > len ( str ) { return fmt . Sprintf ( " " , str ) } return fmt . Sprintf ( " " , str [ : pre ] , str [ len ( str ) - suf : ] ) } 
func passConfChange ( entry raftpb . Entry ) ( bool , string ) { return entry . Type == raftpb . EntryConfChange , " " } 
func printInternalRaftRequest ( entry raftpb . Entry ) { var rr etcdserverpb . InternalRaftRequest if err := rr . Unmarshal ( entry . Data ) ; err == nil { fmt . Printf ( " \t \t \t " , entry . Term , entry . Index , rr . String ( ) ) } } 
func evaluateEntrytypeFlag ( entrytype string ) [ ] EntryFilter { var entrytypelist [ ] string if entrytype != " " { entrytypelist = strings . Split ( entrytype , " " ) } validRequest := map [ string ] [ ] EntryFilter { " " : { passConfChange } , " " : { passInternalRaftRequest , passRequest , passUnknownNormal } , " " : { passRequest } , " " : { passInternalRaftRequest } , " " : { passIRRRange } , " " : { passIRRPut } , " " : { passIRRDeleteRange } , " " : { passIRRTxn } , " " : { passIRRCompaction } , " " : { passIRRLeaseGrant } , " " : { passIRRLeaseRevoke } , " " : { passIRRLeaseCheckpoint } , } filters := make ( [ ] EntryFilter , 0 ) if len ( entrytypelist ) == 0 { filters = append ( filters , passInternalRaftRequest ) filters = append ( filters , passRequest ) filters = append ( filters , passUnknownNormal ) filters = append ( filters , passConfChange ) } for _ , et := range entrytypelist { if f , ok := validRequest [ et ] ; ok { filters = append ( filters , f ... ) } else { log . Printf ( `[%+v] is not a valid entry-type, ignored. Please set entry-type to one or more of the following: ConfigChange, Normal, Request, InternalRaftRequest, IRRRange, IRRPut, IRRDeleteRange, IRRTxn, IRRCompaction, IRRLeaseGrant, IRRLeaseRevoke, IRRLeaseCheckpoint` , et ) } } return filters } 
func listEntriesType ( entrytype string , streamdecoder string , ents [ ] raftpb . Entry ) { entryFilters := evaluateEntrytypeFlag ( entrytype ) printerMap := map [ string ] EntryPrinter { " " : printInternalRaftRequest , " " : printRequest , " " : printConfChange , " " : printUnknownNormal } var stderr bytes . Buffer args := strings . Split ( streamdecoder , " " ) cmd := exec . Command ( args [ 0 ] , args [ 1 : ] ... ) stdin , err := cmd . StdinPipe ( ) if err != nil { log . Panic ( err ) } stdout , err := cmd . StdoutPipe ( ) if err != nil { log . Panic ( err ) } cmd . Stderr = & stderr if streamdecoder != " " { err = cmd . Start ( ) if err != nil { log . Panic ( err ) } } cnt := 0 for _ , e := range ents { passed := false currtype := " " for _ , filter := range entryFilters { passed , currtype = filter ( e ) if passed { cnt ++ break } } if passed { printer := printerMap [ currtype ] printer ( e ) if streamdecoder == " " { fmt . Println ( ) continue } io . WriteString ( stdin , " \n " ) outputReader := bufio . NewReader ( stdout ) decoderoutput , currerr := outputReader . ReadString ( '\n' ) if currerr != nil { fmt . Println ( currerr ) return } decoder_status , decoded_data := parseDecoderOutput ( decoderoutput ) fmt . Printf ( " \t \t " , decoder_status , decoded_data ) } } stdin . Close ( ) err = cmd . Wait ( ) if streamdecoder != " " { if err != nil { log . Panic ( err ) } if stderr . String ( ) != " " { os . Stderr . WriteString ( " " + stderr . String ( ) ) } } fmt . Printf ( " \n " , entrytype , cnt ) } 
func newLog ( storage Storage , logger Logger ) * raftLog { return newLogWithSize ( storage , logger , noLimit ) } 
func newLogWithSize ( storage Storage , logger Logger , maxNextEntsSize uint64 ) * raftLog { if storage == nil { log . Panic ( " " ) } log := & raftLog { storage : storage , logger : logger , maxNextEntsSize : maxNextEntsSize , } firstIndex , err := storage . FirstIndex ( ) if err != nil { panic ( err ) } lastIndex , err := storage . LastIndex ( ) if err != nil { panic ( err ) } log . unstable . offset = lastIndex + 1 log . unstable . logger = logger log . applied = firstIndex - 1 return log } 
func ( l * raftLog ) maybeAppend ( index , logTerm , committed uint64 , ents ... pb . Entry ) ( lastnewi uint64 , ok bool ) { if l . matchTerm ( index , logTerm ) { lastnewi = index + uint64 ( len ( ents ) ) ci := l . findConflict ( ents ) switch { case ci == 0 : case ci <= l . committed : l . logger . Panicf ( " " , ci , l . committed ) default : offset := index + 1 l . append ( ents [ ci - offset : ] ... ) } l . commitTo ( min ( committed , lastnewi ) ) return lastnewi , true } return 0 , false } 
func ( l * raftLog ) findConflict ( ents [ ] pb . Entry ) uint64 { for _ , ne := range ents { if ! l . matchTerm ( ne . Index , ne . Term ) { if ne . Index <= l . lastIndex ( ) { l . logger . Infof ( " " , ne . Index , l . zeroTermOnErrCompacted ( l . term ( ne . Index ) ) , ne . Term ) } return ne . Index } } return 0 } 
func ( l * raftLog ) nextEnts ( ) ( ents [ ] pb . Entry ) { off := max ( l . applied + 1 , l . firstIndex ( ) ) if l . committed + 1 > off { ents , err := l . slice ( off , l . committed + 1 , l . maxNextEntsSize ) if err != nil { l . logger . Panicf ( " " , err ) } return ents } return nil } 
func ( l * raftLog ) hasNextEnts ( ) bool { off := max ( l . applied + 1 , l . firstIndex ( ) ) return l . committed + 1 > off } 
func ( l * raftLog ) allEntries ( ) [ ] pb . Entry { ents , err := l . entries ( l . firstIndex ( ) , noLimit ) if err == nil { return ents } if err == ErrCompacted { } } 
func ( l * raftLog ) isUpToDate ( lasti , term uint64 ) bool { return term > l . lastTerm ( ) || ( term == l . lastTerm ( ) && lasti >= l . lastIndex ( ) ) } 
func ( l * raftLog ) slice ( lo , hi , maxSize uint64 ) ( [ ] pb . Entry , error ) { err := l . mustCheckOutOfBounds ( lo , hi ) if err != nil { return nil , err } if lo == hi { return nil , nil } var ents [ ] pb . Entry if lo < l . unstable . offset { storedEnts , err := l . storage . Entries ( lo , min ( hi , l . unstable . offset ) , maxSize ) if err == ErrCompacted { return nil , err } else if err == ErrUnavailable { l . logger . Panicf ( " " , lo , min ( hi , l . unstable . offset ) ) } else if err != nil { panic ( err ) } } ents = storedEnts } if hi > l . unstable . offset { unstable := l . unstable . slice ( max ( lo , l . unstable . offset ) , hi ) if len ( ents ) > 0 { combined := make ( [ ] pb . Entry , len ( ents ) + len ( unstable ) ) n := copy ( combined , ents ) copy ( combined [ n : ] , unstable ) ents = combined } else { ents = unstable } } return limitSize ( ents , maxSize ) , nil } 
func ( l * raftLog ) mustCheckOutOfBounds ( lo , hi uint64 ) error { if lo > hi { l . logger . Panicf ( " " , lo , hi ) } fi := l . firstIndex ( ) if lo < fi { return ErrCompacted } length := l . lastIndex ( ) + 1 - fi if lo < fi || hi > fi + length { l . logger . Panicf ( " " , lo , hi , fi , l . lastIndex ( ) ) } return nil } 
func NewSession ( client * v3 . Client , opts ... SessionOption ) ( * Session , error ) { ops := & sessionOptions { ttl : defaultSessionTTL , ctx : client . Ctx ( ) } for _ , opt := range opts { opt ( ops ) } id := ops . leaseID if id == v3 . NoLease { resp , err := client . Grant ( ops . ctx , int64 ( ops . ttl ) ) if err != nil { return nil , err } id = v3 . LeaseID ( resp . ID ) } ctx , cancel := context . WithCancel ( ops . ctx ) keepAlive , err := client . KeepAlive ( ctx , id ) if err != nil || keepAlive == nil { cancel ( ) return nil , err } donec := make ( chan struct { } ) s := & Session { client : client , opts : ops , id : id , cancel : cancel , donec : donec } for range keepAlive { } ( ) return s , nil } 
func ( s * Session ) Close ( ) error { s . Orphan ( ) _ , err := s . client . Revoke ( ctx , s . id ) cancel ( ) return err } 
func WithTTL ( ttl int ) SessionOption { return func ( so * sessionOptions ) { if ttl > 0 { so . ttl = ttl } } } 
func WithLease ( leaseID v3 . LeaseID ) SessionOption { return func ( so * sessionOptions ) { so . leaseID = leaseID } } 
func WithContext ( ctx context . Context ) SessionOption { return func ( so * sessionOptions ) { so . ctx = ctx } } 
func ( ro * readOnly ) addRequest ( index uint64 , m pb . Message ) { ctx := string ( m . Entries [ 0 ] . Data ) if _ , ok := ro . pendingReadIndex [ ctx ] ; ok { return } ro . pendingReadIndex [ ctx ] = & readIndexStatus { index : index , req : m , acks : make ( map [ uint64 ] struct { } ) } ro . readIndexQueue = append ( ro . readIndexQueue , ctx ) } 
func ( ro * readOnly ) recvAck ( m pb . Message ) int { rs , ok := ro . pendingReadIndex [ string ( m . Context ) ] if ! ok { return 0 } rs . acks [ m . From ] = struct { } { } } 
func ( ro * readOnly ) advance ( m pb . Message ) [ ] * readIndexStatus { var ( i int found bool ) ctx := string ( m . Context ) rss := [ ] * readIndexStatus { } for _ , okctx := range ro . readIndexQueue { i ++ rs , ok := ro . pendingReadIndex [ okctx ] if ! ok { panic ( " " ) } rss = append ( rss , rs ) if okctx == ctx { found = true break } } if found { ro . readIndexQueue = ro . readIndexQueue [ i : ] for _ , rs := range rss { delete ( ro . pendingReadIndex , string ( rs . req . Entries [ 0 ] . Data ) ) } return rss } return nil } 
func ( ro * readOnly ) lastPendingRequestCtx ( ) string { if len ( ro . readIndexQueue ) == 0 { return " " } return ro . readIndexQueue [ len ( ro . readIndexQueue ) - 1 ] } 
func NewServer ( cfg ServerConfig ) ( srv * EtcdServer , err error ) { st := v2store . New ( StoreClusterPrefix , StoreKeysPrefix ) var ( w * wal . WAL n raft . Node s * raft . MemoryStorage id types . ID cl * membership . RaftCluster ) if cfg . MaxRequestBytes > recommendedMaxRequestBytes { if cfg . Logger != nil { cfg . Logger . Warn ( " " , zap . Uint ( " " , cfg . MaxRequestBytes ) , zap . String ( " " , humanize . Bytes ( uint64 ( cfg . MaxRequestBytes ) ) ) , zap . Int ( " " , recommendedMaxRequestBytes ) , zap . String ( " " , humanize . Bytes ( uint64 ( recommendedMaxRequestBytes ) ) ) , ) } else { plog . Warningf ( " " , cfg . MaxRequestBytes , recommendedMaxRequestBytes ) } } if terr := fileutil . TouchDirAll ( cfg . DataDir ) ; terr != nil { return nil , fmt . Errorf ( " " , terr ) } haveWAL := wal . Exist ( cfg . WALDir ( ) ) if err = fileutil . TouchDirAll ( cfg . SnapDir ( ) ) ; err != nil { if cfg . Logger != nil { cfg . Logger . Fatal ( " " , zap . String ( " " , cfg . SnapDir ( ) ) , zap . Error ( err ) , ) } else { plog . Fatalf ( " " , err ) } } ss := snap . New ( cfg . Logger , cfg . SnapDir ( ) ) bepath := cfg . backendPath ( ) beExist := fileutil . Exist ( bepath ) be := openBackend ( cfg ) defer func ( ) { if err != nil { be . Close ( ) } } ( ) prt , err := rafthttp . NewRoundTripper ( cfg . PeerTLSInfo , cfg . peerDialTimeout ( ) ) if err != nil { return nil , err } var ( remotes [ ] * membership . Member snapshot * raftpb . Snapshot ) switch { case ! haveWAL && ! cfg . NewCluster : if err = cfg . VerifyJoinExisting ( ) ; err != nil { return nil , err } cl , err = membership . NewClusterFromURLsMap ( cfg . Logger , cfg . InitialClusterToken , cfg . InitialPeerURLsMap ) if err != nil { return nil , err } existingCluster , gerr := GetClusterFromRemotePeers ( cfg . Logger , getRemotePeerURLs ( cl , cfg . Name ) , prt ) if gerr != nil { return nil , fmt . Errorf ( " " , gerr ) } if err = membership . ValidateClusterAndAssignIDs ( cfg . Logger , cl , existingCluster ) ; err != nil { return nil , fmt . Errorf ( " " , existingCluster , err ) } if ! isCompatibleWithCluster ( cfg . Logger , cl , cl . MemberByName ( cfg . Name ) . ID , prt ) { return nil , fmt . Errorf ( " " ) } remotes = existingCluster . Members ( ) cl . SetID ( types . ID ( 0 ) , existingCluster . ID ( ) ) cl . SetStore ( st ) cl . SetBackend ( be ) id , n , s , w = startNode ( cfg , cl , nil ) cl . SetID ( id , existingCluster . ID ( ) ) case ! haveWAL && cfg . NewCluster : if err = cfg . VerifyBootstrap ( ) ; err != nil { return nil , err } cl , err = membership . NewClusterFromURLsMap ( cfg . Logger , cfg . InitialClusterToken , cfg . InitialPeerURLsMap ) if err != nil { return nil , err } m := cl . MemberByName ( cfg . Name ) if isMemberBootstrapped ( cfg . Logger , cl , cfg . Name , prt , cfg . bootstrapTimeout ( ) ) { return nil , fmt . Errorf ( " " , m . ID ) } if cfg . ShouldDiscover ( ) { var str string str , err = v2discovery . JoinCluster ( cfg . Logger , cfg . DiscoveryURL , cfg . DiscoveryProxy , m . ID , cfg . InitialPeerURLsMap . String ( ) ) if err != nil { return nil , & DiscoveryError { Op : " " , Err : err } } var urlsmap types . URLsMap urlsmap , err = types . NewURLsMap ( str ) if err != nil { return nil , err } if checkDuplicateURL ( urlsmap ) { return nil , fmt . Errorf ( " " , urlsmap ) } if cl , err = membership . NewClusterFromURLsMap ( cfg . Logger , cfg . InitialClusterToken , urlsmap ) ; err != nil { return nil , err } } cl . SetStore ( st ) cl . SetBackend ( be ) id , n , s , w = startNode ( cfg , cl , cl . MemberIDs ( ) ) cl . SetID ( id , cl . ID ( ) ) case haveWAL : if err = fileutil . IsDirWriteable ( cfg . MemberDir ( ) ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } if err = fileutil . IsDirWriteable ( cfg . WALDir ( ) ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } if cfg . ShouldDiscover ( ) { if cfg . Logger != nil { cfg . Logger . Warn ( " " , zap . String ( " " , cfg . WALDir ( ) ) , ) } else { plog . Warningf ( " " , cfg . WALDir ( ) ) } } snapshot , err = ss . Load ( ) if err != nil && err != snap . ErrNoSnapshot { return nil , err } if snapshot != nil { if err = st . Recovery ( snapshot . Data ) ; err != nil { if cfg . Logger != nil { cfg . Logger . Panic ( " " ) } else { plog . Panicf ( " " , err ) } } if cfg . Logger != nil { cfg . Logger . Info ( " " , zap . Uint64 ( " " , snapshot . Metadata . Index ) , zap . String ( " " , humanize . Bytes ( uint64 ( snapshot . Size ( ) ) ) ) , ) } else { plog . Infof ( " " , snapshot . Metadata . Index ) } if be , err = recoverSnapshotBackend ( cfg , be , * snapshot ) ; err != nil { if cfg . Logger != nil { cfg . Logger . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } if cfg . Logger != nil { s1 , s2 := be . Size ( ) , be . SizeInUse ( ) cfg . Logger . Info ( " " , zap . Int64 ( " " , s1 ) , zap . String ( " " , humanize . Bytes ( uint64 ( s1 ) ) ) , zap . Int64 ( " " , s2 ) , zap . String ( " " , humanize . Bytes ( uint64 ( s2 ) ) ) , ) } } if ! cfg . ForceNewCluster { id , cl , n , s , w = restartNode ( cfg , snapshot ) } else { id , cl , n , s , w = restartAsStandaloneNode ( cfg , snapshot ) } cl . SetStore ( st ) cl . SetBackend ( be ) cl . Recover ( api . UpdateCapability ) if cl . Version ( ) != nil && ! cl . Version ( ) . LessThan ( semver . Version { Major : 3 } ) && ! beExist { os . RemoveAll ( bepath ) return nil , fmt . Errorf ( " " , bepath ) } default : return nil , fmt . Errorf ( " " ) } if terr := fileutil . TouchDirAll ( cfg . MemberDir ( ) ) ; terr != nil { return nil , fmt . Errorf ( " " , terr ) } sstats := stats . NewServerStats ( cfg . Name , id . String ( ) ) lstats := stats . NewLeaderStats ( id . String ( ) ) heartbeat := time . Duration ( cfg . TickMs ) * time . Millisecond srv = & EtcdServer { readych : make ( chan struct { } ) , Cfg : cfg , lgMu : new ( sync . RWMutex ) , lg : cfg . Logger , errorc : make ( chan error , 1 ) , v2store : st , snapshotter : ss , r : * newRaftNode ( raftNodeConfig { lg : cfg . Logger , isIDRemoved : func ( id uint64 ) bool { return cl . IsIDRemoved ( types . ID ( id ) ) } , Node : n , heartbeat : heartbeat , raftStorage : s , storage : NewStorage ( w , ss ) , } , ) , id : id , attributes : membership . Attributes { Name : cfg . Name , ClientURLs : cfg . ClientURLs . StringSlice ( ) } , cluster : cl , stats : sstats , lstats : lstats , SyncTicker : time . NewTicker ( 500 * time . Millisecond ) , peerRt : prt , reqIDGen : idutil . NewGenerator ( uint16 ( id ) , time . Now ( ) ) , forceVersionC : make ( chan struct { } ) , AccessController : & AccessController { CORS : cfg . CORS , HostWhitelist : cfg . HostWhitelist } , } serverID . With ( prometheus . Labels { " " : id . String ( ) } ) . Set ( 1 ) srv . applyV2 = & applierV2store { store : srv . v2store , cluster : srv . cluster } srv . be = be minTTL := time . Duration ( ( 3 * cfg . ElectionTicks ) / 2 ) * heartbeat srv . kv = mvcc . New ( srv . getLogger ( ) , srv . be , srv . lessor , & srv . consistIndex ) if beExist { kvindex := srv . kv . ConsistentIndex ( ) } if cfg . Logger != nil { cfg . Logger . Warn ( " " , zap . Uint64 ( " " , snapshot . Metadata . Index ) , ) } else { plog . Warningf ( " " , snapshot . Metadata . Index ) } } } newSrv := srv defer func ( ) { } } ( ) srv . consistIndex . setConsistentIndex ( srv . kv . ConsistentIndex ( ) ) tp , err := auth . NewTokenProvider ( cfg . Logger , cfg . AuthToken , func ( index uint64 ) <- chan struct { } { return srv . applyWait . Wait ( index ) } , ) if err != nil { if cfg . Logger != nil { cfg . Logger . Warn ( " " , zap . Error ( err ) ) } else { plog . Errorf ( " " , err ) } return nil , err } srv . authStore = auth . NewAuthStore ( srv . getLogger ( ) , srv . be , tp , int ( cfg . BcryptCost ) ) if num := cfg . AutoCompactionRetention ; num != 0 { srv . compactor , err = v3compactor . New ( cfg . Logger , cfg . AutoCompactionMode , num , srv . kv , srv ) if err != nil { return nil , err } srv . compactor . Run ( ) } srv . applyV3Base = srv . newApplierV3Backend ( ) if err = srv . restoreAlarms ( ) ; err != nil { return nil , err } srv . lessor . SetCheckpointer ( func ( ctx context . Context , cp * pb . LeaseCheckpointRequest ) { srv . raftRequestOnce ( ctx , pb . InternalRaftRequest { LeaseCheckpoint : cp } ) } ) if err = tr . Start ( ) ; err != nil { return nil , err } } } for _ , m := range cl . Members ( ) { if m . ID != id { tr . AddPeer ( m . ID , m . PeerURLs ) } } srv . r . transport = tr return srv , nil } 
func ( s * EtcdServer ) Start ( ) { s . start ( ) s . goAttach ( func ( ) { s . adjustTicks ( ) } ) s . goAttach ( func ( ) { s . publish ( s . Cfg . ReqTimeout ( ) ) } ) s . goAttach ( s . purgeFile ) s . goAttach ( func ( ) { monitorFileDescriptor ( s . getLogger ( ) , s . stopping ) } ) s . goAttach ( s . monitorVersions ) s . goAttach ( s . linearizableReadLoop ) s . goAttach ( s . monitorKVHash ) } 
func ( s * EtcdServer ) start ( ) { lg := s . getLogger ( ) if s . Cfg . SnapshotCount == 0 { if lg != nil { lg . Info ( " " , zap . Uint64 ( " " , s . Cfg . SnapshotCount ) , zap . Uint64 ( " " , DefaultSnapshotCount ) , ) } else { plog . Infof ( " " , DefaultSnapshotCount ) } s . Cfg . SnapshotCount = DefaultSnapshotCount } if s . Cfg . SnapshotCatchUpEntries == 0 { if lg != nil { lg . Info ( " " , zap . Uint64 ( " " , s . Cfg . SnapshotCatchUpEntries ) , zap . Uint64 ( " " , DefaultSnapshotCatchUpEntries ) , ) } s . Cfg . SnapshotCatchUpEntries = DefaultSnapshotCatchUpEntries } s . w = wait . New ( ) s . applyWait = wait . NewTimeList ( ) s . done = make ( chan struct { } ) s . stop = make ( chan struct { } ) s . stopping = make ( chan struct { } ) s . ctx , s . cancel = context . WithCancel ( context . Background ( ) ) s . readwaitc = make ( chan struct { } , 1 ) s . readNotifier = newNotifier ( ) s . leaderChanged = make ( chan struct { } ) if s . ClusterVersion ( ) != nil { if lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , version . Version ) , zap . String ( " " , s . Cluster ( ) . ID ( ) . String ( ) ) , zap . String ( " " , version . Cluster ( s . ClusterVersion ( ) . String ( ) ) ) , ) } else { plog . Infof ( " " , version . Version , version . Cluster ( s . ClusterVersion ( ) . String ( ) ) ) } membership . ClusterVersionMetrics . With ( prometheus . Labels { " " : s . ClusterVersion ( ) . String ( ) } ) . Set ( 1 ) } else { if lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , version . Version ) , zap . String ( " " , " " ) , ) } else { plog . Infof ( " " , version . Version ) } } } 
func ( s * EtcdServer ) Process ( ctx context . Context , m raftpb . Message ) error { if s . cluster . IsIDRemoved ( types . ID ( m . From ) ) { if lg := s . getLogger ( ) ; lg != nil { lg . Warn ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , types . ID ( m . From ) . String ( ) ) , ) } else { plog . Warningf ( " " , types . ID ( m . From ) . String ( ) ) } return httptypes . NewHTTPError ( http . StatusForbidden , " " ) } if m . Type == raftpb . MsgApp { s . stats . RecvAppendReq ( types . ID ( m . From ) . String ( ) , m . Size ( ) ) } return s . r . Step ( ctx , m ) } 
func ( s * EtcdServer ) ReportSnapshot ( id uint64 , status raft . SnapshotStatus ) { s . r . ReportSnapshot ( id , status ) } 
func ( s * EtcdServer ) MoveLeader ( ctx context . Context , lead , transferee uint64 ) error { now := time . Now ( ) interval := time . Duration ( s . Cfg . TickMs ) * time . Millisecond if lg := s . getLogger ( ) ; lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , types . ID ( lead ) . String ( ) ) , zap . String ( " " , types . ID ( transferee ) . String ( ) ) , ) } else { plog . Infof ( " " , s . ID ( ) , types . ID ( lead ) , types . ID ( transferee ) ) } s . r . TransferLeadership ( ctx , lead , transferee ) for s . Lead ( ) != transferee { select { case <- ctx . Done ( ) : case <- time . After ( interval ) : } } } else { plog . Infof ( " " , s . ID ( ) , types . ID ( lead ) , types . ID ( transferee ) , time . Since ( now ) ) } return nil } 
func ( s * EtcdServer ) TransferLeadership ( ) error { if ! s . isLeader ( ) { if lg := s . getLogger ( ) ; lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , types . ID ( s . Lead ( ) ) . String ( ) ) , ) } else { plog . Printf ( " " ) } return nil } if ! s . isMultiNode ( ) { if lg := s . getLogger ( ) ; lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , types . ID ( s . Lead ( ) ) . String ( ) ) , ) } else { plog . Printf ( " " ) } return nil } transferee , ok := longestConnected ( s . r . transport , s . cluster . MemberIDs ( ) ) if ! ok { return ErrUnhealthy } tm := s . Cfg . ReqTimeout ( ) ctx , cancel := context . WithTimeout ( s . ctx , tm ) err := s . MoveLeader ( ctx , s . Lead ( ) , uint64 ( transferee ) ) cancel ( ) return err } 
func ( s * EtcdServer ) Stop ( ) { if err := s . TransferLeadership ( ) ; err != nil { if lg := s . getLogger ( ) ; lg != nil { lg . Warn ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . Error ( err ) ) } else { plog . Warningf ( " " , s . ID ( ) , err ) } } s . HardStop ( ) } 
func ( s * EtcdServer ) configure ( ctx context . Context , cc raftpb . ConfChange ) ( [ ] * membership . Member , error ) { cc . ID = s . reqIDGen . Next ( ) ch := s . w . Register ( cc . ID ) start := time . Now ( ) if err := s . r . ProposeConfChange ( ctx , cc ) ; err != nil { s . w . Trigger ( cc . ID , nil ) return nil , err } select { case x := <- ch : if x == nil { if lg := s . getLogger ( ) ; lg != nil { lg . Panic ( " " ) } else { plog . Panicf ( " " ) } } resp := x . ( * confChangeResponse ) if lg := s . getLogger ( ) ; lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , cc . Type . String ( ) ) , zap . String ( " " , types . ID ( cc . NodeID ) . String ( ) ) , ) } return resp . membs , resp . err case <- ctx . Done ( ) : s . w . Trigger ( cc . ID , nil ) return nil , s . parseProposeCtxErr ( ctx . Err ( ) , start ) case <- s . stopping : return nil , ErrStopped } } 
func ( s * EtcdServer ) sync ( timeout time . Duration ) { req := pb . Request { Method : " " , ID : s . reqIDGen . Next ( ) , Time : time . Now ( ) . UnixNano ( ) , } data := pbutil . MustMarshal ( & req ) s . goAttach ( func ( ) { s . r . Propose ( ctx , data ) cancel ( ) } ) } 
func ( s * EtcdServer ) publish ( timeout time . Duration ) { b , err := json . Marshal ( s . attributes ) if err != nil { if lg := s . getLogger ( ) ; lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } return } req := pb . Request { Method : " " , Path : membership . MemberAttributesStorePath ( s . id ) , Val : string ( b ) , } for { ctx , cancel := context . WithTimeout ( s . ctx , timeout ) _ , err := s . Do ( ctx , req ) cancel ( ) switch err { case nil : close ( s . readych ) if lg := s . getLogger ( ) ; lg != nil { lg . Info ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , fmt . Sprintf ( " " , s . attributes ) ) , zap . String ( " " , req . Path ) , zap . String ( " " , s . cluster . ID ( ) . String ( ) ) , zap . Duration ( " " , timeout ) , ) } else { plog . Infof ( " " , s . attributes , s . cluster . ID ( ) ) } return case ErrStopped : if lg := s . getLogger ( ) ; lg != nil { lg . Warn ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , fmt . Sprintf ( " " , s . attributes ) ) , zap . Duration ( " " , timeout ) , zap . Error ( err ) , ) } else { plog . Infof ( " " ) } return default : if lg := s . getLogger ( ) ; lg != nil { lg . Warn ( " " , zap . String ( " " , s . ID ( ) . String ( ) ) , zap . String ( " " , fmt . Sprintf ( " " , s . attributes ) ) , zap . String ( " " , req . Path ) , zap . Duration ( " " , timeout ) , zap . Error ( err ) , ) } else { plog . Errorf ( " " , err ) } } } } 
func ( s * EtcdServer ) apply ( es [ ] raftpb . Entry , confState * raftpb . ConfState , ) ( appliedt uint64 , appliedi uint64 , shouldStop bool ) { for i := range es { e := es [ i ] switch e . Type { case raftpb . EntryNormal : s . applyEntryNormal ( & e ) s . setAppliedIndex ( e . Index ) s . setTerm ( e . Term ) case raftpb . EntryConfChange : } var cc raftpb . ConfChange pbutil . MustUnmarshal ( & cc , e . Data ) removedSelf , err := s . applyConfChange ( cc , confState ) s . setAppliedIndex ( e . Index ) s . setTerm ( e . Term ) shouldStop = shouldStop || removedSelf s . w . Trigger ( cc . ID , & confChangeResponse { s . cluster . Members ( ) , err } ) default : if lg := s . getLogger ( ) ; lg != nil { lg . Panic ( " " , zap . String ( " " , e . Type . String ( ) ) , ) } else { plog . Panicf ( " " ) } } appliedi , appliedt = e . Index , e . Term } return appliedt , appliedi , shouldStop } 
func ( s * EtcdServer ) applyEntryNormal ( e * raftpb . Entry ) { shouldApplyV3 := false if e . Index > s . consistIndex . ConsistentIndex ( ) { shouldApplyV3 = true } } return } var raftReq pb . InternalRaftRequest if ! pbutil . MaybeUnmarshal ( & raftReq , e . Data ) { rp := & r pbutil . MustUnmarshal ( rp , e . Data ) s . w . Trigger ( r . ID , s . applyV2Request ( ( * RequestV2 ) ( rp ) ) ) return } if raftReq . V2 != nil { req := ( * RequestV2 ) ( raftReq . V2 ) s . w . Trigger ( req . ID , s . applyV2Request ( req ) ) return } } id := raftReq . ID if id == 0 { id = raftReq . Header . ID } var ar * applyResult needResult := s . w . IsRegistered ( id ) if needResult || ! noSideEffect ( & raftReq ) { if ! needResult && raftReq . Txn != nil { removeNeedlessRangeReqs ( raftReq . Txn ) } ar = s . applyV3 . Apply ( & raftReq ) } if ar == nil { return } if ar . err != ErrNoSpace || len ( s . alarmStore . Get ( pb . AlarmType_NOSPACE ) ) > 0 { s . w . Trigger ( id , ar ) return } if lg := s . getLogger ( ) ; lg != nil { lg . Warn ( " " , zap . Int64 ( " " , s . Cfg . QuotaBackendBytes ) , zap . String ( " " , humanize . Bytes ( uint64 ( s . Cfg . QuotaBackendBytes ) ) ) , zap . Error ( ar . err ) , ) } else { plog . Errorf ( " " ) } s . goAttach ( func ( ) { a := & pb . AlarmRequest { MemberID : uint64 ( s . ID ( ) ) , Action : pb . AlarmRequest_ACTIVATE , Alarm : pb . AlarmType_NOSPACE , } s . raftRequest ( s . ctx , pb . InternalRaftRequest { Alarm : a } ) s . w . Trigger ( id , ar ) } ) } 
func ( s * EtcdServer ) applyConfChange ( cc raftpb . ConfChange , confState * raftpb . ConfState ) ( bool , error ) { if err := s . cluster . ValidateConfigurationChange ( cc ) ; err != nil { cc . NodeID = raft . None s . r . ApplyConfChange ( cc ) return false , err } lg := s . getLogger ( ) * confState = * s . r . ApplyConfChange ( cc ) switch cc . Type { case raftpb . ConfChangeAddNode : m := new ( membership . Member ) if err := json . Unmarshal ( cc . Context , m ) ; err != nil { if lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } if cc . NodeID != uint64 ( m . ID ) { if lg != nil { lg . Panic ( " " , zap . String ( " " , types . ID ( cc . NodeID ) . String ( ) ) , zap . String ( " " , m . ID . String ( ) ) , ) } else { plog . Panicf ( " " ) } } s . cluster . AddMember ( m ) if m . ID != s . id { s . r . transport . AddPeer ( m . ID , m . PeerURLs ) } case raftpb . ConfChangeRemoveNode : id := types . ID ( cc . NodeID ) s . cluster . RemoveMember ( id ) if id == s . id { return true , nil } s . r . transport . RemovePeer ( id ) case raftpb . ConfChangeUpdateNode : m := new ( membership . Member ) if err := json . Unmarshal ( cc . Context , m ) ; err != nil { if lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } if cc . NodeID != uint64 ( m . ID ) { if lg != nil { lg . Panic ( " " , zap . String ( " " , types . ID ( cc . NodeID ) . String ( ) ) , zap . String ( " " , m . ID . String ( ) ) , ) } else { plog . Panicf ( " " ) } } s . cluster . UpdateRaftAttributes ( m . ID , m . RaftAttributes ) if m . ID != s . id { s . r . transport . UpdatePeer ( m . ID , m . PeerURLs ) } } return false , nil } 
func ( s * EtcdServer ) snapshot ( snapi uint64 , confState raftpb . ConfState ) { clone := s . v2store . Clone ( ) s . goAttach ( func ( ) { lg := s . getLogger ( ) d , err := clone . SaveNoCopy ( ) } else { plog . Panicf ( " " , err ) } } snap , err := s . r . raftStorage . CreateSnapshot ( snapi , & confState , d ) if err != nil { } if lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } } else { plog . Fatalf ( " " , err ) } } if lg != nil { lg . Info ( " " , zap . Uint64 ( " " , snap . Metadata . Index ) , ) } else { plog . Infof ( " " , snap . Metadata . Index ) } } else { plog . Infof ( " " ) } return } if snapi > s . Cfg . SnapshotCatchUpEntries { compacti = snapi - s . Cfg . SnapshotCatchUpEntries } err = s . r . raftStorage . Compact ( compacti ) if err != nil { } if lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } if lg != nil { lg . Info ( " " , zap . Uint64 ( " " , compacti ) , ) } else { plog . Infof ( " " , compacti ) } } ) } 
func ( s * EtcdServer ) CutPeer ( id types . ID ) { tr , ok := s . r . transport . ( * rafthttp . Transport ) if ok { tr . CutPeer ( id ) } } 
func ( s * EtcdServer ) monitorVersions ( ) { for { select { case <- s . forceVersionC : case <- time . After ( monitorVersionInterval ) : case <- s . stopping : return } if s . Leader ( ) != s . ID ( ) { continue } v := decideClusterVersion ( s . getLogger ( ) , getVersions ( s . getLogger ( ) , s . cluster , s . id , s . peerRt ) ) if v != nil { } if v != nil { verStr = v . String ( ) } s . goAttach ( func ( ) { s . updateClusterVersion ( verStr ) } ) continue } } } } 
func ( s * EtcdServer ) goAttach ( f func ( ) ) { s . wgMu . RLock ( ) defer s . wgMu . RUnlock ( ) select { case <- s . stopping : if lg := s . getLogger ( ) ; lg != nil { lg . Warn ( " " ) } else { plog . Warning ( " " ) } return default : } go func ( ) { defer s . wg . Done ( ) f ( ) } ( ) } 
func NewRoundrobinBalanced ( lg * zap . Logger , scs [ ] balancer . SubConn , addrToSc map [ resolver . Address ] balancer . SubConn , scToAddr map [ balancer . SubConn ] resolver . Address , ) Picker { return & rrBalanced { lg : lg , scs : scs , addrToSc : addrToSc , scToAddr : scToAddr , } } 
func ( rb * rrBalanced ) Pick ( ctx context . Context , opts balancer . PickOptions ) ( balancer . SubConn , func ( balancer . DoneInfo ) , error ) { rb . mu . RLock ( ) n := len ( rb . scs ) rb . mu . RUnlock ( ) if n == 0 { return nil , nil , balancer . ErrNoSubConnAvailable } rb . mu . Lock ( ) cur := rb . next sc := rb . scs [ cur ] picked := rb . scToAddr [ sc ] . Addr rb . next = ( rb . next + 1 ) % len ( rb . scs ) rb . mu . Unlock ( ) rb . lg . Debug ( " " , zap . String ( " " , picked ) , zap . Int ( " " , cur ) , zap . Int ( " " , n ) , ) doneFunc := func ( info balancer . DoneInfo ) { if info . Err == nil { rb . lg . Debug ( " " , fss ... ) } else { rb . lg . Warn ( " " , fss ... ) } } return sc , doneFunc , nil } 
func NewTLSListener ( l net . Listener , tlsinfo * TLSInfo ) ( net . Listener , error ) { check := func ( context . Context , * tls . Conn ) error { return nil } return newTLSListener ( l , tlsinfo , check ) } 
func ( l * tlsListener ) acceptLoop ( ) { var wg sync . WaitGroup var pendingMu sync . Mutex pending := make ( map [ net . Conn ] struct { } ) ctx , cancel := context . WithCancel ( context . Background ( ) ) defer func ( ) { cancel ( ) pendingMu . Lock ( ) for c := range pending { c . Close ( ) } pendingMu . Unlock ( ) wg . Wait ( ) close ( l . donec ) } ( ) for { conn , err := l . Listener . Accept ( ) if err != nil { l . err = err return } pendingMu . Lock ( ) pending [ conn ] = struct { } { } pendingMu . Unlock ( ) wg . Add ( 1 ) go func ( ) { defer func ( ) { if conn != nil { conn . Close ( ) } wg . Done ( ) } ( ) tlsConn := conn . ( * tls . Conn ) herr := tlsConn . Handshake ( ) pendingMu . Lock ( ) delete ( pending , conn ) pendingMu . Unlock ( ) if herr != nil { l . handshakeFailure ( tlsConn , herr ) return } if err := l . check ( ctx , tlsConn ) ; err != nil { l . handshakeFailure ( tlsConn , err ) return } select { case l . connc <- tlsConn : conn = nil case <- ctx . Done ( ) : } } ( ) } } 
func ( e * ResolverGroup ) SetEndpoints ( endpoints [ ] string ) { addrs := epsToAddrs ( endpoints ... ) e . mu . Lock ( ) e . endpoints = endpoints for _ , r := range e . resolvers { r . cc . NewAddress ( addrs ) } e . mu . Unlock ( ) } 
func ( e * ResolverGroup ) Target ( endpoint string ) string { return Target ( e . id , endpoint ) } 
func Target ( id , endpoint string ) string { return fmt . Sprintf ( " " , scheme , id , endpoint ) } 
func ( b * builder ) Build ( target resolver . Target , cc resolver . ClientConn , opts resolver . BuildOption ) ( resolver . Resolver , error ) { if len ( target . Authority ) < 1 { return nil , fmt . Errorf ( " " ) } id := target . Authority es , err := b . getResolverGroup ( id ) if err != nil { return nil , fmt . Errorf ( " " , err ) } r := & Resolver { endpointID : id , cc : cc , } es . addResolver ( r ) return r , nil } 
func epsToAddrs ( eps ... string ) ( addrs [ ] resolver . Address ) { addrs = make ( [ ] resolver . Address , 0 , len ( eps ) ) for _ , ep := range eps { addrs = append ( addrs , resolver . Address { Addr : ep } ) } return addrs } 
func ParseEndpoint ( endpoint string ) ( proto string , host string , scheme string ) { proto = " " host = endpoint url , uerr := url . Parse ( endpoint ) if uerr != nil || ! strings . Contains ( endpoint , " " ) { return proto , host , scheme } scheme = url . Scheme switch url . Scheme { case " " , " " : case " " , " " : proto = " " host = url . Host + url . Path default : proto , host = " " , " " } return proto , host , scheme } 
func ParseTarget ( target string ) ( string , string , error ) { noPrefix := strings . TrimPrefix ( target , targetPrefix ) if noPrefix == target { return " " , " " , fmt . Errorf ( " " , targetPrefix , target ) } parts := strings . SplitN ( noPrefix , " " , 2 ) if len ( parts ) != 2 { return " " , " " , fmt . Errorf ( " " , scheme , target ) } return parts [ 0 ] , parts [ 1 ] , nil } 
func ParseHostPort ( hostPort string ) ( host string , port string ) { parts := strings . SplitN ( hostPort , " " , 2 ) host = parts [ 0 ] if len ( parts ) > 1 { port = parts [ 1 ] } return host , port } 
func ( r * RequestV2 ) Handle ( ctx context . Context , v2api RequestV2Handler ) ( Response , error ) { if r . Method == " " && r . Quorum { r . Method = " " } switch r . Method { case " " : return v2api . Post ( ctx , r ) case " " : return v2api . Put ( ctx , r ) case " " : return v2api . Delete ( ctx , r ) case " " : return v2api . QGet ( ctx , r ) case " " : return v2api . Get ( ctx , r ) case " " : return v2api . Head ( ctx , r ) } return Response { } , ErrUnknownMethod } 
func NewElectionCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : runElectionFunc , } cmd . Flags ( ) . IntVar ( & totalClientConnections , " " , 10 , " " ) return cmd } 
func nodeToMember ( n * v2store . NodeExtern ) ( * Member , error ) { m := & Member { ID : MustParseMemberIDFromKey ( n . Key ) } attrs := make ( map [ string ] [ ] byte ) raftAttrKey := path . Join ( n . Key , raftAttributesSuffix ) attrKey := path . Join ( n . Key , attributesSuffix ) for _ , nn := range n . Nodes { if nn . Key != raftAttrKey && nn . Key != attrKey { return nil , fmt . Errorf ( " " , nn . Key ) } attrs [ nn . Key ] = [ ] byte ( * nn . Value ) } if data := attrs [ raftAttrKey ] ; data != nil { if err := json . Unmarshal ( data , & m . RaftAttributes ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } } else { return nil , fmt . Errorf ( " " ) } if data := attrs [ attrKey ] ; data != nil { if err := json . Unmarshal ( data , & m . Attributes ) ; err != nil { return m , fmt . Errorf ( " " , err ) } } return m , nil } 
func NewTmpBackend ( batchInterval time . Duration , batchLimit int ) ( * backend , string ) { dir , err := ioutil . TempDir ( os . TempDir ( ) , " " ) if err != nil { panic ( err ) } tmpPath := filepath . Join ( dir , " " ) bcfg := DefaultBackendConfig ( ) bcfg . Path , bcfg . BatchInterval , bcfg . BatchLimit = tmpPath , batchInterval , batchLimit return newBackend ( bcfg ) , tmpPath } 
func newRevision ( lg * zap . Logger , clock clockwork . Clock , retention int64 , rg RevGetter , c Compactable ) * Revision { rc := & Revision { lg : lg , clock : clock , retention : retention , rg : rg , c : c , } rc . ctx , rc . cancel = context . WithCancel ( context . Background ( ) ) return rc } 
func ( rc * Revision ) Run ( ) { prev := int64 ( 0 ) go func ( ) { for { select { case <- rc . ctx . Done ( ) : return case <- rc . clock . After ( revInterval ) : rc . mu . Lock ( ) p := rc . paused rc . mu . Unlock ( ) if p { continue } } rev := rc . rg . Rev ( ) - rc . retention if rev <= 0 || rev == prev { continue } now := time . Now ( ) if rc . lg != nil { rc . lg . Info ( " " , zap . Int64 ( " " , rev ) , zap . Int64 ( " " , rc . retention ) , ) } else { plog . Noticef ( " " , rev , rc . retention ) } _ , err := rc . c . Compact ( rc . ctx , & pb . CompactionRequest { Revision : rev } ) if err == nil || err == mvcc . ErrCompacted { prev = rev if rc . lg != nil { rc . lg . Info ( " " , zap . Int64 ( " " , rev ) , zap . Int64 ( " " , rc . retention ) , zap . Duration ( " " , time . Since ( now ) ) , ) } else { plog . Noticef ( " " , rev ) } } else { if rc . lg != nil { rc . lg . Warn ( " " , zap . Int64 ( " " , rev ) , zap . Int64 ( " " , rc . retention ) , zap . Duration ( " " , revInterval ) , zap . Error ( err ) , ) } else { plog . Noticef ( " " , rev , err ) plog . Noticef ( " " , revInterval ) } } } } ( ) } 
func ( rc * Revision ) Pause ( ) { rc . mu . Lock ( ) rc . paused = true rc . mu . Unlock ( ) } 
func ( rc * Revision ) Resume ( ) { rc . mu . Lock ( ) rc . paused = false rc . mu . Unlock ( ) } 
func voteRespMsgType ( msgt pb . MessageType ) pb . MessageType { switch msgt { case pb . MsgVote : return pb . MsgVoteResp case pb . MsgPreVote : return pb . MsgPreVoteResp default : panic ( fmt . Sprintf ( " " , msgt ) ) } } 
func DescribeMessage ( m pb . Message , f EntryFormatter ) string { var buf bytes . Buffer fmt . Fprintf ( & buf , " " , m . From , m . To , m . Type , m . Term , m . LogTerm , m . Index ) if m . Reject { fmt . Fprintf ( & buf , " " , m . RejectHint ) } if m . Commit != 0 { fmt . Fprintf ( & buf , " " , m . Commit ) } if len ( m . Entries ) > 0 { fmt . Fprintf ( & buf , " " ) for i , e := range m . Entries { if i != 0 { buf . WriteString ( " " ) } buf . WriteString ( DescribeEntry ( e , f ) ) } fmt . Fprintf ( & buf , " " ) } if ! IsEmptySnap ( m . Snapshot ) { fmt . Fprintf ( & buf , " " , m . Snapshot ) } return buf . String ( ) } 
func DescribeEntry ( e pb . Entry , f EntryFormatter ) string { var formatted string if e . Type == pb . EntryNormal && f != nil { formatted = f ( e . Data ) } else { formatted = fmt . Sprintf ( " " , e . Data ) } return fmt . Sprintf ( " " , e . Term , e . Index , e . Type , formatted ) } 
func DescribeEntries ( ents [ ] pb . Entry , f EntryFormatter ) string { var buf bytes . Buffer for _ , e := range ents { _ , _ = buf . WriteString ( DescribeEntry ( e , f ) + " \n " ) } return buf . String ( ) } 
func watchCommandFunc ( c * cli . Context , ki client . KeysAPI ) { if len ( c . Args ( ) ) == 0 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } key := c . Args ( ) [ 0 ] recursive := c . Bool ( " " ) forever := c . Bool ( " " ) index := c . Int ( " " ) stop := false w := ki . Watcher ( key , & client . WatcherOptions { AfterIndex : uint64 ( index ) , Recursive : recursive } ) sigch := make ( chan os . Signal , 1 ) signal . Notify ( sigch , os . Interrupt ) go func ( ) { <- sigch os . Exit ( 0 ) } ( ) for ! stop { resp , err := w . Next ( context . TODO ( ) ) if err != nil { handleError ( c , ExitServerError , err ) } if resp . Node . Dir { continue } if recursive { fmt . Printf ( " \n " , resp . Action , resp . Node . Key ) } printResponseKey ( resp , c . GlobalString ( " " ) ) if ! forever { stop = true } } } 
func SetLogger ( l grpclog . LoggerV2 ) { lgMu . Lock ( ) lg = logutil . NewLogger ( l ) lgMu . Unlock ( ) } 
func GetLogger ( ) logutil . Logger { lgMu . RLock ( ) l := lg lgMu . RUnlock ( ) return l } 
func New ( s * etcdserver . EtcdServer ) * clientv3 . Client { c := clientv3 . NewCtxClient ( context . Background ( ) ) kvc := adapter . KvServerToKvClient ( v3rpc . NewQuotaKVServer ( s ) ) c . KV = clientv3 . NewKVFromKVClient ( kvc , c ) lc := adapter . LeaseServerToLeaseClient ( v3rpc . NewQuotaLeaseServer ( s ) ) c . Lease = clientv3 . NewLeaseFromLeaseClient ( lc , c , time . Second ) wc := adapter . WatchServerToWatchClient ( v3rpc . NewWatchServer ( s ) ) c . Watcher = & watchWrapper { clientv3 . NewWatchFromWatchClient ( wc , c ) } mc := adapter . MaintenanceServerToMaintenanceClient ( v3rpc . NewMaintenanceServer ( s ) ) c . Maintenance = clientv3 . NewMaintenanceFromMaintenanceClient ( mc , c ) clc := adapter . ClusterServerToClusterClient ( v3rpc . NewClusterServer ( s ) ) c . Cluster = clientv3 . NewClusterFromClusterClient ( clc , c ) } 
func ( u * unstable ) maybeFirstIndex ( ) ( uint64 , bool ) { if u . snapshot != nil { return u . snapshot . Metadata . Index + 1 , true } return 0 , false } 
func ( u * unstable ) maybeLastIndex ( ) ( uint64 , bool ) { if l := len ( u . entries ) ; l != 0 { return u . offset + uint64 ( l ) - 1 , true } if u . snapshot != nil { return u . snapshot . Metadata . Index , true } return 0 , false } 
func ( u * unstable ) maybeTerm ( i uint64 ) ( uint64 , bool ) { if i < u . offset { if u . snapshot == nil { return 0 , false } if u . snapshot . Metadata . Index == i { return u . snapshot . Metadata . Term , true } return 0 , false } last , ok := u . maybeLastIndex ( ) if ! ok { return 0 , false } if i > last { return 0 , false } return u . entries [ i - u . offset ] . Term , true } 
func ( u * unstable ) shrinkEntriesArray ( ) { if len ( u . entries ) == 0 { u . entries = nil } else if len ( u . entries ) * lenMultiple < cap ( u . entries ) { newEntries := make ( [ ] pb . Entry , len ( u . entries ) ) copy ( newEntries , u . entries ) u . entries = newEntries } } 
func ( u * unstable ) mustCheckOutOfBounds ( lo , hi uint64 ) { if lo > hi { u . logger . Panicf ( " " , lo , hi ) } upper := u . offset + uint64 ( len ( u . entries ) ) if lo < u . offset || hi > upper { u . logger . Panicf ( " " , lo , hi , u . offset , upper ) } } 
func HandleMetrics ( mux * http . ServeMux , c * http . Client , eps [ ] string ) { if len ( eps ) > 1 { eps = shuffleEndpoints ( r , eps ) } pathMetrics := etcdhttp . PathMetrics mux . HandleFunc ( pathMetrics , func ( w http . ResponseWriter , r * http . Request ) { target := fmt . Sprintf ( " " , eps [ 0 ] , pathMetrics ) if ! strings . HasPrefix ( target , " " ) { scheme := " " if r . TLS != nil { scheme = " " } target = fmt . Sprintf ( " " , scheme , target ) } resp , err := c . Get ( target ) if err != nil { http . Error ( w , " " , http . StatusInternalServerError ) } defer resp . Body . Close ( ) w . Header ( ) . Set ( " " , " " ) body , _ := ioutil . ReadAll ( resp . Body ) fmt . Fprintf ( w , " " , body ) } ) } 
func ( st * storage ) SaveSnap ( snap raftpb . Snapshot ) error { walsnap := walpb . Snapshot { Index : snap . Metadata . Index , Term : snap . Metadata . Term , } err := st . WAL . SaveSnapshot ( walsnap ) if err != nil { return err } err = st . Snapshotter . SaveSnap ( snap ) if err != nil { return err } return st . WAL . ReleaseLockTo ( snap . Metadata . Index ) } 
func New ( cfg Config ) ( * Client , error ) { if len ( cfg . Endpoints ) == 0 { return nil , ErrNoAvailableEndpoints } return newClient ( & cfg ) } 
func NewCtxClient ( ctx context . Context ) * Client { cctx , cancel := context . WithCancel ( ctx ) return & Client { ctx : cctx , cancel : cancel } } 
func NewFromURL ( url string ) ( * Client , error ) { return New ( Config { Endpoints : [ ] string { url } } ) } 
func ( c * Client ) Close ( ) error { c . cancel ( ) c . Watcher . Close ( ) c . Lease . Close ( ) if c . resolverGroup != nil { c . resolverGroup . Close ( ) } if c . conn != nil { return toErr ( c . ctx , c . conn . Close ( ) ) } return c . ctx . Err ( ) } 
func ( c * Client ) Endpoints ( ) [ ] string { defer c . mu . RUnlock ( ) eps := make ( [ ] string , len ( c . cfg . Endpoints ) ) copy ( eps , c . cfg . Endpoints ) return eps } 
func ( c * Client ) SetEndpoints ( eps ... string ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) c . cfg . Endpoints = eps c . resolverGroup . SetEndpoints ( eps ) } 
func ( c * Client ) Sync ( ctx context . Context ) error { mresp , err := c . MemberList ( ctx ) if err != nil { return err } var eps [ ] string for _ , m := range mresp . Members { eps = append ( eps , m . ClientURLs ... ) } c . SetEndpoints ( eps ... ) return nil } 
func ( c * Client ) dialSetupOpts ( creds * credentials . TransportCredentials , dopts ... grpc . DialOption ) ( opts [ ] grpc . DialOption , err error ) { if c . cfg . DialKeepAliveTime > 0 { params := keepalive . ClientParameters { Time : c . cfg . DialKeepAliveTime , Timeout : c . cfg . DialKeepAliveTimeout , PermitWithoutStream : c . cfg . PermitWithoutStream , } opts = append ( opts , grpc . WithKeepaliveParams ( params ) ) } opts = append ( opts , dopts ... ) select { case <- c . ctx . Done ( ) : return nil , c . ctx . Err ( ) default : } dialer := & net . Dialer { Timeout : t } return dialer . DialContext ( c . ctx , proto , host ) } opts = append ( opts , grpc . WithDialer ( f ) ) if creds != nil { opts = append ( opts , grpc . WithTransportCredentials ( * creds ) ) } else { opts = append ( opts , grpc . WithInsecure ( ) ) } opts = append ( opts , return opts , nil } 
func ( c * Client ) Dial ( ep string ) ( * grpc . ClientConn , error ) { creds := c . directDialCreds ( ep ) } 
func ( c * Client ) dialWithBalancer ( ep string , dopts ... grpc . DialOption ) ( * grpc . ClientConn , error ) { _ , host , _ := endpoint . ParseEndpoint ( ep ) target := c . resolverGroup . Target ( host ) creds := c . dialWithBalancerCreds ( ep ) return c . dial ( target , creds , dopts ... ) } 
func ( c * Client ) dial ( target string , creds * credentials . TransportCredentials , dopts ... grpc . DialOption ) ( * grpc . ClientConn , error ) { opts , err := c . dialSetupOpts ( creds , dopts ... ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if c . Username != " " && c . Password != " " { c . tokenCred = & authTokenCredential { tokenMu : & sync . RWMutex { } , } ctx , cancel := c . ctx , func ( ) { } if c . cfg . DialTimeout > 0 { ctx , cancel = context . WithTimeout ( ctx , c . cfg . DialTimeout ) } err = c . getToken ( ctx ) if err != nil { if toErr ( ctx , err ) != rpctypes . ErrAuthNotEnabled { if err == ctx . Err ( ) && ctx . Err ( ) != c . ctx . Err ( ) { err = context . DeadlineExceeded } cancel ( ) return nil , err } } else { opts = append ( opts , grpc . WithPerRPCCredentials ( c . tokenCred ) ) } cancel ( ) } opts = append ( opts , c . cfg . DialOptions ... ) dctx := c . ctx if c . cfg . DialTimeout > 0 { var cancel context . CancelFunc dctx , cancel = context . WithTimeout ( c . ctx , c . cfg . DialTimeout ) defer cancel ( ) } conn , err := grpc . DialContext ( dctx , target , opts ... ) if err != nil { return nil , err } return conn , nil } 
func WithRequireLeader ( ctx context . Context ) context . Context { md := metadata . Pairs ( rpctypes . MetadataRequireLeaderKey , rpctypes . MetadataHasLeader ) return metadata . NewOutgoingContext ( ctx , md ) } 
func ( c * Client ) roundRobinQuorumBackoff ( waitBetween time . Duration , jitterFraction float64 ) backoffFunc { return func ( attempt uint ) time . Duration { quorum := ( n / 2 + 1 ) if attempt % quorum == 0 { c . lg . Debug ( " " , zap . Uint ( " " , attempt ) , zap . Uint ( " " , quorum ) , zap . Duration ( " " , waitBetween ) , zap . Float64 ( " " , jitterFraction ) ) return jitterUp ( waitBetween , jitterFraction ) } c . lg . Debug ( " " , zap . Uint ( " " , attempt ) , zap . Uint ( " " , quorum ) ) return 0 } } 
func isHaltErr ( ctx context . Context , err error ) bool { if ctx != nil && ctx . Err ( ) != nil { return true } if err == nil { return false } ev , _ := status . FromError ( err ) } 
func IsConnCanceled ( err error ) bool { if err == nil { return false } if ok { } } } 
func NewLease ( l clientv3 . Lease , prefix string ) clientv3 . Lease { return & leasePrefix { l , [ ] byte ( prefix ) } } 
func serveHttpKVAPI ( kv * kvstore , port int , confChangeC chan <- raftpb . ConfChange , errorC <- chan error ) { srv := http . Server { Addr : " " + strconv . Itoa ( port ) , Handler : & httpKVAPI { store : kv , confChangeC : confChangeC , } , } go func ( ) { if err := srv . ListenAndServe ( ) ; err != nil { log . Fatal ( err ) } } ( ) } } 
func ( e * Event ) IsCreate ( ) bool { return e . Type == EventTypePut && e . Kv . CreateRevision == e . Kv . ModRevision } 
func ( wr * WatchResponse ) Err ( ) error { switch { case wr . closeErr != nil : return v3rpc . Error ( wr . closeErr ) case wr . CompactRevision != 0 : return v3rpc . ErrCompacted case wr . Canceled : if len ( wr . cancelReason ) != 0 { return v3rpc . Error ( status . Error ( codes . FailedPrecondition , wr . cancelReason ) ) } return v3rpc . ErrFutureRev } return nil } 
func ( wr * WatchResponse ) IsProgressNotify ( ) bool { return len ( wr . Events ) == 0 && ! wr . Canceled && ! wr . Created && wr . CompactRevision == 0 && wr . Header . Revision != 0 } 
func ( w * watcher ) Watch ( ctx context . Context , key string , opts ... OpOption ) WatchChan { ow := opWatch ( key , opts ... ) var filters [ ] pb . WatchCreateRequest_FilterType if ow . filterPut { filters = append ( filters , pb . WatchCreateRequest_NOPUT ) } if ow . filterDelete { filters = append ( filters , pb . WatchCreateRequest_NODELETE ) } wr := & watchRequest { ctx : ctx , createdNotify : ow . createdNotify , key : string ( ow . key ) , end : string ( ow . end ) , rev : ow . rev , progressNotify : ow . progressNotify , fragment : ow . fragment , filters : filters , prevKV : ow . prevKV , retc : make ( chan chan WatchResponse , 1 ) , } ok := false ctxKey := streamKeyFromCtx ( ctx ) if w . streams == nil { ch := make ( chan WatchResponse ) close ( ch ) return ch } wgs := w . streams [ ctxKey ] if wgs == nil { wgs = w . newWatcherGrpcStream ( ctx ) w . streams [ ctxKey ] = wgs } donec := wgs . donec reqc := wgs . reqc w . mu . Unlock ( ) case <- wr . ctx . Done ( ) : case <- donec : if wgs . closeErr != nil { closeCh <- WatchResponse { Canceled : true , closeErr : wgs . closeErr } break } } case <- ctx . Done ( ) : case <- donec : if wgs . closeErr != nil { closeCh <- WatchResponse { Canceled : true , closeErr : wgs . closeErr } break } } } close ( closeCh ) return closeCh } 
func ( w * watcher ) RequestProgress ( ctx context . Context ) ( err error ) { ctxKey := streamKeyFromCtx ( ctx ) w . mu . Lock ( ) if w . streams == nil { return fmt . Errorf ( " " ) } wgs := w . streams [ ctxKey ] if wgs == nil { wgs = w . newWatcherGrpcStream ( ctx ) w . streams [ ctxKey ] = wgs } donec := wgs . donec reqc := wgs . reqc w . mu . Unlock ( ) pr := & progressRequest { } select { case reqc <- pr : return nil case <- ctx . Done ( ) : if err == nil { return ctx . Err ( ) } return err case <- donec : if wgs . closeErr != nil { return wgs . closeErr } } } 
func ( w * watchGrpcStream ) run ( ) { var wc pb . Watch_WatchClient var closeErr error defer func ( ) { w . closeErr = closeErr closing [ ws ] = struct { } { } } } for _ , ws := range w . resuming { if _ , ok := closing [ ws ] ; ws != nil && ! ok { close ( ws . recvc ) closing [ ws ] = struct { } { } } } w . joinSubstreams ( ) for range closing { w . closeSubstream ( <- w . closingc ) } w . wg . Wait ( ) w . owner . closeStream ( w ) } ( ) } cancelSet := make ( map [ int64 ] struct { } ) var cur * pb . WatchResponse for { select { ws . donec = make ( chan struct { } ) w . wg . Add ( 1 ) go w . serveSubstream ( ws , w . resumec ) if len ( w . resuming ) == 1 { } case * progressRequest : wc . Send ( wreq . toPB ( ) ) } } else if cur != nil && cur . WatchId == pbresp . WatchId { } switch { case pbresp . Created : w . dispatchEvent ( pbresp ) w . resuming [ 0 ] = nil } if ws := w . nextResume ( ) ; ws != nil { wc . Send ( ws . initReq . toPB ( ) ) } case pbresp . Canceled && pbresp . CompactRevision == 0 : delete ( cancelSet , pbresp . WatchId ) if ws , ok := w . substreams [ pbresp . WatchId ] ; ok { closing [ ws ] = struct { } { } } case cur . Fragment : default : if ok { break } } cancelSet [ pbresp . WatchId ] = struct { } { } cr := & pb . WatchRequest_CancelRequest { CancelRequest : & pb . WatchCancelRequest { WatchId : pbresp . WatchId , } , } req := & pb . WatchRequest { RequestUnion : cr } wc . Send ( req ) } return } if wc , closeErr = w . newWatchClient ( ) ; closeErr != nil { return } if ws := w . nextResume ( ) ; ws != nil { wc . Send ( ws . initReq . toPB ( ) ) } cancelSet = make ( map [ int64 ] struct { } ) case <- w . ctx . Done ( ) : return case ws := <- w . closingc : w . closeSubstream ( ws ) delete ( closing , ws ) } } } } 
func ( w * watchGrpcStream ) nextResume ( ) * watcherStream { for len ( w . resuming ) != 0 { if w . resuming [ 0 ] != nil { return w . resuming [ 0 ] } w . resuming = w . resuming [ 1 : len ( w . resuming ) ] } return nil } 
func ( w * watchGrpcStream ) dispatchEvent ( pbresp * pb . WatchResponse ) bool { events := make ( [ ] * Event , len ( pbresp . Events ) ) for i , ev := range pbresp . Events { events [ i ] = ( * Event ) ( ev ) } } return w . unicastResponse ( wr , pbresp . WatchId ) } 
func ( w * watchGrpcStream ) broadcastResponse ( wr * WatchResponse ) bool { for _ , ws := range w . substreams { select { case ws . recvc <- wr : case <- ws . donec : } } return true } 
func ( w * watchGrpcStream ) unicastResponse ( wr * WatchResponse , watchId int64 ) bool { ws , ok := w . substreams [ watchId ] if ! ok { return false } select { case ws . recvc <- wr : case <- ws . donec : return false } return true } 
func ( w * watchGrpcStream ) serveWatchClient ( wc pb . Watch_WatchClient ) { for { resp , err := wc . Recv ( ) if err != nil { select { case w . errc <- err : case <- w . donec : } return } select { case w . respc <- resp : case <- w . donec : return } } } 
func ( w * watchGrpcStream ) serveSubstream ( ws * watcherStream , resumec chan struct { } ) { if ws . closing { panic ( " " ) } resuming := false defer func ( ) { if ! resuming { ws . closing = true } close ( ws . donec ) if ! resuming { w . closingc <- ws } w . wg . Done ( ) } ( ) emptyWr := & WatchResponse { } for { curWr := emptyWr outc := ws . outc if len ( ws . buf ) > 0 { curWr = ws . buf [ 0 ] } else { outc = nil } select { case outc <- * curWr : if ws . buf [ 0 ] . Err ( ) != nil { return } ws . buf [ 0 ] = nil ws . buf = ws . buf [ 1 : ] case wr , ok := <- ws . recvc : if ! ok { } if wr . Created { if ws . initReq . retc != nil { ws . initReq . retc <- ws . outc } } } } else { } if len ( wr . Events ) > 0 { nextRev = wr . Events [ len ( wr . Events ) - 1 ] . Kv . ModRevision + 1 } ws . initReq . rev = nextRev } case <- w . ctx . Done ( ) : return case <- ws . initReq . ctx . Done ( ) : return case <- resumec : resuming = true return } } // lazily send cancel message if events on missing id } 
func ( w * watchGrpcStream ) joinSubstreams ( ) { for _ , ws := range w . substreams { <- ws . donec } for _ , ws := range w . resuming { if ws != nil { <- ws . donec } } } 
func ( w * watchGrpcStream ) openWatchClient ( ) ( ws pb . Watch_WatchClient , err error ) { backoff := time . Millisecond for { select { case <- w . ctx . Done ( ) : if err == nil { return nil , w . ctx . Err ( ) } return nil , err default : } if ws , err = w . remote . Watch ( w . ctx , w . callOpts ... ) ; ws != nil && err == nil { break } if isHaltErr ( w . ctx , err ) { return nil , v3rpc . Error ( err ) } if isUnavailableErr ( w . ctx , err ) { if backoff > maxBackoff { backoff = maxBackoff } } time . Sleep ( backoff ) } } return ws , nil } 
func ( wr * watchRequest ) toPB ( ) * pb . WatchRequest { req := & pb . WatchCreateRequest { StartRevision : wr . rev , Key : [ ] byte ( wr . key ) , RangeEnd : [ ] byte ( wr . end ) , ProgressNotify : wr . progressNotify , Filters : wr . filters , PrevKv : wr . prevKV , Fragment : wr . fragment , } cr := & pb . WatchRequest_CreateRequest { CreateRequest : req } return & pb . WatchRequest { RequestUnion : cr } } 
func ( pr * progressRequest ) toPB ( ) * pb . WatchRequest { req := & pb . WatchProgressRequest { } cr := & pb . WatchRequest_ProgressRequest { ProgressRequest : req } return & pb . WatchRequest { RequestUnion : cr } } 
func ( us * unsafeSet ) Contains ( value string ) ( exists bool ) { _ , exists = us . d [ value ] return exists } 
func ( us * unsafeSet ) ContainsAll ( values [ ] string ) bool { for _ , s := range values { if ! us . Contains ( s ) { return false } } return true } 
func ( us * unsafeSet ) Equals ( other Set ) bool { v1 := sort . StringSlice ( us . Values ( ) ) v2 := sort . StringSlice ( other . Values ( ) ) v1 . Sort ( ) v2 . Sort ( ) return reflect . DeepEqual ( v1 , v2 ) } 
func ( us * unsafeSet ) Values ( ) ( values [ ] string ) { values = make ( [ ] string , 0 ) for val := range us . d { values = append ( values , val ) } return values } 
func ( us * unsafeSet ) Copy ( ) Set { cp := NewUnsafeSet ( ) for val := range us . d { cp . Add ( val ) } return cp } 
func ( us * unsafeSet ) Sub ( other Set ) Set { oValues := other . Values ( ) result := us . Copy ( ) . ( * unsafeSet ) for _ , val := range oValues { if _ , ok := result . d [ val ] ; ! ok { continue } delete ( result . d , val ) } return result } 
func v2MembersURL ( ep url . URL ) * url . URL { ep . Path = path . Join ( ep . Path , defaultV2MembersPrefix ) return & ep } 
func NewMigrateCommand ( ) * cobra . Command { mc := & cobra . Command { Use : " " , Short : " " , Run : migrateCommandFunc , } mc . Flags ( ) . BoolVar ( & migrateExcludeTTLKey , " " , false , " " ) mc . Flags ( ) . StringVar ( & migrateDatadir , " " , " " , " " ) mc . Flags ( ) . StringVar ( & migrateWALdir , " " , " " , " " ) mc . Flags ( ) . StringVar ( & migrateTransformer , " " , " " , " " ) return mc } 
func newRaftNode ( id int , peers [ ] string , join bool , getSnapshot func ( ) ( [ ] byte , error ) , proposeC <- chan string , confChangeC <- chan raftpb . ConfChange ) ( <- chan * string , <- chan error , <- chan * snap . Snapshotter ) { commitC := make ( chan * string ) errorC := make ( chan error ) rc := & raftNode { proposeC : proposeC , confChangeC : confChangeC , commitC : commitC , errorC : errorC , id : id , peers : peers , join : join , waldir : fmt . Sprintf ( " " , id ) , snapdir : fmt . Sprintf ( " " , id ) , getSnapshot : getSnapshot , snapCount : defaultSnapshotCount , stopc : make ( chan struct { } ) , httpstopc : make ( chan struct { } ) , httpdonec : make ( chan struct { } ) , snapshotterReady : make ( chan * snap . Snapshotter , 1 ) , go rc . startRaft ( ) return commitC , errorC , rc . snapshotterReady } 
func ( rc * raftNode ) publishEntries ( ents [ ] raftpb . Entry ) bool { for i := range ents { switch ents [ i ] . Type { case raftpb . EntryNormal : if len ( ents [ i ] . Data ) == 0 { } s := string ( ents [ i ] . Data ) select { case rc . commitC <- & s : case <- rc . stopc : return false } case raftpb . EntryConfChange : var cc raftpb . ConfChange cc . Unmarshal ( ents [ i ] . Data ) rc . confState = * rc . node . ApplyConfChange ( cc ) switch cc . Type { case raftpb . ConfChangeAddNode : if len ( cc . Context ) > 0 { rc . transport . AddPeer ( types . ID ( cc . NodeID ) , [ ] string { string ( cc . Context ) } ) } case raftpb . ConfChangeRemoveNode : if cc . NodeID == uint64 ( rc . id ) { log . Println ( " " ) return false } rc . transport . RemovePeer ( types . ID ( cc . NodeID ) ) } } } } } return true } 
func ( rc * raftNode ) openWAL ( snapshot * raftpb . Snapshot ) * wal . WAL { if ! wal . Exist ( rc . waldir ) { if err := os . Mkdir ( rc . waldir , 0750 ) ; err != nil { log . Fatalf ( " " , err ) } w , err := wal . Create ( zap . NewExample ( ) , rc . waldir , nil ) if err != nil { log . Fatalf ( " " , err ) } w . Close ( ) } walsnap := walpb . Snapshot { } if snapshot != nil { walsnap . Index , walsnap . Term = snapshot . Metadata . Index , snapshot . Metadata . Term } log . Printf ( " " , walsnap . Term , walsnap . Index ) w , err := wal . Open ( zap . NewExample ( ) , rc . waldir , walsnap ) if err != nil { log . Fatalf ( " " , err ) } return w } 
func ( rc * raftNode ) replayWAL ( ) * wal . WAL { log . Printf ( " " , rc . id ) snapshot := rc . loadSnapshot ( ) w := rc . openWAL ( snapshot ) _ , st , ents , err := w . ReadAll ( ) if err != nil { log . Fatalf ( " " , err ) } rc . raftStorage = raft . NewMemoryStorage ( ) if snapshot != nil { rc . raftStorage . ApplySnapshot ( * snapshot ) } rc . raftStorage . SetHardState ( st ) } else { rc . commitC <- nil } return w } 
func ( rc * raftNode ) stop ( ) { rc . stopHTTP ( ) close ( rc . commitC ) close ( rc . errorC ) rc . node . Stop ( ) } 
func NewWatchCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : watchCommandFunc , } cmd . Flags ( ) . BoolVarP ( & watchInteractive , " " , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & watchPrefix , " " , false , " " ) cmd . Flags ( ) . Int64Var ( & watchRev , " " , 0 , " " ) cmd . Flags ( ) . BoolVar ( & watchPrevKey , " " , false , " " ) return cmd } 
func watchCommandFunc ( cmd * cobra . Command , args [ ] string ) { envKey , envRange := os . Getenv ( " " ) , os . Getenv ( " " ) if envKey == " " && envRange != " " { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " , envRange ) ) } if watchInteractive { watchInteractiveFunc ( cmd , os . Args , envKey , envRange ) return } watchArgs , execArgs , err := parseWatchArgs ( os . Args , args , envKey , envRange , false ) if err != nil { ExitWithError ( ExitBadArgs , err ) } c := mustClientFromCmd ( cmd ) wc , err := getWatchChan ( c , watchArgs ) if err != nil { ExitWithError ( ExitBadArgs , err ) } printWatchCh ( c , wc , execArgs ) if err = c . Close ( ) ; err != nil { ExitWithError ( ExitBadConnection , err ) } ExitWithError ( ExitInterrupted , fmt . Errorf ( " " ) ) } 
func parseWatchArgs ( osArgs , commandArgs [ ] string , envKey , envRange string , interactive bool ) ( watchArgs [ ] string , execArgs [ ] string , err error ) { rawArgs := make ( [ ] string , len ( osArgs ) ) copy ( rawArgs , osArgs ) watchArgs = make ( [ ] string , len ( commandArgs ) ) copy ( watchArgs , commandArgs ) break } } return nil , nil , errBadArgsInteractiveWatch } watchArgs = watchArgs [ 1 : ] } execIdx , execExist := 0 , false if ! interactive { for execIdx = range rawArgs { if rawArgs [ execIdx ] == " " { execExist = true break } } if execExist && execIdx == len ( rawArgs ) - 1 { } } if execExist && envKey != " " { for ; widx >= 0 ; widx -- { if watchArgs [ widx ] == rawArgs [ ridx ] { ridx -- continue } } } } } } else { for execIdx = range watchArgs { if watchArgs [ execIdx ] == " " { execExist = true break } } if execExist && execIdx == len ( watchArgs ) - 1 { return nil , nil , errBadArgsNumSeparator } flagset := NewWatchCommand ( ) . Flags ( ) if perr := flagset . Parse ( watchArgs ) ; perr != nil { watchPrefix , watchRev , watchPrevKey = false , 0 , false return nil , nil , perr } pArgs := flagset . Args ( ) return nil , nil , errBadArgsNum } return nil , nil , errBadArgsNumConflictEnv } } argsWithSep := rawArgs if interactive { } idx , foundSep := 0 , false for idx = range argsWithSep { if argsWithSep [ idx ] == " " { foundSep = true break } } if foundSep { execArgs = argsWithSep [ idx + 1 : ] } if interactive { flagset := NewWatchCommand ( ) . Flags ( ) if perr := flagset . Parse ( argsWithSep ) ; perr != nil { return nil , nil , perr } watchArgs = flagset . Args ( ) watchPrefix , err = flagset . GetBool ( " " ) if err != nil { return nil , nil , err } watchRev , err = flagset . GetInt64 ( " " ) if err != nil { return nil , nil , err } watchPrevKey , err = flagset . GetBool ( " " ) if err != nil { return nil , nil , err } } if envRange != " " { ranges = append ( ranges , envRange ) } watchArgs = append ( ranges , watchArgs ... ) } if ! foundSep { return watchArgs , nil , nil } for endIdx = len ( watchArgs ) - 1 ; endIdx >= 0 ; endIdx -- { if watchArgs [ endIdx ] == argsWithSep [ idx + 1 ] { break } } watchArgs = watchArgs [ : endIdx ] return watchArgs , execArgs , nil } 
func ( ms * MemoryStorage ) InitialState ( ) ( pb . HardState , pb . ConfState , error ) { return ms . hardState , ms . snapshot . Metadata . ConfState , nil } 
func ( ms * MemoryStorage ) SetHardState ( st pb . HardState ) error { ms . Lock ( ) defer ms . Unlock ( ) ms . hardState = st return nil } 
func ( ms * MemoryStorage ) Entries ( lo , hi , maxSize uint64 ) ( [ ] pb . Entry , error ) { ms . Lock ( ) defer ms . Unlock ( ) offset := ms . ents [ 0 ] . Index if lo <= offset { return nil , ErrCompacted } if hi > ms . lastIndex ( ) + 1 { raftLogger . Panicf ( " " , hi , ms . lastIndex ( ) ) } } ents := ms . ents [ lo - offset : hi - offset ] return limitSize ( ents , maxSize ) , nil } 
func ( ms * MemoryStorage ) Term ( i uint64 ) ( uint64 , error ) { ms . Lock ( ) defer ms . Unlock ( ) offset := ms . ents [ 0 ] . Index if i < offset { return 0 , ErrCompacted } if int ( i - offset ) >= len ( ms . ents ) { return 0 , ErrUnavailable } return ms . ents [ i - offset ] . Term , nil } 
func ( ms * MemoryStorage ) LastIndex ( ) ( uint64 , error ) { ms . Lock ( ) defer ms . Unlock ( ) return ms . lastIndex ( ) , nil } 
func ( ms * MemoryStorage ) FirstIndex ( ) ( uint64 , error ) { ms . Lock ( ) defer ms . Unlock ( ) return ms . firstIndex ( ) , nil } 
func ( ms * MemoryStorage ) Snapshot ( ) ( pb . Snapshot , error ) { ms . Lock ( ) defer ms . Unlock ( ) return ms . snapshot , nil } 
func ( ms * MemoryStorage ) ApplySnapshot ( snap pb . Snapshot ) error { ms . Lock ( ) defer ms . Unlock ( ) snapIndex := snap . Metadata . Index if msIndex >= snapIndex { return ErrSnapOutOfDate } ms . snapshot = snap ms . ents = [ ] pb . Entry { { Term : snap . Metadata . Term , Index : snap . Metadata . Index } } return nil } 
func ( ms * MemoryStorage ) CreateSnapshot ( i uint64 , cs * pb . ConfState , data [ ] byte ) ( pb . Snapshot , error ) { ms . Lock ( ) defer ms . Unlock ( ) if i <= ms . snapshot . Metadata . Index { return pb . Snapshot { } , ErrSnapOutOfDate } offset := ms . ents [ 0 ] . Index if i > ms . lastIndex ( ) { raftLogger . Panicf ( " " , i , ms . lastIndex ( ) ) } ms . snapshot . Metadata . Index = i ms . snapshot . Metadata . Term = ms . ents [ i - offset ] . Term if cs != nil { ms . snapshot . Metadata . ConfState = * cs } ms . snapshot . Data = data return ms . snapshot , nil } 
func ( ms * MemoryStorage ) Compact ( compactIndex uint64 ) error { ms . Lock ( ) defer ms . Unlock ( ) offset := ms . ents [ 0 ] . Index if compactIndex <= offset { return ErrCompacted } if compactIndex > ms . lastIndex ( ) { raftLogger . Panicf ( " " , compactIndex , ms . lastIndex ( ) ) } i := compactIndex - offset ents := make ( [ ] pb . Entry , 1 , 1 + uint64 ( len ( ms . ents ) ) - i ) ents [ 0 ] . Index = ms . ents [ i ] . Index ents [ 0 ] . Term = ms . ents [ i ] . Term ents = append ( ents , ms . ents [ i + 1 : ] ... ) ms . ents = ents return nil } 
func ( ms * MemoryStorage ) Append ( entries [ ] pb . Entry ) error { if len ( entries ) == 0 { return nil } ms . Lock ( ) defer ms . Unlock ( ) first := ms . firstIndex ( ) last := entries [ 0 ] . Index + uint64 ( len ( entries ) ) - 1 } } offset := entries [ 0 ] . Index - ms . ents [ 0 ] . Index switch { case uint64 ( len ( ms . ents ) ) > offset : ms . ents = append ( [ ] pb . Entry { } , ms . ents [ : offset ] ... ) ms . ents = append ( ms . ents , entries ... ) case uint64 ( len ( ms . ents ) ) == offset : ms . ents = append ( ms . ents , entries ... ) default : raftLogger . Panicf ( " " , ms . lastIndex ( ) , entries [ 0 ] . Index ) } return nil } 
func ( p * urlPicker ) unreachable ( u url . URL ) { p . mu . Lock ( ) defer p . mu . Unlock ( ) if u == p . urls [ p . picked ] { p . picked = ( p . picked + 1 ) % len ( p . urls ) } } 
func NewEndpointCommand ( ) * cobra . Command { ec := & cobra . Command { Use : " " , Short : " " , } ec . PersistentFlags ( ) . BoolVar ( & epClusterEndpoints , " " , false , " " ) ec . AddCommand ( newEpHealthCommand ( ) ) ec . AddCommand ( newEpStatusCommand ( ) ) ec . AddCommand ( newEpHashKVCommand ( ) ) return ec } 
func epHealthCommandFunc ( cmd * cobra . Command , args [ ] string ) { flags . SetPflagsFromEnv ( " " , cmd . InheritedFlags ( ) ) initDisplayFromCmd ( cmd ) sec := secureCfgFromCmd ( cmd ) dt := dialTimeoutFromCmd ( cmd ) ka := keepAliveTimeFromCmd ( cmd ) kat := keepAliveTimeoutFromCmd ( cmd ) auth := authCfgFromCmd ( cmd ) cfgs := [ ] * v3 . Config { } for _ , ep := range endpointsFromCluster ( cmd ) { cfg , err := newClientCfg ( [ ] string { ep } , dt , ka , kat , sec , auth ) if err != nil { ExitWithError ( ExitBadArgs , err ) } cfgs = append ( cfgs , cfg ) } var wg sync . WaitGroup hch := make ( chan epHealth , len ( cfgs ) ) for _ , cfg := range cfgs { wg . Add ( 1 ) go func ( cfg * v3 . Config ) { defer wg . Done ( ) ep := cfg . Endpoints [ 0 ] cli , err := v3 . New ( * cfg ) if err != nil { hch <- epHealth { Ep : ep , Health : false , Error : err . Error ( ) } return } st := time . Now ( ) _ , err = cli . Get ( ctx , " " ) cancel ( ) eh := epHealth { Ep : ep , Health : false , Took : time . Since ( st ) . String ( ) } } else { eh . Error = err . Error ( ) } hch <- eh } ( cfg ) } wg . Wait ( ) close ( hch ) errs := false healthList := [ ] epHealth { } for h := range hch { healthList = append ( healthList , h ) if h . Error != " " { errs = true } } display . EndpointHealth ( healthList ) if errs { ExitWithError ( ExitError , fmt . Errorf ( " " ) ) } } 
func NewElectCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : electCommandFunc , } cmd . Flags ( ) . BoolVarP ( & electListen , " " , " " , false , " " ) return cmd } 
func NewDefragCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : defragCommandFunc , } cmd . PersistentFlags ( ) . BoolVar ( & epClusterEndpoints , " " , false , " " ) cmd . Flags ( ) . StringVar ( & defragDataDir , " " , " " , " " ) return cmd } 
func RegisterBuilder ( cfg Config ) { bb := & builder { cfg } balancer . Register ( bb ) bb . cfg . Logger . Debug ( " " , zap . String ( " " , bb . cfg . Policy . String ( ) ) , zap . String ( " " , bb . cfg . Name ) , ) } 
func ( b * builder ) Build ( cc balancer . ClientConn , opt balancer . BuildOptions ) balancer . Balancer { bb := & baseBalancer { id : strconv . FormatInt ( time . Now ( ) . UnixNano ( ) , 36 ) , policy : b . cfg . Policy , name : b . cfg . Name , lg : b . cfg . Logger , addrToSc : make ( map [ resolver . Address ] balancer . SubConn ) , scToAddr : make ( map [ balancer . SubConn ] resolver . Address ) , scToSt : make ( map [ balancer . SubConn ] connectivity . State ) , currentConn : nil , csEvltr : & connectivityStateEvaluator { } , if bb . lg == nil { bb . lg = zap . NewNop ( ) } bb . currentConn = cc bb . mu . Unlock ( ) bb . lg . Info ( " " , zap . String ( " " , bb . id ) , zap . String ( " " , bb . policy . String ( ) ) , zap . String ( " " , cc . Target ( ) ) , ) return bb } 
func ( bb * baseBalancer ) HandleResolvedAddrs ( addrs [ ] resolver . Address , err error ) { if err != nil { bb . lg . Warn ( " " , zap . String ( " " , bb . id ) , zap . Error ( err ) ) return } bb . lg . Info ( " " , zap . String ( " " , bb . id ) , zap . Strings ( " " , addrsToStrings ( addrs ) ) ) bb . mu . Lock ( ) defer bb . mu . Unlock ( ) resolved := make ( map [ resolver . Address ] struct { } ) for _ , addr := range addrs { resolved [ addr ] = struct { } { } if _ , ok := bb . addrToSc [ addr ] ; ! ok { sc , err := bb . currentConn . NewSubConn ( [ ] resolver . Address { addr } , balancer . NewSubConnOptions { } ) if err != nil { bb . lg . Warn ( " " , zap . String ( " " , bb . id ) , zap . Error ( err ) , zap . String ( " " , addr . Addr ) ) continue } bb . addrToSc [ addr ] = sc bb . scToAddr [ sc ] = addr bb . scToSt [ sc ] = connectivity . Idle sc . Connect ( ) } } for addr , sc := range bb . addrToSc { if _ , ok := resolved [ addr ] ; ! ok { delete ( bb . addrToSc , addr ) bb . lg . Info ( " " , zap . String ( " " , bb . id ) , zap . String ( " " , addr . Addr ) , zap . String ( " " , scToString ( sc ) ) , ) } } 
func ( bb * baseBalancer ) HandleSubConnStateChange ( sc balancer . SubConn , s connectivity . State ) { bb . mu . Lock ( ) defer bb . mu . Unlock ( ) old , ok := bb . scToSt [ sc ] if ! ok { bb . lg . Warn ( " " , zap . String ( " " , bb . id ) , zap . String ( " " , scToString ( sc ) ) , zap . String ( " " , s . String ( ) ) , ) return } bb . lg . Info ( " " , zap . String ( " " , bb . id ) , zap . Bool ( " " , s == connectivity . Ready ) , zap . String ( " " , scToString ( sc ) ) , zap . String ( " " , bb . scToAddr [ sc ] . Addr ) , zap . String ( " " , old . String ( ) ) , zap . String ( " " , s . String ( ) ) , ) bb . scToSt [ sc ] = s switch s { case connectivity . Idle : sc . Connect ( ) case connectivity . Shutdown : delete ( bb . scToSt , sc ) } oldAggrState := bb . currentState bb . currentState = bb . csEvltr . recordTransition ( old , s ) } bb . currentConn . UpdateBalancerState ( bb . currentState , bb . Picker ) return } 
func ( cse * connectivityStateEvaluator ) recordTransition ( oldState , newState connectivity . State ) connectivity . State { switch state { case connectivity . Ready : cse . numReady += updateVal case connectivity . Connecting : cse . numConnecting += updateVal case connectivity . TransientFailure : cse . numTransientFailure += updateVal } } } if cse . numConnecting > 0 { return connectivity . Connecting } return connectivity . TransientFailure } 
func ( s * EtcdServer ) doSerialize ( ctx context . Context , chk func ( * auth . AuthInfo ) error , get func ( ) ) error { ai , err := s . AuthInfoFromCtx ( ctx ) if err != nil { return err } if ai == nil { } if err = chk ( ai ) ; err != nil { return err } } return nil } 
func ( w * watcher ) send ( wr clientv3 . WatchResponse ) { if wr . IsProgressNotify ( ) && ! w . progress { return } if w . nextrev > wr . Header . Revision && len ( wr . Events ) > 0 { return } if w . nextrev == 0 { } events := make ( [ ] * mvccpb . Event , 0 , len ( wr . Events ) ) var lastRev int64 for i := range wr . Events { ev := ( * mvccpb . Event ) ( wr . Events [ i ] ) if ev . Kv . ModRevision < w . nextrev { continue } else { } filtered := false for _ , filter := range w . filters { if filter ( * ev ) { filtered = true break } } if filtered { continue } if ! w . prevKV { evCopy := * ev evCopy . PrevKv = nil ev = & evCopy } events = append ( events , ev ) } if lastRev >= w . nextrev { w . nextrev = lastRev + 1 } } w . lastHeader = wr . Header w . post ( & pb . WatchResponse { Header : & wr . Header , Created : wr . Created , CompactRevision : wr . CompactRevision , Canceled : wr . Canceled , WatchId : w . id , Events : events , } ) } 
func ( w * watcher ) post ( wr * pb . WatchResponse ) bool { select { case w . wps . watchCh <- wr : case <- time . After ( 50 * time . Millisecond ) : w . wps . cancel ( ) return false } return true } 
func ( ac * AccessController ) OriginAllowed ( origin string ) bool { ac . corsMu . RLock ( ) defer ac . corsMu . RUnlock ( ) if len ( ac . CORS ) == 0 { } _ , ok := ac . CORS [ " " ] if ok { return true } _ , ok = ac . CORS [ origin ] return ok } 
func ( ac * AccessController ) IsHostWhitelisted ( host string ) bool { ac . hostWhitelistMu . RLock ( ) defer ac . hostWhitelistMu . RUnlock ( ) if len ( ac . HostWhitelist ) == 0 { } _ , ok := ac . HostWhitelist [ " " ] if ok { return true } _ , ok = ac . HostWhitelist [ host ] return ok } 
func ( ss * SelectiveStringValue ) Set ( s string ) error { if _ , ok := ss . valids [ s ] ; ok { ss . v = s return nil } return errors . New ( " " ) } 
func ( ss * SelectiveStringValue ) Valids ( ) [ ] string { s := make ( [ ] string , 0 , len ( ss . valids ) ) for k := range ss . valids { s = append ( s , k ) } sort . Strings ( s ) return s } 
func NewSelectiveStringValue ( valids ... string ) * SelectiveStringValue { vm := make ( map [ string ] struct { } ) for _ , v := range valids { vm [ v ] = struct { } { } } return & SelectiveStringValue { valids : vm , v : valids [ 0 ] } } 
func ( ss * SelectiveStringsValue ) Set ( s string ) error { vs := strings . Split ( s , " " ) for i := range vs { if _ , ok := ss . valids [ vs [ i ] ] ; ok { ss . vs = append ( ss . vs , vs [ i ] ) } else { return fmt . Errorf ( " " , vs [ i ] ) } } sort . Strings ( ss . vs ) return nil } 
func NewSelectiveStringsValue ( valids ... string ) * SelectiveStringsValue { vm := make ( map [ string ] struct { } ) for _ , v := range valids { vm [ v ] = struct { } { } } return & SelectiveStringsValue { valids : vm , vs : [ ] string { } } } 
func NewKV ( kv clientv3 . KV , prefix string ) clientv3 . KV { return & kvPrefix { kv , prefix } } 
func NewTimeoutTransport ( info TLSInfo , dialtimeoutd , rdtimeoutd , wtimeoutd time . Duration ) ( * http . Transport , error ) { tr , err := NewTransport ( info , dialtimeoutd ) if err != nil { return nil , err } if rdtimeoutd != 0 || wtimeoutd != 0 { } else { } tr . Dial = ( & rwTimeoutDialer { Dialer : net . Dialer { Timeout : dialtimeoutd , KeepAlive : 30 * time . Second , } , rdtimeoutd : rdtimeoutd , wtimeoutd : wtimeoutd , } ) . Dial return tr , nil } 
func ( us * URLsValue ) Set ( s string ) error { ss , err := types . NewURLs ( strings . Split ( s , " " ) ) if err != nil { return err } * us = URLsValue ( ss ) return nil } 
func ( us * URLsValue ) String ( ) string { all := make ( [ ] string , len ( * us ) ) for i , u := range * us { all [ i ] = u . String ( ) } return strings . Join ( all , " " ) } 
func NewURLsValue ( s string ) * URLsValue { if s == " " { return & URLsValue { } } v := & URLsValue { } if err := v . Set ( s ) ; err != nil { plog . Panicf ( " " , err ) } return v } 
func URLsFromFlag ( fs * flag . FlagSet , urlsFlagName string ) [ ] url . URL { return [ ] url . URL ( * fs . Lookup ( urlsFlagName ) . Value . ( * URLsValue ) ) } 
func StartEtcd ( inCfg * Config ) ( e * Etcd , err error ) { if err = inCfg . Validate ( ) ; err != nil { return nil , err } serving := false e = & Etcd { cfg : * inCfg , stopc : make ( chan struct { } ) } cfg := & e . cfg defer func ( ) { if e == nil || err == nil { return } if ! serving { } } e . Close ( ) e = nil } ( ) if e . cfg . logger != nil { e . cfg . logger . Info ( " " , zap . Strings ( " " , e . cfg . getLPURLs ( ) ) , ) } if e . Peers , err = configurePeerListeners ( cfg ) ; err != nil { return e , err } if e . cfg . logger != nil { e . cfg . logger . Info ( " " , zap . Strings ( " " , e . cfg . getLCURLs ( ) ) , ) } if e . sctxs , err = configureClientListeners ( cfg ) ; err != nil { return e , err } for _ , sctx := range e . sctxs { e . Clients = append ( e . Clients , sctx . l ) } var ( urlsmap types . URLsMap token string ) memberInitialized := true if ! isMemberInitialized ( cfg ) { memberInitialized = false urlsmap , token , err = cfg . PeerURLsMapAndToken ( " " ) if err != nil { return e , fmt . Errorf ( " " , err ) } } } autoCompactionRetention , err := parseCompactionRetention ( cfg . AutoCompactionMode , cfg . AutoCompactionRetention ) if err != nil { return e , err } backendFreelistType := parseBackendFreelistType ( cfg . ExperimentalBackendFreelistType ) srvcfg := etcdserver . ServerConfig { Name : cfg . Name , ClientURLs : cfg . ACUrls , PeerURLs : cfg . APUrls , DataDir : cfg . Dir , DedicatedWALDir : cfg . WalDir , SnapshotCount : cfg . SnapshotCount , SnapshotCatchUpEntries : cfg . SnapshotCatchUpEntries , MaxSnapFiles : cfg . MaxSnapFiles , MaxWALFiles : cfg . MaxWalFiles , InitialPeerURLsMap : urlsmap , InitialClusterToken : token , DiscoveryURL : cfg . Durl , DiscoveryProxy : cfg . Dproxy , NewCluster : cfg . IsNewCluster ( ) , PeerTLSInfo : cfg . PeerTLSInfo , TickMs : cfg . TickMs , ElectionTicks : cfg . ElectionTicks ( ) , InitialElectionTickAdvance : cfg . InitialElectionTickAdvance , AutoCompactionRetention : autoCompactionRetention , AutoCompactionMode : cfg . AutoCompactionMode , QuotaBackendBytes : cfg . QuotaBackendBytes , BackendBatchLimit : cfg . BackendBatchLimit , BackendFreelistType : backendFreelistType , BackendBatchInterval : cfg . BackendBatchInterval , MaxTxnOps : cfg . MaxTxnOps , MaxRequestBytes : cfg . MaxRequestBytes , StrictReconfigCheck : cfg . StrictReconfigCheck , ClientCertAuthEnabled : cfg . ClientTLSInfo . ClientCertAuth , AuthToken : cfg . AuthToken , BcryptCost : cfg . BcryptCost , CORS : cfg . CORS , HostWhitelist : cfg . HostWhitelist , InitialCorruptCheck : cfg . ExperimentalInitialCorruptCheck , CorruptCheckTime : cfg . ExperimentalCorruptCheckTime , PreVote : cfg . PreVote , Logger : cfg . logger , LoggerConfig : cfg . loggerConfig , LoggerCore : cfg . loggerCore , LoggerWriteSyncer : cfg . loggerWriteSyncer , Debug : cfg . Debug , ForceNewCluster : cfg . ForceNewCluster , EnableGRPCGateway : cfg . EnableGRPCGateway , } print ( e . cfg . logger , * cfg , srvcfg , memberInitialized ) if e . Server , err = etcdserver . NewServer ( srvcfg ) ; err != nil { return e , err } return e , err } } e . Server . Start ( ) if err = e . servePeers ( ) ; err != nil { return e , err } if err = e . serveClients ( ) ; err != nil { return e , err } if err = e . serveMetrics ( ) ; err != nil { return e , err } if e . cfg . logger != nil { e . cfg . logger . Info ( " " , zap . String ( " " , e . Server . ID ( ) . String ( ) ) , zap . Strings ( " " , e . cfg . getAPURLs ( ) ) , zap . Strings ( " " , e . cfg . getLPURLs ( ) ) , zap . Strings ( " " , e . cfg . getACURLs ( ) ) , zap . Strings ( " " , e . cfg . getLCURLs ( ) ) , zap . Strings ( " " , e . cfg . getMetricsURLs ( ) ) , ) } serving = true return e , nil } 
func ( e * Etcd ) Close ( ) { fields := [ ] zap . Field { zap . String ( " " , e . cfg . Name ) , zap . String ( " " , e . cfg . Dir ) , zap . Strings ( " " , e . cfg . getAPURLs ( ) ) , zap . Strings ( " " , e . cfg . getACURLs ( ) ) , } lg := e . GetLogger ( ) if lg != nil { lg . Info ( " " , fields ... ) } defer func ( ) { if lg != nil { lg . Info ( " " , fields ... ) lg . Sync ( ) } } ( ) e . closeOnce . Do ( func ( ) { close ( e . stopc ) } ) if e . Server != nil { timeout = e . Server . Cfg . ReqTimeout ( ) } for _ , sctx := range e . sctxs { for ss := range sctx . serversC { ctx , cancel := context . WithTimeout ( context . Background ( ) , timeout ) stopServers ( ctx , ss ) cancel ( ) } } for _ , sctx := range e . sctxs { sctx . cancel ( ) } for i := range e . Clients { if e . Clients [ i ] != nil { e . Clients [ i ] . Close ( ) } } for i := range e . metricsListeners { e . metricsListeners [ i ] . Close ( ) } } e . Peers [ i ] . close ( ctx ) cancel ( ) } } } 
func ( e * Etcd ) servePeers ( ) ( err error ) { ph := etcdhttp . NewPeerHandler ( e . GetLogger ( ) , e . Server ) var peerTLScfg * tls . Config if ! e . cfg . PeerTLSInfo . Empty ( ) { if peerTLScfg , err = e . cfg . PeerTLSInfo . ServerConfig ( ) ; err != nil { return err } } for _ , p := range e . Peers { u := p . Listener . Addr ( ) . String ( ) gs := v3rpc . Server ( e . Server , peerTLScfg ) m := cmux . New ( p . Listener ) go gs . Serve ( m . Match ( cmux . HTTP2 ( ) ) ) srv := & http . Server { Handler : grpcHandlerFunc ( gs , ph ) , ReadTimeout : 5 * time . Minute , ErrorLog : defaultLog . New ( ioutil . Discard , " " , 0 ) , go srv . Serve ( m . Match ( cmux . Any ( ) ) ) p . serve = func ( ) error { return m . Serve ( ) } p . close = func ( ctx context . Context ) error { } stopServers ( ctx , & servers { secure : peerTLScfg != nil , grpc : gs , http : srv } ) if e . cfg . logger != nil { e . cfg . logger . Info ( " " , zap . String ( " " , u ) , ) } return nil } } if e . cfg . logger != nil { e . cfg . logger . Info ( " " , zap . String ( " " , u ) , ) } else { plog . Info ( " " , u ) } e . errHandler ( l . serve ( ) ) } ( pl ) } return nil } 
func ( e * Etcd ) GetLogger ( ) * zap . Logger { e . cfg . loggerMu . RLock ( ) l := e . cfg . logger e . cfg . loggerMu . RUnlock ( ) return l } 
func NewStore ( lg * zap . Logger , b backend . Backend , le lease . Lessor , ig ConsistentIndexGetter ) * store { s := & store { b : b , ig : ig , kvindex : newTreeIndex ( lg ) , le : le , currentRev : 1 , compactMainRev : - 1 , bytesBuf8 : make ( [ ] byte , 8 ) , fifoSched : schedule . NewFIFOScheduler ( ) , stopc : make ( chan struct { } ) , lg : lg , } s . ReadView = & readView { s } s . WriteView = & writeView { s } if s . le != nil { s . le . SetRangeDeleter ( func ( ) lease . TxnDelete { return s . Write ( ) } ) } tx := s . b . BatchTx ( ) tx . Lock ( ) tx . UnsafeCreateBucket ( keyBucketName ) tx . UnsafeCreateBucket ( metaBucketName ) tx . Unlock ( ) s . b . ForceCommit ( ) s . mu . Lock ( ) defer s . mu . Unlock ( ) if err := s . restore ( ) ; err != nil { } return s } 
func appendMarkTombstone ( lg * zap . Logger , b [ ] byte ) [ ] byte { if len ( b ) != revBytesLen { if lg != nil { lg . Panic ( " " , zap . Int ( " " , revBytesLen ) , zap . Int ( " " , len ( b ) ) , ) } else { plog . Panicf ( " " ) } } return append ( b , markTombstone ) } 
func IsDirWriteable ( dir string ) error { f := filepath . Join ( dir , " " ) if err := ioutil . WriteFile ( f , [ ] byte ( " " ) , PrivateFileMode ) ; err != nil { return err } return os . Remove ( f ) } 
func TouchDirAll ( dir string ) error { if err != nil { } return IsDirWriteable ( dir ) } 
func CreateDirAll ( dir string ) error { err := TouchDirAll ( dir ) if err == nil { var ns [ ] string ns , err = ReadDir ( dir ) if err != nil { return err } if len ( ns ) != 0 { err = fmt . Errorf ( " " , dir , ns ) } } return err } 
func ZeroToEnd ( f * os . File ) error { if err != nil { return err } lenf , lerr := f . Seek ( 0 , io . SeekEnd ) if lerr != nil { return lerr } if err = f . Truncate ( off ) ; err != nil { return err } } _ , err = f . Seek ( off , io . SeekStart ) return err } 
func ( fp * filePipeline ) Open ( ) ( f * fileutil . LockedFile , err error ) { select { case f = <- fp . filec : case err = <- fp . errc : } return f , err } 
func NewRaftLogger ( lcfg * zap . Config ) ( raft . Logger , error ) { if lcfg == nil { return nil , errors . New ( " " ) } lg , err := lcfg . Build ( zap . AddCallerSkip ( 1 ) ) if err != nil { return nil , err } return & zapRaftLogger { lg : lg , sugar : lg . Sugar ( ) } , nil } 
func NewRaftLoggerFromZapCore ( cr zapcore . Core , syncer zapcore . WriteSyncer ) raft . Logger { return & zapRaftLogger { lg : lg , sugar : lg . Sugar ( ) } } 
func NewConfig ( fpath string ) ( * clientv3 . Config , error ) { b , err := ioutil . ReadFile ( fpath ) if err != nil { return nil , err } yc := & yamlConfig { } err = yaml . Unmarshal ( b , yc ) if err != nil { return nil , err } if yc . InsecureTransport { return & yc . Config , nil } var ( cert * tls . Certificate cp * x509 . CertPool ) if yc . Certfile != " " && yc . Keyfile != " " { cert , err = tlsutil . NewCert ( yc . Certfile , yc . Keyfile , nil ) if err != nil { return nil , err } } if yc . TrustedCAfile != " " { cp , err = tlsutil . NewCertPool ( [ ] string { yc . TrustedCAfile } ) if err != nil { return nil , err } } tlscfg := & tls . Config { MinVersion : tls . VersionTLS12 , InsecureSkipVerify : yc . InsecureSkipTLSVerify , RootCAs : cp , } if cert != nil { tlscfg . Certificates = [ ] tls . Certificate { * cert } } yc . Config . TLS = tlscfg return & yc . Config , nil } 
func RegisterElectionHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterElectionHandlerClient ( ctx , mux , v3electionpb . NewElectionClient ( conn ) ) } 
func RegisterElectionHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client v3electionpb . ElectionClient ) error { mux . Handle ( " " , pattern_Election_Campaign_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Election_Campaign_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Election_Campaign_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Election_Proclaim_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Election_Proclaim_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Election_Proclaim_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Election_Leader_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Election_Leader_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Election_Leader_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Election_Observe_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Election_Observe_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Election_Observe_0 ( ctx , mux , outboundMarshaler , w , req , func ( ) ( proto . Message , error ) { return resp . Recv ( ) } , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Election_Resign_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Election_Resign_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Election_Resign_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func UpdateCapability ( lg * zap . Logger , v * semver . Version ) { if v == nil { } enableMapMu . Lock ( ) if curVersion != nil && ! curVersion . LessThan ( * v ) { enableMapMu . Unlock ( ) return } curVersion = v enabledMap = capabilityMaps [ curVersion . String ( ) ] enableMapMu . Unlock ( ) if lg != nil { lg . Info ( " " , zap . String ( " " , version . Cluster ( v . String ( ) ) ) , ) } else { plog . Infof ( " " , version . Cluster ( v . String ( ) ) ) } } 
func NewLockCommand ( ) * cobra . Command { c := & cobra . Command { Use : " " , Short : " " , Run : lockCommandFunc , } c . Flags ( ) . IntVarP ( & lockTTL , " " , " " , lockTTL , " " ) return c } 
func ( r * raftNode ) tick ( ) { r . tickMu . Lock ( ) r . Tick ( ) r . tickMu . Unlock ( ) } 
func ( r * raftNode ) start ( rh * raftReadyHandler ) { internalTimeout := time . Second go func ( ) { defer r . onStop ( ) islead := false for { select { case <- r . ticker . C : r . tick ( ) case rd := <- r . Ready ( ) : if rd . SoftState != nil { newLeader := rd . SoftState . Lead != raft . None && rh . getLead ( ) != rd . SoftState . Lead if newLeader { leaderChanges . Inc ( ) } if rd . SoftState . Lead == raft . None { hasLeader . Set ( 0 ) } else { hasLeader . Set ( 1 ) } rh . updateLead ( rd . SoftState . Lead ) islead = rd . RaftState == raft . StateLeader if islead { isLeader . Set ( 1 ) } else { isLeader . Set ( 0 ) } rh . updateLeadership ( newLeader ) r . td . Reset ( ) } if len ( rd . ReadStates ) != 0 { select { case r . readStateC <- rd . ReadStates [ len ( rd . ReadStates ) - 1 ] : case <- time . After ( internalTimeout ) : if r . lg != nil { r . lg . Warn ( " " , zap . Duration ( " " , internalTimeout ) ) } else { plog . Warningf ( " " ) } case <- r . stopped : return } } notifyc := make ( chan struct { } , 1 ) ap := apply { entries : rd . CommittedEntries , snapshot : rd . Snapshot , notifyc : notifyc , } updateCommittedIndex ( & ap , rh ) select { case r . applyc <- ap : case <- r . stopped : return } } } else { plog . Fatalf ( " " , err ) } } if ! raft . IsEmptyHardState ( rd . HardState ) { proposalsCommitted . Set ( float64 ( rd . HardState . Commit ) ) } } else { plog . Fatalf ( " " , err ) } } if r . lg != nil { r . lg . Info ( " " , zap . Uint64 ( " " , rd . Snapshot . Metadata . Index ) ) } else { plog . Infof ( " " , rd . Snapshot . Metadata . Index ) } r . raftStorage . Append ( rd . Entries ) if ! islead { for _ , ent := range rd . CommittedEntries { if ent . Type == raftpb . EntryConfChange { waitApply = true break } } if waitApply { } } } else { } r . Advance ( ) case <- r . stopped : return } } } ( ) } 
func ( r * raftNode ) pauseSending ( ) { p := r . transport . ( rafthttp . Pausable ) p . Pause ( ) } 
func ( r * raftNode ) advanceTicks ( ticks int ) { for i := 0 ; i < ticks ; i ++ { r . tick ( ) } } 
func getIDs ( lg * zap . Logger , snap * raftpb . Snapshot , ents [ ] raftpb . Entry ) [ ] uint64 { ids := make ( map [ uint64 ] bool ) if snap != nil { for _ , id := range snap . Metadata . ConfState . Nodes { ids [ id ] = true } } for _ , e := range ents { if e . Type != raftpb . EntryConfChange { continue } var cc raftpb . ConfChange pbutil . MustUnmarshal ( & cc , e . Data ) switch cc . Type { case raftpb . ConfChangeAddNode : ids [ cc . NodeID ] = true case raftpb . ConfChangeRemoveNode : delete ( ids , cc . NodeID ) case raftpb . ConfChangeUpdateNode : } else { plog . Panicf ( " " ) } } } sids := make ( types . Uint64Slice , 0 , len ( ids ) ) for id := range ids { sids = append ( sids , id ) } sort . Sort ( sids ) return [ ] uint64 ( sids ) } 
func createConfigChangeEnts ( lg * zap . Logger , ids [ ] uint64 , self uint64 , term , index uint64 ) [ ] raftpb . Entry { ents := make ( [ ] raftpb . Entry , 0 ) next := index + 1 found := false for _ , id := range ids { if id == self { found = true continue } cc := & raftpb . ConfChange { Type : raftpb . ConfChangeRemoveNode , NodeID : id , } e := raftpb . Entry { Type : raftpb . EntryConfChange , Data : pbutil . MustMarshal ( cc ) , Term : term , Index : next , } ents = append ( ents , e ) next ++ } if ! found { m := membership . Member { ID : types . ID ( self ) , RaftAttributes : membership . RaftAttributes { PeerURLs : [ ] string { " " } } , } ctx , err := json . Marshal ( m ) if err != nil { if lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } cc := & raftpb . ConfChange { Type : raftpb . ConfChangeAddNode , NodeID : self , Context : ctx , } e := raftpb . Entry { Type : raftpb . EntryConfChange , Data : pbutil . MustMarshal ( cc ) , Term : term , Index : next , } ents = append ( ents , e ) } return ents } 
func NewAuthCommand ( ) * cobra . Command { ac := & cobra . Command { Use : " " , Short : " " , } ac . AddCommand ( newAuthEnableCommand ( ) ) ac . AddCommand ( newAuthDisableCommand ( ) ) return ac } 
func authEnableCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 0 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } ctx , cancel := commandCtx ( cmd ) cli := mustClientFromCmd ( cmd ) var err error for err == nil { if _ , err = cli . AuthEnable ( ctx ) ; err == nil { break } if err == rpctypes . ErrRootRoleNotExist { if _ , err = cli . RoleAdd ( ctx , " " ) ; err != nil { break } if _ , err = cli . UserGrantRole ( ctx , " " , " " ) ; err != nil { break } } } cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } fmt . Println ( " " ) } 
func authDisableCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 0 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } ctx , cancel := commandCtx ( cmd ) _ , err := mustClientFromCmd ( cmd ) . Auth . AuthDisable ( ctx ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } fmt . Println ( " " ) } 
func isSafeRetryImmutableRPC ( err error ) bool { eErr := rpctypes . Error ( err ) if serverErr , ok := eErr . ( rpctypes . EtcdError ) ; ok && serverErr . Code ( ) != codes . Unavailable { } if ! ok { } return ev . Code ( ) == codes . Unavailable } 
func isSafeRetryMutableRPC ( err error ) bool { if ev , ok := status . FromError ( err ) ; ok && ev . Code ( ) != codes . Unavailable { } desc := rpctypes . ErrorDesc ( err ) return desc == " " || desc == " " } 
func RetryKVClient ( c * Client ) pb . KVClient { return & retryKVClient { kc : pb . NewKVClient ( c . conn ) , } } 
func RetryLeaseClient ( c * Client ) pb . LeaseClient { return & retryLeaseClient { lc : pb . NewLeaseClient ( c . conn ) , } } 
func RetryClusterClient ( c * Client ) pb . ClusterClient { return & retryClusterClient { cc : pb . NewClusterClient ( c . conn ) , } } 
func RetryMaintenanceClient ( c * Client , conn * grpc . ClientConn ) pb . MaintenanceClient { return & retryMaintenanceClient { mc : pb . NewMaintenanceClient ( conn ) , } } 
func RetryAuthClient ( c * Client ) pb . AuthClient { return & retryAuthClient { ac : pb . NewAuthClient ( c . conn ) , } } 
func NewSetDirCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Flags : [ ] cli . Flag { cli . IntFlag { Name : " " , Value : 0 , Usage : " " } , } , Action : func ( c * cli . Context ) error { mkdirCommandFunc ( c , mustNewKeyAPI ( c ) , client . PrevIgnore ) return nil } , } } 
func ( b * DoubleBarrier ) Enter ( ) error { client := b . s . Client ( ) ek , err := newUniqueEphemeralKey ( b . s , b . key + " " ) if err != nil { return err } b . myKey = ek resp , err := client . Get ( b . ctx , b . key + " " , clientv3 . WithPrefix ( ) ) if err != nil { return err } if len ( resp . Kvs ) > b . count { return ErrTooManyClients } if len ( resp . Kvs ) == b . count { return err } _ , err = WaitEvents ( client , b . key + " " , ek . Revision ( ) , [ ] mvccpb . Event_EventType { mvccpb . PUT } ) return err } 
func ( b * DoubleBarrier ) Leave ( ) error { client := b . s . Client ( ) resp , err := client . Get ( b . ctx , b . key + " " , clientv3 . WithPrefix ( ) ) if err != nil { return err } if len ( resp . Kvs ) == 0 { return nil } lowest , highest := resp . Kvs [ 0 ] , resp . Kvs [ 0 ] for _ , k := range resp . Kvs { if k . ModRevision < lowest . ModRevision { lowest = k } if k . ModRevision > highest . ModRevision { highest = k } } isLowest := string ( lowest . Key ) == b . myKey . Key ( ) if len ( resp . Kvs ) == 1 { } return b . myKey . Delete ( ) } if err != nil { return err } return b . Leave ( ) } } key := string ( lowest . Key ) _ , err = WaitEvents ( client , key , lowest . ModRevision , [ ] mvccpb . Event_EventType { mvccpb . DELETE } ) if err != nil { return err } return b . Leave ( ) } 
func HandleBasic ( mux * http . ServeMux , server etcdserver . ServerPeer ) { mux . HandleFunc ( varsPath , serveVars ) HandleMetricsHealth ( mux , server ) mux . HandleFunc ( versionPath , versionHandler ( server . Cluster ( ) , serveVersion ) ) } 
func logHandleFunc ( w http . ResponseWriter , r * http . Request ) { if ! allowMethod ( w , r , " " ) { return } in := struct { Level string } { } d := json . NewDecoder ( r . Body ) if err := d . Decode ( & in ) ; err != nil { WriteError ( nil , w , r , httptypes . NewHTTPError ( http . StatusBadRequest , " " ) ) return } logl , err := capnslog . ParseLevel ( strings . ToUpper ( in . Level ) ) if err != nil { WriteError ( nil , w , r , httptypes . NewHTTPError ( http . StatusBadRequest , " " + in . Level ) ) return } plog . Noticef ( " " , logl . String ( ) ) capnslog . SetGlobalLogLevel ( logl ) w . WriteHeader ( http . StatusNoContent ) } 
func WriteError ( lg * zap . Logger , w http . ResponseWriter , r * http . Request , err error ) { if err == nil { return } switch e := err . ( type ) { case * v2error . Error : e . WriteTo ( w ) case * httptypes . HTTPError : if et := e . WriteTo ( w ) ; et != nil { if lg != nil { lg . Debug ( " " , zap . String ( " " , r . RemoteAddr ) , zap . String ( " " , e . Error ( ) ) , zap . Error ( et ) , ) } else { plog . Debugf ( " " , et , r . RemoteAddr ) } } default : switch err { case etcdserver . ErrTimeoutDueToLeaderFail , etcdserver . ErrTimeoutDueToConnectionLost , etcdserver . ErrNotEnoughStartedMembers , etcdserver . ErrUnhealthy : if lg != nil { lg . Warn ( " " , zap . String ( " " , r . RemoteAddr ) , zap . String ( " " , err . Error ( ) ) , ) } else { mlog . MergeError ( err ) } default : if lg != nil { lg . Warn ( " " , zap . String ( " " , r . RemoteAddr ) , zap . String ( " " , err . Error ( ) ) , ) } else { mlog . MergeErrorf ( " " , err ) } } herr := httptypes . NewHTTPError ( http . StatusInternalServerError , " " ) if et := herr . WriteTo ( w ) ; et != nil { if lg != nil { lg . Debug ( " " , zap . String ( " " , r . RemoteAddr ) , zap . String ( " " , err . Error ( ) ) , zap . Error ( et ) , ) } else { plog . Debugf ( " " , et , r . RemoteAddr ) } } } } 
func ( c * RaftCluster ) MemberByName ( name string ) * Member { c . Lock ( ) defer c . Unlock ( ) var memb * Member for _ , m := range c . members { if m . Name == name { if memb != nil { if c . lg != nil { c . lg . Panic ( " " , zap . String ( " " , name ) ) } else { plog . Panicf ( " " , name ) } } memb = m } } return memb . Clone ( ) } 
func ( c * RaftCluster ) PeerURLs ( ) [ ] string { c . Lock ( ) defer c . Unlock ( ) urls := make ( [ ] string , 0 ) for _ , p := range c . members { urls = append ( urls , p . PeerURLs ... ) } sort . Strings ( urls ) return urls } 
func ( c * RaftCluster ) ValidateConfigurationChange ( cc raftpb . ConfChange ) error { members , removed := membersFromStore ( c . lg , c . v2store ) id := types . ID ( cc . NodeID ) if removed [ id ] { return ErrIDRemoved } switch cc . Type { case raftpb . ConfChangeAddNode : if members [ id ] != nil { return ErrIDExists } urls := make ( map [ string ] bool ) for _ , m := range members { for _ , u := range m . PeerURLs { urls [ u ] = true } } m := new ( Member ) if err := json . Unmarshal ( cc . Context , m ) ; err != nil { if c . lg != nil { c . lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } for _ , u := range m . PeerURLs { if urls [ u ] { return ErrPeerURLexists } } case raftpb . ConfChangeRemoveNode : if members [ id ] == nil { return ErrIDNotFound } case raftpb . ConfChangeUpdateNode : if members [ id ] == nil { return ErrIDNotFound } urls := make ( map [ string ] bool ) for _ , m := range members { if m . ID == id { continue } for _ , u := range m . PeerURLs { urls [ u ] = true } } m := new ( Member ) if err := json . Unmarshal ( cc . Context , m ) ; err != nil { if c . lg != nil { c . lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } for _ , u := range m . PeerURLs { if urls [ u ] { return ErrPeerURLexists } } default : if c . lg != nil { c . lg . Panic ( " " , zap . String ( " " , cc . Type . String ( ) ) ) } else { plog . Panicf ( " " ) } } return nil } 
func ( c * RaftCluster ) AddMember ( m * Member ) { c . Lock ( ) defer c . Unlock ( ) if c . v2store != nil { mustSaveMemberToStore ( c . v2store , m ) } if c . be != nil { mustSaveMemberToBackend ( c . be , m ) } c . members [ m . ID ] = m if c . lg != nil { c . lg . Info ( " " , zap . String ( " " , c . cid . String ( ) ) , zap . String ( " " , c . localID . String ( ) ) , zap . String ( " " , m . ID . String ( ) ) , zap . Strings ( " " , m . PeerURLs ) , ) } else { plog . Infof ( " " , m . ID , m . PeerURLs , c . cid ) } } 
func ( c * RaftCluster ) RemoveMember ( id types . ID ) { c . Lock ( ) defer c . Unlock ( ) if c . v2store != nil { mustDeleteMemberFromStore ( c . v2store , id ) } if c . be != nil { mustDeleteMemberFromBackend ( c . be , id ) } m , ok := c . members [ id ] delete ( c . members , id ) c . removed [ id ] = true if c . lg != nil { if ok { c . lg . Info ( " " , zap . String ( " " , c . cid . String ( ) ) , zap . String ( " " , c . localID . String ( ) ) , zap . String ( " " , id . String ( ) ) , zap . Strings ( " " , m . PeerURLs ) , ) } else { c . lg . Warn ( " " , zap . String ( " " , c . cid . String ( ) ) , zap . String ( " " , c . localID . String ( ) ) , zap . String ( " " , id . String ( ) ) , ) } } else { plog . Infof ( " " , id , c . cid ) } } 
func ValidateClusterAndAssignIDs ( lg * zap . Logger , local * RaftCluster , existing * RaftCluster ) error { ems := existing . Members ( ) lms := local . Members ( ) if len ( ems ) != len ( lms ) { return fmt . Errorf ( " " ) } sort . Sort ( MembersByPeerURLs ( ems ) ) sort . Sort ( MembersByPeerURLs ( lms ) ) ctx , cancel := context . WithTimeout ( context . TODO ( ) , 30 * time . Second ) defer cancel ( ) for i := range ems { if ok , err := netutil . URLStringsEqual ( ctx , lg , ems [ i ] . PeerURLs , lms [ i ] . PeerURLs ) ; ! ok { return fmt . Errorf ( " " , err ) } lms [ i ] . ID = ems [ i ] . ID } local . members = make ( map [ types . ID ] * Member ) for _ , m := range lms { local . members [ m . ID ] = m } return nil } 
func ( ti * treeIndex ) RangeSince ( key , end [ ] byte , rev int64 ) [ ] revision { keyi := & keyIndex { key : key } ti . RLock ( ) defer ti . RUnlock ( ) if end == nil { item := ti . tree . Get ( keyi ) if item == nil { return nil } keyi = item . ( * keyIndex ) return keyi . since ( ti . lg , rev ) } endi := & keyIndex { key : end } var revs [ ] revision ti . tree . AscendGreaterOrEqual ( keyi , func ( item btree . Item ) bool { if len ( endi . key ) > 0 && ! item . Less ( endi ) { return false } curKeyi := item . ( * keyIndex ) revs = append ( revs , curKeyi . since ( ti . lg , rev ) ... ) return true } ) sort . Sort ( revisions ( revs ) ) return revs } 
func ( ti * treeIndex ) Keep ( rev int64 ) map [ revision ] struct { } { available := make ( map [ revision ] struct { } ) ti . RLock ( ) defer ti . RUnlock ( ) ti . tree . Ascend ( func ( i btree . Item ) bool { keyi := i . ( * keyIndex ) keyi . keep ( rev , available ) return true } ) return available } 
func ( l * lessor ) closeRequireLeader ( ) { l . mu . Lock ( ) defer l . mu . Unlock ( ) for _ , ka := range l . keepAlives { reqIdxs := 0 if ! ok { continue } ks := md [ rpctypes . MetadataRequireLeaderKey ] if len ( ks ) < 1 || ks [ 0 ] != rpctypes . MetadataHasLeader { continue } close ( ka . chs [ i ] ) ka . chs [ i ] = nil reqIdxs ++ } if reqIdxs == 0 { continue } newCtxs := make ( [ ] context . Context , len ( newChs ) ) newIdx := 0 for i := range ka . chs { if ka . chs [ i ] == nil { continue } newChs [ newIdx ] , newCtxs [ newIdx ] = ka . chs [ i ] , ka . ctxs [ newIdx ] newIdx ++ } ka . chs , ka . ctxs = newChs , newCtxs } } 
func ( l * lessor ) resetRecv ( ) ( pb . Lease_LeaseKeepAliveClient , error ) { sctx , cancel := context . WithCancel ( l . stopCtx ) stream , err := l . remote . LeaseKeepAlive ( sctx , append ( l . callOpts , withMax ( 0 ) ) ... ) if err != nil { cancel ( ) return nil , err } l . mu . Lock ( ) defer l . mu . Unlock ( ) if l . stream != nil && l . streamCancel != nil { l . streamCancel ( ) } l . streamCancel = cancel l . stream = stream go l . sendKeepAliveLoop ( stream ) return stream , nil } 
func ( l * lessor ) recvKeepAlive ( resp * pb . LeaseKeepAliveResponse ) { karesp := & LeaseKeepAliveResponse { ResponseHeader : resp . GetHeader ( ) , ID : LeaseID ( resp . ID ) , TTL : resp . TTL , } l . mu . Lock ( ) defer l . mu . Unlock ( ) ka , ok := l . keepAlives [ karesp . ID ] if ! ok { return } if karesp . TTL <= 0 { ka . close ( ) return } ka . deadline = time . Now ( ) . Add ( time . Duration ( karesp . TTL ) * time . Second ) for _ , ch := range ka . chs { select { case ch <- karesp : default : if l . lg != nil { l . lg . Warn ( " " , zap . Int ( " " , len ( ch ) ) , zap . Int ( " " , cap ( ch ) ) , ) } } } } 
func ( l * lessor ) deadlineLoop ( ) { for { select { case <- time . After ( time . Second ) : case <- l . donec : return } now := time . Now ( ) l . mu . Lock ( ) for id , ka := range l . keepAlives { if ka . deadline . Before ( now ) { delete ( l . keepAlives , id ) } } l . mu . Unlock ( ) } } 
func ( l * lessor ) sendKeepAliveLoop ( stream pb . Lease_LeaseKeepAliveClient ) { for { var tosend [ ] LeaseID now := time . Now ( ) l . mu . Lock ( ) for id , ka := range l . keepAlives { if ka . nextKeepAlive . Before ( now ) { tosend = append ( tosend , id ) } } l . mu . Unlock ( ) for _ , id := range tosend { r := & pb . LeaseKeepAliveRequest { ID : int64 ( id ) } if err := stream . Send ( r ) ; err != nil { } } select { case <- time . After ( retryConnWait ) : case <- stream . Context ( ) . Done ( ) : return case <- l . donec : return case <- l . stopCtx . Done ( ) : return } } } 
func NewKV ( cl * v3 . Client , pfx string , opts ... concurrency . SessionOption ) ( v3 . KV , func ( ) , error ) { cctx , cancel := context . WithCancel ( cl . Ctx ( ) ) lkv := & leasingKV { cl : cl , kv : cl . KV , pfx : pfx , leases : leaseCache { revokes : make ( map [ string ] time . Time ) } , ctx : cctx , cancel : cancel , sessionOpts : opts , sessionc : make ( chan struct { } ) , } lkv . wg . Add ( 2 ) go func ( ) { defer lkv . wg . Done ( ) lkv . monitorSession ( ) } ( ) go func ( ) { defer lkv . wg . Done ( ) lkv . leases . clearOldRevokes ( cctx ) } ( ) return lkv , lkv . Close , lkv . waitSession ( cctx ) } 
func ( lkv * leasingKV ) rescind ( ctx context . Context , key string , rev int64 ) { if lkv . leases . Evict ( key ) > rev { return } cmp := v3 . Compare ( v3 . CreateRevision ( lkv . pfx + key ) , " " , rev ) op := v3 . OpDelete ( lkv . pfx + key ) for ctx . Err ( ) == nil { if _ , err := lkv . kv . Txn ( ctx ) . If ( cmp ) . Then ( op ) . Commit ( ) ; err == nil { return } } } 
func LeaseValue ( key string ) Cmp { return Cmp { Key : [ ] byte ( key ) , Target : pb . Compare_LEASE } } 
func ( cmp * Cmp ) ValueBytes ( ) [ ] byte { if tu , ok := cmp . TargetUnion . ( * pb . Compare_Value ) ; ok { return tu . Value } return nil } 
func ( cmp Cmp ) WithRange ( end string ) Cmp { cmp . RangeEnd = [ ] byte ( end ) return cmp } 
func ( cmp Cmp ) WithPrefix ( ) Cmp { cmp . RangeEnd = getPrefix ( cmp . Key ) return cmp } 
func mustInt64 ( val interface { } ) int64 { if v , ok := val . ( int64 ) ; ok { return v } if v , ok := val . ( int ) ; ok { return int64 ( v ) } panic ( " " ) } 
func mustInt64orLeaseID ( val interface { } ) int64 { if v , ok := val . ( LeaseID ) ; ok { return int64 ( v ) } return mustInt64 ( val ) } 
func ( gw * gRPCWatcher ) Next ( ) ( [ ] * naming . Update , error ) { if gw . wch == nil { } if gw . err != nil { return nil , gw . err } if ! ok { gw . err = status . Error ( codes . Unavailable , ErrWatcherClosed . Error ( ) ) return nil , gw . err } if gw . err = wr . Err ( ) ; gw . err != nil { return nil , gw . err } updates := make ( [ ] * naming . Update , 0 , len ( wr . Events ) ) for _ , e := range wr . Events { var jupdate naming . Update var err error switch e . Type { case etcd . EventTypePut : err = json . Unmarshal ( e . Kv . Value , & jupdate ) jupdate . Op = naming . Add case etcd . EventTypeDelete : err = json . Unmarshal ( e . PrevKv . Value , & jupdate ) jupdate . Op = naming . Delete default : continue } if err == nil { updates = append ( updates , & jupdate ) } } return updates , nil } 
func getJournalWriteSyncer ( ) ( zapcore . WriteSyncer , error ) { jw , err := logutil . NewJournalWriter ( os . Stderr ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return zapcore . AddSync ( jw ) , nil } 
func newKV ( store * store , nodePath string , value string , createdIndex uint64 , parent * node , expireTime time . Time ) * node { return & node { Path : nodePath , CreatedIndex : createdIndex , ModifiedIndex : createdIndex , Parent : parent , store : store , ExpireTime : expireTime , Value : value , } } 
func newDir ( store * store , nodePath string , createdIndex uint64 , parent * node , expireTime time . Time ) * node { return & node { Path : nodePath , CreatedIndex : createdIndex , ModifiedIndex : createdIndex , Parent : parent , ExpireTime : expireTime , Children : make ( map [ string ] * node ) , store : store , } } 
func ( n * node ) IsHidden ( ) bool { _ , name := path . Split ( n . Path ) return name [ 0 ] == '_' } 
func ( n * node ) Read ( ) ( string , * v2error . Error ) { if n . IsDir ( ) { return " " , v2error . NewError ( v2error . EcodeNotFile , " " , n . store . CurrentIndex ) } return n . Value , nil } 
func ( n * node ) Write ( value string , index uint64 ) * v2error . Error { if n . IsDir ( ) { return v2error . NewError ( v2error . EcodeNotFile , " " , n . store . CurrentIndex ) } n . Value = value n . ModifiedIndex = index return nil } 
func ( n * node ) List ( ) ( [ ] * node , * v2error . Error ) { if ! n . IsDir ( ) { return nil , v2error . NewError ( v2error . EcodeNotDir , " " , n . store . CurrentIndex ) } nodes := make ( [ ] * node , len ( n . Children ) ) i := 0 for _ , node := range n . Children { nodes [ i ] = node i ++ } return nodes , nil } 
func ( n * node ) GetChild ( name string ) ( * node , * v2error . Error ) { if ! n . IsDir ( ) { return nil , v2error . NewError ( v2error . EcodeNotDir , n . Path , n . store . CurrentIndex ) } child , ok := n . Children [ name ] if ok { return child , nil } return nil , nil } 
func ( n * node ) Add ( child * node ) * v2error . Error { if ! n . IsDir ( ) { return v2error . NewError ( v2error . EcodeNotDir , " " , n . store . CurrentIndex ) } _ , name := path . Split ( child . Path ) if _ , ok := n . Children [ name ] ; ok { return v2error . NewError ( v2error . EcodeNodeExist , " " , n . store . CurrentIndex ) } n . Children [ name ] = child return nil } 
func ( n * node ) Remove ( dir , recursive bool , callback func ( path string ) ) * v2error . Error { if ! n . IsDir ( ) { } if callback != nil { callback ( n . Path ) } if ! n . IsPermanent ( ) { n . store . ttlKeyHeap . remove ( n ) } return nil } if ! dir { } if len ( n . Children ) != 0 && ! recursive { } for _ , child := range n . Children { } if n . Parent != nil && n . Parent . Children [ name ] == n { delete ( n . Parent . Children , name ) if callback != nil { callback ( n . Path ) } if ! n . IsPermanent ( ) { n . store . ttlKeyHeap . remove ( n ) } } return nil } 
func ( n * node ) Compare ( prevValue string , prevIndex uint64 ) ( ok bool , which int ) { indexMatch := prevIndex == 0 || n . ModifiedIndex == prevIndex valueMatch := prevValue == " " || n . Value == prevValue ok = valueMatch && indexMatch switch { case valueMatch && indexMatch : which = CompareMatch case indexMatch && ! valueMatch : which = CompareValueNotMatch case valueMatch && ! indexMatch : which = CompareIndexNotMatch default : which = CompareNotMatch } return ok , which } 
func ( n * node ) Clone ( ) * node { if ! n . IsDir ( ) { newkv := newKV ( n . store , n . Path , n . Value , n . CreatedIndex , n . Parent , n . ExpireTime ) newkv . ModifiedIndex = n . ModifiedIndex return newkv } clone := newDir ( n . store , n . Path , n . CreatedIndex , n . Parent , n . ExpireTime ) clone . ModifiedIndex = n . ModifiedIndex for key , child := range n . Children { clone . Children [ key ] = child . Clone ( ) } return clone } 
func ( n * node ) recoverAndclean ( ) { if n . IsDir ( ) { for _ , child := range n . Children { child . Parent = n child . store = n . store child . recoverAndclean ( ) } } if ! n . ExpireTime . IsZero ( ) { n . store . ttlKeyHeap . push ( n ) } } 
func isConnectedToQuorumSince ( transport rafthttp . Transporter , since time . Time , self types . ID , members [ ] * membership . Member ) bool { return numConnectedSince ( transport , since , self , members ) >= ( len ( members ) / 2 ) + 1 } 
func isConnectedSince ( transport rafthttp . Transporter , since time . Time , remote types . ID ) bool { t := transport . ActiveSince ( remote ) return ! t . IsZero ( ) && t . Before ( since ) } 
func numConnectedSince ( transport rafthttp . Transporter , since time . Time , self types . ID , members [ ] * membership . Member ) int { connectedNum := 0 for _ , m := range members { if m . ID == self || isConnectedSince ( transport , since , m . ID ) { connectedNum ++ } } return connectedNum } 
func longestConnected ( tp rafthttp . Transporter , membs [ ] types . ID ) ( types . ID , bool ) { var longest types . ID var oldest time . Time for _ , id := range membs { tm := tp . ActiveSince ( id ) if tm . IsZero ( ) { } if oldest . IsZero ( ) { longest = id } if tm . Before ( oldest ) { oldest = tm longest = id } } if uint64 ( longest ) == 0 { return longest , false } return longest , true } 
func ( d * decoder ) isTornEntry ( data [ ] byte ) bool { if len ( d . brs ) != 1 { return false } fileOff := d . lastValidOff + frameSizeBytes curOff := 0 chunks := [ ] [ ] byte { } if chunkLen > len ( data ) - curOff { chunkLen = len ( data ) - curOff } chunks = append ( chunks , data [ curOff : curOff + chunkLen ] ) fileOff += int64 ( chunkLen ) curOff += chunkLen } for _ , v := range sect { if v != 0 { isZero = false break } } if isZero { return true } } return false } 
func StartMockServersOnNetwork ( count int , network string ) ( ms * MockServers , err error ) { switch network { case " " : return startMockServersTcp ( count ) case " " : return startMockServersUnix ( count ) default : return nil , fmt . Errorf ( " " , network ) } } 
func ( ms * MockServers ) StartAt ( idx int ) ( err error ) { ms . mu . Lock ( ) defer ms . mu . Unlock ( ) if ms . Servers [ idx ] . ln == nil { ms . Servers [ idx ] . ln , err = net . Listen ( ms . Servers [ idx ] . Network , ms . Servers [ idx ] . Address ) if err != nil { return fmt . Errorf ( " " , err ) } } svr := grpc . NewServer ( ) pb . RegisterKVServer ( svr , & mockKVServer { } ) ms . Servers [ idx ] . GrpcServer = svr ms . wg . Add ( 1 ) go func ( svr * grpc . Server , l net . Listener ) { svr . Serve ( l ) } ( ms . Servers [ idx ] . GrpcServer , ms . Servers [ idx ] . ln ) return nil } 
func ( ms * MockServers ) StopAt ( idx int ) { ms . mu . Lock ( ) defer ms . mu . Unlock ( ) if ms . Servers [ idx ] . ln == nil { return } ms . Servers [ idx ] . GrpcServer . Stop ( ) ms . Servers [ idx ] . GrpcServer = nil ms . Servers [ idx ] . ln = nil ms . wg . Done ( ) } 
func ( ms * MockServers ) Stop ( ) { for idx := range ms . Servers { ms . StopAt ( idx ) } ms . wg . Wait ( ) } 
func NewCheckCommand ( ) * cobra . Command { cc := & cobra . Command { Use : " " , Short : " " , } cc . AddCommand ( NewCheckPerfCommand ( ) ) cc . AddCommand ( NewCheckDatascaleCommand ( ) ) return cc } 
func NewCheckPerfCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : newCheckPerfCommand , } cmd . Flags ( ) . StringVar ( & checkPerfPrefix , " " , " " , " " ) cmd . Flags ( ) . BoolVar ( & autoCompact , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & autoDefrag , " " , false , " " ) return cmd } 
func newCheckPerfCommand ( cmd * cobra . Command , args [ ] string ) { var checkPerfAlias = map [ string ] string { " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , } model , ok := checkPerfAlias [ checkPerfLoad ] if ! ok { ExitWithError ( ExitBadFeature , fmt . Errorf ( " " , checkPerfLoad ) ) } cfg := checkPerfCfgMap [ model ] requests := make ( chan v3 . Op , cfg . clients ) limit := rate . NewLimiter ( rate . Limit ( cfg . limit ) , 1 ) cc := clientConfigFromCmd ( cmd ) clients := make ( [ ] * v3 . Client , cfg . clients ) for i := 0 ; i < cfg . clients ; i ++ { clients [ i ] = cc . mustClient ( ) } ctx , cancel := context . WithTimeout ( context . Background ( ) , time . Duration ( cfg . duration ) * time . Second ) resp , err := clients [ 0 ] . Get ( ctx , checkPerfPrefix , v3 . WithPrefix ( ) , v3 . WithLimit ( 1 ) ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } if len ( resp . Kvs ) > 0 { ExitWithError ( ExitInvalidInput , fmt . Errorf ( " " , checkPerfPrefix , checkPerfPrefix ) ) } ksize , vsize := 256 , 1024 k , v := make ( [ ] byte , ksize ) , string ( make ( [ ] byte , vsize ) ) bar := pb . New ( cfg . duration ) bar . Format ( " " ) bar . Start ( ) r := report . NewReport ( " " ) var wg sync . WaitGroup wg . Add ( len ( clients ) ) for i := range clients { go func ( c * v3 . Client ) { defer wg . Done ( ) for op := range requests { st := time . Now ( ) _ , derr := c . Do ( context . Background ( ) , op ) r . Results ( ) <- report . Result { Err : derr , Start : st , End : time . Now ( ) } } } ( clients [ i ] ) } go func ( ) { cctx , ccancel := context . WithTimeout ( context . Background ( ) , time . Duration ( cfg . duration ) * time . Second ) defer ccancel ( ) for limit . Wait ( cctx ) == nil { binary . PutVarint ( k , rand . Int63n ( math . MaxInt64 ) ) requests <- v3 . OpPut ( checkPerfPrefix + string ( k ) , v ) } close ( requests ) } ( ) go func ( ) { for i := 0 ; i < cfg . duration ; i ++ { time . Sleep ( time . Second ) bar . Add ( 1 ) } bar . Finish ( ) } ( ) sc := r . Stats ( ) wg . Wait ( ) close ( r . Results ( ) ) s := <- sc ctx , cancel = context . WithTimeout ( context . Background ( ) , 30 * time . Second ) dresp , err := clients [ 0 ] . Delete ( ctx , checkPerfPrefix , v3 . WithPrefix ( ) ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } if autoCompact { compact ( clients [ 0 ] , dresp . Header . Revision ) } if autoDefrag { for _ , ep := range clients [ 0 ] . Endpoints ( ) { defrag ( clients [ 0 ] , ep ) } } ok = true if len ( s . ErrorDist ) != 0 { fmt . Println ( " " ) for k , v := range s . ErrorDist { fmt . Printf ( " \n " , k , v ) } ok = false } if s . RPS / float64 ( cfg . limit ) <= 0.9 { fmt . Printf ( " \n " , int ( s . RPS ) + 1 ) ok = false } else { fmt . Printf ( " \n " , int ( s . RPS ) + 1 ) } if s . Slowest > 0.5 { ok = false } else { fmt . Printf ( " \n " , s . Slowest ) } if s . Stddev > 0.1 { ok = false } else { fmt . Printf ( " \n " , s . Stddev ) } if ok { fmt . Println ( " " ) } else { fmt . Println ( " " ) os . Exit ( ExitError ) } } 
func NewCheckDatascaleCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : newCheckDatascaleCommand , } cmd . Flags ( ) . StringVar ( & checkDatascaleLoad , " " , " " , " " ) cmd . Flags ( ) . StringVar ( & checkDatascalePrefix , " " , " " , " " ) cmd . Flags ( ) . BoolVar ( & autoCompact , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & autoDefrag , " " , false , " " ) return cmd } 
func newCheckDatascaleCommand ( cmd * cobra . Command , args [ ] string ) { var checkDatascaleAlias = map [ string ] string { " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , " " : " " , } model , ok := checkDatascaleAlias [ checkDatascaleLoad ] if ! ok { ExitWithError ( ExitBadFeature , fmt . Errorf ( " " , checkDatascaleLoad ) ) } cfg := checkDatascaleCfgMap [ model ] requests := make ( chan v3 . Op , cfg . clients ) cc := clientConfigFromCmd ( cmd ) clients := make ( [ ] * v3 . Client , cfg . clients ) for i := 0 ; i < cfg . clients ; i ++ { clients [ i ] = cc . mustClient ( ) } if errEndpoints != nil { ExitWithError ( ExitError , errEndpoints ) } ctx , cancel := context . WithCancel ( context . Background ( ) ) resp , err := clients [ 0 ] . Get ( ctx , checkDatascalePrefix , v3 . WithPrefix ( ) , v3 . WithLimit ( 1 ) ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } if len ( resp . Kvs ) > 0 { ExitWithError ( ExitInvalidInput , fmt . Errorf ( " " , checkDatascalePrefix , checkDatascalePrefix ) ) } ksize , vsize := 512 , 512 k , v := make ( [ ] byte , ksize ) , string ( make ( [ ] byte , vsize ) ) r := report . NewReport ( " " ) var wg sync . WaitGroup wg . Add ( len ( clients ) ) if bytesBefore == 0 { fmt . Println ( " " ) os . Exit ( ExitError ) } fmt . Println ( fmt . Sprintf ( " " , cfg . limit , cfg . kvSize , cfg . clients ) ) bar := pb . New ( cfg . limit ) bar . Format ( " " ) bar . Start ( ) for i := range clients { go func ( c * v3 . Client ) { defer wg . Done ( ) for op := range requests { st := time . Now ( ) _ , derr := c . Do ( context . Background ( ) , op ) r . Results ( ) <- report . Result { Err : derr , Start : st , End : time . Now ( ) } bar . Increment ( ) } } ( clients [ i ] ) } go func ( ) { for i := 0 ; i < cfg . limit ; i ++ { binary . PutVarint ( k , rand . Int63n ( math . MaxInt64 ) ) requests <- v3 . OpPut ( checkDatascalePrefix + string ( k ) , v ) } close ( requests ) } ( ) sc := r . Stats ( ) wg . Wait ( ) close ( r . Results ( ) ) bar . Finish ( ) s := <- sc if bytesAfter == 0 { fmt . Println ( " " ) os . Exit ( ExitError ) } dresp , derr := clients [ 0 ] . Delete ( ctx , checkDatascalePrefix , v3 . WithPrefix ( ) ) defer cancel ( ) if derr != nil { ExitWithError ( ExitError , derr ) } if autoCompact { compact ( clients [ 0 ] , dresp . Header . Revision ) } if autoDefrag { for _ , ep := range clients [ 0 ] . Endpoints ( ) { defrag ( clients [ 0 ] , ep ) } } if bytesAfter == 0 { fmt . Println ( " " ) os . Exit ( ExitError ) } bytesUsed := bytesAfter - bytesBefore mbUsed := bytesUsed / ( 1024 * 1024 ) if len ( s . ErrorDist ) != 0 { fmt . Println ( " " ) for k , v := range s . ErrorDist { fmt . Printf ( " \n " , k , v ) } os . Exit ( ExitError ) } else { fmt . Println ( fmt . Sprintf ( " " , strconv . FormatFloat ( mbUsed , 'f' , 2 , 64 ) ) ) } } 
func NewGetCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : getCommandFunc , } cmd . Flags ( ) . StringVar ( & getConsistency , " " , " " , " " ) cmd . Flags ( ) . StringVar ( & getSortOrder , " " , " " , " " ) cmd . Flags ( ) . StringVar ( & getSortTarget , " " , " " , " " ) cmd . Flags ( ) . Int64Var ( & getLimit , " " , 0 , " " ) cmd . Flags ( ) . BoolVar ( & getPrefix , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & getFromKey , " " , false , " " ) cmd . Flags ( ) . Int64Var ( & getRev , " " , 0 , " " ) cmd . Flags ( ) . BoolVar ( & getKeysOnly , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & printValueOnly , " " , false , `Only write values when using the "simple" output format` ) return cmd } 
func getCommandFunc ( cmd * cobra . Command , args [ ] string ) { key , opts := getGetOp ( args ) ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . Get ( ctx , key , opts ... ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } if printValueOnly { dp , simple := ( display ) . ( * simplePrinter ) if ! simple { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } dp . valueOnly = true } display . Get ( * resp ) } 
func NewGetCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Flags : [ ] cli . Flag { cli . BoolFlag { Name : " " , Usage : " " } , cli . BoolFlag { Name : " " , Usage : " " } , } , Action : func ( c * cli . Context ) error { getCommandFunc ( c , mustNewKeyAPI ( c ) ) return nil } , } } 
func getCommandFunc ( c * cli . Context , ki client . KeysAPI ) { if len ( c . Args ( ) ) == 0 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } key := c . Args ( ) [ 0 ] sorted := c . Bool ( " " ) quorum := c . Bool ( " " ) ctx , cancel := contextWithTotalTimeout ( c ) resp , err := ki . Get ( ctx , key , & client . GetOptions { Sort : sorted , Quorum : quorum } ) cancel ( ) if err != nil { handleError ( c , ExitServerError , err ) } if resp . Node . Dir { fmt . Fprintln ( os . Stderr , fmt . Sprintf ( " " , resp . Node . Key ) ) os . Exit ( 1 ) } printResponseKey ( resp , c . GlobalString ( " " ) ) } 
func NewMember ( name string , peerURLs types . URLs , clusterName string , now * time . Time ) * Member { m := & Member { RaftAttributes : RaftAttributes { PeerURLs : peerURLs . StringSlice ( ) } , Attributes : Attributes { Name : name } , } var b [ ] byte sort . Strings ( m . PeerURLs ) for _ , p := range m . PeerURLs { b = append ( b , [ ] byte ( p ) ... ) } b = append ( b , [ ] byte ( clusterName ) ... ) if now != nil { b = append ( b , [ ] byte ( fmt . Sprintf ( " " , now . Unix ( ) ) ) ... ) } hash := sha1 . Sum ( b ) m . ID = types . ID ( binary . BigEndian . Uint64 ( hash [ : 8 ] ) ) return m } 
func ( m * Member ) PickPeerURL ( ) string { if len ( m . PeerURLs ) == 0 { panic ( " " ) } return m . PeerURLs [ rand . Intn ( len ( m . PeerURLs ) ) ] } 
func HandleMetricsHealth ( mux * http . ServeMux , srv etcdserver . ServerV2 ) { mux . Handle ( PathMetrics , promhttp . Handler ( ) ) mux . Handle ( PathHealth , NewHealthHandler ( func ( ) Health { return checkHealth ( srv ) } ) ) } 
func NewHealthHandler ( hfunc func ( ) Health ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { if r . Method != http . MethodGet { w . Header ( ) . Set ( " " , http . MethodGet ) http . Error ( w , " " , http . StatusMethodNotAllowed ) return } h := hfunc ( ) d , _ := json . Marshal ( h ) if h . Health != " " { http . Error ( w , string ( d ) , http . StatusServiceUnavailable ) return } w . WriteHeader ( http . StatusOK ) w . Write ( d ) } } 
func checkHealth ( srv etcdserver . ServerV2 ) Health { h := Health { Health : " " } as := srv . Alarms ( ) if len ( as ) > 0 { h . Health = " " } if h . Health == " " { if uint64 ( srv . Leader ( ) ) == raft . None { h . Health = " " } } if h . Health == " " { ctx , cancel := context . WithTimeout ( context . Background ( ) , time . Second ) _ , err := srv . Do ( ctx , etcdserverpb . Request { Method : " " } ) cancel ( ) if err != nil { h . Health = " " } } if h . Health == " " { healthSuccess . Inc ( ) } else { healthFailed . Inc ( ) } return h } 
func NewRemoveCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Flags : [ ] cli . Flag { cli . BoolFlag { Name : " " , Usage : " " } , cli . BoolFlag { Name : " " , Usage : " " } , cli . StringFlag { Name : " " , Value : " " , Usage : " " } , cli . IntFlag { Name : " " , Value : 0 , Usage : " " } , } , Action : func ( c * cli . Context ) error { rmCommandFunc ( c , mustNewKeyAPI ( c ) ) return nil } , } } 
func rmCommandFunc ( c * cli . Context , ki client . KeysAPI ) { if len ( c . Args ( ) ) == 0 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } key := c . Args ( ) [ 0 ] recursive := c . Bool ( " " ) dir := c . Bool ( " " ) prevValue := c . String ( " " ) prevIndex := c . Int ( " " ) ctx , cancel := contextWithTotalTimeout ( c ) resp , err := ki . Delete ( ctx , key , & client . DeleteOptions { PrevIndex : uint64 ( prevIndex ) , PrevValue : prevValue , Dir : dir , Recursive : recursive } ) cancel ( ) if err != nil { handleError ( c , ExitServerError , err ) } if ! resp . Node . Dir || c . GlobalString ( " " ) != " " { printResponseKey ( resp , c . GlobalString ( " " ) ) } } 
func checkIntervals ( reqs [ ] * pb . RequestOp ) ( map [ string ] struct { } , adt . IntervalTree , error ) { var dels adt . IntervalTree if ! ok { continue } dreq := tv . RequestDeleteRange if dreq == nil { continue } var iv adt . Interval if len ( dreq . RangeEnd ) != 0 { iv = adt . NewStringAffineInterval ( string ( dreq . Key ) , string ( dreq . RangeEnd ) ) } else { iv = adt . NewStringAffinePoint ( string ( dreq . Key ) ) } dels . Insert ( iv , struct { } { } ) } for _ , req := range reqs { tv , ok := req . Request . ( * pb . RequestOp_RequestTxn ) if ! ok { continue } putsThen , delsThen , err := checkIntervals ( tv . RequestTxn . Success ) if err != nil { return nil , dels , err } putsElse , delsElse , err := checkIntervals ( tv . RequestTxn . Failure ) if err != nil { return nil , dels , err } for k := range putsThen { if _ , ok := puts [ k ] ; ok { return nil , dels , rpctypes . ErrGRPCDuplicateKey } if dels . Intersects ( adt . NewStringAffinePoint ( k ) ) { return nil , dels , rpctypes . ErrGRPCDuplicateKey } puts [ k ] = struct { } { } } for k := range putsElse { if _ , ok := puts [ k ] ; ok { } } if dels . Intersects ( adt . NewStringAffinePoint ( k ) ) { return nil , dels , rpctypes . ErrGRPCDuplicateKey } puts [ k ] = struct { } { } } dels . Union ( delsThen , adt . NewStringAffineInterval ( " \x00 " , " " ) ) dels . Union ( delsElse , adt . NewStringAffineInterval ( " \x00 " , " " ) ) } if ! ok || tv . RequestPut == nil { continue } k := string ( tv . RequestPut . Key ) if _ , ok := puts [ k ] ; ok { return nil , dels , rpctypes . ErrGRPCDuplicateKey } if dels . Intersects ( adt . NewStringAffinePoint ( k ) ) { return nil , dels , rpctypes . ErrGRPCDuplicateKey } puts [ k ] = struct { } { } } return puts , dels , nil } 
func ReportEventReceived ( n int ) { pendingEventsGauge . Sub ( float64 ( n ) ) totalEventsCounter . Add ( float64 ( n ) ) } 
func RegisterKVHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterKVHandlerClient ( ctx , mux , etcdserverpb . NewKVClient ( conn ) ) } 
func RegisterKVHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client etcdserverpb . KVClient ) error { mux . Handle ( " " , pattern_KV_Range_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_KV_Range_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_KV_Range_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_KV_Put_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_KV_Put_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_KV_Put_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_KV_DeleteRange_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_KV_DeleteRange_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_KV_DeleteRange_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_KV_Txn_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_KV_Txn_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_KV_Txn_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_KV_Compact_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_KV_Compact_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_KV_Compact_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func RegisterWatchHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterWatchHandlerClient ( ctx , mux , etcdserverpb . NewWatchClient ( conn ) ) } 
func RegisterWatchHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client etcdserverpb . WatchClient ) error { mux . Handle ( " " , pattern_Watch_Watch_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Watch_Watch_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Watch_Watch_0 ( ctx , mux , outboundMarshaler , w , req , func ( ) ( proto . Message , error ) { return resp . Recv ( ) } , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func RegisterLeaseHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterLeaseHandlerClient ( ctx , mux , etcdserverpb . NewLeaseClient ( conn ) ) } 
func RegisterLeaseHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client etcdserverpb . LeaseClient ) error { mux . Handle ( " " , pattern_Lease_LeaseGrant_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseGrant_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseGrant_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lease_LeaseRevoke_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseRevoke_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseRevoke_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lease_LeaseRevoke_1 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseRevoke_1 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseRevoke_1 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lease_LeaseKeepAlive_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseKeepAlive_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseKeepAlive_0 ( ctx , mux , outboundMarshaler , w , req , func ( ) ( proto . Message , error ) { return resp . Recv ( ) } , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lease_LeaseTimeToLive_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseTimeToLive_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseTimeToLive_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lease_LeaseTimeToLive_1 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseTimeToLive_1 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseTimeToLive_1 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lease_LeaseLeases_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseLeases_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseLeases_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lease_LeaseLeases_1 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lease_LeaseLeases_1 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lease_LeaseLeases_1 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func RegisterClusterHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterClusterHandlerClient ( ctx , mux , etcdserverpb . NewClusterClient ( conn ) ) } 
func RegisterClusterHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client etcdserverpb . ClusterClient ) error { mux . Handle ( " " , pattern_Cluster_MemberAdd_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Cluster_MemberAdd_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Cluster_MemberAdd_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Cluster_MemberRemove_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Cluster_MemberRemove_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Cluster_MemberRemove_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Cluster_MemberUpdate_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Cluster_MemberUpdate_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Cluster_MemberUpdate_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Cluster_MemberList_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Cluster_MemberList_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Cluster_MemberList_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func RegisterMaintenanceHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterMaintenanceHandlerClient ( ctx , mux , etcdserverpb . NewMaintenanceClient ( conn ) ) } 
func RegisterMaintenanceHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client etcdserverpb . MaintenanceClient ) error { mux . Handle ( " " , pattern_Maintenance_Alarm_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Maintenance_Alarm_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Maintenance_Alarm_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Maintenance_Status_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Maintenance_Status_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Maintenance_Status_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Maintenance_Defragment_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Maintenance_Defragment_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Maintenance_Defragment_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Maintenance_Hash_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Maintenance_Hash_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Maintenance_Hash_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Maintenance_HashKV_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Maintenance_HashKV_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Maintenance_HashKV_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Maintenance_Snapshot_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Maintenance_Snapshot_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Maintenance_Snapshot_0 ( ctx , mux , outboundMarshaler , w , req , func ( ) ( proto . Message , error ) { return resp . Recv ( ) } , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Maintenance_MoveLeader_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Maintenance_MoveLeader_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Maintenance_MoveLeader_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func RegisterAuthHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterAuthHandlerClient ( ctx , mux , etcdserverpb . NewAuthClient ( conn ) ) } 
func RegisterAuthHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client etcdserverpb . AuthClient ) error { mux . Handle ( " " , pattern_Auth_AuthEnable_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_AuthEnable_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_AuthEnable_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_AuthDisable_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_AuthDisable_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_AuthDisable_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_Authenticate_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_Authenticate_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_Authenticate_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_UserAdd_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_UserAdd_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_UserAdd_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_UserGet_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_UserGet_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_UserGet_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_UserList_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_UserList_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_UserList_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_UserDelete_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_UserDelete_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_UserDelete_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_UserChangePassword_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_UserChangePassword_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_UserChangePassword_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_UserGrantRole_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_UserGrantRole_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_UserGrantRole_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_UserRevokeRole_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_UserRevokeRole_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_UserRevokeRole_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_RoleAdd_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_RoleAdd_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_RoleAdd_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_RoleGet_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_RoleGet_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_RoleGet_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_RoleList_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_RoleList_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_RoleList_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_RoleDelete_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_RoleDelete_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_RoleDelete_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_RoleGrantPermission_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_RoleGrantPermission_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_RoleGrantPermission_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Auth_RoleRevokePermission_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Auth_RoleRevokePermission_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Auth_RoleRevokePermission_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func startEtcd ( cfg * embed . Config ) ( <- chan struct { } , <- chan error , error ) { e , err := embed . StartEtcd ( cfg ) if err != nil { return nil , nil , err } osutil . RegisterInterruptHandler ( e . Close ) select { case <- e . Server . ReadyNotify ( ) : return e . Server . StopNotify ( ) , e . Err ( ) , nil } 
func startProxy ( cfg * config ) error { lg := cfg . ec . GetLogger ( ) if lg != nil { lg . Info ( " " ) } else { plog . Notice ( " " ) } clientTLSInfo := cfg . ec . ClientTLSInfo if clientTLSInfo . Empty ( ) { } clientTLSInfo . InsecureSkipVerify = cfg . ec . ClientAutoTLS cfg . ec . PeerTLSInfo . InsecureSkipVerify = cfg . ec . PeerAutoTLS pt , err := transport . NewTimeoutTransport ( clientTLSInfo , time . Duration ( cfg . cp . ProxyDialTimeoutMs ) * time . Millisecond , time . Duration ( cfg . cp . ProxyReadTimeoutMs ) * time . Millisecond , time . Duration ( cfg . cp . ProxyWriteTimeoutMs ) * time . Millisecond , ) if err != nil { return err } pt . MaxIdleConnsPerHost = httpproxy . DefaultMaxIdleConnsPerHost if err = cfg . ec . PeerSelfCert ( ) ; err != nil { if lg != nil { lg . Fatal ( " " , zap . Error ( err ) ) } else { plog . Fatalf ( " " , err ) } } tr , err := transport . NewTimeoutTransport ( cfg . ec . PeerTLSInfo , time . Duration ( cfg . cp . ProxyDialTimeoutMs ) * time . Millisecond , time . Duration ( cfg . cp . ProxyReadTimeoutMs ) * time . Millisecond , time . Duration ( cfg . cp . ProxyWriteTimeoutMs ) * time . Millisecond , ) if err != nil { return err } cfg . ec . Dir = filepath . Join ( cfg . ec . Dir , " " ) err = os . MkdirAll ( cfg . ec . Dir , fileutil . PrivateDirMode ) if err != nil { return err } var peerURLs [ ] string clusterfile := filepath . Join ( cfg . ec . Dir , " " ) b , err := ioutil . ReadFile ( clusterfile ) switch { case err == nil : if cfg . ec . Durl != " " { if lg != nil { lg . Warn ( " " , zap . String ( " " , clusterfile ) , ) } else { plog . Warningf ( " " , clusterfile ) } } if cfg . ec . DNSCluster != " " { if lg != nil { lg . Warn ( " " , zap . String ( " " , clusterfile ) , ) } else { plog . Warningf ( " " , clusterfile ) } } urls := struct { PeerURLs [ ] string } { } err = json . Unmarshal ( b , & urls ) if err != nil { return err } peerURLs = urls . PeerURLs if lg != nil { lg . Info ( " " , zap . Strings ( " " , peerURLs ) , zap . String ( " " , clusterfile ) , ) } else { plog . Infof ( " " , peerURLs , clusterfile ) } case os . IsNotExist ( err ) : var urlsmap types . URLsMap urlsmap , _ , err = cfg . ec . PeerURLsMapAndToken ( " " ) if err != nil { return fmt . Errorf ( " " , err ) } if cfg . ec . Durl != " " { var s string s , err = v2discovery . GetCluster ( lg , cfg . ec . Durl , cfg . ec . Dproxy ) if err != nil { return err } if urlsmap , err = types . NewURLsMap ( s ) ; err != nil { return err } } peerURLs = urlsmap . URLs ( ) if lg != nil { lg . Info ( " " , zap . Strings ( " " , peerURLs ) ) } else { plog . Infof ( " " , peerURLs ) } default : return err } clientURLs := [ ] string { } uf := func ( ) [ ] string { gcls , gerr := etcdserver . GetClusterFromRemotePeers ( lg , peerURLs , tr ) if gerr != nil { if lg != nil { lg . Warn ( " " , zap . Strings ( " " , peerURLs ) , zap . Error ( gerr ) , ) } else { plog . Warningf ( " " , gerr ) } return [ ] string { } } clientURLs = gcls . ClientURLs ( ) urls := struct { PeerURLs [ ] string } { gcls . PeerURLs ( ) } b , jerr := json . Marshal ( urls ) if jerr != nil { if lg != nil { lg . Warn ( " " , zap . Error ( jerr ) ) } else { plog . Warningf ( " " , jerr ) } return clientURLs } err = pkgioutil . WriteAndSyncFile ( clusterfile + " " , b , 0600 ) if err != nil { if lg != nil { lg . Warn ( " " , zap . Error ( err ) ) } else { plog . Warningf ( " " , err ) } return clientURLs } err = os . Rename ( clusterfile + " " , clusterfile ) if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , clusterfile ) , zap . Error ( err ) , ) } else { plog . Warningf ( " " , err ) } return clientURLs } if ! reflect . DeepEqual ( gcls . PeerURLs ( ) , peerURLs ) { if lg != nil { lg . Info ( " " , zap . Strings ( " " , peerURLs ) , zap . Strings ( " " , gcls . PeerURLs ( ) ) , ) } else { plog . Noticef ( " " , peerURLs , gcls . PeerURLs ( ) ) } } peerURLs = gcls . PeerURLs ( ) return clientURLs } ph := httpproxy . NewHandler ( pt , uf , time . Duration ( cfg . cp . ProxyFailureWaitMs ) * time . Millisecond , time . Duration ( cfg . cp . ProxyRefreshIntervalMs ) * time . Millisecond ) ph = embed . WrapCORS ( cfg . ec . CORS , ph ) if cfg . isReadonlyProxy ( ) { ph = httpproxy . NewReadonlyHandler ( ph ) } for _ , u := range cfg . ec . LCUrls { cHosts = append ( cHosts , u . Host ) cTLS = cTLS || u . Scheme == " " } for _ , u := range cfg . ec . ACUrls { cHosts = append ( cHosts , u . Host ) cTLS = cTLS || u . Scheme == " " } listenerTLS := cfg . ec . ClientTLSInfo if cfg . ec . ClientAutoTLS && cTLS { listenerTLS , err = transport . SelfCert ( cfg . ec . GetLogger ( ) , filepath . Join ( cfg . ec . Dir , " " ) , cHosts ) if err != nil { if lg != nil { lg . Fatal ( " " , zap . Error ( err ) ) } else { plog . Fatalf ( " " , err ) } } } if err != nil { return err } host := u . String ( ) go func ( ) { if lg != nil { lg . Info ( " " , zap . String ( " " , host ) ) } else { plog . Infof ( " " , host ) } mux := http . NewServeMux ( ) etcdhttp . HandlePrometheus ( mux ) mux . Handle ( " " , ph ) plog . Fatal ( http . Serve ( l , mux ) ) } ( ) } return nil } 
func identifyDataDirOrDie ( lg * zap . Logger , dir string ) dirType { names , err := fileutil . ReadDir ( dir ) if err != nil { if os . IsNotExist ( err ) { return dirEmpty } if lg != nil { lg . Fatal ( " " , zap . String ( " " , dir ) , zap . Error ( err ) ) } else { plog . Fatalf ( " " , dir ) } } var m , p bool for _ , name := range names { switch dirType ( name ) { case dirMember : m = true case dirProxy : p = true default : if lg != nil { lg . Warn ( " " , zap . String ( " " , name ) , zap . String ( " " , dir ) , ) } else { plog . Warningf ( " " , name , dir ) } } } if m && p { if lg != nil { lg . Fatal ( " " ) } else { plog . Fatal ( " " ) } } if m { return dirMember } if p { return dirProxy } return dirEmpty } 
func Repair ( lg * zap . Logger , dirpath string ) bool { f , err := openLast ( lg , dirpath ) if err != nil { return false } defer f . Close ( ) if lg != nil { lg . Info ( " " , zap . String ( " " , f . Name ( ) ) ) } else { plog . Noticef ( " " , f . Name ( ) ) } rec := & walpb . Record { } decoder := newDecoder ( f ) for { lastOffset := decoder . lastOffset ( ) err := decoder . decode ( rec ) switch err { case nil : } decoder . updateCRC ( rec . Crc ) } continue case io . EOF : if lg != nil { lg . Info ( " " , zap . String ( " " , f . Name ( ) ) , zap . Error ( io . EOF ) ) } return true case io . ErrUnexpectedEOF : bf , bferr := os . Create ( f . Name ( ) + " " ) if bferr != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , f . Name ( ) + " " ) , zap . Error ( bferr ) ) } else { plog . Errorf ( " " , f . Name ( ) ) } return false } defer bf . Close ( ) if _ , err = f . Seek ( 0 , io . SeekStart ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , f . Name ( ) ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , f . Name ( ) ) } return false } if _ , err = io . Copy ( bf , f ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , f . Name ( ) + " " ) , zap . String ( " " , f . Name ( ) ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , f . Name ( ) ) } return false } if err = f . Truncate ( lastOffset ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , f . Name ( ) ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , f . Name ( ) ) } return false } if err = fileutil . Fsync ( f . File ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , f . Name ( ) ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , f . Name ( ) ) } return false } if lg != nil { lg . Info ( " " , zap . String ( " " , f . Name ( ) ) , zap . Error ( io . ErrUnexpectedEOF ) ) } return true default : if lg != nil { lg . Warn ( " " , zap . String ( " " , f . Name ( ) ) , zap . Error ( err ) ) } else { plog . Errorf ( " " , err ) } return false } } } 
func openLast ( lg * zap . Logger , dirpath string ) ( * fileutil . LockedFile , error ) { names , err := readWALNames ( lg , dirpath ) if err != nil { return nil , err } last := filepath . Join ( dirpath , names [ len ( names ) - 1 ] ) return fileutil . LockFile ( last , os . O_RDWR , fileutil . PrivateFileMode ) } 
func ( b * bridge ) ioCopy ( dst io . Writer , src io . Reader ) ( err error ) { buf := make ( [ ] byte , 32 * 1024 ) for { select { case <- b . blackholec : io . Copy ( ioutil . Discard , src ) return nil default : } nr , er := src . Read ( buf ) if nr > 0 { nw , ew := dst . Write ( buf [ 0 : nr ] ) if ew != nil { return ew } if nr != nw { return io . ErrShortWrite } } if er != nil { err = er break } } return err } 
func ( l * leader ) gotLeader ( ) { l . mu . Lock ( ) defer l . mu . Unlock ( ) select { case <- l . leaderc : l . leaderc = make ( chan struct { } ) default : } } 
func ( l * leader ) lostNotify ( ) <- chan struct { } { l . mu . RLock ( ) defer l . mu . RUnlock ( ) return l . leaderc } 
func newGRPCProxyCommand ( ) * cobra . Command { lpc := & cobra . Command { Use : " " , Short : " " , } lpc . AddCommand ( newGRPCProxyStartCommand ( ) ) return lpc } 
func NewMemberCommand ( ) * cobra . Command { mc := & cobra . Command { Use : " " , Short : " " , } mc . AddCommand ( NewMemberAddCommand ( ) ) mc . AddCommand ( NewMemberRemoveCommand ( ) ) mc . AddCommand ( NewMemberUpdateCommand ( ) ) mc . AddCommand ( NewMemberListCommand ( ) ) return mc } 
func NewMemberAddCommand ( ) * cobra . Command { cc := & cobra . Command { Use : " " , Short : " " , Run : memberAddCommandFunc , } cc . Flags ( ) . StringVar ( & memberPeerURLs , " " , " " , " " ) return cc } 
func NewMemberRemoveCommand ( ) * cobra . Command { cc := & cobra . Command { Use : " " , Short : " " , Run : memberRemoveCommandFunc , } return cc } 
func NewMemberUpdateCommand ( ) * cobra . Command { cc := & cobra . Command { Use : " " , Short : " " , Run : memberUpdateCommandFunc , } cc . Flags ( ) . StringVar ( & memberPeerURLs , " " , " " , " " ) return cc } 
func NewMemberListCommand ( ) * cobra . Command { cc := & cobra . Command { Use : " " , Short : " " , Long : `When --write-out is set to simple, this command prints out comma-separated member lists for each endpoint. The items in the lists are ID, Status, Name, Peer Addrs, Client Addrs. ` , Run : memberListCommandFunc , } return cc } 
func memberAddCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) < 1 { ExitWithError ( ExitBadArgs , errors . New ( " " ) ) } if len ( args ) > 1 { ev := " " for _ , s := range args { if strings . HasPrefix ( strings . ToLower ( s ) , " " ) { ev += fmt . Sprintf ( `, did you mean --peer-urls=%s` , s ) } } ExitWithError ( ExitBadArgs , errors . New ( ev ) ) } newMemberName := args [ 0 ] if len ( memberPeerURLs ) == 0 { ExitWithError ( ExitBadArgs , errors . New ( " " ) ) } urls := strings . Split ( memberPeerURLs , " " ) ctx , cancel := commandCtx ( cmd ) cli := mustClientFromCmd ( cmd ) resp , err := cli . MemberAdd ( ctx , urls ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } newID := resp . Member . ID display . MemberAdd ( * resp ) if _ , ok := ( display ) . ( * simplePrinter ) ; ok { ctx , cancel = commandCtx ( cmd ) listResp , err := cli . MemberList ( ctx ) } if listResp . Header . MemberId == resp . Header . MemberId { break } if gerr != nil { ExitWithError ( ExitError , err ) } resp . Header . MemberId = gresp . Header . MemberId listResp , err = cli . MemberList ( ctx ) } cancel ( ) conf := [ ] string { } for _ , memb := range listResp . Members { for _ , u := range memb . PeerURLs { n := memb . Name if memb . ID == newID { n = newMemberName } conf = append ( conf , fmt . Sprintf ( " " , n , u ) ) } } fmt . Print ( " \n " ) fmt . Printf ( " \n " , newMemberName ) fmt . Printf ( " \n " , strings . Join ( conf , " " ) ) fmt . Printf ( " \n " , memberPeerURLs ) fmt . Printf ( " \" \" \n " ) } } 
func memberRemoveCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } id , err := strconv . ParseUint ( args [ 0 ] , 16 , 64 ) if err != nil { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " , err ) ) } ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . MemberRemove ( ctx , id ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . MemberRemove ( id , * resp ) } 
func memberUpdateCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } id , err := strconv . ParseUint ( args [ 0 ] , 16 , 64 ) if err != nil { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " , err ) ) } if len ( memberPeerURLs ) == 0 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } urls := strings . Split ( memberPeerURLs , " " ) ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . MemberUpdate ( ctx , id , urls ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . MemberUpdate ( id , * resp ) } 
func memberListCommandFunc ( cmd * cobra . Command , args [ ] string ) { ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . MemberList ( ctx ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . MemberList ( * resp ) } 
func Create ( lg * zap . Logger , dirpath string , metadata [ ] byte ) ( * WAL , error ) { if Exist ( dirpath ) { return nil , os . ErrExist } if fileutil . Exist ( tmpdirpath ) { if err := os . RemoveAll ( tmpdirpath ) ; err != nil { return nil , err } } if err := fileutil . CreateDirAll ( tmpdirpath ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , tmpdirpath ) , zap . String ( " " , dirpath ) , zap . Error ( err ) , ) } return nil , err } p := filepath . Join ( tmpdirpath , walName ( 0 , 0 ) ) f , err := fileutil . LockFile ( p , os . O_WRONLY | os . O_CREATE , fileutil . PrivateFileMode ) if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , p ) , zap . Error ( err ) , ) } return nil , err } if _ , err = f . Seek ( 0 , io . SeekEnd ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , p ) , zap . Error ( err ) , ) } return nil , err } if err = fileutil . Preallocate ( f . File , SegmentSizeBytes , true ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , p ) , zap . Int64 ( " " , SegmentSizeBytes ) , zap . Error ( err ) , ) } return nil , err } w := & WAL { lg : lg , dir : dirpath , metadata : metadata , } w . encoder , err = newFileEncoder ( f . File , 0 ) if err != nil { return nil , err } w . locks = append ( w . locks , f ) if err = w . saveCrc ( 0 ) ; err != nil { return nil , err } if err = w . encoder . encode ( & walpb . Record { Type : metadataType , Data : metadata } ) ; err != nil { return nil , err } if err = w . SaveSnapshot ( walpb . Snapshot { } ) ; err != nil { return nil , err } if w , err = w . renameWAL ( tmpdirpath ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , tmpdirpath ) , zap . String ( " " , w . dir ) , zap . Error ( err ) , ) } return nil , err } if perr != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , filepath . Dir ( w . dir ) ) , zap . String ( " " , w . dir ) , zap . Error ( perr ) , ) } return nil , perr } if perr = fileutil . Fsync ( pdir ) ; perr != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , filepath . Dir ( w . dir ) ) , zap . String ( " " , w . dir ) , zap . Error ( perr ) , ) } return nil , perr } if perr = pdir . Close ( ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , filepath . Dir ( w . dir ) ) , zap . String ( " " , w . dir ) , zap . Error ( perr ) , ) } return nil , perr } return w , nil } 
func Open ( lg * zap . Logger , dirpath string , snap walpb . Snapshot ) ( * WAL , error ) { w , err := openAtIndex ( lg , dirpath , snap , true ) if err != nil { return nil , err } if w . dirFile , err = fileutil . OpenDir ( w . dir ) ; err != nil { return nil , err } return w , nil } 
func OpenForRead ( lg * zap . Logger , dirpath string , snap walpb . Snapshot ) ( * WAL , error ) { return openAtIndex ( lg , dirpath , snap , false ) } 
func ( w * WAL ) ReadAll ( ) ( metadata [ ] byte , state raftpb . HardState , ents [ ] raftpb . Entry , err error ) { w . mu . Lock ( ) defer w . mu . Unlock ( ) rec := & walpb . Record { } decoder := w . decoder var match bool for err = decoder . decode ( rec ) ; err == nil ; err = decoder . decode ( rec ) { switch rec . Type { case entryType : e := mustUnmarshalEntry ( rec . Data ) if e . Index > w . start . Index { ents = append ( ents [ : e . Index - w . start . Index - 1 ] , e ) } w . enti = e . Index case stateType : state = mustUnmarshalState ( rec . Data ) case metadataType : if metadata != nil && ! bytes . Equal ( metadata , rec . Data ) { state . Reset ( ) return nil , state , nil , ErrMetadataConflict } metadata = rec . Data case crcType : crc := decoder . crc . Sum32 ( ) return nil , state , nil , ErrCRCMismatch } decoder . updateCRC ( rec . Crc ) case snapshotType : var snap walpb . Snapshot pbutil . MustUnmarshal ( & snap , rec . Data ) if snap . Index == w . start . Index { if snap . Term != w . start . Term { state . Reset ( ) return nil , state , nil , ErrSnapshotMismatch } match = true } default : state . Reset ( ) return nil , state , nil , fmt . Errorf ( " " , rec . Type ) } } switch w . tail ( ) { case nil : return nil , state , nil , err } default : return nil , state , nil , err } } if err = fileutil . ZeroToEnd ( w . tail ( ) . File ) ; err != nil { return nil , state , nil , err } } err = nil if ! match { err = ErrSnapshotNotFound } w . readClose = nil } w . start = walpb . Snapshot { } w . metadata = metadata if w . tail ( ) != nil { if err != nil { return } } w . decoder = nil return metadata , state , ents , err } 
func Verify ( lg * zap . Logger , walDir string , snap walpb . Snapshot ) error { var metadata [ ] byte var err error var match bool rec := & walpb . Record { } names , nameIndex , err := selectWALFiles ( lg , walDir , snap ) if err != nil { return err } if err != nil { return err } for err = decoder . decode ( rec ) ; err == nil ; err = decoder . decode ( rec ) { switch rec . Type { case metadataType : if metadata != nil && ! bytes . Equal ( metadata , rec . Data ) { return ErrMetadataConflict } metadata = rec . Data case crcType : crc := decoder . crc . Sum32 ( ) } decoder . updateCRC ( rec . Crc ) case snapshotType : var loadedSnap walpb . Snapshot pbutil . MustUnmarshal ( & loadedSnap , rec . Data ) if loadedSnap . Index == snap . Index { if loadedSnap . Term != snap . Term { return ErrSnapshotMismatch } match = true } } } if closer != nil { closer ( ) } } if ! match { return ErrSnapshotNotFound } return nil } 
func ( w * WAL ) cut ( ) error { if serr != nil { return serr } if err := w . tail ( ) . Truncate ( off ) ; err != nil { return err } if err := w . sync ( ) ; err != nil { return err } fpath := filepath . Join ( w . dir , walName ( w . seq ( ) + 1 , w . enti + 1 ) ) if err != nil { return err } prevCrc := w . encoder . crc . Sum32 ( ) w . encoder , err = newFileEncoder ( w . tail ( ) . File , prevCrc ) if err != nil { return err } if err = w . saveCrc ( prevCrc ) ; err != nil { return err } if err = w . encoder . encode ( & walpb . Record { Type : metadataType , Data : w . metadata } ) ; err != nil { return err } if err = w . saveState ( & w . state ) ; err != nil { return err } } off , err = w . tail ( ) . Seek ( 0 , io . SeekCurrent ) if err != nil { return err } if err = os . Rename ( newTail . Name ( ) , fpath ) ; err != nil { return err } if err = fileutil . Fsync ( w . dirFile ) ; err != nil { return err } if newTail , err = fileutil . LockFile ( fpath , os . O_WRONLY , fileutil . PrivateFileMode ) ; err != nil { return err } if _ , err = newTail . Seek ( off , io . SeekStart ) ; err != nil { return err } w . locks [ len ( w . locks ) - 1 ] = newTail prevCrc = w . encoder . crc . Sum32 ( ) w . encoder , err = newFileEncoder ( w . tail ( ) . File , prevCrc ) if err != nil { return err } if w . lg != nil { w . lg . Info ( " " , zap . String ( " " , fpath ) ) } else { plog . Infof ( " " , fpath ) } return nil } 
func ( w * WAL ) Close ( ) error { w . mu . Lock ( ) defer w . mu . Unlock ( ) if w . fp != nil { w . fp . Close ( ) w . fp = nil } if w . tail ( ) != nil { if err := w . sync ( ) ; err != nil { return err } } for _ , l := range w . locks { if l == nil { continue } if err := l . Close ( ) ; err != nil { if w . lg != nil { w . lg . Warn ( " " , zap . Error ( err ) ) } else { plog . Errorf ( " " , err ) } } } return w . dirFile . Close ( ) } 
func ( w * watcher ) notify ( e * Event , originalPath bool , deleted bool ) bool { } return true } return false } 
func ( w * watcher ) Remove ( ) { w . hub . mutex . Lock ( ) defer w . hub . mutex . Unlock ( ) close ( w . eventChan ) if w . remove != nil { w . remove ( ) } } 
func Preallocate ( f * os . File , sizeInBytes int64 , extendFile bool ) error { if sizeInBytes == 0 { } if extendFile { return preallocExtend ( f , sizeInBytes ) } return preallocFixed ( f , sizeInBytes ) } 
func ( s * v2v3Store ) mkPathDepth ( nodePath string , depth int ) string { normalForm := path . Clean ( path . Join ( " " , nodePath ) ) n := strings . Count ( normalForm , " " ) + depth return fmt . Sprintf ( " " , s . pfx , n , normalForm ) } 
func ( s * v2v3Store ) mkV2Node ( kv * mvccpb . KeyValue ) * v2store . NodeExtern { if kv == nil { return nil } n := & v2store . NodeExtern { Key : s . mkNodePath ( string ( kv . Key ) ) , Dir : kv . Key [ len ( kv . Key ) - 1 ] == '/' , CreatedIndex : mkV2Rev ( kv . CreateRevision ) , ModifiedIndex : mkV2Rev ( kv . ModRevision ) , } if ! n . Dir { v := string ( kv . Value ) n . Value = & v } return n } 
func prevKeyFromPuts ( resp * clientv3 . TxnResponse ) * mvccpb . KeyValue { for _ , r := range resp . Responses { pkv := r . GetResponsePut ( ) . PrevKv if pkv != nil && pkv . CreateRevision > 0 { return pkv } } return nil } 
func NewWeightedReport ( r Report , precision string ) Report { return & weightedReport { baseReport : r , report : newReport ( precision ) , results : make ( chan Result , 16 ) , } } 
func HandleHealth ( mux * http . ServeMux , c * clientv3 . Client ) { mux . Handle ( etcdhttp . PathHealth , etcdhttp . NewHealthHandler ( func ( ) etcdhttp . Health { return checkHealth ( c ) } ) ) } 
func NewURLsMap ( s string ) ( URLsMap , error ) { m := parse ( s ) cl := URLsMap { } for name , urls := range m { us , err := NewURLs ( urls ) if err != nil { return nil , err } cl [ name ] = us } return cl , nil } 
func NewURLsMapFromStringMap ( m map [ string ] string , sep string ) ( URLsMap , error ) { var err error um := URLsMap { } for k , v := range m { um [ k ] , err = NewURLs ( strings . Split ( v , sep ) ) if err != nil { return nil , err } } return um , nil } 
func ( c URLsMap ) String ( ) string { var pairs [ ] string for name , urls := range c { for _ , url := range urls { pairs = append ( pairs , fmt . Sprintf ( " " , name , url . String ( ) ) ) } } sort . Strings ( pairs ) return strings . Join ( pairs , " " ) } 
func ( c URLsMap ) URLs ( ) [ ] string { var urls [ ] string for _ , us := range c { for _ , u := range us { urls = append ( urls , u . String ( ) ) } } sort . Strings ( urls ) return urls } 
func parse ( s string ) map [ string ] [ ] string { m := make ( map [ string ] [ ] string ) for s != " " { key := s if i := strings . IndexAny ( key , " " ) ; i >= 0 { key , s = key [ : i ] , key [ i + 1 : ] } else { s = " " } if key == " " { continue } value := " " if i := strings . Index ( key , " " ) ; i >= 0 { key , value = key [ : i ] , key [ i + 1 : ] } m [ key ] = append ( m [ key ] , value ) } return m } 
func NewClientHandler ( lg * zap . Logger , server etcdserver . ServerPeer , timeout time . Duration ) http . Handler { mux := http . NewServeMux ( ) etcdhttp . HandleBasic ( mux , server ) handleV2 ( lg , mux , server , timeout ) return requestLogger ( lg , mux ) } 
func parseKeyRequest ( r * http . Request , clock clockwork . Clock ) ( etcdserverpb . Request , bool , error ) { var noValueOnSuccess bool emptyReq := etcdserverpb . Request { } err := r . ParseForm ( ) if err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidForm , err . Error ( ) , ) } if ! strings . HasPrefix ( r . URL . Path , keysPrefix ) { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidForm , " " , ) } p := path . Join ( etcdserver . StoreKeysPrefix , r . URL . Path [ len ( keysPrefix ) : ] ) var pIdx , wIdx uint64 if pIdx , err = getUint64 ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeIndexNaN , `invalid value for "prevIndex"` , ) } if wIdx , err = getUint64 ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeIndexNaN , `invalid value for "waitIndex"` , ) } var rec , sort , wait , dir , quorum , stream bool if rec , err = getBool ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , `invalid value for "recursive"` , ) } if sort , err = getBool ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , `invalid value for "sorted"` , ) } if wait , err = getBool ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , `invalid value for "wait"` , ) } } if quorum , err = getBool ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , `invalid value for "quorum"` , ) } if stream , err = getBool ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , `invalid value for "stream"` , ) } if wait && r . Method != " " { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , `"wait" can only be used with GET requests` , ) } pV := r . FormValue ( " " ) if _ , ok := r . Form [ " " ] ; ok && pV == " " { return emptyReq , false , v2error . NewRequestError ( v2error . EcodePrevValueRequired , `"prevValue" cannot be empty` , ) } if noValueOnSuccess , err = getBool ( r . Form , " " ) ; err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , `invalid value for "noValueOnSuccess"` , ) } if len ( r . FormValue ( " " ) ) > 0 { i , err := getUint64 ( r . Form , " " ) if err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeTTLNaN , `invalid value for "ttl"` , ) } ttl = & i } if _ , ok := r . Form [ " " ] ; ok { bv , err := getBool ( r . Form , " " ) if err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , " " , ) } pe = & bv } if _ , ok := r . Form [ " " ] ; ok { bv , err := getBool ( r . Form , " " ) if err != nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeInvalidField , " " , ) } refresh = & bv if refresh != nil && * refresh { val := r . FormValue ( " " ) if _ , ok := r . Form [ " " ] ; ok && val != " " { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeRefreshValue , `A value was provided on a refresh` , ) } if ttl == nil { return emptyReq , false , v2error . NewRequestError ( v2error . EcodeRefreshTTLRequired , `No TTL value set` , ) } } } rr := etcdserverpb . Request { Method : r . Method , Path : p , Val : r . FormValue ( " " ) , Dir : dir , PrevValue : pV , PrevIndex : pIdx , PrevExist : pe , Wait : wait , Since : wIdx , Recursive : rec , Sorted : sort , Quorum : quorum , Stream : stream , } if pe != nil { rr . PrevExist = pe } if refresh != nil { rr . Refresh = refresh } rr . Expiration = clock . Now ( ) . Add ( expr ) . UnixNano ( ) } return rr , noValueOnSuccess , nil } 
func writeKeyEvent ( w http . ResponseWriter , resp etcdserver . Response , noValueOnSuccess bool ) error { ev := resp . Event if ev == nil { return errors . New ( " " ) } w . Header ( ) . Set ( " " , " " ) w . Header ( ) . Set ( " " , fmt . Sprint ( ev . EtcdIndex ) ) w . Header ( ) . Set ( " " , fmt . Sprint ( resp . Index ) ) w . Header ( ) . Set ( " " , fmt . Sprint ( resp . Term ) ) if ev . IsCreated ( ) { w . WriteHeader ( http . StatusCreated ) } ev = trimEventPrefix ( ev , etcdserver . StoreKeysPrefix ) if noValueOnSuccess && ( ev . Action == v2store . Set || ev . Action == v2store . CompareAndSwap || ev . Action == v2store . Create || ev . Action == v2store . Update ) { ev . Node = nil ev . PrevNode = nil } return json . NewEncoder ( w ) . Encode ( ev ) } 
func writeKeyError ( lg * zap . Logger , w http . ResponseWriter , err error ) { if err == nil { return } switch e := err . ( type ) { case * v2error . Error : e . WriteTo ( w ) default : switch err { case etcdserver . ErrTimeoutDueToLeaderFail , etcdserver . ErrTimeoutDueToConnectionLost : if lg != nil { lg . Warn ( " " , zap . String ( " " , err . Error ( ) ) , ) } else { mlog . MergeError ( err ) } default : if lg != nil { lg . Warn ( " " , zap . String ( " " , err . Error ( ) ) , ) } else { mlog . MergeErrorf ( " " , err ) } } ee := v2error . NewError ( v2error . EcodeRaftInternal , err . Error ( ) , 0 ) ee . WriteTo ( w ) } } 
func getUint64 ( form url . Values , key string ) ( i uint64 , err error ) { if vals , ok := form [ key ] ; ok { i , err = strconv . ParseUint ( vals [ 0 ] , 10 , 64 ) } return } 
func getBool ( form url . Values , key string ) ( b bool , err error ) { if vals , ok := form [ key ] ; ok { b , err = strconv . ParseBool ( vals [ 0 ] ) } return } 
func trimPrefix ( p , prefix string ) ( s string ) { s = strings . TrimPrefix ( p , prefix ) s = strings . TrimPrefix ( s , " " ) return } 
func waitDeletes ( ctx context . Context , client * v3 . Client , pfx string , maxCreateRev int64 ) ( * pb . ResponseHeader , error ) { getOpts := append ( v3 . WithLastCreate ( ) , v3 . WithMaxCreateRev ( maxCreateRev ) ) for { resp , err := client . Get ( ctx , pfx , getOpts ... ) if err != nil { return nil , err } if len ( resp . Kvs ) == 0 { return resp . Header , nil } lastKey := string ( resp . Kvs [ 0 ] . Key ) if err = waitDelete ( ctx , client , lastKey , resp . Header . Revision ) ; err != nil { return nil , err } } } 
func AddOutputPaths ( cfg zap . Config , outputPaths , errorOutputPaths [ ] string ) zap . Config { outputs := make ( map [ string ] struct { } ) for _ , v := range cfg . OutputPaths { outputs [ v ] = struct { } { } } for _ , v := range outputPaths { outputs [ v ] = struct { } { } } outputSlice := make ( [ ] string , 0 ) if _ , ok := outputs [ " " ] ; ok { } else { for k := range outputs { outputSlice = append ( outputSlice , k ) } } cfg . OutputPaths = outputSlice sort . Strings ( cfg . OutputPaths ) errOutputs := make ( map [ string ] struct { } ) for _ , v := range cfg . ErrorOutputPaths { errOutputs [ v ] = struct { } { } } for _ , v := range errorOutputPaths { errOutputs [ v ] = struct { } { } } errOutputSlice := make ( [ ] string , 0 ) if _ , ok := errOutputs [ " " ] ; ok { } else { for k := range errOutputs { errOutputSlice = append ( errOutputSlice , k ) } } cfg . ErrorOutputPaths = errOutputSlice sort . Strings ( cfg . ErrorOutputPaths ) return cfg } 
func NewConfig ( ) * Config { lpurl , _ := url . Parse ( DefaultListenPeerURLs ) apurl , _ := url . Parse ( DefaultInitialAdvertisePeerURLs ) lcurl , _ := url . Parse ( DefaultListenClientURLs ) acurl , _ := url . Parse ( DefaultAdvertiseClientURLs ) cfg := & Config { MaxSnapFiles : DefaultMaxSnapshots , MaxWalFiles : DefaultMaxWALs , Name : DefaultName , SnapshotCount : etcdserver . DefaultSnapshotCount , SnapshotCatchUpEntries : etcdserver . DefaultSnapshotCatchUpEntries , MaxTxnOps : DefaultMaxTxnOps , MaxRequestBytes : DefaultMaxRequestBytes , GRPCKeepAliveMinTime : DefaultGRPCKeepAliveMinTime , GRPCKeepAliveInterval : DefaultGRPCKeepAliveInterval , GRPCKeepAliveTimeout : DefaultGRPCKeepAliveTimeout , TickMs : 100 , ElectionMs : 1000 , InitialElectionTickAdvance : true , LPUrls : [ ] url . URL { * lpurl } , LCUrls : [ ] url . URL { * lcurl } , APUrls : [ ] url . URL { * apurl } , ACUrls : [ ] url . URL { * acurl } , ClusterState : ClusterStateFlagNew , InitialClusterToken : " " , StrictReconfigCheck : DefaultStrictReconfigCheck , Metrics : " " , EnableV2 : DefaultEnableV2 , CORS : map [ string ] struct { } { " " : { } } , HostWhitelist : map [ string ] struct { } { " " : { } } , AuthToken : " " , BcryptCost : uint ( bcrypt . DefaultCost ) , PreVote : false , cfg . InitialCluster = cfg . InitialClusterFromName ( cfg . Name ) return cfg } 
func ( cfg * Config ) Validate ( ) error { if err := cfg . setupLogging ( ) ; err != nil { return err } if err := checkBindURLs ( cfg . LPUrls ) ; err != nil { return err } if err := checkBindURLs ( cfg . LCUrls ) ; err != nil { return err } if err := checkBindURLs ( cfg . ListenMetricsUrls ) ; err != nil { return err } if err := checkHostURLs ( cfg . APUrls ) ; err != nil { addrs := cfg . getAPURLs ( ) return fmt . Errorf ( `--initial-advertise-peer-urls %q must be "host:port" (%v)` , strings . Join ( addrs , " " ) , err ) } if err := checkHostURLs ( cfg . ACUrls ) ; err != nil { addrs := cfg . getACURLs ( ) return fmt . Errorf ( `--advertise-client-urls %q must be "host:port" (%v)` , strings . Join ( addrs , " " ) , err ) } for _ , v := range [ ] bool { cfg . Durl != " " , cfg . InitialCluster != " " , cfg . DNSCluster != " " } { if v { nSet ++ } } if cfg . ClusterState != ClusterStateFlagNew && cfg . ClusterState != ClusterStateFlagExisting { return fmt . Errorf ( " " , cfg . ClusterState ) } if nSet > 1 { return ErrConflictBootstrapFlags } if cfg . TickMs <= 0 { return fmt . Errorf ( " " , cfg . TickMs ) } if cfg . ElectionMs <= 0 { return fmt . Errorf ( " " , cfg . ElectionMs ) } if 5 * cfg . TickMs > cfg . ElectionMs { return fmt . Errorf ( " " , cfg . ElectionMs , cfg . TickMs ) } if cfg . ElectionMs > maxElectionMs { return fmt . Errorf ( " " , cfg . ElectionMs , maxElectionMs ) } } switch cfg . AutoCompactionMode { case " " : case CompactorModeRevision , CompactorModePeriodic : default : return fmt . Errorf ( " " , cfg . AutoCompactionMode ) } return nil } 
func ( cfg * Config ) PeerURLsMapAndToken ( which string ) ( urlsmap types . URLsMap , token string , err error ) { token = cfg . InitialClusterToken switch { case cfg . Durl != " " : urlsmap = types . URLsMap { } token = cfg . Durl case cfg . DNSCluster != " " : clusterStrs , cerr := cfg . GetDNSClusterNames ( ) lg := cfg . logger if cerr != nil { if lg != nil { lg . Warn ( " " , zap . Error ( cerr ) ) } else { plog . Errorf ( " " , cerr ) } return nil , " " , cerr } for _ , s := range clusterStrs { if lg != nil { lg . Info ( " " , zap . String ( " " , s ) ) } else { plog . Noticef ( " " , s ) } } clusterStr := strings . Join ( clusterStrs , " " ) if strings . Contains ( clusterStr , " " ) && cfg . PeerTLSInfo . TrustedCAFile == " " { cfg . PeerTLSInfo . ServerName = cfg . DNSCluster } urlsmap , err = types . NewURLsMap ( clusterStr ) } } default : } return urlsmap , token , err } 
func ( cfg * Config ) GetDNSClusterNames ( ) ( [ ] string , error ) { var ( clusterStrs [ ] string cerr error serviceNameSuffix string ) if cfg . DNSClusterServiceName != " " { serviceNameSuffix = " " + cfg . DNSClusterServiceName } lg := cfg . GetLogger ( ) if cerr != nil { clusterStrs = make ( [ ] string , 0 ) } if lg != nil { lg . Info ( " " , zap . String ( " " , " " ) , zap . String ( " " , " " + serviceNameSuffix ) , zap . String ( " " , cfg . Name ) , zap . String ( " " , cfg . DNSCluster ) , zap . Strings ( " " , cfg . getAPURLs ( ) ) , zap . Strings ( " " , clusterStrs ) , zap . Error ( cerr ) , ) } defaultHTTPClusterStrs , httpCerr := srv . GetCluster ( " " , " " + serviceNameSuffix , cfg . Name , cfg . DNSCluster , cfg . APUrls ) if httpCerr != nil { clusterStrs = append ( clusterStrs , defaultHTTPClusterStrs ... ) } if lg != nil { lg . Info ( " " , zap . String ( " " , " " ) , zap . String ( " " , " " + serviceNameSuffix ) , zap . String ( " " , cfg . Name ) , zap . String ( " " , cfg . DNSCluster ) , zap . Strings ( " " , cfg . getAPURLs ( ) ) , zap . Strings ( " " , clusterStrs ) , zap . Error ( httpCerr ) , ) } return clusterStrs , cerr } 
func ( cfg * Config ) UpdateDefaultClusterFromName ( defaultInitialCluster string ) ( string , error ) { if defaultHostname == " " || defaultHostStatus != nil { } return " " , defaultHostStatus } used := false pip , pport := cfg . LPUrls [ 0 ] . Hostname ( ) , cfg . LPUrls [ 0 ] . Port ( ) if cfg . defaultPeerHost ( ) && pip == " " { cfg . APUrls [ 0 ] = url . URL { Scheme : cfg . APUrls [ 0 ] . Scheme , Host : fmt . Sprintf ( " " , defaultHostname , pport ) } used = true } } cip , cport := cfg . LCUrls [ 0 ] . Hostname ( ) , cfg . LCUrls [ 0 ] . Port ( ) if cfg . defaultClientHost ( ) && cip == " " { cfg . ACUrls [ 0 ] = url . URL { Scheme : cfg . ACUrls [ 0 ] . Scheme , Host : fmt . Sprintf ( " " , defaultHostname , cport ) } used = true } dhost := defaultHostname if ! used { dhost = " " } return dhost , defaultHostStatus } 
func checkBindURLs ( urls [ ] url . URL ) error { for _ , url := range urls { if url . Scheme == " " || url . Scheme == " " { continue } host , _ , err := net . SplitHostPort ( url . Host ) if err != nil { return err } if host == " " { } if net . ParseIP ( host ) == nil { return fmt . Errorf ( " " , url . String ( ) ) } } return nil } 
func GetCluster ( serviceScheme , service , name , dns string , apurls types . URLs ) ( [ ] string , error ) { tempName := int ( 0 ) tcp2ap := make ( map [ string ] url . URL ) if err != nil { return nil , err } tcp2ap [ tcpAddr . String ( ) ] = url } stringParts := [ ] string { } updateNodeMap := func ( service , scheme string ) error { _ , addrs , err := lookupSRV ( service , " " , dns ) if err != nil { return err } for _ , srv := range addrs { port := fmt . Sprintf ( " " , srv . Port ) host := net . JoinHostPort ( srv . Target , port ) tcpAddr , terr := resolveTCPAddr ( " " , host ) if terr != nil { err = terr continue } n := " " url , ok := tcp2ap [ tcpAddr . String ( ) ] if ok { n = name } if n == " " { n = fmt . Sprintf ( " " , tempName ) tempName ++ } urlHost := net . JoinHostPort ( shortHost , port ) if ok && url . Scheme != scheme { err = fmt . Errorf ( " " , scheme + " " + urlHost , service , url . String ( ) ) } else { stringParts = append ( stringParts , fmt . Sprintf ( " " , n , scheme , urlHost ) ) } } if len ( stringParts ) == 0 { return err } return nil } err := updateNodeMap ( service , serviceScheme ) if err != nil { return nil , fmt . Errorf ( " " , service , err ) } return stringParts , nil } 
func GetClient ( service , domain string , serviceName string ) ( * SRVClients , error ) { var urls [ ] * url . URL var srvs [ ] * net . SRV updateURLs := func ( service , scheme string ) error { _ , addrs , err := lookupSRV ( service , " " , domain ) if err != nil { return err } for _ , srv := range addrs { urls = append ( urls , & url . URL { Scheme : scheme , Host : net . JoinHostPort ( srv . Target , fmt . Sprintf ( " " , srv . Port ) ) , } ) } srvs = append ( srvs , addrs ... ) return nil } errHTTPS := updateURLs ( GetSRVService ( service , serviceName , " " ) , " " ) errHTTP := updateURLs ( GetSRVService ( service , serviceName , " " ) , " " ) if errHTTPS != nil && errHTTP != nil { return nil , fmt . Errorf ( " " , errHTTPS , errHTTP ) } endpoints := make ( [ ] string , len ( urls ) ) for i := range urls { endpoints [ i ] = urls [ i ] . String ( ) } return & SRVClients { Endpoints : endpoints , SRVs : srvs } , nil } 
func GetSRVService ( service , serviceName string , scheme string ) ( SRVService string ) { if scheme == " " { service = fmt . Sprintf ( " " , service ) } if serviceName != " " { return fmt . Sprintf ( " " , service , serviceName ) } return service } 
func ReadDir ( d string , opts ... ReadDirOption ) ( [ ] string , error ) { op := & ReadDirOp { } op . applyOpts ( opts ) dir , err := os . Open ( d ) if err != nil { return nil , err } defer dir . Close ( ) names , err := dir . Readdirnames ( - 1 ) if err != nil { return nil , err } sort . Strings ( names ) if op . ext != " " { tss := make ( [ ] string , 0 ) for _ , v := range names { if filepath . Ext ( v ) == op . ext { tss = append ( tss , v ) } } names = tss } return names , nil } 
func NewJournalWriter ( wr io . Writer ) ( io . Writer , error ) { return & journalWriter { Writer : wr } , systemd . DialJournal ( ) } 
func ( s * EtcdServer ) createMergedSnapshotMessage ( m raftpb . Message , snapt , snapi uint64 , confState raftpb . ConfState ) snap . Message { d , err := clone . SaveNoCopy ( ) if err != nil { if lg := s . getLogger ( ) ; lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } dbsnap := s . be . Snapshot ( ) m . Snapshot = snapshot return * snap . NewMessage ( m , rc , dbsnap . Size ( ) ) } 
func endpointMemoryMetrics ( host string ) float64 { residentMemoryKey := " " var residentMemoryValue string if ! strings . HasPrefix ( host , `http: } url := host + " " resp , err := http . Get ( url ) if err != nil { fmt . Println ( fmt . Sprintf ( " " , err ) ) return 0.0 } byts , readerr := ioutil . ReadAll ( resp . Body ) resp . Body . Close ( ) if readerr != nil { fmt . Println ( fmt . Sprintf ( " " , url , readerr ) ) return 0.0 } for _ , line := range strings . Split ( string ( byts ) , " \n " ) { if strings . HasPrefix ( line , residentMemoryKey ) { residentMemoryValue = strings . TrimSpace ( strings . TrimPrefix ( line , residentMemoryKey ) ) break } } if residentMemoryValue == " " { fmt . Println ( fmt . Sprintf ( " " , residentMemoryKey ) ) return 0.0 } residentMemoryBytes , parseErr := strconv . ParseFloat ( residentMemoryValue , 64 ) if parseErr != nil { fmt . Println ( fmt . Sprintf ( " " , parseErr ) ) return 0.0 } return residentMemoryBytes } 
func compact ( c * v3 . Client , rev int64 ) { fmt . Printf ( " \n " , rev ) ctx , cancel := context . WithTimeout ( context . Background ( ) , 30 * time . Second ) _ , err := c . Compact ( ctx , rev , v3 . WithCompactPhysical ( ) ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } fmt . Printf ( " \n " , rev ) } 
func defrag ( c * v3 . Client , ep string ) { fmt . Printf ( " \n " , ep ) ctx , cancel := context . WithTimeout ( context . Background ( ) , 30 * time . Second ) _ , err := c . Defragment ( ctx , ep ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } fmt . Printf ( " \n " , ep ) } 
func NewUserCommand ( ) * cobra . Command { ac := & cobra . Command { Use : " " , Short : " " , } ac . AddCommand ( newUserAddCommand ( ) ) ac . AddCommand ( newUserDeleteCommand ( ) ) ac . AddCommand ( newUserGetCommand ( ) ) ac . AddCommand ( newUserListCommand ( ) ) ac . AddCommand ( newUserChangePasswordCommand ( ) ) ac . AddCommand ( newUserGrantRoleCommand ( ) ) ac . AddCommand ( newUserRevokeRoleCommand ( ) ) return ac } 
func userAddCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } var password string var user string if passwordFromFlag != " " { user = args [ 0 ] password = passwordFromFlag } else { splitted := strings . SplitN ( args [ 0 ] , " " , 2 ) if len ( splitted ) < 2 { user = args [ 0 ] if ! passwordInteractive { fmt . Scanf ( " " , & password ) } else { password = readPasswordInteractive ( args [ 0 ] ) } } else { user = splitted [ 0 ] password = splitted [ 1 ] if len ( user ) == 0 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } } } resp , err := mustClientFromCmd ( cmd ) . Auth . UserAdd ( context . TODO ( ) , user , password ) if err != nil { ExitWithError ( ExitError , err ) } display . UserAdd ( user , * resp ) } 
func userGetCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } name := args [ 0 ] client := mustClientFromCmd ( cmd ) resp , err := client . Auth . UserGet ( context . TODO ( ) , name ) if err != nil { ExitWithError ( ExitError , err ) } if userShowDetail { fmt . Printf ( " \n " , name ) for _ , role := range resp . Roles { fmt . Printf ( " \n " ) roleResp , err := client . Auth . RoleGet ( context . TODO ( ) , role ) if err != nil { ExitWithError ( ExitError , err ) } display . RoleGet ( role , * roleResp ) } } else { display . UserGet ( name , * resp ) } } 
func userChangePasswordCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } var password string if ! passwordInteractive { fmt . Scanf ( " " , & password ) } else { password = readPasswordInteractive ( args [ 0 ] ) } resp , err := mustClientFromCmd ( cmd ) . Auth . UserChangePassword ( context . TODO ( ) , args [ 0 ] , password ) if err != nil { ExitWithError ( ExitError , err ) } display . UserChangePassword ( * resp ) } 
func ( eh * EventHistory ) addEvent ( e * Event ) * Event { eh . rwl . Lock ( ) defer eh . rwl . Unlock ( ) eh . Queue . insert ( e ) eh . LastIndex = e . Index ( ) eh . StartIndex = eh . Queue . Events [ eh . Queue . Front ] . Index ( ) return e } 
func ( eh * EventHistory ) scan ( key string , recursive bool , index uint64 ) ( * Event , * v2error . Error ) { eh . rwl . RLock ( ) defer eh . rwl . RUnlock ( ) } } offset := index - eh . StartIndex i := ( eh . Queue . Front + int ( offset ) ) % eh . Queue . Capacity for { e := eh . Queue . Events [ i ] if ! e . Refresh { ok := e . Node . Key == key if recursive { if nkey [ len ( nkey ) - 1 ] != '/' { nkey = nkey + " " } ok = ok || strings . HasPrefix ( e . Node . Key , nkey ) } if ( e . Action == Delete || e . Action == Expire ) && e . PrevNode != nil && e . PrevNode . Dir { ok = ok || strings . HasPrefix ( key , e . PrevNode . Key ) } if ok { return e , nil } } i = ( i + 1 ) % eh . Queue . Capacity if i == eh . Queue . Back { return nil , nil } } } 
func ( eh * EventHistory ) clone ( ) * EventHistory { clonedQueue := eventQueue { Capacity : eh . Queue . Capacity , Events : make ( [ ] * Event , eh . Queue . Capacity ) , Size : eh . Queue . Size , Front : eh . Queue . Front , Back : eh . Queue . Back , } copy ( clonedQueue . Events , eh . Queue . Events ) return & EventHistory { StartIndex : eh . StartIndex , Queue : clonedQueue , LastIndex : eh . LastIndex , } } 
func openSnapshotBackend ( cfg ServerConfig , ss * snap . Snapshotter , snapshot raftpb . Snapshot ) ( backend . Backend , error ) { snapPath , err := ss . DBFilePath ( snapshot . Metadata . Index ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if err := os . Rename ( snapPath , cfg . backendPath ( ) ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } return openBackend ( cfg ) , nil } 
func openBackend ( cfg ServerConfig ) backend . Backend { fn := cfg . backendPath ( ) now , beOpened := time . Now ( ) , make ( chan backend . Backend ) go func ( ) { beOpened <- newBackend ( cfg ) } ( ) select { case be := <- beOpened : if cfg . Logger != nil { cfg . Logger . Info ( " " , zap . String ( " " , fn ) , zap . Duration ( " " , time . Since ( now ) ) ) } return be case <- time . After ( 10 * time . Second ) : if cfg . Logger != nil { cfg . Logger . Info ( " " , zap . String ( " " , fn ) , zap . Duration ( " " , time . Since ( now ) ) , ) } else { plog . Warningf ( " " , fn ) plog . Warningf ( " " ) } } return <- beOpened } 
func recoverSnapshotBackend ( cfg ServerConfig , oldbe backend . Backend , snapshot raftpb . Snapshot ) ( backend . Backend , error ) { var cIndex consistentIndex kv := mvcc . New ( cfg . Logger , oldbe , & lease . FakeLessor { } , & cIndex ) defer kv . Close ( ) if snapshot . Metadata . Index <= kv . ConsistentIndex ( ) { return oldbe , nil } oldbe . Close ( ) return openSnapshotBackend ( cfg , snap . New ( cfg . Logger , cfg . SnapDir ( ) ) , snapshot ) } 
func NewUpdateCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Flags : [ ] cli . Flag { cli . IntFlag { Name : " " , Value : 0 , Usage : " " } , } , Action : func ( c * cli . Context ) error { updateCommandFunc ( c , mustNewKeyAPI ( c ) ) return nil } , } } 
func updateCommandFunc ( c * cli . Context , ki client . KeysAPI ) { if len ( c . Args ( ) ) == 0 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } key := c . Args ( ) [ 0 ] value , err := argOrStdin ( c . Args ( ) , os . Stdin , 1 ) if err != nil { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } ttl := c . Int ( " " ) ctx , cancel := contextWithTotalTimeout ( c ) resp , err := ki . Set ( ctx , key , value , & client . SetOptions { TTL : time . Duration ( ttl ) * time . Second , PrevExist : client . PrevExist } ) cancel ( ) if err != nil { handleError ( c , ExitServerError , err ) } printResponseKey ( resp , c . GlobalString ( " " ) ) } 
func ( q * statsQueue ) frontAndBack ( ) ( * RequestStats , * RequestStats ) { q . rwl . RLock ( ) defer q . rwl . RUnlock ( ) if q . size != 0 { return q . items [ q . front ] , q . items [ q . back ] } return nil , nil } 
func ( q * statsQueue ) Insert ( p * RequestStats ) { q . rwl . Lock ( ) defer q . rwl . Unlock ( ) q . back = ( q . back + 1 ) % queueCapacity if q . size == queueCapacity { q . front = ( q . back + 1 ) % queueCapacity } else { q . size ++ } q . items [ q . back ] = p q . totalReqSize += q . items [ q . back ] . Size } 
func ( q * statsQueue ) Rate ( ) ( float64 , float64 ) { front , back := q . frontAndBack ( ) if front == nil || back == nil { return 0 , 0 } if time . Since ( back . SendingTime ) > time . Second { q . Clear ( ) return 0 , 0 } sampleDuration := back . SendingTime . Sub ( front . SendingTime ) pr := float64 ( q . Len ( ) ) / float64 ( sampleDuration ) * float64 ( time . Second ) br := float64 ( q . ReqSize ( ) ) / float64 ( sampleDuration ) * float64 ( time . Second ) return pr , br } 
func ( q * statsQueue ) Clear ( ) { q . rwl . Lock ( ) defer q . rwl . Unlock ( ) q . back = - 1 q . front = 0 q . size = 0 q . totalReqSize = 0 } 
func UniqueStrings ( slen uint , n int ) ( ss [ ] string ) { exist := make ( map [ string ] struct { } ) ss = make ( [ ] string , 0 , n ) for len ( ss ) < n { s := randString ( slen ) if _ , ok := exist [ s ] ; ! ok { ss = append ( ss , s ) exist [ s ] = struct { } { } } } return ss } 
func RandomStrings ( slen uint , n int ) ( ss [ ] string ) { ss = make ( [ ] string , 0 , n ) for i := 0 ; i < n ; i ++ { ss = append ( ss , randString ( slen ) ) } return ss } 
func IsKeyNotFound ( err error ) bool { if cErr , ok := err . ( Error ) ; ok { return cErr . Code == ErrorCodeKeyNotFound } return false } 
func IsRoleNotFound ( err error ) bool { if ae , ok := err . ( authError ) ; ok { return roleNotFoundRegExp . MatchString ( ae . Message ) } return false } 
func IsUserNotFound ( err error ) bool { if ae , ok := err . ( authError ) ; ok { return userNotFoundRegExp . MatchString ( ae . Message ) } return false } 
func JoinCluster ( lg * zap . Logger , durl , dproxyurl string , id types . ID , config string ) ( string , error ) { d , err := newDiscovery ( lg , durl , dproxyurl , id ) if err != nil { return " " , err } return d . joinCluster ( config ) } 
func GetCluster ( lg * zap . Logger , durl , dproxyurl string ) ( string , error ) { d , err := newDiscovery ( lg , durl , dproxyurl , 0 ) if err != nil { return " " , err } return d . getCluster ( ) } 
func newProxyFunc ( lg * zap . Logger , proxy string ) ( func ( * http . Request ) ( * url . URL , error ) , error ) { if proxy == " " { return nil , nil } if err != nil || ! strings . HasPrefix ( proxyURL . Scheme , " " ) { proxyURL , err2 = url . Parse ( " " + proxy ) if err2 == nil { err = nil } } if err != nil { return nil , fmt . Errorf ( " " , proxy , err ) } if lg != nil { lg . Info ( " " , zap . String ( " " , proxyURL . String ( ) ) ) } else { plog . Infof ( " " , proxyURL . String ( ) ) } return http . ProxyURL ( proxyURL ) , nil } 
func ( c * Client ) unaryClientInterceptor ( logger * zap . Logger , optFuncs ... retryOption ) grpc . UnaryClientInterceptor { intOpts := reuseOrNewWithCallOptions ( defaultOptions , optFuncs ) return func ( ctx context . Context , method string , req , reply interface { } , cc * grpc . ClientConn , invoker grpc . UnaryInvoker , opts ... grpc . CallOption ) error { grpcOpts , retryOpts := filterCallOptions ( opts ) callOpts := reuseOrNewWithCallOptions ( intOpts , retryOpts ) } var lastErr error for attempt := uint ( 0 ) ; attempt < callOpts . max ; attempt ++ { if err := waitRetryBackoff ( ctx , attempt , callOpts ) ; err != nil { return err } logger . Debug ( " " , zap . String ( " " , cc . Target ( ) ) , zap . Uint ( " " , attempt ) , ) lastErr = invoker ( ctx , method , req , reply , cc , grpcOpts ... ) if lastErr == nil { return nil } logger . Warn ( " " , zap . String ( " " , cc . Target ( ) ) , zap . Uint ( " " , attempt ) , zap . Error ( lastErr ) , ) if isContextError ( lastErr ) { if ctx . Err ( ) != nil { } } if callOpts . retryAuth && rpctypes . Error ( lastErr ) == rpctypes . ErrInvalidAuthToken { gterr := c . getToken ( ctx ) if gterr != nil { logger . Warn ( " " , zap . String ( " " , cc . Target ( ) ) , zap . Error ( gterr ) , ) return lastErr } continue } if ! isSafeRetry ( c . lg , lastErr , callOpts ) { return lastErr } } return lastErr } } 
func ( c * Client ) streamClientInterceptor ( logger * zap . Logger , optFuncs ... retryOption ) grpc . StreamClientInterceptor { intOpts := reuseOrNewWithCallOptions ( defaultOptions , optFuncs ) return func ( ctx context . Context , desc * grpc . StreamDesc , cc * grpc . ClientConn , method string , streamer grpc . Streamer , opts ... grpc . CallOption ) ( grpc . ClientStream , error ) { grpcOpts , retryOpts := filterCallOptions ( opts ) callOpts := reuseOrNewWithCallOptions ( intOpts , retryOpts ) } if desc . ClientStreams { return nil , grpc . Errorf ( codes . Unimplemented , " " ) } newStreamer , err := streamer ( ctx , desc , cc , method , grpcOpts ... ) logger . Warn ( " " , zap . Error ( err ) ) if err != nil { } retryingStreamer := & serverStreamingRetryingStream { client : c , ClientStream : newStreamer , callOpts : callOpts , ctx : ctx , streamerCall : func ( ctx context . Context ) ( grpc . ClientStream , error ) { return streamer ( ctx , desc , cc , method , grpcOpts ... ) } , } return retryingStreamer , nil } } 
func isSafeRetry ( lg * zap . Logger , err error , callOpts * options ) bool { if isContextError ( err ) { return false } switch callOpts . retryPolicy { case repeatable : return isSafeRetryImmutableRPC ( err ) case nonRepeatable : return isSafeRetryMutableRPC ( err ) default : lg . Warn ( " " , zap . String ( " " , callOpts . retryPolicy . String ( ) ) ) return false } } 
func withRetryPolicy ( rp retryPolicy ) retryOption { return retryOption { applyFunc : func ( o * options ) { o . retryPolicy = rp } } } 
func withAuthRetry ( retryAuth bool ) retryOption { return retryOption { applyFunc : func ( o * options ) { o . retryAuth = retryAuth } } } 
func withMax ( maxRetries uint ) retryOption { return retryOption { applyFunc : func ( o * options ) { o . max = maxRetries } } } 
func withBackoff ( bf backoffFunc ) retryOption { return retryOption { applyFunc : func ( o * options ) { o . backoffFunc = bf } } } 
func backoffLinearWithJitter ( waitBetween time . Duration , jitterFraction float64 ) backoffFunc { return func ( attempt uint ) time . Duration { return jitterUp ( waitBetween , jitterFraction ) } } 
func ( ss * ServerStats ) RecvAppendReq ( leader string , reqSize int ) { ss . Lock ( ) defer ss . Unlock ( ) now := time . Now ( ) ss . State = raft . StateFollower if leader != ss . LeaderInfo . Name { ss . LeaderInfo . Name = leader ss . LeaderInfo . StartTime = now } ss . recvRateQueue . Insert ( & RequestStats { SendingTime : now , Size : reqSize , } , ) ss . RecvAppendRequestCnt ++ } 
func ( ss * ServerStats ) SendAppendReq ( reqSize int ) { ss . Lock ( ) defer ss . Unlock ( ) ss . becomeLeader ( ) ss . sendRateQueue . Insert ( & RequestStats { SendingTime : time . Now ( ) , Size : reqSize , } , ) ss . SendAppendRequestCnt ++ } 
func NewPackageLogger ( repo , pkg string ) Logger { return & packageLogger { p : capnslog . NewPackageLogger ( repo , pkg ) } } 
func ( bb * bucketBuffer ) merge ( bbsrc * bucketBuffer ) { for i := 0 ; i < bbsrc . used ; i ++ { bb . add ( bbsrc . buf [ i ] . key , bbsrc . buf [ i ] . val ) } if bb . used == bbsrc . used { return } if bytes . Compare ( bb . buf [ ( bb . used - bbsrc . used ) - 1 ] . key , bbsrc . buf [ 0 ] . key ) < 0 { return } sort . Stable ( bb ) for ridx := 1 ; ridx < bb . used ; ridx ++ { if ! bytes . Equal ( bb . buf [ ridx ] . key , bb . buf [ widx ] . key ) { widx ++ } bb . buf [ widx ] = bb . buf [ ridx ] } bb . used = widx + 1 } 
func deleteRevKey ( kv v3 . KV , key string , rev int64 ) ( bool , error ) { cmp := v3 . Compare ( v3 . ModRevision ( key ) , " " , rev ) req := v3 . OpDelete ( key ) txnresp , err := kv . Txn ( context . TODO ( ) ) . If ( cmp ) . Then ( req ) . Commit ( ) if err != nil { return false , err } else if ! txnresp . Succeeded { return false , nil } return true , nil } 
func isMemberBootstrapped ( lg * zap . Logger , cl * membership . RaftCluster , member string , rt http . RoundTripper , timeout time . Duration ) bool { rcl , err := getClusterFromRemotePeers ( lg , getRemotePeerURLs ( cl , member ) , timeout , false , rt ) if err != nil { return false } id := cl . MemberByName ( member ) . ID m := rcl . Member ( id ) if m == nil { return false } if len ( m . ClientURLs ) > 0 { return true } return false } 
func GetClusterFromRemotePeers ( lg * zap . Logger , urls [ ] string , rt http . RoundTripper ) ( * membership . RaftCluster , error ) { return getClusterFromRemotePeers ( lg , urls , 10 * time . Second , true , rt ) } 
func getClusterFromRemotePeers ( lg * zap . Logger , urls [ ] string , timeout time . Duration , logerr bool , rt http . RoundTripper ) ( * membership . RaftCluster , error ) { cc := & http . Client { Transport : rt , Timeout : timeout , } for _ , u := range urls { addr := u + " " resp , err := cc . Get ( addr ) if err != nil { if logerr { if lg != nil { lg . Warn ( " " , zap . String ( " " , addr ) , zap . Error ( err ) ) } else { plog . Warningf ( " " , u , err ) } } continue } b , err := ioutil . ReadAll ( resp . Body ) resp . Body . Close ( ) if err != nil { if logerr { if lg != nil { lg . Warn ( " " , zap . String ( " " , addr ) , zap . Error ( err ) ) } else { plog . Warningf ( " " , err ) } } continue } var membs [ ] * membership . Member if err = json . Unmarshal ( b , & membs ) ; err != nil { if logerr { if lg != nil { lg . Warn ( " " , zap . String ( " " , addr ) , zap . Error ( err ) ) } else { plog . Warningf ( " " , err ) } } continue } id , err := types . IDFromString ( resp . Header . Get ( " " ) ) if err != nil { if logerr { if lg != nil { lg . Warn ( " " , zap . String ( " " , addr ) , zap . String ( " " , resp . Header . Get ( " " ) ) , zap . Error ( err ) , ) } else { plog . Warningf ( " " , err ) } } continue } } return nil , fmt . Errorf ( " " ) } return nil , fmt . Errorf ( " " ) } 
func getRemotePeerURLs ( cl * membership . RaftCluster , local string ) [ ] string { us := make ( [ ] string , 0 ) for _ , m := range cl . Members ( ) { if m . Name == local { continue } us = append ( us , m . PeerURLs ... ) } sort . Strings ( us ) return us } 
func getVersions ( lg * zap . Logger , cl * membership . RaftCluster , local types . ID , rt http . RoundTripper ) map [ string ] * version . Versions { members := cl . Members ( ) vers := make ( map [ string ] * version . Versions ) for _ , m := range members { if m . ID == local { cv := " " if cl . Version ( ) != nil { cv = cl . Version ( ) . String ( ) } vers [ m . ID . String ( ) ] = & version . Versions { Server : version . Version , Cluster : cv } continue } ver , err := getVersion ( lg , m , rt ) if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , m . ID . String ( ) ) , zap . Error ( err ) ) } else { plog . Warningf ( " " , m . ID , err ) } vers [ m . ID . String ( ) ] = nil } else { vers [ m . ID . String ( ) ] = ver } } return vers } 
func decideClusterVersion ( lg * zap . Logger , vers map [ string ] * version . Versions ) * semver . Version { var cv * semver . Version lv := semver . Must ( semver . NewVersion ( version . Version ) ) for mid , ver := range vers { if ver == nil { return nil } v , err := semver . NewVersion ( ver . Server ) if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , mid ) , zap . String ( " " , ver . Server ) , zap . Error ( err ) , ) } else { plog . Errorf ( " " , mid , err ) } return nil } if lv . LessThan ( * v ) { if lg != nil { lg . Warn ( " " , zap . String ( " " , lv . String ( ) ) , zap . String ( " " , mid ) , zap . String ( " " , ver . Server ) , ) } else { plog . Warningf ( " " , lv . String ( ) ) plog . Warningf ( " " , mid , ver . Server ) } } if cv == nil { cv = v } else if v . LessThan ( * cv ) { cv = v } } return cv } 
func isCompatibleWithCluster ( lg * zap . Logger , cl * membership . RaftCluster , local types . ID , rt http . RoundTripper ) bool { vers := getVersions ( lg , cl , local , rt ) minV := semver . Must ( semver . NewVersion ( version . MinClusterVersion ) ) maxV := semver . Must ( semver . NewVersion ( version . Version ) ) maxV = & semver . Version { Major : maxV . Major , Minor : maxV . Minor , } return isCompatibleWithVers ( lg , vers , local , minV , maxV ) } 
func getVersion ( lg * zap . Logger , m * membership . Member , rt http . RoundTripper ) ( * version . Versions , error ) { cc := & http . Client { Transport : rt , } var ( err error resp * http . Response ) for _ , u := range m . PeerURLs { addr := u + " " resp , err = cc . Get ( addr ) if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , addr ) , zap . String ( " " , m . ID . String ( ) ) , zap . Error ( err ) , ) } else { plog . Warningf ( " " , u , m . ID , err ) } continue } var b [ ] byte b , err = ioutil . ReadAll ( resp . Body ) resp . Body . Close ( ) if err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , addr ) , zap . String ( " " , m . ID . String ( ) ) , zap . Error ( err ) , ) } else { plog . Warningf ( " " , u , m . ID , err ) } continue } var vers version . Versions if err = json . Unmarshal ( b , & vers ) ; err != nil { if lg != nil { lg . Warn ( " " , zap . String ( " " , addr ) , zap . String ( " " , m . ID . String ( ) ) , zap . Error ( err ) , ) } else { plog . Warningf ( " " , u , m . ID , err ) } continue } return & vers , nil } return nil , err } 
func NewTimeoutDetector ( maxDuration time . Duration ) * TimeoutDetector { return & TimeoutDetector { maxDuration : maxDuration , records : make ( map [ uint64 ] time . Time ) , } } 
func ( td * TimeoutDetector ) Reset ( ) { td . mu . Lock ( ) defer td . mu . Unlock ( ) td . records = make ( map [ uint64 ] time . Time ) } 
func ( td * TimeoutDetector ) Observe ( which uint64 ) ( bool , time . Duration ) { td . mu . Lock ( ) defer td . mu . Unlock ( ) ok := true now := time . Now ( ) exceed := time . Duration ( 0 ) if pt , found := td . records [ which ] ; found { exceed = now . Sub ( pt ) - td . maxDuration if exceed > 0 { ok = false } } td . records [ which ] = now return ok , exceed } 
func NewPeerHandler ( lg * zap . Logger , s etcdserver . ServerPeer ) http . Handler { return newPeerHandler ( lg , s . Cluster ( ) , s . RaftHandler ( ) , s . LeaseHandler ( ) ) } 
func ( ki * keyIndex ) put ( lg * zap . Logger , main int64 , sub int64 ) { rev := revision { main : main , sub : sub } if ! rev . GreaterThan ( ki . modified ) { if lg != nil { lg . Panic ( " " , zap . Int64 ( " " , rev . main ) , zap . Int64 ( " " , rev . sub ) , zap . Int64 ( " " , ki . modified . main ) , zap . Int64 ( " " , ki . modified . sub ) , ) } else { plog . Panicf ( " " , rev , ki . modified ) } } if len ( ki . generations ) == 0 { ki . generations = append ( ki . generations , generation { } ) } g := & ki . generations [ len ( ki . generations ) - 1 ] if len ( g . revs ) == 0 { g . created = rev } g . revs = append ( g . revs , rev ) g . ver ++ ki . modified = rev } 
func ( ki * keyIndex ) tombstone ( lg * zap . Logger , main int64 , sub int64 ) error { if ki . isEmpty ( ) { if lg != nil { lg . Panic ( " " , zap . String ( " " , string ( ki . key ) ) , ) } else { plog . Panicf ( " " , string ( ki . key ) ) } } if ki . generations [ len ( ki . generations ) - 1 ] . isEmpty ( ) { return ErrRevisionNotFound } ki . put ( lg , main , sub ) ki . generations = append ( ki . generations , generation { } ) keysGauge . Dec ( ) return nil } 
func ( ki * keyIndex ) get ( lg * zap . Logger , atRev int64 ) ( modified , created revision , ver int64 , err error ) { if ki . isEmpty ( ) { if lg != nil { lg . Panic ( " " , zap . String ( " " , string ( ki . key ) ) , ) } else { plog . Panicf ( " " , string ( ki . key ) ) } } g := ki . findGeneration ( atRev ) if g . isEmpty ( ) { return revision { } , revision { } , 0 , ErrRevisionNotFound } n := g . walk ( func ( rev revision ) bool { return rev . main > atRev } ) if n != - 1 { return g . revs [ n ] , g . created , g . ver - int64 ( len ( g . revs ) - n - 1 ) , nil } return revision { } , revision { } , 0 , ErrRevisionNotFound } 
func ( ki * keyIndex ) since ( lg * zap . Logger , rev int64 ) [ ] revision { if ki . isEmpty ( ) { if lg != nil { lg . Panic ( " " , zap . String ( " " , string ( ki . key ) ) , ) } else { plog . Panicf ( " " , string ( ki . key ) ) } } since := revision { rev , 0 } var gi int if g . isEmpty ( ) { continue } if since . GreaterThan ( g . created ) { break } } var revs [ ] revision var last int64 for ; gi < len ( ki . generations ) ; gi ++ { for _ , r := range ki . generations [ gi ] . revs { if since . GreaterThan ( r ) { continue } if r . main == last { continue } revs = append ( revs , r ) last = r . main } } return revs } 
func ( ki * keyIndex ) compact ( lg * zap . Logger , atRev int64 , available map [ revision ] struct { } ) { if ki . isEmpty ( ) { if lg != nil { lg . Panic ( " " , zap . String ( " " , string ( ki . key ) ) , ) } else { plog . Panicf ( " " , string ( ki . key ) ) } } genIdx , revIndex := ki . doCompact ( atRev , available ) g := & ki . generations [ genIdx ] if ! g . isEmpty ( ) { } genIdx ++ } } } 
func ( ki * keyIndex ) keep ( atRev int64 , available map [ revision ] struct { } ) { if ki . isEmpty ( ) { return } genIdx , revIndex := ki . doCompact ( atRev , available ) g := & ki . generations [ genIdx ] if ! g . isEmpty ( ) { } } } 
func ( ki * keyIndex ) findGeneration ( rev int64 ) * generation { lastg := len ( ki . generations ) - 1 cg := lastg for cg >= 0 { if len ( ki . generations [ cg ] . revs ) == 0 { cg -- continue } g := ki . generations [ cg ] if cg != lastg { if tomb := g . revs [ len ( g . revs ) - 1 ] . main ; tomb <= rev { return nil } } if g . revs [ 0 ] . main <= rev { return & ki . generations [ cg ] } cg -- } return nil } 
func ( g * generation ) walk ( f func ( rev revision ) bool ) int { l := len ( g . revs ) for i := range g . revs { ok := f ( g . revs [ l - i - 1 ] ) if ! ok { return l - i - 1 } } return - 1 } 
func ( s * store ) CreateOrUpdateUser ( user User ) ( out User , created bool , err error ) { _ , err = s . getUser ( user . User , true ) if err == nil { out , err = s . UpdateUser ( user ) return out , false , err } u , err := s . CreateUser ( user ) return u , true , err } 
func ( ou User ) merge ( lg * zap . Logger , nu User , s PasswordStore ) ( User , error ) { var out User if ou . User != nu . User { return out , authErr ( http . StatusConflict , " " , ou . User , nu . User ) } out . User = ou . User if nu . Password != " " { hash , err := s . HashPassword ( nu . Password ) if err != nil { return ou , err } out . Password = hash } else { out . Password = ou . Password } currentRoles := types . NewUnsafeSet ( ou . Roles ... ) for _ , g := range nu . Grant { if currentRoles . Contains ( g ) { if lg != nil { lg . Warn ( " " , zap . String ( " " , nu . User ) , zap . String ( " " , g ) , ) } else { plog . Noticef ( " " , g , nu . User ) } return User { } , authErr ( http . StatusConflict , fmt . Sprintf ( " " , g , nu . User ) ) } currentRoles . Add ( g ) } for _ , r := range nu . Revoke { if ! currentRoles . Contains ( r ) { if lg != nil { lg . Warn ( " " , zap . String ( " " , nu . User ) , zap . String ( " " , r ) , ) } else { plog . Noticef ( " " , r , nu . User ) } return User { } , authErr ( http . StatusConflict , fmt . Sprintf ( " " , r , nu . User ) ) } currentRoles . Remove ( r ) } out . Roles = currentRoles . Values ( ) sort . Strings ( out . Roles ) return out , nil } 
func ( r Role ) merge ( lg * zap . Logger , n Role ) ( Role , error ) { var out Role var err error if r . Role != n . Role { return out , authErr ( http . StatusConflict , " " , r . Role , n . Role ) } out . Role = r . Role out . Permissions , err = r . Permissions . Grant ( n . Grant ) if err != nil { return out , err } out . Permissions , err = out . Permissions . Revoke ( lg , n . Revoke ) return out , err } 
func ( p Permissions ) Grant ( n * Permissions ) ( Permissions , error ) { var out Permissions var err error if n == nil { return p , nil } out . KV , err = p . KV . Grant ( n . KV ) return out , err } 
func ( p Permissions ) Revoke ( lg * zap . Logger , n * Permissions ) ( Permissions , error ) { var out Permissions var err error if n == nil { return p , nil } out . KV , err = p . KV . Revoke ( lg , n . KV ) return out , err } 
func ( rw RWPermission ) Grant ( n RWPermission ) ( RWPermission , error ) { var out RWPermission currentRead := types . NewUnsafeSet ( rw . Read ... ) for _ , r := range n . Read { if currentRead . Contains ( r ) { return out , authErr ( http . StatusConflict , " " , r ) } currentRead . Add ( r ) } currentWrite := types . NewUnsafeSet ( rw . Write ... ) for _ , w := range n . Write { if currentWrite . Contains ( w ) { return out , authErr ( http . StatusConflict , " " , w ) } currentWrite . Add ( w ) } out . Read = currentRead . Values ( ) out . Write = currentWrite . Values ( ) sort . Strings ( out . Read ) sort . Strings ( out . Write ) return out , nil } 
func ( rw RWPermission ) Revoke ( lg * zap . Logger , n RWPermission ) ( RWPermission , error ) { var out RWPermission currentRead := types . NewUnsafeSet ( rw . Read ... ) for _ , r := range n . Read { if ! currentRead . Contains ( r ) { if lg != nil { lg . Info ( " " , zap . String ( " " , r ) , ) } else { plog . Noticef ( " " , r ) } continue } currentRead . Remove ( r ) } currentWrite := types . NewUnsafeSet ( rw . Write ... ) for _ , w := range n . Write { if ! currentWrite . Contains ( w ) { if lg != nil { lg . Info ( " " , zap . String ( " " , w ) , ) } else { plog . Noticef ( " " , w ) } continue } currentWrite . Remove ( w ) } out . Read = currentRead . Values ( ) out . Write = currentWrite . Values ( ) sort . Strings ( out . Read ) sort . Strings ( out . Write ) return out , nil } 
func ( s * watchableStore ) cancelWatcher ( wa * watcher ) { for { s . mu . Lock ( ) if s . unsynced . delete ( wa ) { slowWatcherGauge . Dec ( ) break } else if s . synced . delete ( wa ) { break } else if wa . compacted { break } else if wa . ch == nil { } if ! wa . victim { panic ( " " ) } var victimBatch watcherBatch for _ , wb := range s . victims { if wb [ wa ] != nil { victimBatch = wb break } } if victimBatch != nil { slowWatcherGauge . Dec ( ) delete ( victimBatch , wa ) break } time . Sleep ( time . Millisecond ) } watcherGauge . Dec ( ) wa . ch = nil s . mu . Unlock ( ) } 
func ( s * watchableStore ) syncWatchersLoop ( ) { defer s . wg . Done ( ) for { s . mu . RLock ( ) st := time . Now ( ) lastUnsyncedWatchers := s . unsynced . size ( ) s . mu . RUnlock ( ) unsyncedWatchers := 0 if lastUnsyncedWatchers > 0 { unsyncedWatchers = s . syncWatchers ( ) } syncDuration := time . Since ( st ) waitDuration := 100 * time . Millisecond } select { case <- time . After ( waitDuration ) : case <- s . stopc : return } } } 
func ( s * watchableStore ) syncVictimsLoop ( ) { defer s . wg . Done ( ) for { for s . moveVictims ( ) != 0 { s . mu . RLock ( ) isEmpty := len ( s . victims ) == 0 s . mu . RUnlock ( ) var tickc <- chan time . Time if ! isEmpty { tickc = time . After ( 10 * time . Millisecond ) } select { case <- tickc : case <- s . victimc : case <- s . stopc : return } } } 
func ( s * watchableStore ) moveVictims ( ) ( moved int ) { s . mu . Lock ( ) victims := s . victims s . victims = nil s . mu . Unlock ( ) var newVictim watcherBatch for _ , wb := range victims { if w . send ( WatchResponse { WatchID : w . id , Events : eb . evs , Revision : rev } ) { pendingEventsGauge . Add ( float64 ( len ( eb . evs ) ) ) } else { if newVictim == nil { newVictim = make ( watcherBatch ) } newVictim [ w ] = eb continue } moved ++ } s . store . revMu . RLock ( ) curRev := s . store . currentRev for w , eb := range wb { if newVictim != nil && newVictim [ w ] != nil { } w . victim = false if eb . moreRev != 0 { w . minRev = eb . moreRev } if w . minRev <= curRev { s . unsynced . add ( w ) } else { slowWatcherGauge . Dec ( ) s . synced . add ( w ) } } s . store . revMu . RUnlock ( ) s . mu . Unlock ( ) } if len ( newVictim ) > 0 { s . mu . Lock ( ) s . victims = append ( s . victims , newVictim ) s . mu . Unlock ( ) } return moved } 
func ( s * watchableStore ) syncWatchers ( ) int { s . mu . Lock ( ) defer s . mu . Unlock ( ) if s . unsynced . size ( ) == 0 { return 0 } s . store . revMu . RLock ( ) defer s . store . revMu . RUnlock ( ) compactionRev := s . store . compactMainRev wg , minRev := s . unsynced . choose ( maxWatchersPerSync , curRev , compactionRev ) minBytes , maxBytes := newRevBytes ( ) , newRevBytes ( ) revToBytes ( revision { main : minRev } , minBytes ) revToBytes ( revision { main : curRev + 1 } , maxBytes ) tx . RLock ( ) revs , vs := tx . UnsafeRange ( keyBucketName , minBytes , maxBytes , 0 ) var evs [ ] mvccpb . Event if s . store != nil && s . store . lg != nil { evs = kvsToEvents ( s . store . lg , wg , revs , vs ) } else { } tx . RUnlock ( ) var victims watcherBatch wb := newWatcherBatch ( wg , evs ) for w := range wg . watchers { w . minRev = curRev + 1 eb , ok := wb [ w ] if ! ok { s . unsynced . delete ( w ) continue } if eb . moreRev != 0 { w . minRev = eb . moreRev } if w . send ( WatchResponse { WatchID : w . id , Events : eb . evs , Revision : curRev } ) { pendingEventsGauge . Add ( float64 ( len ( eb . evs ) ) ) } else { if victims == nil { victims = make ( watcherBatch ) } w . victim = true } if w . victim { victims [ w ] = eb } else { if eb . moreRev != 0 { } s . synced . add ( w ) } s . unsynced . delete ( w ) } s . addVictim ( victims ) vsz := 0 for _ , v := range s . victims { vsz += len ( v ) } slowWatcherGauge . Set ( float64 ( s . unsynced . size ( ) + vsz ) ) return s . unsynced . size ( ) } 
func kvsToEvents ( lg * zap . Logger , wg * watcherGroup , revs , vals [ ] [ ] byte ) ( evs [ ] mvccpb . Event ) { for i , v := range vals { var kv mvccpb . KeyValue if err := kv . Unmarshal ( v ) ; err != nil { if lg != nil { lg . Panic ( " " , zap . Error ( err ) ) } else { plog . Panicf ( " " , err ) } } if ! wg . contains ( string ( kv . Key ) ) { continue } ty := mvccpb . PUT if isTombstone ( revs [ i ] ) { ty = mvccpb . DELETE } evs = append ( evs , mvccpb . Event { Kv : & kv , Type : ty } ) } return evs } 
func ( s * watchableStore ) notify ( rev int64 , evs [ ] mvccpb . Event ) { var victim watcherBatch for w , eb := range newWatcherBatch ( & s . synced , evs ) { if eb . revs != 1 { if s . store != nil && s . store . lg != nil { s . store . lg . Panic ( " " , zap . Int ( " " , eb . revs ) , ) } else { plog . Panicf ( " " ) } } if w . send ( WatchResponse { WatchID : w . id , Events : eb . evs , Revision : rev } ) { pendingEventsGauge . Add ( float64 ( len ( eb . evs ) ) ) } else { if victim == nil { victim = make ( watcherBatch ) } w . victim = true victim [ w ] = eb s . synced . delete ( w ) slowWatcherGauge . Inc ( ) } } s . addVictim ( victim ) } 
func jitterUp ( duration time . Duration , jitter float64 ) time . Duration { multiplier := jitter * ( rand . Float64 ( ) * 2 - 1 ) return time . Duration ( float64 ( duration ) * ( 1 + multiplier ) ) } 
func isOpFuncCalled ( op string , opts [ ] OpOption ) bool { for _ , opt := range opts { v := reflect . ValueOf ( opt ) if v . Kind ( ) == reflect . Func { if opFunc := runtime . FuncForPC ( v . Pointer ( ) ) ; opFunc != nil { if strings . Contains ( opFunc . Name ( ) , op ) { return true } } } } return false } 
func ( t * batchTx ) UnsafePut ( bucketName [ ] byte , key [ ] byte , value [ ] byte ) { t . unsafePut ( bucketName , key , value , false ) } 
func ( t * batchTx ) UnsafeSeqPut ( bucketName [ ] byte , key [ ] byte , value [ ] byte ) { t . unsafePut ( bucketName , key , value , true ) } 
func ( t * batchTx ) UnsafeRange ( bucketName , key , endKey [ ] byte , limit int64 ) ( [ ] [ ] byte , [ ] [ ] byte ) { bucket := t . tx . Bucket ( bucketName ) if bucket == nil { if t . backend . lg != nil { t . backend . lg . Fatal ( " " , zap . String ( " " , string ( bucketName ) ) , ) } else { plog . Fatalf ( " " , bucketName ) } } return unsafeRange ( bucket . Cursor ( ) , key , endKey , limit ) } 
func ( t * batchTx ) UnsafeDelete ( bucketName [ ] byte , key [ ] byte ) { bucket := t . tx . Bucket ( bucketName ) if bucket == nil { if t . backend . lg != nil { t . backend . lg . Fatal ( " " , zap . String ( " " , string ( bucketName ) ) , ) } else { plog . Fatalf ( " " , bucketName ) } } err := bucket . Delete ( key ) if err != nil { if t . backend . lg != nil { t . backend . lg . Fatal ( " " , zap . String ( " " , string ( bucketName ) ) , zap . Error ( err ) , ) } else { plog . Fatalf ( " " , err ) } } t . pending ++ } 
func ( t * batchTx ) UnsafeForEach ( bucketName [ ] byte , visitor func ( k , v [ ] byte ) error ) error { return unsafeForEach ( t . tx , bucketName , visitor ) } 
func ( t * batchTx ) Commit ( ) { t . Lock ( ) t . commit ( false ) t . Unlock ( ) } 
func ( t * batchTx ) CommitAndStop ( ) { t . Lock ( ) t . commit ( true ) t . Unlock ( ) } 
func ( le * lessor ) Renew ( id LeaseID ) ( int64 , error ) { le . mu . RLock ( ) if ! le . isPrimary ( ) { return - 1 , ErrNotPrimary } demotec := le . demotec l := le . leaseMap [ id ] if l == nil { le . mu . RUnlock ( ) return - 1 , ErrLeaseNotFound } le . mu . RUnlock ( ) if l . expired ( ) { select { case <- le . stopC : return - 1 , ErrNotPrimary } } } le . mu . Lock ( ) l . refresh ( 0 ) item := & LeaseWithTime { id : l . ID , time : l . expiry . UnixNano ( ) } heap . Push ( & le . leaseHeap , item ) le . mu . Unlock ( ) leaseRenewed . Inc ( ) return l . ttl , nil } 
func ( le * lessor ) Attach ( id LeaseID , items [ ] LeaseItem ) error { le . mu . Lock ( ) defer le . mu . Unlock ( ) l := le . leaseMap [ id ] if l == nil { return ErrLeaseNotFound } l . mu . Lock ( ) for _ , it := range items { l . itemSet [ it ] = struct { } { } le . itemMap [ it ] = id } l . mu . Unlock ( ) return nil } 
func ( le * lessor ) revokeExpiredLeases ( ) { var ls [ ] * Lease le . mu . RLock ( ) if le . isPrimary ( ) { ls = le . findExpiredLeases ( revokeLimit ) } le . mu . RUnlock ( ) if len ( ls ) != 0 { select { case <- le . stopC : return case le . expiredC <- ls : default : } } 
func ( le * lessor ) checkpointScheduledLeases ( ) { var cps [ ] * pb . LeaseCheckpoint if le . isPrimary ( ) { cps = le . findDueScheduledCheckpoints ( maxLeaseCheckpointBatchSize ) } le . mu . Unlock ( ) if len ( cps ) != 0 { le . cp ( context . Background ( ) , & pb . LeaseCheckpointRequest { Checkpoints : cps } ) } if len ( cps ) < maxLeaseCheckpointBatchSize { return } } } 
func ( le * lessor ) expireExists ( ) ( l * Lease , ok bool , next bool ) { if le . leaseHeap . Len ( ) == 0 { return nil , false , false } item := le . leaseHeap [ 0 ] l = le . leaseMap [ item . id ] if l == nil { return nil , false , true } if time . Now ( ) . UnixNano ( ) < item . time { } return l , true , false } 
func ( le * lessor ) findExpiredLeases ( limit int ) [ ] * Lease { leases := make ( [ ] * Lease , 0 , 16 ) for { l , ok , next := le . expireExists ( ) if ! ok && ! next { break } if ! ok { continue } if next { continue } if l . expired ( ) { leases = append ( leases , l ) } } } return leases } 
func ( l * Lease ) RemainingTTL ( ) int64 { if l . remainingTTL > 0 { return l . remainingTTL } return l . ttl } 
func ( l * Lease ) refresh ( extend time . Duration ) { newExpiry := time . Now ( ) . Add ( extend + time . Duration ( l . RemainingTTL ( ) ) * time . Second ) l . expiryMu . Lock ( ) defer l . expiryMu . Unlock ( ) l . expiry = newExpiry } 
func ( l * Lease ) forever ( ) { l . expiryMu . Lock ( ) defer l . expiryMu . Unlock ( ) l . expiry = forever } 
func ( l * Lease ) Keys ( ) [ ] string { l . mu . RLock ( ) keys := make ( [ ] string , 0 , len ( l . itemSet ) ) for k := range l . itemSet { keys = append ( keys , k . Key ) } l . mu . RUnlock ( ) return keys } 
func ( l * Lease ) Remaining ( ) time . Duration { l . expiryMu . RLock ( ) defer l . expiryMu . RUnlock ( ) if l . expiry . IsZero ( ) { return time . Duration ( math . MaxInt64 ) } return time . Until ( l . expiry ) } 
func NewCompactionCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : compactionCommandFunc , } cmd . Flags ( ) . BoolVar ( & compactPhysical , " " , false , " " ) return cmd } 
func compactionCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } rev , err := strconv . ParseInt ( args [ 0 ] , 10 , 64 ) if err != nil { ExitWithError ( ExitError , err ) } var opts [ ] clientv3 . CompactOption if compactPhysical { opts = append ( opts , clientv3 . WithCompactPhysical ( ) ) } c := mustClientFromCmd ( cmd ) ctx , cancel := commandCtx ( cmd ) _ , cerr := c . Compact ( ctx , rev , opts ... ) cancel ( ) if cerr != nil { ExitWithError ( ExitError , cerr ) } fmt . Println ( " " , rev ) } 
func caseSensitiveJsonIterator ( ) jsoniter . API { config := jsoniter . Config { EscapeHTML : true , SortMapKeys : true , ValidateJsonRawMessage : true , CaseSensitive : true , } . Froze ( ) return config } 
func NewPutCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Long : ` Puts the given key into the store. When <value> begins with '-', <value> is interpreted as a flag. Insert '--' for workaround: $ put <key> -- <value> $ put -- <key> <value> If <value> isn't given as a command line argument and '--ignore-value' is not specified, this command tries to read the value from standard input. If <lease> isn't given as a command line argument and '--ignore-lease' is not specified, this command tries to read the value from standard input. For example, $ cat file | put <key> will store the content of the file to <key>. ` , Run : putCommandFunc , } cmd . Flags ( ) . StringVar ( & leaseStr , " " , " " , " " ) cmd . Flags ( ) . BoolVar ( & putPrevKV , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & putIgnoreVal , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & putIgnoreLease , " " , false , " " ) return cmd } 
func putCommandFunc ( cmd * cobra . Command , args [ ] string ) { key , value , opts := getPutOp ( args ) ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . Put ( ctx , key , value , opts ... ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . Put ( * resp ) } 
func NewHandler ( t * http . Transport , urlsFunc GetProxyURLs , failureWait time . Duration , refreshInterval time . Duration ) http . Handler { if t . TLSClientConfig != nil { if err != nil { plog . Infof ( " " , err ) } } p := & reverseProxy { director : newDirector ( urlsFunc , failureWait , refreshInterval ) , transport : t , } mux := http . NewServeMux ( ) mux . Handle ( " " , p ) mux . HandleFunc ( " " , p . configHandler ) return mux } 
func NewReadonlyHandler ( hdlr http . Handler ) http . Handler { readonly := readonlyHandlerFunc ( hdlr ) return http . HandlerFunc ( readonly ) } 
func NewSetCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Description : `Set sets the value of a key. When <value> begins with '-', <value> is interpreted as a flag. Insert '--' for workaround: $ set -- <key> <value>` , Flags : [ ] cli . Flag { cli . IntFlag { Name : " " , Value : 0 , Usage : " " } , cli . StringFlag { Name : " " , Value : " " , Usage : " " } , cli . IntFlag { Name : " " , Value : 0 , Usage : " " } , } , Action : func ( c * cli . Context ) error { setCommandFunc ( c , mustNewKeyAPI ( c ) ) return nil } , } } 
func setCommandFunc ( c * cli . Context , ki client . KeysAPI ) { if len ( c . Args ( ) ) == 0 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } key := c . Args ( ) [ 0 ] value , err := argOrStdin ( c . Args ( ) , os . Stdin , 1 ) if err != nil { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } ttl := c . Int ( " " ) prevValue := c . String ( " " ) prevIndex := c . Int ( " " ) ctx , cancel := contextWithTotalTimeout ( c ) resp , err := ki . Set ( ctx , key , value , & client . SetOptions { TTL : time . Duration ( ttl ) * time . Second , PrevIndex : uint64 ( prevIndex ) , PrevValue : prevValue } ) cancel ( ) if err != nil { handleError ( c , ExitServerError , err ) } printResponseKey ( resp , c . GlobalString ( " " ) ) } 
func ( rwm * RWMutex ) waitOnLastRev ( pfx string ) ( bool , error ) { client := rwm . s . Client ( ) lastKey , err := client . Get ( rwm . ctx , pfx , opts ... ) if err != nil { return false , err } if len ( lastKey . Kvs ) == 0 { return true , nil } return false , err } 
func GetDefaultInterfaces ( ) ( map [ string ] uint8 , error ) { return nil , fmt . Errorf ( " " , runtime . GOOS , runtime . GOARCH ) } 
func NewSnapshotCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , } cmd . AddCommand ( NewSnapshotSaveCommand ( ) ) cmd . AddCommand ( NewSnapshotRestoreCommand ( ) ) cmd . AddCommand ( newSnapshotStatusCommand ( ) ) return cmd } 
func NewMoveLeaderCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : transferLeadershipCommandFunc , } return cmd } 
func transferLeadershipCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 1 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } target , err := strconv . ParseUint ( args [ 0 ] , 16 , 64 ) if err != nil { ExitWithError ( ExitBadArgs , err ) } c := mustClientFromCmd ( cmd ) eps := c . Endpoints ( ) c . Close ( ) ctx , cancel := commandCtx ( cmd ) var leaderID uint64 for _ , ep := range eps { cfg := clientConfigFromCmd ( cmd ) cfg . endpoints = [ ] string { ep } cli := cfg . mustClient ( ) resp , serr := cli . Status ( ctx , ep ) if serr != nil { ExitWithError ( ExitError , serr ) } if resp . Header . GetMemberId ( ) == resp . Leader { leaderCli = cli leaderID = resp . Leader break } cli . Close ( ) } if leaderCli == nil { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " , eps ) ) } var resp * clientv3 . MoveLeaderResponse resp , err = leaderCli . MoveLeader ( ctx , target ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . MoveLeader ( leaderID , target , * resp ) } 
func OpenDir ( path string ) ( * os . File , error ) { fd , err := openDir ( path ) if err != nil { return nil , err } return os . NewFile ( uintptr ( fd ) , path ) , nil } 
func NewRemoveDirCommand ( ) cli . Command { return cli . Command { Name : " " , Usage : " " , ArgsUsage : " " , Action : func ( c * cli . Context ) error { rmdirCommandFunc ( c , mustNewKeyAPI ( c ) ) return nil } , } } 
func rmdirCommandFunc ( c * cli . Context , ki client . KeysAPI ) { if len ( c . Args ( ) ) == 0 { handleError ( c , ExitBadArgs , errors . New ( " " ) ) } key := c . Args ( ) [ 0 ] ctx , cancel := contextWithTotalTimeout ( c ) resp , err := ki . Delete ( ctx , key , & client . DeleteOptions { Dir : true } ) cancel ( ) if err != nil { handleError ( c , ExitServerError , err ) } if ! resp . Node . Dir || c . GlobalString ( " " ) != " " { printResponseKey ( resp , c . GlobalString ( " " ) ) } } 
func NewDelCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : delCommandFunc , } cmd . Flags ( ) . BoolVar ( & delPrefix , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & delPrevKV , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & delFromKey , " " , false , " " ) return cmd } 
func delCommandFunc ( cmd * cobra . Command , args [ ] string ) { key , opts := getDelOp ( args ) ctx , cancel := commandCtx ( cmd ) resp , err := mustClientFromCmd ( cmd ) . Delete ( ctx , key , opts ... ) cancel ( ) if err != nil { ExitWithError ( ExitError , err ) } display . Del ( * resp ) } 
func archive ( baseDir , etcdLogPath , dataDir string ) error { dir := filepath . Join ( baseDir , " " , time . Now ( ) . Format ( time . RFC3339 ) ) if existDir ( dir ) { dir = filepath . Join ( baseDir , " " , time . Now ( ) . Add ( time . Second ) . Format ( time . RFC3339 ) ) } if err := fileutil . TouchDirAll ( dir ) ; err != nil { return err } if err := os . Rename ( etcdLogPath , filepath . Join ( dir , " " ) ) ; err != nil { if ! os . IsNotExist ( err ) { return err } } if err := os . Rename ( dataDir , filepath . Join ( dir , filepath . Base ( dataDir ) ) ) ; err != nil { if ! os . IsNotExist ( err ) { return err } } return nil } 
func NewExpect ( name string , arg ... string ) ( ep * ExpectProcess , err error ) { } 
func NewExpectWithEnv ( name string , args [ ] string , env [ ] string ) ( ep * ExpectProcess , err error ) { cmd := exec . Command ( name , args ... ) cmd . Env = env ep = & ExpectProcess { cmd : cmd , StopSignal : syscall . SIGKILL , } ep . cond = sync . NewCond ( & ep . mu ) ep . cmd . Stderr = ep . cmd . Stdout ep . cmd . Stdin = nil if ep . fpty , err = pty . Start ( ep . cmd ) ; err != nil { return nil , err } ep . wg . Add ( 1 ) go ep . read ( ) return ep , nil } 
func ( ep * ExpectProcess ) ExpectFunc ( f func ( string ) bool ) ( string , error ) { ep . mu . Lock ( ) for { for len ( ep . lines ) == 0 && ep . err == nil { ep . cond . Wait ( ) } if len ( ep . lines ) == 0 { break } l := ep . lines [ 0 ] ep . lines = ep . lines [ 1 : ] if f ( l ) { ep . mu . Unlock ( ) return l , nil } } ep . mu . Unlock ( ) return " " , ep . err } 
func ( ep * ExpectProcess ) Expect ( s string ) ( string , error ) { return ep . ExpectFunc ( func ( txt string ) bool { return strings . Contains ( txt , s ) } ) } 
func ( ep * ExpectProcess ) LineCount ( ) int { ep . mu . Lock ( ) defer ep . mu . Unlock ( ) return ep . count } 
func ( ep * ExpectProcess ) Signal ( sig os . Signal ) error { return ep . cmd . Process . Signal ( sig ) } 
func readyWait ( rpcCtx , clientCtx context . Context , ready <- chan struct { } ) error { select { case <- ready : return nil case <- rpcCtx . Done ( ) : return rpcCtx . Err ( ) case <- clientCtx . Done ( ) : return clientCtx . Err ( ) } } 
func keyFunc ( req * pb . RangeRequest ) string { if err != nil { panic ( err ) } return string ( b ) } 
func ( c * cache ) Add ( req * pb . RangeRequest , resp * pb . RangeResponse ) { key := keyFunc ( req ) c . mu . Lock ( ) defer c . mu . Unlock ( ) if req . Revision > c . compactedRev { c . lru . Add ( key , resp ) } } var ( iv * adt . IntervalValue ivl adt . Interval ) if len ( req . RangeEnd ) != 0 { ivl = adt . NewStringAffineInterval ( string ( req . Key ) , string ( req . RangeEnd ) ) } else { ivl = adt . NewStringAffinePoint ( string ( req . Key ) ) } iv = c . cachedRanges . Find ( ivl ) if iv == nil { val := map [ string ] struct { } { key : { } } c . cachedRanges . Insert ( ivl , val ) } else { val := iv . Val . ( map [ string ] struct { } ) val [ key ] = struct { } { } iv . Val = val } } 
func ( c * cache ) Get ( req * pb . RangeRequest ) ( * pb . RangeResponse , error ) { key := keyFunc ( req ) c . mu . Lock ( ) defer c . mu . Unlock ( ) if req . Revision > 0 && req . Revision < c . compactedRev { c . lru . Remove ( key ) return nil , ErrCompacted } if resp , ok := c . lru . Get ( key ) ; ok { return resp . ( * pb . RangeResponse ) , nil } return nil , errors . New ( " " ) } 
func ( c * cache ) Invalidate ( key , endkey [ ] byte ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) var ( ivs [ ] * adt . IntervalValue ivl adt . Interval ) if len ( endkey ) == 0 { ivl = adt . NewStringAffinePoint ( string ( key ) ) } else { ivl = adt . NewStringAffineInterval ( string ( key ) , string ( endkey ) ) } ivs = c . cachedRanges . Stab ( ivl ) for _ , iv := range ivs { keys := iv . Val . ( map [ string ] struct { } ) for key := range keys { c . lru . Remove ( key ) } } } 
func ( c * cache ) Compact ( revision int64 ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) if revision > c . compactedRev { c . compactedRev = revision } } 
func ( us * UniqueURLs ) Set ( s string ) error { if _ , ok := us . Values [ s ] ; ok { return nil } if _ , ok := us . Allowed [ s ] ; ok { us . Values [ s ] = struct { } { } return nil } ss , err := types . NewURLs ( strings . Split ( s , " " ) ) if err != nil { return err } us . Values = make ( map [ string ] struct { } ) us . uss = make ( [ ] url . URL , 0 ) for _ , v := range ss { us . Values [ v . String ( ) ] = struct { } { } us . uss = append ( us . uss , v ) } return nil } 
func ( us * UniqueURLs ) String ( ) string { all := make ( [ ] string , 0 , len ( us . Values ) ) for u := range us . Values { all = append ( all , u ) } sort . Strings ( all ) return strings . Join ( all , " " ) } 
func NewUniqueURLsWithExceptions ( s string , exceptions ... string ) * UniqueURLs { us := & UniqueURLs { Values : make ( map [ string ] struct { } ) , Allowed : make ( map [ string ] struct { } ) } for _ , v := range exceptions { us . Allowed [ v ] = struct { } { } } if s == " " { return us } if err := us . Set ( s ) ; err != nil { plog . Panicf ( " " , err ) } return us } 
func UniqueURLsFromFlag ( fs * flag . FlagSet , urlsFlagName string ) [ ] url . URL { return ( * fs . Lookup ( urlsFlagName ) . Value . ( * UniqueURLs ) ) . uss } 
func UniqueURLsMapFromFlag ( fs * flag . FlagSet , urlsFlagName string ) map [ string ] struct { } { return ( * fs . Lookup ( urlsFlagName ) . Value . ( * UniqueURLs ) ) . Values } 
func ( b * Barrier ) Hold ( ) error { _ , err := newKey ( b . client , b . key , v3 . NoLease ) return err } 
func ( b * Barrier ) Release ( ) error { _ , err := b . client . Delete ( b . ctx , b . key ) return err } 
func ( b * Barrier ) Wait ( ) error { resp , err := b . client . Get ( b . ctx , b . key , v3 . WithFirstKey ( ) ... ) if err != nil { return err } if len ( resp . Kvs ) == 0 { } _ , err = WaitEvents ( b . client , b . key , resp . Header . Revision , [ ] mvccpb . Event_EventType { mvccpb . PUT , mvccpb . DELETE } ) return err } 
func NewLockRacerCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : runRacerFunc , } cmd . Flags ( ) . IntVar ( & totalClientConnections , " " , 10 , " " ) return cmd } 
func ( m * Member ) ElectionTimeout ( ) time . Duration { return time . Duration ( m . Etcd . ElectionTimeoutMs ) * time . Millisecond } 
func ( m * Member ) DialEtcdGRPCServer ( opts ... grpc . DialOption ) ( * grpc . ClientConn , error ) { dialOpts := [ ] grpc . DialOption { grpc . WithTimeout ( 5 * time . Second ) , grpc . WithBlock ( ) , } secure := false for _ , cu := range m . Etcd . AdvertiseClientURLs { u , err := url . Parse ( cu ) if err != nil { return nil , err } if u . Scheme == " " { } } if secure { tlsConfig , err := tlsInfo . ClientConfig ( ) if err != nil { return nil , err } creds := credentials . NewTLS ( tlsConfig ) dialOpts = append ( dialOpts , grpc . WithTransportCredentials ( creds ) ) } else { dialOpts = append ( dialOpts , grpc . WithInsecure ( ) ) } dialOpts = append ( dialOpts , opts ... ) return grpc . Dial ( m . EtcdClientEndpoint , dialOpts ... ) } 
func ( m * Member ) CreateEtcdClientConfig ( opts ... grpc . DialOption ) ( cfg * clientv3 . Config , err error ) { secure := false for _ , cu := range m . Etcd . AdvertiseClientURLs { var u * url . URL u , err = url . Parse ( cu ) if err != nil { return nil , err } if u . Scheme == " " { } } cfg = & clientv3 . Config { Endpoints : [ ] string { m . EtcdClientEndpoint } , DialTimeout : 10 * time . Second , DialOptions : opts , } if secure { var tlsConfig * tls . Config tlsConfig , err = tlsInfo . ClientConfig ( ) if err != nil { return nil , err } cfg . TLS = tlsConfig } return cfg , err } 
func ( m * Member ) CreateEtcdClient ( opts ... grpc . DialOption ) ( * clientv3 . Client , error ) { cfg , err := m . CreateEtcdClientConfig ( opts ... ) if err != nil { return nil , err } return clientv3 . New ( * cfg ) } 
func ( m * Member ) CheckCompact ( rev int64 ) error { cli , err := m . CreateEtcdClient ( ) if err != nil { return fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } defer cli . Close ( ) ctx , cancel := context . WithTimeout ( context . Background ( ) , 5 * time . Second ) wch := cli . Watch ( ctx , " \x00 " , clientv3 . WithFromKey ( ) , clientv3 . WithRev ( rev - 1 ) ) wr , ok := <- wch cancel ( ) if ! ok { return fmt . Errorf ( " " , m . EtcdClientEndpoint ) } if wr . CompactRevision != rev { return fmt . Errorf ( " " , wr . CompactRevision , rev , m . EtcdClientEndpoint ) } return nil } 
func ( m * Member ) Defrag ( ) error { cli , err := m . CreateEtcdClient ( ) if err != nil { return fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } defer cli . Close ( ) ctx , cancel := context . WithTimeout ( context . Background ( ) , 5 * time . Minute ) _ , err = cli . Defragment ( ctx , m . EtcdClientEndpoint ) cancel ( ) return err } 
func ( m * Member ) RevHash ( ) ( int64 , int64 , error ) { conn , err := m . DialEtcdGRPCServer ( ) if err != nil { return 0 , 0 , err } defer conn . Close ( ) mt := pb . NewMaintenanceClient ( conn ) ctx , cancel := context . WithTimeout ( context . Background ( ) , 5 * time . Second ) resp , err := mt . Hash ( ctx , & pb . HashRequest { } , grpc . FailFast ( false ) ) cancel ( ) if err != nil { return 0 , 0 , err } return resp . Header . Revision , int64 ( resp . Hash ) , nil } 
func ( m * Member ) Rev ( ctx context . Context ) ( int64 , error ) { cli , err := m . CreateEtcdClient ( ) if err != nil { return 0 , fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } defer cli . Close ( ) resp , err := cli . Status ( ctx , m . EtcdClientEndpoint ) if err != nil { return 0 , err } return resp . Header . Revision , nil } 
func ( m * Member ) Compact ( rev int64 , timeout time . Duration ) error { cli , err := m . CreateEtcdClient ( ) if err != nil { return fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } defer cli . Close ( ) ctx , cancel := context . WithTimeout ( context . Background ( ) , timeout ) _ , err = cli . Compact ( ctx , rev , clientv3 . WithCompactPhysical ( ) ) cancel ( ) return err } 
func ( m * Member ) IsLeader ( ) ( bool , error ) { cli , err := m . CreateEtcdClient ( ) if err != nil { return false , fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } defer cli . Close ( ) resp , err := cli . Status ( context . Background ( ) , m . EtcdClientEndpoint ) if err != nil { return false , err } return resp . Header . MemberId == resp . Leader , nil } 
func ( m * Member ) WriteHealthKey ( ) error { cli , err := m . CreateEtcdClient ( ) if err != nil { return fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } defer cli . Close ( ) _ , err = cli . Put ( ctx , " " , " " ) cancel ( ) if err != nil { return fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } return nil } 
func ( m * Member ) SaveSnapshot ( lg * zap . Logger ) ( err error ) { } var ccfg * clientv3 . Config ccfg , err = m . CreateEtcdClientConfig ( ) if err != nil { return fmt . Errorf ( " " , err , m . EtcdClientEndpoint ) } lg . Info ( " " , zap . String ( " " , m . Etcd . Name ) , zap . Strings ( " " , m . Etcd . AdvertiseClientURLs ) , zap . String ( " " , m . SnapshotPath ) , ) now := time . Now ( ) mgr := snapshot . NewV3 ( lg ) if err = mgr . Save ( context . Background ( ) , * ccfg , m . SnapshotPath ) ; err != nil { return err } took := time . Since ( now ) var fi os . FileInfo fi , err = os . Stat ( m . SnapshotPath ) if err != nil { return err } var st snapshot . Status st , err = mgr . Status ( m . SnapshotPath ) if err != nil { return err } m . SnapshotInfo = & SnapshotInfo { MemberName : m . Etcd . Name , MemberClientURLs : m . Etcd . AdvertiseClientURLs , SnapshotPath : m . SnapshotPath , SnapshotFileSize : humanize . Bytes ( uint64 ( fi . Size ( ) ) ) , SnapshotTotalSize : humanize . Bytes ( uint64 ( st . TotalSize ) ) , SnapshotTotalKey : int64 ( st . TotalKey ) , SnapshotHash : int64 ( st . Hash ) , SnapshotRevision : st . Revision , Took : fmt . Sprintf ( " " , took ) , } lg . Info ( " " , zap . String ( " " , m . SnapshotInfo . MemberName ) , zap . Strings ( " " , m . SnapshotInfo . MemberClientURLs ) , zap . String ( " " , m . SnapshotPath ) , zap . String ( " " , m . SnapshotInfo . SnapshotFileSize ) , zap . String ( " " , m . SnapshotInfo . SnapshotTotalSize ) , zap . Int64 ( " " , m . SnapshotInfo . SnapshotTotalKey ) , zap . Int64 ( " " , m . SnapshotInfo . SnapshotHash ) , zap . Int64 ( " " , m . SnapshotInfo . SnapshotRevision ) , zap . String ( " " , m . SnapshotInfo . Took ) , ) return nil } 
func ( m * Member ) RestoreSnapshot ( lg * zap . Logger ) ( err error ) { if err = os . RemoveAll ( m . EtcdOnSnapshotRestore . DataDir ) ; err != nil { return err } if err = os . RemoveAll ( m . EtcdOnSnapshotRestore . WALDir ) ; err != nil { return err } lg . Info ( " " , zap . String ( " " , m . Etcd . Name ) , zap . Strings ( " " , m . Etcd . AdvertiseClientURLs ) , zap . String ( " " , m . SnapshotPath ) , ) now := time . Now ( ) mgr := snapshot . NewV3 ( lg ) err = mgr . Restore ( snapshot . RestoreConfig { SnapshotPath : m . SnapshotInfo . SnapshotPath , Name : m . EtcdOnSnapshotRestore . Name , OutputDataDir : m . EtcdOnSnapshotRestore . DataDir , OutputWALDir : m . EtcdOnSnapshotRestore . WALDir , PeerURLs : m . EtcdOnSnapshotRestore . AdvertisePeerURLs , InitialCluster : m . EtcdOnSnapshotRestore . InitialCluster , InitialClusterToken : m . EtcdOnSnapshotRestore . InitialClusterToken , SkipHashCheck : false , took := time . Since ( now ) lg . Info ( " " , zap . String ( " " , m . SnapshotInfo . MemberName ) , zap . Strings ( " " , m . SnapshotInfo . MemberClientURLs ) , zap . String ( " " , m . SnapshotPath ) , zap . String ( " " , m . SnapshotInfo . SnapshotFileSize ) , zap . String ( " " , m . SnapshotInfo . SnapshotTotalSize ) , zap . Int64 ( " " , m . SnapshotInfo . SnapshotTotalKey ) , zap . Int64 ( " " , m . SnapshotInfo . SnapshotHash ) , zap . Int64 ( " " , m . SnapshotInfo . SnapshotRevision ) , zap . String ( " " , took . String ( ) ) , zap . Error ( err ) , ) return err } 
func NewWatcher ( w clientv3 . Watcher , prefix string ) clientv3 . Watcher { return & watcherPrefix { Watcher : w , pfx : prefix , stopc : make ( chan struct { } ) } } 
func Register ( c * clientv3 . Client , prefix string , addr string , ttl int ) <- chan struct { } { rm := rate . NewLimiter ( rate . Limit ( registerRetryRate ) , registerRetryRate ) donec := make ( chan struct { } ) go func ( ) { defer close ( donec ) for rm . Wait ( c . Ctx ( ) ) == nil { ss , err := registerSession ( c , prefix , addr , ttl ) if err != nil { plog . Warningf ( " " , err ) continue } select { case <- c . Ctx ( ) . Done ( ) : ss . Close ( ) return case <- ss . Done ( ) : plog . Warning ( " " ) plog . Warning ( " " ) continue } } } ( ) return donec } 
func NewRawNode ( config * Config , peers [ ] Peer ) ( * RawNode , error ) { if config . ID == 0 { panic ( " " ) } r := newRaft ( config ) rn := & RawNode { raft : r , } lastIndex , err := config . Storage . LastIndex ( ) if err != nil { panic ( err ) } ents := make ( [ ] pb . Entry , len ( peers ) ) for i , peer := range peers { cc := pb . ConfChange { Type : pb . ConfChangeAddNode , NodeID : peer . ID , Context : peer . Context } data , err := cc . Marshal ( ) if err != nil { panic ( " " ) } ents [ i ] = pb . Entry { Type : pb . EntryConfChange , Term : 1 , Index : uint64 ( i + 1 ) , Data : data } } r . raftLog . append ( ents ... ) r . raftLog . committed = uint64 ( len ( ents ) ) for _ , peer := range peers { r . addNode ( peer . ID ) } } if lastIndex == 0 { rn . prevHardSt = emptyState } else { rn . prevHardSt = r . hardState ( ) } return rn , nil } 
func ( rn * RawNode ) Campaign ( ) error { return rn . raft . Step ( pb . Message { Type : pb . MsgHup , } ) } 
func ( rn * RawNode ) Propose ( data [ ] byte ) error { return rn . raft . Step ( pb . Message { Type : pb . MsgProp , From : rn . raft . id , Entries : [ ] pb . Entry { { Data : data } , } } ) } 
func ( rn * RawNode ) ProposeConfChange ( cc pb . ConfChange ) error { data , err := cc . Marshal ( ) if err != nil { return err } return rn . raft . Step ( pb . Message { Type : pb . MsgProp , Entries : [ ] pb . Entry { { Type : pb . EntryConfChange , Data : data } , } , } ) } 
func ( rn * RawNode ) ApplyConfChange ( cc pb . ConfChange ) * pb . ConfState { if cc . NodeID == None { return & pb . ConfState { Nodes : rn . raft . nodes ( ) , Learners : rn . raft . learnerNodes ( ) } } switch cc . Type { case pb . ConfChangeAddNode : rn . raft . addNode ( cc . NodeID ) case pb . ConfChangeAddLearnerNode : rn . raft . addLearner ( cc . NodeID ) case pb . ConfChangeRemoveNode : rn . raft . removeNode ( cc . NodeID ) case pb . ConfChangeUpdateNode : default : panic ( " " ) } return & pb . ConfState { Nodes : rn . raft . nodes ( ) , Learners : rn . raft . learnerNodes ( ) } } 
func ( rn * RawNode ) Step ( m pb . Message ) error { } if pr := rn . raft . getProgress ( m . From ) ; pr != nil || ! IsResponseMsg ( m . Type ) { return rn . raft . Step ( m ) } return ErrStepPeerNotFound } 
func ( rn * RawNode ) Ready ( ) Ready { rd := rn . newReady ( ) rn . raft . msgs = nil rn . raft . reduceUncommittedSize ( rd . CommittedEntries ) return rd } 
func ( rn * RawNode ) HasReady ( ) bool { r := rn . raft if ! r . softState ( ) . equal ( rn . prevSoftSt ) { return true } if hardSt := r . hardState ( ) ; ! IsEmptyHardState ( hardSt ) && ! isHardStateEqual ( hardSt , rn . prevHardSt ) { return true } if r . raftLog . unstable . snapshot != nil && ! IsEmptySnap ( * r . raftLog . unstable . snapshot ) { return true } if len ( r . msgs ) > 0 || len ( r . raftLog . unstableEntries ( ) ) > 0 || r . raftLog . hasNextEnts ( ) { return true } if len ( r . readStates ) != 0 { return true } return false } 
func ( rn * RawNode ) WithProgress ( visitor func ( id uint64 , typ ProgressType , pr Progress ) ) { for id , pr := range rn . raft . prs { pr := * pr pr . ins = nil visitor ( id , ProgressTypePeer , pr ) } for id , pr := range rn . raft . learnerPrs { pr := * pr pr . ins = nil visitor ( id , ProgressTypeLearner , pr ) } } 
func ( rn * RawNode ) ReportUnreachable ( id uint64 ) { _ = rn . raft . Step ( pb . Message { Type : pb . MsgUnreachable , From : id } ) } 
func ( rn * RawNode ) ReportSnapshot ( id uint64 , status SnapshotStatus ) { rej := status == SnapshotFailure _ = rn . raft . Step ( pb . Message { Type : pb . MsgSnapStatus , From : id , Reject : rej } ) } 
func ( rn * RawNode ) TransferLeader ( transferee uint64 ) { _ = rn . raft . Step ( pb . Message { Type : pb . MsgTransferLeader , From : transferee } ) } 
func ( rn * RawNode ) ReadIndex ( rctx [ ] byte ) { _ = rn . raft . Step ( pb . Message { Type : pb . MsgReadIndex , Entries : [ ] pb . Entry { { Data : rctx } } } ) } 
func printcURL ( req * http . Request ) error { if ! cURLDebug { return nil } var ( command string b [ ] byte err error ) if req . URL != nil { command = fmt . Sprintf ( " " , req . Method , req . URL . String ( ) ) } if req . Body != nil { b , err = ioutil . ReadAll ( req . Body ) if err != nil { return err } command += fmt . Sprintf ( " " , string ( b ) ) } fmt . Fprintf ( os . Stderr , " \n " , command ) req . Body = ioutil . NopCloser ( body ) return nil } 
func Fsync ( f * os . File ) error { _ , _ , errno := syscall . Syscall ( syscall . SYS_FCNTL , f . Fd ( ) , uintptr ( syscall . F_FULLFSYNC ) , uintptr ( 0 ) ) if errno == 0 { return nil } return errno } 
func ( rd Ready ) appliedCursor ( ) uint64 { if n := len ( rd . CommittedEntries ) ; n > 0 { return rd . CommittedEntries [ n - 1 ] . Index } if index := rd . Snapshot . Metadata . Index ; index > 0 { return index } return 0 } 
func StartNode ( c * Config , peers [ ] Peer ) Node { r := newRaft ( c ) for _ , peer := range peers { cc := pb . ConfChange { Type : pb . ConfChangeAddNode , NodeID : peer . ID , Context : peer . Context } d , err := cc . Marshal ( ) if err != nil { panic ( " " ) } e := pb . Entry { Type : pb . EntryConfChange , Term : 1 , Index : r . raftLog . lastIndex ( ) + 1 , Data : d } r . raftLog . append ( e ) } } n := newNode ( ) n . logger = c . Logger go n . run ( r ) return & n } 
func RestartNode ( c * Config ) Node { r := newRaft ( c ) n := newNode ( ) n . logger = c . Logger go n . run ( r ) return & n } 
func ( n * node ) Tick ( ) { select { case n . tickc <- struct { } { } : case <- n . done : default : n . logger . Warningf ( " " ) } } 
func ( n * node ) stepWithWaitOption ( ctx context . Context , m pb . Message , wait bool ) error { if m . Type != pb . MsgProp { select { case n . recvc <- m : return nil case <- ctx . Done ( ) : return ctx . Err ( ) case <- n . done : return ErrStopped } } ch := n . propc pm := msgWithResult { m : m } if wait { pm . result = make ( chan error , 1 ) } select { case ch <- pm : if ! wait { return nil } case <- ctx . Done ( ) : return ctx . Err ( ) case <- n . done : return ErrStopped } select { case err := <- pm . result : if err != nil { return err } case <- ctx . Done ( ) : return ctx . Err ( ) case <- n . done : return ErrStopped } return nil } 
func MustSync ( st , prevst pb . HardState , entsnum int ) bool { } 
func NewGRPC17Health ( eps [ ] string , timeout time . Duration , dialFunc DialFunc , ) * GRPC17Health { notifyCh := make ( chan [ ] grpc . Address ) addrs := eps2addrs ( eps ) hb := & GRPC17Health { addrs : addrs , eps : eps , notifyCh : notifyCh , readyc : make ( chan struct { } ) , healthCheck : func ( ep string ) ( bool , error ) { return grpcHealthCheck ( ep , dialFunc ) } , unhealthyHostPorts : make ( map [ string ] time . Time ) , upc : make ( chan struct { } ) , stopc : make ( chan struct { } ) , downc : make ( chan struct { } ) , donec : make ( chan struct { } ) , updateAddrsC : make ( chan NotifyMsg ) , hostPort2ep : getHostPort2ep ( eps ) , } if timeout < minHealthRetryDuration { timeout = minHealthRetryDuration } hb . healthCheckTimeout = timeout close ( hb . downc ) go hb . updateNotifyLoop ( ) hb . wg . Add ( 1 ) go func ( ) { defer hb . wg . Done ( ) hb . updateUnhealthy ( ) } ( ) return hb } 
func ( b * GRPC17Health ) NeedUpdate ( ) bool { update := ! hasAddr ( b . addrs , b . pinAddr ) b . mu . RUnlock ( ) return update } 
func dflSignal ( sig syscall . Signal ) { ptr := unsafe . Pointer ( & sigactBuf ) syscall . Syscall6 ( uintptr ( syscall . SYS_RT_SIGACTION ) , uintptr ( sig ) , uintptr ( ptr ) , 0 , 8 , 0 , 0 ) } 
func New ( namespaces ... string ) Store { s := newStore ( namespaces ... ) s . clock = clockwork . NewRealClock ( ) return s } 
func ( s * store ) Index ( ) uint64 { s . worldLock . RLock ( ) defer s . worldLock . RUnlock ( ) return s . CurrentIndex } 
func ( s * store ) Get ( nodePath string , recursive , sorted bool ) ( * Event , error ) { var err * v2error . Error s . worldLock . RLock ( ) defer s . worldLock . RUnlock ( ) defer func ( ) { if err == nil { s . Stats . Inc ( GetSuccess ) if recursive { reportReadSuccess ( GetRecursive ) } else { reportReadSuccess ( Get ) } return } s . Stats . Inc ( GetFail ) if recursive { reportReadFailure ( GetRecursive ) } else { reportReadFailure ( Get ) } } ( ) n , err := s . internalGet ( nodePath ) if err != nil { return nil , err } e := newEvent ( Get , nodePath , n . ModifiedIndex , n . CreatedIndex ) e . EtcdIndex = s . CurrentIndex e . Node . loadInternalNode ( n , recursive , sorted , s . clock ) return e , nil } 
func ( s * store ) Create ( nodePath string , dir bool , value string , unique bool , expireOpts TTLOptionSet ) ( * Event , error ) { var err * v2error . Error s . worldLock . Lock ( ) defer s . worldLock . Unlock ( ) defer func ( ) { if err == nil { s . Stats . Inc ( CreateSuccess ) reportWriteSuccess ( Create ) return } s . Stats . Inc ( CreateFail ) reportWriteFailure ( Create ) } ( ) e , err := s . internalCreate ( nodePath , dir , value , unique , false , expireOpts . ExpireTime , Create ) if err != nil { return nil , err } e . EtcdIndex = s . CurrentIndex s . WatcherHub . notify ( e ) return e , nil } 
func ( s * store ) Set ( nodePath string , dir bool , value string , expireOpts TTLOptionSet ) ( * Event , error ) { var err * v2error . Error s . worldLock . Lock ( ) defer s . worldLock . Unlock ( ) defer func ( ) { if err == nil { s . Stats . Inc ( SetSuccess ) reportWriteSuccess ( Set ) return } s . Stats . Inc ( SetFail ) reportWriteFailure ( Set ) } ( ) if getErr != nil && getErr . ErrorCode != v2error . EcodeKeyNotFound { err = getErr return nil , err } if expireOpts . Refresh { if getErr != nil { err = getErr return nil , err } value = n . Value } if err != nil { return nil , err } e . EtcdIndex = s . CurrentIndex prev . Node . loadInternalNode ( n , false , false , s . clock ) e . PrevNode = prev . Node } if ! expireOpts . Refresh { s . WatcherHub . notify ( e ) } else { e . SetRefresh ( ) s . WatcherHub . add ( e ) } return e , nil } 
func getCompareFailCause ( n * node , which int , prevValue string , prevIndex uint64 ) string { switch which { case CompareIndexNotMatch : return fmt . Sprintf ( " " , prevIndex , n . ModifiedIndex ) case CompareValueNotMatch : return fmt . Sprintf ( " " , prevValue , n . Value ) default : return fmt . Sprintf ( " " , prevValue , n . Value , prevIndex , n . ModifiedIndex ) } } 
func ( s * store ) Delete ( nodePath string , dir , recursive bool ) ( * Event , error ) { var err * v2error . Error s . worldLock . Lock ( ) defer s . worldLock . Unlock ( ) defer func ( ) { if err == nil { s . Stats . Inc ( DeleteSuccess ) reportWriteSuccess ( Delete ) return } s . Stats . Inc ( DeleteFail ) reportWriteFailure ( Delete ) } ( ) nodePath = path . Clean ( path . Join ( " " , nodePath ) ) } } n , err := s . internalGet ( nodePath ) if err != nil { } nextIndex := s . CurrentIndex + 1 e := newEvent ( Delete , nodePath , nextIndex , n . CreatedIndex ) e . EtcdIndex = nextIndex e . PrevNode = n . Repr ( false , false , s . clock ) eNode := e . Node if n . IsDir ( ) { eNode . Dir = true } callback := func ( path string ) { } err = n . Remove ( dir , recursive , callback ) if err != nil { return nil , err } s . WatcherHub . notify ( e ) return e , nil } 
func ( s * store ) walk ( nodePath string , walkFunc func ( prev * node , component string ) ( * node , * v2error . Error ) ) ( * node , * v2error . Error ) { components := strings . Split ( nodePath , " " ) curr := s . Root var err * v2error . Error for i := 1 ; i < len ( components ) ; i ++ { if len ( components [ i ] ) == 0 { } curr , err = walkFunc ( curr , components [ i ] ) if err != nil { return nil , err } } return curr , nil } 
func ( s * store ) Update ( nodePath string , newValue string , expireOpts TTLOptionSet ) ( * Event , error ) { var err * v2error . Error s . worldLock . Lock ( ) defer s . worldLock . Unlock ( ) defer func ( ) { if err == nil { s . Stats . Inc ( UpdateSuccess ) reportWriteSuccess ( Update ) return } s . Stats . Inc ( UpdateFail ) reportWriteFailure ( Update ) } ( ) nodePath = path . Clean ( path . Join ( " " , nodePath ) ) } currIndex , nextIndex := s . CurrentIndex , s . CurrentIndex + 1 n , err := s . internalGet ( nodePath ) if err != nil { } if n . IsDir ( ) && len ( newValue ) != 0 { } if expireOpts . Refresh { newValue = n . Value } e := newEvent ( Update , nodePath , nextIndex , n . CreatedIndex ) e . EtcdIndex = nextIndex e . PrevNode = n . Repr ( false , false , s . clock ) eNode := e . Node n . Write ( newValue , nextIndex ) if n . IsDir ( ) { eNode . Dir = true } else { eNode . Value = & newValueCopy } eNode . Expiration , eNode . TTL = n . expirationAndTTL ( s . clock ) if ! expireOpts . Refresh { s . WatcherHub . notify ( e ) } else { e . SetRefresh ( ) s . WatcherHub . add ( e ) } s . CurrentIndex = nextIndex return e , nil } 
func ( s * store ) internalGet ( nodePath string ) ( * node , * v2error . Error ) { nodePath = path . Clean ( path . Join ( " " , nodePath ) ) walkFunc := func ( parent * node , name string ) ( * node , * v2error . Error ) { if ! parent . IsDir ( ) { err := v2error . NewError ( v2error . EcodeNotDir , parent . Path , s . CurrentIndex ) return nil , err } child , ok := parent . Children [ name ] if ok { return child , nil } return nil , v2error . NewError ( v2error . EcodeKeyNotFound , path . Join ( parent . Path , name ) , s . CurrentIndex ) } f , err := s . walk ( nodePath , walkFunc ) if err != nil { return nil , err } return f , nil } 
func ( s * store ) DeleteExpiredKeys ( cutoff time . Time ) { s . worldLock . Lock ( ) defer s . worldLock . Unlock ( ) for { node := s . ttlKeyHeap . top ( ) if node == nil || node . ExpireTime . After ( cutoff ) { break } s . CurrentIndex ++ e := newEvent ( Expire , node . Path , s . CurrentIndex , node . CreatedIndex ) e . EtcdIndex = s . CurrentIndex e . PrevNode = node . Repr ( false , false , s . clock ) if node . IsDir ( ) { e . Node . Dir = true } callback := func ( path string ) { } s . ttlKeyHeap . pop ( ) node . Remove ( true , true , callback ) reportExpiredKey ( ) s . Stats . Inc ( ExpireCount ) s . WatcherHub . notify ( e ) } } 
func ( s * store ) checkDir ( parent * node , dirName string ) ( * node , * v2error . Error ) { node , ok := parent . Children [ dirName ] if ok { if node . IsDir ( ) { return node , nil } return nil , v2error . NewError ( v2error . EcodeNotDir , node . Path , s . CurrentIndex ) } n := newDir ( s , path . Join ( parent . Path , dirName ) , s . CurrentIndex + 1 , parent , Permanent ) parent . Children [ dirName ] = n return n , nil } 
func ( s * store ) Save ( ) ( [ ] byte , error ) { b , err := json . Marshal ( s . Clone ( ) ) if err != nil { return nil , err } return b , nil } 
func ( s * store ) Recovery ( state [ ] byte ) error { s . worldLock . Lock ( ) defer s . worldLock . Unlock ( ) err := json . Unmarshal ( state , s ) if err != nil { return err } s . ttlKeyHeap = newTtlKeyHeap ( ) s . Root . recoverAndclean ( ) return nil } 
func ( g * Generator ) Next ( ) uint64 { suffix := atomic . AddUint64 ( & g . suffix , 1 ) id := g . prefix | lowbit ( suffix , suffixLen ) return id } 
func NewMakeMirrorCommand ( ) * cobra . Command { c := & cobra . Command { Use : " " , Short : " " , Run : makeMirrorCommandFunc , } c . Flags ( ) . StringVar ( & mmprefix , " " , " " , " " ) c . Flags ( ) . StringVar ( & mmdestprefix , " " , " " , " " ) c . Flags ( ) . BoolVar ( & mmnodestprefix , " " , false , " " ) c . Flags ( ) . StringVar ( & mmcert , " " , " " , " " ) c . Flags ( ) . StringVar ( & mmkey , " " , " " , " " ) c . Flags ( ) . StringVar ( & mmcacert , " " , " " , " " ) return c } 
func ( cfg Config ) GetLogger ( ) * zap . Logger { cfg . loggerMu . RLock ( ) l := cfg . logger cfg . loggerMu . RUnlock ( ) return l } 
func ( cfg * Config ) setupLogging ( ) error { len2 := len ( cfg . LogOutputs ) if len1 != len2 { switch { case len1 > len2 : cfg . LogOutputs = cfg . DeprecatedLogOutput case len1 < len2 : } } else { if len1 > 1 { return errors . New ( " " ) } if len1 < 1 { return errors . New ( " " ) } if reflect . DeepEqual ( cfg . DeprecatedLogOutput , cfg . LogOutputs ) && cfg . DeprecatedLogOutput [ 0 ] != DefaultLogOutput { return fmt . Errorf ( " " , cfg . DeprecatedLogOutput , cfg . LogOutputs ) } if ! reflect . DeepEqual ( cfg . DeprecatedLogOutput , [ ] string { DefaultLogOutput } ) { fmt . Fprintf ( os . Stderr , " \n " , cfg . DeprecatedLogOutput ) fmt . Fprintln ( os . Stderr , " " ) } } switch cfg . Logger { case " " : cfg . PeerTLSInfo . HandshakeFailure = logTLSHandshakeFailure if cfg . Debug { capnslog . SetGlobalLogLevel ( capnslog . DEBUG ) grpc . EnableTracing = true } else { capnslog . SetGlobalLogLevel ( capnslog . INFO ) } settings , err := repoLog . ParseLogLevelConfig ( cfg . LogPkgLevels ) if err != nil { plog . Warningf ( " " , err . Error ( ) ) return nil } repoLog . SetLogLevel ( settings ) } if len ( cfg . LogOutputs ) != 1 { return fmt . Errorf ( " " , cfg . LogOutputs ) } switch output { case StdErrLogOutput : capnslog . SetFormatter ( capnslog . NewPrettyFormatter ( os . Stderr , cfg . Debug ) ) case StdOutLogOutput : capnslog . SetFormatter ( capnslog . NewPrettyFormatter ( os . Stdout , cfg . Debug ) ) case DefaultLogOutput : default : return fmt . Errorf ( " " , output , DefaultLogOutput , StdErrLogOutput , StdOutLogOutput ) } case " " : if len ( cfg . LogOutputs ) == 0 { cfg . LogOutputs = [ ] string { DefaultLogOutput } } if len ( cfg . LogOutputs ) > 1 { for _ , v := range cfg . LogOutputs { if v == DefaultLogOutput { return fmt . Errorf ( " " , DefaultLogOutput ) } } } outputPaths , errOutputPaths := make ( [ ] string , 0 ) , make ( [ ] string , 0 ) isJournal := false for _ , v := range cfg . LogOutputs { switch v { case DefaultLogOutput : outputPaths = append ( outputPaths , StdErrLogOutput ) errOutputPaths = append ( errOutputPaths , StdErrLogOutput ) case JournalLogOutput : isJournal = true case StdErrLogOutput : outputPaths = append ( outputPaths , StdErrLogOutput ) errOutputPaths = append ( errOutputPaths , StdErrLogOutput ) case StdOutLogOutput : outputPaths = append ( outputPaths , StdOutLogOutput ) errOutputPaths = append ( errOutputPaths , StdOutLogOutput ) default : outputPaths = append ( outputPaths , v ) errOutputPaths = append ( errOutputPaths , v ) } } if ! isJournal { copied := logutil . AddOutputPaths ( logutil . DefaultZapLoggerConfig , outputPaths , errOutputPaths ) if cfg . Debug { copied . Level = zap . NewAtomicLevelAt ( zap . DebugLevel ) grpc . EnableTracing = true } if cfg . ZapLoggerBuilder == nil { cfg . ZapLoggerBuilder = func ( c * Config ) error { var err error c . logger , err = copied . Build ( ) if err != nil { return err } c . loggerMu . Lock ( ) defer c . loggerMu . Unlock ( ) c . loggerConfig = & copied c . loggerCore = nil c . loggerWriteSyncer = nil grpcLogOnce . Do ( func ( ) { gl , err = logutil . NewGRPCLoggerV2 ( copied ) if err == nil { grpclog . SetLoggerV2 ( gl ) } } ) return nil } } } else { if len ( cfg . LogOutputs ) > 1 { for _ , v := range cfg . LogOutputs { if v != DefaultLogOutput { return fmt . Errorf ( " " , cfg . LogOutputs ) } } } if lerr != nil { return lerr } lvl := zap . NewAtomicLevelAt ( zap . InfoLevel ) if cfg . Debug { lvl = zap . NewAtomicLevelAt ( zap . DebugLevel ) grpc . EnableTracing = true } if cfg . ZapLoggerBuilder == nil { cfg . ZapLoggerBuilder = func ( c * Config ) error { c . logger = zap . New ( cr , zap . AddCaller ( ) , zap . ErrorOutput ( syncer ) ) c . loggerMu . Lock ( ) defer c . loggerMu . Unlock ( ) c . loggerConfig = nil c . loggerCore = cr c . loggerWriteSyncer = syncer grpcLogOnce . Do ( func ( ) { grpclog . SetLoggerV2 ( logutil . NewGRPCLoggerV2FromZapCore ( cr , syncer ) ) } ) return nil } } } err := cfg . ZapLoggerBuilder ( cfg ) if err != nil { return err } logTLSHandshakeFailure := func ( conn * tls . Conn , err error ) { state := conn . ConnectionState ( ) remoteAddr := conn . RemoteAddr ( ) . String ( ) serverName := state . ServerName if len ( state . PeerCertificates ) > 0 { cert := state . PeerCertificates [ 0 ] ips := make ( [ ] string , 0 , len ( cert . IPAddresses ) ) for i := range cert . IPAddresses { ips [ i ] = cert . IPAddresses [ i ] . String ( ) } cfg . logger . Warn ( " " , zap . String ( " " , remoteAddr ) , zap . String ( " " , serverName ) , zap . Strings ( " " , ips ) , zap . Strings ( " " , cert . DNSNames ) , zap . Error ( err ) , ) } else { cfg . logger . Warn ( " " , zap . String ( " " , remoteAddr ) , zap . String ( " " , serverName ) , zap . Error ( err ) , ) } } cfg . ClientTLSInfo . HandshakeFailure = logTLSHandshakeFailure cfg . PeerTLSInfo . HandshakeFailure = logTLSHandshakeFailure default : return fmt . Errorf ( " " , cfg . Logger ) } return nil } 
func NewZapCoreLoggerBuilder ( lg * zap . Logger , cr zapcore . Core , syncer zapcore . WriteSyncer ) func ( * Config ) error { return func ( cfg * Config ) error { cfg . loggerMu . Lock ( ) defer cfg . loggerMu . Unlock ( ) cfg . logger = lg cfg . loggerConfig = nil cfg . loggerCore = cr cfg . loggerWriteSyncer = syncer grpcLogOnce . Do ( func ( ) { grpclog . SetLoggerV2 ( logutil . NewGRPCLoggerV2FromZapCore ( cr , syncer ) ) } ) return nil } } 
func NewSyncer ( c * clientv3 . Client , prefix string , rev int64 ) Syncer { return & syncer { c : c , prefix : prefix , rev : rev } } 
func DropPort ( port int ) error { cmdStr := fmt . Sprintf ( " " , port ) if _ , err := exec . Command ( " " , " " , cmdStr ) . Output ( ) ; err != nil { return err } cmdStr = fmt . Sprintf ( " " , port ) _ , err := exec . Command ( " " , " " , cmdStr ) . Output ( ) return err } 
func SetLatency ( ms , rv int ) error { ifces , err := GetDefaultInterfaces ( ) if err != nil { return err } if rv > ms { rv = 1 } for ifce := range ifces { cmdStr := fmt . Sprintf ( " " , ifce , ms , rv ) _ , err = exec . Command ( " " , " " , cmdStr ) . Output ( ) if err != nil { _ , err = exec . Command ( " " , " " , cmdStr ) . Output ( ) if err != nil { return err } } } return nil } 
func RemoveLatency ( ) error { ifces , err := GetDefaultInterfaces ( ) if err != nil { return err } for ifce := range ifces { _ , err = exec . Command ( " " , " " , fmt . Sprintf ( " " , ifce ) ) . Output ( ) if err != nil { return err } } return nil } 
func NewTxnCommand ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Run : txnCommandFunc , } cmd . Flags ( ) . BoolVarP ( & txnInteractive , " " , " " , false , " " ) return cmd } 
func txnCommandFunc ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != 0 { ExitWithError ( ExitBadArgs , fmt . Errorf ( " " ) ) } reader := bufio . NewReader ( os . Stdin ) txn := mustClientFromCmd ( cmd ) . Txn ( context . Background ( ) ) promptInteractive ( " " ) txn . If ( readCompares ( reader ) ... ) promptInteractive ( " " ) txn . Then ( readOps ( reader ) ... ) promptInteractive ( " " ) txn . Else ( readOps ( reader ) ... ) resp , err := txn . Commit ( ) if err != nil { ExitWithError ( ExitError , err ) } display . Txn ( * resp ) } 
func New ( lg * zap . Logger , mode string , retention time . Duration , rg RevGetter , c Compactable , ) ( Compactor , error ) { switch mode { case ModePeriodic : return newPeriodic ( lg , clockwork . NewRealClock ( ) , retention , rg , c ) , nil case ModeRevision : return newRevision ( lg , clockwork . NewRealClock ( ) , int64 ( retention ) , rg , c ) , nil default : return nil , fmt . Errorf ( " " , mode ) } } 
func printResponseKey ( resp * client . Response , format string ) { } else { fmt . Println ( " " , resp . PrevNode . Value ) } case " " : fmt . Println ( " " , resp . Node . CreatedIndex ) fmt . Println ( " " , resp . Node . ModifiedIndex ) if resp . PrevNode != nil { fmt . Println ( " " , resp . PrevNode . Value ) } fmt . Println ( " " , resp . Node . TTL ) fmt . Println ( " " , resp . Index ) if resp . Action != " " { fmt . Println ( " " ) fmt . Println ( resp . Node . Value ) } case " " : b , err := json . Marshal ( resp ) if err != nil { panic ( err ) } fmt . Println ( string ( b ) ) default : fmt . Fprintln ( os . Stderr , " " , format ) } } 
func RegisterLockHandler ( ctx context . Context , mux * runtime . ServeMux , conn * grpc . ClientConn ) error { return RegisterLockHandlerClient ( ctx , mux , v3lockpb . NewLockClient ( conn ) ) } 
func RegisterLockHandlerClient ( ctx context . Context , mux * runtime . ServeMux , client v3lockpb . LockClient ) error { mux . Handle ( " " , pattern_Lock_Lock_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lock_Lock_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lock_Lock_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) mux . Handle ( " " , pattern_Lock_Unlock_0 , func ( w http . ResponseWriter , req * http . Request , pathParams map [ string ] string ) { ctx , cancel := context . WithCancel ( req . Context ( ) ) defer cancel ( ) if cn , ok := w . ( http . CloseNotifier ) ; ok { go func ( done <- chan struct { } , closed <- chan bool ) { select { case <- done : case <- closed : cancel ( ) } } ( ctx . Done ( ) , cn . CloseNotify ( ) ) } inboundMarshaler , outboundMarshaler := runtime . MarshalerForRequest ( mux , req ) rctx , err := runtime . AnnotateContext ( ctx , mux , req ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } resp , md , err := request_Lock_Unlock_0 ( rctx , inboundMarshaler , client , req , pathParams ) ctx = runtime . NewServerMetadataContext ( ctx , md ) if err != nil { runtime . HTTPError ( ctx , mux , outboundMarshaler , w , req , err ) return } forward_Lock_Unlock_0 ( ctx , mux , outboundMarshaler , w , req , resp , mux . GetForwardResponseOptions ( ) ... ) } ) return nil } 
func NewServer ( cfg ServerConfig ) Server { s := & server { lg : cfg . Logger , from : cfg . From , to : cfg . To , tlsInfo : cfg . TLSInfo , dialTimeout : cfg . DialTimeout , bufferSize : cfg . BufferSize , retryInterval : cfg . RetryInterval , readyc : make ( chan struct { } ) , donec : make ( chan struct { } ) , errc : make ( chan error , 16 ) , pauseAcceptc : make ( chan struct { } ) , pauseTxc : make ( chan struct { } ) , pauseRxc : make ( chan struct { } ) , } _ , fromPort , err := net . SplitHostPort ( cfg . From . Host ) if err == nil { s . fromPort , _ = strconv . Atoi ( fromPort ) } var toPort string _ , toPort , err = net . SplitHostPort ( cfg . To . Host ) if err == nil { s . toPort , _ = strconv . Atoi ( toPort ) } if s . dialTimeout == 0 { s . dialTimeout = defaultDialTimeout } if s . bufferSize == 0 { s . bufferSize = defaultBufferSize } if s . retryInterval == 0 { s . retryInterval = defaultRetryInterval } if s . lg == nil { s . lg = defaultLogger } close ( s . pauseAcceptc ) close ( s . pauseTxc ) close ( s . pauseRxc ) if strings . HasPrefix ( s . from . Scheme , " " ) { s . from . Scheme = " " } if strings . HasPrefix ( s . to . Scheme , " " ) { s . to . Scheme = " " } addr := fmt . Sprintf ( " " , s . fromPort ) if s . fromPort == 0 { } var ln net . Listener if ! s . tlsInfo . Empty ( ) { ln , err = transport . NewListener ( addr , s . from . Scheme , & s . tlsInfo ) } else { ln , err = net . Listen ( s . from . Scheme , addr ) } if err != nil { s . errc <- err s . Close ( ) return s } s . listener = ln s . closeWg . Add ( 1 ) go s . listenAndServe ( ) s . lg . Info ( " " , zap . String ( " " , s . From ( ) ) , zap . String ( " " , s . To ( ) ) ) return s } 
func ( s * server ) listenAndServe ( ) { defer s . closeWg . Done ( ) s . lg . Info ( " " , zap . String ( " " , s . From ( ) ) ) close ( s . readyc ) for { s . pauseAcceptMu . Lock ( ) pausec := s . pauseAcceptc s . pauseAcceptMu . Unlock ( ) select { case <- pausec : case <- s . donec : return } s . latencyAcceptMu . RLock ( ) lat := s . latencyAccept s . latencyAcceptMu . RUnlock ( ) if lat > 0 { select { case <- time . After ( lat ) : case <- s . donec : return } } s . listenerMu . RLock ( ) ln := s . listener s . listenerMu . RUnlock ( ) in , err := ln . Accept ( ) if err != nil { select { case s . errc <- err : select { case <- s . donec : return default : } case <- s . donec : return } s . lg . Debug ( " " , zap . Error ( err ) ) if strings . HasSuffix ( err . Error ( ) , " " ) { select { case <- time . After ( s . retryInterval ) : case <- s . donec : return } s . lg . Debug ( " " , zap . String ( " " , s . From ( ) ) ) if err = s . ResetListener ( ) ; err != nil { select { case s . errc <- err : select { case <- s . donec : return default : } case <- s . donec : return } s . lg . Warn ( " " , zap . Error ( err ) ) } } continue } var out net . Conn if ! s . tlsInfo . Empty ( ) { var tp * http . Transport tp , err = transport . NewTransport ( s . tlsInfo , s . dialTimeout ) if err != nil { select { case s . errc <- err : select { case <- s . donec : return default : } case <- s . donec : return } continue } out , err = tp . Dial ( s . to . Scheme , s . to . Host ) } else { out , err = net . Dial ( s . to . Scheme , s . to . Host ) } if err != nil { select { case s . errc <- err : select { case <- s . donec : return default : } case <- s . donec : return } s . lg . Debug ( " " , zap . Error ( err ) ) continue } go func ( ) { out . Close ( ) in . Close ( ) } ( ) go func ( ) { in . Close ( ) out . Close ( ) } ( ) } } 
func ( sctx * serveCtx ) serve ( s * etcdserver . EtcdServer , tlsinfo * transport . TLSInfo , handler http . Handler , errHandler func ( error ) , gopts ... grpc . ServerOption ) ( err error ) { logger := defaultLog . New ( ioutil . Discard , " " , 0 ) <- s . ReadyNotify ( ) if sctx . lg == nil { plog . Info ( " " ) } m := cmux . New ( sctx . l ) v3c := v3client . New ( s ) servElection := v3election . NewElectionServer ( v3c ) servLock := v3lock . NewLockServer ( v3c ) var gs * grpc . Server defer func ( ) { if err != nil && gs != nil { gs . Stop ( ) } } ( ) if sctx . insecure { gs = v3rpc . Server ( s , nil , gopts ... ) v3electionpb . RegisterElectionServer ( gs , servElection ) v3lockpb . RegisterLockServer ( gs , servLock ) if sctx . serviceRegister != nil { sctx . serviceRegister ( gs ) } grpcl := m . Match ( cmux . HTTP2 ( ) ) go func ( ) { errHandler ( gs . Serve ( grpcl ) ) } ( ) var gwmux * gw . ServeMux if s . Cfg . EnableGRPCGateway { gwmux , err = sctx . registerGateway ( [ ] grpc . DialOption { grpc . WithInsecure ( ) } ) if err != nil { return err } } httpmux := sctx . createMux ( gwmux , handler ) srvhttp := & http . Server { Handler : createAccessController ( sctx . lg , s , httpmux ) , ErrorLog : logger , httpl := m . Match ( cmux . HTTP1 ( ) ) go func ( ) { errHandler ( srvhttp . Serve ( httpl ) ) } ( ) sctx . serversC <- & servers { grpc : gs , http : srvhttp } if sctx . lg != nil { sctx . lg . Info ( " " , zap . String ( " " , sctx . l . Addr ( ) . String ( ) ) , ) } else { plog . Noticef ( " " , sctx . l . Addr ( ) . String ( ) ) } } if sctx . secure { tlscfg , tlsErr := tlsinfo . ServerConfig ( ) if tlsErr != nil { return tlsErr } gs = v3rpc . Server ( s , tlscfg , gopts ... ) v3electionpb . RegisterElectionServer ( gs , servElection ) v3lockpb . RegisterLockServer ( gs , servLock ) if sctx . serviceRegister != nil { sctx . serviceRegister ( gs ) } handler = grpcHandlerFunc ( gs , handler ) var gwmux * gw . ServeMux if s . Cfg . EnableGRPCGateway { dtls := tlscfg . Clone ( ) creds := credentials . NewTLS ( dtls ) opts := [ ] grpc . DialOption { grpc . WithTransportCredentials ( creds ) } gwmux , err = sctx . registerGateway ( opts ) if err != nil { return err } } var tlsl net . Listener tlsl , err = transport . NewTLSListener ( m . Match ( cmux . Any ( ) ) , tlsinfo ) if err != nil { return err } srv := & http . Server { Handler : createAccessController ( sctx . lg , s , httpmux ) , TLSConfig : tlscfg , ErrorLog : logger , go func ( ) { errHandler ( srv . Serve ( tlsl ) ) } ( ) sctx . serversC <- & servers { secure : true , grpc : gs , http : srv } if sctx . lg != nil { sctx . lg . Info ( " " , zap . String ( " " , sctx . l . Addr ( ) . String ( ) ) , ) } else { plog . Infof ( " " , sctx . l . Addr ( ) . String ( ) ) } } close ( sctx . serversC ) return m . Serve ( ) } 
func grpcHandlerFunc ( grpcServer * grpc . Server , otherHandler http . Handler ) http . Handler { if otherHandler == nil { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { grpcServer . ServeHTTP ( w , r ) } ) } return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { if r . ProtoMajor == 2 && strings . Contains ( r . Header . Get ( " " ) , " " ) { grpcServer . ServeHTTP ( w , r ) } else { otherHandler . ServeHTTP ( w , r ) } } ) } 
func createAccessController ( lg * zap . Logger , s * etcdserver . EtcdServer , mux * http . ServeMux ) http . Handler { return & accessController { lg : lg , s : s , mux : mux } } 
func addCORSHeader ( w http . ResponseWriter , origin string ) { w . Header ( ) . Add ( " " , " " ) w . Header ( ) . Add ( " " , origin ) w . Header ( ) . Add ( " " , " " ) } 
func WrapCORS ( cors map [ string ] struct { } , h http . Handler ) http . Handler { return & corsHandler { ac : & etcdserver . AccessController { CORS : cors } , h : h , } } 
func ( txn * txnLeasing ) fallback ( ops [ ] v3 . Op ) ( fbOps [ ] v3 . Op ) { for _ , op := range ops { if op . IsGet ( ) { continue } lkey , lend := txn . lkv . pfx + string ( op . KeyBytes ( ) ) , " " if len ( op . RangeBytes ( ) ) > 0 { lend = txn . lkv . pfx + string ( op . RangeBytes ( ) ) } fbOps = append ( fbOps , v3 . OpGet ( lkey , v3 . WithRange ( lend ) ) ) } return fbOps } 
func IDFromString ( s string ) ( ID , error ) { i , err := strconv . ParseUint ( s , 16 , 64 ) return ID ( i ) , err } 
func acquireDirectoryLock ( dirPath string , pidFileName string , readOnly bool ) ( * directoryLockGuard , error ) { if err != nil { return nil , errors . Wrap ( err , " " ) } f , err := os . Open ( dirPath ) if err != nil { return nil , errors . Wrapf ( err , " " , dirPath ) } opts := unix . LOCK_EX | unix . LOCK_NB if readOnly { opts = unix . LOCK_SH | unix . LOCK_NB } err = unix . Flock ( int ( f . Fd ( ) ) , opts ) if err != nil { f . Close ( ) return nil , errors . Wrapf ( err , " " , dirPath ) } if ! readOnly { if err != nil { f . Close ( ) return nil , errors . Wrapf ( err , " " , absPidFilePath ) } } return & directoryLockGuard { f , absPidFilePath , readOnly } , nil } 
func ( guard * directoryLockGuard ) release ( ) error { var err error if ! guard . readOnly { } if closeErr := guard . f . Close ( ) ; err == nil { err = closeErr } guard . path = " " guard . f = nil return err } 
func ( v * ValueStruct ) EncodedSize ( ) uint16 { sz := len ( v . Value ) + 2 if v . ExpiresAt == 0 { return uint16 ( sz + 1 ) } enc := sizeVarint ( v . ExpiresAt ) return uint16 ( sz + enc ) } 
func ( v * ValueStruct ) Decode ( b [ ] byte ) { v . Meta = b [ 0 ] v . UserMeta = b [ 1 ] var sz int v . ExpiresAt , sz = binary . Uvarint ( b [ 2 : ] ) v . Value = b [ 2 + sz : ] } 
func ( v * ValueStruct ) Encode ( b [ ] byte ) { b [ 0 ] = v . Meta b [ 1 ] = v . UserMeta sz := binary . PutUvarint ( b [ 2 : ] , v . ExpiresAt ) copy ( b [ 2 + sz : ] , v . Value ) } 
func ( v * ValueStruct ) EncodeTo ( buf * bytes . Buffer ) { buf . WriteByte ( v . Meta ) buf . WriteByte ( v . UserMeta ) var enc [ binary . MaxVarintLen64 ] byte sz := binary . PutUvarint ( enc [ : ] , v . ExpiresAt ) buf . Write ( enc [ : sz ] ) buf . Write ( v . Value ) } 
func NewMergeIterator ( iters [ ] Iterator , reversed bool ) * MergeIterator { m := & MergeIterator { all : iters , reversed : reversed } m . h = make ( elemHeap , 0 , len ( iters ) ) m . initHeap ( ) return m } 
func ( s * MergeIterator ) initHeap ( ) { s . h = s . h [ : 0 ] for idx , itr := range s . all { if ! itr . Valid ( ) { continue } e := & elem { itr : itr , nice : idx , reversed : s . reversed } s . h = append ( s . h , e ) } heap . Init ( & s . h ) for len ( s . h ) > 0 { it := s . h [ 0 ] . itr if it == nil || ! it . Valid ( ) { heap . Pop ( & s . h ) continue } s . storeKey ( s . h [ 0 ] . itr ) break } } 
func ( s * MergeIterator ) Valid ( ) bool { if s == nil { return false } if len ( s . h ) == 0 { return false } return s . h [ 0 ] . itr . Valid ( ) } 
func ( s * MergeIterator ) Key ( ) [ ] byte { if len ( s . h ) == 0 { return nil } return s . h [ 0 ] . itr . Key ( ) } 
func ( s * MergeIterator ) Value ( ) ValueStruct { if len ( s . h ) == 0 { return ValueStruct { } } return s . h [ 0 ] . itr . Value ( ) } 
func ( s * MergeIterator ) Next ( ) { if len ( s . h ) == 0 { return } smallest := s . h [ 0 ] . itr smallest . Next ( ) for len ( s . h ) > 0 { smallest = s . h [ 0 ] . itr if ! smallest . Valid ( ) { heap . Pop ( & s . h ) continue } heap . Fix ( & s . h , 0 ) smallest = s . h [ 0 ] . itr if smallest . Valid ( ) { if ! bytes . Equal ( smallest . Key ( ) , s . curKey ) { break } smallest . Next ( ) } } if ! smallest . Valid ( ) { return } s . storeKey ( smallest ) } 
func ( s * MergeIterator ) Rewind ( ) { for _ , itr := range s . all { itr . Rewind ( ) } s . initHeap ( ) } 
func ( s * MergeIterator ) Seek ( key [ ] byte ) { for _ , itr := range s . all { itr . Seek ( key ) } s . initHeap ( ) } 
func ( s * MergeIterator ) Close ( ) error { for _ , itr := range s . all { if err := itr . Close ( ) ; err != nil { return errors . Wrap ( err , " " ) } } return nil } 
func ( p valuePointer ) Encode ( b [ ] byte ) [ ] byte { binary . BigEndian . PutUint32 ( b [ : 4 ] , p . Fid ) binary . BigEndian . PutUint32 ( b [ 4 : 8 ] , p . Len ) binary . BigEndian . PutUint32 ( b [ 8 : 12 ] , p . Offset ) return b [ : vptrSize ] } 
func ( h * header ) Decode ( buf [ ] byte ) { h . klen = binary . BigEndian . Uint32 ( buf [ 0 : 4 ] ) h . vlen = binary . BigEndian . Uint32 ( buf [ 4 : 8 ] ) h . expiresAt = binary . BigEndian . Uint64 ( buf [ 8 : 16 ] ) h . meta = buf [ 16 ] h . userMeta = buf [ 17 ] } 
func encodeEntry ( e * Entry , buf * bytes . Buffer ) ( int , error ) { h := header { klen : uint32 ( len ( e . Key ) ) , vlen : uint32 ( len ( e . Value ) ) , expiresAt : e . ExpiresAt , meta : e . meta , userMeta : e . UserMeta , } var headerEnc [ headerBufSize ] byte h . Encode ( headerEnc [ : ] ) hash := crc32 . New ( y . CastagnoliCrcTable ) buf . Write ( headerEnc [ : ] ) hash . Write ( headerEnc [ : ] ) buf . Write ( e . Key ) hash . Write ( e . Key ) buf . Write ( e . Value ) hash . Write ( e . Value ) var crcBuf [ crc32 . Size ] byte binary . BigEndian . PutUint32 ( crcBuf [ : ] , hash . Sum32 ( ) ) buf . Write ( crcBuf [ : ] ) return len ( headerEnc ) + len ( e . Key ) + len ( e . Value ) + len ( crcBuf ) , nil } 
func ( db * DB ) NewWriteBatch ( ) * WriteBatch { txn := db . newTransaction ( true , true ) return & WriteBatch { db : db , txn : txn } } 
func ( wb * WriteBatch ) SetEntry ( e * Entry ) error { wb . Lock ( ) defer wb . Unlock ( ) if err := wb . txn . SetEntry ( e ) ; err != ErrTxnTooBig { return err } } return err } return nil } 
func ( wb * WriteBatch ) Set ( k , v [ ] byte , meta byte ) error { e := & Entry { Key : k , Value : v , UserMeta : meta } return wb . SetEntry ( e ) } 
func ( wb * WriteBatch ) SetWithTTL ( key , val [ ] byte , dur time . Duration ) error { expire := time . Now ( ) . Add ( dur ) . Unix ( ) e := & Entry { Key : key , Value : val , ExpiresAt : uint64 ( expire ) } return wb . SetEntry ( e ) } 
func ( wb * WriteBatch ) Delete ( k [ ] byte ) error { wb . Lock ( ) defer wb . Unlock ( ) if err := wb . txn . Delete ( k ) ; err != ErrTxnTooBig { return err } if err := wb . commit ( ) ; err != nil { return err } if err := wb . txn . Delete ( k ) ; err != nil { wb . err = err return err } return nil } 
func ( wb * WriteBatch ) commit ( ) error { if wb . err != nil { return wb . err } wb . txn . CommitWith ( wb . callback ) wb . txn = wb . db . newTransaction ( true , true ) return wb . err } 
func ( wb * WriteBatch ) Flush ( ) error { wb . Lock ( ) _ = wb . commit ( ) wb . txn . Discard ( ) wb . Unlock ( ) wb . wg . Wait ( ) } 
func ( wb * WriteBatch ) Error ( ) error { wb . Lock ( ) defer wb . Unlock ( ) return wb . err } 
func Open ( opt Options ) ( db * DB , err error ) { opt . maxBatchSize = ( 15 * opt . MaxTableSize ) / 100 opt . maxBatchCount = opt . maxBatchSize / int64 ( skl . MaxNodeSize ) if opt . ValueThreshold > math . MaxUint16 - 16 { return nil , ErrValueThreshold } if opt . ReadOnly { } for _ , path := range [ ] string { opt . Dir , opt . ValueDir } { dirExists , err := exists ( path ) if err != nil { return nil , y . Wrapf ( err , " " , path ) } if ! dirExists { if opt . ReadOnly { return nil , y . Wrapf ( err , " " , path ) } if err != nil { return nil , y . Wrapf ( err , " " , path ) } } } absDir , err := filepath . Abs ( opt . Dir ) if err != nil { return nil , err } absValueDir , err := filepath . Abs ( opt . ValueDir ) if err != nil { return nil , err } var dirLockGuard , valueDirLockGuard * directoryLockGuard dirLockGuard , err = acquireDirectoryLock ( opt . Dir , lockFile , opt . ReadOnly ) if err != nil { return nil , err } defer func ( ) { if dirLockGuard != nil { _ = dirLockGuard . release ( ) } } ( ) if absValueDir != absDir { valueDirLockGuard , err = acquireDirectoryLock ( opt . ValueDir , lockFile , opt . ReadOnly ) if err != nil { return nil , err } defer func ( ) { if valueDirLockGuard != nil { _ = valueDirLockGuard . release ( ) } } ( ) } if ! ( opt . ValueLogFileSize <= 2 << 30 && opt . ValueLogFileSize >= 1 << 20 ) { return nil , ErrValueLogSize } if ! ( opt . ValueLogLoadingMode == options . FileIO || opt . ValueLogLoadingMode == options . MemoryMap ) { return nil , ErrInvalidLoadingMode } manifestFile , manifest , err := openOrCreateManifestFile ( opt . Dir , opt . ReadOnly ) if err != nil { return nil , err } defer func ( ) { if manifestFile != nil { _ = manifestFile . close ( ) } } ( ) db = & DB { imm : make ( [ ] * skl . Skiplist , 0 , opt . NumMemtables ) , flushChan : make ( chan flushTask , opt . NumMemtables ) , writeCh : make ( chan * request , kvWriteChCapacity ) , opt : opt , manifest : manifestFile , elog : trace . NewEventLog ( " " , " " ) , dirLockGuard : dirLockGuard , valueDirGuard : valueDirLockGuard , orc : newOracle ( opt ) , } db . closers . updateSize = y . NewCloser ( 1 ) go db . updateSize ( db . closers . updateSize ) db . mt = skl . NewSkiplist ( arenaSize ( opt ) ) } if ! opt . ReadOnly { db . closers . compactors = y . NewCloser ( 1 ) db . lc . startCompact ( db . closers . compactors ) db . closers . memtable = y . NewCloser ( 1 ) go db . flushMemtable ( db . closers . memtable ) } headKey := y . KeyWithTs ( head , math . MaxUint64 ) if err != nil { return nil , errors . Wrap ( err , " " ) } db . orc . nextTxnTs = vs . Version var vptr valuePointer if len ( vs . Value ) > 0 { vptr . Decode ( vs . Value ) } replayCloser := y . NewCloser ( 1 ) go db . doWrites ( replayCloser ) if err = db . vlog . open ( db , vptr , db . replayFunction ( ) ) ; err != nil { return db , err } replayCloser . SignalAndWait ( ) db . orc . nextTxnTs ++ db . writeCh = make ( chan * request , kvWriteChCapacity ) db . closers . writes = y . NewCloser ( 1 ) go db . doWrites ( db . closers . writes ) db . closers . valueGC = y . NewCloser ( 1 ) go db . vlog . waitOnGC ( db . closers . valueGC ) valueDirLockGuard = nil dirLockGuard = nil manifestFile = nil return db , nil } 
func ( db * DB ) Close ( ) ( err error ) { db . elog . Printf ( " " ) atomic . StoreInt32 ( & db . blockWrites , 1 ) } for { pushedFlushTask := func ( ) bool { db . Lock ( ) defer db . Unlock ( ) y . AssertTrue ( db . mt != nil ) select { case db . flushChan <- flushTask { mt : db . mt , vptr : db . vhead } : db . imm = append ( db . imm , db . mt ) db . mt = nil db . elog . Printf ( " \n " ) return true default : return false } ( ) if pushedFlushTask { break } time . Sleep ( 10 * time . Millisecond ) } } db . stopCompactions ( ) switch err { case errFillTables : default : db . opt . Warningf ( " " , err ) } } if lcErr := db . lc . close ( ) ; err == nil { err = errors . Wrap ( lcErr , " " ) } db . elog . Printf ( " " ) db . closers . updateSize . SignalAndWait ( ) db . orc . Stop ( ) db . elog . Finish ( ) if db . dirLockGuard != nil { if guardErr := db . dirLockGuard . release ( ) ; err == nil { err = errors . Wrap ( guardErr , " " ) } } if db . valueDirGuard != nil { if guardErr := db . valueDirGuard . release ( ) ; err == nil { err = errors . Wrap ( guardErr , " " ) } } if manifestErr := db . manifest . close ( ) ; err == nil { err = errors . Wrap ( manifestErr , " " ) } } if syncErr := syncDir ( db . opt . ValueDir ) ; err == nil { err = errors . Wrap ( syncErr , " " ) } return err } 
func syncDir ( dir string ) error { f , err := openDir ( dir ) if err != nil { return errors . Wrapf ( err , " " , dir ) } err = f . Sync ( ) closeErr := f . Close ( ) if err != nil { return errors . Wrapf ( err , " " , dir ) } return errors . Wrapf ( closeErr , " " , dir ) } 
func ( db * DB ) getMemTables ( ) ( [ ] * skl . Skiplist , func ( ) ) { db . RLock ( ) defer db . RUnlock ( ) tables := make ( [ ] * skl . Skiplist , len ( db . imm ) + 1 ) tables [ 0 ] . IncrRef ( ) for i := range db . imm { tables [ i + 1 ] = db . imm [ last - i ] tables [ i + 1 ] . IncrRef ( ) } return tables , func ( ) { for _ , tbl := range tables { tbl . DecrRef ( ) } } } 
func ( db * DB ) get ( key [ ] byte ) ( y . ValueStruct , error ) { tables , decr := db . getMemTables ( ) defer decr ( ) var maxVs * y . ValueStruct var version uint64 if bytes . HasPrefix ( key , badgerMove ) { version = y . ParseTs ( key ) } y . NumGets . Add ( 1 ) for i := 0 ; i < len ( tables ) ; i ++ { vs := tables [ i ] . Get ( key ) y . NumMemtableGets . Add ( 1 ) if vs . Meta == 0 && vs . Value == nil { continue } } if maxVs . Version < vs . Version { * maxVs = vs } } return db . lc . get ( key , maxVs ) } 
func ( db * DB ) writeRequests ( reqs [ ] * request ) error { if len ( reqs ) == 0 { return nil } done := func ( err error ) { for _ , r := range reqs { r . Err = err r . Wg . Done ( ) } } db . elog . Printf ( " " ) err := db . vlog . write ( reqs ) if err != nil { done ( err ) return err } db . elog . Printf ( " " ) var count int for _ , b := range reqs { if len ( b . Entries ) == 0 { continue } count += len ( b . Entries ) var i uint64 for err = db . ensureRoomForWrite ( ) ; err == errNoRoom ; err = db . ensureRoomForWrite ( ) { i ++ if i % 100 == 0 { db . elog . Printf ( " " ) } } if err != nil { done ( err ) return errors . Wrap ( err , " " ) } if err := db . writeToLSM ( b ) ; err != nil { done ( err ) return errors . Wrap ( err , " " ) } db . updateHead ( b . Ptrs ) } done ( nil ) db . elog . Printf ( " " , count ) return nil } 
func ( db * DB ) batchSet ( entries [ ] * Entry ) error { req , err := db . sendToWriteCh ( entries ) if err != nil { return err } return req . Wait ( ) } 
func ( db * DB ) batchSetAsync ( entries [ ] * Entry , f func ( error ) ) error { req , err := db . sendToWriteCh ( entries ) if err != nil { return err } go func ( ) { err := req . Wait ( ) } ( ) return nil } 
func ( db * DB ) ensureRoomForWrite ( ) error { var err error db . Lock ( ) defer db . Unlock ( ) if db . mt . MemSize ( ) < db . opt . MaxTableSize { return nil } y . AssertTrue ( db . mt != nil ) select { case db . flushChan <- flushTask { mt : db . mt , vptr : db . vhead } : db . elog . Printf ( " " ) if err != nil { return err } db . elog . Printf ( " \n " , db . mt . MemSize ( ) , len ( db . flushChan ) ) db . mt = skl . NewSkiplist ( arenaSize ( db . opt ) ) default : } } 
func writeLevel0Table ( ft flushTask , f io . Writer ) error { iter := ft . mt . NewIterator ( ) defer iter . Close ( ) b := table . NewTableBuilder ( ) defer b . Close ( ) for iter . SeekToFirst ( ) ; iter . Valid ( ) ; iter . Next ( ) { if len ( ft . dropPrefix ) > 0 && bytes . HasPrefix ( iter . Key ( ) , ft . dropPrefix ) { continue } if err := b . Add ( iter . Key ( ) , iter . Value ( ) ) ; err != nil { return err } } _ , err := f . Write ( b . Finish ( ) ) return err } 
func ( db * DB ) handleFlushTask ( ft flushTask ) error { if ! ft . mt . Empty ( ) { db . elog . Printf ( " \n " , ft . vptr ) offset := make ( [ ] byte , vptrSize ) ft . vptr . Encode ( offset ) ft . mt . Put ( headTs , y . ValueStruct { Value : offset } ) ft . mt . Put ( discardStatsKey , y . ValueStruct { Value : db . vlog . encodedDiscardStats ( ) } ) } fileID := db . lc . reserveFileID ( ) fd , err := y . CreateSyncedFile ( table . NewFilename ( fileID , db . opt . Dir ) , true ) if err != nil { return y . Wrap ( err ) } go func ( ) { dirSyncCh <- syncDir ( db . opt . Dir ) } ( ) err = writeLevel0Table ( ft , fd ) dirSyncErr := <- dirSyncCh if err != nil { db . elog . Errorf ( " " , err ) return err } if dirSyncErr != nil { } tbl , err := table . OpenTable ( fd , db . opt . TableLoadingMode , nil ) if err != nil { db . elog . Printf ( " " , err ) return err } tbl . DecrRef ( ) return err } 
func ( db * DB ) flushMemtable ( lc * y . Closer ) error { defer lc . Done ( ) for ft := range db . flushChan { if ft . mt == nil { } for { err := db . handleFlushTask ( ft ) if err == nil { db . imm = db . imm [ 1 : ] ft . mt . DecrRef ( ) db . Unlock ( ) break } time . Sleep ( time . Second ) } } return nil } 
func ( db * DB ) calculateSize ( ) { newInt := func ( val int64 ) * expvar . Int { v := new ( expvar . Int ) v . Add ( val ) return v } totalSize := func ( dir string ) ( int64 , int64 ) { var lsmSize , vlogSize int64 err := filepath . Walk ( dir , func ( path string , info os . FileInfo , err error ) error { if err != nil { return err } ext := filepath . Ext ( path ) if ext == " " { lsmSize += info . Size ( ) } else if ext == " " { vlogSize += info . Size ( ) } return nil } ) if err != nil { db . elog . Printf ( " " , dir ) } return lsmSize , vlogSize } lsmSize , vlogSize := totalSize ( db . opt . Dir ) y . LSMSize . Set ( db . opt . Dir , newInt ( lsmSize ) ) } y . VlogSize . Set ( db . opt . Dir , newInt ( vlogSize ) ) } 
func ( db * DB ) RunValueLogGC ( discardRatio float64 ) error { if discardRatio >= 1.0 || discardRatio <= 0.0 { return ErrInvalidRequest } if err != nil { return errors . Wrap ( err , " " ) } var head valuePointer if len ( val . Value ) > 0 { head . Decode ( val . Value ) } } 
func ( db * DB ) Size ( ) ( lsm , vlog int64 ) { if y . LSMSize . Get ( db . opt . Dir ) == nil { lsm , vlog = 0 , 0 return } lsm = y . LSMSize . Get ( db . opt . Dir ) . ( * expvar . Int ) . Value ( ) vlog = y . VlogSize . Get ( db . opt . Dir ) . ( * expvar . Int ) . Value ( ) return } 
func ( seq * Sequence ) Next ( ) ( uint64 , error ) { seq . Lock ( ) defer seq . Unlock ( ) if seq . next >= seq . leased { if err := seq . updateLease ( ) ; err != nil { return 0 , err } } val := seq . next seq . next ++ return val , nil } 
func ( seq * Sequence ) Release ( ) error { seq . Lock ( ) defer seq . Unlock ( ) err := seq . db . Update ( func ( txn * Txn ) error { var buf [ 8 ] byte binary . BigEndian . PutUint64 ( buf [ : ] , seq . next ) return txn . Set ( seq . key , buf [ : ] ) } ) if err != nil { return err } seq . leased = seq . next return nil } 
func ( db * DB ) GetSequence ( key [ ] byte , bandwidth uint64 ) ( * Sequence , error ) { if db . opt . managedTxns { panic ( " " ) } switch { case len ( key ) == 0 : return nil , ErrEmptyKey case bandwidth == 0 : return nil , ErrZeroBandwidth } seq := & Sequence { db : db , key : key , next : 0 , leased : 0 , bandwidth : bandwidth , } err := seq . updateLease ( ) return seq , err } 
func ( db * DB ) KeySplits ( prefix [ ] byte ) [ ] string { var splits [ ] string for _ , ti := range db . Tables ( ) { } } sort . Strings ( splits ) return splits } 
func ( db * DB ) Flatten ( workers int ) error { db . stopCompactions ( ) defer db . startCompactions ( ) compactAway := func ( cp compactionPriority ) error { db . opt . Infof ( " \n " , cp ) errCh := make ( chan error , 1 ) for i := 0 ; i < workers ; i ++ { go func ( ) { errCh <- db . lc . doCompact ( cp ) } ( ) } var success int var rerr error for i := 0 ; i < workers ; i ++ { err := <- errCh if err != nil { rerr = err db . opt . Warningf ( " \n " , cp , err ) } else { success ++ } } if success == 0 { return rerr } return nil } hbytes := func ( sz int64 ) string { return humanize . Bytes ( uint64 ( sz ) ) } for { db . opt . Infof ( " \n " ) var levels [ ] int for i , l := range db . lc . levels { sz := l . getTotalSize ( ) db . opt . Infof ( " \n " , i , hbytes ( l . getTotalSize ( ) ) , hbytes ( l . maxTotalSize ) ) if sz > 0 { levels = append ( levels , i ) } } if len ( levels ) <= 1 { prios := db . lc . pickCompactLevels ( ) if len ( prios ) == 0 || prios [ 0 ] . score <= 1.0 { db . opt . Infof ( " \n " ) return nil } if err := compactAway ( prios [ 0 ] ) ; err != nil { return err } continue } if err := compactAway ( cp ) ; err != nil { return err } } } 
func ( db * DB ) DropAll ( ) error { db . opt . Infof ( " " ) f := db . prepareToDrop ( ) defer f ( ) defer db . Unlock ( ) for _ , mt := range db . imm { mt . DecrRef ( ) } db . imm = db . imm [ : 0 ] db . mt = skl . NewSkiplist ( arenaSize ( db . opt ) ) num , err := db . lc . dropTree ( ) if err != nil { return err } db . opt . Infof ( " \n " , num ) num , err = db . vlog . dropAll ( ) if err != nil { return err } db . vhead = valuePointer { } db . opt . Infof ( " \n " , num ) return nil } 
func ( db * DB ) DropPrefix ( prefix [ ] byte ) error { db . opt . Infof ( " " , hex . Dump ( prefix ) ) f := db . prepareToDrop ( ) defer f ( ) defer db . Unlock ( ) db . imm = append ( db . imm , db . mt ) for _ , memtable := range db . imm { if memtable . Empty ( ) { memtable . DecrRef ( ) continue } task := flushTask { mt : memtable , db . opt . Debugf ( " " ) if err := db . handleFlushTask ( task ) ; err != nil { db . opt . Errorf ( " " , err ) return err } memtable . DecrRef ( ) } db . imm = db . imm [ : 0 ] db . mt = skl . NewSkiplist ( arenaSize ( db . opt ) ) } db . opt . Infof ( " " ) return nil } 
func Mmap ( fd * os . File , writable bool , size int64 ) ( [ ] byte , error ) { mtype := unix . PROT_READ if writable { mtype |= unix . PROT_WRITE } return unix . Mmap ( int ( fd . Fd ( ) ) , 0 , int ( size ) , mtype , unix . MAP_SHARED ) } 
func Madvise ( b [ ] byte , readahead bool ) error { flags := unix . MADV_NORMAL if ! readahead { flags = unix . MADV_RANDOM } return madvise ( b , flags ) } 
func ( o * oracle ) setDiscardTs ( ts uint64 ) { o . Lock ( ) defer o . Unlock ( ) o . discardTs = ts } 
func ( o * oracle ) hasConflict ( txn * Txn ) bool { if len ( txn . reads ) == 0 { return false } for _ , ro := range txn . reads { } } return false } 
func ( txn * Txn ) Set ( key , val [ ] byte ) error { e := & Entry { Key : key , Value : val , } return txn . SetEntry ( e ) } 
func ( txn * Txn ) SetWithMeta ( key , val [ ] byte , meta byte ) error { e := & Entry { Key : key , Value : val , UserMeta : meta } return txn . SetEntry ( e ) } 
func ( txn * Txn ) Delete ( key [ ] byte ) error { e := & Entry { Key : key , meta : bitDelete , } return txn . modify ( e ) } 
func ( txn * Txn ) Get ( key [ ] byte ) ( item * Item , rerr error ) { if len ( key ) == 0 { return nil , ErrEmptyKey } else if txn . discarded { return nil , ErrDiscardedTxn } item = new ( Item ) if txn . update { if e , has := txn . pendingWrites [ string ( key ) ] ; has && bytes . Equal ( key , e . Key ) { if isDeletedOrExpired ( e . meta , e . ExpiresAt ) { return nil , ErrKeyNotFound } item . val = e . Value item . userMeta = e . UserMeta item . key = key item . status = prefetched item . version = txn . readTs item . expiresAt = e . ExpiresAt } } seek := y . KeyWithTs ( key , txn . readTs ) vs , err := txn . db . get ( seek ) if err != nil { return nil , errors . Wrapf ( err , " " , key ) } if vs . Value == nil && vs . Meta == 0 { return nil , ErrKeyNotFound } if isDeletedOrExpired ( vs . Meta , vs . ExpiresAt ) { return nil , ErrKeyNotFound } item . key = key item . version = vs . Version item . meta = vs . Meta item . userMeta = vs . UserMeta item . db = txn . db item . vptr = vs . Value item . txn = txn item . expiresAt = vs . ExpiresAt return item , nil } 
func ( txn * Txn ) Discard ( ) { if txn . discarded { } if atomic . LoadInt32 ( & txn . numIterators ) > 0 { panic ( " " ) } txn . discarded = true if ! txn . db . orc . isManaged { txn . db . orc . readMark . Done ( txn . readTs ) } if txn . update { txn . db . orc . decrRef ( ) } } 
func ( txn * Txn ) Commit ( ) error { txn . commitPrecheck ( ) defer txn . Discard ( ) if len ( txn . writes ) == 0 { return nil } txnCb , err := txn . commitAndSend ( ) if err != nil { return err } } 
func ( txn * Txn ) CommitWith ( cb func ( error ) ) { txn . commitPrecheck ( ) defer txn . Discard ( ) if cb == nil { panic ( " " ) } if len ( txn . writes ) == 0 { return } commitCb , err := txn . commitAndSend ( ) if err != nil { go runTxnCallback ( & txnCb { user : cb , err : err } ) return } go runTxnCallback ( & txnCb { user : cb , commit : commitCb } ) } 
func ( db * DB ) NewTransaction ( update bool ) * Txn { return db . newTransaction ( update , false ) } 
func ( db * DB ) View ( fn func ( txn * Txn ) error ) error { var txn * Txn if db . opt . managedTxns { txn = db . NewTransactionAt ( math . MaxUint64 , false ) } else { txn = db . NewTransaction ( false ) } defer txn . Discard ( ) return fn ( txn ) } 
func ( db * DB ) Update ( fn func ( txn * Txn ) error ) error { if db . opt . managedTxns { panic ( " " ) } txn := db . NewTransaction ( true ) defer txn . Discard ( ) if err := fn ( txn ) ; err != nil { return err } return txn . Commit ( ) } 
func ( itr * blockIterator ) Seek ( key [ ] byte , whence int ) { itr . err = nil switch whence { case origin : itr . Reset ( ) case current : } var done bool for itr . Init ( ) ; itr . Valid ( ) ; itr . Next ( ) { k := itr . Key ( ) if y . CompareKeys ( k , key ) >= 0 { break } } if ! done { itr . err = io . EOF } } 
func ( itr * blockIterator ) SeekToLast ( ) { itr . err = nil for itr . Init ( ) ; itr . Valid ( ) ; itr . Next ( ) { } itr . Prev ( ) } 
func ( itr * blockIterator ) parseKV ( h header ) { if cap ( itr . key ) < int ( h . plen + h . klen ) { sz := int ( h . plen ) + int ( h . klen ) itr . key = make ( [ ] byte , 2 * sz ) } itr . key = itr . key [ : h . plen + h . klen ] copy ( itr . key , itr . baseKey [ : h . plen ] ) copy ( itr . key [ h . plen : ] , itr . data [ itr . pos : itr . pos + uint32 ( h . klen ) ] ) itr . pos += uint32 ( h . klen ) if itr . pos + uint32 ( h . vlen ) > uint32 ( len ( itr . data ) ) { itr . err = errors . Errorf ( " " , itr . pos , h . klen , h . vlen , len ( itr . data ) , h ) return } itr . val = y . SafeCopy ( itr . val , itr . data [ itr . pos : itr . pos + uint32 ( h . vlen ) ] ) itr . pos += uint32 ( h . vlen ) } 
func ( t * Table ) NewIterator ( reversed bool ) * Iterator { t . IncrRef ( ) ti := & Iterator { t : t , reversed : reversed } ti . next ( ) return ti } 
func ( itr * Iterator ) seekFrom ( key [ ] byte , whence int ) { itr . err = nil switch whence { case origin : itr . reset ( ) case current : } idx := sort . Search ( len ( itr . t . blockIndex ) , func ( idx int ) bool { ko := itr . t . blockIndex [ idx ] return y . CompareKeys ( ko . key , key ) > 0 } ) if idx == 0 { return } if itr . err == io . EOF { } } // Case 2: No need to do anything. We already did the seek in block[idx-1]. } 
func ( itr * Iterator ) seekForPrev ( key [ ] byte ) { if ! bytes . Equal ( itr . Key ( ) , key ) { itr . prev ( ) } } 
func ( itr * Iterator ) Value ( ) ( ret y . ValueStruct ) { ret . Decode ( itr . bi . Value ( ) ) return } 
func ( itr * Iterator ) Seek ( key [ ] byte ) { if ! itr . reversed { itr . seek ( key ) } else { itr . seekForPrev ( key ) } } 
func NewConcatIterator ( tbls [ ] * Table , reversed bool ) * ConcatIterator { iters := make ( [ ] * Iterator , len ( tbls ) ) for i := 0 ; i < len ( tbls ) ; i ++ { iters [ i ] = tbls [ i ] . NewIterator ( reversed ) } return & ConcatIterator { reversed : reversed , iters : iters , tables : tbls , idx : - 1 , } 
func ( s * ConcatIterator ) Rewind ( ) { if len ( s . iters ) == 0 { return } if ! s . reversed { s . setIdx ( 0 ) } else { s . setIdx ( len ( s . iters ) - 1 ) } s . cur . Rewind ( ) } 
func ( s * ConcatIterator ) Valid ( ) bool { return s . cur != nil && s . cur . Valid ( ) } 
func ( s * ConcatIterator ) Seek ( key [ ] byte ) { var idx int if ! s . reversed { idx = sort . Search ( len ( s . tables ) , func ( i int ) bool { return y . CompareKeys ( s . tables [ i ] . Biggest ( ) , key ) >= 0 } ) } else { n := len ( s . tables ) idx = n - 1 - sort . Search ( n , func ( i int ) bool { return y . CompareKeys ( s . tables [ n - 1 - i ] . Smallest ( ) , key ) <= 0 } ) } if idx >= len ( s . tables ) || idx < 0 { s . setIdx ( - 1 ) return } s . cur . Seek ( key ) } 
func ( s * ConcatIterator ) Next ( ) { s . cur . Next ( ) if s . cur . Valid ( ) { } for { } else { s . setIdx ( s . idx - 1 ) } if s . cur == nil { } s . cur . Rewind ( ) if s . cur . Valid ( ) { break } } } 
func ( s * ConcatIterator ) Close ( ) error { for _ , it := range s . iters { if err := it . Close ( ) ; err != nil { return errors . Wrap ( err , " " ) } } return nil } 
func OpenExistingFile ( filename string , flags uint32 ) ( * os . File , error ) { openFlags := os . O_RDWR if flags & ReadOnly != 0 { openFlags = os . O_RDONLY } if flags & Sync != 0 { openFlags |= datasyncFileFlag } return os . OpenFile ( filename , openFlags , 0 ) } 
func CreateSyncedFile ( filename string , sync bool ) ( * os . File , error ) { flags := os . O_RDWR | os . O_CREATE | os . O_EXCL if sync { flags |= datasyncFileFlag } return os . OpenFile ( filename , flags , 0666 ) } 
func Copy ( a [ ] byte ) [ ] byte { b := make ( [ ] byte , len ( a ) ) copy ( b , a ) return b } 
func KeyWithTs ( key [ ] byte , ts uint64 ) [ ] byte { out := make ( [ ] byte , len ( key ) + 8 ) copy ( out , key ) binary . BigEndian . PutUint64 ( out [ len ( key ) : ] , math . MaxUint64 - ts ) return out } 
func ParseTs ( key [ ] byte ) uint64 { if len ( key ) <= 8 { return 0 } return math . MaxUint64 - binary . BigEndian . Uint64 ( key [ len ( key ) - 8 : ] ) } 
func CompareKeys ( key1 , key2 [ ] byte ) int { AssertTrue ( len ( key1 ) > 8 && len ( key2 ) > 8 ) if cmp := bytes . Compare ( key1 [ : len ( key1 ) - 8 ] , key2 [ : len ( key2 ) - 8 ] ) ; cmp != 0 { return cmp } return bytes . Compare ( key1 [ len ( key1 ) - 8 : ] , key2 [ len ( key2 ) - 8 : ] ) } 
func ParseKey ( key [ ] byte ) [ ] byte { if key == nil { return nil } AssertTrue ( len ( key ) > 8 ) return key [ : len ( key ) - 8 ] } 
func SameKey ( src , dst [ ] byte ) bool { if len ( src ) != len ( dst ) { return false } return bytes . Equal ( ParseKey ( src ) , ParseKey ( dst ) ) } 
func ( s * Slice ) Resize ( sz int ) [ ] byte { if cap ( s . buf ) < sz { s . buf = make ( [ ] byte , sz ) } return s . buf [ 0 : sz ] } 
func FixedDuration ( d time . Duration ) string { str := fmt . Sprintf ( " " , int ( d . Seconds ( ) ) % 60 ) if d >= time . Minute { str = fmt . Sprintf ( " " , int ( d . Minutes ( ) ) % 60 ) + str } if d >= time . Hour { str = fmt . Sprintf ( " " , int ( d . Hours ( ) ) ) + str } return str } 
func NewCloser ( initial int ) * Closer { ret := & Closer { closed : make ( chan struct { } ) } ret . waiting . Add ( initial ) return ret } 
func NewThrottle ( max int ) * Throttle { return & Throttle { ch : make ( chan struct { } , max ) , errCh : make ( chan error , max ) , } } 
func ( t * Throttle ) Do ( ) error { for { select { case t . ch <- struct { } { } : t . wg . Add ( 1 ) return nil case err := <- t . errCh : if err != nil { return err } } } } 
func ( t * Throttle ) Done ( err error ) { if err != nil { t . errCh <- err } select { case <- t . ch : default : panic ( " " ) } t . wg . Done ( ) } 
func ( t * Throttle ) Finish ( ) error { t . wg . Wait ( ) close ( t . ch ) close ( t . errCh ) for err := range t . errCh { if err != nil { return err } } return nil } 
func OpenManaged ( opts Options ) ( * DB , error ) { opts . managedTxns = true return Open ( opts ) } 
func ( db * DB ) NewTransactionAt ( readTs uint64 , update bool ) * Txn { if ! db . opt . managedTxns { panic ( " " ) } txn := db . newTransaction ( update , true ) txn . readTs = readTs return txn } 
func ( txn * Txn ) CommitAt ( commitTs uint64 , callback func ( error ) ) error { if ! txn . db . opt . managedTxns { panic ( " " ) } txn . commitTs = commitTs if callback == nil { return txn . Commit ( ) } txn . CommitWith ( callback ) return nil } 
func ( db * DB ) SetDiscardTs ( ts uint64 ) { if ! db . opt . managedTxns { panic ( " " ) } db . orc . setDiscardTs ( ts ) } 
func ( lf * logFile ) openReadOnly ( ) error { var err error lf . fd , err = os . OpenFile ( lf . path , os . O_RDONLY , 0666 ) if err != nil { return errors . Wrapf ( err , " " , lf . path ) } fi , err := lf . fd . Stat ( ) if err != nil { return errors . Wrapf ( err , " " , lf . path ) } y . AssertTrue ( fi . Size ( ) <= math . MaxUint32 ) lf . size = uint32 ( fi . Size ( ) ) if err = lf . mmap ( fi . Size ( ) ) ; err != nil { _ = lf . fd . Close ( ) return y . Wrapf ( err , " " ) } return nil } 
func ( lf * logFile ) read ( p valuePointer , s * y . Slice ) ( buf [ ] byte , err error ) { var nbr int64 offset := p . Offset if lf . loadingMode == options . FileIO { buf = s . Resize ( int ( p . Len ) ) var n int n , err = lf . fd . ReadAt ( buf , int64 ( offset ) ) nbr = int64 ( n ) } else { valsz := p . Len if int64 ( offset ) >= size || int64 ( offset + valsz ) > size { err = y . ErrEOF } else { buf = lf . fmap [ offset : offset + valsz ] nbr = int64 ( valsz ) } } y . NumReads . Add ( 1 ) y . NumBytesRead . Add ( nbr ) return buf , err } 
func ( vlog * valueLog ) iterate ( lf * logFile , offset uint32 , fn logEntry ) ( uint32 , error ) { fi , err := lf . fd . Stat ( ) if err != nil { return 0 , err } if int64 ( offset ) == fi . Size ( ) { } if vlog . opt . ReadOnly { } } reader := bufio . NewReader ( lf . fd ) read := & safeRead { k : make ( [ ] byte , 10 ) , v : make ( [ ] byte , 10 ) , recordOffset : offset , } var lastCommit uint64 var validEndOffset uint32 for { e , err := read . Entry ( reader ) if err == io . EOF { break } else if err == io . ErrUnexpectedEOF || err == errTruncate { break } else if err != nil { return 0 , err } else if e == nil { continue } var vp valuePointer vp . Len = uint32 ( headerBufSize + len ( e . Key ) + len ( e . Value ) + crc32 . Size ) read . recordOffset += vp . Len vp . Offset = e . offset vp . Fid = lf . fid if e . meta & bitTxn > 0 { txnTs := y . ParseTs ( e . Key ) if lastCommit == 0 { lastCommit = txnTs } if lastCommit != txnTs { break } } else if e . meta & bitFinTxn > 0 { txnTs , err := strconv . ParseUint ( string ( e . Value ) , 10 , 64 ) if err != nil || lastCommit != txnTs { break } validEndOffset = read . recordOffset } else { if lastCommit != 0 { } validEndOffset = read . recordOffset } if err := fn ( * e , vp ) ; err != nil { if err == errStop { break } return 0 , errFile ( err , lf . path , " " ) } } return validEndOffset , nil } 
func ( vlog * valueLog ) sortedFids ( ) [ ] uint32 { toBeDeleted := make ( map [ uint32 ] struct { } ) for _ , fid := range vlog . filesToBeDeleted { toBeDeleted [ fid ] = struct { } { } } ret := make ( [ ] uint32 , 0 , len ( vlog . filesMap ) ) for fid := range vlog . filesMap { if _ , ok := toBeDeleted [ fid ] ; ! ok { ret = append ( ret , fid ) } } sort . Slice ( ret , func ( i , j int ) bool { return ret [ i ] < ret [ j ] } ) return ret } 
func ( vlog * valueLog ) sync ( fid uint32 ) error { if vlog . opt . SyncWrites { return nil } vlog . filesLock . RLock ( ) maxFid := atomic . LoadUint32 ( & vlog . maxFid ) return nil } curlf := vlog . filesMap [ maxFid ] return nil } curlf . lock . RLock ( ) vlog . filesLock . RUnlock ( ) err := curlf . sync ( ) curlf . lock . RUnlock ( ) return err } 
func ( vlog * valueLog ) write ( reqs [ ] * request ) error { vlog . filesLock . RLock ( ) maxFid := atomic . LoadUint32 ( & vlog . maxFid ) curlf := vlog . filesMap [ maxFid ] vlog . filesLock . RUnlock ( ) var buf bytes . Buffer toDisk := func ( ) error { if buf . Len ( ) == 0 { return nil } vlog . elog . Printf ( " " , len ( reqs ) , buf . Len ( ) ) n , err := curlf . fd . Write ( buf . Bytes ( ) ) if err != nil { return errors . Wrapf ( err , " " , curlf . path ) } buf . Reset ( ) y . NumWrites . Add ( 1 ) y . NumBytesWritten . Add ( int64 ( n ) ) vlog . elog . Printf ( " " ) atomic . AddUint32 ( & vlog . writableLogOffset , uint32 ( n ) ) if vlog . woffset ( ) > uint32 ( vlog . opt . ValueLogFileSize ) || vlog . numEntriesWritten > vlog . opt . ValueLogMaxEntries { var err error if err = curlf . doneWriting ( vlog . woffset ( ) ) ; err != nil { return err } newid := atomic . AddUint32 ( & vlog . maxFid , 1 ) y . AssertTruef ( newid > 0 , " " , newid ) newlf , err := vlog . createVlogFile ( newid ) if err != nil { return err } curlf = newlf } return nil } for i := range reqs { b := reqs [ i ] b . Ptrs = b . Ptrs [ : 0 ] for j := range b . Entries { e := b . Entries [ j ] var p valuePointer p . Fid = curlf . fid plen , err := encodeEntry ( e , & buf ) if err != nil { return err } p . Len = uint32 ( plen ) b . Ptrs = append ( b . Ptrs , p ) } vlog . numEntriesWritten += uint32 ( len ( b . Entries ) ) if writeNow { if err := toDisk ( ) ; err != nil { return err } } } return toDisk ( ) } 
func ( vlog * valueLog ) getFileRLocked ( fid uint32 ) ( * logFile , error ) { vlog . filesLock . RLock ( ) defer vlog . filesLock . RUnlock ( ) ret , ok := vlog . filesMap [ fid ] if ! ok { } ret . lock . RLock ( ) return ret , nil } 
func ( vlog * valueLog ) Read ( vp valuePointer , s * y . Slice ) ( [ ] byte , func ( ) , error ) { if vp . Fid == maxFid && vp . Offset >= vlog . woffset ( ) { return nil , nil , errors . Errorf ( " " , vp . Offset , vlog . woffset ( ) ) } buf , cb , err := vlog . readValueBytes ( vp , s ) if err != nil { return nil , cb , err } var h header h . Decode ( buf ) n := uint32 ( headerBufSize ) + h . klen return buf [ n : n + h . vlen ] , cb , nil } 
func valueBytesToEntry ( buf [ ] byte ) ( e Entry ) { var h header h . Decode ( buf ) n := uint32 ( headerBufSize ) e . Key = buf [ n : n + h . klen ] n += h . klen e . meta = h . meta e . UserMeta = h . userMeta e . Value = buf [ n : n + h . vlen ] return } 
func ( vlog * valueLog ) encodedDiscardStats ( ) [ ] byte { vlog . lfDiscardStats . Lock ( ) defer vlog . lfDiscardStats . Unlock ( ) encodedStats , _ := json . Marshal ( vlog . lfDiscardStats . m ) return encodedStats } 
func ( vlog * valueLog ) populateDiscardStats ( ) error { discardStatsKey := y . KeyWithTs ( lfDiscardStatsKey , math . MaxUint64 ) vs , err := vlog . db . get ( discardStatsKey ) if err != nil { return err } return nil } var statsMap map [ uint32 ] int64 if err := json . Unmarshal ( vs . Value , & statsMap ) ; err != nil { return err } vlog . opt . Debugf ( " " , statsMap ) vlog . lfDiscardStats = & lfDiscardStats { m : statsMap } return nil } 
func ( db * DB ) Backup ( w io . Writer , since uint64 ) ( uint64 , error ) { stream := db . NewStream ( ) stream . LogPrefix = " " return stream . Backup ( w , since ) } 
func ( stream * Stream ) Backup ( w io . Writer , since uint64 ) ( uint64 , error ) { stream . KeyToList = func ( key [ ] byte , itr * Iterator ) ( * pb . KVList , error ) { list := & pb . KVList { } for ; itr . Valid ( ) ; itr . Next ( ) { item := itr . Item ( ) if ! bytes . Equal ( item . Key ( ) , key ) { return list , nil } if item . Version ( ) < since { } var valCopy [ ] byte if ! item . IsDeletedOrExpired ( ) { valCopy , err = item . ValueCopy ( nil ) if err != nil { stream . db . opt . Errorf ( " \n " , item . Key ( ) , item . Version ( ) , err ) return nil , err } } kv := & pb . KV { Key : item . KeyCopy ( nil ) , Value : valCopy , UserMeta : [ ] byte { item . UserMeta ( ) } , Version : item . Version ( ) , ExpiresAt : item . ExpiresAt ( ) , Meta : [ ] byte { meta } , } list . Kv = append ( list . Kv , kv ) switch { case item . DiscardEarlierVersions ( ) : return list , nil case item . IsDeletedOrExpired ( ) : return list , nil } } return list , nil } var maxVersion uint64 stream . Send = func ( list * pb . KVList ) error { for _ , kv := range list . Kv { if maxVersion < kv . Version { maxVersion = kv . Version } if err := writeTo ( kv , w ) ; err != nil { return err } } return nil } if err := stream . Orchestrate ( context . Background ( ) ) ; err != nil { return 0 , err } return maxVersion , nil } 
func ( db * DB ) Load ( r io . Reader ) error { br := bufio . NewReaderSize ( r , 16 << 10 ) unmarshalBuf := make ( [ ] byte , 1 << 10 ) var entries [ ] * Entry var wg sync . WaitGroup errChan := make ( chan error , 1 ) default : wg . Add ( 1 ) return db . batchSetAsync ( entries , func ( err error ) { defer wg . Done ( ) if err != nil { select { case errChan <- err : default : } } } ) } } for { var sz uint64 err := binary . Read ( br , binary . LittleEndian , & sz ) if err == io . EOF { break } else if err != nil { return err } if cap ( unmarshalBuf ) < int ( sz ) { unmarshalBuf = make ( [ ] byte , sz ) } e := & pb . KV { } if _ , err = io . ReadFull ( br , unmarshalBuf [ : sz ] ) ; err != nil { return err } if err = e . Unmarshal ( unmarshalBuf [ : sz ] ) ; err != nil { return err } var userMeta byte if len ( e . UserMeta ) > 0 { userMeta = e . UserMeta [ 0 ] } entries = append ( entries , & Entry { Key : y . KeyWithTs ( e . Key , e . Version ) , Value : e . Value , UserMeta : userMeta , ExpiresAt : e . ExpiresAt , meta : e . Meta [ 0 ] , } ) } if len ( entries ) == 1000 { if err := batchSetAsyncIfNoErr ( entries ) ; err != nil { return err } entries = make ( [ ] * Entry , 0 , 1000 ) } } if len ( entries ) > 0 { if err := batchSetAsyncIfNoErr ( entries ) ; err != nil { return err } } wg . Wait ( ) select { case err := <- errChan : return err default : return nil } } 
func ( st * Stream ) ToList ( key [ ] byte , itr * Iterator ) ( * pb . KVList , error ) { list := & pb . KVList { } for ; itr . Valid ( ) ; itr . Next ( ) { item := itr . Item ( ) if item . IsDeletedOrExpired ( ) { break } if ! bytes . Equal ( key , item . Key ( ) ) { } valCopy , err := item . ValueCopy ( nil ) if err != nil { return nil , err } kv := & pb . KV { Key : item . KeyCopy ( nil ) , Value : valCopy , UserMeta : [ ] byte { item . UserMeta ( ) } , Version : item . Version ( ) , ExpiresAt : item . ExpiresAt ( ) , } list . Kv = append ( list . Kv , kv ) if st . db . opt . NumVersionsToKeep == 1 { break } if item . DiscardEarlierVersions ( ) { break } } return list , nil } 
func ( st * Stream ) produceRanges ( ctx context . Context ) { splits := st . db . KeySplits ( st . Prefix ) start := y . SafeCopy ( nil , st . Prefix ) for _ , key := range splits { st . rangeCh <- keyRange { left : start , right : y . SafeCopy ( nil , [ ] byte ( key ) ) } start = y . SafeCopy ( nil , [ ] byte ( key ) ) } close ( st . rangeCh ) } 
func ( st * Stream ) produceKVs ( ctx context . Context ) error { var size int var txn * Txn if st . readTs > 0 { txn = st . db . NewTransactionAt ( st . readTs , false ) } else { txn = st . db . NewTransaction ( false ) } defer txn . Discard ( ) iterate := func ( kr keyRange ) error { iterOpts := DefaultIteratorOptions iterOpts . AllVersions = true iterOpts . Prefix = st . Prefix iterOpts . PrefetchValues = false itr := txn . NewIterator ( iterOpts ) defer itr . Close ( ) outList := new ( pb . KVList ) var prevKey [ ] byte for itr . Seek ( kr . left ) ; itr . Valid ( ) ; { if bytes . Equal ( item . Key ( ) , prevKey ) { itr . Next ( ) continue } prevKey = append ( prevKey [ : 0 ] , item . Key ( ) ... ) } } if err != nil { return err } if list == nil || len ( list . Kv ) == 0 { continue } outList . Kv = append ( outList . Kv , list . Kv ... ) size += list . Size ( ) if size >= pageSize { st . kvChan <- outList outList = new ( pb . KVList ) size = 0 } } if len ( outList . Kv ) > 0 { st . kvChan <- outList } return nil } for { select { case kr , ok := <- st . rangeCh : if ! ok { } if err := iterate ( kr ) ; err != nil { return err } case <- ctx . Done ( ) : return ctx . Err ( ) } } } 
func ( st * Stream ) Orchestrate ( ctx context . Context ) error { st . rangeCh = make ( chan keyRange , 3 ) if st . KeyToList == nil { st . KeyToList = st . ToList } errCh := make ( chan error , 1 ) var wg sync . WaitGroup for i := 0 ; i < st . NumGo ; i ++ { wg . Add ( 1 ) go func ( ) { defer wg . Done ( ) } } ( ) } go func ( ) { } ( ) wg . Wait ( ) close ( st . kvChan ) select { case err := <- errCh : default : } return err } 
func ( db * DB ) NewStream ( ) * Stream { if db . opt . managedTxns { panic ( " " ) } return db . newStream ( ) } 
func ( db * DB ) NewStreamAt ( readTs uint64 ) * Stream { if ! db . opt . managedTxns { panic ( " " ) } stream := db . newStream ( ) stream . readTs = readTs return stream } 
func ( t * Table ) DecrRef ( ) error { newRef := atomic . AddInt32 ( & t . ref , - 1 ) if newRef == 0 { } if err := t . fd . Truncate ( 0 ) ; err != nil { } filename := t . fd . Name ( ) if err := t . fd . Close ( ) ; err != nil { return err } if err := os . Remove ( filename ) ; err != nil { return err } } return nil } 
func OpenTable ( fd * os . File , mode options . FileLoadingMode , cksum [ ] byte ) ( * Table , error ) { fileInfo , err := fd . Stat ( ) if err != nil { return nil , y . Wrap ( err ) } filename := fileInfo . Name ( ) id , ok := ParseFileID ( filename ) if ! ok { _ = fd . Close ( ) return nil , errors . Errorf ( " " , filename ) } t := & Table { fd : fd , ref : 1 , t . tableSize = int ( fileInfo . Size ( ) ) } } if err := t . readIndex ( ) ; err != nil { return nil , y . Wrap ( err ) } it := t . NewIterator ( false ) defer it . Close ( ) it . Rewind ( ) if it . Valid ( ) { t . smallest = it . Key ( ) } it2 := t . NewIterator ( true ) defer it2 . Close ( ) it2 . Rewind ( ) if it2 . Valid ( ) { t . biggest = it2 . Key ( ) } switch mode { case options . LoadToRAM : if err != nil { _ = fd . Close ( ) return nil , y . Wrapf ( err , " " ) } case options . FileIO : t . mmap = nil default : panic ( fmt . Sprintf ( " " , mode ) ) } return t , nil } 
func ( t * Table ) Close ( ) error { if t . loadingMode == options . MemoryMap { y . Munmap ( t . mmap ) } return t . fd . Close ( ) } 
func ParseFileID ( name string ) ( uint64 , bool ) { name = path . Base ( name ) if ! strings . HasSuffix ( name , fileSuffix ) { return 0 , false } id , err := strconv . Atoi ( name ) if err != nil { return 0 , false } y . AssertTrue ( id >= 0 ) return uint64 ( id ) , true } 
func NewFilename ( id uint64 , dir string ) string { return filepath . Join ( dir , IDToFilename ( id ) ) } 
func ( db * DB ) PrintHistogram ( keyPrefix [ ] byte ) { if db == nil { fmt . Println ( " \n " ) return } histogram := db . buildHistogram ( keyPrefix ) fmt . Printf ( " \n " ) histogram . keySizeHistogram . printHistogram ( ) fmt . Printf ( " \n " ) histogram . valueSizeHistogram . printHistogram ( ) } 
func newSizeHistogram ( ) * sizeHistogram { valueBins := createHistogramBins ( 1 , 30 ) return & sizeHistogram { keySizeHistogram : histogramData { bins : keyBins , countPerBin : make ( [ ] int64 , len ( keyBins ) + 1 ) , max : math . MinInt64 , min : math . MaxInt64 , sum : 0 , } , valueSizeHistogram : histogramData { bins : valueBins , countPerBin : make ( [ ] int64 , len ( valueBins ) + 1 ) , max : math . MinInt64 , min : math . MaxInt64 , sum : 0 , } , } } 
func createHistogramBins ( minExponent , maxExponent uint32 ) [ ] int64 { var bins [ ] int64 for i := minExponent ; i <= maxExponent ; i ++ { bins = append ( bins , int64 ( 1 ) << i ) } return bins } 
func ( histogram * histogramData ) Update ( value int64 ) { if value > histogram . max { histogram . max = value } if value < histogram . min { histogram . min = value } histogram . sum += value histogram . totalCount ++ for index := 0 ; index <= len ( histogram . bins ) ; index ++ { break } break } } } 
func ( db * DB ) buildHistogram ( keyPrefix [ ] byte ) * sizeHistogram { txn := db . NewTransaction ( false ) defer txn . Discard ( ) itr := txn . NewIterator ( DefaultIteratorOptions ) defer itr . Close ( ) badgerHistogram := newSizeHistogram ( ) badgerHistogram . keySizeHistogram . Update ( item . KeySize ( ) ) badgerHistogram . valueSizeHistogram . Update ( item . ValueSize ( ) ) } return badgerHistogram } 
func ( histogram histogramData ) printHistogram ( ) { fmt . Printf ( " \n " , histogram . totalCount ) fmt . Printf ( " \n " , histogram . min ) fmt . Printf ( " \n " , histogram . max ) fmt . Printf ( " \n " , float64 ( histogram . sum ) / float64 ( histogram . totalCount ) ) fmt . Printf ( " \n " , " " , " " ) numBins := len ( histogram . bins ) for index , count := range histogram . countPerBin { if count == 0 { continue } fmt . Printf ( " \n " , lowerBound , " " , count ) continue } upperBound := int ( histogram . bins [ index ] ) lowerBound := 0 if index > 0 { lowerBound = int ( histogram . bins [ index - 1 ] ) } fmt . Printf ( " \n " , lowerBound , upperBound , count ) } fmt . Println ( ) } 
func ( w * WaterMark ) Init ( closer * Closer ) { w . markCh = make ( chan mark , 100 ) w . elog = trace . NewEventLog ( " " , w . Name ) go w . process ( closer ) } 
func ( w * WaterMark ) Begin ( index uint64 ) { atomic . StoreUint64 ( & w . lastIndex , index ) w . markCh <- mark { index : index , done : false } } 
func ( w * WaterMark ) BeginMany ( indices [ ] uint64 ) { atomic . StoreUint64 ( & w . lastIndex , indices [ len ( indices ) - 1 ] ) w . markCh <- mark { index : 0 , indices : indices , done : false } } 
func ( w * WaterMark ) Done ( index uint64 ) { w . markCh <- mark { index : index , done : true } } 
func ( w * WaterMark ) DoneMany ( indices [ ] uint64 ) { w . markCh <- mark { index : 0 , indices : indices , done : true } } 
func ( w * WaterMark ) SetDoneUntil ( val uint64 ) { atomic . StoreUint64 ( & w . doneUntil , val ) } 
func ( w * WaterMark ) WaitForMark ( ctx context . Context , index uint64 ) error { if w . DoneUntil ( ) >= index { return nil } waitCh := make ( chan struct { } ) w . markCh <- mark { index : index , waiter : waitCh } select { case <- ctx . Done ( ) : return ctx . Err ( ) case <- waitCh : return nil } } 
func ( w * WaterMark ) process ( closer * Closer ) { defer closer . Done ( ) var indices uint64Heap waiters := make ( map [ uint64 ] [ ] chan struct { } ) heap . Init ( & indices ) var loop uint64 processOne := func ( index uint64 , done bool ) { if ! present { heap . Push ( & indices , index ) } delta := 1 if done { delta = - 1 } pending [ index ] = prev + delta loop ++ if len ( indices ) > 0 && loop % 10000 == 0 { min := indices [ 0 ] w . elog . Printf ( " \n " , w . Name , index , len ( indices ) , w . DoneUntil ( ) , min , pending [ min ] ) } if doneUntil > index { AssertTruef ( false , " " , w . Name , doneUntil , index ) } until := doneUntil loops := 0 for len ( indices ) > 0 { min := indices [ 0 ] if done := pending [ min ] ; done > 0 { break } delete ( pending , min ) until = min loops ++ } for i := doneUntil + 1 ; i <= until ; i ++ { toNotify := waiters [ i ] for _ , ch := range toNotify { close ( ch ) } delete ( waiters , i ) } if until != doneUntil { AssertTrue ( atomic . CompareAndSwapUint64 ( & w . doneUntil , doneUntil , until ) ) w . elog . Printf ( " \n " , w . Name , until , loops ) } } for { select { case <- closer . HasBeenClosed ( ) : return case mark := <- w . markCh : if mark . waiter != nil { doneUntil := atomic . LoadUint64 ( & w . doneUntil ) if doneUntil >= mark . index { close ( mark . waiter ) } else { ws , ok := waiters [ mark . index ] if ! ok { waiters [ mark . index ] = [ ] chan struct { } { mark . waiter } } else { waiters [ mark . index ] = append ( ws , mark . waiter ) } } } else { if mark . index > 0 { processOne ( mark . index , mark . done ) } for _ , index := range mark . indices { processOne ( index , mark . done ) } } } } } 
func ( h header ) Encode ( b [ ] byte ) { binary . BigEndian . PutUint16 ( b [ 0 : 2 ] , h . plen ) binary . BigEndian . PutUint16 ( b [ 2 : 4 ] , h . klen ) binary . BigEndian . PutUint16 ( b [ 4 : 6 ] , h . vlen ) binary . BigEndian . PutUint32 ( b [ 6 : 10 ] , h . prev ) } 
func ( h * header ) Decode ( buf [ ] byte ) int { h . plen = binary . BigEndian . Uint16 ( buf [ 0 : 2 ] ) h . klen = binary . BigEndian . Uint16 ( buf [ 2 : 4 ] ) h . vlen = binary . BigEndian . Uint16 ( buf [ 4 : 6 ] ) h . prev = binary . BigEndian . Uint32 ( buf [ 6 : 10 ] ) return h . Size ( ) } 
func NewTableBuilder ( ) * Builder { return & Builder { keyBuf : newBuffer ( 1 << 20 ) , buf : newBuffer ( 1 << 20 ) , prevOffset : math . MaxUint32 , } 
func ( b Builder ) keyDiff ( newKey [ ] byte ) [ ] byte { var i int for i = 0 ; i < len ( newKey ) && i < len ( b . baseKey ) ; i ++ { if newKey [ i ] != b . baseKey [ i ] { break } } return newKey [ i : ] } 
func ( b * Builder ) Add ( key [ ] byte , value y . ValueStruct ) error { if b . counter >= restartInterval { b . finishBlock ( ) b . counter = 0 b . baseKey = [ ] byte { } b . baseOffset = uint32 ( b . buf . Len ( ) ) b . prevOffset = math . MaxUint32 } b . addHelper ( key , value ) return nil } 
func ( b * Builder ) ReachedCapacity ( cap int64 ) bool { estimateSz := b . buf . Len ( ) + 8 + 4 * len ( b . restarts ) + 8 return int64 ( estimateSz ) > cap } 
func ( b * Builder ) blockIndex ( ) [ ] byte { out := make ( [ ] byte , sz ) buf := out for _ , r := range b . restarts { binary . BigEndian . PutUint32 ( buf [ : 4 ] , r ) buf = buf [ 4 : ] } binary . BigEndian . PutUint32 ( buf [ : 4 ] , uint32 ( len ( b . restarts ) ) ) return out } 
func ( b * Builder ) Finish ( ) [ ] byte { bf := bbloom . New ( float64 ( b . keyCount ) , 0.01 ) var klen [ 2 ] byte key := make ( [ ] byte , 1024 ) for { if _ , err := b . keyBuf . Read ( klen [ : ] ) ; err == io . EOF { break } else if err != nil { y . Check ( err ) } kl := int ( binary . BigEndian . Uint16 ( klen [ : ] ) ) if cap ( key ) < kl { key = make ( [ ] byte , 2 * int ( kl ) ) } key = key [ : kl ] y . Check2 ( b . keyBuf . Read ( key ) ) bf . Add ( key ) } b . finishBlock ( ) index := b . blockIndex ( ) b . buf . Write ( index ) n , err := b . buf . Write ( bdata ) y . Check ( err ) var buf [ 4 ] byte binary . BigEndian . PutUint32 ( buf [ : ] , uint32 ( n ) ) b . buf . Write ( buf [ : ] ) return b . buf . Bytes ( ) } 
func ( opt * Options ) Errorf ( format string , v ... interface { } ) { if opt . Logger == nil { return } opt . Logger . Errorf ( format , v ... ) } 
func ( opt * Options ) Infof ( format string , v ... interface { } ) { if opt . Logger == nil { return } opt . Logger . Infof ( format , v ... ) } 
func ( opt * Options ) Warningf ( format string , v ... interface { } ) { if opt . Logger == nil { return } opt . Logger . Warningf ( format , v ... ) } 
func ( opt * Options ) Debugf ( format string , v ... interface { } ) { if opt . Logger == nil { return } opt . Logger . Debugf ( format , v ... ) } 
func ( s * Skiplist ) DecrRef ( ) { newRef := atomic . AddInt32 ( & s . ref , - 1 ) if newRef > 0 { return } s . arena . reset ( ) } 
func NewSkiplist ( arenaSize int64 ) * Skiplist { arena := newArena ( arenaSize ) head := newNode ( arena , nil , y . ValueStruct { } , maxHeight ) return & Skiplist { height : 1 , head : head , arena : arena , ref : 1 , } } 
func randomHeight ( ) int { h := 1 for h < maxHeight && rand . Uint32 ( ) <= heightIncrease { h ++ } return h } 
func ( s * Skiplist ) findNear ( key [ ] byte , less bool , allowEqual bool ) ( * node , bool ) { x := s . head level := int ( s . getHeight ( ) - 1 ) for { if next == nil { continue } } } return x , false } nextKey := next . key ( s . arena ) cmp := y . CompareKeys ( key , nextKey ) if cmp > 0 { continue } if cmp == 0 { } if ! less { } continue } } return x , false } continue } } } return x , false } } 
func ( s * Skiplist ) findSpliceForLevel ( key [ ] byte , before * node , level int ) ( * node , * node ) { for { if next == nil { return before , next } nextKey := next . key ( s . arena ) cmp := y . CompareKeys ( key , nextKey ) if cmp == 0 { } if cmp < 0 { } before = next } } 
func ( s * Skiplist ) Put ( key [ ] byte , v y . ValueStruct ) { var prev [ maxHeight + 1 ] * node var next [ maxHeight + 1 ] * node prev [ listHeight ] = s . head next [ listHeight ] = nil for i := int ( listHeight ) - 1 ; i >= 0 ; i -- { if prev [ i ] == next [ i ] { prev [ i ] . setValue ( s . arena , v ) return } } x := newNode ( s . arena , key , v , height ) for height > int ( listHeight ) { if atomic . CompareAndSwapInt32 ( & s . height , listHeight , int32 ( height ) ) { } listHeight = s . getHeight ( ) } } nextOffset := s . arena . getNodeOffset ( next [ i ] ) x . tower [ i ] = nextOffset if prev [ i ] . casNextOffset ( i , nextOffset , s . arena . getNodeOffset ( x ) ) { } if prev [ i ] == next [ i ] { y . AssertTruef ( i == 0 , " " , i ) prev [ i ] . setValue ( s . arena , v ) return } } } } 
func ( s * Skiplist ) findLast ( ) * node { n := s . head level := int ( s . getHeight ( ) ) - 1 for { next := s . getNext ( n , level ) if next != nil { n = next continue } if level == 0 { if n == s . head { return nil } return n } level -- } } 
func ( s * Skiplist ) Get ( key [ ] byte ) y . ValueStruct { n , _ := s . findNear ( key , false , true ) if n == nil { return y . ValueStruct { } } nextKey := s . arena . getKey ( n . keyOffset , n . keySize ) if ! y . SameKey ( key , nextKey ) { return y . ValueStruct { } } valOffset , valSize := n . getValueOffset ( ) vs := s . arena . getVal ( valOffset , valSize ) vs . Version = y . ParseTs ( nextKey ) return vs } 
func ( s * Iterator ) Key ( ) [ ] byte { return s . list . arena . getKey ( s . n . keyOffset , s . n . keySize ) } 
func ( s * Iterator ) Value ( ) y . ValueStruct { valOffset , valSize := s . n . getValueOffset ( ) return s . list . arena . getVal ( valOffset , valSize ) } 
func ( s * Iterator ) Next ( ) { y . AssertTrue ( s . Valid ( ) ) s . n = s . list . getNext ( s . n , 0 ) } 
func ( s * Iterator ) Prev ( ) { y . AssertTrue ( s . Valid ( ) ) s . n , _ = s . list . findNear ( s . Key ( ) , true , false ) } 
func ( s * Iterator ) Seek ( target [ ] byte ) { s . n , _ = s . list . findNear ( target , false , true ) } 
func ( s * Iterator ) SeekForPrev ( target [ ] byte ) { s . n , _ = s . list . findNear ( target , true , true ) } 
func ( s * Iterator ) SeekToFirst ( ) { s . n = s . list . getNext ( s . list . head , 0 ) } 
func ( s * Skiplist ) NewUniIterator ( reversed bool ) * UniIterator { return & UniIterator { iter : s . NewIterator ( ) , reversed : reversed , } } 
func ( s * UniIterator ) Next ( ) { if ! s . reversed { s . iter . Next ( ) } else { s . iter . Prev ( ) } } 
func ( s * UniIterator ) Rewind ( ) { if ! s . reversed { s . iter . SeekToFirst ( ) } else { s . iter . SeekToLast ( ) } } 
func ( s * UniIterator ) Seek ( key [ ] byte ) { if ! s . reversed { s . iter . Seek ( key ) } else { s . iter . SeekForPrev ( key ) } } 
func ( m * Manifest ) asChanges ( ) [ ] * pb . ManifestChange { changes := make ( [ ] * pb . ManifestChange , 0 , len ( m . Tables ) ) for id , tm := range m . Tables { changes = append ( changes , newCreateChange ( id , int ( tm . Level ) , tm . Checksum ) ) } return changes } 
func openOrCreateManifestFile ( dir string , readOnly bool ) ( ret * manifestFile , result Manifest , err error ) { return helpOpenOrCreateManifestFile ( dir , readOnly , manifestDeletionsRewriteThreshold ) } 
func ( mf * manifestFile ) addChanges ( changesParam [ ] * pb . ManifestChange ) error { changes := pb . ManifestChangeSet { Changes : changesParam } buf , err := changes . Marshal ( ) if err != nil { return err } if err := applyChangeSet ( & mf . manifest , & changes ) ; err != nil { mf . appendLock . Unlock ( ) return err } return err } } else { var lenCrcBuf [ 8 ] byte binary . BigEndian . PutUint32 ( lenCrcBuf [ 0 : 4 ] , uint32 ( len ( buf ) ) ) binary . BigEndian . PutUint32 ( lenCrcBuf [ 4 : 8 ] , crc32 . Checksum ( buf , y . CastagnoliCrcTable ) ) buf = append ( lenCrcBuf [ : ] , buf ... ) if _ , err := mf . fp . Write ( buf ) ; err != nil { mf . appendLock . Unlock ( ) return err } } mf . appendLock . Unlock ( ) return mf . fp . Sync ( ) } 
func ( mf * manifestFile ) rewrite ( ) error { } fp , netCreations , err := helpRewrite ( mf . directory , & mf . manifest ) if err != nil { return err } mf . fp = fp mf . manifest . Creations = netCreations mf . manifest . Deletions = 0 return nil } 
func ReplayManifestFile ( fp * os . File ) ( ret Manifest , truncOffset int64 , err error ) { r := countingReader { wrapped : bufio . NewReader ( fp ) } var magicBuf [ 8 ] byte if _ , err := io . ReadFull ( & r , magicBuf [ : ] ) ; err != nil { return Manifest { } , 0 , errBadMagic } if ! bytes . Equal ( magicBuf [ 0 : 4 ] , magicText [ : ] ) { return Manifest { } , 0 , errBadMagic } version := binary . BigEndian . Uint32 ( magicBuf [ 4 : 8 ] ) if version != magicVersion { return Manifest { } , 0 , fmt . Errorf ( " " , version , magicVersion ) } build := createManifest ( ) var offset int64 for { offset = r . count var lenCrcBuf [ 8 ] byte _ , err := io . ReadFull ( & r , lenCrcBuf [ : ] ) if err != nil { if err == io . EOF || err == io . ErrUnexpectedEOF { break } return Manifest { } , 0 , err } length := binary . BigEndian . Uint32 ( lenCrcBuf [ 0 : 4 ] ) var buf = make ( [ ] byte , length ) if _ , err := io . ReadFull ( & r , buf ) ; err != nil { if err == io . EOF || err == io . ErrUnexpectedEOF { break } return Manifest { } , 0 , err } if crc32 . Checksum ( buf , y . CastagnoliCrcTable ) != binary . BigEndian . Uint32 ( lenCrcBuf [ 4 : 8 ] ) { break } var changeSet pb . ManifestChangeSet if err := changeSet . Unmarshal ( buf ) ; err != nil { return Manifest { } , 0 , err } if err := applyChangeSet ( & build , & changeSet ) ; err != nil { return Manifest { } , 0 , err } } return build , offset , err } 
func applyChangeSet ( build * Manifest , changeSet * pb . ManifestChangeSet ) error { for _ , change := range changeSet . Changes { if err := applyManifestChange ( build , change ) ; err != nil { return err } } return nil } 
func ( s * levelHandler ) validate ( ) error { if s . level == 0 { return nil } s . RLock ( ) defer s . RUnlock ( ) numTables := len ( s . tables ) for j := 1 ; j < numTables ; j ++ { if j >= len ( s . tables ) { return errors . Errorf ( " " , s . level , j , numTables ) } if y . CompareKeys ( s . tables [ j - 1 ] . Biggest ( ) , s . tables [ j ] . Smallest ( ) ) >= 0 { return errors . Errorf ( " \n \n \n \n " , hex . Dump ( s . tables [ j - 1 ] . Biggest ( ) ) , hex . Dump ( s . tables [ j ] . Smallest ( ) ) , s . level , j , numTables ) } if y . CompareKeys ( s . tables [ j ] . Smallest ( ) , s . tables [ j ] . Biggest ( ) ) > 0 { return errors . Errorf ( " " , s . tables [ j ] . Smallest ( ) , s . tables [ j ] . Biggest ( ) , s . level , j , numTables ) } } return nil } 
func ( s * levelsController ) reserveFileID ( ) uint64 { id := atomic . AddUint64 ( & s . nextFileID , 1 ) return id - 1 } 
func acquireDirectoryLock ( dirPath string , pidFileName string , readOnly bool ) ( * directoryLockGuard , error ) { if readOnly { return nil , ErrWindowsNotSupported } if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrapf ( err , " " , absLockFilePath ) } return & directoryLockGuard { h : h , path : absLockFilePath } , nil } 
func ( g * directoryLockGuard ) release ( ) error { g . path = " " return syscall . CloseHandle ( g . h ) } 
func AssertTruef ( b bool , format string , args ... interface { } ) { if ! b { log . Fatalf ( " " , errors . Errorf ( format , args ... ) ) } } 
func Wrapf ( err error , format string , args ... interface { } ) error { if ! debugMode { if err == nil { return nil } return fmt . Errorf ( format + " " , append ( args , err ) ... ) } return errors . Wrapf ( err , format , args ... ) } 
func ( s * levelHandler ) initTables ( tables [ ] * table . Table ) { s . Lock ( ) defer s . Unlock ( ) s . tables = tables s . totalSize = 0 for _ , t := range tables { s . totalSize += t . Size ( ) } if s . level == 0 { } ) } else { } ) } } 
func ( s * levelHandler ) deleteTables ( toDel [ ] * table . Table ) error { s . Lock ( ) toDelMap := make ( map [ uint64 ] struct { } ) for _ , t := range toDel { toDelMap [ t . ID ( ) ] = struct { } { } } for _ , t := range s . tables { _ , found := toDelMap [ t . ID ( ) ] if ! found { newTables = append ( newTables , t ) continue } s . totalSize -= t . Size ( ) } s . tables = newTables s . Unlock ( ) return decrRefs ( toDel ) } 
func ( s * levelHandler ) replaceTables ( toDel , toAdd [ ] * table . Table ) error { toDelMap := make ( map [ uint64 ] struct { } ) for _ , t := range toDel { toDelMap [ t . ID ( ) ] = struct { } { } } var newTables [ ] * table . Table for _ , t := range s . tables { _ , found := toDelMap [ t . ID ( ) ] if ! found { newTables = append ( newTables , t ) continue } s . totalSize -= t . Size ( ) } t . IncrRef ( ) newTables = append ( newTables , t ) } sort . Slice ( s . tables , func ( i , j int ) bool { return y . CompareKeys ( s . tables [ i ] . Smallest ( ) , s . tables [ j ] . Smallest ( ) ) < 0 } ) s . Unlock ( ) return decrRefs ( toDel ) } 
func ( s * levelHandler ) tryAddLevel0Table ( t * table . Table ) bool { y . AssertTrue ( s . level == 0 ) defer s . Unlock ( ) if len ( s . tables ) >= s . db . opt . NumLevelZeroTablesStall { return false } s . tables = append ( s . tables , t ) t . IncrRef ( ) s . totalSize += t . Size ( ) return true } 
func ( s * levelHandler ) getTableForKey ( key [ ] byte ) ( [ ] * table . Table , func ( ) error ) { s . RLock ( ) defer s . RUnlock ( ) if s . level == 0 { for i := len ( s . tables ) - 1 ; i >= 0 ; i -- { out = append ( out , s . tables [ i ] ) s . tables [ i ] . IncrRef ( ) } return out , func ( ) error { for _ , t := range out { if err := t . DecrRef ( ) ; err != nil { return err } } return nil } } } ) if idx >= len ( s . tables ) { } tbl := s . tables [ idx ] tbl . IncrRef ( ) return [ ] * table . Table { tbl } , tbl . DecrRef } 
func ( s * levelHandler ) get ( key [ ] byte ) ( y . ValueStruct , error ) { tables , decr := s . getTableForKey ( key ) keyNoTs := y . ParseKey ( key ) var maxVs y . ValueStruct for _ , th := range tables { if th . DoesNotHave ( keyNoTs ) { y . NumLSMBloomHits . Add ( s . strLevel , 1 ) continue } it := th . NewIterator ( false ) defer it . Close ( ) y . NumLSMGets . Add ( s . strLevel , 1 ) it . Seek ( key ) if ! it . Valid ( ) { continue } if y . SameKey ( key , it . Key ( ) ) { if version := y . ParseTs ( it . Key ( ) ) ; maxVs . Version < version { maxVs = it . Value ( ) maxVs . Version = version } } } return maxVs , decr ( ) } 
func ( s * levelHandler ) appendIterators ( iters [ ] y . Iterator , opt * IteratorOptions ) [ ] y . Iterator { s . RLock ( ) defer s . RUnlock ( ) tables := make ( [ ] * table . Table , 0 , len ( s . tables ) ) for _ , t := range s . tables { if opt . pickTable ( t ) { tables = append ( tables , t ) } } if len ( tables ) == 0 { return iters } if s . level == 0 { } return append ( iters , table . NewConcatIterator ( tables , opt . Reverse ) ) } 
func ( s * levelHandler ) overlappingTables ( _ levelHandlerRLocked , kr keyRange ) ( int , int ) { if len ( kr . left ) == 0 || len ( kr . right ) == 0 { return 0 , 0 } left := sort . Search ( len ( s . tables ) , func ( i int ) bool { return y . CompareKeys ( kr . left , s . tables [ i ] . Biggest ( ) ) <= 0 } ) right := sort . Search ( len ( s . tables ) , func ( i int ) bool { return y . CompareKeys ( kr . right , s . tables [ i ] . Smallest ( ) ) < 0 } ) return left , right } 
func ( item * Item ) String ( ) string { return fmt . Sprintf ( " " , item . Key ( ) , item . Version ( ) , item . meta ) } 
func ( item * Item ) KeyCopy ( dst [ ] byte ) [ ] byte { return y . SafeCopy ( dst , item . key ) } 
func ( item * Item ) Value ( fn func ( val [ ] byte ) error ) error { item . wg . Wait ( ) if item . status == prefetched { if item . err == nil && fn != nil { if err := fn ( item . val ) ; err != nil { return err } } return item . err } buf , cb , err := item . yieldItemValue ( ) defer runCallback ( cb ) if err != nil { return err } if fn != nil { return fn ( buf ) } return nil } 
func ( item * Item ) ValueCopy ( dst [ ] byte ) ( [ ] byte , error ) { item . wg . Wait ( ) if item . status == prefetched { return y . SafeCopy ( dst , item . val ) , item . err } buf , cb , err := item . yieldItemValue ( ) defer runCallback ( cb ) return y . SafeCopy ( dst , buf ) , err } 
func ( item * Item ) EstimatedSize ( ) int64 { if ! item . hasValue ( ) { return 0 } if ( item . meta & bitValuePointer ) == 0 { return int64 ( len ( item . key ) + len ( item . vptr ) ) } var vp valuePointer vp . Decode ( item . vptr ) return int64 ( vp . Len ) } 
func ( item * Item ) ValueSize ( ) int64 { if ! item . hasValue ( ) { return 0 } if ( item . meta & bitValuePointer ) == 0 { return int64 ( len ( item . vptr ) ) } var vp valuePointer vp . Decode ( item . vptr ) klen := int64 ( len ( item . key ) + 8 ) return int64 ( vp . Len ) - klen - headerBufSize - crc32 . Size } 
func ( txn * Txn ) NewIterator ( opt IteratorOptions ) * Iterator { if txn . discarded { panic ( " " ) } panic ( " " ) } defer decr ( ) txn . db . vlog . incrIteratorCount ( ) var iters [ ] y . Iterator if itr := txn . newPendingWritesIterator ( opt . Reverse ) ; itr != nil { iters = append ( iters , itr ) } for i := 0 ; i < len ( tables ) ; i ++ { iters = append ( iters , tables [ i ] . NewUniIterator ( opt . Reverse ) ) } iters = txn . db . lc . appendIterators ( iters , & opt ) res := & Iterator { txn : txn , iitr : y . NewMergeIterator ( iters , opt . Reverse ) , opt : opt , readTs : txn . readTs , } return res } 
func ( txn * Txn ) NewKeyIterator ( key [ ] byte , opt IteratorOptions ) * Iterator { if len ( opt . Prefix ) > 0 { panic ( " " ) } opt . Prefix = key opt . prefixIsKey = true return txn . NewIterator ( opt ) } 
func ( it * Iterator ) Item ( ) * Item { tx := it . txn tx . addReadKey ( it . item . Key ( ) ) return it . item } 
func ( it * Iterator ) Valid ( ) bool { if it . item == nil { return false } return bytes . HasPrefix ( it . item . key , it . opt . Prefix ) } 
func ( it * Iterator ) ValidForPrefix ( prefix [ ] byte ) bool { return it . Valid ( ) && bytes . HasPrefix ( it . item . key , prefix ) } 
func ( it * Iterator ) Close ( ) { if it . closed { return } it . closed = true it . iitr . Close ( ) for item != nil { item . wg . Wait ( ) item = l . pop ( ) } } waitFor ( it . waste ) waitFor ( it . data ) atomic . AddInt32 ( & it . txn . numIterators , - 1 ) } 
func ( it * Iterator ) Next ( ) { it . waste . push ( it . item ) for it . iitr . Valid ( ) { if it . parseItem ( ) { } } } 
func ( it * Iterator ) parseItem ( ) bool { mi := it . iitr key := mi . Key ( ) setItem := func ( item * Item ) { if it . item == nil { it . item = item } else { it . data . push ( item ) } } return false } if version > it . readTs { mi . Next ( ) return false } if it . opt . AllVersions { it . fill ( item ) setItem ( item ) mi . Next ( ) return true } return false } } FILL : if isDeletedOrExpired ( vs . Meta , vs . ExpiresAt ) { mi . Next ( ) return false } item := it . newItem ( ) it . fill ( item ) if ! it . opt . Reverse || ! mi . Valid ( ) { return true } mik := y . ParseKey ( mi . Key ( ) ) if nextTs <= it . readTs && bytes . Equal ( mik , item . key ) { } return true } 
func ( it * Iterator ) Seek ( key [ ] byte ) { for i := it . data . pop ( ) ; i != nil ; i = it . data . pop ( ) { i . wg . Wait ( ) it . waste . push ( i ) } it . lastKey = it . lastKey [ : 0 ] if len ( key ) == 0 { key = it . opt . Prefix } if len ( key ) == 0 { it . iitr . Rewind ( ) it . prefetch ( ) return } if ! it . opt . Reverse { key = y . KeyWithTs ( key , it . txn . readTs ) } else { key = y . KeyWithTs ( key , 0 ) } it . iitr . Seek ( key ) it . prefetch ( ) } 
func ( db * DB ) GetMergeOperator ( key [ ] byte , f MergeFunc , dur time . Duration ) * MergeOperator { op := & MergeOperator { f : f , db : db , key : key , closer : y . NewCloser ( 1 ) , } go op . runCompactions ( dur ) return op } 
func ( op * MergeOperator ) Add ( val [ ] byte ) error { return op . db . Update ( func ( txn * Txn ) error { return txn . Set ( op . key , val ) } ) } 
func ( op * MergeOperator ) Get ( ) ( [ ] byte , error ) { op . RLock ( ) defer op . RUnlock ( ) var existing [ ] byte err := op . db . View ( func ( txn * Txn ) ( err error ) { existing , err = op . iterateAndMerge ( txn ) return err } ) if err == errNoMerge { return existing , nil } return existing , err } 
func ( cs * compactStatus ) compareAndAdd ( _ thisAndNextLevelRLocked , cd compactDef ) bool { cs . Lock ( ) defer cs . Unlock ( ) level := cd . thisLevel . level y . AssertTruef ( level < len ( cs . levels ) - 1 , " " , level , len ( cs . levels ) ) thisLevel := cs . levels [ level ] nextLevel := cs . levels [ level + 1 ] if thisLevel . overlapsWith ( cd . thisRange ) { return false } if nextLevel . overlapsWith ( cd . nextRange ) { return false } nextLevel . ranges = append ( nextLevel . ranges , cd . nextRange ) thisLevel . delSize += cd . thisSize return true } 
func newArena ( n int64 ) * Arena { return out } 
func ( s * Arena ) putNode ( height int ) uint32 { n := atomic . AddUint32 ( & s . n , l ) y . AssertTruef ( int ( n ) <= len ( s . buf ) , " " , l , n , len ( s . buf ) ) return m } 
func ( s * Arena ) putVal ( v y . ValueStruct ) uint32 { l := uint32 ( v . EncodedSize ( ) ) n := atomic . AddUint32 ( & s . n , l ) y . AssertTruef ( int ( n ) <= len ( s . buf ) , " " , l , n , len ( s . buf ) ) m := n - l v . Encode ( s . buf [ m : ] ) return m } 
func ( s * Arena ) getNode ( offset uint32 ) * node { if offset == 0 { return nil } return ( * node ) ( unsafe . Pointer ( & s . buf [ offset ] ) ) } 
func ( s * Arena ) getKey ( offset uint32 , size uint16 ) [ ] byte { return s . buf [ offset : offset + uint32 ( size ) ] } 
func ( s * Arena ) getVal ( offset uint32 , size uint16 ) ( ret y . ValueStruct ) { ret . Decode ( s . buf [ offset : offset + uint32 ( size ) ] ) return } 
func ( s * Arena ) getNodeOffset ( nd * node ) uint32 { if nd == nil { return 0 } return uint32 ( uintptr ( unsafe . Pointer ( nd ) ) - uintptr ( unsafe . Pointer ( & s . buf [ 0 ] ) ) ) } 
func init ( ) { NumReads = expvar . NewInt ( " " ) NumWrites = expvar . NewInt ( " " ) NumBytesRead = expvar . NewInt ( " " ) NumBytesWritten = expvar . NewInt ( " " ) NumLSMGets = expvar . NewMap ( " " ) NumLSMBloomHits = expvar . NewMap ( " " ) NumGets = expvar . NewInt ( " " ) NumPuts = expvar . NewInt ( " " ) NumBlockedPuts = expvar . NewInt ( " " ) NumMemtableGets = expvar . NewInt ( " " ) LSMSize = expvar . NewMap ( " " ) VlogSize = expvar . NewMap ( " " ) PendingWrites = expvar . NewMap ( " " ) } 
func revertToManifest ( kv * DB , mf * Manifest , idMap map [ uint64 ] struct { } ) error { } } filename := table . NewFilename ( id , kv . opt . Dir ) if err := os . Remove ( filename ) ; err != nil { return y . Wrapf ( err , " " , id ) } } } return nil } 
func closeAllTables ( tables [ ] [ ] * table . Table ) { for _ , tableSlice := range tables { for _ , table := range tableSlice { _ = table . Close ( ) } } } 
func ( s * levelsController ) dropTree ( ) ( int , error ) { for _ , l := range s . levels { l . RLock ( ) all = append ( all , l . tables ... ) l . RUnlock ( ) } if len ( all ) == 0 { return 0 , nil } for _ , table := range all { changes = append ( changes , newDeleteChange ( table . ID ( ) ) ) } changeSet := pb . ManifestChangeSet { Changes : changes } if err := s . kv . manifest . addChanges ( changeSet . Changes ) ; err != nil { return 0 , err } l . totalSize = 0 l . tables = l . tables [ : 0 ] l . Unlock ( ) } for _ , table := range all { if err := table . DecrRef ( ) ; err != nil { return 0 , err } } return len ( all ) , nil } 
func ( s * levelsController ) dropPrefix ( prefix [ ] byte ) error { opt := s . kv . opt for _ , l := range s . levels { l . RLock ( ) if l . level == 0 { size := len ( l . tables ) l . RUnlock ( ) if size > 0 { cp := compactionPriority { level : 0 , score : 1.74 , if err := s . doCompact ( cp ) ; err != nil { opt . Warningf ( " " , err ) return nil } } continue } var tables [ ] * table . Table for _ , table := range l . tables { var absent bool switch { case bytes . HasPrefix ( table . Smallest ( ) , prefix ) : case bytes . HasPrefix ( table . Biggest ( ) , prefix ) : case bytes . Compare ( prefix , table . Smallest ( ) ) > 0 && bytes . Compare ( prefix , table . Biggest ( ) ) < 0 : default : absent = true } if ! absent { tables = append ( tables , table ) } } l . RUnlock ( ) if len ( tables ) == 0 { continue } cd := compactDef { elog : trace . New ( fmt . Sprintf ( " " , l . level ) , " " ) , thisLevel : l , nextLevel : l , top : [ ] * table . Table { } , bot : tables , dropPrefix : prefix , } if err := s . runCompactDef ( l . level , cd ) ; err != nil { opt . Warningf ( " " , cd , err ) return err } } return nil } 
func ( s * levelsController ) isLevel0Compactable ( ) bool { return s . levels [ 0 ] . numTables ( ) >= s . kv . opt . NumLevelZeroTables } 
func ( l * levelHandler ) isCompactable ( delSize int64 ) bool { return l . getTotalSize ( ) - delSize >= l . maxTotalSize } 
func ( s * levelsController ) pickCompactLevels ( ) ( prios [ ] compactionPriority ) { prios = append ( prios , pri ) } for i , l := range s . levels [ 1 : ] { if l . isCompactable ( delSize ) { pri := compactionPriority { level : i + 1 , score : float64 ( l . getTotalSize ( ) - delSize ) / float64 ( l . maxTotalSize ) , } prios = append ( prios , pri ) } } sort . Slice ( prios , func ( i , j int ) bool { return prios [ i ] . score > prios [ j ] . score } ) return prios } 
func ( s * levelsController ) compactBuildTables ( lev int , cd compactDef ) ( [ ] * table . Table , func ( ) error , error ) { topTables := cd . top botTables := cd . bot var hasOverlap bool { kr := getKeyRange ( cd . top ) for i , lh := range s . levels { if i <= lev { } lh . RLock ( ) left , right := lh . overlappingTables ( levelHandlerRLocked { } , kr ) lh . RUnlock ( ) if right - left > 0 { hasOverlap = true break } } } updateStats := func ( vs y . ValueStruct ) { if vs . Meta & bitValuePointer > 0 { var vp valuePointer vp . Decode ( vs . Value ) discardStats [ vp . Fid ] += int64 ( vp . Len ) } } if lev == 0 { iters = appendIteratorsReversed ( iters , topTables , false ) } else if len ( topTables ) > 0 { y . AssertTrue ( len ( topTables ) == 1 ) iters = [ ] y . Iterator { topTables [ 0 ] . NewIterator ( false ) } } for _ , table := range botTables { if len ( cd . dropPrefix ) > 0 && bytes . HasPrefix ( table . Smallest ( ) , cd . dropPrefix ) && bytes . HasPrefix ( table . Biggest ( ) , cd . dropPrefix ) { } valid = append ( valid , table ) } iters = append ( iters , table . NewConcatIterator ( valid , false ) ) it := y . NewMergeIterator ( iters , false ) defer it . Close ( ) it . Rewind ( ) err error } resultCh := make ( chan newTableResult ) var numBuilds , numVersions int var lastKey , skipKey [ ] byte for it . Valid ( ) { timeStart := time . Now ( ) builder := table . NewTableBuilder ( ) var numKeys , numSkips uint64 for ; it . Valid ( ) ; it . Next ( ) { updateStats ( it . Value ( ) ) continue } updateStats ( it . Value ( ) ) continue } else { skipKey = skipKey [ : 0 ] } } if ! y . SameKey ( it . Key ( ) , lastKey ) { if builder . ReachedCapacity ( s . kv . opt . MaxTableSize ) { } lastKey = y . SafeCopy ( lastKey , it . Key ( ) ) numVersions = 0 } vs := it . Value ( ) version := y . ParseTs ( it . Key ( ) ) if version <= discardTs { lastValidVersion := vs . Meta & bitDiscardEarlierVersions > 0 if isDeletedOrExpired ( vs . Meta , vs . ExpiresAt ) || numVersions > s . kv . opt . NumVersionsToKeep || lastValidVersion { if lastValidVersion { updateStats ( vs ) continue } } } numKeys ++ y . Check ( builder . Add ( it . Key ( ) , it . Value ( ) ) ) } if ! builder . Empty ( ) { numBuilds ++ fileID := s . reserveFileID ( ) go func ( builder * table . Builder ) { defer builder . Close ( ) fd , err := y . CreateSyncedFile ( table . NewFilename ( fileID , s . kv . opt . Dir ) , true ) if err != nil { resultCh <- newTableResult { nil , errors . Wrapf ( err , " " , fileID ) } return } if _ , err := fd . Write ( builder . Finish ( ) ) ; err != nil { resultCh <- newTableResult { nil , errors . Wrapf ( err , " " , fileID ) } return } tbl , err := table . OpenTable ( fd , s . kv . opt . TableLoadingMode , nil ) } ( builder ) } } newTables := make ( [ ] * table . Table , 0 , 20 ) for x := 0 ; x < numBuilds ; x ++ { res := <- resultCh newTables = append ( newTables , res . table ) if firstErr == nil { firstErr = res . err } } if firstErr == nil { } if firstErr != nil { } } errorReturn := errors . Wrapf ( firstErr , " " , cd ) return nil , nil , errorReturn } sort . Slice ( newTables , func ( i , j int ) bool { return y . CompareKeys ( newTables [ i ] . Biggest ( ) , newTables [ j ] . Biggest ( ) ) < 0 } ) s . kv . vlog . updateDiscardStats ( discardStats ) s . kv . opt . Debugf ( " " , discardStats ) return newTables , func ( ) error { return decrRefs ( newTables ) } , nil } 
func ( s * levelsController ) doCompact ( p compactionPriority ) error { l := p . level y . AssertTrue ( l + 1 < s . kv . opt . MaxLevels ) cd := compactDef { elog : trace . New ( fmt . Sprintf ( " " , l ) , " " ) , thisLevel : s . levels [ l ] , nextLevel : s . levels [ l + 1 ] , dropPrefix : p . dropPrefix , } cd . elog . SetMaxEvents ( 100 ) defer cd . elog . Finish ( ) s . kv . opt . Infof ( " " , p ) } } else { if ! s . fillTables ( & cd ) { return errFillTables } } defer s . cstatus . delete ( cd ) s . kv . opt . Infof ( " \n " , cd . thisLevel . level ) s . cstatus . toLog ( cd . elog ) if err := s . runCompactDef ( l , cd ) ; err != nil { return err } s . cstatus . toLog ( cd . elog ) s . kv . opt . Infof ( " " , cd . thisLevel . level ) return nil } 
func ( s * levelsController ) get ( key [ ] byte , maxVs * y . ValueStruct ) ( y . ValueStruct , error ) { for _ , h := range s . levels { vs , err := h . get ( key ) if err != nil { return y . ValueStruct { } , errors . Wrapf ( err , " " , key ) } if vs . Value == nil && vs . Meta == 0 { continue } if maxVs == nil || vs . Version == version { return vs , nil } if maxVs . Version < vs . Version { * maxVs = vs } } if maxVs != nil { return * maxVs , nil } return y . ValueStruct { } , nil } 
func ( s * levelsController ) appendIterators ( iters [ ] y . Iterator , opt * IteratorOptions ) [ ] y . Iterator { } return iters } 
func seekTotal ( txn * badger . Txn ) ( [ ] account , error ) { expected := uint64 ( numAccounts ) * uint64 ( initialBal ) var accounts [ ] account var total uint64 for i := 0 ; i < numAccounts ; i ++ { item , err := txn . Get ( key ( i ) ) if err != nil { log . Printf ( " \n " , i , err , key ( i ) ) return accounts , err } val , err := item . ValueCopy ( nil ) if err != nil { return accounts , err } acc := account { Id : i , Bal : toUint64 ( val ) , } accounts = append ( accounts , acc ) total += acc . Bal } if total != expected { log . Printf ( " " , expected , total ) atomic . AddInt32 ( & stopAll , 1 ) return accounts , errFailure } return accounts , nil } 
func findFirstInvalidTxn ( db * badger . DB , lowTs , highTs uint64 ) uint64 { checkAt := func ( ts uint64 ) error { txn := db . NewTransactionAt ( ts , false ) _ , err := seekTotal ( txn ) txn . Discard ( ) return err } if highTs - lowTs < 1 { log . Printf ( " \n " , lowTs ) err := checkAt ( lowTs ) if err == errFailure { fmt . Printf ( " \n " , lowTs ) return lowTs } else if err != nil { log . Printf ( " \n " , lowTs , err ) return 0 } fmt . Printf ( " \n " , lowTs ) return 0 } midTs := ( lowTs + highTs ) / 2 log . Println ( ) log . Printf ( " \n " , lowTs , highTs , midTs ) err := checkAt ( midTs ) if err == badger . ErrKeyNotFound || err == nil { } } 
func ( m * InmemSnapshotStore ) Create ( version SnapshotVersion , index , term uint64 , configuration Configuration , configurationIndex uint64 , trans Transport ) ( SnapshotSink , error ) { } name := snapshotName ( term , index ) m . Lock ( ) defer m . Unlock ( ) sink := & InmemSnapshotSink { meta : SnapshotMeta { Version : version , ID : name , Index : index , Term : term , Peers : encodePeers ( configuration , trans ) , Configuration : configuration , ConfigurationIndex : configurationIndex , } , contents : & bytes . Buffer { } , } m . hasSnapshot = true m . latest = sink return sink , nil } 
func ( m * InmemSnapshotStore ) List ( ) ( [ ] * SnapshotMeta , error ) { m . RLock ( ) defer m . RUnlock ( ) if ! m . hasSnapshot { return [ ] * SnapshotMeta { } , nil } return [ ] * SnapshotMeta { & m . latest . meta } , nil } 
func ( m * InmemSnapshotStore ) Open ( id string ) ( * SnapshotMeta , io . ReadCloser , error ) { m . RLock ( ) defer m . RUnlock ( ) if m . latest . meta . ID != id { return nil , nil , fmt . Errorf ( " " , id ) } return & m . latest . meta , ioutil . NopCloser ( m . latest . contents ) , nil } 
func ( s * InmemSnapshotSink ) Write ( p [ ] byte ) ( n int , err error ) { written , err := io . Copy ( s . contents , bytes . NewReader ( p ) ) s . meta . Size += written return int ( written ) , err } 
func NewFileSnapshotStoreWithLogger ( base string , retain int , logger * log . Logger ) ( * FileSnapshotStore , error ) { if retain < 1 { return nil , fmt . Errorf ( " " ) } if logger == nil { logger = log . New ( os . Stderr , " " , log . LstdFlags ) } if err := os . MkdirAll ( path , 0755 ) ; err != nil && ! os . IsExist ( err ) { return nil , fmt . Errorf ( " " , err ) } } return store , nil } 
func NewFileSnapshotStore ( base string , retain int , logOutput io . Writer ) ( * FileSnapshotStore , error ) { if logOutput == nil { logOutput = os . Stderr } return NewFileSnapshotStoreWithLogger ( base , retain , log . New ( logOutput , " " , log . LstdFlags ) ) } 
func snapshotName ( term , index uint64 ) string { now := time . Now ( ) msec := now . UnixNano ( ) / int64 ( time . Millisecond ) return fmt . Sprintf ( " " , term , index , msec ) } 
func ( f * FileSnapshotStore ) Create ( version SnapshotVersion , index , term uint64 , configuration Configuration , configurationIndex uint64 , trans Transport ) ( SnapshotSink , error ) { } path := filepath . Join ( f . path , name + tmpSuffix ) f . logger . Printf ( " " , path ) return nil , err } return nil , err } fh , err := os . Create ( statePath ) if err != nil { f . logger . Printf ( " " , err ) return nil , err } sink . stateFile = fh sink . buffered = bufio . NewWriter ( multi ) } 
func ( f * FileSnapshotStore ) List ( ) ( [ ] * SnapshotMeta , error ) { if err != nil { f . logger . Printf ( " " , err ) return nil , err } var snapMeta [ ] * SnapshotMeta for _ , meta := range snapshots { snapMeta = append ( snapMeta , & meta . SnapshotMeta ) if len ( snapMeta ) == f . retain { break } } return snapMeta , nil } 
func ( f * FileSnapshotStore ) getSnapshots ( ) ( [ ] * fileSnapshotMeta , error ) { if err != nil { f . logger . Printf ( " " , err ) return nil , err } for _ , snap := range snapshots { } if strings . HasSuffix ( dirName , tmpSuffix ) { f . logger . Printf ( " " , dirName ) continue } if err != nil { f . logger . Printf ( " " , dirName , err ) continue } continue } } return snapMeta , nil } 
func ( f * FileSnapshotStore ) readMeta ( name string ) ( * fileSnapshotMeta , error ) { fh , err := os . Open ( metaPath ) if err != nil { return nil , err } defer fh . Close ( ) dec := json . NewDecoder ( buffered ) if err := dec . Decode ( meta ) ; err != nil { return nil , err } return meta , nil } 
func ( f * FileSnapshotStore ) Open ( id string ) ( * SnapshotMeta , io . ReadCloser , error ) { if err != nil { f . logger . Printf ( " " , err ) return nil , nil , err } fh , err := os . Open ( statePath ) if err != nil { f . logger . Printf ( " " , err ) return nil , nil , err } if err != nil { f . logger . Printf ( " " , err ) fh . Close ( ) return nil , nil , err } if bytes . Compare ( meta . CRC , computed ) != 0 { f . logger . Printf ( " " , meta . CRC , computed ) fh . Close ( ) return nil , nil , fmt . Errorf ( " " ) } fh . Close ( ) return nil , nil , err } return & meta . SnapshotMeta , buffered , nil } 
func ( f * FileSnapshotStore ) ReapSnapshots ( ) error { snapshots , err := f . getSnapshots ( ) if err != nil { f . logger . Printf ( " " , err ) return err } for i := f . retain ; i < len ( snapshots ) ; i ++ { path := filepath . Join ( f . path , snapshots [ i ] . ID ) f . logger . Printf ( " " , path ) if err := os . RemoveAll ( path ) ; err != nil { f . logger . Printf ( " " , path , err ) return err } } return nil } 
func ( s * FileSnapshotSink ) Write ( b [ ] byte ) ( int , error ) { return s . buffered . Write ( b ) } 
func ( s * FileSnapshotSink ) Close ( ) error { } s . closed = true if delErr := os . RemoveAll ( s . dir ) ; delErr != nil { s . logger . Printf ( " " , s . dir , delErr ) return delErr } return err } return err } if err := os . Rename ( s . dir , newPath ) ; err != nil { s . logger . Printf ( " " , err ) return err } if runtime . GOOS != " " { defer parentFH . Close ( ) if err != nil { s . logger . Printf ( " " , s . parentDir , err ) return err } if err = parentFH . Sync ( ) ; err != nil { s . logger . Printf ( " " , s . parentDir , err ) return err } } } return nil } 
func ( s * FileSnapshotSink ) Cancel ( ) error { } s . closed = true return err } } 
func ( s * FileSnapshotSink ) finalize ( ) error { } } } } s . meta . Size = stat . Size ( ) return nil } 
func ( s * FileSnapshotSink ) writeMeta ( ) error { fh , err := os . Create ( metaPath ) if err != nil { return err } defer fh . Close ( ) if err := enc . Encode ( & s . meta ) ; err != nil { return err } if err = buffered . Flush ( ) ; err != nil { return err } if err = fh . Sync ( ) ; err != nil { return err } return nil } 
func NewNetworkTransportWithConfig ( config * NetworkTransportConfig , ) * NetworkTransport { if config . Logger == nil { config . Logger = log . New ( os . Stderr , " " , log . LstdFlags ) } trans := & NetworkTransport { connPool : make ( map [ ServerAddress ] [ ] * netConn ) , consumeCh : make ( chan RPC ) , logger : config . Logger , maxPool : config . MaxPool , shutdownCh : make ( chan struct { } ) , stream : config . Stream , timeout : config . Timeout , TimeoutScale : DefaultTimeoutScale , serverAddressProvider : config . ServerAddressProvider , } go trans . listen ( ) return trans } 
func NewNetworkTransport ( stream StreamLayer , maxPool int , timeout time . Duration , logOutput io . Writer , ) * NetworkTransport { if logOutput == nil { logOutput = os . Stderr } logger := log . New ( logOutput , " " , log . LstdFlags ) config := & NetworkTransportConfig { Stream : stream , MaxPool : maxPool , Timeout : timeout , Logger : logger } return NewNetworkTransportWithConfig ( config ) } 
func NewNetworkTransportWithLogger ( stream StreamLayer , maxPool int , timeout time . Duration , logger * log . Logger , ) * NetworkTransport { config := & NetworkTransportConfig { Stream : stream , MaxPool : maxPool , Timeout : timeout , Logger : logger } return NewNetworkTransportWithConfig ( config ) } 
func ( n * NetworkTransport ) setupStreamContext ( ) { ctx , cancel := context . WithCancel ( context . Background ( ) ) n . streamCtx = ctx n . streamCancel = cancel } 
func ( n * NetworkTransport ) getStreamContext ( ) context . Context { n . streamCtxLock . RLock ( ) defer n . streamCtxLock . RUnlock ( ) return n . streamCtx } 
func ( n * NetworkTransport ) SetHeartbeatHandler ( cb func ( rpc RPC ) ) { n . heartbeatFnLock . Lock ( ) defer n . heartbeatFnLock . Unlock ( ) n . heartbeatFn = cb } 
func ( n * NetworkTransport ) CloseStreams ( ) { n . connPoolLock . Lock ( ) defer n . connPoolLock . Unlock ( ) } delete ( n . connPool , k ) } n . streamCancel ( ) n . setupStreamContext ( ) n . streamCtxLock . Unlock ( ) } 
func ( n * NetworkTransport ) Close ( ) error { n . shutdownLock . Lock ( ) defer n . shutdownLock . Unlock ( ) if ! n . shutdown { close ( n . shutdownCh ) n . stream . Close ( ) n . shutdown = true } return nil } 
func ( n * NetworkTransport ) getPooledConn ( target ServerAddress ) * netConn { n . connPoolLock . Lock ( ) defer n . connPoolLock . Unlock ( ) conns , ok := n . connPool [ target ] if ! ok || len ( conns ) == 0 { return nil } var conn * netConn num := len ( conns ) conn , conns [ num - 1 ] = conns [ num - 1 ] , nil n . connPool [ target ] = conns [ : num - 1 ] return conn } 
func ( n * NetworkTransport ) getConnFromAddressProvider ( id ServerID , target ServerAddress ) ( * netConn , error ) { address := n . getProviderAddressOrFallback ( id , target ) return n . getConn ( address ) } 
func ( n * NetworkTransport ) getConn ( target ServerAddress ) ( * netConn , error ) { } if err != nil { return nil , err } netConn . enc = codec . NewEncoder ( netConn . w , & codec . MsgpackHandle { } ) } 
func ( n * NetworkTransport ) returnConn ( conn * netConn ) { n . connPoolLock . Lock ( ) defer n . connPoolLock . Unlock ( ) key := conn . target conns , _ := n . connPool [ key ] if ! n . IsShutdown ( ) && len ( conns ) < n . maxPool { n . connPool [ key ] = append ( conns , conn ) } else { conn . Release ( ) } } 
func ( n * NetworkTransport ) AppendEntriesPipeline ( id ServerID , target ServerAddress ) ( AppendPipeline , error ) { if err != nil { return nil , err } } 
func ( n * NetworkTransport ) AppendEntries ( id ServerID , target ServerAddress , args * AppendEntriesRequest , resp * AppendEntriesResponse ) error { return n . genericRPC ( id , target , rpcAppendEntries , args , resp ) } 
func ( n * NetworkTransport ) RequestVote ( id ServerID , target ServerAddress , args * RequestVoteRequest , resp * RequestVoteResponse ) error { return n . genericRPC ( id , target , rpcRequestVote , args , resp ) } 
func ( n * NetworkTransport ) genericRPC ( id ServerID , target ServerAddress , rpcType uint8 , args interface { } , resp interface { } ) error { if err != nil { return err } } } if canReturn { n . returnConn ( conn ) } return err } 
func ( n * NetworkTransport ) InstallSnapshot ( id ServerID , target ServerAddress , args * InstallSnapshotRequest , resp * InstallSnapshotResponse , data io . Reader ) error { if err != nil { return err } defer conn . Release ( ) if timeout < n . timeout { timeout = n . timeout } conn . conn . SetDeadline ( time . Now ( ) . Add ( timeout ) ) } } } } return err } 
func ( n * NetworkTransport ) EncodePeer ( id ServerID , p ServerAddress ) [ ] byte { address := n . getProviderAddressOrFallback ( id , p ) return [ ] byte ( address ) } 
func ( n * NetworkTransport ) listen ( ) { const baseDelay = 5 * time . Millisecond const maxDelay = 1 * time . Second var loopDelay time . Duration for { if err != nil { if loopDelay == 0 { loopDelay = baseDelay } else { loopDelay *= 2 } if loopDelay > maxDelay { loopDelay = maxDelay } if ! n . IsShutdown ( ) { n . logger . Printf ( " " , err ) } select { case <- n . shutdownCh : return case <- time . After ( loopDelay ) : continue } } n . logger . Printf ( " " , n . LocalAddr ( ) , conn . RemoteAddr ( ) ) } } 
func ( n * NetworkTransport ) handleConn ( connCtx context . Context , conn net . Conn ) { defer conn . Close ( ) r := bufio . NewReader ( conn ) w := bufio . NewWriter ( conn ) dec := codec . NewDecoder ( r , & codec . MsgpackHandle { } ) enc := codec . NewEncoder ( w , & codec . MsgpackHandle { } ) for { select { case <- connCtx . Done ( ) : n . logger . Println ( " " ) return default : } if err := n . handleCommand ( r , dec , enc ) ; err != nil { if err != io . EOF { n . logger . Printf ( " " , err ) } return } if err := w . Flush ( ) ; err != nil { n . logger . Printf ( " " , err ) return } } } 
func ( n * NetworkTransport ) handleCommand ( r * bufio . Reader , dec * codec . Decoder , enc * codec . Encoder ) error { if err != nil { return err } rpc := RPC { RespChan : respCh , } switch rpcType { case rpcAppendEntries : var req AppendEntriesRequest if err := dec . Decode ( & req ) ; err != nil { return err } rpc . Command = & req } case rpcRequestVote : var req RequestVoteRequest if err := dec . Decode ( & req ) ; err != nil { return err } rpc . Command = & req case rpcInstallSnapshot : var req InstallSnapshotRequest if err := dec . Decode ( & req ) ; err != nil { return err } rpc . Command = & req rpc . Reader = io . LimitReader ( r , req . Size ) default : return fmt . Errorf ( " " , rpcType ) } fn := n . heartbeatFn n . heartbeatFnLock . Unlock ( ) if fn != nil { fn ( rpc ) goto RESP } } } if resp . Error != nil { respErr = resp . Error . Error ( ) } if err := enc . Encode ( respErr ) ; err != nil { return err } } case <- n . shutdownCh : return ErrTransportShutdown } return nil } 
func decodeResponse ( conn * netConn , resp interface { } ) ( bool , error ) { if err := conn . dec . Decode ( & rpcError ) ; err != nil { conn . Release ( ) return false , err } return false , err } } return true , nil } 
func sendRPC ( conn * netConn , rpcType uint8 , args interface { } ) error { return err } return err } return err } return nil } 
func newNetPipeline ( trans * NetworkTransport , conn * netConn ) * netPipeline { n := & netPipeline { conn : conn , trans : trans , doneCh : make ( chan AppendFuture , rpcMaxPipeline ) , inprogressCh : make ( chan * appendFuture , rpcMaxPipeline ) , shutdownCh : make ( chan struct { } ) , } go n . decodeResponses ( ) return n } 
func ( n * netPipeline ) decodeResponses ( ) { timeout := n . trans . timeout for { select { case future := <- n . inprogressCh : if timeout > 0 { n . conn . conn . SetReadDeadline ( time . Now ( ) . Add ( timeout ) ) } _ , err := decodeResponse ( n . conn , future . resp ) future . respond ( err ) select { case n . doneCh <- future : case <- n . shutdownCh : return } case <- n . shutdownCh : return } } } 
func ( n * netPipeline ) AppendEntries ( args * AppendEntriesRequest , resp * AppendEntriesResponse ) ( AppendFuture , error ) { future . init ( ) } } case <- n . shutdownCh : return nil , ErrPipelineShutdown } } 
func ( n * netPipeline ) Close ( ) error { n . shutdownLock . Lock ( ) defer n . shutdownLock . Unlock ( ) if n . shutdown { return nil } n . shutdown = true close ( n . shutdownCh ) return nil } 
func NewObserver ( channel chan Observation , blocking bool , filter FilterFn ) * Observer { return & Observer { channel : channel , blocking : blocking , filter : filter , id : atomic . AddUint64 ( & nextObserverID , 1 ) , } } 
func ( r * Raft ) RegisterObserver ( or * Observer ) { r . observersLock . Lock ( ) defer r . observersLock . Unlock ( ) r . observers [ or . id ] = or } 
func ( r * Raft ) DeregisterObserver ( or * Observer ) { r . observersLock . Lock ( ) defer r . observersLock . Unlock ( ) delete ( r . observers , or . id ) } 
func ( r * Raft ) observe ( o interface { } ) { defer r . observersLock . RUnlock ( ) for _ , or := range r . observers { if or . filter != nil && ! or . filter ( & ob ) { continue } if or . channel == nil { continue } if or . blocking { or . channel <- ob atomic . AddUint64 ( & or . numObserved , 1 ) } else { select { case or . channel <- ob : atomic . AddUint64 ( & or . numObserved , 1 ) default : atomic . AddUint64 ( & or . numDropped , 1 ) } } } } 
func NewInmemStore ( ) * InmemStore { i := & InmemStore { logs : make ( map [ uint64 ] * Log ) , kv : make ( map [ string ] [ ] byte ) , kvInt : make ( map [ string ] uint64 ) , } return i } 
func ( i * InmemStore ) FirstIndex ( ) ( uint64 , error ) { i . l . RLock ( ) defer i . l . RUnlock ( ) return i . lowIndex , nil } 
func ( i * InmemStore ) LastIndex ( ) ( uint64 , error ) { i . l . RLock ( ) defer i . l . RUnlock ( ) return i . highIndex , nil } 
func ( i * InmemStore ) GetLog ( index uint64 , log * Log ) error { i . l . RLock ( ) defer i . l . RUnlock ( ) l , ok := i . logs [ index ] if ! ok { return ErrLogNotFound } * log = * l return nil } 
func ( i * InmemStore ) StoreLog ( log * Log ) error { return i . StoreLogs ( [ ] * Log { log } ) } 
func ( i * InmemStore ) StoreLogs ( logs [ ] * Log ) error { i . l . Lock ( ) defer i . l . Unlock ( ) for _ , l := range logs { i . logs [ l . Index ] = l if i . lowIndex == 0 { i . lowIndex = l . Index } if l . Index > i . highIndex { i . highIndex = l . Index } } return nil } 
func ( i * InmemStore ) DeleteRange ( min , max uint64 ) error { i . l . Lock ( ) defer i . l . Unlock ( ) for j := min ; j <= max ; j ++ { delete ( i . logs , j ) } if min <= i . lowIndex { i . lowIndex = max + 1 } if max >= i . highIndex { i . highIndex = min - 1 } if i . lowIndex > i . highIndex { i . lowIndex = 0 i . highIndex = 0 } return nil } 
func ( i * InmemStore ) Set ( key [ ] byte , val [ ] byte ) error { i . l . Lock ( ) defer i . l . Unlock ( ) i . kv [ string ( key ) ] = val return nil } 
func ( i * InmemStore ) Get ( key [ ] byte ) ( [ ] byte , error ) { i . l . RLock ( ) defer i . l . RUnlock ( ) val := i . kv [ string ( key ) ] if val == nil { return nil , errors . New ( " " ) } return val , nil } 
func ( i * InmemStore ) SetUint64 ( key [ ] byte , val uint64 ) error { i . l . Lock ( ) defer i . l . Unlock ( ) i . kvInt [ string ( key ) ] = val return nil } 
func ( i * InmemStore ) GetUint64 ( key [ ] byte ) ( uint64 , error ) { i . l . RLock ( ) defer i . l . RUnlock ( ) return i . kvInt [ string ( key ) ] , nil } 
func NewLogCache ( capacity int , store LogStore ) ( * LogCache , error ) { if capacity <= 0 { return nil , fmt . Errorf ( " " ) } c := & LogCache { store : store , cache : make ( [ ] * Log , capacity ) , } return c , nil } 
func NewInmemTransportWithTimeout ( addr ServerAddress , timeout time . Duration ) ( ServerAddress , * InmemTransport ) { if string ( addr ) == " " { addr = NewInmemAddr ( ) } trans := & InmemTransport { consumerCh : make ( chan RPC , 16 ) , localAddr : addr , peers : make ( map [ ServerAddress ] * InmemTransport ) , timeout : timeout , } return addr , trans } 
func ( i * InmemTransport ) AppendEntriesPipeline ( id ServerID , target ServerAddress ) ( AppendPipeline , error ) { i . Lock ( ) defer i . Unlock ( ) peer , ok := i . peers [ target ] if ! ok { return nil , fmt . Errorf ( " " , target ) } pipeline := newInmemPipeline ( i , peer , target ) i . pipelines = append ( i . pipelines , pipeline ) return pipeline , nil } 
func ( i * InmemTransport ) AppendEntries ( id ServerID , target ServerAddress , args * AppendEntriesRequest , resp * AppendEntriesResponse ) error { rpcResp , err := i . makeRPC ( target , args , nil , i . timeout ) if err != nil { return err } * resp = * out return nil } 
func ( i * InmemTransport ) RequestVote ( id ServerID , target ServerAddress , args * RequestVoteRequest , resp * RequestVoteResponse ) error { rpcResp , err := i . makeRPC ( target , args , nil , i . timeout ) if err != nil { return err } * resp = * out return nil } 
func ( i * InmemTransport ) InstallSnapshot ( id ServerID , target ServerAddress , args * InstallSnapshotRequest , resp * InstallSnapshotResponse , data io . Reader ) error { rpcResp , err := i . makeRPC ( target , args , data , 10 * i . timeout ) if err != nil { return err } * resp = * out return nil } 
func ( i * InmemTransport ) EncodePeer ( id ServerID , p ServerAddress ) [ ] byte { return [ ] byte ( p ) } 
func ( i * InmemTransport ) Connect ( peer ServerAddress , t Transport ) { trans := t . ( * InmemTransport ) i . Lock ( ) defer i . Unlock ( ) i . peers [ peer ] = trans } 
func ( i * InmemTransport ) Disconnect ( peer ServerAddress ) { i . Lock ( ) defer i . Unlock ( ) delete ( i . peers , peer ) for idx := 0 ; idx < n ; idx ++ { if i . pipelines [ idx ] . peerAddr == peer { i . pipelines [ idx ] . Close ( ) i . pipelines [ idx ] , i . pipelines [ n - 1 ] = i . pipelines [ n - 1 ] , nil idx -- n -- } } i . pipelines = i . pipelines [ : n ] } 
func ( i * InmemTransport ) DisconnectAll ( ) { i . Lock ( ) defer i . Unlock ( ) i . peers = make ( map [ ServerAddress ] * InmemTransport ) } i . pipelines = nil } 
func ( r * RPC ) Respond ( resp interface { } , err error ) { r . RespChan <- RPCResponse { resp , err } } 
func ( u * userSnapshotFuture ) Open ( ) ( * SnapshotMeta , io . ReadCloser , error ) { if u . opener == nil { return nil , nil , fmt . Errorf ( " " ) } else { } ( ) return u . opener ( ) } } 
func ( v * verifyFuture ) vote ( leader bool ) { v . voteLock . Lock ( ) defer v . voteLock . Unlock ( ) } if leader { v . votes ++ if v . votes >= v . quorumSize { v . notifyCh <- v v . notifyCh = nil } } else { v . notifyCh <- v v . notifyCh = nil } } 
func ( s * followerReplication ) notifyAll ( leader bool ) { n := s . notify s . notify = make ( map [ * verifyFuture ] struct { } ) s . notifyLock . Unlock ( ) } } 
func ( s * followerReplication ) cleanNotify ( v * verifyFuture ) { s . notifyLock . Lock ( ) delete ( s . notify , v ) s . notifyLock . Unlock ( ) } 
func ( s * followerReplication ) LastContact ( ) time . Time { s . lastContactLock . RLock ( ) last := s . lastContact s . lastContactLock . RUnlock ( ) return last } 
func ( s * followerReplication ) setLastContact ( ) { s . lastContactLock . Lock ( ) s . lastContact = time . Now ( ) s . lastContactLock . Unlock ( ) } 
func ( r * Raft ) replicate ( s * followerReplication ) { defer close ( stopHeartbeat ) r . goFunc ( func ( ) { r . heartbeat ( s , stopHeartbeat ) } ) RPC : shouldStop := false for ! shouldStop { select { case maxIndex := <- s . stopCh : } return case <- s . triggerCh : lastLogIdx , _ := r . getLastLog ( ) shouldStop = r . replicateTo ( s , lastLogIdx ) shouldStop = r . replicateTo ( s , lastLogIdx ) } } } return PIPELINE : } } goto RPC } 
func ( r * Raft ) replicateTo ( s * followerReplication , lastIndex uint64 ) ( shouldStop bool ) { var resp AppendEntriesResponse var start time . Time START : } } else if err != nil { return } if err := r . trans . AppendEntries ( s . peer . ID , s . peer . Address , & req , & resp ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , s . peer , err ) ) s . failures ++ return } appendStats ( string ( s . peer . ID ) , start , float32 ( len ( req . Entries ) ) ) return true } s . allowPipeline = true } else { s . nextIndex = max ( min ( s . nextIndex - 1 , resp . LastLog + 1 ) , 1 ) if resp . NoRetryBackoff { s . failures = 0 } else { s . failures ++ } r . logger . Warn ( fmt . Sprintf ( " " , s . peer , s . nextIndex ) ) } CHECK_MORE : default : } } return } else if err != nil { r . logger . Error ( fmt . Sprintf ( " " , s . peer , err ) ) return } } 
func ( r * Raft ) heartbeat ( s * followerReplication , stopCh chan struct { } ) { var failures uint64 req := AppendEntriesRequest { RPCHeader : r . getRPCHeader ( ) , Term : s . currentTerm , Leader : r . trans . EncodePeer ( r . localID , r . localAddr ) , } var resp AppendEntriesResponse for { } start := time . Now ( ) if err := r . trans . AppendEntries ( s . peer . ID , s . peer . Address , & req , & resp ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , s . peer . Address , err ) ) failures ++ select { case <- time . After ( backoff ( failureWait , failures , maxFailureScale ) ) : case <- stopCh : } } else { s . setLastContact ( ) failures = 0 metrics . MeasureSince ( [ ] string { " " , " " , " " , string ( s . peer . ID ) } , start ) s . notifyAll ( resp . Success ) } } } 
func ( r * Raft ) pipelineReplicate ( s * followerReplication ) error { if err != nil { return err } defer pipeline . Close ( ) defer r . logger . Info ( fmt . Sprintf ( " " , s . peer ) ) finishCh := make ( chan struct { } ) shouldStop := false SEND : for ! shouldStop { select { case <- finishCh : break SEND case maxIndex := <- s . stopCh : } break SEND case <- s . triggerCh : lastLogIdx , _ := r . getLastLog ( ) shouldStop = r . pipelineSend ( s , pipeline , & nextIndex , lastLogIdx ) case <- randomTimeout ( r . conf . CommitTimeout ) : lastLogIdx , _ := r . getLastLog ( ) shouldStop = r . pipelineSend ( s , pipeline , & nextIndex , lastLogIdx ) } } select { case <- finishCh : case <- r . shutdownCh : } return nil } 
func ( r * Raft ) pipelineSend ( s * followerReplication , p AppendPipeline , nextIdx * uint64 , lastIndex uint64 ) ( shouldStop bool ) { if err := r . setupAppendEntries ( s , req , * nextIdx , lastIndex ) ; err != nil { return true } return true } * nextIdx = last . Index + 1 } return false } 
func ( r * Raft ) pipelineDecode ( s * followerReplication , p AppendPipeline , stopCh , finishCh chan struct { } ) { defer close ( finishCh ) respCh := p . Consumer ( ) for { select { case ready := <- respCh : req , resp := ready . Request ( ) , ready . Response ( ) appendStats ( string ( s . peer . ID ) , ready . Start ( ) , float32 ( len ( req . Entries ) ) ) return } } case <- stopCh : return } } } 
func ( r * Raft ) setupAppendEntries ( s * followerReplication , req * AppendEntriesRequest , nextIndex , lastIndex uint64 ) error { req . RPCHeader = r . getRPCHeader ( ) req . Term = s . currentTerm req . Leader = r . trans . EncodePeer ( r . localID , r . localAddr ) req . LeaderCommitIndex = r . getCommitIndex ( ) if err := r . setPreviousLog ( req , nextIndex ) ; err != nil { return err } if err := r . setNewLogs ( req , nextIndex , lastIndex ) ; err != nil { return err } return nil } 
func ( r * Raft ) setPreviousLog ( req * AppendEntriesRequest , nextIndex uint64 ) error { if nextIndex == 1 { req . PrevLogEntry = 0 req . PrevLogTerm = 0 } else if ( nextIndex - 1 ) == lastSnapIdx { req . PrevLogEntry = lastSnapIdx req . PrevLogTerm = lastSnapTerm } else { var l Log if err := r . logs . GetLog ( nextIndex - 1 , & l ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , nextIndex - 1 , err ) ) return err } req . PrevLogTerm = l . Term } return nil } 
func ( r * Raft ) setNewLogs ( req * AppendEntriesRequest , nextIndex , lastIndex uint64 ) error { maxIndex := min ( nextIndex + uint64 ( r . conf . MaxAppendEntries ) - 1 , lastIndex ) for i := nextIndex ; i <= maxIndex ; i ++ { oldLog := new ( Log ) if err := r . logs . GetLog ( i , oldLog ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , i , err ) ) return err } req . Entries = append ( req . Entries , oldLog ) } return nil } 
func appendStats ( peer string , start time . Time , logs float32 ) { metrics . MeasureSince ( [ ] string { " " , " " , " " , " " , peer } , start ) metrics . IncrCounter ( [ ] string { " " , " " , " " , " " , peer } , logs ) } 
func ( r * Raft ) handleStaleTerm ( s * followerReplication ) { r . logger . Error ( fmt . Sprintf ( " " , s . peer ) ) s . notifyAll ( false ) asyncNotifyCh ( s . stepDown ) } 
func updateLastAppended ( s * followerReplication , req * AppendEntriesRequest ) { s . nextIndex = last . Index + 1 s . commitment . match ( s . peer . ID , last . Index ) } } 
func ( t * transport ) AppendEntries ( id raft . ServerID , target raft . ServerAddress , args * raft . AppendEntriesRequest , resp * raft . AppendEntriesResponse ) error { ae := appendEntries { source : t . node , target : target , firstIndex : firstIndex ( args ) , lastIndex : lastIndex ( args ) , commitIndex : args . LeaderCommitIndex , } if len ( t . ae ) < cap ( t . ae ) { t . ae = append ( t . ae , ae ) } return t . sendRPC ( string ( target ) , args , resp ) } 
func ( t * transport ) RequestVote ( id raft . ServerID , target raft . ServerAddress , args * raft . RequestVoteRequest , resp * raft . RequestVoteResponse ) error { return t . sendRPC ( string ( target ) , args , resp ) } 
func ( t * transport ) InstallSnapshot ( id raft . ServerID , target raft . ServerAddress , args * raft . InstallSnapshotRequest , resp * raft . InstallSnapshotResponse , data io . Reader ) error { t . log . Printf ( " " ) return errors . New ( " " ) } 
func ( t * transport ) EncodePeer ( id raft . ServerID , p raft . ServerAddress ) [ ] byte { return [ ] byte ( p ) } 
func ( t * transport ) DecodePeer ( p [ ] byte ) raft . ServerAddress { return raft . ServerAddress ( p ) } 
func ( t * transport ) AppendEntriesPipeline ( id raft . ServerID , target raft . ServerAddress ) ( raft . AppendPipeline , error ) { p := & pipeline { t : t , id : id , target : target , work : make ( chan * appendEntry , 100 ) , consumer : make ( chan raft . AppendFuture , 100 ) , } go p . run ( ) return p , nil } 
func ( p * pipeline ) AppendEntries ( args * raft . AppendEntriesRequest , resp * raft . AppendEntriesResponse ) ( raft . AppendFuture , error ) { e := & appendEntry { req : args , res : resp , start : time . Now ( ) , ready : make ( chan error ) , consumer : p . consumer , } p . work <- e return e , nil } 
func ReadPeersJSON ( path string ) ( Configuration , error ) { if err != nil { return Configuration { } , err } dec := json . NewDecoder ( bytes . NewReader ( buf ) ) if err := dec . Decode ( & peers ) ; err != nil { return Configuration { } , err } for _ , peer := range peers { server := Server { Suffrage : Voter , ID : ServerID ( peer ) , Address : ServerAddress ( peer ) , } configuration . Servers = append ( configuration . Servers , server ) } } return configuration , nil } 
func ReadConfigJSON ( path string ) ( Configuration , error ) { if err != nil { return Configuration { } , err } dec := json . NewDecoder ( bytes . NewReader ( buf ) ) if err := dec . Decode ( & peers ) ; err != nil { return Configuration { } , err } for _ , peer := range peers { suffrage := Voter if peer . NonVoter { suffrage = Nonvoter } server := Server { Suffrage : suffrage , ID : peer . ID , Address : peer . Address , } configuration . Servers = append ( configuration . Servers , server ) } } return configuration , nil } 
func NewTCPTransport ( bindAddr string , advertise net . Addr , maxPool int , timeout time . Duration , logOutput io . Writer , ) ( * NetworkTransport , error ) { return newTCPTransport ( bindAddr , advertise , func ( stream StreamLayer ) * NetworkTransport { return NewNetworkTransport ( stream , maxPool , timeout , logOutput ) } ) } 
func NewTCPTransportWithLogger ( bindAddr string , advertise net . Addr , maxPool int , timeout time . Duration , logger * log . Logger , ) ( * NetworkTransport , error ) { return newTCPTransport ( bindAddr , advertise , func ( stream StreamLayer ) * NetworkTransport { return NewNetworkTransportWithLogger ( stream , maxPool , timeout , logger ) } ) } 
func NewTCPTransportWithConfig ( bindAddr string , advertise net . Addr , config * NetworkTransportConfig , ) ( * NetworkTransport , error ) { return newTCPTransport ( bindAddr , advertise , func ( stream StreamLayer ) * NetworkTransport { config . Stream = stream return NewNetworkTransportWithConfig ( config ) } ) } 
func ( t * TCPStreamLayer ) Dial ( address ServerAddress , timeout time . Duration ) ( net . Conn , error ) { return net . DialTimeout ( " " , string ( address ) , timeout ) } 
func ( t * TCPStreamLayer ) Accept ( ) ( c net . Conn , err error ) { return t . listener . Accept ( ) } 
func ( t * TCPStreamLayer ) Addr ( ) net . Addr { } return t . listener . Addr ( ) } 
func BootstrapCluster ( conf * Config , logs LogStore , stable StableStore , snaps SnapshotStore , trans Transport , configuration Configuration ) error { } } if err != nil { return fmt . Errorf ( " " , err ) } if hasState { return ErrCantBootstrap } } if conf . ProtocolVersion < 3 { entry . Type = LogRemovePeerDeprecated entry . Data = encodePeers ( configuration , trans ) } else { entry . Type = LogConfiguration entry . Data = encodeConfiguration ( configuration ) } if err := logs . StoreLog ( entry ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func RecoverCluster ( conf * Config , fsm FSM , logs LogStore , stable StableStore , snaps SnapshotStore , trans Transport , configuration Configuration ) error { } } if err != nil { return fmt . Errorf ( " " , err ) } if ! hasState { return fmt . Errorf ( " " ) } var snapshotTerm uint64 snapshots , err := snaps . List ( ) if err != nil { return fmt . Errorf ( " " , err ) } for _ , snapshot := range snapshots { _ , source , err := snaps . Open ( snapshot . ID ) if err != nil { } defer source . Close ( ) if err := fsm . Restore ( source ) ; err != nil { } snapshotIndex = snapshot . Index snapshotTerm = snapshot . Term break } if len ( snapshots ) > 0 && ( snapshotIndex == 0 || snapshotTerm == 0 ) { return fmt . Errorf ( " " ) } lastTerm := snapshotTerm if err != nil { return fmt . Errorf ( " " , err ) } for index := snapshotIndex + 1 ; index <= lastLogIndex ; index ++ { var entry Log if err := logs . GetLog ( index , & entry ) ; err != nil { return fmt . Errorf ( " " , index , err ) } if entry . Type == LogCommand { _ = fsm . Apply ( & entry ) } lastIndex = entry . Index lastTerm = entry . Term } if err != nil { return fmt . Errorf ( " " , err ) } version := getSnapshotVersion ( conf . ProtocolVersion ) sink , err := snaps . Create ( version , lastIndex , lastTerm , configuration , 1 , trans ) if err != nil { return fmt . Errorf ( " " , err ) } if err := snapshot . Persist ( sink ) ; err != nil { return fmt . Errorf ( " " , err ) } if err := sink . Close ( ) ; err != nil { return fmt . Errorf ( " " , err ) } if err != nil { return fmt . Errorf ( " " , err ) } if err := logs . DeleteRange ( firstLogIndex , lastLogIndex ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func HasExistingState ( logs LogStore , stable StableStore , snaps SnapshotStore ) ( bool , error ) { if err == nil { if currentTerm > 0 { return true , nil } } else { if err . Error ( ) != " " { return false , fmt . Errorf ( " " , err ) } } if err != nil { return false , fmt . Errorf ( " " , err ) } if lastIndex > 0 { return true , nil } if err != nil { return false , fmt . Errorf ( " " , err ) } if len ( snapshots ) > 0 { return true , nil } return false , nil } 
func NewRaft ( conf * Config , fsm FSM , logs LogStore , stable StableStore , snaps SnapshotStore , trans Transport ) ( * Raft , error ) { } if conf . Logger != nil { logger = conf . Logger } else { if conf . LogOutput == nil { conf . LogOutput = os . Stderr } logger = hclog . New ( & hclog . LoggerOptions { Name : " " , Level : hclog . LevelFromString ( conf . LogLevel ) , Output : conf . LogOutput , } ) } if err != nil && err . Error ( ) != " " { return nil , fmt . Errorf ( " " , err ) } if err != nil { return nil , fmt . Errorf ( " " , err ) } if lastIndex > 0 { if err = logs . GetLog ( lastIndex , & lastLog ) ; err != nil { return nil , fmt . Errorf ( " " , lastIndex , err ) } } localAddr := ServerAddress ( trans . LocalAddr ( ) ) localID := conf . LocalID } r . setLeader ( r . localAddr ) } r . setLastLog ( lastLog . Index , lastLog . Term ) } for index := snapshotIndex + 1 ; index <= lastLog . Index ; index ++ { var entry Log if err := r . logs . GetLog ( index , & entry ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , index , err ) ) panic ( err ) } r . processConfigurationLogEntry ( & entry ) } r . logger . Info ( fmt . Sprintf ( " " , r . configurations . latestIndex , r . configurations . latest . Servers ) ) r . goFunc ( r . runFSM ) r . goFunc ( r . runSnapshots ) return r , nil } 
func ( r * Raft ) restoreSnapshot ( ) error { snapshots , err := r . snapshots . List ( ) if err != nil { r . logger . Error ( fmt . Sprintf ( " " , err ) ) return err } if err != nil { r . logger . Error ( fmt . Sprintf ( " " , snapshot . ID , err ) ) continue } defer source . Close ( ) if err := r . fsm . Restore ( source ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , snapshot . ID , err ) ) continue } r . configurations . committedIndex = snapshot . ConfigurationIndex r . configurations . latest = snapshot . Configuration r . configurations . latestIndex = snapshot . ConfigurationIndex } else { configuration := decodePeers ( snapshot . Peers , r . trans ) r . configurations . committed = configuration r . configurations . committedIndex = snapshot . Index r . configurations . latest = configuration r . configurations . latestIndex = snapshot . Index } } } return nil } 
func ( r * Raft ) BootstrapCluster ( configuration Configuration ) Future { bootstrapReq := & bootstrapFuture { } bootstrapReq . init ( ) bootstrapReq . configuration = configuration select { case <- r . shutdownCh : return errorFuture { ErrRaftShutdown } case r . bootstrapCh <- bootstrapReq : return bootstrapReq } } 
func ( r * Raft ) Leader ( ) ServerAddress { r . leaderLock . RLock ( ) leader := r . leader r . leaderLock . RUnlock ( ) return leader } 
func ( r * Raft ) Apply ( cmd [ ] byte , timeout time . Duration ) ApplyFuture { metrics . IncrCounter ( [ ] string { " " , " " } , 1 ) var timer <- chan time . Time if timeout > 0 { timer = time . After ( timeout ) } logFuture . init ( ) select { case <- timer : return errorFuture { ErrEnqueueTimeout } case <- r . shutdownCh : return errorFuture { ErrRaftShutdown } case r . applyCh <- logFuture : return logFuture } } 
func ( r * Raft ) Barrier ( timeout time . Duration ) Future { metrics . IncrCounter ( [ ] string { " " , " " } , 1 ) var timer <- chan time . Time if timeout > 0 { timer = time . After ( timeout ) } logFuture . init ( ) select { case <- timer : return errorFuture { ErrEnqueueTimeout } case <- r . shutdownCh : return errorFuture { ErrRaftShutdown } case r . applyCh <- logFuture : return logFuture } } 
func ( r * Raft ) VerifyLeader ( ) Future { metrics . IncrCounter ( [ ] string { " " , " " } , 1 ) verifyFuture := & verifyFuture { } verifyFuture . init ( ) select { case <- r . shutdownCh : return errorFuture { ErrRaftShutdown } case r . verifyCh <- verifyFuture : return verifyFuture } } 
func ( r * Raft ) GetConfiguration ( ) ConfigurationFuture { configReq := & configurationsFuture { } configReq . init ( ) select { case <- r . shutdownCh : configReq . respond ( ErrRaftShutdown ) return configReq case r . configurationsCh <- configReq : return configReq } } 
func ( r * Raft ) AddPeer ( peer ServerAddress ) Future { if r . protocolVersion > 2 { return errorFuture { ErrUnsupportedProtocol } } return r . requestConfigChange ( configurationChangeRequest { command : AddStaging , serverID : ServerID ( peer ) , serverAddress : peer , prevIndex : 0 , } , 0 ) } 
func ( r * Raft ) RemovePeer ( peer ServerAddress ) Future { if r . protocolVersion > 2 { return errorFuture { ErrUnsupportedProtocol } } return r . requestConfigChange ( configurationChangeRequest { command : RemoveServer , serverID : ServerID ( peer ) , prevIndex : 0 , } , 0 ) } 
func ( r * Raft ) AddVoter ( id ServerID , address ServerAddress , prevIndex uint64 , timeout time . Duration ) IndexFuture { if r . protocolVersion < 2 { return errorFuture { ErrUnsupportedProtocol } } return r . requestConfigChange ( configurationChangeRequest { command : AddStaging , serverID : id , serverAddress : address , prevIndex : prevIndex , } , timeout ) } 
func ( r * Raft ) RemoveServer ( id ServerID , prevIndex uint64 , timeout time . Duration ) IndexFuture { if r . protocolVersion < 2 { return errorFuture { ErrUnsupportedProtocol } } return r . requestConfigChange ( configurationChangeRequest { command : RemoveServer , serverID : id , prevIndex : prevIndex , } , timeout ) } 
func ( r * Raft ) Shutdown ( ) Future { r . shutdownLock . Lock ( ) defer r . shutdownLock . Unlock ( ) if ! r . shutdown { close ( r . shutdownCh ) r . shutdown = true r . setState ( Shutdown ) return & shutdownFuture { r } } } 
func ( r * Raft ) Snapshot ( ) SnapshotFuture { future := & userSnapshotFuture { } future . init ( ) select { case r . userSnapshotCh <- future : return future case <- r . shutdownCh : future . respond ( ErrRaftShutdown ) return future } } 
func ( r * Raft ) Restore ( meta * SnapshotMeta , reader io . Reader , timeout time . Duration ) error { metrics . IncrCounter ( [ ] string { " " , " " } , 1 ) var timer <- chan time . Time if timeout > 0 { timer = time . After ( timeout ) } restore . init ( ) select { case <- timer : return ErrEnqueueTimeout case <- r . shutdownCh : return ErrRaftShutdown case r . userRestoreCh <- restore : } } noop . init ( ) select { case <- timer : return ErrEnqueueTimeout case <- r . shutdownCh : return ErrRaftShutdown case r . applyCh <- noop : return noop . Error ( ) } } 
func ( r * Raft ) String ( ) string { return fmt . Sprintf ( " " , r . localAddr , r . getState ( ) ) } 
func ( r * Raft ) LastContact ( ) time . Time { r . lastContactLock . RLock ( ) last := r . lastContact r . lastContactLock . RUnlock ( ) return last } 
func ( r * Raft ) Stats ( ) map [ string ] string { toString := func ( v uint64 ) string { return strconv . FormatUint ( v , 10 ) } lastLogIndex , lastLogTerm := r . getLastLog ( ) lastSnapIndex , lastSnapTerm := r . getLastSnapshot ( ) s := map [ string ] string { " " : r . getState ( ) . String ( ) , " " : toString ( r . getCurrentTerm ( ) ) , " " : toString ( lastLogIndex ) , " " : toString ( lastLogTerm ) , " " : toString ( r . getCommitIndex ( ) ) , " " : toString ( r . getLastApplied ( ) ) , " " : toString ( uint64 ( len ( r . fsmMutateCh ) ) ) , " " : toString ( lastSnapIndex ) , " " : toString ( lastSnapTerm ) , " " : toString ( uint64 ( r . protocolVersion ) ) , " " : toString ( uint64 ( ProtocolVersionMin ) ) , " " : toString ( uint64 ( ProtocolVersionMax ) ) , " " : toString ( uint64 ( SnapshotVersionMin ) ) , " " : toString ( uint64 ( SnapshotVersionMax ) ) , } future := r . GetConfiguration ( ) if err := future . Error ( ) ; err != nil { r . logger . Warn ( fmt . Sprintf ( " " , err ) ) } else { configuration := future . Configuration ( ) s [ " " ] = toString ( future . Index ( ) ) s [ " " ] = fmt . Sprintf ( " " , configuration . Servers ) numPeers := 0 for _ , server := range configuration . Servers { if server . Suffrage == Voter { if server . ID == r . localID { hasUs = true } else { numPeers ++ } } } if ! hasUs { numPeers = 0 } s [ " " ] = toString ( uint64 ( numPeers ) ) } last := r . LastContact ( ) if r . getState ( ) == Leader { s [ " " ] = " " } else if last . IsZero ( ) { s [ " " ] = " " } else { s [ " " ] = fmt . Sprintf ( " " , time . Now ( ) . Sub ( last ) ) } return s } 
func ( a * LoggerAdapter ) Logf ( s string , v ... interface { } ) { a . log . Printf ( s , v ... ) } 
func ( c * cluster ) Leader ( timeout time . Duration ) * raftNode { start := time . Now ( ) for true { for _ , n := range c . nodes { if n . raft . State ( ) == raft . Leader { return n } } if time . Now ( ) . Sub ( start ) > timeout { return nil } time . Sleep ( time . Millisecond ) } return nil } 
func containsNode ( nodes [ ] * raftNode , n * raftNode ) bool { for _ , rn := range nodes { if rn == n { return true } } return false } 
func ( c * cluster ) LeaderPlus ( n int ) [ ] * raftNode { r := make ( [ ] * raftNode , 0 , n + 1 ) ldr := c . Leader ( time . Second ) if ldr != nil { r = append ( r , ldr ) } if len ( r ) >= n { return r } for _ , node := range c . nodes { if ! containsNode ( r , node ) { r = append ( r , node ) if len ( r ) >= n { return r } } } return r } 
func ( c * cluster ) WaitTilUptoDate ( t * testing . T , maxWait time . Duration ) { idx := c . lastApplySuccess . Index ( ) start := time . Now ( ) for true { allAtIdx := true for i := 0 ; i < len ( c . nodes ) ; i ++ { nodeAppliedIdx := c . nodes [ i ] . raft . AppliedIndex ( ) if nodeAppliedIdx < idx { allAtIdx = false break } else if nodeAppliedIdx > idx { allAtIdx = false idx = nodeAppliedIdx break } } if allAtIdx { t . Logf ( " " , idx ) return } if time . Now ( ) . Sub ( start ) > maxWait { t . Fatalf ( " " , idx , c . appliedIndexes ( ) ) } time . Sleep ( time . Millisecond * 10 ) } } 
func assertLogEntryEqual ( t * testing . T , node string , exp * raft . Log , act * raft . Log ) bool { res := true if exp . Term != act . Term { t . Errorf ( " " , exp . Index , node , exp . Term , act . Term ) res = false } if exp . Index != act . Index { t . Errorf ( " " , node , exp . Index , act . Index ) res = false } if exp . Type != act . Type { t . Errorf ( " " , node , exp . Index , exp . Type , act . Type ) res = false } if ! bytes . Equal ( exp . Data , act . Data ) { t . Errorf ( " " , node , exp . Index , exp . Data , act . Data ) res = false } return res } 
func ( r * Raft ) runFSM ( ) { var lastIndex , lastTerm uint64 commit := func ( req * commitTuple ) { if req . log . Type == LogCommand { start := time . Now ( ) resp = r . fsm . Apply ( req . log ) metrics . MeasureSince ( [ ] string { " " , " " , " " } , start ) } lastTerm = req . log . Term req . future . respond ( nil ) } } restore := func ( req * restoreFuture ) { if err != nil { req . respond ( fmt . Errorf ( " " , req . ID , err ) ) return } if err := r . fsm . Restore ( source ) ; err != nil { req . respond ( fmt . Errorf ( " " , req . ID , err ) ) source . Close ( ) return } source . Close ( ) metrics . MeasureSince ( [ ] string { " " , " " , " " } , start ) lastTerm = meta . Term req . respond ( nil ) } snapshot := func ( req * reqSnapshotFuture ) { return } snap , err := r . fsm . Snapshot ( ) metrics . MeasureSince ( [ ] string { " " , " " , " " } , start ) req . term = lastTerm req . snapshot = snap req . respond ( err ) } for { select { case ptr := <- r . fsmMutateCh : switch req := ptr . ( type ) { case * commitTuple : commit ( req ) case * restoreFuture : restore ( req ) default : panic ( fmt . Errorf ( " " , ptr ) ) } case req := <- r . fsmSnapshotCh : snapshot ( req ) case <- r . shutdownCh : return } } } 
func ( c * Configuration ) Clone ( ) ( copy Configuration ) { copy . Servers = append ( copy . Servers , c . Servers ... ) return } 
func ( c * configurations ) Clone ( ) ( copy configurations ) { copy . committed = c . committed . Clone ( ) copy . committedIndex = c . committedIndex copy . latest = c . latest . Clone ( ) copy . latestIndex = c . latestIndex return } 
func hasVote ( configuration Configuration , id ServerID ) bool { for _ , server := range configuration . Servers { if server . ID == id { return server . Suffrage == Voter } } return false } 
func checkConfiguration ( configuration Configuration ) error { idSet := make ( map [ ServerID ] bool ) addressSet := make ( map [ ServerAddress ] bool ) var voters int for _ , server := range configuration . Servers { if server . ID == " " { return fmt . Errorf ( " " , configuration ) } if server . Address == " " { return fmt . Errorf ( " " , server ) } if idSet [ server . ID ] { return fmt . Errorf ( " " , server . ID ) } idSet [ server . ID ] = true if addressSet [ server . Address ] { return fmt . Errorf ( " " , server . Address ) } addressSet [ server . Address ] = true if server . Suffrage == Voter { voters ++ } } if voters == 0 { return fmt . Errorf ( " " , configuration ) } return nil } 
func nextConfiguration ( current Configuration , currentIndex uint64 , change configurationChangeRequest ) ( Configuration , error ) { if change . prevIndex > 0 && change . prevIndex != currentIndex { return Configuration { } , fmt . Errorf ( " " , change . prevIndex , currentIndex ) } configuration := current . Clone ( ) switch change . command { case AddStaging : found := false for i , server := range configuration . Servers { if server . ID == change . serverID { if server . Suffrage == Voter { configuration . Servers [ i ] . Address = change . serverAddress } else { configuration . Servers [ i ] = newServer } found = true break } } if ! found { configuration . Servers = append ( configuration . Servers , newServer ) } case AddNonvoter : newServer := Server { Suffrage : Nonvoter , ID : change . serverID , Address : change . serverAddress , } found := false for i , server := range configuration . Servers { if server . ID == change . serverID { if server . Suffrage != Nonvoter { configuration . Servers [ i ] . Address = change . serverAddress } else { configuration . Servers [ i ] = newServer } found = true break } } if ! found { configuration . Servers = append ( configuration . Servers , newServer ) } case DemoteVoter : for i , server := range configuration . Servers { if server . ID == change . serverID { configuration . Servers [ i ] . Suffrage = Nonvoter break } } case RemoveServer : for i , server := range configuration . Servers { if server . ID == change . serverID { configuration . Servers = append ( configuration . Servers [ : i ] , configuration . Servers [ i + 1 : ] ... ) break } } case Promote : for i , server := range configuration . Servers { if server . ID == change . serverID && server . Suffrage == Staging { configuration . Servers [ i ] . Suffrage = Voter break } } } } return configuration , nil } 
func encodePeers ( configuration Configuration , trans Transport ) [ ] byte { for _ , server := range configuration . Servers { if server . Suffrage == Voter { encPeers = append ( encPeers , trans . EncodePeer ( server . ID , server . Address ) ) } } if err != nil { panic ( fmt . Errorf ( " " , err ) ) } return buf . Bytes ( ) } 
func decodePeers ( buf [ ] byte , trans Transport ) Configuration { if err := decodeMsgPack ( buf , & encPeers ) ; err != nil { panic ( fmt . Errorf ( " " , err ) ) } for _ , enc := range encPeers { p := trans . DecodePeer ( enc ) servers = append ( servers , Server { Suffrage : Voter , ID : ServerID ( p ) , Address : ServerAddress ( p ) , } ) } return Configuration { Servers : servers , } } 
func encodeConfiguration ( configuration Configuration ) [ ] byte { buf , err := encodeMsgPack ( configuration ) if err != nil { panic ( fmt . Errorf ( " " , err ) ) } return buf . Bytes ( ) } 
func decodeConfiguration ( buf [ ] byte ) Configuration { var configuration Configuration if err := decodeMsgPack ( buf , & configuration ) ; err != nil { panic ( fmt . Errorf ( " " , err ) ) } return configuration } 
func ( r * raftState ) goFunc ( f func ( ) ) { r . routinesGroup . Add ( 1 ) go func ( ) { defer r . routinesGroup . Done ( ) f ( ) } ( ) } 
func ( r * raftState ) getLastIndex ( ) uint64 { r . lastLock . Lock ( ) defer r . lastLock . Unlock ( ) return max ( r . lastLogIndex , r . lastSnapshotIndex ) } 
func ( r * raftState ) getLastEntry ( ) ( uint64 , uint64 ) { r . lastLock . Lock ( ) defer r . lastLock . Unlock ( ) if r . lastLogIndex >= r . lastSnapshotIndex { return r . lastLogIndex , r . lastLogTerm } return r . lastSnapshotIndex , r . lastSnapshotTerm } 
func resolveDirectory ( dir string , create bool ) ( string , error ) { var resolved string if filepath . IsAbs ( dir ) { resolved = dir } else { execdir , err := filepath . Abs ( filepath . Dir ( os . Args [ 0 ] ) ) if err != nil { return " " , err } resolved = filepath . Join ( execdir , dir ) } if create { if _ , err := os . Stat ( resolved ) ; os . IsNotExist ( err ) { if err := os . MkdirAll ( resolved , 0744 ) ; err != nil { return " " , err } } } return resolved , nil } 
func ( r * Raft ) checkRPCHeader ( rpc RPC ) error { if ! ok { return fmt . Errorf ( " " ) } header := wh . GetRPCHeader ( ) } } return nil } 
func ( r * Raft ) setLeader ( leader ServerAddress ) { r . leaderLock . Lock ( ) oldLeader := r . leader r . leader = leader r . leaderLock . Unlock ( ) if oldLeader != leader { r . observe ( LeaderObservation { leader : leader } ) } } 
func ( r * Raft ) requestConfigChange ( req configurationChangeRequest , timeout time . Duration ) IndexFuture { var timer <- chan time . Time if timeout > 0 { timer = time . After ( timeout ) } future := & configurationChangeFuture { req : req , } future . init ( ) select { case <- timer : return errorFuture { ErrEnqueueTimeout } case r . configurationChangeCh <- future : return future case <- r . shutdownCh : return errorFuture { ErrRaftShutdown } } } 
func ( r * Raft ) run ( ) { for { return default : } case Candidate : r . runCandidate ( ) case Leader : r . runLeader ( ) } } } 
func ( r * Raft ) runFollower ( ) { didWarn := false r . logger . Info ( fmt . Sprintf ( " " , r , r . Leader ( ) ) ) metrics . IncrCounter ( [ ] string { " " , " " , " " } , 1 ) heartbeatTimer := randomTimeout ( r . conf . HeartbeatTimeout ) for { select { case rpc := <- r . rpcCh : r . processRPC ( rpc ) case c := <- r . configurationChangeCh : case a := <- r . applyCh : case v := <- r . verifyCh : case r := <- r . userRestoreCh : case c := <- r . configurationsCh : c . configurations = r . configurations . Clone ( ) c . respond ( nil ) case b := <- r . bootstrapCh : b . respond ( r . liveBootstrap ( b . configuration ) ) case <- heartbeatTimer : if time . Now ( ) . Sub ( lastContact ) < r . conf . HeartbeatTimeout { continue } r . setLeader ( " " ) if r . configurations . latestIndex == 0 { if ! didWarn { r . logger . Warn ( " " ) didWarn = true } } else if r . configurations . latestIndex == r . configurations . committedIndex && ! hasVote ( r . configurations . latest , r . localID ) { if ! didWarn { r . logger . Warn ( " " ) didWarn = true } } else { r . logger . Warn ( fmt . Sprintf ( " " , lastLeader ) ) metrics . IncrCounter ( [ ] string { " " , " " , " " } , 1 ) r . setState ( Candidate ) return } case <- r . shutdownCh : return } } } 
func ( r * Raft ) liveBootstrap ( configuration Configuration ) error { if err != nil { return err } if err := r . logs . GetLog ( 1 , & entry ) ; err != nil { panic ( err ) } r . setCurrentTerm ( 1 ) r . setLastLog ( entry . Index , entry . Term ) r . processConfigurationLogEntry ( & entry ) return nil } 
func ( r * Raft ) runCandidate ( ) { r . logger . Info ( fmt . Sprintf ( " " , r , r . getCurrentTerm ( ) + 1 ) ) metrics . IncrCounter ( [ ] string { " " , " " , " " } , 1 ) electionTimer := randomTimeout ( r . conf . ElectionTimeout ) votesNeeded := r . quorumSize ( ) r . logger . Debug ( fmt . Sprintf ( " " , votesNeeded ) ) for r . getState ( ) == Candidate { select { case rpc := <- r . rpcCh : r . processRPC ( rpc ) case vote := <- voteCh : r . setState ( Follower ) r . setCurrentTerm ( vote . Term ) return } r . logger . Debug ( fmt . Sprintf ( " " , vote . voterID , vote . Term , grantedVotes ) ) } r . setState ( Leader ) r . setLeader ( r . localAddr ) return } case c := <- r . configurationChangeCh : case a := <- r . applyCh : case v := <- r . verifyCh : case r := <- r . userRestoreCh : case c := <- r . configurationsCh : c . configurations = r . configurations . Clone ( ) c . respond ( nil ) case b := <- r . bootstrapCh : b . respond ( ErrCantBootstrap ) case <- electionTimer : return case <- r . shutdownCh : return } } } 
func ( r * Raft ) runLeader ( ) { r . logger . Info ( fmt . Sprintf ( " " , r ) ) metrics . IncrCounter ( [ ] string { " " , " " , " " } , 1 ) } r . leaderState . commitment = newCommitment ( r . leaderState . commitCh , r . configurations . latest , r . getLastIndex ( ) + 1 ) r . leaderState . inflight = list . New ( ) r . leaderState . replState = make ( map [ ServerID ] * followerReplication ) r . leaderState . notify = make ( map [ * verifyFuture ] struct { } ) r . leaderState . stepDown = make ( chan struct { } , 1 ) } } } r . leaderState . commitment = nil r . leaderState . inflight = nil r . leaderState . replState = nil r . leaderState . notify = nil r . leaderState . stepDown = nil if r . leader == r . localAddr { r . leader = " " } r . leaderLock . Unlock ( ) } } } ( ) r . dispatchLogs ( [ ] * logFuture { noop } ) } 
func ( r * Raft ) startStopReplication ( ) { inConfig := make ( map [ ServerID ] bool , len ( r . configurations . latest . Servers ) ) lastIdx := r . getLastIndex ( ) } inConfig [ server . ID ] = true if _ , ok := r . leaderState . replState [ server . ID ] ; ! ok { r . logger . Info ( fmt . Sprintf ( " " , server . ID ) ) s := & followerReplication { peer : server , commitment : r . leaderState . commitment , stopCh : make ( chan uint64 , 1 ) , triggerCh : make ( chan struct { } , 1 ) , currentTerm : r . getCurrentTerm ( ) , nextIndex : lastIdx + 1 , lastContact : time . Now ( ) , notify : make ( map [ * verifyFuture ] struct { } ) , notifyCh : make ( chan struct { } , 1 ) , stepDown : r . leaderState . stepDown , } r . leaderState . replState [ server . ID ] = s r . goFunc ( func ( ) { r . replicate ( s ) } ) asyncNotifyCh ( s . triggerCh ) } } } repl . stopCh <- lastIdx close ( repl . stopCh ) delete ( r . leaderState . replState , serverID ) } } 
func ( r * Raft ) configurationChangeChIfStable ( ) chan * configurationChangeFuture { } return nil } 
func ( r * Raft ) leaderLoop ( ) { lease := time . After ( r . conf . LeaderLeaseTimeout ) for r . getState ( ) == Leader { select { case rpc := <- r . rpcCh : r . processRPC ( rpc ) case <- r . leaderState . stepDown : r . setState ( Follower ) case <- r . leaderState . commitCh : commitIndex := r . leaderState . commitment . getCommitIndex ( ) r . setCommitIndex ( commitIndex ) if r . configurations . latestIndex > oldCommitIndex && r . configurations . latestIndex <= commitIndex { r . configurations . committed = r . configurations . latest r . configurations . committedIndex = r . configurations . latestIndex if ! hasVote ( r . configurations . committed , r . localID ) { stepDown = true } } var numProcessed int start := time . Now ( ) for { e := r . leaderState . inflight . Front ( ) if e == nil { break } commitLog := e . Value . ( * logFuture ) idx := commitLog . log . Index if idx > commitIndex { break } r . processLogs ( idx , commitLog ) r . leaderState . inflight . Remove ( e ) numProcessed ++ } if stepDown { if r . conf . ShutdownOnRemove { r . logger . Info ( " " ) r . Shutdown ( ) } else { r . logger . Info ( " " ) r . setState ( Follower ) } } case v := <- r . verifyCh : if v . quorumSize == 0 { } else if v . votes < v . quorumSize { r . setState ( Follower ) delete ( r . leaderState . notify , v ) for _ , repl := range r . leaderState . replState { repl . cleanNotify ( v ) } v . respond ( ErrNotLeader ) } else { for _ , repl := range r . leaderState . replState { repl . cleanNotify ( v ) } v . respond ( nil ) } case future := <- r . userRestoreCh : err := r . restoreUserSnapshot ( future . meta , future . reader ) future . respond ( err ) case c := <- r . configurationsCh : c . configurations = r . configurations . Clone ( ) c . respond ( nil ) case future := <- r . configurationChangeChIfStable ( ) : r . appendConfigurationEntry ( future ) case b := <- r . bootstrapCh : b . respond ( ErrCantBootstrap ) case newLog := <- r . applyCh : for i := 0 ; i < r . conf . MaxAppendEntries ; i ++ { select { case newLog := <- r . applyCh : ready = append ( ready , newLog ) default : break } } } } else { r . dispatchLogs ( ready ) } case <- lease : if checkInterval < minCheckInterval { checkInterval = minCheckInterval } case <- r . shutdownCh : return } } } 
func ( r * Raft ) verifyLeader ( v * verifyFuture ) { if v . quorumSize == 1 { v . respond ( nil ) return } r . leaderState . notify [ v ] = struct { } { } repl . notify [ v ] = struct { } { } repl . notifyLock . Unlock ( ) asyncNotifyCh ( repl . notifyCh ) } } 
func ( r * Raft ) checkLeaderLease ( ) time . Duration { now := time . Now ( ) for peer , f := range r . leaderState . replState { diff := now . Sub ( f . LastContact ( ) ) if diff <= r . conf . LeaderLeaseTimeout { contacted ++ if diff > maxDiff { maxDiff = diff } } else { } else { r . logger . Debug ( fmt . Sprintf ( " " , peer , diff ) ) } } metrics . AddSample ( [ ] string { " " , " " , " " } , float32 ( diff / time . Millisecond ) ) } if contacted < quorum { r . logger . Warn ( " " ) r . setState ( Follower ) metrics . IncrCounter ( [ ] string { " " , " " , " " } , 1 ) } return maxDiff } 
func ( r * Raft ) quorumSize ( ) int { voters := 0 for _ , server := range r . configurations . latest . Servers { if server . Suffrage == Voter { voters ++ } } return voters / 2 + 1 } 
func ( r * Raft ) restoreUserSnapshot ( meta * SnapshotMeta , reader io . Reader ) error { defer metrics . MeasureSince ( [ ] string { " " , " " } , time . Now ( ) ) if version < SnapshotVersionMin || version > SnapshotVersionMax { return fmt . Errorf ( " " , version ) } latestIndex := r . configurations . latestIndex if committedIndex != latestIndex { return fmt . Errorf ( " " , latestIndex , committedIndex ) } if e == nil { break } e . Value . ( * logFuture ) . respond ( ErrAbortedByRestore ) r . leaderState . inflight . Remove ( e ) } lastIndex := r . getLastIndex ( ) if meta . Index > lastIndex { lastIndex = meta . Index } lastIndex ++ if err != nil { return fmt . Errorf ( " " , err ) } n , err := io . Copy ( sink , reader ) if err != nil { sink . Cancel ( ) return fmt . Errorf ( " " , err ) } if n != meta . Size { sink . Cancel ( ) return fmt . Errorf ( " " , n , meta . Size ) } if err := sink . Close ( ) ; err != nil { return fmt . Errorf ( " " , err ) } r . logger . Info ( fmt . Sprintf ( " " , n ) ) fsm . init ( ) select { case r . fsmMutateCh <- fsm : case <- r . shutdownCh : return ErrRaftShutdown } if err := fsm . Error ( ) ; err != nil { panic ( fmt . Errorf ( " " , err ) ) } r . setLastApplied ( lastIndex ) r . setLastSnapshot ( lastIndex , term ) r . logger . Info ( fmt . Sprintf ( " " , lastIndex ) ) return nil } 
func ( r * Raft ) appendConfigurationEntry ( future * configurationChangeFuture ) { configuration , err := nextConfiguration ( r . configurations . latest , r . configurations . latestIndex , future . req ) if err != nil { future . respond ( err ) return } r . logger . Info ( fmt . Sprintf ( " " , future . req . command , future . req . serverID , future . req . serverAddress , configuration . Servers ) ) } else { future . log = Log { Type : LogConfiguration , Data : encodeConfiguration ( configuration ) , } } r . dispatchLogs ( [ ] * logFuture { & future . logFuture } ) index := future . Index ( ) r . configurations . latest = configuration r . configurations . latestIndex = index r . leaderState . commitment . setConfiguration ( configuration ) r . startStopReplication ( ) } 
func ( r * Raft ) dispatchLogs ( applyLogs [ ] * logFuture ) { now := time . Now ( ) defer metrics . MeasureSince ( [ ] string { " " , " " , " " } , now ) term := r . getCurrentTerm ( ) lastIndex := r . getLastIndex ( ) n := len ( applyLogs ) logs := make ( [ ] * Log , n ) metrics . SetGauge ( [ ] string { " " , " " , " " } , float32 ( n ) ) for idx , applyLog := range applyLogs { applyLog . dispatch = now lastIndex ++ applyLog . log . Index = lastIndex applyLog . log . Term = term logs [ idx ] = & applyLog . log r . leaderState . inflight . PushBack ( applyLog ) } for _ , applyLog := range applyLogs { applyLog . respond ( err ) } r . setState ( Follower ) return } r . leaderState . commitment . match ( r . localID , lastIndex ) } } 
func ( r * Raft ) processLogs ( index uint64 , future * logFuture ) { if index <= lastApplied { r . logger . Warn ( fmt . Sprintf ( " " , index ) ) return } } else { l := new ( Log ) if err := r . logs . GetLog ( idx , l ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , idx , err ) ) panic ( err ) } r . processLog ( l , nil ) } } } 
func ( r * Raft ) processLog ( l * Log , future * logFuture ) { switch l . Type { case LogBarrier : case LogCommand : } } case LogConfiguration : case LogAddPeerDeprecated : case LogRemovePeerDeprecated : case LogNoop : } } } 
func ( r * Raft ) processRPC ( rpc RPC ) { if err := r . checkRPCHeader ( rpc ) ; err != nil { rpc . Respond ( nil , err ) return } switch cmd := rpc . Command . ( type ) { case * AppendEntriesRequest : r . appendEntries ( rpc , cmd ) case * RequestVoteRequest : r . requestVote ( rpc , cmd ) case * InstallSnapshotRequest : r . installSnapshot ( rpc , cmd ) default : r . logger . Error ( fmt . Sprintf ( " " , rpc . Command ) ) rpc . Respond ( nil , fmt . Errorf ( " " ) ) } } 
func ( r * Raft ) processHeartbeat ( rpc RPC ) { defer metrics . MeasureSince ( [ ] string { " " , " " , " " } , time . Now ( ) ) default : } default : r . logger . Error ( fmt . Sprintf ( " " , rpc . Command ) ) rpc . Respond ( nil , fmt . Errorf ( " " ) ) } } 
func ( r * Raft ) appendEntries ( rpc RPC , a * AppendEntriesRequest ) { defer metrics . MeasureSince ( [ ] string { " " , " " , " " } , time . Now ( ) ) var rpcErr error defer func ( ) { rpc . Respond ( resp , rpcErr ) } ( ) } r . setCurrentTerm ( a . Term ) resp . Term = a . Term } var prevLogTerm uint64 if a . PrevLogEntry == lastIdx { prevLogTerm = lastTerm } else { var prevLog Log if err := r . logs . GetLog ( a . PrevLogEntry , & prevLog ) ; err != nil { r . logger . Warn ( fmt . Sprintf ( " " , a . PrevLogEntry , err , lastIdx ) ) resp . NoRetryBackoff = true return } prevLogTerm = prevLog . Term } if a . PrevLogTerm != prevLogTerm { r . logger . Warn ( fmt . Sprintf ( " " , prevLogTerm , a . PrevLogTerm ) ) resp . NoRetryBackoff = true return } } var newEntries [ ] * Log for i , entry := range a . Entries { if entry . Index > lastLogIdx { newEntries = a . Entries [ i : ] break } var storeEntry Log if err := r . logs . GetLog ( entry . Index , & storeEntry ) ; err != nil { r . logger . Warn ( fmt . Sprintf ( " " , entry . Index , err ) ) return } if entry . Term != storeEntry . Term { r . logger . Warn ( fmt . Sprintf ( " " , entry . Index , lastLogIdx ) ) if err := r . logs . DeleteRange ( entry . Index , lastLogIdx ) ; err != nil { r . logger . Error ( fmt . Sprintf ( " " , err ) ) return } if entry . Index <= r . configurations . latestIndex { r . configurations . latest = r . configurations . committed r . configurations . latestIndex = r . configurations . committedIndex } newEntries = a . Entries [ i : ] break } } if n := len ( newEntries ) ; n > 0 { } } r . setLastLog ( last . Index , last . Term ) } metrics . MeasureSince ( [ ] string { " " , " " , " " , " " } , start ) } idx := min ( a . LeaderCommitIndex , r . getLastIndex ( ) ) r . setCommitIndex ( idx ) if r . configurations . latestIndex <= idx { r . configurations . committed = r . configurations . latest r . configurations . committedIndex = r . configurations . latestIndex } r . processLogs ( idx , nil ) metrics . MeasureSince ( [ ] string { " " , " " , " " , " " } , start ) } r . setLastContact ( ) return } 
func ( r * Raft ) processConfigurationLogEntry ( entry * Log ) { if entry . Type == LogConfiguration { r . configurations . committed = r . configurations . latest r . configurations . committedIndex = r . configurations . latestIndex r . configurations . latest = decodeConfiguration ( entry . Data ) r . configurations . latestIndex = entry . Index } else if entry . Type == LogAddPeerDeprecated || entry . Type == LogRemovePeerDeprecated { r . configurations . committed = r . configurations . latest r . configurations . committedIndex = r . configurations . latestIndex r . configurations . latest = decodePeers ( entry . Data , r . trans ) r . configurations . latestIndex = entry . Index } } 
func ( r * Raft ) requestVote ( rpc RPC , req * RequestVoteRequest ) { defer metrics . MeasureSince ( [ ] string { " " , " " , " " } , time . Now ( ) ) r . observe ( * req ) var rpcErr error defer func ( ) { rpc . Respond ( resp , rpcErr ) } ( ) } if leader := r . Leader ( ) ; leader != " " && leader != candidate { r . logger . Warn ( fmt . Sprintf ( " " , candidate , leader ) ) return } } r . setCurrentTerm ( req . Term ) resp . Term = req . Term } if err != nil && err . Error ( ) != " " { r . logger . Error ( fmt . Sprintf ( " " , err ) ) return } lastVoteCandBytes , err := r . stable . Get ( keyLastVoteCand ) if err != nil && err . Error ( ) != " " { r . logger . Error ( fmt . Sprintf ( " " , err ) ) return } if bytes . Compare ( lastVoteCandBytes , req . Candidate ) == 0 { r . logger . Warn ( fmt . Sprintf ( " " , req . Candidate ) ) resp . Granted = true } return } if lastTerm > req . LastLogTerm { r . logger . Warn ( fmt . Sprintf ( " " , candidate , lastTerm , req . LastLogTerm ) ) return } if lastTerm == req . LastLogTerm && lastIdx > req . LastLogIndex { r . logger . Warn ( fmt . Sprintf ( " " , candidate , lastIdx , req . LastLogIndex ) ) return } return } resp . Granted = true r . setLastContact ( ) return } 
func ( r * Raft ) installSnapshot ( rpc RPC , req * InstallSnapshotRequest ) { defer metrics . MeasureSince ( [ ] string { " " , " " , " " } , time . Now ( ) ) var rpcErr error defer func ( ) { io . Copy ( ioutil . Discard , rpc . Reader ) rpc . Respond ( resp , rpcErr ) } ( ) return } return } r . setCurrentTerm ( req . Term ) resp . Term = req . Term } var reqConfigurationIndex uint64 if req . SnapshotVersion > 0 { reqConfiguration = decodeConfiguration ( req . Configuration ) reqConfigurationIndex = req . ConfigurationIndex } else { reqConfiguration = decodePeers ( req . Peers , r . trans ) reqConfigurationIndex = req . LastLogIndex } version := getSnapshotVersion ( r . protocolVersion ) sink , err := r . snapshots . Create ( version , req . LastLogIndex , req . LastLogTerm , reqConfiguration , reqConfigurationIndex , r . trans ) if err != nil { r . logger . Error ( fmt . Sprintf ( " " , err ) ) rpcErr = fmt . Errorf ( " " , err ) return } if err != nil { sink . Cancel ( ) r . logger . Error ( fmt . Sprintf ( " " , err ) ) rpcErr = err return } r . logger . Error ( fmt . Sprintf ( " " , n , req . Size ) ) rpcErr = fmt . Errorf ( " " ) return } rpcErr = err return } r . logger . Info ( fmt . Sprintf ( " " , n ) ) future . init ( ) select { case r . fsmMutateCh <- future : case <- r . shutdownCh : future . respond ( ErrRaftShutdown ) return } rpcErr = err return } r . configurations . latestIndex = reqConfigurationIndex r . configurations . committed = reqConfiguration r . configurations . committedIndex = reqConfigurationIndex } r . logger . Info ( " " ) resp . Success = true r . setLastContact ( ) return } 
func ( r * Raft ) setLastContact ( ) { r . lastContactLock . Lock ( ) r . lastContact = time . Now ( ) r . lastContactLock . Unlock ( ) } 
func ( r * Raft ) electSelf ( ) <- chan * voteResult { req := & RequestVoteRequest { RPCHeader : r . getRPCHeader ( ) , Term : r . getCurrentTerm ( ) , Candidate : r . trans . EncodePeer ( r . localID , r . localAddr ) , LastLogIndex : lastIdx , LastLogTerm : lastTerm , } resp := & voteResult { voterID : peer . ID } err := r . trans . RequestVote ( peer . ID , peer . Address , req , & resp . RequestVoteResponse ) if err != nil { r . logger . Error ( fmt . Sprintf ( " " , peer , err ) ) resp . Term = req . Term resp . Granted = false } respCh <- resp } ) } return nil } } else { askPeer ( server ) } } } return respCh } 
func ( r * Raft ) persistVote ( term uint64 , candidate [ ] byte ) error { if err := r . stable . SetUint64 ( keyLastVoteTerm , term ) ; err != nil { return err } if err := r . stable . Set ( keyLastVoteCand , candidate ) ; err != nil { return err } return nil } 
func ( r * Raft ) setCurrentTerm ( t uint64 ) { } r . raftState . setCurrentTerm ( t ) } 
func ( r * Raft ) setState ( state RaftState ) { r . setLeader ( " " ) oldState := r . raftState . getState ( ) r . raftState . setState ( state ) if oldState != state { r . observe ( state ) } } 
func newCommitment ( commitCh chan struct { } , configuration Configuration , startIndex uint64 ) * commitment { matchIndexes := make ( map [ ServerID ] uint64 ) for _ , server := range configuration . Servers { if server . Suffrage == Voter { matchIndexes [ server . ID ] = 0 } } return & commitment { commitCh : commitCh , matchIndexes : matchIndexes , commitIndex : 0 , startIndex : startIndex , } } 
func ( c * commitment ) setConfiguration ( configuration Configuration ) { c . Lock ( ) defer c . Unlock ( ) oldMatchIndexes := c . matchIndexes c . matchIndexes = make ( map [ ServerID ] uint64 ) for _ , server := range configuration . Servers { if server . Suffrage == Voter { c . matchIndexes [ server . ID ] = oldMatchIndexes [ server . ID ] } } c . recalculate ( ) } 
func ( c * commitment ) getCommitIndex ( ) uint64 { c . Lock ( ) defer c . Unlock ( ) return c . commitIndex } 
func ( c * commitment ) match ( server ServerID , matchIndex uint64 ) { c . Lock ( ) defer c . Unlock ( ) if prev , hasVote := c . matchIndexes [ server ] ; hasVote && matchIndex > prev { c . matchIndexes [ server ] = matchIndex c . recalculate ( ) } } 
func ( c * commitment ) recalculate ( ) { if len ( c . matchIndexes ) == 0 { return } matched := make ( [ ] uint64 , 0 , len ( c . matchIndexes ) ) for _ , idx := range c . matchIndexes { matched = append ( matched , idx ) } sort . Sort ( uint64Slice ( matched ) ) quorumMatchIndex := matched [ ( len ( matched ) - 1 ) / 2 ] if quorumMatchIndex > c . commitIndex && quorumMatchIndex >= c . startIndex { c . commitIndex = quorumMatchIndex asyncNotifyCh ( c . commitCh ) } } 
func newSeed ( ) int64 { r , err := crand . Int ( crand . Reader , big . NewInt ( math . MaxInt64 ) ) if err != nil { panic ( fmt . Errorf ( " " , err ) ) } return r . Int64 ( ) } 
func randomTimeout ( minVal time . Duration ) <- chan time . Time { if minVal == 0 { return nil } extra := ( time . Duration ( rand . Int63 ( ) ) % minVal ) return time . After ( minVal + extra ) } 
func generateUUID ( ) string { buf := make ( [ ] byte , 16 ) if _ , err := crand . Read ( buf ) ; err != nil { panic ( fmt . Errorf ( " " , err ) ) } return fmt . Sprintf ( " " , buf [ 0 : 4 ] , buf [ 4 : 6 ] , buf [ 6 : 8 ] , buf [ 8 : 10 ] , buf [ 10 : 16 ] ) } 
func decodeMsgPack ( buf [ ] byte , out interface { } ) error { r := bytes . NewBuffer ( buf ) hd := codec . MsgpackHandle { } dec := codec . NewDecoder ( r , & hd ) return dec . Decode ( out ) } 
func encodeMsgPack ( in interface { } ) ( * bytes . Buffer , error ) { buf := bytes . NewBuffer ( nil ) hd := codec . MsgpackHandle { } enc := codec . NewEncoder ( buf , & hd ) err := enc . Encode ( in ) return buf , err } 
func backoff ( base time . Duration , round , limit uint64 ) time . Duration { power := min ( round , limit ) for power > 2 { base *= 2 power -- } return base } 
func newApplySource ( seed string ) * applySource { h := fnv . New32 ( ) h . Write ( [ ] byte ( seed ) ) s := & applySource { seed : int64 ( h . Sum32 ( ) ) } s . reset ( ) return s } 
func ( a * applySource ) reset ( ) { a . rnd = rand . New ( rand . NewSource ( a . seed ) ) } 
func ( a * applySource ) apply ( t * testing . T , c * cluster , n uint ) * clusterApplier { ap := & clusterApplier { stopCh : make ( chan bool ) , src : a } go ap . apply ( t , c , n ) return ap } 
func DefaultConfig ( ) * Config { return & Config { ProtocolVersion : ProtocolVersionMax , HeartbeatTimeout : 1000 * time . Millisecond , ElectionTimeout : 1000 * time . Millisecond , CommitTimeout : 50 * time . Millisecond , MaxAppendEntries : 64 , ShutdownOnRemove : true , TrailingLogs : 10240 , SnapshotInterval : 120 * time . Second , SnapshotThreshold : 8192 , LeaderLeaseTimeout : 500 * time . Millisecond , LogLevel : " " , } } 
func ValidateConfig ( config * Config ) error { if protocolMin == 0 { protocolMin = 1 } if config . ProtocolVersion < protocolMin || config . ProtocolVersion > ProtocolVersionMax { return fmt . Errorf ( " " , config . ProtocolVersion , protocolMin , ProtocolVersionMax ) } if len ( config . LocalID ) == 0 { return fmt . Errorf ( " " ) } if config . HeartbeatTimeout < 5 * time . Millisecond { return fmt . Errorf ( " " ) } if config . ElectionTimeout < 5 * time . Millisecond { return fmt . Errorf ( " " ) } if config . CommitTimeout < time . Millisecond { return fmt . Errorf ( " " ) } if config . MaxAppendEntries <= 0 { return fmt . Errorf ( " " ) } if config . MaxAppendEntries > 1024 { return fmt . Errorf ( " " ) } if config . SnapshotInterval < 5 * time . Millisecond { return fmt . Errorf ( " " ) } if config . LeaderLeaseTimeout < 5 * time . Millisecond { return fmt . Errorf ( " " ) } if config . LeaderLeaseTimeout > config . HeartbeatTimeout { return fmt . Errorf ( " " ) } if config . ElectionTimeout < config . HeartbeatTimeout { return fmt . Errorf ( " " ) } return nil } 
func ( r * Raft ) runSnapshots ( ) { for { select { case <- randomTimeout ( r . conf . SnapshotInterval ) : } } case future := <- r . userSnapshotCh : if err != nil { r . logger . Error ( fmt . Sprintf ( " " , err ) ) } else { future . opener = func ( ) ( * SnapshotMeta , io . ReadCloser , error ) { return r . snapshots . Open ( id ) } } future . respond ( err ) case <- r . shutdownCh : return } } } 
func ( r * Raft ) shouldSnapshot ( ) bool { if err != nil { r . logger . Error ( fmt . Sprintf ( " " , err ) ) return false } return delta >= r . conf . SnapshotThreshold } 
func ( r * Raft ) takeSnapshot ( ) ( string , error ) { defer metrics . MeasureSince ( [ ] string { " " , " " , " " } , time . Now ( ) ) snapReq . init ( ) } } return " " , err } defer snapReq . snapshot . Release ( ) configReq . init ( ) select { case r . configurationsCh <- configReq : case <- r . shutdownCh : return " " , ErrRaftShutdown } if err := configReq . Error ( ) ; err != nil { return " " , err } committed := configReq . configurations . committed committedIndex := configReq . configurations . committedIndex } start := time . Now ( ) version := getSnapshotVersion ( r . protocolVersion ) sink , err := r . snapshots . Create ( version , snapReq . index , snapReq . term , committed , committedIndex , r . trans ) if err != nil { return " " , fmt . Errorf ( " " , err ) } metrics . MeasureSince ( [ ] string { " " , " " , " " } , start ) if err := snapReq . snapshot . Persist ( sink ) ; err != nil { sink . Cancel ( ) return " " , fmt . Errorf ( " " , err ) } metrics . MeasureSince ( [ ] string { " " , " " , " " } , start ) } } r . logger . Info ( fmt . Sprintf ( " " , snapReq . index ) ) return sink . ID ( ) , nil } 
func ( r * Raft ) compactLogs ( snapIdx uint64 ) error { defer metrics . MeasureSince ( [ ] string { " " , " " } , time . Now ( ) ) if err != nil { return fmt . Errorf ( " " , err ) } if lastLogIdx <= r . conf . TrailingLogs { return nil } } return nil } 
func WebpackCheck ( r * Runner ) error { fmt . Println ( " " ) if ! r . App . WithWebpack { return nil } box := webpack . Templates f , err := box . FindString ( " " ) if err != nil { return err } tmpl , err := template . New ( " " ) . Parse ( f ) if err != nil { return err } bb := & bytes . Buffer { } err = tmpl . Execute ( bb , map [ string ] interface { } { " " : & webpack . Options { App : r . App , } , } ) if err != nil { return err } b , err := ioutil . ReadFile ( " " ) if err != nil { return err } if string ( b ) == bb . String ( ) { return nil } if ! ask ( " \n " ) { fmt . Println ( " \t " ) return nil } wf , err := os . Create ( " " ) if err != nil { return err } _ , err = wf . Write ( bb . Bytes ( ) ) if err != nil { return err } return wf . Close ( ) } 
func Auto ( ctx context . Context , i interface { } ) Renderer { e := New ( Options { } ) return e . Auto ( ctx , i ) } 
func ( e * Engine ) Auto ( ctx context . Context , i interface { } ) Renderer { ct , _ := ctx . Value ( " " ) . ( string ) if ct == " " { ct = e . DefaultContentType } ct = strings . TrimSpace ( strings . ToLower ( ct ) ) if strings . Contains ( ct , " " ) { return e . JSON ( i ) } if strings . Contains ( ct , " " ) { return e . XML ( i ) } return htmlAutoRenderer { Engine : e , model : i , } } 
func ( opts * Options ) Validate ( ) error { if opts . Options == nil { opts . Options = & core . Options { } } if err := opts . Options . Validate ( ) ; err != nil { return err } if opts . Docker != nil { if opts . Docker . App . IsZero ( ) { opts . Docker . App = opts . App } if err := opts . Docker . Validate ( ) ; err != nil { return err } } if opts . Webpack != nil { if opts . Webpack . App . IsZero ( ) { opts . Webpack . App = opts . App } if err := opts . Webpack . Validate ( ) ; err != nil { return err } } if opts . Standard != nil && opts . Webpack != nil { return errors . New ( " " ) } return nil } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } if opts . Provider == " " { return g , nil } box := packr . New ( " " , " " ) s , err := box . FindString ( " " ) if err != nil { return g , err } p := opts . Provider n := fmt . Sprintf ( " " , p ) g . File ( genny . NewFileS ( n , s ) ) g . Command ( exec . Command ( p , " " ) ) args := [ ] string { " " , " " } if p == " " { } g . Command ( exec . Command ( p , args ... ) ) g . Command ( exec . Command ( p , " " , " " , " " , " " ) ) return g , nil } 
func ( s * Listener ) SetAddr ( addr string ) { if s . Server . Addr == " " { s . Server . Addr = addr } } 
func ( s * Listener ) Start ( c context . Context , h http . Handler ) error { s . Handler = h return s . Serve ( s . Listener ) } 
func UnixSocket ( addr string ) ( * Listener , error ) { listener , err := net . Listen ( " " , addr ) if err != nil { return nil , err } return & Listener { Server : & http . Server { } , Listener : listener , } , nil } 
func ( e ErrorHandlers ) Get ( status int ) ErrorHandler { if eh , ok := e [ status ] ; ok { return eh } if eh , ok := e [ 0 ] ; ok { return eh } return defaultErrorHandler } 
func ( a * App ) PanicHandler ( next Handler ) Handler { return func ( c Context ) error { defer func ( ) { var err error if r != nil { case string : err = errors . New ( t ) default : err = errors . New ( fmt . Sprint ( t ) ) } err = err events . EmitError ( events . ErrPanic , err , map [ string ] interface { } { " " : c , " " : a , } , ) eh := a . ErrorHandlers . Get ( 500 ) eh ( 500 , err , c ) } } ( ) return next ( c ) } } 
func ( opts * Options ) Validate ( ) error { if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } if len ( opts . Version ) == 0 { opts . Version = runtime . Version } if len ( opts . Provider ) == 0 { return errors . New ( " " ) } opts . Provider = strings . ToLower ( opts . Provider ) var found bool for _ , a := range Available { if opts . Provider == a { found = true break } if opts . Provider == a + " " { opts . Provider = a found = true break } } if ! found { return fmt . Errorf ( " " , opts . Provider , strings . Join ( Available , " " ) ) } found = false for _ , d := range pop . AvailableDialects { if d == opts . DBType { found = true break } } if ! found { return fmt . Errorf ( " " , opts . DBType , strings . Join ( pop . AvailableDialects , " " ) ) } return nil } 
func WrapTLS ( s * http . Server , certFile string , keyFile string ) Server { return & TLS { Server : s , CertFile : certFile , KeyFile : keyFile , } } 
func WrapListener ( s * http . Server , l net . Listener ) Server { return & Listener { Server : s , Listener : l , } } 
func ( s templateRenderer ) partialFeeder ( name string ) ( string , error ) { ct := strings . ToLower ( s . contentType ) d , f := filepath . Split ( name ) name = filepath . Join ( d , " " + f ) name = fixExtension ( name , ct ) return s . TemplatesBox . FindString ( name ) } 
func Template ( c string , names ... string ) Renderer { e := New ( Options { } ) return e . Template ( c , names ... ) } 
func ( e * Engine ) Template ( c string , names ... string ) Renderer { return & templateRenderer { Engine : e , contentType : c , names : names , } } 
func New ( opts Options ) * Engine { if opts . Helpers == nil { opts . Helpers = map [ string ] interface { } { } } if opts . TemplateEngines == nil { opts . TemplateEngines = map [ string ] TemplateEngine { } } if _ , ok := opts . TemplateEngines [ " " ] ; ! ok { opts . TemplateEngines [ " " ] = plush . BuffaloRenderer } if _ , ok := opts . TemplateEngines [ " " ] ; ! ok { opts . TemplateEngines [ " " ] = plush . BuffaloRenderer } if _ , ok := opts . TemplateEngines [ " " ] ; ! ok { opts . TemplateEngines [ " " ] = plush . BuffaloRenderer } if _ , ok := opts . TemplateEngines [ " " ] ; ! ok { opts . TemplateEngines [ " " ] = plush . BuffaloRenderer } if _ , ok := opts . TemplateEngines [ " " ] ; ! ok { opts . TemplateEngines [ " " ] = MDTemplateEngine } if _ , ok := opts . TemplateEngines [ " " ] ; ! ok { opts . TemplateEngines [ " " ] = GoTemplateEngine } if opts . DefaultContentType == " " { opts . DefaultContentType = " " } e := & Engine { Options : opts , } return e } 
func ( s * Simple ) SetAddr ( addr string ) { if s . Server . Addr == " " { s . Server . Addr = addr } } 
func ( s * Simple ) Start ( c context . Context , h http . Handler ) error { s . Handler = h return s . ListenAndServe ( ) } 
func ( m * Message ) WriteTo ( w io . Writer ) ( int64 , error ) { mw := & messageWriter { w : w } mw . writeMessage ( m ) return mw . n , mw . err } 
func App ( ) * buffalo . App { if app == nil { app = buffalo . New ( buffalo . Options { Env : ENV , SessionName : " " , } ) app . GET ( " " , HomeHandler ) app . ServeFiles ( " " , assetsBox ) } return app } 
func translations ( ) buffalo . MiddlewareFunc { var err error if T , err = i18n . New ( packr . New ( " " , " " ) , " " ) ; err != nil { app . Stop ( err ) } return T . Middleware ( ) } 
func forceSSL ( ) buffalo . MiddlewareFunc { return forcessl . Middleware ( secure . Options { SSLRedirect : ENV == " " , SSLProxyHeaders : map [ string ] string { " " : " " } , } ) } 
func ( sm SMTPSender ) Send ( message Message ) error { gm := gomail . NewMessage ( ) gm . SetHeader ( " " , message . From ) gm . SetHeader ( " " , message . To ... ) gm . SetHeader ( " " , message . Subject ) gm . SetHeader ( " " , message . CC ... ) gm . SetHeader ( " " , message . Bcc ... ) sm . addBodies ( message , gm ) sm . addAttachments ( message , gm ) for field , value := range message . Headers { gm . SetHeader ( field , value ) } err := sm . Dialer . DialAndSend ( gm ) if err != nil { return err } return nil } 
func NewSMTPSender ( host string , port string , user string , password string ) ( SMTPSender , error ) { iport , err := strconv . Atoi ( port ) if err != nil { return SMTPSender { } , errors . New ( " " ) } dialer := & gomail . Dialer { Host : host , Port : iport , } if user != " " { dialer . Username = user dialer . Password = password } return SMTPSender { Dialer : dialer , } , nil } 
func ( d * DefaultContext ) Param ( key string ) string { return d . Params ( ) . Get ( key ) } 
func ( d * DefaultContext ) Set ( key string , value interface { } ) { d . moot . Lock ( ) d . data [ key ] = value d . moot . Unlock ( ) } 
func ( d * DefaultContext ) Value ( key interface { } ) interface { } { if k , ok := key . ( string ) ; ok { d . moot . RLock ( ) defer d . moot . RUnlock ( ) if v , ok := d . data [ k ] ; ok { return v } } return d . Context . Value ( key ) } 
func ( d * DefaultContext ) Render ( status int , rr render . Renderer ) error { start := time . Now ( ) defer func ( ) { d . LogField ( " " , time . Since ( start ) ) } ( ) if rr != nil { data := d . Data ( ) pp := map [ string ] string { } for k , v := range d . params { pp [ k ] = v [ 0 ] } data [ " " ] = pp data [ " " ] = d . Flash ( ) . data data [ " " ] = d . Session ( ) data [ " " ] = d . Request ( ) data [ " " ] = status bb := & bytes . Buffer { } err := rr . Render ( bb , data ) if err != nil { if er , ok := errors . Cause ( err ) . ( render . ErrRedirect ) ; ok { return d . Redirect ( er . Status , er . URL ) } return HTTPError { Status : 500 , Cause : err } } if d . Session ( ) != nil { d . Flash ( ) . Clear ( ) d . Flash ( ) . persist ( d . Session ( ) ) } d . Response ( ) . Header ( ) . Set ( " " , rr . ContentType ( ) ) if p , ok := data [ " " ] . ( paginable ) ; ok { d . Response ( ) . Header ( ) . Set ( " " , p . Paginate ( ) ) } d . Response ( ) . WriteHeader ( status ) _ , err = io . Copy ( d . Response ( ) , bb ) if err != nil { return HTTPError { Status : 500 , Cause : err } } return nil } d . Response ( ) . WriteHeader ( status ) return nil } 
func ( d * DefaultContext ) Bind ( value interface { } ) error { return binding . Exec ( d . Request ( ) , value ) } 
func ( d * DefaultContext ) LogField ( key string , value interface { } ) { d . logger = d . logger . WithField ( key , value ) } 
func ( d * DefaultContext ) LogFields ( values map [ string ] interface { } ) { d . logger = d . logger . WithFields ( values ) } 
func ( d * DefaultContext ) Redirect ( status int , url string , args ... interface { } ) error { d . Flash ( ) . persist ( d . Session ( ) ) if strings . HasSuffix ( url , " " ) { if len ( args ) > 1 { return fmt . Errorf ( " " , args ) } var m map [ string ] interface { } if len ( args ) == 1 { rv := reflect . Indirect ( reflect . ValueOf ( args [ 0 ] ) ) if ! rv . Type ( ) . ConvertibleTo ( mapType ) { return fmt . Errorf ( " " , args ) } m = rv . Convert ( mapType ) . Interface ( ) . ( map [ string ] interface { } ) } h , ok := d . Value ( strings . TrimSuffix ( url , " " ) ) . ( RouteHelperFunc ) if ! ok { return fmt . Errorf ( " " , url ) } url , err := h ( m ) if err != nil { return err } http . Redirect ( d . Response ( ) , d . Request ( ) , string ( url ) , status ) return nil } if len ( args ) > 0 { url = fmt . Sprintf ( url , args ... ) } http . Redirect ( d . Response ( ) , d . Request ( ) , url , status ) return nil } 
func ( d * DefaultContext ) Data ( ) map [ string ] interface { } { d . moot . Lock ( ) m := map [ string ] interface { } { } for k , v := range d . data { m [ k ] = v } d . moot . Unlock ( ) return m } 
func ( d * DefaultContext ) File ( name string ) ( binding . File , error ) { req := d . Request ( ) if err := req . ParseMultipartForm ( 5 * 1024 * 1024 ) ; err != nil { return binding . File { } , err } f , h , err := req . FormFile ( name ) bf := binding . File { File : f , FileHeader : h , } if err != nil { return bf , err } return bf , nil } 
func ( d * DefaultContext ) MarshalJSON ( ) ( [ ] byte , error ) { m := map [ string ] interface { } { } data := d . Data ( ) for k , v := range data { } if _ , err := json . Marshal ( v ) ; err == nil { } } return json . Marshal ( m ) } 
func New ( opts * Options ) ( * genny . Group , error ) { gg := & genny . Group { } if err != nil { return gg , err } gg . Add ( g ) app := opts . App if app . WithModules { g , err := gomods . Init ( app . PackagePkg , app . Root ) if err != nil { return gg , err } g . Command ( gogen . Get ( " " + runtime . Version ) ) g . Command ( gogen . Get ( " " ) ) gg . Add ( g ) } plugs , err := plugdeps . List ( app ) if err != nil && ( errors . Cause ( err ) != plugdeps . ErrMissingConfig ) { return nil , err } if opts . Docker != nil { if err != nil { return gg , err } gg . Add ( g ) } if opts . Pop != nil { if err != nil { return gg , err } gg . Merge ( gg2 ) } if opts . CI != nil { if err != nil { return gg , err } gg . Add ( g ) } if opts . Refresh != nil { g , err = refresh . New ( opts . Refresh ) if err != nil { return gg , err } gg . Add ( g ) } if app . WithSQLite { iopts . Tags = meta . BuildTags { " " } } ig , err := install . New ( iopts ) if err != nil { return gg , err } gg . Merge ( ig ) if err != nil { return gg , err } gg . Add ( di ) } if ! app . WithDep && ! app . WithModules { g := genny . New ( ) g . Command ( gogen . Get ( " " , " " ) ) gg . Add ( g ) } if app . WithModules { g , err := gomods . Tidy ( app . Root , false ) if err != nil { return gg , err } gg . Add ( g ) } return gg , nil } 
func New ( opts * Options ) ( * genny . Group , error ) { if err := opts . Validate ( ) ; err != nil { return nil , err } gg , err := core . New ( opts . Options ) if err != nil { return gg , err } g := genny . New ( ) data := map [ string ] interface { } { " " : opts , } helpers := template . FuncMap { } t := gogen . TemplateTransformer ( data , helpers ) g . Transformer ( t ) g . Box ( packr . New ( " " , " " ) ) gg . Add ( g ) return gg , nil } 
func New ( opts Options ) * App { LoadPlugins ( ) envy . Load ( ) opts = optionsWithDefaults ( opts ) a := & App { Options : opts , ErrorHandlers : ErrorHandlers { 404 : defaultErrorHandler , 500 : defaultErrorHandler , } , router : mux . NewRouter ( ) , moot : & sync . RWMutex { } , routes : RouteList { } , children : [ ] * App { } , } dem := a . defaultErrorMiddleware a . Middleware = newMiddlewareStack ( dem ) notFoundHandler := func ( errorf string , code int ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { c := a . newContext ( RouteInfo { } , res , req ) err := fmt . Errorf ( errorf , req . Method , req . URL . Path ) a . ErrorHandlers . Get ( code ) ( code , err , c ) } } a . router . NotFoundHandler = notFoundHandler ( " " , 404 ) a . router . MethodNotAllowedHandler = notFoundHandler ( " " , 405 ) if a . MethodOverride == nil { a . MethodOverride = MethodOverride } a . Use ( a . PanicHandler ) a . Use ( RequestLogger ) a . Use ( sessionSaver ) return a } 
func DeprecrationsCheck ( r * Runner ) error { fmt . Println ( " " ) b , err := ioutil . ReadFile ( " " ) if err != nil { return err } if bytes . Contains ( b , [ ] byte ( " " ) ) { r . Warnings = append ( r . Warnings , " " ) } return filepath . Walk ( filepath . Join ( r . App . Root , " " ) , func ( path string , info os . FileInfo , _ error ) error { if info . IsDir ( ) { return nil } if filepath . Ext ( path ) != " " { return nil } b , err := ioutil . ReadFile ( path ) if err != nil { return err } if bytes . Contains ( b , [ ] byte ( " " ) ) { r . Warnings = append ( r . Warnings , fmt . Sprintf ( " " , path ) ) } if bytes . Contains ( b , [ ] byte ( " " ) ) { r . Warnings = append ( r . Warnings , fmt . Sprintf ( " " , path ) ) } if bytes . Contains ( b , [ ] byte ( " " ) ) { r . Warnings = append ( r . Warnings , fmt . Sprintf ( " " , path ) ) } } if bytes . Contains ( b , [ ] byte ( " " ) ) { b = bytes . Replace ( b , [ ] byte ( " " ) , [ ] byte ( " \" \" " ) , - 1 ) } if bytes . Contains ( b , [ ] byte ( " " ) ) || bytes . Contains ( b , [ ] byte ( " " ) ) { r . Warnings = append ( r . Warnings , fmt . Sprintf ( " " , path ) ) } ioutil . WriteFile ( path , b , 0664 ) return nil } ) } 
func ( v BaseResource ) List ( c Context ) error { return c . Error ( 404 , errors . New ( " " ) ) } 
func ( s funcRenderer ) Render ( w io . Writer , data Data ) error { return s . renderFunc ( w , data ) } 
func Func ( s string , fn RendererFunc ) Renderer { return funcRenderer { contentType : s , renderFunc : fn , } } 
func ( e * Engine ) Func ( s string , fn RendererFunc ) Renderer { return Func ( s , fn ) } 
func ( opts * Options ) Validate ( ) error { if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } if opts . Out . Writer == nil { opts . Out = rx . NewWriter ( os . Stdout ) } return nil } 
func buildActions ( pres * presenter ) genny . RunFn { return func ( r * genny . Runner ) error { fn := fmt . Sprintf ( " " , pres . Name . File ( ) ) xf , err := r . FindFile ( fn ) if err != nil { return buildNewActions ( fn , pres ) ( r ) } if err := appendActions ( xf , pres ) ( r ) ; err != nil { return err } return nil } } 
func buildNewActions ( fn string , pres * presenter ) genny . RunFn { return func ( r * genny . Runner ) error { for _ , a := range pres . Options . Actions { pres . Actions = append ( pres . Actions , name . New ( a ) ) } h , err := box . FindString ( " " ) if err != nil { return err } a , err := box . FindString ( " " ) if err != nil { return err } f := genny . NewFileS ( fn + " " , h + a ) f , err = transform ( pres , f ) if err != nil { return err } return r . File ( f ) } } 
func appendActions ( f genny . File , pres * presenter ) genny . RunFn { return func ( r * genny . Runner ) error { body := f . String ( ) for _ , ac := range pres . Options . Actions { a := name . New ( ac ) x := fmt . Sprintf ( " " , pres . Name . Pascalize ( ) , a . Pascalize ( ) ) if strings . Contains ( body , x ) { continue } pres . Actions = append ( pres . Actions , a ) } a , err := box . FindString ( " " ) if err != nil { return err } f = genny . NewFileS ( f . Name ( ) + " " , f . String ( ) + a ) f , err = transform ( pres , f ) if err != nil { return err } return r . File ( f ) } } 
func ( s * Session ) Save ( ) error { return s . Session . Save ( s . req , s . res ) } 
func ( s * Session ) GetOnce ( name interface { } ) interface { } { if x , ok := s . Session . Values [ name ] ; ok { s . Delete ( name ) return x } return nil } 
func ( s * Session ) Set ( name , value interface { } ) { s . Session . Values [ name ] = value } 
func ( s * Session ) Clear ( ) { for k := range s . Session . Values { s . Delete ( k ) } } 
func ( a * App ) getSession ( r * http . Request , w http . ResponseWriter ) * Session { if a . root != nil { return a . root . getSession ( r , w ) } session , _ := a . SessionStore . Get ( r , a . SessionName ) return & Session { Session : session , req : r , res : w , } } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } data := map [ string ] interface { } { " " : opts , } t := gogen . TemplateTransformer ( data , template . FuncMap { } ) g . Transformer ( t ) g . RunFn ( func ( r * genny . Runner ) error { return genFile ( r , opts ) } ) return g , nil } 
func String ( s string , args ... interface { } ) Renderer { e := New ( Options { } ) return e . String ( s , args ... ) } 
func ( e * Engine ) String ( s string , args ... interface { } ) Renderer { if len ( args ) > 0 { s = fmt . Sprintf ( s , args ... ) } return stringRenderer { Engine : e , body : s , } } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } g . RunFn ( func ( r * genny . Runner ) error { if _ , err := r . LookPath ( " " ) ; err != nil { return errors . New ( " " ) } return nil } ) g . Box ( Templates ) data := map [ string ] interface { } { " " : opts , } t := gogen . TemplateTransformer ( data , gogen . TemplateHelpers ) g . Transformer ( t ) g . Transformer ( genny . Dot ( ) ) g . RunFn ( func ( r * genny . Runner ) error { return installPkgs ( r , opts ) } ) return g , nil } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } g . Box ( packr . New ( " " , " " ) ) ctx := plush . NewContext ( ) ctx . Set ( " " , opts . App ) g . Transformer ( plushgen . Transformer ( ctx ) ) g . Transformer ( genny . Dot ( ) ) return g , nil } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } g . ErrorFn = func ( err error ) { events . EmitError ( EvtBuildStopErr , err , events . Payload { " " : opts } ) } g . RunFn ( func ( r * genny . Runner ) error { events . EmitPayload ( EvtBuildStart , events . Payload { " " : opts } ) return nil } ) g . Transformer ( genny . Dot ( ) ) if err := g . Box ( box ) ; err != nil { return g , err } ctx . Set ( " " , opts ) ctx . Set ( " " , opts . BuildTime . Format ( time . RFC3339 ) ) ctx . Set ( " " , opts . BuildVersion ) ctx . Set ( " " , runtime . Version ) g . Transformer ( plushgen . Transformer ( ctx ) ) if err != nil { return g , err } g . Merge ( ag ) if opts . WithAssets { if err != nil { return g , err } g . Merge ( ag ) } if err != nil { return g , err } g . Merge ( dg ) g . RunFn ( func ( r * genny . Runner ) error { return jam . Pack ( jam . PackOptions { } ) } ) if err != nil { return g , err } g . Command ( c ) g . RunFn ( Cleanup ( opts ) ) g . RunFn ( func ( r * genny . Runner ) error { events . EmitPayload ( EvtBuildStop , events . Payload { " " : opts } ) return nil } ) return g , nil } 
func Execute ( ) { if err := RootCmd . Execute ( ) ; err != nil { if strings . Contains ( err . Error ( ) , dbNotFound ) || strings . Contains ( err . Error ( ) , popNotFound ) { logrus . Errorf ( popInstallInstructions ) os . Exit ( - 1 ) } logrus . Errorf ( " " , err ) if strings . Contains ( err . Error ( ) , dbNotFound ) || strings . Contains ( err . Error ( ) , popNotFound ) { fmt . Println ( popInstallInstructions ) os . Exit ( - 1 ) } os . Exit ( - 1 ) } } 
func ( opts * Options ) Validate ( ) error { pwd , _ := os . Getwd ( ) if opts . App . IsZero ( ) { opts . App = meta . New ( pwd ) } if len ( opts . Environment ) == 0 { opts . Environment = " " } if opts . BuildTime . IsZero ( ) { opts . BuildTime = time . Now ( ) } if len ( opts . BuildVersion ) == 0 { opts . BuildVersion = opts . BuildTime . Format ( time . RFC3339 ) } if opts . rollback == nil { opts . rollback = & sync . Map { } } if len ( opts . GoCommand ) == 0 { opts . GoCommand = " " } return nil } 
func ( opts * Options ) Validate ( ) error { if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } if len ( opts . Name ) == 0 { return errors . New ( " " ) } if len ( opts . Model ) == 0 { opts . Model = opts . Name } if strings . Contains ( opts . Model , " " ) { parts := strings . Split ( opts . Model , " " ) opts . Model = parts [ len ( parts ) - 1 ] } if opts . App . AsAPI { opts . SkipTemplates = true } return nil } 
func NewMessage ( settings ... MessageSetting ) * Message { m := & Message { header : make ( header ) , charset : " " , encoding : QuotedPrintable , } m . applySettings ( settings ) if m . encoding == Base64 { m . hEncoder = bEncoding } else { m . hEncoder = qEncoding } return m } 
func ( m * Message ) Reset ( ) { for k := range m . header { delete ( m . header , k ) } m . parts = nil m . attachments = nil m . embedded = nil } 
func ( m * Message ) SetHeader ( field string , value ... string ) { m . encodeHeader ( value ) m . header [ field ] = value } 
func ( m * Message ) SetHeaders ( h map [ string ] [ ] string ) { for k , v := range h { m . SetHeader ( k , v ... ) } } 
func ( m * Message ) SetAddressHeader ( field , address , name string ) { m . header [ field ] = [ ] string { m . FormatAddress ( address , name ) } } 
func ( m * Message ) FormatAddress ( address , name string ) string { if name == " " { return address } enc := m . encodeString ( name ) if enc == name { m . buf . WriteByte ( '"' ) for i := 0 ; i < len ( name ) ; i ++ { b := name [ i ] if b == '\\' || b == '"' { m . buf . WriteByte ( '\\' ) } m . buf . WriteByte ( b ) } m . buf . WriteByte ( '"' ) } else if hasSpecials ( name ) { m . buf . WriteString ( bEncoding . Encode ( m . charset , name ) ) } else { m . buf . WriteString ( enc ) } m . buf . WriteString ( " " ) m . buf . WriteString ( address ) m . buf . WriteByte ( '>' ) addr := m . buf . String ( ) m . buf . Reset ( ) return addr } 
func ( m * Message ) SetDateHeader ( field string , date time . Time ) { m . header [ field ] = [ ] string { m . FormatDate ( date ) } } 
func ( m * Message ) FormatDate ( date time . Time ) string { return date . Format ( time . RFC1123Z ) } 
func ( m * Message ) SetBody ( contentType , body string , settings ... PartSetting ) { m . SetBodyWriter ( contentType , newCopier ( body ) , settings ... ) } 
func ( m * Message ) SetBodyWriter ( contentType string , f func ( io . Writer ) error , settings ... PartSetting ) { m . parts = [ ] * part { m . newPart ( contentType , f , settings ) } } 
func ( m * Message ) AddAlternative ( contentType , body string , settings ... PartSetting ) { m . AddAlternativeWriter ( contentType , newCopier ( body ) , settings ... ) } 
func ( m * Message ) AddAlternativeWriter ( contentType string , f func ( io . Writer ) error , settings ... PartSetting ) { m . parts = append ( m . parts , m . newPart ( contentType , f , settings ) ) } 
func SetPartEncoding ( e Encoding ) PartSetting { return PartSetting ( func ( p * part ) { p . encoding = e } ) } 
func SetHeader ( h map [ string ] [ ] string ) FileSetting { return func ( f * file ) { for k , v := range h { f . Header [ k ] = v } } } 
func SetCopyFunc ( f func ( io . Writer ) error ) FileSetting { return func ( fi * file ) { fi . CopyFunc = f } } 
func ( m * Message ) AttachReader ( name string , r io . Reader , settings ... FileSetting ) { m . attachments = m . appendFile ( m . attachments , fileFromReader ( name , r ) , settings ) } 
func ( m * Message ) Attach ( filename string , settings ... FileSetting ) { m . attachments = m . appendFile ( m . attachments , fileFromFilename ( filename ) , settings ) } 
func ( m * Message ) EmbedReader ( name string , r io . Reader , settings ... FileSetting ) { m . embedded = m . appendFile ( m . embedded , fileFromReader ( name , r ) , settings ) } 
func ( m * Message ) Embed ( filename string , settings ... FileSetting ) { m . embedded = m . appendFile ( m . embedded , fileFromFilename ( filename ) , settings ) } 
func ValidateTemplates ( walk packd . Walker , tvs [ ] TemplateValidator ) genny . RunFn { if len ( tvs ) == 0 { return func ( r * genny . Runner ) error { return nil } } return func ( r * genny . Runner ) error { var errs [ ] string err := packd . SkipWalker ( walk , packd . CommonSkipPrefixes , func ( path string , file packd . File ) error { info , err := file . FileInfo ( ) if err != nil { return err } if info . IsDir ( ) { return nil } f := genny . NewFile ( path , file ) for _ , tv := range tvs { err := safe . Run ( func ( ) { if err := tv ( f ) ; err != nil { errs = append ( errs , fmt . Sprintf ( " " , path , err . Error ( ) ) ) } } ) if err != nil { return err } } return nil } ) if err != nil { return err } if len ( errs ) == 0 { return nil } return errors . New ( strings . Join ( errs , " \n " ) ) } } 
func PlushValidator ( f genny . File ) error { if ! genny . HasExt ( f , " " , " " , " " ) { return nil } _ , err := plush . Parse ( f . String ( ) ) return err } 
func GoTemplateValidator ( f genny . File ) error { if ! genny . HasExt ( f , " " ) { return nil } t := template . New ( f . Name ( ) ) _ , err := t . Parse ( f . String ( ) ) return err } 
func ( opts * Options ) Validate ( ) error { if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } var found bool for _ , a := range Available { if opts . Provider == a { found = true break } } if ! found { return fmt . Errorf ( " " , opts . Provider , strings . Join ( Available , " " ) ) } return nil } 
func ( opts * Options ) Validate ( ) error { if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } if len ( opts . Version ) == 0 { opts . Version = runtime . Version } if opts . Pop != nil { if opts . Pop . App . IsZero ( ) { opts . Pop . App = opts . App } if err := opts . Pop . Validate ( ) ; err != nil { return err } } if opts . CI != nil { if opts . CI . App . IsZero ( ) { opts . CI . App = opts . App } if err := opts . CI . Validate ( ) ; err != nil { return err } } if opts . Refresh != nil { if opts . Refresh . App . IsZero ( ) { opts . Refresh . App = opts . App } if err := opts . Refresh . Validate ( ) ; err != nil { return err } } if opts . VCS != nil { if opts . VCS . App . IsZero ( ) { opts . VCS . App = opts . App } if err := opts . VCS . Validate ( ) ; err != nil { return err } } if opts . App . WithModules && opts . App . WithDep { return ErrGoModulesWithDep } name := strings . ToLower ( opts . App . Name . String ( ) ) fb := append ( opts . ForbiddenNames , " " , " " , " " ) for _ , n := range fb { rx , err := regexp . Compile ( n ) if err != nil { return err } if rx . MatchString ( name ) { return fmt . Errorf ( " " , opts . App . Name ) } } if ! nameRX . MatchString ( name ) { return fmt . Errorf ( " " , opts . App . Name ) } return nil } 
func ( opts * Options ) Validate ( ) error { if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } if len ( opts . Name . String ( ) ) == 0 { return errors . New ( " " ) } return nil } 
func LoadPlugins ( ) error { var err error oncer . Do ( " " , func ( ) { } plugs , err := plugins . Available ( ) if err != nil { err = err return } for _ , cmds := range plugs { for _ , c := range cmds { if c . BuffaloCommand != " " { continue } err := func ( c plugins . Command ) error { return safe . RunE ( func ( ) error { n := fmt . Sprintf ( " " , c . Binary , c . Name ) fn := func ( e events . Event ) { b , err := json . Marshal ( e ) if err != nil { fmt . Println ( " " , e , err ) return } cmd := exec . Command ( c . Binary , c . UseCommand , string ( b ) ) cmd . Stderr = os . Stderr cmd . Stdout = os . Stdout cmd . Stdin = os . Stdin if err := cmd . Run ( ) ; err != nil { fmt . Println ( " " , strings . Join ( cmd . Args , " " ) , err ) } } _ , err := events . NamedListen ( n , events . Filter ( c . ListenFor , fn ) ) if err != nil { return err } return nil } ) } ( c ) if err != nil { err = err return } } } } ) return err } 
func ( w * Response ) WriteHeader ( i int ) { w . Status = i w . ResponseWriter . WriteHeader ( i ) } 
func ( w * Response ) Write ( b [ ] byte ) ( int , error ) { w . Size = binary . Size ( b ) return w . ResponseWriter . Write ( b ) } 
func ( w * Response ) Flush ( ) { if f , ok := w . ResponseWriter . ( http . Flusher ) ; ok { f . Flush ( ) } } 
func ( w * Response ) CloseNotify ( ) <- chan bool { if cn , ok := w . ResponseWriter . ( closeNotifier ) ; ok { return cn . CloseNotify ( ) } return nil } 
func Run ( ) error { fmt . Printf ( " \n " , runtime . Version ) if ! ask ( " " ) { fmt . Println ( " " ) return nil } r := & Runner { App : meta . New ( " " ) , Warnings : [ ] string { } , } defer func ( ) { if len ( r . Warnings ) == 0 { return } fmt . Println ( " \n \n " ) fmt . Printf ( " \n \n " , len ( r . Warnings ) ) for _ , w := range r . Warnings { fmt . Printf ( " \n " , w ) } } ( ) for _ , c := range checks { if err := c ( r ) ; err != nil { return err } } return nil } 
func onlyRelevantFiles ( p string , fi os . FileInfo , err error , fn func ( p string ) error ) error { if err != nil { return err } if fi . IsDir ( ) { base := filepath . Base ( p ) if strings . HasPrefix ( base , " " ) { return filepath . SkipDir } for _ , n := range [ ] string { " " , " " , " " } { if base == n { return filepath . SkipDir } } return nil } ext := filepath . Ext ( p ) if ext != " " { return nil } return fn ( p ) } 
func GoTemplateEngine ( input string , data map [ string ] interface { } , helpers map [ string ] interface { } ) ( string , error ) { t := template . New ( input ) if helpers != nil { t = t . Funcs ( helpers ) } t , err := t . Parse ( input ) if err != nil { return " " , err } bb := & bytes . Buffer { } err = t . Execute ( bb , data ) return bb . String ( ) , err } 
func ( a * App ) GET ( p string , h Handler ) * RouteInfo { return a . addRoute ( " " , p , h ) } 
func ( a * App ) Redirect ( status int , from , to string ) * RouteInfo { return a . GET ( from , func ( c Context ) error { return c . Redirect ( status , to ) } ) } 
func ( a * App ) Mount ( p string , h http . Handler ) { prefix := path . Join ( a . Prefix , p ) path := path . Join ( p , " " ) a . ANY ( path , WrapHandler ( http . StripPrefix ( prefix , h ) ) ) } 
func ( a * App ) ServeFiles ( p string , root http . FileSystem ) { path := path . Join ( a . Prefix , p ) a . filepaths = append ( a . filepaths , path ) h := stripAsset ( path , a . fileServer ( root ) , a ) a . router . PathPrefix ( path ) . Handler ( h ) } 
func ( a * App ) Resource ( p string , r Resource ) * App { g := a . Group ( p ) p = " " rv := reflect . ValueOf ( r ) if rv . Kind ( ) == reflect . Ptr { rv = rv . Elem ( ) } rt := rv . Type ( ) rname := fmt . Sprintf ( " " , rt . PkgPath ( ) , rt . Name ( ) ) + " " n := strings . TrimSuffix ( rt . Name ( ) , " " ) paramName := name . New ( n ) . ParamID ( ) . String ( ) type paramKeyable interface { ParamKey ( ) string } if pk , ok := r . ( paramKeyable ) ; ok { paramName = pk . ParamKey ( ) } spath := path . Join ( p , " " + paramName + " " ) setFuncKey ( r . List , fmt . Sprintf ( rname , " " ) ) g . GET ( p , r . List ) if n , ok := r . ( newable ) ; ok { setFuncKey ( n . New , fmt . Sprintf ( rname , " " ) ) g . GET ( path . Join ( p , " " ) , n . New ) } setFuncKey ( r . Show , fmt . Sprintf ( rname , " " ) ) g . GET ( path . Join ( spath ) , r . Show ) if n , ok := r . ( editable ) ; ok { setFuncKey ( n . Edit , fmt . Sprintf ( rname , " " ) ) g . GET ( path . Join ( spath , " " ) , n . Edit ) } setFuncKey ( r . Create , fmt . Sprintf ( rname , " " ) ) g . POST ( p , r . Create ) setFuncKey ( r . Update , fmt . Sprintf ( rname , " " ) ) g . PUT ( path . Join ( spath ) , r . Update ) setFuncKey ( r . Destroy , fmt . Sprintf ( rname , " " ) ) g . DELETE ( path . Join ( spath ) , r . Destroy ) g . Prefix = path . Join ( g . Prefix , spath ) return g } 
func ( a * App ) ANY ( p string , h Handler ) { a . GET ( p , h ) a . POST ( p , h ) a . PUT ( p , h ) a . PATCH ( p , h ) a . HEAD ( p , h ) a . OPTIONS ( p , h ) a . DELETE ( p , h ) } 
func ( a * App ) Group ( groupPath string ) * App { g := New ( a . Options ) g . Prefix = path . Join ( a . Prefix , groupPath ) g . Name = g . Prefix g . router = a . router g . Middleware = a . Middleware . clone ( ) g . ErrorHandlers = a . ErrorHandlers g . root = a if a . root != nil { g . root = a . root } a . children = append ( a . children , g ) return g } 
func ( a * App ) RouteHelpers ( ) map [ string ] RouteHelperFunc { rh := map [ string ] RouteHelperFunc { } for _ , route := range a . Routes ( ) { cRoute := route rh [ cRoute . PathName ] = cRoute . BuildPathHelper ( ) } return rh } 
func ( a * App ) buildRouteName ( p string ) string { if p == " " || p == " " { return " " } resultParts := [ ] string { } parts := strings . Split ( p , " " ) for index , part := range parts { if strings . Contains ( part , " " ) || part == " " { continue } shouldSingularize := ( len ( parts ) > index + 1 ) && strings . Contains ( parts [ index + 1 ] , " " ) if shouldSingularize { part = flect . Singularize ( part ) } if parts [ index ] == " " || parts [ index ] == " " { resultParts = append ( [ ] string { part } , resultParts ... ) continue } if index > 0 && strings . Contains ( parts [ index - 1 ] , " " ) { resultParts = append ( resultParts , part ) continue } resultParts = append ( resultParts , part ) } if len ( resultParts ) == 0 { return " " } underscore := strings . TrimSpace ( strings . Join ( resultParts , " " ) ) return name . VarCase ( underscore ) } 
func New ( opts * Options ) ( * genny . Group , error ) { gg := & genny . Group { } if err := opts . Validate ( ) ; err != nil { return gg , err } if ! opts . SkipInit { g , err := initGenerator ( opts ) if err != nil { return gg , err } gg . Add ( g ) } g := genny . New ( ) h := template . FuncMap { } data := map [ string ] interface { } { " " : opts , } t := gogen . TemplateTransformer ( data , h ) g . Transformer ( t ) fn := opts . Name . File ( ) . String ( ) g . File ( genny . NewFileS ( " " + fn + " " , mailerTmpl ) ) g . File ( genny . NewFileS ( " " + fn + " " , mailTmpl ) ) gg . Add ( g ) return gg , nil } 
func NewDialer ( host string , port int , username , password string ) * Dialer { return & Dialer { Host : host , Port : port , Username : username , Password : password , SSL : port == 465 , Timeout : 10 * time . Second , RetryFailure : true , } } 
func ( d * Dialer ) Dial ( ) ( SendCloser , error ) { conn , err := NetDialTimeout ( " " , addr ( d . Host , d . Port ) , d . Timeout ) if err != nil { return nil , err } if d . SSL { conn = tlsClient ( conn , d . tlsConfig ( ) ) } c , err := smtpNewClient ( conn , d . Host ) if err != nil { return nil , err } if d . Timeout > 0 { conn . SetDeadline ( time . Now ( ) . Add ( d . Timeout ) ) } if d . LocalName != " " { if err := c . Hello ( d . LocalName ) ; err != nil { return nil , err } } if ! d . SSL && d . StartTLSPolicy != NoStartTLS { ok , _ := c . Extension ( " " ) if ! ok && d . StartTLSPolicy == MandatoryStartTLS { err := StartTLSUnsupportedError { Policy : d . StartTLSPolicy } return nil , err } if ok { if err := c . StartTLS ( d . tlsConfig ( ) ) ; err != nil { c . Close ( ) return nil , err } } } if d . Auth == nil && d . Username != " " { if ok , auths := c . Extension ( " " ) ; ok { if strings . Contains ( auths , " " ) { d . Auth = smtp . CRAMMD5Auth ( d . Username , d . Password ) } else if strings . Contains ( auths , " " ) && ! strings . Contains ( auths , " " ) { d . Auth = & loginAuth { username : d . Username , password : d . Password , host : d . Host , } } else { d . Auth = smtp . PlainAuth ( " " , d . Username , d . Password , d . Host ) } } } if d . Auth != nil { if err = c . Auth ( d . Auth ) ; err != nil { c . Close ( ) return nil , err } } return & smtpSender { c , conn , d } , nil } 
func ( d * Dialer ) DialAndSend ( m ... * Message ) error { s , err := d . Dial ( ) if err != nil { return err } defer s . Close ( ) return Send ( s , m ... ) } 
func RequestLoggerFunc ( h Handler ) Handler { return func ( c Context ) error { var irid interface { } if irid = c . Session ( ) . Get ( " " ) ; irid == nil { irid = randx . String ( 10 ) c . Session ( ) . Set ( " " , irid ) c . Session ( ) . Save ( ) } rid := irid . ( string ) + " " + randx . String ( 10 ) c . Set ( " " , rid ) c . LogField ( " " , rid ) start := time . Now ( ) defer func ( ) { ws , ok := c . Response ( ) . ( * Response ) if ! ok { ws = & Response { ResponseWriter : c . Response ( ) } ws . Status = 200 } req := c . Request ( ) ct := httpx . ContentType ( req ) if ct != " " { c . LogField ( " " , ct ) } c . LogFields ( map [ string ] interface { } { " " : req . Method , " " : req . URL . String ( ) , " " : time . Since ( start ) , " " : ws . Size , " " : humanize . Bytes ( uint64 ( ws . Size ) ) , " " : ws . Status , } ) c . Logger ( ) . Info ( req . URL . String ( ) ) } ( ) return h ( c ) } } 
func ( f Flash ) Set ( key string , values [ ] string ) { f . data [ key ] = values } 
func ( f Flash ) Add ( key , value string ) { if len ( f . data [ key ] ) == 0 { f . data [ key ] = [ ] string { value } return } f . data [ key ] = append ( f . data [ key ] , value ) } 
func ( f Flash ) persist ( session * Session ) { b , _ := json . Marshal ( f . data ) session . Set ( flashKey , b ) session . Save ( ) } 
func newFlash ( session * Session ) * Flash { result := & Flash { data : map [ string ] [ ] string { } , } if session . Session != nil { if f := session . Get ( flashKey ) ; f != nil { json . Unmarshal ( f . ( [ ] byte ) , & result . data ) } } return result } 
func ( c * Cookies ) Get ( name string ) ( string , error ) { ck , err := c . req . Cookie ( name ) if err != nil { return " " , err } return ck . Value , nil } 
func ( c * Cookies ) Set ( name , value string , maxAge time . Duration ) { ck := http . Cookie { Name : name , Value : value , MaxAge : int ( maxAge . Seconds ( ) ) , } http . SetCookie ( c . res , & ck ) } 
func ( c * Cookies ) SetWithExpirationTime ( name , value string , expires time . Time ) { ck := http . Cookie { Name : name , Value : value , Expires : expires , } http . SetCookie ( c . res , & ck ) } 
func ( c * Cookies ) SetWithPath ( name , value , path string ) { ck := http . Cookie { Name : name , Value : value , Path : path , } http . SetCookie ( c . res , & ck ) } 
func ( c * Cookies ) Delete ( name string ) { ck := http . Cookie { Name : name , Value : " " , http . SetCookie ( c . res , & ck ) } 
func NewMessage ( ) Message { return Message { Context : context . Background ( ) , Headers : map [ string ] string { } , Data : render . Data { } , moot : & sync . RWMutex { } , } } 
func NewFromData ( data render . Data ) Message { d := render . Data { } for k , v := range data { d [ k ] = v } m := NewMessage ( ) m . Data = d return m } 
func New ( c buffalo . Context ) Message { m := NewFromData ( c . Data ( ) ) m . Context = c return m } 
func ( es * EventSource ) CloseNotify ( ) <- chan bool { if cn , ok := es . w . ( closeNotifier ) ; ok { return cn . CloseNotify ( ) } return nil } 
func NewEventSource ( w http . ResponseWriter ) ( * EventSource , error ) { es := & EventSource { w : w } var ok bool es . fl , ok = w . ( http . Flusher ) if ! ok { return es , errors . New ( " " ) } es . w . Header ( ) . Set ( " " , " " ) es . w . Header ( ) . Set ( " " , " " ) es . w . Header ( ) . Set ( " " , " " ) es . w . Header ( ) . Set ( " " , " " ) return es , nil } 
func NewSimpleWithContext ( ctx context . Context ) * Simple { ctx , cancel := context . WithCancel ( ctx ) l := logrus . New ( ) l . Level = logrus . InfoLevel l . Formatter = & logrus . TextFormatter { } return & Simple { Logger : l , ctx : ctx , cancel : cancel , handlers : map [ string ] Handler { } , moot : & sync . Mutex { } , } } 
func ( w * Simple ) Register ( name string , h Handler ) error { w . moot . Lock ( ) defer w . moot . Unlock ( ) if _ , ok := w . handlers [ name ] ; ok { return fmt . Errorf ( " " , name ) } w . handlers [ name ] = h return nil } 
func ( w * Simple ) Start ( ctx context . Context ) error { w . Logger . Info ( " " ) w . ctx , w . cancel = context . WithCancel ( ctx ) return nil } 
func ( w Simple ) Stop ( ) error { w . Logger . Info ( " " ) w . cancel ( ) return nil } 
func ( w Simple ) Perform ( job Job ) error { w . Logger . Debugf ( " " , job ) if job . Handler == " " { err := fmt . Errorf ( " " , job ) w . Logger . Error ( err ) return err } w . moot . Lock ( ) defer w . moot . Unlock ( ) if h , ok := w . handlers [ job . Handler ] ; ok { go func ( ) { err := safe . RunE ( func ( ) error { return h ( job . Args ) } ) if err != nil { w . Logger . Error ( err ) } w . Logger . Debugf ( " " , job ) } ( ) return nil } err := fmt . Errorf ( " " , job . Handler ) w . Logger . Error ( err ) return err } 
func ( w Simple ) PerformAt ( job Job , t time . Time ) error { return w . PerformIn ( job , time . Until ( t ) ) } 
func ( w Simple ) PerformIn ( job Job , d time . Duration ) error { go func ( ) { select { case <- time . After ( d ) : w . Perform ( job ) case <- w . ctx . Done ( ) : w . cancel ( ) } } ( ) return nil } 
func ( opts * Options ) Validate ( ) error { if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } return nil } 
func ( ri RouteInfo ) String ( ) string { b , _ := json . MarshalIndent ( ri , " " , " " ) return string ( b ) } 
func ( ri * RouteInfo ) Alias ( aliases ... string ) * RouteInfo { ri . Aliases = append ( ri . Aliases , aliases ... ) for _ , a := range aliases { ri . App . router . Handle ( a , ri ) . Methods ( ri . Method ) } return ri } 
func ( ri * RouteInfo ) Name ( name string ) * RouteInfo { routeIndex := - 1 for index , route := range ri . App . Routes ( ) { if route . Path == ri . Path && route . Method == ri . Method { routeIndex = index break } } name = flect . Camelize ( name ) if ! strings . HasSuffix ( name , " " ) { name = name + " " } ri . PathName = name if routeIndex != - 1 { ri . App . Routes ( ) [ routeIndex ] = reflect . ValueOf ( ri ) . Interface ( ) . ( * RouteInfo ) } return ri } 
func ( ri * RouteInfo ) BuildPathHelper ( ) RouteHelperFunc { cRoute := ri return func ( opts map [ string ] interface { } ) ( template . HTML , error ) { pairs := [ ] string { } for k , v := range opts { pairs = append ( pairs , k ) pairs = append ( pairs , fmt . Sprintf ( " " , v ) ) } url , err := cRoute . MuxRoute . URL ( pairs ... ) if err != nil { return " " , errors . Wrapf ( err , " " , cRoute . Path ) } result := url . Path result = addExtraParamsTo ( result , opts ) return template . HTML ( result ) , nil } } 
func ( s * TLS ) SetAddr ( addr string ) { if s . Server . Addr == " " { s . Server . Addr = addr } } 
func ( s * TLS ) Start ( c context . Context , h http . Handler ) error { s . Handler = h return s . ListenAndServeTLS ( s . CertFile , s . KeyFile ) } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } g . Transformer ( genny . Replace ( " " , " " ) ) g . Transformer ( genny . Dot ( ) ) box := packr . New ( " " , " " ) var fname string switch opts . Provider { case " " , " " : fname = " " case " " , " " : if opts . App . WithPop { fname = " " } else { fname = " " } default : return g , fmt . Errorf ( " " , opts . Provider ) } f , err := box . FindString ( fname ) if err != nil { return g , err } g . File ( genny . NewFileS ( fname , f ) ) data := map [ string ] interface { } { " " : opts , } if opts . DBType == " " { data [ " " ] = " " + opts . App . Name . File ( ) . String ( ) + " " } else if opts . DBType == " " { data [ " " ] = " " + opts . App . Name . File ( ) . String ( ) + " " } else { data [ " " ] = " " } helpers := template . FuncMap { } t := gogen . TemplateTransformer ( data , helpers ) g . Transformer ( t ) return g , nil } 
func Download ( ctx context . Context , name string , r io . Reader ) Renderer { return downloadRenderer { ctx : ctx , name : name , reader : r , } } 
func ( e * Engine ) Download ( ctx context . Context , name string , r io . Reader ) Renderer { return Download ( ctx , name , r ) } 
func JavaScript ( names ... string ) Renderer { e := New ( Options { } ) return e . JavaScript ( names ... ) } 
func ( e * Engine ) JavaScript ( names ... string ) Renderer { if e . JavaScriptLayout != " " && len ( names ) == 1 { names = append ( names , e . JavaScriptLayout ) } hr := & templateRenderer { Engine : e , contentType : " " , names : names , } return hr } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } g . RunFn ( construct ( opts ) ) return g , nil } 
func RegisterCustomDecoder ( fn CustomTypeDecoder , types [ ] interface { } , fields [ ] interface { } ) { rawFunc := ( func ( [ ] string ) ( interface { } , error ) ) ( fn ) decoder . RegisterCustomType ( rawFunc , types , fields ) } 
func Register ( contentType string , fn Binder ) { lock . Lock ( ) defer lock . Unlock ( ) binders [ strings . ToLower ( contentType ) ] = fn } 
func Exec ( req * http . Request , value interface { } ) error { if ba , ok := value . ( Bindable ) ; ok { return ba . Bind ( req ) } ct := httpx . ContentType ( req ) if ct == " " { return errors . New ( " " ) } if b , ok := binders [ ct ] ; ok { return b ( req , value ) } return fmt . Errorf ( " " , ct ) } 
func MethodOverride ( res http . ResponseWriter , req * http . Request ) { if req . Method == " " { req . Method = defaults . String ( req . FormValue ( " " ) , " " ) req . Form . Del ( " " ) req . PostForm . Del ( " " ) } } 
func ( ms * MiddlewareStack ) Clear ( ) { ms . stack = [ ] MiddlewareFunc { } ms . skips = map [ string ] bool { } } 
func ( ms * MiddlewareStack ) Use ( mw ... MiddlewareFunc ) { ms . stack = append ( ms . stack , mw ... ) } 
func ( ms * MiddlewareStack ) Skip ( mw MiddlewareFunc , handlers ... Handler ) { for _ , h := range handlers { key := funcKey ( mw , h ) ms . skips [ key ] = true } } 
func ( ms * MiddlewareStack ) Replace ( mw1 MiddlewareFunc , mw2 MiddlewareFunc ) { m1k := funcKey ( mw1 ) stack := [ ] MiddlewareFunc { } for _ , mw := range ms . stack { if funcKey ( mw ) == m1k { stack = append ( stack , mw2 ) } else { stack = append ( stack , mw ) } } ms . stack = stack } 
func ( a * App ) Routes ( ) RouteList { if a . root != nil { return a . root . routes } return a . routes } 
func ( a RouteList ) Lookup ( name string ) ( * RouteInfo , error ) { for _ , ri := range a { if ri . PathName == name { return ri , nil } } return nil , errors . New ( " " ) } 
func WrapBuffaloHandler ( h Handler ) http . Handler { a := New ( Options { } ) return ri } 
func PackageJSONCheck ( r * Runner ) error { fmt . Println ( " " ) if ! r . App . WithWebpack { return nil } box := webpack . Templates f , err := box . FindString ( " " ) if err != nil { return err } tmpl , err := template . New ( " " ) . Parse ( f ) if err != nil { return err } bb := & bytes . Buffer { } err = tmpl . Execute ( bb , map [ string ] interface { } { " " : & webpack . Options { App : r . App , } , } ) if err != nil { return err } b , err := ioutil . ReadFile ( " " ) if err != nil { return err } if string ( b ) == bb . String ( ) { return nil } if ! ask ( " \n " ) { fmt . Println ( " \t " ) return nil } pf , err := os . Create ( " " ) if err != nil { return err } _ , err = pf . Write ( bb . Bytes ( ) ) if err != nil { return err } err = pf . Close ( ) if err != nil { return err } os . RemoveAll ( filepath . Join ( r . App . Root , " " ) ) var cmd * exec . Cmd if r . App . WithYarn { cmd = exec . Command ( " " , " " ) } else { cmd = exec . Command ( " " , " " ) } cmd . Stdin = os . Stdin cmd . Stdout = os . Stdout cmd . Stderr = os . Stderr return cmd . Run ( ) } 
func ( c ImportConverter ) match ( importpath string ) ( string , bool ) { for key , value := range c . Data { if ! strings . HasPrefix ( importpath , key ) { continue } result := strings . Replace ( importpath , key , value , 1 ) return result , true } return importpath , false } 
func ( opts * Options ) Validate ( ) error { if len ( opts . Name ) == 0 { return errors . New ( " " ) } if len ( opts . Actions ) == 0 { return errors . New ( " " ) } if opts . App . IsZero ( ) { opts . App = meta . New ( " " ) } if len ( opts . Method ) == 0 { opts . Method = " " } return nil } 
func ( f SendFunc ) Send ( from string , to [ ] string , msg io . WriterTo ) error { return f ( from , to , msg ) } 
func Send ( s Sender , msg ... * Message ) error { for i , m := range msg { if err := send ( s , m ) ; err != nil { return & SendError { Cause : err , Index : uint ( i ) } } } return nil } 
func ( opts Options ) Last ( n name . Ident ) bool { return opts . Parts [ len ( opts . Parts ) - 1 ] . String ( ) == n . String ( ) } 
func ( opts * Options ) Validate ( ) error { if len ( opts . Args ) == 0 { return errors . New ( " " ) } opts . Namespaced = strings . Contains ( opts . Args [ 0 ] , " " ) for _ , n := range strings . Split ( opts . Args [ 0 ] , " " ) { opts . Parts = append ( opts . Parts , name . New ( n ) ) } opts . Name = opts . Parts [ len ( opts . Parts ) - 1 ] return nil } 
func ( a * App ) Serve ( srvs ... servers . Server ) error { a . Logger . Infof ( " " , a . Options . Addr ) payload := events . Payload { " " : a , } if err := events . EmitPayload ( EvtAppStart , payload ) ; err != nil { return err } if len ( srvs ) == 0 { if strings . HasPrefix ( a . Options . Addr , " " ) { tcp , err := servers . UnixSocket ( a . Options . Addr [ 5 : ] ) if err != nil { return err } srvs = append ( srvs , tcp ) } else { srvs = append ( srvs , servers . New ( ) ) } } ctx , cancel := sigtx . WithCancel ( a . Context , syscall . SIGTERM , os . Interrupt ) defer cancel ( ) go func ( ) { a . Logger . Info ( " " ) events . EmitError ( EvtAppStop , ctx . Err ( ) , payload ) if err := a . Stop ( ctx . Err ( ) ) ; err != nil { events . EmitError ( EvtAppStopErr , err , payload ) a . Logger . Error ( err ) } if ! a . WorkerOff { events . EmitPayload ( EvtWorkerStop , payload ) if err := a . Worker . Stop ( ) ; err != nil { events . EmitError ( EvtWorkerStopErr , err , payload ) a . Logger . Error ( err ) } } for _ , s := range srvs { if err := s . Shutdown ( ctx ) ; err != nil { a . Logger . Error ( err ) } } } ( ) if err := a . Worker . Start ( ctx ) ; err != nil { a . Stop ( err ) } } ( ) } for _ , s := range srvs { s . SetAddr ( a . Addr ) go func ( s servers . Server ) { if err := s . Start ( ctx , a ) ; err != nil { a . Stop ( err ) } } ( s ) } <- ctx . Done ( ) return a . Context . Err ( ) } 
func ( a * App ) Stop ( err error ) error { a . cancel ( ) if err != nil && errors . Cause ( err ) != context . Canceled { a . Logger . Error ( err ) return err } return nil } 
func DepEnsure ( r * Runner ) error { if r . App . WithPop { upkg = append ( upkg , " " , " " ) } if ! r . App . WithDep { fmt . Println ( " " ) return modGetUpdate ( r ) } fmt . Println ( " " ) return runDepEnsure ( r ) } 
func Plain ( names ... string ) Renderer { e := New ( Options { } ) return e . Plain ( names ... ) } 
func ( e * Engine ) Plain ( names ... string ) Renderer { hr := & templateRenderer { Engine : e , contentType : " " , names : names , } return hr } 
func ( b BuildInfo ) String ( ) string { return fmt . Sprintf ( " " , b . Version , b . Time ) } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , err } if ! opts . SkipTemplates { core := packr . New ( " " , " " ) if err := g . Box ( core ) ; err != nil { return g , err } } var abox packd . Box if opts . SkipModel { abox = packr . New ( " " , " " ) } else { abox = packr . New ( " " , " " ) } if err := g . Box ( abox ) ; err != nil { return g , err } pres := presenter { App : opts . App , Name : name . New ( opts . Name ) , Model : name . New ( opts . Model ) , Attrs : opts . Attrs , } x := pres . Name . Resource ( ) . File ( ) . String ( ) folder := pres . Name . Folder ( ) . Pluralize ( ) . String ( ) g . Transformer ( genny . Replace ( " " , x ) ) g . Transformer ( genny . Replace ( " " , x ) ) g . Transformer ( genny . Replace ( " " , folder ) ) data := map [ string ] interface { } { " " : pres , " " : actions ( opts ) , " " : folder , } helpers := template . FuncMap { " " : func ( s string ) string { return flect . Camelize ( s ) } , } g . Transformer ( gogen . TemplateTransformer ( data , helpers ) ) g . RunFn ( installPop ( opts ) ) g . RunFn ( addResource ( pres ) ) return g , nil } 
func ( m * Message ) AddBody ( r render . Renderer , data render . Data ) error { buf := bytes . NewBuffer ( [ ] byte { } ) err := r . Render ( buf , m . merge ( data ) ) if err != nil { return err } m . Bodies = append ( m . Bodies , Body { Content : buf . String ( ) , ContentType : r . ContentType ( ) , } ) return nil } 
func ( m * Message ) AddBodies ( data render . Data , renderers ... render . Renderer ) error { for _ , r := range renderers { err := m . AddBody ( r , data ) if err != nil { return err } } return nil } 
func ( m * Message ) AddAttachment ( name , contentType string , r io . Reader ) error { m . Attachments = append ( m . Attachments , Attachment { Name : name , ContentType : contentType , Reader : r , Embedded : false , } ) return nil } 
func ( m * Message ) AddEmbedded ( name string , r io . Reader ) error { m . Attachments = append ( m . Attachments , Attachment { Name : name , Reader : r , Embedded : true , } ) return nil } 
func ( m * Message ) SetHeader ( field , value string ) { m . Headers [ field ] = value } 
func New ( opts * Options ) ( * genny . Group , error ) { if err := opts . Validate ( ) ; err != nil { return nil , err } gg , err := core . New ( opts . Options ) if err != nil { return gg , err } g := genny . New ( ) g . Transformer ( genny . Dot ( ) ) data := map [ string ] interface { } { " " : opts , } helpers := template . FuncMap { } t := gogen . TemplateTransformer ( data , helpers ) g . Transformer ( t ) g . Box ( packr . New ( " " , " " ) ) gg . Add ( g ) if opts . Webpack != nil { if err != nil { return gg , err } gg . Add ( g ) } if opts . Standard != nil { if err != nil { return gg , err } gg . Add ( g ) } return gg , nil } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) g . Box ( packr . New ( " " , " " ) ) data := map [ string ] interface { } { } h := template . FuncMap { } t := gogen . TemplateTransformer ( data , h ) g . Transformer ( t ) g . RunFn ( func ( r * genny . Runner ) error { f , err := r . FindFile ( " " ) if err != nil { return err } s := strings . Replace ( f . String ( ) , " " , " \n " + bs4 , 1 ) return r . File ( genny . NewFileS ( f . Name ( ) , s ) ) } ) return g , nil } 
func New ( opts * Options ) ( * genny . Generator , error ) { g := genny . New ( ) if err := opts . Validate ( ) ; err != nil { return g , errors . WithStack ( err ) } g . RunFn ( appDetails ( opts ) ) cBox := packr . Folder ( filepath . Join ( opts . App . Root , " " ) ) g . RunFn ( configs ( opts , cBox ) ) aBox := packr . Folder ( opts . App . Root ) g . RunFn ( pkgChecks ( opts , aBox ) ) return g , nil } 
func Cleanup ( opts * Options ) genny . RunFn { return func ( r * genny . Runner ) error { defer os . RemoveAll ( filepath . Join ( opts . Root , " " ) ) if err := jam . Clean ( ) ; err != nil { return err } var err error opts . rollback . Range ( func ( k , v interface { } ) bool { f := genny . NewFileS ( k . ( string ) , v . ( string ) ) r . Logger . Debugf ( " " , f . Name ( ) ) if err = r . File ( f ) ; err != nil { return false } r . Disk . Remove ( f . Name ( ) ) return true } ) if err != nil { return err } for _ , f := range r . Disk . Files ( ) { if err := r . Disk . Delete ( f . Name ( ) ) ; err != nil { return err } } if envy . Mods ( ) { if err := r . Exec ( exec . Command ( genny . GoBin ( ) , " " , " " ) ) ; err != nil { return err } } return nil } } 
func ( opts * Options ) Validate ( ) error { if opts . Options == nil { opts . Options = & core . Options { } } return opts . Options . Validate ( ) } 
func HTML ( names ... string ) Renderer { e := New ( Options { } ) return e . HTML ( names ... ) } 
func ( e * Engine ) HTML ( names ... string ) Renderer { if e . HTMLLayout != " " && len ( names ) == 1 { names = append ( names , e . HTMLLayout ) } hr := & templateRenderer { Engine : e , contentType : " " , names : names , } return hr } 
func MDTemplateEngine ( input string , data map [ string ] interface { } , helpers map [ string ] interface { } ) ( string , error ) { if ct , ok := data [ " " ] . ( string ) ; ok && ct == " " { return plush . BuffaloRenderer ( input , data , helpers ) } source := github_flavored_markdown . Markdown ( [ ] byte ( input ) ) source = [ ] byte ( html . UnescapeString ( string ( source ) ) ) return plush . BuffaloRenderer ( string ( source ) , data , helpers ) } 
func Update ( fg FileGetter , kc corev1 . ConfigMapInterface , name , namespace string , updates [ ] ConfigMapUpdate , logger * logrus . Entry ) error { cm , getErr := kc . Get ( name , metav1 . GetOptions { } ) isNotFound := errors . IsNotFound ( getErr ) if getErr != nil && ! isNotFound { return fmt . Errorf ( " " , getErr ) } if cm == nil || isNotFound { cm = & coreapi . ConfigMap { ObjectMeta : metav1 . ObjectMeta { Name : name , Namespace : namespace , } , } } if cm . Data == nil { cm . Data = map [ string ] string { } } if cm . BinaryData == nil { cm . BinaryData = map [ string ] [ ] byte { } } for _ , upd := range updates { if upd . Filename == " " { logger . WithField ( " " , upd . Key ) . Debug ( " " ) delete ( cm . Data , upd . Key ) delete ( cm . BinaryData , upd . Key ) continue } content , err := fg . GetFile ( upd . Filename ) if err != nil { return fmt . Errorf ( " " , err ) } logger . WithFields ( logrus . Fields { " " : upd . Key , " " : upd . Filename } ) . Debug ( " " ) value := content if upd . GZIP { buff := bytes . NewBuffer ( [ ] byte { } ) if _ , err := z . Write ( content ) ; err != nil { logger . WithError ( err ) . Error ( " " ) } else { if err := z . Close ( ) ; err != nil { logger . WithError ( err ) . Error ( " " ) } else { value = buff . Bytes ( ) } } } if utf8 . ValidString ( string ( value ) ) { delete ( cm . BinaryData , upd . Key ) cm . Data [ upd . Key ] = string ( value ) } else { delete ( cm . Data , upd . Key ) cm . BinaryData [ upd . Key ] = value } } var updateErr error var verb string if getErr != nil && isNotFound { verb = " " _ , updateErr = kc . Create ( cm ) } else { verb = " " _ , updateErr = kc . Update ( cm ) } if updateErr != nil { return fmt . Errorf ( " " , verb , updateErr ) } return nil } 
func FilterChanges ( cfg plugins . ConfigUpdater , changes [ ] github . PullRequestChange , log * logrus . Entry ) map [ ConfigMapID ] [ ] ConfigMapUpdate { toUpdate := map [ ConfigMapID ] [ ] ConfigMapUpdate { } for _ , change := range changes { var cm plugins . ConfigMapSpec found := false for key , configMap := range cfg . Maps { var matchErr error found , matchErr = zglob . Match ( key , change . Filename ) if matchErr != nil { continue } if found { cm = configMap break } } if ! found { continue } key := cm . Key if key == " " { key = path . Base ( change . Filename ) } } if change . Status == github . PullRequestFileRemoved { toUpdate [ id ] = append ( toUpdate [ id ] , ConfigMapUpdate { Key : key } ) } else { gzip := cfg . GZIP if cm . GZIP != nil { gzip = * cm . GZIP } toUpdate [ id ] = append ( toUpdate [ id ] , ConfigMapUpdate { Key : key , Filename : change . Filename , GZIP : gzip } ) } } } return toUpdate } 
func getLabelsFromREMatches ( matches [ ] [ ] string ) ( labels [ ] string ) { for _ , match := range matches { for _ , label := range strings . Split ( match [ 0 ] , " " ) [ 1 : ] { label = strings . ToLower ( match [ 1 ] + " " + strings . TrimSpace ( label ) ) labels = append ( labels , label ) } } return } 
func getLabelsFromGenericMatches ( matches [ ] [ ] string , additionalLabels [ ] string ) [ ] string { if len ( additionalLabels ) == 0 { return nil } var labels [ ] string for _ , match := range matches { parts := strings . Split ( match [ 0 ] , " " ) if ( ( parts [ 0 ] != " " ) && ( parts [ 0 ] != " " ) ) || len ( parts ) != 2 { continue } for _ , l := range additionalLabels { if l == parts [ 1 ] { labels = append ( labels , parts [ 1 ] ) } } } return labels } 
func ( ca * Agent ) Start ( prowConfig , jobConfig string ) error { c , err := Load ( prowConfig , jobConfig ) if err != nil { return err } ca . Set ( c ) go func ( ) { var lastModTime time . Time for range time . Tick ( 1 * time . Second ) { if skips < 600 { if err != nil { logrus . WithField ( " " , prowConfig ) . WithError ( err ) . Error ( " " ) continue } recentModTime := prowStat . ModTime ( ) if err != nil { logrus . WithField ( " " , jobConfig ) . WithError ( err ) . Error ( " " ) continue } if jobConfigStat . ModTime ( ) . After ( recentModTime ) { recentModTime = jobConfigStat . ModTime ( ) } } if ! recentModTime . After ( lastModTime ) { skips ++ continue } lastModTime = recentModTime } if c , err := Load ( prowConfig , jobConfig ) ; err != nil { logrus . WithField ( " " , prowConfig ) . WithField ( " " , jobConfig ) . WithError ( err ) . Error ( " " ) } else { skips = 0 ca . Set ( c ) } } } ( ) return nil } 
func ( ca * Agent ) Subscribe ( subscription DeltaChan ) { ca . mut . Lock ( ) defer ca . mut . Unlock ( ) ca . subscriptions = append ( ca . subscriptions , subscription ) } 
func ( ca * Agent ) Config ( ) * Config { ca . mut . RLock ( ) defer ca . mut . RUnlock ( ) return ca . c } 
func ( ca * Agent ) Set ( c * Config ) { ca . mut . Lock ( ) defer ca . mut . Unlock ( ) var oldConfig Config if ca . c != nil { oldConfig = * ca . c } delta := Delta { oldConfig , * c } ca . c = c for _ , subscription := range ca . subscriptions { go func ( sub DeltaChan ) { select { case sub <- delta : case <- end . C : } if ! end . Stop ( ) { } } ( subscription ) } } 
func ( f * FakeClient ) IsMember ( org , user string ) ( bool , error ) { for _ , m := range f . OrgMembers [ org ] { if m == user { return true , nil } } return false , nil } 
func ( f * FakeClient ) ListIssueComments ( owner , repo string , number int ) ( [ ] github . IssueComment , error ) { return append ( [ ] github . IssueComment { } , f . IssueComments [ number ] ... ) , nil } 
func ( f * FakeClient ) ListPullRequestComments ( owner , repo string , number int ) ( [ ] github . ReviewComment , error ) { return append ( [ ] github . ReviewComment { } , f . PullRequestComments [ number ] ... ) , nil } 
func ( f * FakeClient ) ListReviews ( owner , repo string , number int ) ( [ ] github . Review , error ) { return append ( [ ] github . Review { } , f . Reviews [ number ] ... ) , nil } 
func ( f * FakeClient ) ListIssueEvents ( owner , repo string , number int ) ( [ ] github . ListedIssueEvent , error ) { return append ( [ ] github . ListedIssueEvent { } , f . IssueEvents [ number ] ... ) , nil } 
func ( f * FakeClient ) CreateComment ( owner , repo string , number int , comment string ) error { f . IssueCommentsAdded = append ( f . IssueCommentsAdded , fmt . Sprintf ( " " , owner , repo , number , comment ) ) f . IssueComments [ number ] = append ( f . IssueComments [ number ] , github . IssueComment { ID : f . IssueCommentID , Body : comment , User : github . User { Login : botName } , } ) f . IssueCommentID ++ return nil } 
func ( f * FakeClient ) CreateReview ( org , repo string , number int , r github . DraftReview ) error { f . Reviews [ number ] = append ( f . Reviews [ number ] , github . Review { ID : f . ReviewID , User : github . User { Login : botName } , Body : r . Body , } ) f . ReviewID ++ return nil } 
func ( f * FakeClient ) CreateCommentReaction ( org , repo string , ID int , reaction string ) error { f . CommentReactionsAdded = append ( f . CommentReactionsAdded , fmt . Sprintf ( " " , org , repo , ID , reaction ) ) return nil } 
func ( f * FakeClient ) CreateIssueReaction ( org , repo string , ID int , reaction string ) error { f . IssueReactionsAdded = append ( f . IssueReactionsAdded , fmt . Sprintf ( " " , org , repo , ID , reaction ) ) return nil } 
func ( f * FakeClient ) DeleteComment ( owner , repo string , ID int ) error { f . IssueCommentsDeleted = append ( f . IssueCommentsDeleted , fmt . Sprintf ( " " , owner , repo , ID ) ) for num , ics := range f . IssueComments { for i , ic := range ics { if ic . ID == ID { f . IssueComments [ num ] = append ( ics [ : i ] , ics [ i + 1 : ] ... ) return nil } } } return fmt . Errorf ( " " , ID ) } 
func ( f * FakeClient ) DeleteStaleComments ( org , repo string , number int , comments [ ] github . IssueComment , isStale func ( github . IssueComment ) bool ) error { if comments == nil { comments , _ = f . ListIssueComments ( org , repo , number ) } for _ , comment := range comments { if isStale ( comment ) { if err := f . DeleteComment ( org , repo , comment . ID ) ; err != nil { return fmt . Errorf ( " " , comment . ID ) } } } return nil } 
func ( f * FakeClient ) GetPullRequest ( owner , repo string , number int ) ( * github . PullRequest , error ) { val , exists := f . PullRequests [ number ] if ! exists { return nil , fmt . Errorf ( " " , number ) } return val , nil } 
func ( f * FakeClient ) GetPullRequestChanges ( org , repo string , number int ) ( [ ] github . PullRequestChange , error ) { return f . PullRequestChanges [ number ] , nil } 
func ( f * FakeClient ) GetRef ( owner , repo , ref string ) ( string , error ) { return TestRef , nil } 
func ( f * FakeClient ) DeleteRef ( owner , repo , ref string ) error { f . RefsDeleted = append ( f . RefsDeleted , struct { Org , Repo , Ref string } { Org : owner , Repo : repo , Ref : ref } ) return nil } 
func ( f * FakeClient ) GetSingleCommit ( org , repo , SHA string ) ( github . SingleCommit , error ) { return f . Commits [ SHA ] , nil } 
func ( f * FakeClient ) CreateStatus ( owner , repo , SHA string , s github . Status ) error { if f . CreatedStatuses == nil { f . CreatedStatuses = make ( map [ string ] [ ] github . Status ) } statuses := f . CreatedStatuses [ SHA ] var updated bool for i := range statuses { if statuses [ i ] . Context == s . Context { statuses [ i ] = s updated = true } } if ! updated { statuses = append ( statuses , s ) } f . CreatedStatuses [ SHA ] = statuses return nil } 
func ( f * FakeClient ) ListStatuses ( org , repo , ref string ) ( [ ] github . Status , error ) { return f . CreatedStatuses [ ref ] , nil } 
func ( f * FakeClient ) GetCombinedStatus ( owner , repo , ref string ) ( * github . CombinedStatus , error ) { return f . CombinedStatuses [ ref ] , nil } 
func ( f * FakeClient ) GetRepoLabels ( owner , repo string ) ( [ ] github . Label , error ) { la := [ ] github . Label { } for _ , l := range f . RepoLabelsExisting { la = append ( la , github . Label { Name : l } ) } return la , nil } 
func ( f * FakeClient ) GetIssueLabels ( owner , repo string , number int ) ( [ ] github . Label , error ) { re := regexp . MustCompile ( fmt . Sprintf ( `^%s/%s#%d:(.*)$` , owner , repo , number ) ) la := [ ] github . Label { } allLabels := sets . NewString ( f . IssueLabelsExisting ... ) allLabels . Insert ( f . IssueLabelsAdded ... ) allLabels . Delete ( f . IssueLabelsRemoved ... ) for _ , l := range allLabels . List ( ) { groups := re . FindStringSubmatch ( l ) if groups != nil { la = append ( la , github . Label { Name : groups [ 1 ] } ) } } return la , nil } 
func ( f * FakeClient ) AddLabel ( owner , repo string , number int , label string ) error { labelString := fmt . Sprintf ( " " , owner , repo , number , label ) if sets . NewString ( f . IssueLabelsAdded ... ) . Has ( labelString ) { return fmt . Errorf ( " " , label , owner , repo , number ) } if f . RepoLabelsExisting == nil { f . IssueLabelsAdded = append ( f . IssueLabelsAdded , labelString ) return nil } for _ , l := range f . RepoLabelsExisting { if label == l { f . IssueLabelsAdded = append ( f . IssueLabelsAdded , labelString ) return nil } } return fmt . Errorf ( " " , label , owner , repo , number ) } 
func ( f * FakeClient ) RemoveLabel ( owner , repo string , number int , label string ) error { labelString := fmt . Sprintf ( " " , owner , repo , number , label ) if ! sets . NewString ( f . IssueLabelsRemoved ... ) . Has ( labelString ) { f . IssueLabelsRemoved = append ( f . IssueLabelsRemoved , labelString ) return nil } return fmt . Errorf ( " " , label , owner , repo , number ) } 
func ( f * FakeClient ) FindIssues ( query , sort string , asc bool ) ( [ ] github . Issue , error ) { return f . Issues , nil } 
func ( f * FakeClient ) AssignIssue ( owner , repo string , number int , assignees [ ] string ) error { var m github . MissingUsers for _ , a := range assignees { if a == " " { m . Users = append ( m . Users , a ) continue } f . AssigneesAdded = append ( f . AssigneesAdded , fmt . Sprintf ( " " , owner , repo , number , a ) ) } if m . Users == nil { return nil } return m } 
func ( f * FakeClient ) GetFile ( org , repo , file , commit string ) ( [ ] byte , error ) { contents , ok := f . RemoteFiles [ file ] if ! ok { return nil , fmt . Errorf ( " " , file ) } if commit == " " { if master , ok := contents [ " " ] ; ok { return [ ] byte ( master ) , nil } return nil , fmt . Errorf ( " " , file ) } if content , ok := contents [ commit ] ; ok { return [ ] byte ( content ) , nil } return nil , fmt . Errorf ( " " , file , commit ) } 
func ( f * FakeClient ) ListTeams ( org string ) ( [ ] github . Team , error ) { return [ ] github . Team { { ID : 0 , Name : " " , } , { ID : 42 , Name : " " , } , } , nil } 
func ( f * FakeClient ) ListTeamMembers ( teamID int , role string ) ( [ ] github . TeamMember , error ) { if role != github . RoleAll { return nil , fmt . Errorf ( " " , role ) } teams := map [ int ] [ ] github . TeamMember { 0 : { { Login : " " } } , 42 : { { Login : " " } } , } members , ok := teams [ teamID ] if ! ok { return [ ] github . TeamMember { } , nil } return members , nil } 
func ( f * FakeClient ) IsCollaborator ( org , repo , login string ) ( bool , error ) { normed := github . NormLogin ( login ) for _ , collab := range f . Collaborators { if github . NormLogin ( collab ) == normed { return true , nil } } return false , nil } 
func ( f * FakeClient ) ListCollaborators ( org , repo string ) ( [ ] github . User , error ) { result := make ( [ ] github . User , 0 , len ( f . Collaborators ) ) for _ , login := range f . Collaborators { result = append ( result , github . User { Login : login } ) } return result , nil } 
func ( f * FakeClient ) ClearMilestone ( org , repo string , issueNum int ) error { f . Milestone = 0 return nil } 
func ( f * FakeClient ) SetMilestone ( org , repo string , issueNum , milestoneNum int ) error { if milestoneNum < 0 { return fmt . Errorf ( " " ) } f . Milestone = milestoneNum return nil } 
func ( f * FakeClient ) ListMilestones ( org , repo string ) ( [ ] github . Milestone , error ) { milestones := [ ] github . Milestone { } for k , v := range f . MilestoneMap { milestones = append ( milestones , github . Milestone { Title : k , Number : v } ) } return milestones , nil } 
func ( f * FakeClient ) ListPRCommits ( org , repo string , prNumber int ) ( [ ] github . RepositoryCommit , error ) { k := fmt . Sprintf ( " " , org , repo , prNumber ) return f . CommitMap [ k ] , nil } 
func ( f * FakeClient ) GetRepoProjects ( owner , repo string ) ( [ ] github . Project , error ) { return f . RepoProjects [ fmt . Sprintf ( " " , owner , repo ) ] , nil } 
func ( f * FakeClient ) GetOrgProjects ( org string ) ( [ ] github . Project , error ) { return f . RepoProjects [ fmt . Sprintf ( " " , org ) ] , nil } 
func ( f * FakeClient ) GetProjectColumns ( projectID int ) ( [ ] github . ProjectColumn , error ) { } } } return nil , fmt . Errorf ( " " ) } 
func ( f * FakeClient ) CreateProjectCard ( columnID int , projectCard github . ProjectCard ) ( * github . ProjectCard , error ) { if f . ColumnCardsMap == nil { f . ColumnCardsMap = make ( map [ int ] [ ] github . ProjectCard ) } for project , columnIDMap := range f . ColumnIDMap { columnName , exists := columnIDMap [ columnID ] if exists { f . ColumnCardsMap [ columnID ] = append ( f . ColumnCardsMap [ columnID ] , projectCard , ) f . Column = columnName f . Project = project return & projectCard , nil } } return nil , fmt . Errorf ( " " , columnID , f . ColumnIDMap ) } 
func ( f * FakeClient ) DeleteProjectCard ( projectCardID int ) error { if f . ColumnCardsMap == nil { return fmt . Errorf ( " " ) } f . Project = " " f . Column = " " newCards := [ ] github . ProjectCard { } oldColumnID := - 1 for column , cards := range f . ColumnCardsMap { removalIndex := - 1 for i , existingCard := range cards { if existingCard . ContentID == projectCardID { oldColumnID = column removalIndex = i break } } if removalIndex != - 1 { newCards = cards newCards [ removalIndex ] = newCards [ len ( newCards ) - 1 ] newCards = newCards [ : len ( newCards ) - 1 ] break } } } return nil } 
func ( f * FakeClient ) MoveProjectCard ( projectCardID int , newColumnID int ) error { oldColumnID := - 1 projectCard := github . ProjectCard { } for column , cards := range f . ColumnCardsMap { removalIndex := - 1 for i , existingCard := range cards { if existingCard . ContentID == projectCardID { oldColumnID = column removalIndex = i projectCard = existingCard break } } if removalIndex != - 1 { newCards = cards newCards [ removalIndex ] = newCards [ len ( newCards ) - 1 ] newCards = newCards [ : len ( newCards ) - 1 ] } } if oldColumnID != - 1 { } for project , columnIDMap := range f . ColumnIDMap { if columnName , exists := columnIDMap [ newColumnID ] ; exists { f . Column = columnName f . Project = project break } } return nil } 
func ( f * FakeClient ) TeamHasMember ( teamID int , memberLogin string ) ( bool , error ) { teamMembers , _ := f . ListTeamMembers ( teamID , github . RoleAll ) for _ , member := range teamMembers { if member . Login == memberLogin { return true , nil } } return false , nil } 
func ( config * InfluxConfig ) AddFlags ( cmd * cobra . Command ) { cmd . PersistentFlags ( ) . StringVar ( & config . User , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & config . Password , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & config . Host , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & config . DB , " " , " " , " " ) } 
func ( config * InfluxConfig ) CreateDatabaseClient ( ) ( * InfluxDB , error ) { client , err := influxdb . NewHTTPClient ( influxdb . HTTPConfig { Addr : config . Host , Username : config . User , Password : config . Password , } ) if err != nil { return nil , err } return & InfluxDB { client : client , database : config . DB , } , nil } 
func ( i * InfluxDB ) Push ( measurement string , tags map [ string ] string , fields map [ string ] interface { } , date time . Time ) error { batch , err := influxdb . NewBatchPoints ( influxdb . BatchPointsConfig { Database : i . database , Precision : " " , } ) if err != nil { return err } pt , err := influxdb . NewPoint ( measurement , tags , fields , date ) if err != nil { return err } batch . AddPoint ( pt ) err = i . client . Write ( batch ) if err != nil { return err } glog . Infof ( " " , measurement , tags , fields , date ) return nil } 
func NewProwJobWithAnnotation ( spec prowapi . ProwJobSpec , labels , annotations map [ string ] string ) prowapi . ProwJob { return newProwJob ( spec , labels , annotations ) } 
func NewProwJob ( spec prowapi . ProwJobSpec , labels map [ string ] string ) prowapi . ProwJob { return newProwJob ( spec , labels , nil ) } 
func NewPresubmit ( pr github . PullRequest , baseSHA string , job config . Presubmit , eventGUID string ) prowapi . ProwJob { refs := createRefs ( pr , baseSHA ) labels := make ( map [ string ] string ) for k , v := range job . Labels { labels [ k ] = v } labels [ github . EventGUID ] = eventGUID return NewProwJob ( PresubmitSpec ( job , refs ) , labels ) } 
func PresubmitSpec ( p config . Presubmit , refs prowapi . Refs ) prowapi . ProwJobSpec { pjs := specFromJobBase ( p . JobBase ) pjs . Type = prowapi . PresubmitJob pjs . Context = p . Context pjs . Report = ! p . SkipReport pjs . RerunCommand = p . RerunCommand if p . JenkinsSpec != nil { pjs . JenkinsSpec = & prowapi . JenkinsSpec { GitHubBranchSourceJob : p . JenkinsSpec . GitHubBranchSourceJob , } } pjs . Refs = completePrimaryRefs ( refs , p . JobBase ) return pjs } 
func PostsubmitSpec ( p config . Postsubmit , refs prowapi . Refs ) prowapi . ProwJobSpec { pjs := specFromJobBase ( p . JobBase ) pjs . Type = prowapi . PostsubmitJob pjs . Context = p . Context pjs . Report = ! p . SkipReport pjs . Refs = completePrimaryRefs ( refs , p . JobBase ) if p . JenkinsSpec != nil { pjs . JenkinsSpec = & prowapi . JenkinsSpec { GitHubBranchSourceJob : p . JenkinsSpec . GitHubBranchSourceJob , } } return pjs } 
func PeriodicSpec ( p config . Periodic ) prowapi . ProwJobSpec { pjs := specFromJobBase ( p . JobBase ) pjs . Type = prowapi . PeriodicJob return pjs } 
func BatchSpec ( p config . Presubmit , refs prowapi . Refs ) prowapi . ProwJobSpec { pjs := specFromJobBase ( p . JobBase ) pjs . Type = prowapi . BatchJob pjs . Context = p . Context pjs . Refs = completePrimaryRefs ( refs , p . JobBase ) return pjs } 
func PartitionActive ( pjs [ ] prowapi . ProwJob ) ( pending , triggered chan prowapi . ProwJob ) { for _ , pj := range pjs { switch pj . Status . State { case prowapi . PendingState : pendingCount ++ case prowapi . TriggeredState : triggeredCount ++ } } pending = make ( chan prowapi . ProwJob , pendingCount ) triggered = make ( chan prowapi . ProwJob , triggeredCount ) case prowapi . TriggeredState : triggered <- pj } } close ( pending ) close ( triggered ) return pending , triggered } 
func ProwJobFields ( pj * prowapi . ProwJob ) logrus . Fields { fields := make ( logrus . Fields ) fields [ " " ] = pj . ObjectMeta . Name fields [ " " ] = pj . Spec . Job fields [ " " ] = pj . Spec . Type if len ( pj . ObjectMeta . Labels [ github . EventGUID ] ) > 0 { fields [ github . EventGUID ] = pj . ObjectMeta . Labels [ github . EventGUID ] } if pj . Spec . Refs != nil && len ( pj . Spec . Refs . Pulls ) == 1 { fields [ github . PrLogField ] = pj . Spec . Refs . Pulls [ 0 ] . Number fields [ github . RepoLogField ] = pj . Spec . Refs . Repo fields [ github . OrgLogField ] = pj . Spec . Refs . Org } if pj . Spec . JenkinsSpec != nil { fields [ " " ] = pj . Spec . JenkinsSpec . GitHubBranchSourceJob } return fields } 
func JobURL ( plank config . Plank , pj prowapi . ProwJob , log * logrus . Entry ) string { if pj . Spec . DecorationConfig != nil && plank . GetJobURLPrefix ( pj . Spec . Refs ) != " " { spec := downwardapi . NewJobSpec ( pj . Spec , pj . Status . BuildID , pj . Name ) gcsConfig := pj . Spec . DecorationConfig . GCSConfiguration _ , gcsPath , _ := gcsupload . PathsForJob ( gcsConfig , & spec , " " ) prefix , _ := url . Parse ( plank . GetJobURLPrefix ( pj . Spec . Refs ) ) prefix . Path = path . Join ( prefix . Path , gcsConfig . Bucket , gcsPath ) return prefix . String ( ) } var b bytes . Buffer if err := plank . JobURLTemplate . Execute ( & b , & pj ) ; err != nil { log . WithFields ( ProwJobFields ( & pj ) ) . Errorf ( " " , err ) } else { return b . String ( ) } return " " } 
func ClusterToCtx ( cluster string ) string { if cluster == kube . InClusterContext { return kube . DefaultClusterAlias } return cluster } 
func ( pluginHelp * PluginHelp ) AddCommand ( command Command ) { pluginHelp . Commands = append ( pluginHelp . Commands , command ) } 
func ( c * FakeProwJobs ) Get ( name string , options v1 . GetOptions ) ( result * prowjobsv1 . ProwJob , err error ) { obj , err := c . Fake . Invokes ( testing . NewGetAction ( prowjobsResource , c . ns , name ) , & prowjobsv1 . ProwJob { } ) if obj == nil { return nil , err } return obj . ( * prowjobsv1 . ProwJob ) , err } 
func ( c * FakeProwJobs ) List ( opts v1 . ListOptions ) ( result * prowjobsv1 . ProwJobList , err error ) { obj , err := c . Fake . Invokes ( testing . NewListAction ( prowjobsResource , prowjobsKind , c . ns , opts ) , & prowjobsv1 . ProwJobList { } ) if obj == nil { return nil , err } label , _ , _ := testing . ExtractFromListOptions ( opts ) if label == nil { label = labels . Everything ( ) } list := & prowjobsv1 . ProwJobList { ListMeta : obj . ( * prowjobsv1 . ProwJobList ) . ListMeta } for _ , item := range obj . ( * prowjobsv1 . ProwJobList ) . Items { if label . Matches ( labels . Set ( item . Labels ) ) { list . Items = append ( list . Items , item ) } } return list , err } 
func ( c * FakeProwJobs ) Watch ( opts v1 . ListOptions ) ( watch . Interface , error ) { return c . Fake . InvokesWatch ( testing . NewWatchAction ( prowjobsResource , c . ns , opts ) ) } 
func ( c * FakeProwJobs ) Create ( prowJob * prowjobsv1 . ProwJob ) ( result * prowjobsv1 . ProwJob , err error ) { obj , err := c . Fake . Invokes ( testing . NewCreateAction ( prowjobsResource , c . ns , prowJob ) , & prowjobsv1 . ProwJob { } ) if obj == nil { return nil , err } return obj . ( * prowjobsv1 . ProwJob ) , err } 
func ( c * FakeProwJobs ) Update ( prowJob * prowjobsv1 . ProwJob ) ( result * prowjobsv1 . ProwJob , err error ) { obj , err := c . Fake . Invokes ( testing . NewUpdateAction ( prowjobsResource , c . ns , prowJob ) , & prowjobsv1 . ProwJob { } ) if obj == nil { return nil , err } return obj . ( * prowjobsv1 . ProwJob ) , err } 
func ( c * FakeProwJobs ) UpdateStatus ( prowJob * prowjobsv1 . ProwJob ) ( * prowjobsv1 . ProwJob , error ) { obj , err := c . Fake . Invokes ( testing . NewUpdateSubresourceAction ( prowjobsResource , " " , c . ns , prowJob ) , & prowjobsv1 . ProwJob { } ) if obj == nil { return nil , err } return obj . ( * prowjobsv1 . ProwJob ) , err } 
func ( c * FakeProwJobs ) Delete ( name string , options * v1 . DeleteOptions ) error { _ , err := c . Fake . Invokes ( testing . NewDeleteAction ( prowjobsResource , c . ns , name ) , & prowjobsv1 . ProwJob { } ) return err } 
func ( c * FakeProwJobs ) DeleteCollection ( options * v1 . DeleteOptions , listOptions v1 . ListOptions ) error { action := testing . NewDeleteCollectionAction ( prowjobsResource , c . ns , listOptions ) _ , err := c . Fake . Invokes ( action , & prowjobsv1 . ProwJobList { } ) return err } 
func ( c * FakeProwJobs ) Patch ( name string , pt types . PatchType , data [ ] byte , subresources ... string ) ( result * prowjobsv1 . ProwJob , err error ) { obj , err := c . Fake . Invokes ( testing . NewPatchSubresourceAction ( prowjobsResource , c . ns , name , data , subresources ... ) , & prowjobsv1 . ProwJob { } ) if obj == nil { return nil , err } return obj . ( * prowjobsv1 . ProwJob ) , err } 
func ( t * Tide ) MergeMethod ( org , repo string ) github . PullRequestMergeType { name := org + " " + repo v , ok := t . MergeType [ name ] if ! ok { if ov , found := t . MergeType [ org ] ; found { return ov } return github . MergeMerge } return v } 
func ( t * Tide ) MergeCommitTemplate ( org , repo string ) TideMergeCommitTemplate { name := org + " " + repo v , ok := t . MergeTemplate [ name ] if ! ok { return t . MergeTemplate [ org ] } return v } 
func ( tq * TideQuery ) Query ( ) string { toks := [ ] string { " " , " " } for _ , o := range tq . Orgs { toks = append ( toks , fmt . Sprintf ( " \" \" " , o ) ) } for _ , r := range tq . Repos { toks = append ( toks , fmt . Sprintf ( " \" \" " , r ) ) } for _ , r := range tq . ExcludedRepos { toks = append ( toks , fmt . Sprintf ( " \" \" " , r ) ) } for _ , b := range tq . ExcludedBranches { toks = append ( toks , fmt . Sprintf ( " \" \" " , b ) ) } for _ , b := range tq . IncludedBranches { toks = append ( toks , fmt . Sprintf ( " \" \" " , b ) ) } for _ , l := range tq . Labels { toks = append ( toks , fmt . Sprintf ( " \" \" " , l ) ) } for _ , l := range tq . MissingLabels { toks = append ( toks , fmt . Sprintf ( " \" \" " , l ) ) } if tq . Milestone != " " { toks = append ( toks , fmt . Sprintf ( " \" \" " , tq . Milestone ) ) } if tq . ReviewApprovedRequired { toks = append ( toks , " " ) } return strings . Join ( toks , " " ) } 
func ( tq TideQuery ) ForRepo ( org , repo string ) bool { fullName := fmt . Sprintf ( " " , org , repo ) for _ , queryOrg := range tq . Orgs { if queryOrg != org { continue } } } return true } for _ , queryRepo := range tq . Repos { if queryRepo == fullName { return true } } return false } 
func ( tqs TideQueries ) OrgExceptionsAndRepos ( ) ( map [ string ] sets . String , sets . String ) { orgs := make ( map [ string ] sets . String ) for i := range tqs { for _ , org := range tqs [ i ] . Orgs { applicableRepos := sets . NewString ( reposInOrg ( org , tqs [ i ] . ExcludedRepos ) ... ) if excepts , ok := orgs [ org ] ; ! ok { } else { } } } repos := sets . NewString ( ) for i := range tqs { repos . Insert ( tqs [ i ] . Repos ... ) } for _ , excepts := range orgs { excepts . Delete ( reposList ... ) } return orgs , repos } 
func ( tqs TideQueries ) QueryMap ( ) * QueryMap { return & QueryMap { queries : tqs , cache : make ( map [ string ] TideQueries ) , } } 
func ( qm * QueryMap ) ForRepo ( org , repo string ) TideQueries { res := TideQueries ( nil ) fullName := fmt . Sprintf ( " " , org , repo ) qm . Lock ( ) defer qm . Unlock ( ) if qs , ok := qm . cache [ fullName ] ; ok { return append ( res , qs ... ) } } } qm . cache [ fullName ] = res return res } 
func ( tq * TideQuery ) Validate ( ) error { duplicates := func ( field string , list [ ] string ) error { dups := sets . NewString ( ) seen := sets . NewString ( ) for _ , elem := range list { if seen . Has ( elem ) { dups . Insert ( elem ) } else { seen . Insert ( elem ) } } dupCount := len ( list ) - seen . Len ( ) if dupCount == 0 { return nil } return fmt . Errorf ( " " , field , dupCount , strings . Join ( dups . List ( ) , " " ) ) } orgs := sets . NewString ( ) for o := range tq . Orgs { if strings . Contains ( tq . Orgs [ o ] , " " ) { return fmt . Errorf ( " " , o , tq . Orgs [ o ] ) } if len ( tq . Orgs [ o ] ) == 0 { return fmt . Errorf ( " " , o ) } orgs . Insert ( tq . Orgs [ o ] ) } if err := duplicates ( " " , tq . Orgs ) ; err != nil { return err } for r := range tq . Repos { parts := strings . Split ( tq . Repos [ r ] , " " ) if len ( parts ) != 2 || len ( parts [ 0 ] ) == 0 || len ( parts [ 1 ] ) == 0 { return fmt . Errorf ( " \" \" " , r , tq . Repos [ r ] ) } if orgs . Has ( parts [ 0 ] ) { return fmt . Errorf ( " " , r , tq . Repos [ r ] , parts [ 0 ] ) } } if err := duplicates ( " " , tq . Repos ) ; err != nil { return err } if len ( tq . Orgs ) == 0 && len ( tq . Repos ) == 0 { return errors . New ( " " ) } for er := range tq . ExcludedRepos { parts := strings . Split ( tq . ExcludedRepos [ er ] , " " ) if len ( parts ) != 2 || len ( parts [ 0 ] ) == 0 || len ( parts [ 1 ] ) == 0 { return fmt . Errorf ( " \" \" " , er , tq . ExcludedRepos [ er ] ) } if ! orgs . Has ( parts [ 0 ] ) { return fmt . Errorf ( " " , er , tq . ExcludedRepos [ er ] , parts [ 0 ] ) } if err := duplicates ( " " , tq . ExcludedRepos ) ; err != nil { return err } if invalids := sets . NewString ( tq . Labels ... ) . Intersection ( sets . NewString ( tq . MissingLabels ... ) ) ; len ( invalids ) > 0 { return fmt . Errorf ( " " , invalids . List ( ) ) } if err := duplicates ( " " , tq . Labels ) ; err != nil { return err } if err := duplicates ( " " , tq . MissingLabels ) ; err != nil { return err } if len ( tq . ExcludedBranches ) > 0 && len ( tq . IncludedBranches ) > 0 { return errors . New ( " " ) } if err := duplicates ( " " , tq . IncludedBranches ) ; err != nil { return err } if err := duplicates ( " " , tq . ExcludedBranches ) ; err != nil { return err } return nil } 
func ( cp * TideContextPolicy ) Validate ( ) error { if inter := sets . NewString ( cp . RequiredContexts ... ) . Intersection ( sets . NewString ( cp . OptionalContexts ... ) ) ; inter . Len ( ) > 0 { return fmt . Errorf ( " " , strings . Join ( inter . List ( ) , " " ) ) } if inter := sets . NewString ( cp . RequiredContexts ... ) . Intersection ( sets . NewString ( cp . RequiredIfPresentContexts ... ) ) ; inter . Len ( ) > 0 { return fmt . Errorf ( " " , strings . Join ( inter . List ( ) , " " ) ) } if inter := sets . NewString ( cp . OptionalContexts ... ) . Intersection ( sets . NewString ( cp . RequiredIfPresentContexts ... ) ) ; inter . Len ( ) > 0 { return fmt . Errorf ( " " , strings . Join ( inter . List ( ) , " " ) ) } return nil } 
func ( c Config ) GetTideContextPolicy ( org , repo , branch string ) ( * TideContextPolicy , error ) { options := parseTideContextPolicyOptions ( org , repo , branch , c . Tide . ContextOptions ) requiredIfPresent := sets . NewString ( options . RequiredIfPresentContexts ... ) optional := sets . NewString ( options . OptionalContexts ... ) required . Insert ( prowRequired ... ) requiredIfPresent . Insert ( prowRequiredIfPresent ... ) optional . Insert ( prowOptional ... ) if err != nil { logrus . WithError ( err ) . Warningf ( " " , org , repo , branch ) } else if bp != nil && bp . Protect != nil && * bp . Protect && bp . RequiredStatusChecks != nil { required . Insert ( bp . RequiredStatusChecks . Contexts ... ) } } t := & TideContextPolicy { RequiredContexts : required . List ( ) , RequiredIfPresentContexts : requiredIfPresent . List ( ) , OptionalContexts : optional . List ( ) , SkipUnknownContexts : options . SkipUnknownContexts , } if err := t . Validate ( ) ; err != nil { return t , err } return t , nil } 
func ( cp * TideContextPolicy ) IsOptional ( c string ) bool { if sets . NewString ( cp . OptionalContexts ... ) . Has ( c ) { return true } if sets . NewString ( cp . RequiredContexts ... ) . Has ( c ) { return false } } if cp . SkipUnknownContexts != nil && * cp . SkipUnknownContexts { return true } return false } 
func ( cp * TideContextPolicy ) MissingRequiredContexts ( contexts [ ] string ) [ ] string { if len ( cp . RequiredContexts ) == 0 { return nil } existingContexts := sets . NewString ( ) for _ , c := range contexts { existingContexts . Insert ( c ) } var missingContexts [ ] string for c := range sets . NewString ( cp . RequiredContexts ... ) . Difference ( existingContexts ) { missingContexts = append ( missingContexts , c ) } return missingContexts } 
func ValidateWebhook ( w http . ResponseWriter , r * http . Request , hmacSecret [ ] byte ) ( string , string , [ ] byte , bool , int ) { defer r . Body . Close ( ) } return " " , " " , nil , false , http . StatusMethodNotAllowed } eventType := r . Header . Get ( " " ) if eventType == " " { responseHTTPError ( w , http . StatusBadRequest , " " ) return " " , " " , nil , false , http . StatusBadRequest } eventGUID := r . Header . Get ( " " ) if eventGUID == " " { responseHTTPError ( w , http . StatusBadRequest , " " ) return " " , " " , nil , false , http . StatusBadRequest } sig := r . Header . Get ( " " ) if sig == " " { responseHTTPError ( w , http . StatusForbidden , " " ) return " " , " " , nil , false , http . StatusForbidden } contentType := r . Header . Get ( " " ) if contentType != " " { responseHTTPError ( w , http . StatusBadRequest , " " ) return " " , " " , nil , false , http . StatusBadRequest } payload , err := ioutil . ReadAll ( r . Body ) if err != nil { responseHTTPError ( w , http . StatusInternalServerError , " " ) return " " , " " , nil , false , http . StatusInternalServerError } return " " , " " , nil , false , http . StatusForbidden } return eventType , eventGUID , payload , true , http . StatusOK } 
func NewForConfigOrDie ( c * rest . Config ) * Clientset { var cs Clientset cs . prowV1 = prowv1 . NewForConfigOrDie ( c ) cs . DiscoveryClient = discovery . NewDiscoveryClientForConfigOrDie ( c ) return & cs } 
func New ( c rest . Interface ) * Clientset { var cs Clientset cs . prowV1 = prowv1 . New ( c ) cs . DiscoveryClient = discovery . NewDiscoveryClient ( c ) return & cs } 
func matches ( repo string , repos [ ] string ) bool { org := strings . Split ( repo , " " ) [ 0 ] for _ , r := range repos { if r == repo || r == org { return true } } return false } 
func HelpProvider ( enabledRepos [ ] string ) ( * pluginhelp . PluginHelp , error ) { return & pluginhelp . PluginHelp { Description : `The needs-rebase plugin manages the '` + labels . NeedsRebase + `' label by removing it from Pull Requests that are mergeable and adding it to those which are not. The plugin reacts to commit changes on PRs in addition to periodically scanning all open PRs for any changes to mergeability that could have resulted from changes in other PRs.` , } , nil } 
func HandleEvent ( log * logrus . Entry , ghc githubClient , pre * github . PullRequestEvent ) error { if pre . Action != github . PullRequestActionOpened && pre . Action != github . PullRequestActionSynchronize && pre . Action != github . PullRequestActionReopened { return nil } org := pre . Repo . Owner . Login repo := pre . Repo . Name number := pre . Number sha := pre . PullRequest . Head . SHA mergeable , err := ghc . IsMergeable ( org , repo , number , sha ) if err != nil { return err } issueLabels , err := ghc . GetIssueLabels ( org , repo , number ) if err != nil { return err } hasLabel := github . HasLabel ( labels . NeedsRebase , issueLabels ) return takeAction ( log , ghc , org , repo , number , pre . PullRequest . User . Login , hasLabel , mergeable ) } 
func HandleAll ( log * logrus . Entry , ghc githubClient , config * plugins . Configuration ) error { log . Info ( " " ) orgs , repos := config . EnabledReposForExternalPlugin ( PluginName ) if len ( orgs ) == 0 && len ( repos ) == 0 { log . Warnf ( " " , PluginName ) return nil } var buf bytes . Buffer fmt . Fprint ( & buf , " " ) for _ , org := range orgs { fmt . Fprintf ( & buf , " \" \" " , org ) } for _ , repo := range repos { fmt . Fprintf ( & buf , " \" \" " , repo ) } prs , err := search ( context . Background ( ) , log , ghc , buf . String ( ) ) if err != nil { return err } log . Infof ( " " , len ( prs ) ) for _ , pr := range prs { } org := string ( pr . Repository . Owner . Login ) repo := string ( pr . Repository . Name ) num := int ( pr . Number ) l := log . WithFields ( logrus . Fields { " " : org , " " : repo , " " : num , } ) hasLabel := false for _ , label := range pr . Labels . Nodes { if label . Name == labels . NeedsRebase { hasLabel = true break } } err := takeAction ( l , ghc , org , repo , num , string ( pr . Author . Login ) , hasLabel , pr . Mergeable == githubql . MergeableStateMergeable , ) if err != nil { l . WithError ( err ) . Error ( " " ) } } return nil } 
func takeAction ( log * logrus . Entry , ghc githubClient , org , repo string , num int , author string , hasLabel , mergeable bool ) error { if ! mergeable && ! hasLabel { if err := ghc . AddLabel ( org , repo , num , labels . NeedsRebase ) ; err != nil { log . WithError ( err ) . Errorf ( " " , labels . NeedsRebase ) } msg := plugins . FormatSimpleResponse ( author , needsRebaseMessage ) return ghc . CreateComment ( org , repo , num , msg ) } else if mergeable && hasLabel { } botName , err := ghc . BotName ( ) if err != nil { return err } return ghc . DeleteStaleComments ( org , repo , num , nil , shouldPrune ( botName ) ) } return nil } 
func NewDryRunProwJobClient ( deckURL string ) prowv1 . ProwJobInterface { return & dryRunProwJobClient { deckURL : deckURL , client : & http . Client { } , } } 
func ( c * dryRunProwJobClient ) Create ( * prowapi . ProwJob ) ( * prowapi . ProwJob , error ) { return nil , nil } 
func ( c * dryRunProwJobClient ) Update ( * prowapi . ProwJob ) ( * prowapi . ProwJob , error ) { return nil , nil } 
func ( c * dryRunProwJobClient ) UpdateStatus ( * prowapi . ProwJob ) ( * prowapi . ProwJob , error ) { return nil , nil } 
func ( c * dryRunProwJobClient ) Delete ( name string , options * metav1 . DeleteOptions ) error { return nil } 
func ( c * dryRunProwJobClient ) DeleteCollection ( options * metav1 . DeleteOptions , listOptions metav1 . ListOptions ) error { return nil } 
func ( c * dryRunProwJobClient ) Get ( name string , options metav1 . GetOptions ) ( * prowapi . ProwJob , error ) { return nil , nil } 
func ( c * dryRunProwJobClient ) List ( opts metav1 . ListOptions ) ( * prowapi . ProwJobList , error ) { var jl prowapi . ProwJobList err := c . request ( " " , map [ string ] string { " " : opts . LabelSelector } , & jl ) return & jl , err } 
func ( c * dryRunProwJobClient ) requestRetry ( path string , query map [ string ] string ) ( [ ] byte , error ) { resp , err := c . retry ( path , query ) if err != nil { return nil , err } defer resp . Body . Close ( ) rb , err := ioutil . ReadAll ( resp . Body ) if err != nil { return nil , err } if resp . StatusCode == 404 { return nil , & kapierrors . StatusError { ErrStatus : metav1 . Status { Status : metav1 . StatusFailure , Code : http . StatusNotFound , Reason : metav1 . StatusReasonNotFound , } } } else if resp . StatusCode == 409 { return nil , & kapierrors . StatusError { ErrStatus : metav1 . Status { Status : metav1 . StatusFailure , Code : http . StatusConflict , Reason : metav1 . StatusReasonAlreadyExists , } } } else if resp . StatusCode == 422 { return nil , & kapierrors . StatusError { ErrStatus : metav1 . Status { Status : metav1 . StatusFailure , Code : http . StatusUnprocessableEntity , Reason : metav1 . StatusReasonInvalid , } } } else if resp . StatusCode < 200 || resp . StatusCode > 299 { return nil , fmt . Errorf ( " \" \" \" \" " , resp . Status , string ( rb ) ) } return rb , nil } 
func ( c * dryRunProwJobClient ) Watch ( opts metav1 . ListOptions ) ( watch . Interface , error ) { return nil , nil } 
func ( c * dryRunProwJobClient ) Patch ( name string , pt types . PatchType , data [ ] byte , subresources ... string ) ( result * prowapi . ProwJob , err error ) { return nil , nil } 
func ( c * controller ) hasSynced ( ) bool { if ! c . pjInformer . HasSynced ( ) { if c . wait != " " { c . wait = " " ns := c . pjNamespace ( ) if ns == " " { ns = " " } logrus . Infof ( " " , ns ) } return false } if ! c . prowJobsDone { c . prowJobsDone = true logrus . Info ( " " ) } if c . pipelinesDone == nil { c . pipelinesDone = map [ string ] bool { } } for n , cfg := range c . pipelines { if ! cfg . informer . Informer ( ) . HasSynced ( ) { if c . wait != n { c . wait = n logrus . Infof ( " " , n ) } return false } else if ! c . pipelinesDone [ n ] { c . pipelinesDone [ n ] = true logrus . Infof ( " " , n ) } } return true } 
func ( c * controller ) Run ( threads int , stop <- chan struct { } ) error { defer runtime . HandleCrash ( ) defer c . workqueue . ShutDown ( ) logrus . Info ( " " ) logrus . Info ( " " ) if ok := cache . WaitForCacheSync ( stop , c . hasSynced ) ; ! ok { return fmt . Errorf ( " " ) } logrus . Info ( " " ) for i := 0 ; i < threads ; i ++ { go wait . Until ( c . runWorker , time . Second , stop ) } logrus . Info ( " " ) <- stop logrus . Info ( " " ) return nil } 
func ( c * controller ) runWorker ( ) { for { key , shutdown := c . workqueue . Get ( ) if shutdown { return } func ( ) { defer c . workqueue . Done ( key ) if err := reconcile ( c , key . ( string ) ) ; err != nil { runtime . HandleError ( fmt . Errorf ( " " , key , err ) ) return } c . workqueue . Forget ( key ) } ( ) } } 
func toKey ( ctx , namespace , name string ) string { return strings . Join ( [ ] string { ctx , namespace , name } , " " ) } 
func fromKey ( key string ) ( string , string , string , error ) { parts := strings . Split ( key , " " ) if len ( parts ) != 3 { return " " , " " , " " , fmt . Errorf ( " " , key ) } return parts [ 0 ] , parts [ 1 ] , parts [ 2 ] , nil } 
func ( c * controller ) enqueueKey ( ctx string , obj interface { } ) { switch o := obj . ( type ) { case * prowjobv1 . ProwJob : ns := o . Spec . Namespace if ns == " " { ns = o . Namespace } c . workqueue . AddRateLimited ( toKey ( ctx , ns , o . Name ) ) case * pipelinev1alpha1 . PipelineRun : c . workqueue . AddRateLimited ( toKey ( ctx , o . Namespace , o . Name ) ) default : logrus . Warnf ( " " , o , obj ) return } } 
func reconcile ( c reconciler , key string ) error { logrus . Debugf ( " \n " , key ) ctx , namespace , name , err := fromKey ( key ) if err != nil { runtime . HandleError ( err ) return nil } var wantPipelineRun bool pj , err := c . getProwJob ( name ) switch { case apierrors . IsNotFound ( err ) : case pj . Spec . Agent != prowjobv1 . TektonAgent : case pj . DeletionTimestamp == nil : wantPipelineRun = true } var havePipelineRun bool p , err := c . getPipelineRun ( ctx , namespace , name ) switch { case apierrors . IsNotFound ( err ) : case p . DeletionTimestamp == nil : havePipelineRun = true } var newPipelineRun bool switch { case ! wantPipelineRun : if ! havePipelineRun { if pj != nil && pj . Spec . Agent == prowjobv1 . TektonAgent { logrus . Infof ( " " , key ) } return nil } } logrus . Infof ( " " , key ) if err = c . deletePipelineRun ( ctx , namespace , name ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil case finalState ( pj . Status . State ) : logrus . Infof ( " " , key ) return nil case wantPipelineRun && pj . Spec . PipelineRunSpec == nil : return fmt . Errorf ( " " , key ) case wantPipelineRun && ! havePipelineRun : id , url , err := c . pipelineID ( * pj ) if err != nil { return fmt . Errorf ( " " , err ) } pj . Status . BuildID = id pj . Status . URL = url newPipelineRun = true pr := makePipelineGitResource ( * pj ) logrus . Infof ( " " , key ) if pr , err = c . createPipelineResource ( ctx , namespace , pr ) ; err != nil { return fmt . Errorf ( " " , key , err ) } newp , err := makePipelineRun ( * pj , pr ) if err != nil { return fmt . Errorf ( " " , key , err ) } logrus . Infof ( " " , key ) p , err = c . createPipelineRun ( ctx , namespace , newp ) if err != nil { jerr := fmt . Errorf ( " " , err ) } } if p == nil { return fmt . Errorf ( " " , key , wantPipelineRun ) } wantState , wantMsg := prowJobStatus ( p . Status ) return updateProwJobState ( c , key , newPipelineRun , pj , wantState , wantMsg ) } 
func finalState ( status prowjobv1 . ProwJobState ) bool { switch status { case " " , prowjobv1 . PendingState , prowjobv1 . TriggeredState : return false } return true } 
func description ( cond duckv1alpha1 . Condition , fallback string ) string { switch { case cond . Message != " " : return cond . Message case cond . Reason != " " : return cond . Reason } return fallback } 
func prowJobStatus ( ps pipelinev1alpha1 . PipelineRunStatus ) ( prowjobv1 . ProwJobState , string ) { started := ps . StartTime finished := ps . CompletionTime pcond := ps . GetCondition ( duckv1alpha1 . ConditionSucceeded ) if pcond == nil { if ! finished . IsZero ( ) { return prowjobv1 . ErrorState , descMissingCondition } return prowjobv1 . TriggeredState , descScheduling } cond := * pcond switch { case cond . Status == untypedcorev1 . ConditionTrue : return prowjobv1 . SuccessState , description ( cond , descSucceeded ) case cond . Status == untypedcorev1 . ConditionFalse : return prowjobv1 . FailureState , description ( cond , descFailed ) case started . IsZero ( ) : return prowjobv1 . TriggeredState , description ( cond , descInitializing ) case cond . Status == untypedcorev1 . ConditionUnknown , finished . IsZero ( ) : return prowjobv1 . PendingState , description ( cond , descRunning ) } logrus . Warnf ( " " , cond ) return prowjobv1 . ErrorState , description ( cond , descUnknown ) } 
func pipelineMeta ( pj prowjobv1 . ProwJob ) metav1 . ObjectMeta { labels , annotations := decorate . LabelsAndAnnotationsForJob ( pj ) return metav1 . ObjectMeta { Annotations : annotations , Name : pj . Name , Namespace : pj . Spec . Namespace , Labels : labels , } } 
func sourceURL ( pj prowjobv1 . ProwJob ) string { if pj . Spec . Refs == nil { return " " } sourceURL := pj . Spec . Refs . CloneURI if sourceURL == " " { sourceURL = fmt . Sprintf ( " " , pj . Spec . Refs . RepoLink ) } return sourceURL } 
func makePipelineGitResource ( pj prowjobv1 . ProwJob ) * pipelinev1alpha1 . PipelineResource { var revision string if pj . Spec . Refs != nil { if len ( pj . Spec . Refs . Pulls ) > 0 { revision = pj . Spec . Refs . Pulls [ 0 ] . SHA } else { revision = pj . Spec . Refs . BaseSHA } } pr := pipelinev1alpha1 . PipelineResource { ObjectMeta : pipelineMeta ( pj ) , Spec : pipelinev1alpha1 . PipelineResourceSpec { Type : pipelinev1alpha1 . PipelineResourceTypeGit , Params : [ ] pipelinev1alpha1 . Param { { Name : " " , Value : sourceURL ( pj ) , } , { Name : " " , Value : revision , } , } , } , } return & pr } 
func makePipelineRun ( pj prowjobv1 . ProwJob , pr * pipelinev1alpha1 . PipelineResource ) ( * pipelinev1alpha1 . PipelineRun , error ) { if pj . Spec . PipelineRunSpec == nil { return nil , errors . New ( " " ) } p := pipelinev1alpha1 . PipelineRun { ObjectMeta : pipelineMeta ( pj ) , Spec : * pj . Spec . PipelineRunSpec . DeepCopy ( ) , } buildID := pj . Status . BuildID if buildID == " " { return nil , errors . New ( " " ) } p . Spec . Params = append ( p . Spec . Params , pipelinev1alpha1 . Param { Name : " " , Value : buildID , } ) rb := pipelinev1alpha1 . PipelineResourceBinding { Name : pr . Name , ResourceRef : pipelinev1alpha1 . PipelineResourceRef { Name : pr . Name , APIVersion : pr . APIVersion , } , } p . Spec . Resources = append ( p . Spec . Resources , rb ) return & p , nil } 
func diskMonitor ( interval time . Duration , diskRoot string ) { logger := logrus . WithField ( " " , " " ) ticker := time . NewTicker ( interval ) for ; true ; <- ticker . C { logger . Info ( " " ) _ , bytesFree , bytesUsed , err := diskutil . GetDiskUsage ( diskRoot ) if err != nil { logger . WithError ( err ) . Error ( " " ) } else { diskFree . Set ( float64 ( bytesFree ) / 1e9 ) diskUsed . Set ( float64 ( bytesUsed ) / 1e9 ) diskTotal . Set ( float64 ( bytesFree + bytesUsed ) / 1e9 ) } } } 
func ( m * MultiplexerPluginWrapper ) ReceiveIssue ( issue sql . Issue ) [ ] Point { points := [ ] Point { } for _ , plugin := range m . plugins { points = append ( points , plugin . ReceiveIssue ( issue ) ... ) } return points } 
func ( m * MultiplexerPluginWrapper ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { points := [ ] Point { } for _ , plugin := range m . plugins { points = append ( points , plugin . ReceiveIssueEvent ( event ) ... ) } return points } 
func ( m * MultiplexerPluginWrapper ) ReceiveComment ( comment sql . Comment ) [ ] Point { points := [ ] Point { } for _ , plugin := range m . plugins { points = append ( points , plugin . ReceiveComment ( comment ) ... ) } return points } 
func matchingConfigs ( org , repo , branch , label string , allConfigs [ ] plugins . RequireMatchingLabel ) [ ] plugins . RequireMatchingLabel { var filtered [ ] plugins . RequireMatchingLabel for _ , cfg := range allConfigs { } } } filtered = append ( filtered , cfg ) } return filtered } 
func SuggestCodeChange ( p lint . Problem ) string { var suggestion = " " for regex , handler := range lintHandlersMap { matches := regex . FindStringSubmatch ( p . Text ) suggestion = handler ( p , matches ) if suggestion != " " && suggestion != p . LineText { return formatSuggestion ( suggestion ) } } return " " } 
func ServeExternalPluginHelp ( mux * http . ServeMux , log * logrus . Entry , provider ExternalPluginHelpProvider ) { mux . HandleFunc ( " " , func ( w http . ResponseWriter , r * http . Request ) { w . Header ( ) . Set ( " " , " " ) serverError := func ( action string , err error ) { log . WithError ( err ) . Errorf ( " " , action ) msg := fmt . Sprintf ( " " , action , err ) http . Error ( w , msg , http . StatusInternalServerError ) } if r . Method != http . MethodPost { log . Errorf ( " " , r . Method ) http . Error ( w , " " , http . StatusMethodNotAllowed ) return } b , err := ioutil . ReadAll ( r . Body ) if err != nil { serverError ( " " , err ) return } var enabledRepos [ ] string if err := json . Unmarshal ( b , & enabledRepos ) ; err != nil { serverError ( " " , err ) return } if provider == nil { serverError ( " " , errors . New ( " " ) ) return } help , err := provider ( enabledRepos ) if err != nil { serverError ( " " , err ) return } b , err = json . Marshal ( help ) if err != nil { serverError ( " " , err ) return } fmt . Fprint ( w , string ( b ) ) } , ) } 
func ( p * protector ) protect ( ) { bp := p . cfg . BranchProtection if err := p . UpdateOrg ( orgName , * org ) ; err != nil { p . errors . add ( fmt . Errorf ( " " , orgName , err ) ) } } } } parts := strings . Split ( repo , " " ) if len ( parts ) != 2 { continue } orgName := parts [ 0 ] repoName := parts [ 1 ] repo := bp . GetOrg ( orgName ) . GetRepo ( repoName ) if err := p . UpdateRepo ( orgName , repoName , * repo ) ; err != nil { p . errors . add ( fmt . Errorf ( " " , orgName , repoName , err ) ) } } } 
func ( p * protector ) UpdateOrg ( orgName string , org config . Org ) error { var repos [ ] string if org . Protect != nil { if err != nil { return fmt . Errorf ( " " , err ) } for _ , r := range rs { if ! r . Archived { repos = append ( repos , r . Name ) } } } else { } } for _ , repoName := range repos { repo := org . GetRepo ( repoName ) if err := p . UpdateRepo ( orgName , repoName , * repo ) ; err != nil { return fmt . Errorf ( " " , repoName , err ) } } return nil } 
func ( p * protector ) UpdateRepo ( orgName string , repoName string , repo config . Repo ) error { p . completedRepos [ orgName + " " + repoName ] = true githubRepo , err := p . client . GetRepo ( orgName , repoName ) if err != nil { return fmt . Errorf ( " " , err ) } if githubRepo . Archived { } branches := map [ string ] github . Branch { } for _ , onlyProtected := range [ ] bool { false , true } { if err != nil { return fmt . Errorf ( " " , err ) } for _ , b := range bs { branches [ b . Name ] = b } } for bn , githubBranch := range branches { if branch , err := repo . GetBranch ( bn ) ; err != nil { return fmt . Errorf ( " " , bn , err ) } else if err = p . UpdateBranch ( orgName , repoName , bn , * branch , githubBranch . Protected ) ; err != nil { return fmt . Errorf ( " " , bn , githubBranch . Protected , err ) } } return nil } 
func ( p * protector ) UpdateBranch ( orgName , repo string , branchName string , branch config . Branch , protected bool ) error { bp , err := p . cfg . GetPolicy ( orgName , repo , branchName , branch ) if err != nil { return fmt . Errorf ( " " , err ) } if bp == nil || bp . Protect == nil { return nil } if ! protected && ! * bp . Protect { logrus . Infof ( " " , orgName , repo , branchName ) return nil } var req * github . BranchProtectionRequest if * bp . Protect { r := makeRequest ( * bp ) req = & r } p . updates <- requirements { Org : orgName , Repo : repo , Branch : branchName , Request : req , } return nil } 
func ( o * Options ) Validate ( ) error { if o . NumWorkers == 0 { return errors . New ( " " ) } if o . ProwJobNamespace == " " { return errors . New ( " " ) } return o . Options . Validate ( ) } 
func ( o * Options ) LoadConfig ( config string ) error { return json . Unmarshal ( [ ] byte ( config ) , o ) } 
func ( o * Options ) AddFlags ( flags * flag . FlagSet ) { flags . IntVar ( & o . NumWorkers , " " , 25 , " " ) flags . StringVar ( & o . ProwJobNamespace , " " , " " , " " ) o . Options . AddFlags ( flags ) } 
func loadClusterConfig ( ) ( * rest . Config , error ) { clusterConfig , err := rest . InClusterConfig ( ) if err == nil { return clusterConfig , nil } credentials , err := clientcmd . NewDefaultClientConfigLoadingRules ( ) . Load ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } clusterConfig , err = clientcmd . NewDefaultClientConfig ( * credentials , & clientcmd . ConfigOverrides { } ) . ClientConfig ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return clusterConfig , nil } 
func ( o * Options ) Run ( ) error { clusterConfig , err := loadClusterConfig ( ) if err != nil { return fmt . Errorf ( " " , err ) } client , err := kubernetes . NewForConfig ( clusterConfig ) if err != nil { return err } prowJobClient , err := kube . NewClientInCluster ( o . ProwJobNamespace ) if err != nil { return err } controller := artifact_uploader . NewController ( client . CoreV1 ( ) , prowJobClient , o . Options ) stop := make ( chan struct { } ) defer close ( stop ) go controller . Run ( o . NumWorkers , stop ) } 
func ( a * Agent ) Start ( paths [ ] string ) error { secretsMap , err := LoadSecrets ( paths ) if err != nil { return err } a . secretsMap = secretsMap } return nil } 
func ( a * Agent ) reloadSecret ( secretPath string ) { var lastModTime time . Time logger := logrus . NewEntry ( logrus . StandardLogger ( ) ) skips := 0 for range time . Tick ( 1 * time . Second ) { if skips < 600 { if err != nil { logger . WithField ( " " , secretPath ) . WithError ( err ) . Error ( " " ) continue } recentModTime := secretStat . ModTime ( ) if ! recentModTime . After ( lastModTime ) { skips ++ continue } lastModTime = recentModTime } if secretValue , err := LoadSingleSecret ( secretPath ) ; err != nil { logger . WithField ( " " , secretPath ) . WithError ( err ) . Error ( " " ) } else { a . setSecret ( secretPath , secretValue ) skips = 0 } } } 
func ( a * Agent ) GetSecret ( secretPath string ) [ ] byte { a . RLock ( ) defer a . RUnlock ( ) return a . secretsMap [ secretPath ] } 
func ( a * Agent ) setSecret ( secretPath string , secretValue [ ] byte ) { a . Lock ( ) defer a . Unlock ( ) a . secretsMap [ secretPath ] = secretValue } 
func ( a * Agent ) GetTokenGenerator ( secretPath string ) func ( ) [ ] byte { return func ( ) [ ] byte { return a . GetSecret ( secretPath ) } } 
func New ( maxRecordsPerKey int , opener io . Opener , path string ) ( * History , error ) { hist := & History { logs : map [ string ] * recordLog { } , logSizeLimit : maxRecordsPerKey , opener : opener , path : path , } if path != " " { start := time . Now ( ) hist . logs , err = readHistory ( maxRecordsPerKey , hist . opener , hist . path ) if err != nil { return nil , err } logrus . WithFields ( logrus . Fields { " " : time . Since ( start ) . String ( ) , " " : hist . path , } ) . Debugf ( " " , len ( hist . logs ) ) } return hist , nil } 
func ( h * History ) Record ( poolKey , action , baseSHA , err string , targets [ ] prowapi . Pull ) { t := now ( ) sort . Sort ( ByNum ( targets ) ) h . addRecord ( poolKey , & Record { Time : t , Action : action , BaseSHA : baseSHA , Target : targets , Err : err , } , ) } 
func ( h * History ) ServeHTTP ( w http . ResponseWriter , r * http . Request ) { b , err := json . Marshal ( h . AllRecords ( ) ) if err != nil { logrus . WithError ( err ) . Error ( " " ) b = [ ] byte ( " " ) } if _ , err = w . Write ( b ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } } 
func ( h * History ) Flush ( ) { if h . path == " " { return } records := h . AllRecords ( ) start := time . Now ( ) err := writeHistory ( h . opener , h . path , records ) log := logrus . WithFields ( logrus . Fields { " " : time . Since ( start ) . String ( ) , " " : h . path , } ) if err != nil { log . WithError ( err ) . Error ( " " ) } else { log . Debugf ( " " , len ( h . logs ) ) } } 
func ( h * History ) AllRecords ( ) map [ string ] [ ] * Record { h . Lock ( ) defer h . Unlock ( ) res := make ( map [ string ] [ ] * Record , len ( h . logs ) ) for key , log := range h . logs { res [ key ] = log . toSlice ( ) } return res } 
func MakeCommand ( ) * cobra . Command { flags := & flags { } cmd := & cobra . Command { Use : " " , Short : " " , Long : `Finds and downloads the coverage profile file from the latest healthy build stored in given gcs directory.` , Run : func ( cmd * cobra . Command , args [ ] string ) { run ( flags , cmd , args ) } , } cmd . Flags ( ) . StringVarP ( & flags . outputFile , " " , " " , " " , " " ) cmd . Flags ( ) . StringVarP ( & flags . artifactsDirName , " " , " " , " " , " " ) cmd . Flags ( ) . StringVarP ( & flags . profileName , " " , " " , " " , " " ) return cmd } 
func ( c * CommentCounterPlugin ) AddFlags ( cmd * cobra . Command ) { cmd . Flags ( ) . StringSliceVar ( & c . pattern , " " , [ ] string { } , " " ) } 
func ( c * CommentCounterPlugin ) CheckFlags ( ) error { for _ , pattern := range c . pattern { matcher , err := regexp . Compile ( pattern ) if err != nil { return err } c . matcher = append ( c . matcher , matcher ) } return nil } 
func ( c * CommentCounterPlugin ) ReceiveComment ( comment sql . Comment ) [ ] Point { points := [ ] Point { } for _ , matcher := range c . matcher { if matcher . MatchString ( comment . Body ) { points = append ( points , Point { Values : map [ string ] interface { } { " " : 1 , } , Date : comment . CommentCreatedAt , } ) } } return points } 
func NewController ( pjclientset clientset . Interface , queue workqueue . RateLimitingInterface , informer pjinformers . ProwJobInformer , reporter reportClient , numWorkers int , wg * sync . WaitGroup ) * Controller { return & Controller { pjclientset : pjclientset , queue : queue , informer : informer , reporter : reporter , numWorkers : numWorkers , wg : wg , } } 
func ( c * Controller ) Run ( stopCh <- chan struct { } ) { logrus . Info ( " " ) c . informer . Informer ( ) . AddEventHandler ( cache . ResourceEventHandlerFuncs { AddFunc : func ( obj interface { } ) { key , err := cache . MetaNamespaceKeyFunc ( obj ) logrus . WithField ( " " , key ) . Infof ( " " ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return } c . queue . AddRateLimited ( key ) } , UpdateFunc : func ( oldObj , newObj interface { } ) { key , err := cache . MetaNamespaceKeyFunc ( newObj ) logrus . WithField ( " " , key ) . Infof ( " " ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return } c . queue . AddRateLimited ( key ) } , } ) return } logrus . Info ( " " ) } logrus . Infof ( " " , c . numWorkers ) <- stopCh logrus . Info ( " " ) } 
func ( c * Controller ) runWorker ( ) { c . wg . Add ( 1 ) for c . processNextItem ( ) { } c . wg . Done ( ) } 
func ( c * Controller ) processNextItem ( ) bool { key , quit := c . queue . Get ( ) if quit { return false } defer c . queue . Done ( key ) namespace , name , err := cache . SplitMetaNamespaceKey ( keyRaw ) if err != nil { logrus . WithError ( err ) . WithField ( " " , keyRaw ) . Error ( " " ) c . queue . Forget ( key ) return true } if err != nil { if errors . IsNotFound ( err ) { logrus . WithField ( " " , keyRaw ) . Info ( " " ) c . queue . Forget ( key ) return true } return c . retry ( key , err ) } return true } } c . queue . Forget ( key ) return true } logrus . WithField ( " " , keyRaw ) . Infof ( " " , pj . Status . State ) pjs , err := c . reporter . Report ( pj ) if err != nil { fields := logrus . Fields { " " : keyRaw , " " : pj . Name , " " : pj . Status , } logrus . WithError ( err ) . WithFields ( fields ) . Error ( " " ) return c . retry ( key , err ) } logrus . WithField ( " " , keyRaw ) . Info ( " " ) for _ , pjob := range pjs { if err := c . updateReportState ( pjob ) ; err != nil { logrus . WithError ( err ) . WithField ( " " , keyRaw ) . Error ( " " ) if err != nil { logrus . WithError ( err ) . WithField ( " " , keyRaw ) . Error ( " " ) c . queue . Forget ( key ) return true } if err := c . updateReportState ( updatedPJ ) ; err != nil { c . queue . Forget ( key ) return true } } logrus . WithField ( " " , keyRaw ) . Infof ( " " , pjob . Spec . Job , pjob . Status . State ) } c . queue . Forget ( key ) return true } 
func NewAggregate ( errlist ... error ) Aggregate { if len ( errlist ) == 0 { return nil } for _ , e := range errlist { if e != nil { errs = append ( errs , e ) } } if len ( errs ) == 0 { return nil } return aggregate ( errs ) } 
func ( agg aggregate ) Error ( ) string { if len ( agg ) == 0 { } return fmt . Sprintf ( " " , strings . Join ( agg . Strings ( ) , " " ) ) } 
func ( agg aggregate ) Strings ( ) [ ] string { strs := make ( [ ] string , 0 , len ( agg ) ) for _ , e := range agg { if subAgg , ok := e . ( aggregate ) ; ok { strs = append ( strs , subAgg . Strings ( ) ... ) } else { strs = append ( strs , e . Error ( ) ) } } return strs } 
func New ( ) ( * LocalGit , * git . Client , error ) { g , err := exec . LookPath ( " " ) if err != nil { return nil , nil , err } t , err := ioutil . TempDir ( " " , " " ) if err != nil { return nil , nil , err } c , err := git . NewClient ( ) if err != nil { os . RemoveAll ( t ) return nil , nil , err } getSecret := func ( ) [ ] byte { return [ ] byte ( " " ) } c . SetCredentials ( " " , getSecret ) c . SetRemote ( t ) return & LocalGit { Dir : t , Git : g , } , c , nil } 
func ( lg * LocalGit ) MakeFakeRepo ( org , repo string ) error { rdir := filepath . Join ( lg . Dir , org , repo ) if err := os . MkdirAll ( rdir , os . ModePerm ) ; err != nil { return err } if err := runCmd ( lg . Git , rdir , " " ) ; err != nil { return err } if err := runCmd ( lg . Git , rdir , " " , " " , " " ) ; err != nil { return err } if err := runCmd ( lg . Git , rdir , " " , " " , " " ) ; err != nil { return err } if err := runCmd ( lg . Git , rdir , " " , " " , " " ) ; err != nil { return err } if err := lg . AddCommit ( org , repo , map [ string ] [ ] byte { " " : { } } ) ; err != nil { return err } return nil } 
func ( lg * LocalGit ) AddCommit ( org , repo string , files map [ string ] [ ] byte ) error { rdir := filepath . Join ( lg . Dir , org , repo ) for f , b := range files { path := filepath . Join ( rdir , f ) if err := os . MkdirAll ( filepath . Dir ( path ) , os . ModePerm ) ; err != nil { return err } if err := ioutil . WriteFile ( path , b , os . ModePerm ) ; err != nil { return err } if err := runCmd ( lg . Git , rdir , " " , f ) ; err != nil { return err } } return runCmd ( lg . Git , rdir , " " , " " , " " ) } 
func ( lg * LocalGit ) CheckoutNewBranch ( org , repo , branch string ) error { rdir := filepath . Join ( lg . Dir , org , repo ) return runCmd ( lg . Git , rdir , " " , " " , branch ) } 
func ( lg * LocalGit ) Checkout ( org , repo , commitlike string ) error { rdir := filepath . Join ( lg . Dir , org , repo ) return runCmd ( lg . Git , rdir , " " , commitlike ) } 
func ( lg * LocalGit ) RevParse ( org , repo , commitlike string ) ( string , error ) { rdir := filepath . Join ( lg . Dir , org , repo ) return runCmdOutput ( lg . Git , rdir , " " , commitlike ) } 
func CleanAll ( sess * session . Session , region string ) error { acct , err := account . GetAccount ( sess , regions . Default ) if err != nil { return errors . Wrap ( err , " " ) } klog . V ( 1 ) . Infof ( " " , acct ) var regionList [ ] string if region == " " { regionList , err = regions . GetAll ( sess ) if err != nil { return errors . Wrap ( err , " " ) } } else { regionList = [ ] string { region } } klog . Infof ( " " , regionList ) for _ , r := range regionList { for _ , typ := range RegionalTypeList { set , err := typ . ListAll ( sess , acct , r ) if err != nil { return errors . Wrapf ( err , " " , typ ) } if err := typ . MarkAndSweep ( sess , acct , r , set ) ; err != nil { return errors . Wrapf ( err , " " , typ ) } } } for _ , typ := range GlobalTypeList { set , err := typ . ListAll ( sess , acct , regions . Default ) if err != nil { return errors . Wrapf ( err , " " , typ ) } if err := typ . MarkAndSweep ( sess , acct , regions . Default , set ) ; err != nil { return errors . Wrapf ( err , " " , typ ) } } return nil } 
func optionsForRepo ( config * plugins . Configuration , org , repo string ) * plugins . Lgtm { fullName := fmt . Sprintf ( " " , org , repo ) for i := range config . Lgtm { if ! strInSlice ( org , config . Lgtm [ i ] . Repos ) && ! strInSlice ( fullName , config . Lgtm [ i ] . Repos ) { continue } return & config . Lgtm [ i ] } return & plugins . Lgtm { } } 
func getChangedFiles ( gc githubClient , org , repo string , number int ) ( [ ] string , error ) { changes , err := gc . GetPullRequestChanges ( org , repo , number ) if err != nil { return nil , fmt . Errorf ( " " , org , repo , number ) } var filenames [ ] string for _ , change := range changes { filenames = append ( filenames , change . Filename ) } return filenames , nil } 
func loadReviewers ( ro repoowners . RepoOwner , filenames [ ] string ) sets . String { reviewers := sets . String { } for _ , filename := range filenames { reviewers = reviewers . Union ( ro . Approvers ( filename ) ) . Union ( ro . Reviewers ( filename ) ) } return reviewers } 
func NewController ( lastSyncFallback , cookiefilePath string , projects map [ string ] [ ] string , kc * kube . Client , cfg config . Getter ) ( * Controller , error ) { if lastSyncFallback == " " { return nil , errors . New ( " " ) } var lastUpdate time . Time if buf , err := ioutil . ReadFile ( lastSyncFallback ) ; err == nil { unix , err := strconv . ParseInt ( string ( buf ) , 10 , 64 ) if err != nil { return nil , err } lastUpdate = time . Unix ( unix , 0 ) } else if err != nil && ! os . IsNotExist ( err ) { return nil , fmt . Errorf ( " " , err ) } else { logrus . Warnf ( " " , lastSyncFallback ) lastUpdate = time . Now ( ) } c , err := client . NewClient ( projects ) if err != nil { return nil , err } c . Start ( cookiefilePath ) return & Controller { kc : kc , config : cfg , gc : c , lastUpdate : lastUpdate , lastSyncFallback : lastSyncFallback , } , nil } 
func ( c * Controller ) SaveLastSync ( lastSync time . Time ) error { if c . lastSyncFallback == " " { return nil } lastSyncUnix := strconv . FormatInt ( lastSync . Unix ( ) , 10 ) logrus . Infof ( " " , lastSyncUnix ) tempFile , err := ioutil . TempFile ( filepath . Dir ( c . lastSyncFallback ) , " " ) if err != nil { return err } defer os . Remove ( tempFile . Name ( ) ) err = ioutil . WriteFile ( tempFile . Name ( ) , [ ] byte ( lastSyncUnix ) , 0644 ) if err != nil { return err } err = os . Rename ( tempFile . Name ( ) , c . lastSyncFallback ) if err != nil { logrus . WithError ( err ) . Info ( " " ) return copyFile ( tempFile . Name ( ) , c . lastSyncFallback ) } return nil } 
func ( c * Controller ) Sync ( ) error { syncTime := c . lastUpdate for instance , changes := range c . gc . QueryChanges ( c . lastUpdate , c . config ( ) . Gerrit . RateLimit ) { for _ , change := range changes { if err := c . ProcessChange ( instance , change ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , change . CurrentRevision ) } if syncTime . Before ( change . Updated . Time ) { syncTime = change . Updated . Time } } logrus . Infof ( " " , len ( changes ) , instance ) } c . lastUpdate = syncTime if err := c . SaveLastSync ( syncTime ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , syncTime , c . lastSyncFallback ) } return nil } 
func listChangedFiles ( changeInfo client . ChangeInfo ) config . ChangedFilesProvider { return func ( ) ( [ ] string , error ) { var changed [ ] string revision := changeInfo . Revisions [ changeInfo . CurrentRevision ] for file := range revision . Files { changed = append ( changed , file ) } return changed , nil } } 
func ( c * Controller ) ProcessChange ( instance string , change client . ChangeInfo ) error { logger := logrus . WithField ( " " , change . Number ) cloneURI , err := makeCloneURI ( instance , change . Project ) if err != nil { return fmt . Errorf ( " " , err ) } baseSHA , err := c . gc . GetBranchRevision ( instance , change . Project , change . Branch ) if err != nil { return fmt . Errorf ( " " , err ) } triggeredJobs := [ ] string { } refs , err := createRefs ( instance , change , cloneURI , baseSHA ) if err != nil { return fmt . Errorf ( " " , err ) } type jobSpec struct { spec prowapi . ProwJobSpec labels map [ string ] string } var jobSpecs [ ] jobSpec changedFiles := listChangedFiles ( change ) switch change . Status { case client . Merged : postsubmits := c . config ( ) . Postsubmits [ cloneURI . String ( ) ] postsubmits = append ( postsubmits , c . config ( ) . Postsubmits [ cloneURI . Host + " " + cloneURI . Path ] ... ) for _ , postsubmit := range postsubmits { if shouldRun , err := postsubmit . ShouldRun ( change . Branch , changedFiles ) ; err != nil { return fmt . Errorf ( " " , postsubmit . Name , err ) } else if shouldRun { jobSpecs = append ( jobSpecs , jobSpec { spec : pjutil . PostsubmitSpec ( postsubmit , refs ) , labels : postsubmit . Labels , } ) } } case client . New : presubmits := c . config ( ) . Presubmits [ cloneURI . String ( ) ] presubmits = append ( presubmits , c . config ( ) . Presubmits [ cloneURI . Host + " " + cloneURI . Path ] ... ) var filters [ ] pjutil . Filter filter , err := messageFilter ( c . lastUpdate , change , presubmits ) if err != nil { logger . WithError ( err ) . Warn ( " " ) } else { filters = append ( filters , filter ) } if change . Revisions [ change . CurrentRevision ] . Created . Time . After ( c . lastUpdate ) { filters = append ( filters , pjutil . TestAllFilter ( ) ) } toTrigger , _ , err := pjutil . FilterPresubmits ( pjutil . AggregateFilter ( filters ) , listChangedFiles ( change ) , change . Branch , presubmits , logger ) if err != nil { return fmt . Errorf ( " " , err ) } for _ , presubmit := range toTrigger { jobSpecs = append ( jobSpecs , jobSpec { spec : pjutil . PresubmitSpec ( presubmit , refs ) , labels : presubmit . Labels , } ) } } annotations := map [ string ] string { client . GerritID : change . ID , client . GerritInstance : instance , } for _ , jSpec := range jobSpecs { labels := make ( map [ string ] string ) for k , v := range jSpec . labels { labels [ k ] = v } labels [ client . GerritRevision ] = change . CurrentRevision if gerritLabel , ok := labels [ client . GerritReportLabel ] ; ! ok || gerritLabel == " " { labels [ client . GerritReportLabel ] = client . CodeReview } pj := pjutil . NewProwJobWithAnnotation ( jSpec . spec , labels , annotations ) if _ , err := c . kc . CreateProwJob ( pj ) ; err != nil { logger . WithError ( err ) . Errorf ( " " , pj ) } else { logger . Infof ( " " , jSpec . spec . Job ) triggeredJobs = append ( triggeredJobs , jSpec . spec . Job ) } } if len ( triggeredJobs ) > 0 { for _ , job := range triggeredJobs { message += fmt . Sprintf ( " \n " , job ) } if err := c . gc . SetReview ( instance , change . ID , change . CurrentRevision , message , nil ) ; err != nil { return err } } return nil } 
func ( e * EventCounterPlugin ) AddFlags ( cmd * cobra . Command ) { cmd . Flags ( ) . StringVar ( & e . desc , " " , " " , " " ) } 
func ( e * EventCounterPlugin ) CheckFlags ( ) error { e . matcher = NewEventMatcher ( e . desc ) return nil } 
func ( e * EventCounterPlugin ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { var label string if event . Label != nil { label = * event . Label } if ! e . matcher . Match ( event . Event , label ) { return nil } return [ ] Point { { Values : map [ string ] interface { } { " " : 1 } , Date : event . EventCreatedAt , } , } } 
func Upload ( bucket * storage . BucketHandle , uploadTargets map [ string ] UploadFunc ) error { errCh := make ( chan error , len ( uploadTargets ) ) group := & sync . WaitGroup { } group . Add ( len ( uploadTargets ) ) for dest , upload := range uploadTargets { obj := bucket . Object ( dest ) logrus . WithField ( " " , dest ) . Info ( " " ) go func ( f UploadFunc , obj * storage . ObjectHandle , name string ) { defer group . Done ( ) if err := f ( obj ) ; err != nil { errCh <- err } logrus . WithField ( " " , name ) . Info ( " " ) } ( upload , obj , dest ) } group . Wait ( ) close ( errCh ) if len ( errCh ) != 0 { var uploadErrors [ ] error for err := range errCh { uploadErrors = append ( uploadErrors , err ) } return fmt . Errorf ( " " , uploadErrors ) } return nil } 
func FileUploadWithMetadata ( file string , metadata map [ string ] string ) UploadFunc { return func ( obj * storage . ObjectHandle ) error { reader , err := os . Open ( file ) if err != nil { return err } uploadErr := DataUploadWithMetadata ( reader , metadata ) ( obj ) closeErr := reader . Close ( ) return errorutil . NewAggregate ( uploadErr , closeErr ) } } 
func DataUploadWithMetadata ( src io . Reader , metadata map [ string ] string ) UploadFunc { return func ( obj * storage . ObjectHandle ) error { writer := obj . NewWriter ( context . Background ( ) ) writer . Metadata = metadata _ , copyErr := io . Copy ( writer , src ) closeErr := writer . Close ( ) return errorutil . NewAggregate ( copyErr , closeErr ) } } 
func HasLabel ( label string , issueLabels [ ] Label ) bool { for _ , l := range issueLabels { if strings . ToLower ( l . Name ) == strings . ToLower ( label ) { return true } } return false } 
func ImageTooBig ( url string ) ( bool , error ) { if err != nil { return true , fmt . Errorf ( " " , err ) } if sc := resp . StatusCode ; sc != http . StatusOK { return true , fmt . Errorf ( " " , sc ) } size , _ := strconv . Atoi ( resp . Header . Get ( " " ) ) if size > limit { return true , nil } return false , nil } 
func LevelFromPermissions ( permissions RepoPermissions ) RepoPermissionLevel { if permissions . Admin { return Admin } else if permissions . Push { return Write } else if permissions . Pull { return Read } else { return None } } 
func PermissionsFromLevel ( permission RepoPermissionLevel ) RepoPermissions { switch permission { case None : return RepoPermissions { } case Read : return RepoPermissions { Pull : true } case Write : return RepoPermissions { Pull : true , Push : true } case Admin : return RepoPermissions { Pull : true , Push : true , Admin : true } default : return RepoPermissions { } } } 
func newProwJobs ( c * ProwV1Client , namespace string ) * prowJobs { return & prowJobs { client : c . RESTClient ( ) , ns : namespace , } } 
func ( c * prowJobs ) List ( opts metav1 . ListOptions ) ( result * v1 . ProwJobList , err error ) { result = & v1 . ProwJobList { } err = c . client . Get ( ) . Namespace ( c . ns ) . Resource ( " " ) . VersionedParams ( & opts , scheme . ParameterCodec ) . Do ( ) . Into ( result ) return } 
func ( c * prowJobs ) Create ( prowJob * v1 . ProwJob ) ( result * v1 . ProwJob , err error ) { result = & v1 . ProwJob { } err = c . client . Post ( ) . Namespace ( c . ns ) . Resource ( " " ) . Body ( prowJob ) . Do ( ) . Into ( result ) return } 
func ( c * prowJobs ) Update ( prowJob * v1 . ProwJob ) ( result * v1 . ProwJob , err error ) { result = & v1 . ProwJob { } err = c . client . Put ( ) . Namespace ( c . ns ) . Resource ( " " ) . Name ( prowJob . Name ) . Body ( prowJob ) . Do ( ) . Into ( result ) return } 
func ( b Blockers ) GetApplicable ( org , repo , branch string ) [ ] Blocker { var res [ ] Blocker res = append ( res , b . Repo [ orgRepo { org : org , repo : repo } ] ... ) res = append ( res , b . Branch [ orgRepoBranch { org : org , repo : repo , branch : branch } ] ... ) sort . Slice ( res , func ( i , j int ) bool { return res [ i ] . Number < res [ j ] . Number } ) return res } 
func FindAll ( ghc githubClient , log * logrus . Entry , label , orgRepoTokens string ) ( Blockers , error ) { issues , err := search ( context . Background ( ) , ghc , log , blockerQuery ( label , orgRepoTokens ) , ) if err != nil { return Blockers { } , fmt . Errorf ( " " , err ) } return fromIssues ( issues ) , nil } 
func serve ( jc * jenkins . Client ) { http . Handle ( " " , gziphandler . GzipHandler ( handleLog ( jc ) ) ) http . Handle ( " " , promhttp . Handler ( ) ) logrus . WithError ( http . ListenAndServe ( " " , nil ) ) . Fatal ( " " ) } 
func NewCountPlugin ( runner func ( Plugin ) error ) * cobra . Command { stateCounter := & StatePlugin { } eventCounter := & EventCounterPlugin { } commentsAsEvents := NewFakeCommentPluginWrapper ( eventCounter ) commentCounter := & CommentCounterPlugin { } authorLoggable := NewMultiplexerPluginWrapper ( commentsAsEvents , commentCounter , ) authorLogged := NewAuthorLoggerPluginWrapper ( authorLoggable ) fullMultiplex := NewMultiplexerPluginWrapper ( authorLogged , stateCounter ) fakeOpen := NewFakeOpenPluginWrapper ( fullMultiplex ) typeFilter := NewTypeFilterWrapperPlugin ( fakeOpen ) authorFilter := NewAuthorFilterPluginWrapper ( typeFilter ) cmd := & cobra . Command { Use : " " , Short : " " , RunE : func ( cmd * cobra . Command , args [ ] string ) error { if err := eventCounter . CheckFlags ( ) ; err != nil { return err } if err := stateCounter . CheckFlags ( ) ; err != nil { return err } if err := typeFilter . CheckFlags ( ) ; err != nil { return err } if err := commentCounter . CheckFlags ( ) ; err != nil { return err } return runner ( authorFilter ) } , } eventCounter . AddFlags ( cmd ) stateCounter . AddFlags ( cmd ) commentCounter . AddFlags ( cmd ) typeFilter . AddFlags ( cmd ) authorFilter . AddFlags ( cmd ) authorLogged . AddFlags ( cmd ) return cmd } 
func ( o * FakeCommentPluginWrapper ) ReceiveIssue ( issue sql . Issue ) [ ] Point { } 
func ( o * FakeCommentPluginWrapper ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { } 
func ( o * FakeCommentPluginWrapper ) ReceiveComment ( comment sql . Comment ) [ ] Point { return append ( o . plugin . ReceiveComment ( comment ) , o . plugin . ReceiveIssueEvent ( fakeEvent ) ... , ) } 
func updateMetrics ( interval time . Duration , diskRoot string ) { logger := logrus . WithField ( " " , " " ) ticker := time . NewTicker ( interval ) for ; true ; <- ticker . C { logger . Info ( " " ) _ , bytesFree , bytesUsed , err := diskutil . GetDiskUsage ( diskRoot ) if err != nil { logger . WithError ( err ) . Error ( " " ) } else { promMetrics . DiskFree . Set ( float64 ( bytesFree ) / 1e9 ) promMetrics . DiskUsed . Set ( float64 ( bytesUsed ) / 1e9 ) promMetrics . DiskTotal . Set ( float64 ( bytesFree + bytesUsed ) / 1e9 ) } } } 
func NewRanch ( config string , s * Storage ) ( * Ranch , error ) { newRanch := & Ranch { Storage : s , UpdateTime : updateTime , } if config != " " { if err := newRanch . SyncConfig ( config ) ; err != nil { return nil , err } } newRanch . LogStatus ( ) return newRanch , nil } 
func ( r * Ranch ) Acquire ( rType , state , dest , owner string ) ( * common . Resource , error ) { r . resourcesLock . Lock ( ) defer r . resourcesLock . Unlock ( ) resources , err := r . Storage . GetResources ( ) if err != nil { logrus . WithError ( err ) . Errorf ( " " ) return nil , & ResourceNotFound { rType } } foundType := false for idx := range resources { res := resources [ idx ] if rType == res . Type { foundType = true if state == res . State && res . Owner == " " { res . LastUpdate = r . UpdateTime ( ) res . Owner = owner res . State = dest if err := r . Storage . UpdateResource ( res ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , res . Name ) return nil , err } return & res , nil } } } if foundType { return nil , & ResourceNotFound { rType } } return nil , & ResourceTypeNotFound { rType } } 
func ( r * Ranch ) AcquireByState ( state , dest , owner string , names [ ] string ) ( [ ] common . Resource , error ) { r . resourcesLock . Lock ( ) defer r . resourcesLock . Unlock ( ) if names == nil { return nil , fmt . Errorf ( " " ) } rNames := map [ string ] bool { } for _ , t := range names { rNames [ t ] = true } allResources , err := r . Storage . GetResources ( ) if err != nil { logrus . WithError ( err ) . Errorf ( " " ) return nil , & ResourceNotFound { state } } var resources [ ] common . Resource for idx := range allResources { res := allResources [ idx ] if state == res . State { if res . Owner != " " { continue } if rNames [ res . Name ] { res . LastUpdate = r . UpdateTime ( ) res . Owner = owner res . State = dest if err := r . Storage . UpdateResource ( res ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , res . Name ) return nil , err } resources = append ( resources , res ) delete ( rNames , res . Name ) } } } if len ( rNames ) != 0 { var missingResources [ ] string for n := range rNames { missingResources = append ( missingResources , n ) } err := & ResourceNotFound { state } logrus . WithError ( err ) . Errorf ( " " , strings . Join ( missingResources , " " ) ) return resources , err } return resources , nil } 
func ( r * Ranch ) Release ( name , dest , owner string ) error { r . resourcesLock . Lock ( ) defer r . resourcesLock . Unlock ( ) res , err := r . Storage . GetResource ( name ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , name ) return & ResourceNotFound { name } } if owner != res . Owner { return & OwnerNotMatch { owner : owner , request : res . Owner } } res . LastUpdate = r . UpdateTime ( ) res . Owner = " " res . State = dest if err := r . Storage . UpdateResource ( res ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , res . Name ) return err } return nil } 
func ( r * Ranch ) Update ( name , owner , state string , ud * common . UserData ) error { r . resourcesLock . Lock ( ) defer r . resourcesLock . Unlock ( ) res , err := r . Storage . GetResource ( name ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , name ) return & ResourceNotFound { name } } if owner != res . Owner { return & OwnerNotMatch { owner : owner , request : res . Owner } } if state != res . State { return & StateNotMatch { res . State , state } } if res . UserData == nil { res . UserData = & common . UserData { } } res . UserData . Update ( ud ) res . LastUpdate = r . UpdateTime ( ) if err := r . Storage . UpdateResource ( res ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , res . Name ) return err } return nil } 
func ( r * Ranch ) Reset ( rtype , state string , expire time . Duration , dest string ) ( map [ string ] string , error ) { r . resourcesLock . Lock ( ) defer r . resourcesLock . Unlock ( ) ret := make ( map [ string ] string ) resources , err := r . Storage . GetResources ( ) if err != nil { logrus . WithError ( err ) . Errorf ( " " ) return nil , err } for idx := range resources { res := resources [ idx ] if rtype == res . Type && state == res . State && res . Owner != " " { if time . Since ( res . LastUpdate ) > expire { res . LastUpdate = r . UpdateTime ( ) ret [ res . Name ] = res . Owner res . Owner = " " res . State = dest if err := r . Storage . UpdateResource ( res ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , res . Name ) return ret , err } } } } return ret , nil } 
func ( r * Ranch ) LogStatus ( ) { resources , err := r . Storage . GetResources ( ) if err != nil { return } resJSON , err := json . Marshal ( resources ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , resources ) } logrus . Infof ( " " , string ( resJSON ) ) } 
func ( r * Ranch ) SyncConfig ( config string ) error { resources , err := ParseConfig ( config ) if err != nil { return err } if err := r . Storage . SyncResources ( resources ) ; err != nil { return err } return nil } 
func ( r * Ranch ) Metric ( rtype string ) ( common . Metric , error ) { metric := common . Metric { Type : rtype , Current : map [ string ] int { } , Owners : map [ string ] int { } , } resources , err := r . Storage . GetResources ( ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return metric , & ResourceNotFound { rtype } } for _ , res := range resources { if res . Type != rtype { continue } if _ , ok := metric . Current [ res . State ] ; ! ok { metric . Current [ res . State ] = 0 } if _ , ok := metric . Owners [ res . Owner ] ; ! ok { metric . Owners [ res . Owner ] = 0 } metric . Current [ res . State ] ++ metric . Owners [ res . Owner ] ++ } if len ( metric . Current ) == 0 && len ( metric . Owners ) == 0 { return metric , & ResourceNotFound { rtype } } return metric , nil } 
func FormatURL ( dogURL string ) ( string , error ) { if dogURL == " " { return " " , errors . New ( " " ) } src , err := url . ParseRequestURI ( dogURL ) if err != nil { return " " , fmt . Errorf ( " " , dogURL , err ) } return fmt . Sprintf ( " " , src , src ) , nil } 
func TrustedUser ( ghc trustedUserClient , trigger plugins . Trigger , user , org , repo string ) ( bool , error ) { } else if ok { return true , nil } } } else if member { return true , nil } } if err != nil { return false , fmt . Errorf ( " " , trigger . TrustedOrg , err ) } return member , nil } 
func runAndSkipJobs ( c Client , pr * github . PullRequest , requestedJobs [ ] config . Presubmit , skippedJobs [ ] config . Presubmit , eventGUID string , elideSkippedContexts bool ) error { if err := validateContextOverlap ( requestedJobs , skippedJobs ) ; err != nil { c . Logger . WithError ( err ) . Warn ( " " ) return err } runErr := RunRequested ( c , pr , requestedJobs , eventGUID ) var skipErr error if ! elideSkippedContexts { skipErr = skipRequested ( c , pr , skippedJobs ) } return errorutil . NewAggregate ( runErr , skipErr ) } 
func validateContextOverlap ( toRun , toSkip [ ] config . Presubmit ) error { requestedContexts := sets . NewString ( ) for _ , job := range toRun { requestedContexts . Insert ( job . Context ) } skippedContexts := sets . NewString ( ) for _ , job := range toSkip { skippedContexts . Insert ( job . Context ) } if overlap := requestedContexts . Intersection ( skippedContexts ) . List ( ) ; len ( overlap ) > 0 { return fmt . Errorf ( " " , strings . Join ( overlap , " " ) ) } return nil } 
func RunRequested ( c Client , pr * github . PullRequest , requestedJobs [ ] config . Presubmit , eventGUID string ) error { baseSHA , err := c . GitHubClient . GetRef ( pr . Base . Repo . Owner . Login , pr . Base . Repo . Name , " " + pr . Base . Ref ) if err != nil { return err } var errors [ ] error for _ , job := range requestedJobs { c . Logger . Infof ( " " , job . Name ) pj := pjutil . NewPresubmit ( * pr , baseSHA , job , eventGUID ) c . Logger . WithFields ( pjutil . ProwJobFields ( & pj ) ) . Info ( " " ) if _ , err := c . ProwJobClient . Create ( & pj ) ; err != nil { c . Logger . WithError ( err ) . Error ( " " ) errors = append ( errors , err ) } } return errorutil . NewAggregate ( errors ... ) } 
func skipRequested ( c Client , pr * github . PullRequest , skippedJobs [ ] config . Presubmit ) error { var errors [ ] error for _ , job := range skippedJobs { if job . SkipReport { continue } c . Logger . Infof ( " " , job . Name ) if err := c . GitHubClient . CreateStatus ( pr . Base . Repo . Owner . Login , pr . Base . Repo . Name , pr . Head . SHA , skippedStatusFor ( job . Context ) ) ; err != nil { errors = append ( errors , err ) } } return errorutil . NewAggregate ( errors ... ) } 
func ( l LabelEvent ) Match ( eventName , label string ) bool { return eventName == " " && label == l . Label } 
func ( u UnlabelEvent ) Match ( eventName , label string ) bool { return eventName == " " && label == u . Label } 
func NewEventMatcher ( eventDescription string ) EventMatcher { split := strings . SplitN ( eventDescription , " " , 2 ) switch split [ 0 ] { case " " : return FalseEvent { } case " " : return CommentEvent { } case " " : return OpenEvent { } case " " : return ReopenEvent { } case " " : return MergeEvent { } case " " : return CloseEvent { } case " " : if len ( split ) != 2 { panic ( fmt . Errorf ( " " ) ) } return LabelEvent { split [ 1 ] } case " " : if len ( split ) != 2 { panic ( fmt . Errorf ( " " ) ) } return UnlabelEvent { split [ 1 ] } default : panic ( fmt . Errorf ( " " , split [ 0 ] ) ) } } 
func ( o * GitHubOptions ) AddFlags ( fs * flag . FlagSet ) { o . addFlags ( true , fs ) } 
func ( o * GitHubOptions ) AddFlagsWithoutDefaultGitHubTokenPath ( fs * flag . FlagSet ) { o . addFlags ( false , fs ) } 
func ( o * GitHubOptions ) Validate ( dryRun bool ) error { for _ , uri := range o . endpoint . Strings ( ) { if uri == " " { uri = github . DefaultAPIEndpoint } else if _ , err := url . ParseRequestURI ( uri ) ; err != nil { return fmt . Errorf ( " " , uri ) } } if o . graphqlEndpoint == " " { o . graphqlEndpoint = github . DefaultGraphQLEndpoint } else if _ , err := url . Parse ( o . graphqlEndpoint ) ; err != nil { return fmt . Errorf ( " " , o . graphqlEndpoint ) } if o . deprecatedTokenFile != " " { o . TokenPath = o . deprecatedTokenFile logrus . Error ( " " ) } if o . TokenPath == " " { logrus . Warn ( " " ) } return nil } 
func ( o * GitHubOptions ) GitHubClientWithLogFields ( secretAgent * secret . Agent , dryRun bool , fields logrus . Fields ) ( client * github . Client , err error ) { var generator * func ( ) [ ] byte if o . TokenPath == " " { generatorFunc := func ( ) [ ] byte { return [ ] byte { } } generator = & generatorFunc } else { if secretAgent == nil { return nil , fmt . Errorf ( " " , o . TokenPath ) } generatorFunc := secretAgent . GetTokenGenerator ( o . TokenPath ) generator = & generatorFunc } if dryRun { return github . NewDryRunClientWithFields ( fields , * generator , o . graphqlEndpoint , o . endpoint . Strings ( ) ... ) , nil } return github . NewClientWithFields ( fields , * generator , o . graphqlEndpoint , o . endpoint . Strings ( ) ... ) , nil } 
func ( o * GitHubOptions ) GitHubClient ( secretAgent * secret . Agent , dryRun bool ) ( client * github . Client , err error ) { return o . GitHubClientWithLogFields ( secretAgent , dryRun , logrus . Fields { } ) } 
func ( o * GitHubOptions ) GitClient ( secretAgent * secret . Agent , dryRun bool ) ( client * git . Client , err error ) { client , err = git . NewClient ( ) if err != nil { return nil , err } } } ( client ) if err != nil { return nil , fmt . Errorf ( " " , err ) } botName , err := githubClient . BotName ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } client . SetCredentials ( botName , secretAgent . GetTokenGenerator ( o . TokenPath ) ) return client , nil } 
func toMap ( g * calculation . CoverageList ) map [ string ] calculation . Coverage { m := make ( map [ string ] calculation . Coverage ) for _ , cov := range g . Group { m [ cov . Name ] = cov } return m } 
func findChanges ( baseList * calculation . CoverageList , newList * calculation . CoverageList ) [ ] * coverageChange { var changes [ ] * coverageChange baseFilesMap := toMap ( baseList ) for _ , newCov := range newList . Group { baseCov , ok := baseFilesMap [ newCov . Name ] var baseRatio float32 if ! ok { baseRatio = - 1 } else { baseRatio = baseCov . Ratio ( ) } newRatio := newCov . Ratio ( ) if isChangeSignificant ( baseRatio , newRatio ) { changes = append ( changes , & coverageChange { name : newCov . Name , baseRatio : baseRatio , newRatio : newRatio , } ) } } return changes } 
func ( config * MySQLConfig ) CreateDatabase ( ) ( * gorm . DB , error ) { db , err := gorm . Open ( " " , config . getDSN ( " " ) ) if err != nil { return nil , err } db . Exec ( fmt . Sprintf ( " " , config . Db ) ) db . Close ( ) db , err = gorm . Open ( " " , config . getDSN ( config . Db ) ) err = db . AutoMigrate ( & Assignee { } , & Issue { } , & IssueEvent { } , & Label { } , & Comment { } ) . Error if err != nil { return nil , err } return db , nil } 
func ( config * MySQLConfig ) AddFlags ( cmd * cobra . Command ) { cmd . PersistentFlags ( ) . StringVar ( & config . User , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & config . Password , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & config . Host , " " , " " , " " ) cmd . PersistentFlags ( ) . IntVar ( & config . Port , " " , 3306 , " " ) cmd . PersistentFlags ( ) . StringVar ( & config . Db , " " , " " , " " ) } 
func NewReporter ( gc report . GitHubClient , cfg config . Getter , reportAgent v1 . ProwJobAgent ) * Client { return & Client { gc : gc , config : cfg , reportAgent : reportAgent , } } 
func ( c * Client ) ShouldReport ( pj * v1 . ProwJob ) bool { if ! pj . Spec . Report { } if pj . Spec . Type != v1 . PresubmitJob && pj . Spec . Type != v1 . PostsubmitJob { } if c . reportAgent != " " && pj . Spec . Agent != c . reportAgent { } return true } 
func ( c * Client ) Report ( pj * v1 . ProwJob ) ( [ ] * v1 . ProwJob , error ) { } 
func ParseRefs ( value string ) ( * prowapi . Refs , error ) { gitRef := & prowapi . Refs { } values := strings . SplitN ( value , " " , 2 ) if len ( values ) != 2 { return gitRef , fmt . Errorf ( " " , value ) } info := values [ 0 ] allRefs := values [ 1 ] infoValues := strings . SplitN ( info , " " , 2 ) if len ( infoValues ) != 2 { return gitRef , fmt . Errorf ( " " , value ) } gitRef . Org = infoValues [ 0 ] gitRef . Repo = infoValues [ 1 ] refValues := strings . Split ( allRefs , " " ) if len ( refValues ) == 1 && refValues [ 0 ] == " " { return gitRef , fmt . Errorf ( " " , value ) } baseRefParts := strings . Split ( refValues [ 0 ] , " " ) if len ( baseRefParts ) != 1 && len ( baseRefParts ) != 2 { return gitRef , fmt . Errorf ( " " , refValues [ 0 ] ) } gitRef . BaseRef = baseRefParts [ 0 ] if len ( baseRefParts ) == 2 { gitRef . BaseSHA = baseRefParts [ 1 ] } for _ , refValue := range refValues [ 1 : ] { refParts := strings . Split ( refValue , " " ) if len ( refParts ) == 0 || len ( refParts ) > 3 { return gitRef , fmt . Errorf ( " " , refValue ) } pullNumber , err := strconv . Atoi ( refParts [ 0 ] ) if err != nil { return gitRef , fmt . Errorf ( " " , refValue , err ) } pullRef := prowapi . Pull { Number : pullNumber , } if len ( refParts ) > 1 { pullRef . SHA = refParts [ 1 ] } if len ( refParts ) > 2 { pullRef . Ref = refParts [ 2 ] } gitRef . Pulls = append ( gitRef . Pulls , pullRef ) } return gitRef , nil } 
func dateToken ( start , end time . Time ) string { if start . Year ( ) >= 1970 { startString = start . Format ( github . SearchTimeFormat ) } if end . Year ( ) >= 1970 { endString = end . Format ( github . SearchTimeFormat ) } return fmt . Sprintf ( " " , startString , endString ) } 
func ( s * Set ) Mark ( r Interface ) bool { key := r . ResourceKey ( ) now := time . Now ( ) s . marked [ key ] = true if t , ok := s . firstSeen [ key ] ; ok { since := now . Sub ( t ) if since > s . ttl { s . swept = append ( s . swept , key ) return true } klog . V ( 1 ) . Infof ( " " , key , since ) return false } s . firstSeen [ key ] = now klog . V ( 1 ) . Infof ( " " , key ) if s . ttl == 0 { return true } return false } 
func ( s * Set ) MarkComplete ( ) int { var gone [ ] string for key := range s . firstSeen { if ! s . marked [ key ] { gone = append ( gone , key ) } } for _ , key := range gone { klog . V ( 1 ) . Infof ( " " , key ) delete ( s . firstSeen , key ) } if len ( s . swept ) > 0 { klog . Errorf ( " " , len ( s . swept ) , s . swept ) } return len ( s . swept ) } 
func NewJobAgent ( kc serviceClusterClient , plClients map [ string ] PodLogClient , cfg config . Getter ) * JobAgent { return & JobAgent { kc : kc , pkcs : plClients , config : cfg , } } 
func ( ja * JobAgent ) Start ( ) { ja . tryUpdate ( ) go func ( ) { t := time . Tick ( period ) for range t { ja . tryUpdate ( ) } } ( ) } 
func ( ja * JobAgent ) Jobs ( ) [ ] Job { ja . mut . Lock ( ) defer ja . mut . Unlock ( ) res := make ( [ ] Job , len ( ja . jobs ) ) copy ( res , ja . jobs ) return res } 
func ( ja * JobAgent ) ProwJobs ( ) [ ] prowapi . ProwJob { ja . mut . Lock ( ) defer ja . mut . Unlock ( ) res := make ( [ ] prowapi . ProwJob , len ( ja . prowJobs ) ) copy ( res , ja . prowJobs ) return res } 
func ( ja * JobAgent ) GetProwJob ( job , id string ) ( prowapi . ProwJob , error ) { if ja == nil { return prowapi . ProwJob { } , fmt . Errorf ( " " ) } var j prowapi . ProwJob ja . mut . Lock ( ) idMap , ok := ja . jobsIDMap [ job ] if ok { j , ok = idMap [ id ] } ja . mut . Unlock ( ) if ! ok { return prowapi . ProwJob { } , errProwjobNotFound } return j , nil } 
func ( ja * JobAgent ) GetJobLog ( job , id string ) ( [ ] byte , error ) { j , err := ja . GetProwJob ( job , id ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if j . Spec . Agent == prowapi . KubernetesAgent { client , ok := ja . pkcs [ j . ClusterAlias ( ) ] if ! ok { return nil , fmt . Errorf ( " " , j . ObjectMeta . Name , j . Spec . Agent , j . ClusterAlias ( ) ) } return client . GetLogs ( j . Status . PodName , & coreapi . PodLogOptions { Container : kube . TestContainerName } ) } for _ , agentToTmpl := range ja . config ( ) . Deck . ExternalAgentLogs { if agentToTmpl . Agent != string ( j . Spec . Agent ) { continue } if ! agentToTmpl . Selector . Matches ( labels . Set ( j . ObjectMeta . Labels ) ) { continue } var b bytes . Buffer if err := agentToTmpl . URLTemplate . Execute ( & b , & j ) ; err != nil { return nil , fmt . Errorf ( " " , j . ObjectMeta . Name , j . Spec . Agent , err ) } resp , err := http . Get ( b . String ( ) ) if err != nil { return nil , err } defer resp . Body . Close ( ) return ioutil . ReadAll ( resp . Body ) } return nil , fmt . Errorf ( " " , j . ObjectMeta . Name , j . Spec . Agent ) } 
func unionStrings ( parent , child [ ] string ) [ ] string { if child == nil { return parent } if parent == nil { return child } s := sets . NewString ( parent ... ) s . Insert ( child ... ) return s . List ( ) } 
func ( p Policy ) Apply ( child Policy ) Policy { return Policy { Protect : selectBool ( p . Protect , child . Protect ) , RequiredStatusChecks : mergeContextPolicy ( p . RequiredStatusChecks , child . RequiredStatusChecks ) , Admins : selectBool ( p . Admins , child . Admins ) , Restrictions : mergeRestrictions ( p . Restrictions , child . Restrictions ) , RequiredPullRequestReviews : mergeReviewPolicy ( p . RequiredPullRequestReviews , child . RequiredPullRequestReviews ) , } } 
func ( bp BranchProtection ) GetOrg ( name string ) * Org { o , ok := bp . Orgs [ name ] if ok { o . Policy = bp . Apply ( o . Policy ) } else { o . Policy = bp . Policy } return & o } 
func ( o Org ) GetRepo ( name string ) * Repo { r , ok := o . Repos [ name ] if ok { r . Policy = o . Apply ( r . Policy ) } else { r . Policy = o . Policy } return & r } 
func ( r Repo ) GetBranch ( name string ) ( * Branch , error ) { b , ok := r . Branches [ name ] if ok { b . Policy = r . Apply ( b . Policy ) if b . Protect == nil { return nil , errors . New ( " " ) } } else { b . Policy = r . Policy } return & b , nil } 
func ( c * Config ) GetBranchProtection ( org , repo , branch string ) ( * Policy , error ) { if _ , present := c . BranchProtection . Orgs [ org ] ; ! present { return nil , nil } b , err := c . BranchProtection . GetOrg ( org ) . GetRepo ( repo ) . GetBranch ( branch ) if err != nil { return nil , err } return c . GetPolicy ( org , repo , branch , * b ) } 
func ( c * Config ) GetPolicy ( org , repo , branch string , b Branch ) ( * Policy , error ) { policy := b . Policy } ps := Policy { RequiredStatusChecks : & ContextPolicy { Contexts : prowContexts , } , } ps . Protect = & yes } policy = policy . Apply ( ps ) } if policy . Protect != nil && ! * policy . Protect { old , policy . Protect = policy . Protect , old switch { case policy . defined ( ) && c . BranchProtection . AllowDisabledPolicies : logrus . Warnf ( " " , org , repo , branch ) policy = Policy { Protect : policy . Protect , } case policy . defined ( ) : return nil , fmt . Errorf ( " " , org , repo , branch ) } policy . Protect = old } if ! policy . defined ( ) { return nil , nil } return & policy , nil } 
func BranchRequirements ( org , repo , branch string , presubmits map [ string ] [ ] Presubmit ) ( [ ] string , [ ] string , [ ] string ) { jobs , ok := presubmits [ org + " " + repo ] if ! ok { return nil , nil , nil } var required , requiredIfPresent , optional [ ] string for _ , j := range jobs { if ! j . CouldRun ( branch ) { continue } if j . ContextRequired ( ) { if j . TriggersConditionally ( ) { } else { } } else { optional = append ( optional , j . Context ) } } return required , requiredIfPresent , optional } 
func UpdateIssueEvents ( issueID int , db * gorm . DB , client ClientInterface ) { latest , err := findLatestEvent ( issueID , db , client . RepositoryName ( ) ) if err != nil { glog . Error ( " " , err ) return } c := make ( chan * github . IssueEvent , 500 ) go client . FetchIssueEvents ( issueID , latest , c ) for event := range c { eventOrm , err := NewIssueEvent ( event , issueID , client . RepositoryName ( ) ) if err != nil { glog . Error ( " " , err ) } db . Create ( eventOrm ) } } 
func ( c * controller ) enqueueKey ( ctx string , obj interface { } ) { switch o := obj . ( type ) { case * prowjobv1 . ProwJob : c . workqueue . AddRateLimited ( toKey ( ctx , o . Spec . Namespace , o . Name ) ) case * buildv1alpha1 . Build : c . workqueue . AddRateLimited ( toKey ( ctx , o . Namespace , o . Name ) ) default : logrus . Warnf ( " " , o , obj ) return } } 
func reconcile ( c reconciler , key string ) error { ctx , namespace , name , err := fromKey ( key ) if err != nil { runtime . HandleError ( err ) return nil } if err := c . terminateDupProwJobs ( ctx , namespace ) ; err != nil { logrus . WithError ( err ) . Warn ( " " ) } var wantBuild bool pj , err := c . getProwJob ( name ) switch { case apierrors . IsNotFound ( err ) : case pj . Spec . Agent != prowjobv1 . KnativeBuildAgent : case pj . DeletionTimestamp == nil : wantBuild = true } var haveBuild bool b , err := c . getBuild ( ctx , namespace , name ) switch { case apierrors . IsNotFound ( err ) : case b . DeletionTimestamp == nil : haveBuild = true } var newBuildID bool } return nil } switch v , ok := b . Labels [ kube . CreatedByProw ] ; { case ! ok , v != " " : } logrus . Infof ( " " , key ) if err = c . deleteBuild ( ctx , namespace , name ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil case finalState ( pj . Status . State ) : logrus . Infof ( " " , key ) return nil case wantBuild && pj . Spec . BuildSpec == nil : return errors . New ( " " ) case wantBuild && ! haveBuild : id , url , err := c . buildID ( * pj ) if err != nil { return fmt . Errorf ( " " , err ) } pj . Status . BuildID = id pj . Status . URL = url newBuildID = true if b , err = makeBuild ( * pj , c . defaultBuildTimeout ( ) ) ; err != nil { return fmt . Errorf ( " " , err ) } logrus . Infof ( " " , key ) if b , err = c . createBuild ( ctx , namespace , b ) ; err != nil { return fmt . Errorf ( " " , err ) } } haveMsg := pj . Status . Description wantState , wantMsg := prowJobStatus ( b . Status ) if newBuildID || haveState != wantState || haveMsg != wantMsg { npj := pj . DeepCopy ( ) if npj . Status . StartTime . IsZero ( ) { npj . Status . StartTime = c . now ( ) } if npj . Status . CompletionTime . IsZero ( ) && finalState ( wantState ) { now := c . now ( ) npj . Status . CompletionTime = & now } npj . Status . State = wantState npj . Status . Description = wantMsg logrus . Infof ( " " , key ) if _ , err = c . updateProwJob ( npj ) ; err != nil { return fmt . Errorf ( " " , err ) } } return nil } 
func prowJobStatus ( bs buildv1alpha1 . BuildStatus ) ( prowjobv1 . ProwJobState , string ) { started := bs . StartTime finished := bs . CompletionTime pcond := bs . GetCondition ( buildv1alpha1 . BuildSucceeded ) if pcond == nil { if ! finished . IsZero ( ) { return prowjobv1 . ErrorState , descMissingCondition } return prowjobv1 . TriggeredState , descScheduling } cond := * pcond switch { case cond . Status == coreapi . ConditionTrue : return prowjobv1 . SuccessState , description ( cond , descSucceeded ) case cond . Status == coreapi . ConditionFalse : return prowjobv1 . FailureState , description ( cond , descFailed ) case started . IsZero ( ) : return prowjobv1 . TriggeredState , description ( cond , descInitializing ) case cond . Status == coreapi . ConditionUnknown , finished . IsZero ( ) : return prowjobv1 . PendingState , description ( cond , descRunning ) } logrus . Warnf ( " " , cond ) return prowjobv1 . ErrorState , description ( cond , descUnknown ) } 
func buildEnv ( pj prowjobv1 . ProwJob , buildID string ) ( map [ string ] string , error ) { return downwardapi . EnvForSpec ( downwardapi . NewJobSpec ( pj . Spec , buildID , pj . Name ) ) } 
func defaultArguments ( t * buildv1alpha1 . TemplateInstantiationSpec , rawEnv map [ string ] string ) { keys := sets . String { } for _ , arg := range t . Arguments { keys . Insert ( arg . Name ) } for _ , k := range sets . StringKeySet ( rawEnv ) . List ( ) { } t . Arguments = append ( t . Arguments , buildv1alpha1 . ArgumentSpec { Name : k , Value : rawEnv [ k ] } ) } } 
func defaultEnv ( c * coreapi . Container , rawEnv map [ string ] string ) { keys := sets . String { } for _ , arg := range c . Env { keys . Insert ( arg . Name ) } for _ , k := range sets . StringKeySet ( rawEnv ) . List ( ) { } c . Env = append ( c . Env , coreapi . EnvVar { Name : k , Value : rawEnv [ k ] } ) } } 
func injectEnvironment ( b * buildv1alpha1 . Build , rawEnv map [ string ] string ) { for i := range b . Spec . Steps { } if b . Spec . Template != nil { } } 
func injectSource ( b * buildv1alpha1 . Build , pj prowjobv1 . ProwJob ) ( bool , error ) { if b . Spec . Source != nil { return false , nil } srcContainer , refs , cloneVolumes , err := decorate . CloneRefs ( pj , codeMount , logMount ) if err != nil { return false , fmt . Errorf ( " " , err ) } if srcContainer == nil { return false , nil } else { srcContainer . Name = " " } b . Spec . Source = & buildv1alpha1 . SourceSpec { Custom : srcContainer , } b . Spec . Volumes = append ( b . Spec . Volumes , cloneVolumes ... ) wd := workDir ( refs [ 0 ] ) } b . Spec . Steps [ i ] . WorkingDir = wd . Value } if b . Spec . Template != nil { } return true , nil } 
func injectedSteps ( encodedJobSpec string , dc prowjobv1 . DecorationConfig , injectedSource bool , toolsMount coreapi . VolumeMount , entries [ ] wrapper . Options ) ( [ ] coreapi . Container , * coreapi . Container , * coreapi . Volume , error ) { gcsVol , gcsMount , gcsOptions := decorate . GCSOptions ( dc ) sidecar , err := decorate . Sidecar ( dc . UtilityImages . Sidecar , gcsOptions , gcsMount , logMount , encodedJobSpec , decorate . RequirePassingEntries , entries ... ) if err != nil { return nil , nil , nil , fmt . Errorf ( " " , err ) } var cloneLogMount * coreapi . VolumeMount if injectedSource { cloneLogMount = & logMount } initUpload , err := decorate . InitUpload ( dc . UtilityImages . InitUpload , gcsOptions , gcsMount , cloneLogMount , encodedJobSpec ) if err != nil { return nil , nil , nil , fmt . Errorf ( " " , err ) } placer := decorate . PlaceEntrypoint ( dc . UtilityImages . Entrypoint , toolsMount ) return [ ] coreapi . Container { placer , * initUpload } , sidecar , & gcsVol , nil } 
func determineTimeout ( spec * buildv1alpha1 . BuildSpec , dc * prowjobv1 . DecorationConfig , defaultTimeout time . Duration ) time . Duration { switch { case spec . Timeout != nil : return spec . Timeout . Duration case dc != nil && dc . Timeout . Duration > 0 : return dc . Timeout . Duration default : return defaultTimeout } } 
func makeBuild ( pj prowjobv1 . ProwJob , defaultTimeout time . Duration ) ( * buildv1alpha1 . Build , error ) { if pj . Spec . BuildSpec == nil { return nil , errors . New ( " " ) } buildID := pj . Status . BuildID if buildID == " " { return nil , errors . New ( " " ) } b := buildv1alpha1 . Build { ObjectMeta : buildMeta ( pj ) , Spec : * pj . Spec . BuildSpec . DeepCopy ( ) , } rawEnv , err := buildEnv ( pj , buildID ) if err != nil { return nil , fmt . Errorf ( " " , err ) } injectEnvironment ( & b , rawEnv ) injectedSource , err := injectSource ( & b , pj ) if err != nil { return nil , fmt . Errorf ( " " , err ) } injectTimeout ( & b . Spec , pj . Spec . DecorationConfig , defaultTimeout ) if pj . Spec . DecorationConfig != nil { encodedJobSpec := rawEnv [ downwardapi . JobSpecEnv ] err = decorateBuild ( & b . Spec , encodedJobSpec , * pj . Spec . DecorationConfig , injectedSource ) if err != nil { return nil , fmt . Errorf ( " " , err ) } } return & b , nil } 
func NewIssue ( gIssue * github . Issue , repository string ) ( * sql . Issue , error ) { if gIssue . Number == nil || gIssue . Title == nil || gIssue . User == nil || gIssue . User . Login == nil || gIssue . State == nil || gIssue . Comments == nil || gIssue . CreatedAt == nil || gIssue . UpdatedAt == nil { return nil , fmt . Errorf ( " " , gIssue ) } var closedAt * time . Time if gIssue . ClosedAt != nil { closedAt = gIssue . ClosedAt } assignees , err := newAssignees ( * gIssue . Number , gIssue . Assignees , repository ) if err != nil { return nil , err } var body string if gIssue . Body != nil { body = * gIssue . Body } isPR := ( gIssue . PullRequestLinks != nil && gIssue . PullRequestLinks . URL != nil ) labels , err := newLabels ( * gIssue . Number , gIssue . Labels , repository ) if err != nil { return nil , err } return & sql . Issue { ID : strconv . Itoa ( * gIssue . Number ) , Labels : labels , Title : * gIssue . Title , Body : body , User : * gIssue . User . Login , Assignees : assignees , State : * gIssue . State , Comments : * gIssue . Comments , IsPR : isPR , IssueClosedAt : closedAt , IssueCreatedAt : * gIssue . CreatedAt , IssueUpdatedAt : * gIssue . UpdatedAt , Repository : strings . ToLower ( repository ) , } , nil } 
func NewIssueEvent ( gIssueEvent * github . IssueEvent , issueID int , repository string ) ( * sql . IssueEvent , error ) { if gIssueEvent . ID == nil || gIssueEvent . Event == nil || gIssueEvent . CreatedAt == nil { return nil , fmt . Errorf ( " " , gIssueEvent ) } var label * string if gIssueEvent . Label != nil { label = gIssueEvent . Label . Name } var assignee * string if gIssueEvent . Assignee != nil { assignee = gIssueEvent . Assignee . Login } var actor * string if gIssueEvent . Actor != nil { actor = gIssueEvent . Actor . Login } return & sql . IssueEvent { ID : itoa ( * gIssueEvent . ID ) , Label : label , Event : * gIssueEvent . Event , EventCreatedAt : * gIssueEvent . CreatedAt , IssueID : strconv . Itoa ( issueID ) , Assignee : assignee , Actor : actor , Repository : strings . ToLower ( repository ) , } , nil } 
func newLabels ( issueID int , gLabels [ ] github . Label , repository string ) ( [ ] sql . Label , error ) { labels := [ ] sql . Label { } repository = strings . ToLower ( repository ) for _ , label := range gLabels { if label . Name == nil { return nil , fmt . Errorf ( " " ) } labels = append ( labels , sql . Label { IssueID : strconv . Itoa ( issueID ) , Name : * label . Name , Repository : repository , } ) } return labels , nil } 
func newAssignees ( issueID int , gAssignees [ ] * github . User , repository string ) ( [ ] sql . Assignee , error ) { assignees := [ ] sql . Assignee { } repository = strings . ToLower ( repository ) for _ , assignee := range gAssignees { if assignee != nil && assignee . Login == nil { return nil , fmt . Errorf ( " " ) } assignees = append ( assignees , sql . Assignee { IssueID : strconv . Itoa ( issueID ) , Name : * assignee . Login , Repository : repository , } ) } return assignees , nil } 
func NewIssueComment ( issueID int , gComment * github . IssueComment , repository string ) ( * sql . Comment , error ) { if gComment . ID == nil || gComment . Body == nil || gComment . CreatedAt == nil || gComment . UpdatedAt == nil { return nil , fmt . Errorf ( " " , gComment ) } var login string if gComment . User != nil && gComment . User . Login != nil { login = * gComment . User . Login } return & sql . Comment { ID : itoa ( * gComment . ID ) , IssueID : strconv . Itoa ( issueID ) , Body : * gComment . Body , User : login , CommentCreatedAt : * gComment . CreatedAt , CommentUpdatedAt : * gComment . UpdatedAt , PullRequest : false , Repository : strings . ToLower ( repository ) , } , nil } 
func messageFilter ( lastUpdate time . Time , change client . ChangeInfo , presubmits [ ] config . Presubmit ) ( pjutil . Filter , error ) { var filters [ ] pjutil . Filter currentRevision := change . Revisions [ change . CurrentRevision ] . Number for _ , message := range change . Messages { messageTime := message . Date . Time if message . RevisionNumber != currentRevision || ! messageTime . After ( lastUpdate ) { continue } if ! pjutil . TestAllRe . MatchString ( message . Message ) { for _ , presubmit := range presubmits { if presubmit . TriggerMatches ( message . Message ) { logrus . Infof ( " " , change . Number , message . Message , presubmit . Name ) filters = append ( filters , pjutil . CommandFilter ( message . Message ) ) } } } else { filters = append ( filters , pjutil . TestAllFilter ( ) ) } } return pjutil . AggregateFilter ( filters ) , nil } 
func ( jb * Build ) IsSuccess ( ) bool { return jb . Result != nil && * jb . Result == success } 
func ( jb * Build ) IsFailure ( ) bool { return jb . Result != nil && ( * jb . Result == failure || * jb . Result == unstable ) } 
func ( jb * Build ) IsAborted ( ) bool { return jb . Result != nil && * jb . Result == aborted } 
func ( jb * Build ) ProwJobID ( ) string { for _ , action := range jb . Actions { for _ , p := range action . Parameters { if p . Name == prowJobID { value , ok := p . Value . ( string ) if ! ok { logrus . Errorf ( " " , p . Name , jb ) continue } return value } } } return " " } 
func ( jb * Build ) BuildID ( ) string { var buildID string hasProwJobID := false for _ , action := range jb . Actions { for _ , p := range action . Parameters { hasProwJobID = hasProwJobID || p . Name == prowJobID if p . Name == statusBuildID { value , ok := p . Value . ( string ) if ! ok { logrus . Errorf ( " " , p . Name , jb ) continue } buildID = value } } } if ! hasProwJobID { return " " } return buildID } 
func NewClient ( url string , dryRun bool , tlsConfig * tls . Config , authConfig * AuthConfig , logger * logrus . Entry , metrics * ClientMetrics , ) ( * Client , error ) { if logger == nil { logger = logrus . NewEntry ( logrus . StandardLogger ( ) ) } c := & Client { logger : logger . WithField ( " " , " " ) , dryRun : dryRun , baseURL : url , authConfig : authConfig , client : & http . Client { Timeout : 30 * time . Second , } , metrics : metrics , } if tlsConfig != nil { c . client . Transport = & http . Transport { TLSClientConfig : tlsConfig } } if c . authConfig . CSRFProtect { if err := c . CrumbRequest ( ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } } return c , nil } 
func ( c * Client ) CrumbRequest ( ) error { if c . authConfig . csrfToken != " " && c . authConfig . csrfRequestField != " " { return nil } c . logger . Debug ( " " ) data , err := c . GetSkipMetrics ( " " ) if err != nil { return err } crumbResp := struct { Crumb string `json:"crumb"` CrumbRequestField string `json:"crumbRequestField"` } { } if err := json . Unmarshal ( data , & crumbResp ) ; err != nil { return fmt . Errorf ( " " , err ) } c . authConfig . csrfToken = crumbResp . Crumb c . authConfig . csrfRequestField = crumbResp . CrumbRequestField return nil } 
func ( c * Client ) measure ( method , path string , code int , start time . Time ) { if c . metrics == nil { return } c . metrics . RequestLatency . WithLabelValues ( method , path ) . Observe ( time . Since ( start ) . Seconds ( ) ) c . metrics . Requests . WithLabelValues ( method , path , fmt . Sprintf ( " " , code ) ) . Inc ( ) } 
func ( c * Client ) GetSkipMetrics ( path string ) ( [ ] byte , error ) { resp , err := c . request ( http . MethodGet , path , nil , false ) if err != nil { return nil , err } return readResp ( resp ) } 
func ( c * Client ) Get ( path string ) ( [ ] byte , error ) { resp , err := c . request ( http . MethodGet , path , nil , true ) if err != nil { return nil , err } return readResp ( resp ) } 
func ( c * Client ) request ( method , path string , params url . Values , measure bool ) ( * http . Response , error ) { var resp * http . Response var err error backoff := retryDelay urlPath := fmt . Sprintf ( " " , c . baseURL , path ) if params != nil { urlPath = fmt . Sprintf ( " " , urlPath , params . Encode ( ) ) } start := time . Now ( ) for retries := 0 ; retries < maxRetries ; retries ++ { resp , err = c . doRequest ( method , urlPath ) if err == nil && resp . StatusCode < 500 { break } else if err == nil && retries + 1 < maxRetries { resp . Body . Close ( ) } } time . Sleep ( backoff ) backoff *= 2 } if measure && resp != nil { c . measure ( method , path , resp . StatusCode , start ) } return resp , err } 
func ( c * Client ) doRequest ( method , path string ) ( * http . Response , error ) { req , err := http . NewRequest ( method , path , nil ) if err != nil { return nil , err } if c . authConfig != nil { if c . authConfig . Basic != nil { req . SetBasicAuth ( c . authConfig . Basic . User , string ( c . authConfig . Basic . GetToken ( ) ) ) } if c . authConfig . BearerToken != nil { req . Header . Set ( " " , fmt . Sprintf ( " " , c . authConfig . BearerToken . GetToken ( ) ) ) } if c . authConfig . CSRFProtect && c . authConfig . csrfRequestField != " " && c . authConfig . csrfToken != " " { req . Header . Set ( c . authConfig . csrfRequestField , c . authConfig . csrfToken ) } } return c . client . Do ( req ) } 
func getJobName ( spec * prowapi . ProwJobSpec ) string { if spec . JenkinsSpec != nil && spec . JenkinsSpec . GitHubBranchSourceJob && spec . Refs != nil { if len ( spec . Refs . Pulls ) > 0 { return fmt . Sprintf ( " " , spec . Job , spec . Refs . Pulls [ 0 ] . Number ) } return fmt . Sprintf ( " " , spec . Job , spec . Refs . BaseRef ) } return spec . Job } 
func getBuildPath ( spec * prowapi . ProwJobSpec ) string { jenkinsJobName := getJobName ( spec ) jenkinsPath := fmt . Sprintf ( " " , jenkinsJobName ) return jenkinsPath } 
func ( c * Client ) GetJobInfo ( spec * prowapi . ProwJobSpec ) ( * JobInfo , error ) { path := getJobInfoPath ( spec ) c . logger . Debugf ( " " , path ) data , err := c . Get ( path ) if err != nil { c . logger . Errorf ( " " , err ) return nil , err } var jobInfo JobInfo if err := json . Unmarshal ( data , & jobInfo ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } c . logger . Tracef ( " " , jobInfo ) return & jobInfo , nil } 
func ( c * Client ) JobParameterized ( jobInfo * JobInfo ) bool { for _ , prop := range jobInfo . Property { if prop . ParameterDefinitions != nil && len ( prop . ParameterDefinitions ) > 0 { return true } } return false } 
func ( c * Client ) EnsureBuildableJob ( spec * prowapi . ProwJobSpec ) error { var jobInfo * JobInfo getJobErr := wait . ExponentialBackoff ( getJobInfoBackoff , func ( ) ( bool , error ) { var jobErr error jobInfo , jobErr = c . GetJobInfo ( spec ) if jobErr != nil && ! strings . Contains ( strings . ToLower ( jobErr . Error ( ) ) , " " ) { return false , jobErr } return jobInfo != nil , nil } ) if getJobErr != nil { return fmt . Errorf ( " " , spec . Job ) } isParameterized := c . JobParameterized ( jobInfo ) c . logger . Tracef ( " " , isParameterized ) if isParameterized || len ( jobInfo . Builds ) > 0 { return nil } buildErr := c . LaunchBuild ( spec , nil ) if buildErr != nil { return buildErr } backoff := wait . Backoff { Duration : time . Duration ( 5 ) * time . Second , Factor : 1 , Jitter : 1 , Steps : 10 , } return wait . ExponentialBackoff ( backoff , func ( ) ( bool , error ) { c . logger . Debugf ( " " , spec . Job ) jobInfo , _ := c . GetJobInfo ( spec ) isParameterized := false if jobInfo != nil { isParameterized = c . JobParameterized ( jobInfo ) if isParameterized && jobInfo . LastBuild != nil { c . logger . Debugf ( " " , spec . Job ) err := c . Abort ( getJobName ( spec ) , jobInfo . LastBuild ) if err != nil { c . logger . Infof ( " " , jobInfo . LastBuild . Number , spec . Job , err ) } } } } ) } 
func ( c * Client ) LaunchBuild ( spec * prowapi . ProwJobSpec , params url . Values ) error { var path string if params != nil { path = getBuildWithParametersPath ( spec ) } else { path = getBuildPath ( spec ) } c . logger . Debugf ( " " , path ) resp , err := c . request ( http . MethodPost , path , params , true ) if err != nil { return err } defer resp . Body . Close ( ) if resp . StatusCode != 201 { return fmt . Errorf ( " " , resp . Status ) } return nil } 
func ( c * Client ) Build ( pj * prowapi . ProwJob , buildID string ) error { c . logger . WithFields ( pjutil . ProwJobFields ( pj ) ) . Info ( " " ) return c . BuildFromSpec ( & pj . Spec , buildID , pj . ObjectMeta . Name ) } 
func ( c * Client ) BuildFromSpec ( spec * prowapi . ProwJobSpec , buildID , prowJobID string ) error { if c . dryRun { return nil } env , err := downwardapi . EnvForSpec ( downwardapi . NewJobSpec ( * spec , buildID , prowJobID ) ) if err != nil { return err } params := url . Values { } for key , value := range env { params . Set ( key , value ) } if err := c . EnsureBuildableJob ( spec ) ; err != nil { return fmt . Errorf ( " " , spec . Job , err ) } return c . LaunchBuild ( spec , params ) } 
func ( c * Client ) ListBuilds ( jobs [ ] BuildQueryParams ) ( map [ string ] Build , error ) { if err != nil { return nil , err } buildChan := make ( chan map [ string ] Build , len ( jobs ) ) errChan := make ( chan error , len ( jobs ) ) wg := & sync . WaitGroup { } wg . Add ( len ( jobs ) ) builds , err := c . GetBuilds ( job ) if err != nil { errChan <- err } else { buildChan <- builds } } ( job . JobName ) } wg . Wait ( ) close ( buildChan ) close ( errChan ) for err := range errChan { if err != nil { return nil , err } } for builds := range buildChan { for id , build := range builds { jenkinsBuilds [ id ] = build } } return jenkinsBuilds , nil } 
func ( c * Client ) GetEnqueuedBuilds ( jobs [ ] BuildQueryParams ) ( map [ string ] Build , error ) { c . logger . Debug ( " " ) data , err := c . Get ( " " ) if err != nil { return nil , fmt . Errorf ( " " , err ) } page := struct { QueuedBuilds [ ] Build `json:"items"` } { } if err := json . Unmarshal ( data , & page ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } jenkinsBuilds := make ( map [ string ] Build ) for _ , jb := range page . QueuedBuilds { prowJobID := jb . ProwJobID ( ) } for _ , job := range jobs { if prowJobID == job . ProwJobID { exists = true break } } if ! exists { continue } jb . enqueued = true jenkinsBuilds [ prowJobID ] = jb } return jenkinsBuilds , nil } 
func ( c * Client ) GetBuilds ( job string ) ( map [ string ] Build , error ) { c . logger . Debugf ( " " , job ) data , err := c . Get ( fmt . Sprintf ( " " , job ) ) if err != nil { return nil , nil } return nil , fmt . Errorf ( " " , job , err ) } page := struct { Builds [ ] Build `json:"builds"` } { } if err := json . Unmarshal ( data , & page ) ; err != nil { return nil , fmt . Errorf ( " " , job , err ) } jenkinsBuilds := make ( map [ string ] Build ) for _ , jb := range page . Builds { prowJobID := jb . ProwJobID ( ) } jenkinsBuilds [ prowJobID ] = jb } return jenkinsBuilds , nil } 
func ( c * Client ) Abort ( job string , build * Build ) error { c . logger . Debugf ( " " , job , build . Number ) if c . dryRun { return nil } resp , err := c . request ( http . MethodPost , fmt . Sprintf ( " " , job , build . Number ) , nil , false ) if err != nil { return err } defer resp . Body . Close ( ) if resp . StatusCode < 200 || resp . StatusCode >= 300 { return fmt . Errorf ( " " , resp . Status ) } return nil } 
func PresubmitToJobSpec ( pre config . Presubmit ) * downwardapi . JobSpec { return & downwardapi . JobSpec { Type : prowapi . PresubmitJob , Job : pre . Name , } } 
func PostsubmitToJobSpec ( post config . Postsubmit ) * downwardapi . JobSpec { return & downwardapi . JobSpec { Type : prowapi . PostsubmitJob , Job : post . Name , } } 
func PeriodicToJobSpec ( periodic config . Periodic ) * downwardapi . JobSpec { return & downwardapi . JobSpec { Type : prowapi . PeriodicJob , Job : periodic . Name , } } 
func GetBuildID ( name , totURL string ) ( string , error ) { if totURL == " " { return node . Generate ( ) . String ( ) , nil } var err error url , err := url . Parse ( totURL ) if err != nil { return " " , fmt . Errorf ( " " , err ) } url . Path = path . Join ( url . Path , " " , name ) sleepDuration := 100 * time . Millisecond for retries := 0 ; retries < 10 ; retries ++ { if retries > 0 { sleep ( sleepDuration ) sleepDuration = sleepDuration * 2 } var resp * http . Response resp , err = http . Get ( url . String ( ) ) if err != nil { continue } defer resp . Body . Close ( ) if resp . StatusCode != 200 { err = fmt . Errorf ( " " , resp . Status ) continue } var buf [ ] byte buf , err = ioutil . ReadAll ( resp . Body ) if err == nil { return string ( buf ) , nil } return " " , err } return " " , err } 
func listGcsObjects ( ctx context . Context , client * storage . Client , bucketName , prefix , delim string ) ( [ ] string , error ) { var objects [ ] string it := client . Bucket ( bucketName ) . Objects ( ctx , & storage . Query { Prefix : prefix , Delimiter : delim , } ) for { attrs , err := it . Next ( ) if err == iterator . Done { break } if err != nil { return objects , fmt . Errorf ( " " , err ) } if attrs . Prefix != " " { objects = append ( objects , path . Base ( attrs . Prefix ) ) } } logrus . Info ( " " ) return objects , nil } 
func FindBaseProfile ( ctx context . Context , client * storage . Client , bucket , prowJobName , artifactsDirName , covProfileName string ) ( [ ] byte , error ) { dirOfJob := path . Join ( " " , prowJobName ) strBuilds , err := listGcsObjects ( ctx , client , bucket , dirOfJob + " " , " " ) if err != nil { return nil , fmt . Errorf ( " " , err ) } builds := sortBuilds ( strBuilds ) profilePath := " " for _ , build := range builds { buildDirPath := path . Join ( dirOfJob , strconv . Itoa ( build ) ) dirOfStatusJSON := path . Join ( buildDirPath , statusJSON ) statusText , err := readGcsObject ( ctx , client , bucket , dirOfStatusJSON ) if err != nil { logrus . Infof ( " " , dirOfStatusJSON , bucket ) } else if isBuildSucceeded ( statusText ) { artifactsDirPath := path . Join ( buildDirPath , artifactsDirName ) profilePath = path . Join ( artifactsDirPath , covProfileName ) break } } if profilePath == " " { return nil , fmt . Errorf ( " " , dirOfJob , bucket , len ( builds ) ) } return readGcsObject ( ctx , client , bucket , profilePath ) } 
func sortBuilds ( strBuilds [ ] string ) [ ] int { var res [ ] int for _ , buildStr := range strBuilds { num , err := strconv . Atoi ( buildStr ) if err != nil { logrus . Infof ( " " , buildStr ) } else { res = append ( res , num ) } } sort . Sort ( sort . Reverse ( sort . IntSlice ( res ) ) ) return res } 
func GetAll ( sess * session . Session ) ( [ ] string , error ) { var regions [ ] string svc := ec2 . New ( sess , & aws . Config { Region : aws . String ( Default ) } ) resp , err := svc . DescribeRegions ( nil ) if err != nil { return nil , err } for _ , region := range resp . Regions { regions = append ( regions , * region . RegionName ) } return regions , nil } 
func NewEventClient ( ghc githubClient , log * logrus . Entry , org , repo string , number int ) * EventClient { return & EventClient { org : org , repo : repo , number : number , ghc : ghc , log : log , } } 
func ( c * EventClient ) PruneComments ( shouldPrune func ( github . IssueComment ) bool ) { c . once . Do ( func ( ) { botName , err := c . ghc . BotName ( ) if err != nil { c . log . WithError ( err ) . Error ( " " ) } comments , err := c . ghc . ListIssueComments ( c . org , c . repo , c . number ) if err != nil { c . log . WithError ( err ) . Errorf ( " " , c . org , c . repo , c . number ) } if botName != " " { for _ , comment := range comments { if comment . User . Login == botName { c . comments = append ( c . comments , comment ) } } } } ) c . lock . Lock ( ) defer c . lock . Unlock ( ) var remaining [ ] github . IssueComment for _ , comment := range c . comments { removed := false if shouldPrune ( comment ) { if err := c . ghc . DeleteComment ( c . org , c . repo , comment . ID ) ; err != nil { c . log . WithError ( err ) . Errorf ( " " , comment . ID ) } else { removed = true } } if ! removed { remaining = append ( remaining , comment ) } } c . comments = remaining } 
func makeShield ( subject , status , color string ) [ ] byte { XposLeft , XposRight float64 Subject , Status string Color string } { Subject : subject , Status : status , RightStart : 13 + 6 * len ( subject ) , RightWidth : 13 + 6 * len ( status ) , } p . Width = p . RightStart + p . RightWidth p . XposLeft = float64 ( p . RightStart ) * 0.5 p . XposRight = float64 ( p . RightStart ) + float64 ( p . RightWidth - 2 ) * 0.5 switch color { case " " : p . Color = " " case " " : p . Color = " " default : p . Color = color } var buf bytes . Buffer svgTemplate . Execute ( & buf , p ) return buf . Bytes ( ) } 
func FormatResponse ( to , message , reason string ) string { format := `@%s: %s <details> %s %s </details>` return fmt . Sprintf ( format , to , message , reason , AboutThisBotWithoutCommands ) } 
func FormatSimpleResponse ( to , message string ) string { format := `@%s: %s <details> %s </details>` return fmt . Sprintf ( format , to , message , AboutThisBotWithoutCommands ) } 
func FormatICResponse ( ic github . IssueComment , s string ) string { return FormatResponseRaw ( ic . Body , ic . HTMLURL , ic . User . Login , s ) } 
func FormatResponseRaw ( body , bodyURL , login , reply string ) string { format := `In response to [this](%s): %s ` for _ , l := range strings . Split ( body , " \n " ) { quoted = append ( quoted , " " + l ) } return FormatResponse ( login , reply , fmt . Sprintf ( format , bodyURL , strings . Join ( quoted , " \n " ) ) ) } 
func ( o * Options ) Validate ( ) error { if o . gcsPath . String ( ) != " " { o . Bucket = o . gcsPath . Bucket ( ) o . PathPrefix = o . gcsPath . Object ( ) } if ! o . DryRun { if o . Bucket == " " { return errors . New ( " " ) } if o . GcsCredentialsFile == " " { return errors . New ( " " ) } } return o . GCSConfiguration . Validate ( ) } 
func ( o * Options ) AddFlags ( fs * flag . FlagSet ) { fs . StringVar ( & o . SubDir , " " , " " , " " ) fs . StringVar ( & o . PathStrategy , " " , prowapi . PathStrategyExplicit , " " ) fs . StringVar ( & o . DefaultOrg , " " , " " , " " ) fs . StringVar ( & o . DefaultRepo , " " , " " , " " ) fs . Var ( & o . gcsPath , " " , " " ) fs . StringVar ( & o . GcsCredentialsFile , " " , " " , " " ) fs . BoolVar ( & o . DryRun , " " , true , " " ) } 
func Encode ( options Options ) ( string , error ) { encoded , err := json . Marshal ( options ) return string ( encoded ) , err } 
func RegisterIssueHandler ( name string , fn IssueHandler , help HelpProvider ) { pluginHelp [ name ] = help issueHandlers [ name ] = fn } 
func RegisterIssueCommentHandler ( name string , fn IssueCommentHandler , help HelpProvider ) { pluginHelp [ name ] = help issueCommentHandlers [ name ] = fn } 
func RegisterPullRequestHandler ( name string , fn PullRequestHandler , help HelpProvider ) { pluginHelp [ name ] = help pullRequestHandlers [ name ] = fn } 
func RegisterStatusEventHandler ( name string , fn StatusEventHandler , help HelpProvider ) { pluginHelp [ name ] = help statusEventHandlers [ name ] = fn } 
func RegisterPushEventHandler ( name string , fn PushEventHandler , help HelpProvider ) { pluginHelp [ name ] = help pushEventHandlers [ name ] = fn } 
func RegisterReviewEventHandler ( name string , fn ReviewEventHandler , help HelpProvider ) { pluginHelp [ name ] = help reviewEventHandlers [ name ] = fn } 
func RegisterReviewCommentEventHandler ( name string , fn ReviewCommentEventHandler , help HelpProvider ) { pluginHelp [ name ] = help reviewCommentEventHandlers [ name ] = fn } 
func RegisterGenericCommentHandler ( name string , fn GenericCommentHandler , help HelpProvider ) { pluginHelp [ name ] = help genericCommentHandlers [ name ] = fn } 
func NewAgent ( configAgent * config . Agent , pluginConfigAgent * ConfigAgent , clientAgent * ClientAgent , logger * logrus . Entry ) Agent { prowConfig := configAgent . Config ( ) pluginConfig := pluginConfigAgent . Config ( ) return Agent { GitHubClient : clientAgent . GitHubClient , KubernetesClient : clientAgent . KubernetesClient , ProwJobClient : clientAgent . ProwJobClient , GitClient : clientAgent . GitClient , SlackClient : clientAgent . SlackClient , OwnersClient : clientAgent . OwnersClient , Config : prowConfig , PluginConfig : pluginConfig , Logger : logger , } } 
func ( a * Agent ) InitializeCommentPruner ( org , repo string , pr int ) { a . commentPruner = commentpruner . NewEventClient ( a . GitHubClient , a . Logger . WithField ( " " , " " ) , org , repo , pr , ) } 
func ( a * Agent ) CommentPruner ( ) ( * commentpruner . EventClient , error ) { if a . commentPruner == nil { return nil , errors . New ( " " ) } return a . commentPruner , nil } 
func ( pa * ConfigAgent ) Load ( path string ) error { b , err := ioutil . ReadFile ( path ) if err != nil { return err } np := & Configuration { } if err := yaml . Unmarshal ( b , np ) ; err != nil { return err } if err := np . Validate ( ) ; err != nil { return err } pa . Set ( np ) return nil } 
func ( pa * ConfigAgent ) Config ( ) * Configuration { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) return pa . configuration } 
func ( pa * ConfigAgent ) Set ( pc * Configuration ) { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) pa . configuration = pc } 
func ( pa * ConfigAgent ) Start ( path string ) error { if err := pa . Load ( path ) ; err != nil { return err } ticker := time . Tick ( 1 * time . Minute ) go func ( ) { for range ticker { if err := pa . Load ( path ) ; err != nil { logrus . WithField ( " " , path ) . WithError ( err ) . Error ( " " ) } } } ( ) return nil } 
func ( pa * ConfigAgent ) GenericCommentHandlers ( owner , repo string ) map [ string ] GenericCommentHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] GenericCommentHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := genericCommentHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) IssueHandlers ( owner , repo string ) map [ string ] IssueHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] IssueHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := issueHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) IssueCommentHandlers ( owner , repo string ) map [ string ] IssueCommentHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] IssueCommentHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := issueCommentHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) PullRequestHandlers ( owner , repo string ) map [ string ] PullRequestHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] PullRequestHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := pullRequestHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) ReviewEventHandlers ( owner , repo string ) map [ string ] ReviewEventHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] ReviewEventHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := reviewEventHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) ReviewCommentEventHandlers ( owner , repo string ) map [ string ] ReviewCommentEventHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] ReviewCommentEventHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := reviewCommentEventHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) StatusEventHandlers ( owner , repo string ) map [ string ] StatusEventHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] StatusEventHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := statusEventHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) PushEventHandlers ( owner , repo string ) map [ string ] PushEventHandler { pa . mut . Lock ( ) defer pa . mut . Unlock ( ) hs := map [ string ] PushEventHandler { } for _ , p := range pa . getPlugins ( owner , repo ) { if h , ok := pushEventHandlers [ p ] ; ok { hs [ p ] = h } } return hs } 
func ( pa * ConfigAgent ) getPlugins ( owner , repo string ) [ ] string { var plugins [ ] string fullName := fmt . Sprintf ( " " , owner , repo ) plugins = append ( plugins , pa . configuration . Plugins [ owner ] ... ) plugins = append ( plugins , pa . configuration . Plugins [ fullName ] ... ) return plugins } 
func EventsForPlugin ( name string ) [ ] string { var events [ ] string if _ , ok := issueHandlers [ name ] ; ok { events = append ( events , " " ) } if _ , ok := issueCommentHandlers [ name ] ; ok { events = append ( events , " " ) } if _ , ok := pullRequestHandlers [ name ] ; ok { events = append ( events , " " ) } if _ , ok := pushEventHandlers [ name ] ; ok { events = append ( events , " " ) } if _ , ok := reviewEventHandlers [ name ] ; ok { events = append ( events , " " ) } if _ , ok := reviewCommentEventHandlers [ name ] ; ok { events = append ( events , " " ) } if _ , ok := statusEventHandlers [ name ] ; ok { events = append ( events , " " ) } if _ , ok := genericCommentHandlers [ name ] ; ok { events = append ( events , " " ) } return events } 
func stripTags ( str string ) ( string , [ ] string ) { tags := re . FindAllString ( str , - 1 ) for i , w := range tags { w = strings . TrimSpace ( w ) tags [ i ] = w [ 1 : len ( w ) - 1 ] } var reals [ ] string for _ , p := range re . Split ( str , - 1 ) { if p == " " { continue } reals = append ( reals , p ) } return strings . Join ( reals , " " ) , tags } 
func insertLink ( started * gcs . Started , viewURL string ) ( bool , error ) { if started . Metadata == nil { started . Metadata = metadata . Metadata { } } meta := started . Metadata var changed bool top , present := meta . String ( resultstoreKey ) if ! present || top == nil || * top != viewURL { changed = true meta [ resultstoreKey ] = viewURL } links , present := meta . Meta ( linksKey ) if present && links == nil { return false , fmt . Errorf ( " " , meta [ linksKey ] ) } if links == nil { links = & metadata . Metadata { } changed = true } resultstoreMeta , present := links . Meta ( resultstoreKey ) if present && resultstoreMeta == nil { return false , fmt . Errorf ( " " , ( * links ) [ resultstoreKey ] ) } if resultstoreMeta == nil { resultstoreMeta = & metadata . Metadata { } changed = true } val , present := resultstoreMeta . String ( urlKey ) if present && val == nil { return false , fmt . Errorf ( " " , ( * resultstoreMeta ) [ urlKey ] ) } if ! changed && val != nil && * val == viewURL { return false , nil } ( * resultstoreMeta ) [ urlKey ] = viewURL ( * links ) [ resultstoreKey ] = * resultstoreMeta meta [ linksKey ] = * links return true , nil } 
func ParseConfig ( configPath string ) ( [ ] common . ResourcesConfig , error ) { if _ , err := os . Stat ( configPath ) ; os . IsNotExist ( err ) { return nil , err } file , err := ioutil . ReadFile ( configPath ) if err != nil { return nil , err } var data common . MasonConfig err = yaml . Unmarshal ( file , & data ) if err != nil { return nil , err } return data . Configs , nil } 
func ValidateConfig ( configs [ ] common . ResourcesConfig , resources [ ] common . Resource ) error { resourcesNeeds := map [ string ] int { } actualResources := map [ string ] int { } configNames := map [ string ] map [ string ] int { } for _ , c := range configs { _ , alreadyExists := configNames [ c . Name ] if alreadyExists { return fmt . Errorf ( " " , c . Name ) } configNames [ c . Name ] = c . Needs } for _ , res := range resources { _ , useConfig := configNames [ res . Type ] if useConfig { c , ok := configNames [ res . Type ] if ! ok { err := fmt . Errorf ( " " , res . Type ) logrus . WithError ( err ) . Error ( " " ) return err } } } actualResources [ res . Type ] ++ } for rType , needs := range resourcesNeeds { actual , ok := actualResources [ rType ] if ! ok { err := fmt . Errorf ( " " , rType ) logrus . WithError ( err ) . Errorf ( " " ) return err } if needs > actual { err := fmt . Errorf ( " " , rType ) logrus . WithError ( err ) . Errorf ( " " ) return err } } return nil } 
func NewMason ( cleanerCount int , client boskosClient , waitPeriod , syncPeriod time . Duration ) * Mason { return & Mason { client : client , cleanerCount : cleanerCount , storage : * newStorage ( storage . NewMemoryStorage ( ) ) , pending : make ( chan requirements ) , cleaned : make ( chan requirements , cleanerCount + 1 ) , fulfilled : make ( chan requirements , cleanerCount + 1 ) , boskosWaitPeriod : waitPeriod , boskosSyncPeriod : syncPeriod , configConverters : map [ string ] ConfigConverter { } , } } 
func ( m * Mason ) RegisterConfigConverter ( name string , fn ConfigConverter ) error { _ , ok := m . configConverters [ name ] if ok { return fmt . Errorf ( " " , name ) } m . configConverters [ name ] = fn return nil } 
func ( m * Mason ) UpdateConfigs ( storagePath string ) error { configs , err := ParseConfig ( storagePath ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return err } return m . storage . SyncConfigs ( configs ) } 
func ( m * Mason ) Start ( ) { ctx , cancel := context . WithCancel ( context . Background ( ) ) m . cancel = cancel m . start ( ctx , m . syncAll ) m . start ( ctx , m . recycleAll ) m . start ( ctx , m . fulfillAll ) for i := 0 ; i < m . cleanerCount ; i ++ { m . start ( ctx , m . cleanAll ) } m . start ( ctx , m . freeAll ) logrus . Info ( " " ) } 
func ( m * Mason ) Stop ( ) { logrus . Info ( " " ) m . cancel ( ) m . wg . Wait ( ) close ( m . pending ) close ( m . cleaned ) close ( m . fulfilled ) m . client . ReleaseAll ( common . Dirty ) logrus . Info ( " " ) } 
func HelpProvider ( enabledRepos [ ] string ) ( * pluginhelp . PluginHelp , error ) { pluginHelp := & pluginhelp . PluginHelp { Description : `The cherrypick plugin is used for cherrypicking PRs across branches. For every successful cherrypick invocation a new PR is opened against the target branch and assigned to the requester. If the parent PR contains a release note, it is copied to the cherrypick PR.` , } pluginHelp . AddCommand ( pluginhelp . Command { Usage : " " , Description : " " , Featured : true , return pluginHelp , nil } 
func ( s * Server ) ensureForkExists ( org , repo string ) error { s . repoLock . Lock ( ) defer s . repoLock . Unlock ( ) if ! repoExists ( fork , s . repos ) { if err := s . ghc . CreateFork ( org , repo ) ; err != nil { return fmt . Errorf ( " " , org , repo , err ) } if err := waitForRepo ( s . botName , repo , s . ghc ) ; err != nil { return fmt . Errorf ( " " , org , repo , err ) } s . repos = append ( s . repos , github . Repo { FullName : fork , Fork : true } ) } return nil } 
func ( s * Server ) getPatch ( org , repo , targetBranch string , num int ) ( string , error ) { patch , err := s . ghc . GetPullRequestPatch ( org , repo , num ) if err != nil { return " " , err } localPath := fmt . Sprintf ( " " , org , repo , num , normalize ( targetBranch ) ) out , err := os . Create ( localPath ) if err != nil { return " " , err } defer out . Close ( ) if _ , err := io . Copy ( out , bytes . NewBuffer ( patch ) ) ; err != nil { return " " , err } return localPath , nil } 
func releaseNoteFromParentPR ( body string ) string { potentialMatch := releaseNoteRe . FindStringSubmatch ( body ) if potentialMatch == nil { return " " } return fmt . Sprintf ( " \n \n " , strings . TrimSpace ( potentialMatch [ 1 ] ) ) } 
func ValidatePayload ( payload [ ] byte , sig string , key [ ] byte ) bool { if ! strings . HasPrefix ( sig , " " ) { return false } sig = sig [ 5 : ] sb , err := hex . DecodeString ( sig ) if err != nil { return false } mac := hmac . New ( sha1 . New , key ) mac . Write ( payload ) expected := mac . Sum ( nil ) return hmac . Equal ( sb , expected ) } 
func PayloadSignature ( payload [ ] byte , key [ ] byte ) string { mac := hmac . New ( sha1 . New , key ) mac . Write ( payload ) sum := mac . Sum ( nil ) return " " + hex . EncodeToString ( sum ) } 
func findTeam ( teams map [ string ] github . Team , name string , previousNames ... string ) * github . Team { if t , ok := teams [ name ] ; ok { return & t } for _ , p := range previousNames { if t , ok := teams [ p ] ; ok { return & t } } return nil } 
func validateTeamNames ( orgConfig org . Config ) error { dups := sets . String { } for name , orgTeam := range orgConfig . Teams { if used . Has ( name ) { dups . Insert ( name ) } else { used . Insert ( name ) } for _ , n := range orgTeam . Previously { if used . Has ( n ) { dups . Insert ( n ) } else { used . Insert ( n ) } } } if n := len ( dups ) ; n > 0 { return fmt . Errorf ( " " , n , strings . Join ( dups . List ( ) , " " ) ) } return nil } 
func configureTeams ( client teamClient , orgName string , orgConfig org . Config , maxDelta float64 , ignoreSecretTeams bool ) ( map [ string ] github . Team , error ) { if err := validateTeamNames ( orgConfig ) ; err != nil { return nil , err } ints := sets . Int { } teamList , err := client . ListTeams ( orgName ) if err != nil { return nil , fmt . Errorf ( " " , err ) } logrus . Debugf ( " " , len ( teamList ) ) for _ , t := range teamList { if ignoreSecretTeams && org . Privacy ( t . Privacy ) == org . Secret { continue } ids [ t . ID ] = t ints . Insert ( t . ID ) } if ignoreSecretTeams { logrus . Debugf ( " " , len ( teamList ) ) } names := map [ string ] github . Team { } for _ , t := range ids { logger := logrus . WithFields ( logrus . Fields { " " : t . ID , " " : t . Name } ) n := t . Name switch val , ok := names [ n ] ; { case ! ok : names [ n ] = t case ok && t . ID < val . ID : names [ n ] = t older [ n ] = append ( older [ n ] , val ) default : older [ n ] = append ( older [ n ] , val ) } } missing := map [ string ] org . Team { } used := sets . Int { } var match func ( teams map [ string ] org . Team ) match = func ( teams map [ string ] org . Team ) { for name , orgTeam := range teams { logger := logrus . WithField ( " " , name ) match ( orgTeam . Children ) t := findTeam ( names , name , orgTeam . Previously ... ) if t == nil { missing [ name ] = orgTeam logger . Debug ( " " ) continue } matches [ name ] = * t logger . WithField ( " " , t . ID ) . Debug ( " " ) used . Insert ( t . ID ) } } match ( orgConfig . Teams ) if delta := float64 ( len ( unused ) ) / float64 ( len ( ints ) ) ; delta > maxDelta { return nil , fmt . Errorf ( " " , len ( unused ) , delta , orgName , maxDelta ) } for name , orgTeam := range missing { t := & github . Team { Name : name } if orgTeam . Description != nil { t . Description = * orgTeam . Description } if orgTeam . Privacy != nil { t . Privacy = string ( * orgTeam . Privacy ) } t , err := client . CreateTeam ( orgName , * t ) if err != nil { logrus . WithError ( err ) . Warnf ( " " , name , orgName ) failures = append ( failures , name ) continue } matches [ name ] = * t } if n := len ( failures ) ; n > 0 { return nil , fmt . Errorf ( " " , n , strings . Join ( failures , " " ) ) } unused = unused . Difference ( reused ) } logrus . WithError ( err ) . Warnf ( " " , str , orgName ) failures = append ( failures , str ) } } if n := len ( failures ) ; n > 0 { return nil , fmt . Errorf ( " " , n , strings . Join ( failures , " " ) ) } } 
func updateString ( have , want * string ) bool { switch { case have == nil : panic ( " " ) case want == nil : return false case * have == * want : return false } * have = * want return true } 
func updateBool ( have , want * bool ) bool { switch { case have == nil : panic ( " " ) case want == nil : return false case * have == * want : return false } * have = * want return true } 
func configureOrgMeta ( client orgMetadataClient , orgName string , want org . Metadata ) error { cur , err := client . GetOrg ( orgName ) if err != nil { return fmt . Errorf ( " " , orgName , err ) } change := false change = updateString ( & cur . BillingEmail , want . BillingEmail ) || change change = updateString ( & cur . Company , want . Company ) || change change = updateString ( & cur . Email , want . Email ) || change change = updateString ( & cur . Name , want . Name ) || change change = updateString ( & cur . Description , want . Description ) || change change = updateString ( & cur . Location , want . Location ) || change if want . DefaultRepositoryPermission != nil { w := string ( * want . DefaultRepositoryPermission ) change = updateString ( & cur . DefaultRepositoryPermission , & w ) } change = updateBool ( & cur . HasOrganizationProjects , want . HasOrganizationProjects ) || change change = updateBool ( & cur . HasRepositoryProjects , want . HasRepositoryProjects ) || change change = updateBool ( & cur . MembersCanCreateRepositories , want . MembersCanCreateRepositories ) || change if change { if _ , err := client . EditOrg ( orgName , * cur ) ; err != nil { return fmt . Errorf ( " " , orgName , err ) } } return nil } 
func configureTeam ( client editTeamClient , orgName , teamName string , team org . Team , gt github . Team , parent * int ) error { if gt . Name != teamName { patch = true } gt . Name = teamName if team . Description != nil && gt . Description != * team . Description { patch = true gt . Description = * team . Description } else { gt . Description = " " } gt . ParentTeamID = parent } if gt . Parent != nil { gt . Parent = nil gt . ParentTeamID = parent } else if gt . Parent . ID != * parent { gt . Parent = nil gt . ParentTeamID = parent } } if team . Privacy != nil && gt . Privacy != string ( * team . Privacy ) { patch = true gt . Privacy = string ( * team . Privacy ) } else if team . Privacy == nil && ( parent != nil || len ( team . Children ) > 0 ) && gt . Privacy != " " { patch = true gt . Privacy = github . PrivacyClosed } if patch { } } return nil } 
func configureTeamRepos ( client teamRepoClient , githubTeams map [ string ] github . Team , name , orgName string , team org . Team ) error { gt , ok := githubTeams [ name ] if ! ok { } want := team . Repos have := map [ string ] github . RepoPermissionLevel { } repos , err := client . ListTeamRepos ( gt . ID ) if err != nil { return fmt . Errorf ( " " , gt . ID , name , err ) } for _ , repo := range repos { have [ repo . Name ] = github . LevelFromPermissions ( repo . Permissions ) } actions := map [ string ] github . RepoPermissionLevel { } for wantRepo , wantPermission := range want { if havePermission , haveRepo := have [ wantRepo ] ; haveRepo && havePermission == wantPermission { } } for haveRepo := range have { if _ , wantRepo := want [ haveRepo ] ; ! wantRepo { } } var updateErrors [ ] error for repo , permission := range actions { var err error if permission == github . None { err = client . RemoveTeamRepo ( gt . ID , orgName , repo ) } else { err = client . UpdateTeamRepo ( gt . ID , orgName , repo , permission ) } if err != nil { updateErrors = append ( updateErrors , fmt . Errorf ( " " , gt . ID , name , repo , permission , err ) ) } } return errorutil . NewAggregate ( updateErrors ... ) } 
func configureTeamMembers ( client teamMembersClient , gt github . Team , team org . Team ) error { wantMembers := sets . NewString ( team . Members ... ) haveMembers := sets . String { } members , err := client . ListTeamMembers ( gt . ID , github . RoleMember ) if err != nil { return fmt . Errorf ( " " , gt . ID , gt . Name , err ) } for _ , m := range members { haveMembers . Insert ( m . Login ) } maintainers , err := client . ListTeamMembers ( gt . ID , github . RoleMaintainer ) if err != nil { return fmt . Errorf ( " " , gt . ID , gt . Name , err ) } for _ , m := range maintainers { haveMaintainers . Insert ( m . Login ) } invitees , err := teamInvitations ( client , gt . ID ) if err != nil { return fmt . Errorf ( " " , gt . ID , gt . Name , err ) } adder := func ( user string , super bool ) error { if invitees . Has ( user ) { logrus . Infof ( " " , user , gt . ID , gt . Name ) return nil } role := github . RoleMember if super { role = github . RoleMaintainer } tm , err := client . UpdateTeamMembership ( gt . ID , user , super ) if err != nil { logrus . WithError ( err ) . Warnf ( " " , gt . ID , gt . Name , user , super ) } else if tm . State == github . StatePending { logrus . Infof ( " " , user , gt . ID , gt . Name , role ) } else { logrus . Infof ( " " , user , role , gt . ID , gt . Name ) } return err } remover := func ( user string ) error { err := client . RemoveTeamMembership ( gt . ID , user ) if err != nil { logrus . WithError ( err ) . Warnf ( " " , gt . ID , gt . Name , user ) } else { logrus . Infof ( " " , user , gt . ID , gt . Name ) } return err } want := memberships { members : wantMembers , super : wantMaintainers } have := memberships { members : haveMembers , super : haveMaintainers } return configureMembers ( have , want , invitees , adder , remover ) } 
func ( c * Client ) ShouldReport ( pj * prowapi . ProwJob ) bool { pubSubMap := findLabels ( pj , PubSubProjectLabel , PubSubTopicLabel ) return pubSubMap [ PubSubProjectLabel ] != " " && pubSubMap [ PubSubTopicLabel ] != " " } 
func ( c * Client ) Report ( pj * prowapi . ProwJob ) ( [ ] * prowapi . ProwJob , error ) { message := c . generateMessageFromPJ ( pj ) ctx := context . Background ( ) client , err := pubsub . NewClient ( ctx , message . Project ) if err != nil { return nil , fmt . Errorf ( " " , err ) } topic := client . Topic ( message . Topic ) d , err := json . Marshal ( message ) if err != nil { return nil , fmt . Errorf ( " " , err ) } res := topic . Publish ( ctx , & pubsub . Message { Data : d , } ) _ , err = res . Get ( ctx ) if err != nil { return nil , fmt . Errorf ( " \" \" " , message . RunID , message . Project , message . Topic , err ) } return [ ] * prowapi . ProwJob { pj } , nil } 
func ( o Options ) Run ( spec * downwardapi . JobSpec , extra map [ string ] gcs . UploadFunc ) error { uploadTargets := o . assembleTargets ( spec , extra ) if ! o . DryRun { ctx := context . Background ( ) gcsClient , err := storage . NewClient ( ctx , option . WithCredentialsFile ( o . GcsCredentialsFile ) ) if err != nil { return fmt . Errorf ( " " , err ) } if err := gcs . Upload ( gcsClient . Bucket ( o . Bucket ) , uploadTargets ) ; err != nil { return fmt . Errorf ( " " , err ) } } else { for destination := range uploadTargets { logrus . WithField ( " " , destination ) . Info ( " " ) } } logrus . Info ( " " ) return nil } 
func PathsForJob ( options * prowapi . GCSConfiguration , spec * downwardapi . JobSpec , subdir string ) ( string , string , gcs . RepoPathBuilder ) { builder := builderForStrategy ( options . PathStrategy , options . DefaultOrg , options . DefaultRepo ) jobBasePath := gcs . PathForSpec ( spec , builder ) if options . PathPrefix != " " { jobBasePath = path . Join ( options . PathPrefix , jobBasePath ) } var gcsPath string if subdir == " " { gcsPath = jobBasePath } else { gcsPath = path . Join ( jobBasePath , subdir ) } return jobBasePath , gcsPath , builder } 
func NewDefaultFieldsFormatter ( wrappedFormatter logrus . Formatter , defaultFields logrus . Fields , ) * DefaultFieldsFormatter { res := & DefaultFieldsFormatter { WrappedFormatter : wrappedFormatter , DefaultFields : defaultFields , } if res . WrappedFormatter == nil { res . WrappedFormatter = & logrus . JSONFormatter { } } return res } 
func ( d * DefaultFieldsFormatter ) Format ( entry * logrus . Entry ) ( [ ] byte , error ) { data := make ( logrus . Fields , len ( entry . Data ) + len ( d . DefaultFields ) ) for k , v := range d . DefaultFields { data [ k ] = v } for k , v := range entry . Data { data [ k ] = v } return d . WrappedFormatter . Format ( & logrus . Entry { Logger : entry . Logger , Data : data , Time : entry . Time , Level : entry . Level , Message : entry . Message , } ) } 
func ( issue * Issue ) FindLabels ( regex * regexp . Regexp ) [ ] Label { labels := [ ] Label { } for _ , label := range issue . Labels { if regex . MatchString ( label . Name ) { labels = append ( labels , label ) } } return labels } 
func ( o * Options ) AddFlags ( flags * flag . FlagSet ) { flags . StringVar ( & o . Log , " " , " " , " " ) o . Options . AddFlags ( flags ) } 
func NewAgent ( config * config . GitHubOAuthConfig , logger * logrus . Entry ) * Agent { return & Agent { gc : config , logger : logger , } } 
func ( ga * Agent ) HandleLogin ( client OAuthClient ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { stateToken := xsrftoken . Generate ( ga . gc . ClientSecret , " " , " " ) state := hex . EncodeToString ( [ ] byte ( stateToken ) ) oauthSession , err := ga . gc . CookieStore . New ( r , oauthSessionCookie ) oauthSession . Options . Secure = true oauthSession . Options . HttpOnly = true if err != nil { ga . serverError ( w , " " , err ) return } oauthSession . Options . MaxAge = 10 * 60 oauthSession . Values [ stateKey ] = state if err := oauthSession . Save ( r , w ) ; err != nil { ga . serverError ( w , " " , err ) return } redirectURL := client . AuthCodeURL ( state , oauth2 . ApprovalForce , oauth2 . AccessTypeOnline ) http . Redirect ( w , r , redirectURL , http . StatusFound ) } } 
func ( ga * Agent ) HandleLogout ( client OAuthClient ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { accessTokenSession , err := ga . gc . CookieStore . Get ( r , tokenSession ) if err != nil { ga . serverError ( w , " " , err ) return } if err := accessTokenSession . Save ( r , w ) ; err != nil { ga . serverError ( w , " " , err ) return } loginCookie , err := r . Cookie ( loginSession ) if err == nil { loginCookie . MaxAge = - 1 loginCookie . Expires = time . Now ( ) . Add ( - time . Hour * 24 ) http . SetCookie ( w , loginCookie ) } http . Redirect ( w , r , ga . gc . FinalRedirectURL , http . StatusFound ) } } 
func ( ga * Agent ) HandleRedirect ( client OAuthClient , getter GitHubClientGetter ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { state := r . FormValue ( " " ) stateTokenRaw , err := hex . DecodeString ( state ) if err != nil { ga . serverError ( w , " " , fmt . Errorf ( " " ) ) } stateToken := string ( stateTokenRaw ) return } oauthSession , err := ga . gc . CookieStore . Get ( r , oauthSessionCookie ) if err != nil { ga . serverError ( w , " " , err ) return } secretState , ok := oauthSession . Values [ stateKey ] . ( string ) if ! ok { ga . serverError ( w , " " , fmt . Errorf ( " " ) ) return } return } token , err := client . Exchange ( context . Background ( ) , code ) if err != nil { if gherror := r . FormValue ( " " ) ; len ( gherror ) > 0 { gherrorDescription := r . FormValue ( " " ) gherrorURI := r . FormValue ( " " ) fields := logrus . Fields { " " : gherror , " " : gherrorDescription , " " : gherrorURI , } ga . logger . WithFields ( fields ) . Error ( " " ) ga . serverError ( w , " " , fmt . Errorf ( gherror ) ) } else { ga . serverError ( w , " " , err ) } return } session . Options . Secure = true session . Options . HttpOnly = true if err != nil { ga . serverError ( w , " " , err ) return } session . Values [ tokenKey ] = token if err := session . Save ( r , w ) ; err != nil { ga . serverError ( w , " " , err ) return } ghc := getter . GetGitHubClient ( token . AccessToken , false ) user , err := ghc . GetUser ( " " ) if err != nil { ga . serverError ( w , " " , err ) return } http . SetCookie ( w , & http . Cookie { Name : loginSession , Value : * user . Login , Path : " " , Expires : time . Now ( ) . Add ( time . Hour * 24 * 30 ) , Secure : true , } ) http . Redirect ( w , r , ga . gc . FinalRedirectURL , http . StatusFound ) } } 
func ( ga * Agent ) serverError ( w http . ResponseWriter , action string , err error ) { ga . logger . WithError ( err ) . Errorf ( " " , action ) msg := fmt . Sprintf ( " " , action , err ) http . Error ( w , msg , http . StatusInternalServerError ) } 
func ( in * ResourcesConfigObject ) DeepCopyObject ( ) runtime . Object { if c := in . deepCopy ( ) ; c != nil { return c } return nil } 
func ( in * ResourcesConfigObject ) FromItem ( i common . Item ) { c , err := common . ItemToResourcesConfig ( i ) if err == nil { in . fromConfig ( c ) } } 
func ( in * ResourcesConfigCollection ) GetItems ( ) [ ] Object { var items [ ] Object for _ , i := range in . Items { items = append ( items , i ) } return items } 
func ( in * ResourcesConfigCollection ) SetItems ( objects [ ] Object ) { var items [ ] * ResourcesConfigObject for _ , b := range objects { items = append ( items , b . ( * ResourcesConfigObject ) ) } in . Items = items } 
func ( in * ResourcesConfigCollection ) DeepCopyObject ( ) runtime . Object { if c := in . deepCopy ( ) ; c != nil { return c } return nil } 
func ( s * Server ) ServeHTTP ( w http . ResponseWriter , r * http . Request ) { if ! ok { return } fmt . Fprint ( w , " " ) if err := s . handleEvent ( eventType , eventGUID , payload ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } } 
func ( l * RepoPermissionLevel ) UnmarshalText ( text [ ] byte ) error { v := RepoPermissionLevel ( text ) if _ , ok := repoPermissionLevels [ v ] ; ! ok { return fmt . Errorf ( " " , v , repoPermissionLevels ) } * l = v return nil } 
func ( i Issue ) IsAssignee ( login string ) bool { for _ , assignee := range i . Assignees { if NormLogin ( login ) == NormLogin ( assignee . Login ) { return true } } return false } 
func ( i Issue ) IsAuthor ( login string ) bool { return NormLogin ( i . User . Login ) == NormLogin ( login ) } 
func ( i Issue ) HasLabel ( labelToFind string ) bool { for _ , label := range i . Labels { if strings . ToLower ( label . Name ) == strings . ToLower ( labelToFind ) { return true } } return false } 
func ( pe PushEvent ) Branch ( ) string { ref := strings . TrimPrefix ( pe . Ref , " " ) ref = strings . TrimPrefix ( ref , " " ) return ref } 
func prowjobStateToGitHubStatus ( pjState prowapi . ProwJobState ) ( string , error ) { switch pjState { case prowapi . TriggeredState : return github . StatusPending , nil case prowapi . PendingState : return github . StatusPending , nil case prowapi . SuccessState : return github . StatusSuccess , nil case prowapi . ErrorState : return github . StatusError , nil case prowapi . FailureState : return github . StatusFailure , nil case prowapi . AbortedState : return github . StatusFailure , nil } return " " , fmt . Errorf ( " " , pjState ) } 
func truncate ( in string ) string { const ( half = ( maxLen - len ( elide ) ) / 2 ) if len ( in ) <= maxLen { return in } return in [ : half ] + elide + in [ len ( in ) - half : ] } 
func reportStatus ( ghc GitHubClient , pj prowapi . ProwJob ) error { refs := pj . Spec . Refs if pj . Spec . Report { contextState , err := prowjobStateToGitHubStatus ( pj . Status . State ) if err != nil { return err } sha := refs . BaseSHA if len ( refs . Pulls ) > 0 { sha = refs . Pulls [ 0 ] . SHA } if err := ghc . CreateStatus ( refs . Org , refs . Repo , sha , github . Status { State : contextState , Description : truncate ( pj . Status . Description ) , Context : pj . Spec . Context , } } return nil } 
func ShouldReport ( pj prowapi . ProwJob , validTypes [ ] prowapi . ProwJobType ) bool { valid := false for _ , t := range validTypes { if pj . Spec . Type == t { valid = true } } if ! valid { return false } if ! pj . Spec . Report { return false } return true } 
func Report ( ghc GitHubClient , reportTemplate * template . Template , pj prowapi . ProwJob , validTypes [ ] prowapi . ProwJobType ) error { if ghc == nil { return fmt . Errorf ( " " , pj . ObjectMeta . Name ) } if ! ShouldReport ( pj , validTypes ) { return nil } refs := pj . Spec . Refs } if err := reportStatus ( ghc , pj ) ; err != nil { return fmt . Errorf ( " " , err ) } } if len ( refs . Pulls ) == 0 { return nil } ics , err := ghc . ListIssueComments ( refs . Org , refs . Repo , refs . Pulls [ 0 ] . Number ) if err != nil { return fmt . Errorf ( " " , err ) } botName , err := ghc . BotName ( ) if err != nil { return fmt . Errorf ( " " , err ) } deletes , entries , updateID := parseIssueComments ( pj , botName , ics ) for _ , delete := range deletes { if err := ghc . DeleteComment ( refs . Org , refs . Repo , delete ) ; err != nil { return fmt . Errorf ( " " , err ) } } if len ( entries ) > 0 { comment , err := createComment ( reportTemplate , pj , entries ) if err != nil { return fmt . Errorf ( " " , err ) } if updateID == 0 { if err := ghc . CreateComment ( refs . Org , refs . Repo , refs . Pulls [ 0 ] . Number , comment ) ; err != nil { return fmt . Errorf ( " " , err ) } } else { if err := ghc . EditComment ( refs . Org , refs . Repo , updateID , comment ) ; err != nil { return fmt . Errorf ( " " , err ) } } } return nil } 
func parseIssueComments ( pj prowapi . ProwJob , botName string , ics [ ] github . IssueComment ) ( [ ] int , [ ] string , int ) { var delete [ ] int var previousComments [ ] int var latestComment int var entries [ ] string } } if ! strings . Contains ( ic . Body , commentTag ) { continue } if latestComment != 0 { previousComments = append ( previousComments , latestComment ) } latestComment = ic . ID var tracking bool for _ , line := range strings . Split ( ic . Body , " \n " ) { line = strings . TrimSpace ( line ) if strings . HasPrefix ( line , " " ) { tracking = true } else if len ( line ) == 0 { tracking = false } else if tracking { entries = append ( entries , line ) } } } var newEntries [ ] string f1 := strings . Split ( entries [ i ] , " " ) for j := range entries { if i == j { continue } f2 := strings . Split ( entries [ j ] , " " ) } } } if keep { newEntries = append ( newEntries , entries [ i ] ) } } var createNewComment bool if string ( pj . Status . State ) == github . StatusFailure { newEntries = append ( newEntries , createEntry ( pj ) ) createNewComment = true } delete = append ( delete , previousComments ... ) if ( createNewComment || len ( newEntries ) == 0 ) && latestComment != 0 { delete = append ( delete , latestComment ) latestComment = 0 } return delete , newEntries , latestComment } 
func createComment ( reportTemplate * template . Template , pj prowapi . ProwJob , entries [ ] string ) ( string , error ) { plural := " " if len ( entries ) > 1 { plural = " " } var b bytes . Buffer if reportTemplate != nil { if err := reportTemplate . Execute ( & b , & pj ) ; err != nil { return " " , err } } lines := [ ] string { fmt . Sprintf ( " " , pj . Spec . Refs . Pulls [ 0 ] . Author , plural ) , " " , " " , " " , } lines = append ( lines , entries ... ) if reportTemplate != nil { lines = append ( lines , " " , b . String ( ) ) } lines = append ( lines , [ ] string { " " , " " , " " , plugins . AboutThisBot , " " , commentTag , } ... ) return strings . Join ( lines , " \n " ) , nil } 
func defaultLookingDHCPOptions ( dhcp * ec2 . DhcpOptions , region string ) bool { if len ( dhcp . Tags ) != 0 { return false } for _ , conf := range dhcp . DhcpConfigurations { switch * conf . Key { case " " : var domain string } else { domain = region + " " } } case " " : } default : return false } } return true } 
func genericCommentAction ( action string ) github . GenericCommentEventAction { switch action { case " " , " " , " " : return github . GenericCommentActionCreated case " " : return github . GenericCommentActionEdited case " " , " " : return github . GenericCommentActionDeleted } } 
func ( lens Lens ) Config ( ) lenses . LensConfig { return lenses . LensConfig { Name : name , Title : title , Priority : priority , } } 
func ( lens Lens ) Header ( artifacts [ ] lenses . Artifact , resourceDir string ) string { t , err := template . ParseFiles ( filepath . Join ( resourceDir , " " ) ) if err != nil { return fmt . Sprintf ( " " , err ) } var buf bytes . Buffer if err := t . ExecuteTemplate ( & buf , " " , nil ) ; err != nil { return fmt . Sprintf ( " " , err ) } return buf . String ( ) } 
func ( lens Lens ) Callback ( artifacts [ ] lenses . Artifact , resourceDir string , data string ) string { return " " } 
func ( lens Lens ) Body ( artifacts [ ] lenses . Artifact , resourceDir string , data string ) string { type testResults struct { junit [ ] junit . Result link string path string err error } resultChan := make ( chan testResults ) for _ , artifact := range artifacts { go func ( artifact lenses . Artifact ) { result := testResults { link : artifact . CanonicalLink ( ) , path : artifact . JobPath ( ) , } var contents [ ] byte contents , result . err = artifact . ReadAll ( ) if result . err != nil { logrus . WithError ( result . err ) . WithField ( " " , artifact . CanonicalLink ( ) ) . Warn ( " " ) resultChan <- result return } var suites junit . Suites suites , result . err = junit . Parse ( contents ) if result . err != nil { logrus . WithError ( result . err ) . WithField ( " " , artifact . CanonicalLink ( ) ) . Info ( " " ) resultChan <- result return } for _ , suite := range suites . Suites { for _ , test := range suite . Results { result . junit = append ( result . junit , test ) } } resultChan <- result } ( artifact ) } results := make ( [ ] testResults , 0 , len ( artifacts ) ) for range artifacts { results = append ( results , <- resultChan ) } sort . Slice ( results , func ( i , j int ) bool { return results [ i ] . path < results [ j ] . path } ) jvd := struct { NumTests int Passed [ ] TestResult Failed [ ] TestResult Skipped [ ] TestResult } { } for _ , result := range results { if result . err != nil { continue } for _ , test := range result . junit { if test . Failure != nil { jvd . Failed = append ( jvd . Failed , TestResult { Junit : JunitResult { test } , Link : result . link , } ) } else if test . Skipped != nil { jvd . Skipped = append ( jvd . Skipped , TestResult { Junit : JunitResult { test } , Link : result . link , } ) } else { jvd . Passed = append ( jvd . Passed , TestResult { Junit : JunitResult { test } , Link : result . link , } ) } } } jvd . NumTests = len ( jvd . Passed ) + len ( jvd . Failed ) + len ( jvd . Skipped ) junitTemplate , err := template . ParseFiles ( filepath . Join ( resourceDir , " " ) ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return fmt . Sprintf ( " " , err ) } var buf bytes . Buffer if err := junitTemplate . ExecuteTemplate ( & buf , " " , jvd ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } return buf . String ( ) } 
func FormatRecord ( record Record ) string { output := bytes . Buffer { } if record . Failed { fmt . Fprintln ( & output , " " ) } fmt . Fprintf ( & output , " " , record . Refs . Org , record . Refs . Repo , record . Refs . BaseRef ) if record . Refs . BaseSHA != " " { fmt . Fprintf ( & output , " " , record . Refs . BaseSHA ) } output . WriteString ( " \n " ) if len ( record . Refs . Pulls ) > 0 { output . WriteString ( " \n " ) for _ , pull := range record . Refs . Pulls { fmt . Fprintf ( & output , " \t " , pull . Number ) if pull . SHA != " " { fmt . Fprintf ( & output , " " , pull . SHA ) } fmt . Fprint ( & output , " \n " ) } } for _ , command := range record . Commands { fmt . Fprintf ( & output , " \n " , command . Command ) fmt . Fprint ( & output , command . Output ) if command . Error != " " { fmt . Fprintf ( & output , " \n " , command . Error ) } } return output . String ( ) } 
func ( c * Client ) Namespace ( ns string ) * Client { nc := * c nc . namespace = ns return & nc } 
func ( c * Client ) requestRetryStream ( r * request ) ( io . ReadCloser , error ) { if c . fake && r . deckPath == " " { return nil , nil } resp , err := c . retry ( r ) if err != nil { return nil , err } if resp . StatusCode == 409 { return nil , NewConflictError ( fmt . Errorf ( " " ) ) } else if resp . StatusCode < 200 || resp . StatusCode > 299 { return nil , fmt . Errorf ( " \" \" " , resp . Status ) } return resp . Body , nil } 
func ( c * Client ) requestRetry ( r * request ) ( [ ] byte , error ) { if c . fake && r . deckPath == " " { return [ ] byte ( " " ) , nil } resp , err := c . retry ( r ) if err != nil { return nil , err } defer resp . Body . Close ( ) rb , err := ioutil . ReadAll ( resp . Body ) if err != nil { return nil , err } if resp . StatusCode == 404 { return nil , NewNotFoundError ( fmt . Errorf ( " " , string ( rb ) ) ) } else if resp . StatusCode == 409 { return nil , NewConflictError ( fmt . Errorf ( " " , string ( rb ) ) ) } else if resp . StatusCode == 422 { return nil , NewUnprocessableEntityError ( fmt . Errorf ( " " , string ( rb ) ) ) } else if resp . StatusCode == 404 { return nil , NewNotFoundError ( fmt . Errorf ( " " , string ( rb ) ) ) } else if resp . StatusCode < 200 || resp . StatusCode > 299 { return nil , fmt . Errorf ( " \" \" \" \" " , resp . Status , string ( rb ) ) } return rb , nil } 
func NewFakeClient ( deckURL string ) * Client { return & Client { namespace : " " , deckURL : deckURL , client : & http . Client { } , fake : true , } } 
func NewClientInCluster ( namespace string ) ( * Client , error ) { tokenFile := " " token , err := ioutil . ReadFile ( tokenFile ) if err != nil { return nil , err } rootCAFile := " " certData , err := ioutil . ReadFile ( rootCAFile ) if err != nil { return nil , err } cp := x509 . NewCertPool ( ) cp . AppendCertsFromPEM ( certData ) tr := & http . Transport { TLSClientConfig : & tls . Config { MinVersion : tls . VersionTLS12 , RootCAs : cp , } , } return & Client { logger : logrus . WithField ( " " , " " ) , baseURL : inClusterBaseURL , client : & http . Client { Transport : tr , Timeout : requestTimeout } , token : string ( token ) , namespace : namespace , } , nil } 
func NewClientFromFile ( clusterPath , namespace string ) ( * Client , error ) { data , err := ioutil . ReadFile ( clusterPath ) if err != nil { return nil , err } var c Cluster if err := yaml . Unmarshal ( data , & c ) ; err != nil { return nil , err } return NewClient ( & c , namespace ) } 
func UnmarshalClusterMap ( data [ ] byte ) ( map [ string ] Cluster , error ) { var raw map [ string ] Cluster if err := yaml . Unmarshal ( data , & raw ) ; err != nil { if err := yaml . Unmarshal ( data , & singleConfig ) ; err != nil { return nil , err } raw = map [ string ] Cluster { DefaultClusterAlias : singleConfig } } return raw , nil } 
func ClientMapFromFile ( clustersPath , namespace string ) ( map [ string ] * Client , error ) { data , err := ioutil . ReadFile ( clustersPath ) if err != nil { return nil , fmt . Errorf ( " " , err ) } raw , err := UnmarshalClusterMap ( data ) if err != nil { return nil , fmt . Errorf ( " " , err ) } foundDefault := false result := map [ string ] * Client { } for alias , config := range raw { client , err := newClient ( & config , namespace ) if err != nil { return nil , fmt . Errorf ( " " , alias , clustersPath , err ) } result [ alias ] = client if alias == DefaultClusterAlias { foundDefault = true } } if ! foundDefault { return nil , fmt . Errorf ( " " , DefaultClusterAlias , clustersPath ) } return result , nil } 
func NewClient ( c * Cluster , namespace string ) ( * Client , error ) { ck := c . ClientKey ca := c . ClusterCACertificate cert , err := tls . X509KeyPair ( cc , ck ) if err != nil { return nil , err } cp := x509 . NewCertPool ( ) cp . AppendCertsFromPEM ( ca ) tr := & http . Transport { TLSClientConfig : & tls . Config { MinVersion : tls . VersionTLS12 , Certificates : [ ] tls . Certificate { cert } , RootCAs : cp , } , } return & Client { logger : logrus . WithField ( " " , " " ) , baseURL : c . Endpoint , client : & http . Client { Transport : tr , Timeout : requestTimeout } , namespace : namespace , } , nil } 
func ( c * Client ) GetPod ( name string ) ( Pod , error ) { c . log ( " " , name ) var retPod Pod err := c . request ( & request { path : fmt . Sprintf ( " " , c . namespace , name ) , } , & retPod ) return retPod , err } 
func ( c * Client ) ListPods ( selector string ) ( [ ] Pod , error ) { c . log ( " " , selector ) var pl struct { Items [ ] Pod `json:"items"` } err := c . request ( & request { path : fmt . Sprintf ( " " , c . namespace ) , query : map [ string ] string { " " : selector } , } , & pl ) return pl . Items , err } 
func ( c * Client ) CreateProwJob ( j prowapi . ProwJob ) ( prowapi . ProwJob , error ) { var representation string if out , err := json . Marshal ( j ) ; err == nil { representation = string ( out [ : ] ) } else { representation = fmt . Sprintf ( " " , j ) } c . log ( " " , representation ) var retJob prowapi . ProwJob err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , c . namespace ) , requestBody : & j , } , & retJob ) return retJob , err } 
func ( c * Client ) GetProwJob ( name string ) ( prowapi . ProwJob , error ) { c . log ( " " , name ) var pj prowapi . ProwJob err := c . request ( & request { path : fmt . Sprintf ( " " , c . namespace , name ) , } , & pj ) return pj , err } 
func ( c * Client ) ListProwJobs ( selector string ) ( [ ] prowapi . ProwJob , error ) { c . log ( " " , selector ) var jl struct { Items [ ] prowapi . ProwJob `json:"items"` } err := c . request ( & request { path : fmt . Sprintf ( " " , c . namespace ) , deckPath : " " , query : map [ string ] string { " " : selector } , } , & jl ) if err == nil { var pjs [ ] prowapi . ProwJob for _ , pj := range jl . Items { pjs = append ( pjs , pj ) } jl . Items = pjs } return jl . Items , err } 
func ( c * Client ) DeleteProwJob ( name string ) error { c . log ( " " , name ) return c . request ( & request { method : http . MethodDelete , path : fmt . Sprintf ( " " , c . namespace , name ) , } , nil ) } 
func ( c * Client ) ReplaceProwJob ( name string , job prowapi . ProwJob ) ( prowapi . ProwJob , error ) { c . log ( " " , name , job ) var retJob prowapi . ProwJob err := c . request ( & request { method : http . MethodPut , path : fmt . Sprintf ( " " , c . namespace , name ) , requestBody : & job , } , & retJob ) return retJob , err } 
func ( c * Client ) CreatePod ( p v1 . Pod ) ( Pod , error ) { c . log ( " " , p ) var retPod Pod err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , c . namespace ) , requestBody : & p , } , & retPod ) return retPod , err } 
func ( c * Client ) GetLog ( pod string ) ( [ ] byte , error ) { c . log ( " " , pod ) return c . requestRetry ( & request { path : fmt . Sprintf ( " " , c . namespace , pod ) , } ) } 
func ( c * Client ) GetLogTail ( pod , container string , n int64 ) ( [ ] byte , error ) { c . log ( " " , pod , n ) return c . requestRetry ( & request { path : fmt . Sprintf ( " " , c . namespace , pod ) , query : map [ string ] string { } 
func ( c * Client ) GetContainerLog ( pod , container string ) ( [ ] byte , error ) { c . log ( " " , pod ) return c . requestRetry ( & request { path : fmt . Sprintf ( " " , c . namespace , pod ) , query : map [ string ] string { " " : container } , } ) } 
func ( c * Client ) CreateConfigMap ( content ConfigMap ) ( ConfigMap , error ) { c . log ( " " ) var retConfigMap ConfigMap err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , c . namespace ) , requestBody : & content , } , & retConfigMap ) return retConfigMap , err } 
func ( c * Client ) GetConfigMap ( name , namespace string ) ( ConfigMap , error ) { c . log ( " " , name ) if namespace == " " { namespace = c . namespace } var retConfigMap ConfigMap err := c . request ( & request { path : fmt . Sprintf ( " " , namespace , name ) , } , & retConfigMap ) return retConfigMap , err } 
func ( c * Client ) ReplaceConfigMap ( name string , config ConfigMap ) ( ConfigMap , error ) { c . log ( " " , name ) namespace := c . namespace if config . Namespace != " " { namespace = config . Namespace } var retConfigMap ConfigMap err := c . request ( & request { method : http . MethodPut , path : fmt . Sprintf ( " " , namespace , name ) , requestBody : & config , } , & retConfigMap ) return retConfigMap , err } 
func GetDiskUsage ( path string ) ( percentBlocksFree float64 , bytesFree , bytesUsed uint64 , err error ) { var stat syscall . Statfs_t err = syscall . Statfs ( path , & stat ) if err != nil { return 0 , 0 , 0 , err } percentBlocksFree = float64 ( stat . Bfree ) / float64 ( stat . Blocks ) * 100 bytesFree = stat . Bfree * uint64 ( stat . Bsize ) bytesUsed = ( stat . Blocks - stat . Bfree ) * uint64 ( stat . Bsize ) return percentBlocksFree , bytesFree , bytesUsed , nil } 
func GetATime ( path string , defaultTime time . Time ) time . Time { at , err := atime . Stat ( path ) if err != nil { log . WithError ( err ) . Errorf ( " " , path ) return defaultTime } return at } 
func RegisterLens ( lens Lens ) error { config := lens . Config ( ) _ , ok := lensReg [ config . Name ] if ok { return fmt . Errorf ( " " , config . Name ) } if config . Title == " " { return errors . New ( " " ) } if config . Priority < 0 { return errors . New ( " " ) } lensReg [ config . Name ] = lens logrus . Infof ( " " , config . Name , config . Title ) return nil } 
func GetLens ( name string ) ( Lens , error ) { lens , ok := lensReg [ name ] if ! ok { return nil , ErrInvalidLensName } return lens , nil } 
func LastNLines ( a Artifact , n int64 ) ( [ ] string , error ) { } 
func LastNLinesChunked ( a Artifact , n , chunkSize int64 ) ( [ ] string , error ) { toRead := chunkSize + 1 chunks := int64 ( 1 ) var contents [ ] byte var linesInContents int64 artifactSize , err := a . Size ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } offset := artifactSize - chunks * chunkSize lastOffset := offset var lastRead int64 for linesInContents < n && offset != 0 { offset = lastOffset - lastRead if offset < 0 { toRead = offset + chunkSize + 1 offset = 0 } bytesRead := make ( [ ] byte , toRead ) numBytesRead , err := a . ReadAt ( bytesRead , offset ) if err != nil && err != io . EOF { return nil , fmt . Errorf ( " " , err ) } lastRead = int64 ( numBytesRead ) lastOffset = offset bytesRead = bytes . Trim ( bytesRead , " \x00 " ) linesInContents += int64 ( bytes . Count ( bytesRead , [ ] byte ( " \n " ) ) ) contents = append ( bytesRead , contents ... ) chunks ++ } var lines [ ] string scanner := bufio . NewScanner ( bytes . NewReader ( contents ) ) scanner . Split ( bufio . ScanLines ) for scanner . Scan ( ) { line := scanner . Text ( ) lines = append ( lines , line ) } l := int64 ( len ( lines ) ) if l < n { return lines , nil } return lines [ l - n : ] , nil } 
func NewClient ( tokenGenerator func ( ) [ ] byte ) * Client { return & Client { logger : logrus . WithField ( " " , " " ) , tokenGenerator : tokenGenerator , } } 
func ( sl * Client ) WriteMessage ( text , channel string ) error { sl . log ( " " , text , channel ) if sl . fake { return nil } var uv = sl . urlValues ( ) uv . Add ( " " , channel ) uv . Add ( " " , text ) _ , err := sl . postMessage ( chatPostMessage , uv ) return err } 
func ( NATGateway ) MarkAndSweep ( sess * session . Session , acct string , region string , set * Set ) error { svc := ec2 . New ( sess , & aws . Config { Region : aws . String ( region ) } ) inp := & ec2 . DescribeNatGatewaysInput { } if err := svc . DescribeNatGatewaysPages ( inp , func ( page * ec2 . DescribeNatGatewaysOutput , _ bool ) bool { for _ , gw := range page . NatGateways { g := & natGateway { Account : acct , Region : region , ID : * gw . NatGatewayId , } if set . Mark ( g ) { inp := & ec2 . DeleteNatGatewayInput { NatGatewayId : gw . NatGatewayId } if _ , err := svc . DeleteNatGateway ( inp ) ; err != nil { klog . Warningf ( " " , g . ARN ( ) , err ) } } } return true } ) ; err != nil { return err } return nil } 
func ( NATGateway ) ListAll ( sess * session . Session , acct , region string ) ( * Set , error ) { svc := ec2 . New ( sess , & aws . Config { Region : aws . String ( region ) } ) set := NewSet ( 0 ) inp := & ec2 . DescribeNatGatewaysInput { } err := svc . DescribeNatGatewaysPages ( inp , func ( page * ec2 . DescribeNatGatewaysOutput , _ bool ) bool { for _ , gw := range page . NatGateways { now := time . Now ( ) arn := natGateway { Account : acct , Region : region , ID : * gw . NatGatewayId , } . ARN ( ) set . firstSeen [ arn ] = now } return true } ) return set , errors . Wrapf ( err , " " , acct , region ) } 
func ( c * ProwV1Client ) RESTClient ( ) rest . Interface { if c == nil { return nil } return c . restClient } 
func NewClient ( owner string , url string ) * Client { client := & Client { url : url , owner : owner , storage : storage . NewMemoryStorage ( ) , } client . Dialer . RetrySleep = time . Second * 10 client . Dialer . KeepAlive = 30 * time . Second client . Dialer . DualStack = true client . http . Transport = & http . Transport { Proxy : http . ProxyFromEnvironment , Dial : client . Dialer . Dial , DialContext : client . Dialer . DialContext , MaxIdleConns : 100 , IdleConnTimeout : 90 * time . Second , TLSHandshakeTimeout : 10 * time . Second , ExpectContinueTimeout : 1 * time . Second , } return client } 
func ( c * Client ) Acquire ( rtype , state , dest string ) ( * common . Resource , error ) { r , err := c . acquire ( rtype , state , dest ) if err != nil { return nil , err } c . lock . Lock ( ) defer c . lock . Unlock ( ) if r != nil { c . storage . Add ( * r ) } return r , nil } 
func ( c * Client ) AcquireWait ( ctx context . Context , rtype , state , dest string ) ( * common . Resource , error ) { if ctx == nil { return nil , ErrContextRequired } if err != nil { if err == ErrAlreadyInUse || err == ErrNotFound { select { case <- ctx . Done ( ) : return nil , err case <- time . After ( 3 * time . Second ) : continue } } return nil , err } return r , nil } } 
func ( c * Client ) AcquireByState ( state , dest string , names [ ] string ) ( [ ] common . Resource , error ) { resources , err := c . acquireByState ( state , dest , names ) if err != nil { return nil , err } c . lock . Lock ( ) defer c . lock . Unlock ( ) for _ , r := range resources { c . storage . Add ( r ) } return resources , nil } 
func ( c * Client ) AcquireByStateWait ( ctx context . Context , state , dest string , names [ ] string ) ( [ ] common . Resource , error ) { if ctx == nil { return nil , ErrContextRequired } if err != nil { if err == ErrAlreadyInUse || err == ErrNotFound { select { case <- ctx . Done ( ) : return nil , err case <- time . After ( 3 * time . Second ) : continue } } return nil , err } return r , nil } } 
func ( c * Client ) ReleaseAll ( dest string ) error { c . lock . Lock ( ) defer c . lock . Unlock ( ) resources , err := c . storage . List ( ) if err != nil { return err } if len ( resources ) == 0 { return fmt . Errorf ( " " ) } var allErrors error for _ , r := range resources { c . storage . Delete ( r . GetName ( ) ) err := c . release ( r . GetName ( ) , dest ) if err != nil { allErrors = multierror . Append ( allErrors , err ) } } return allErrors } 
func ( c * Client ) ReleaseOne ( name , dest string ) error { c . lock . Lock ( ) defer c . lock . Unlock ( ) if _ , err := c . storage . Get ( name ) ; err != nil { return fmt . Errorf ( " " , name ) } c . storage . Delete ( name ) if err := c . release ( name , dest ) ; err != nil { return err } return nil } 
func ( c * Client ) UpdateAll ( state string ) error { c . lock . Lock ( ) defer c . lock . Unlock ( ) resources , err := c . storage . List ( ) if err != nil { return err } if len ( resources ) == 0 { return fmt . Errorf ( " " ) } var allErrors error for _ , r := range resources { if err := c . update ( r . GetName ( ) , state , nil ) ; err != nil { allErrors = multierror . Append ( allErrors , err ) continue } if err := c . updateLocalResource ( r , state , nil ) ; err != nil { allErrors = multierror . Append ( allErrors , err ) } } return allErrors } 
func ( c * Client ) SyncAll ( ) error { c . lock . Lock ( ) defer c . lock . Unlock ( ) resources , err := c . storage . List ( ) if err != nil { return err } if len ( resources ) == 0 { logrus . Info ( " " ) return nil } var allErrors error for _ , i := range resources { r , err := common . ItemToResource ( i ) if err != nil { allErrors = multierror . Append ( allErrors , err ) continue } if err := c . update ( r . Name , r . State , nil ) ; err != nil { allErrors = multierror . Append ( allErrors , err ) continue } if err := c . storage . Update ( r ) ; err != nil { allErrors = multierror . Append ( allErrors , err ) } } return allErrors } 
func ( c * Client ) UpdateOne ( name , state string , userData * common . UserData ) error { c . lock . Lock ( ) defer c . lock . Unlock ( ) r , err := c . storage . Get ( name ) if err != nil { return fmt . Errorf ( " " , name ) } if err := c . update ( r . GetName ( ) , state , userData ) ; err != nil { return err } return c . updateLocalResource ( r , state , userData ) } 
func ( c * Client ) Reset ( rtype , state string , expire time . Duration , dest string ) ( map [ string ] string , error ) { return c . reset ( rtype , state , expire , dest ) } 
func ( c * Client ) Metric ( rtype string ) ( common . Metric , error ) { return c . metric ( rtype ) } 
func ( c * Client ) HasResource ( ) bool { resources , _ := c . storage . List ( ) return len ( resources ) > 0 } 
func ( c * Client ) updateLocalResource ( i common . Item , state string , data * common . UserData ) error { res , err := common . ItemToResource ( i ) if err != nil { return err } res . State = state if res . UserData == nil { res . UserData = data } else { res . UserData . Update ( data ) } return c . storage . Update ( res ) } 
func ( d * DialerWithRetry ) DialContext ( ctx context . Context , network , address string ) ( net . Conn , error ) { sleep := d . RetrySleep i := uint ( 0 ) for { conn , err := d . Dialer . DialContext ( ctx , network , address ) if err != nil { if isDialErrorRetriable ( err ) { if i < count - 1 { select { case <- time . After ( sleep ) : i ++ continue case <- ctx . Done ( ) : return nil , err } } } return nil , err } return conn , nil } } 
func isDialErrorRetriable ( err error ) bool { opErr , isOpErr := err . ( * net . OpError ) if ! isOpErr { return false } if opErr . Timeout ( ) || opErr . Temporary ( ) { return true } sysErr , isSysErr := opErr . Err . ( * os . SyscallError ) if ! isSysErr { return false } switch sysErr . Err { case syscall . ECONNREFUSED , syscall . ECONNRESET : return true } return false } 
func NewDashboardAgent ( repos [ ] string , config * config . GitHubOAuthConfig , log * logrus . Entry ) * DashboardAgent { return & DashboardAgent { repos : repos , goac : config , log : log , } } 
func ( da * DashboardAgent ) HandlePrStatus ( queryHandler PullRequestQueryHandler ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { serverError := func ( action string , err error ) { da . log . WithError ( err ) . Errorf ( " " , action ) msg := fmt . Sprintf ( " " , action , err ) http . Error ( w , msg , http . StatusInternalServerError ) } data := UserData { Login : false , } if err != nil { da . log . WithError ( err ) . Info ( " " ) if err := invalidateGitHubSession ( w , r , session ) ; err != nil { serverError ( " " , err ) return } } var user * github . User var botName string if ok && token . Valid ( ) { githubClient := github . NewClient ( func ( ) [ ] byte { return [ ] byte ( token . AccessToken ) } , github . DefaultGraphQLEndpoint , github . DefaultAPIEndpoint ) var err error botName , err = githubClient . BotName ( ) user = & github . User { Login : botName } if err != nil { if strings . Contains ( err . Error ( ) , " " ) { da . log . Info ( " " ) if err := invalidateGitHubSession ( w , r , session ) ; err != nil { serverError ( " " , err ) return } } else { serverError ( " " , err ) return } } } if user != nil { login := user . Login data . Login = true session . Values [ loginKey ] = login if err := session . Save ( r , w ) ; err != nil { serverError ( " " , err ) return } query := da . ConstructSearchQuery ( login ) if err := r . ParseForm ( ) ; err == nil { if q := r . Form . Get ( " " ) ; q != " " { query = q } } } } pullRequests , err := queryHandler . QueryPullRequests ( context . Background ( ) , ghc , query ) if err != nil { serverError ( " " , err ) return } var pullRequestWithContexts [ ] PullRequestWithContexts for _ , pr := range pullRequests { prcontexts , err := queryHandler . GetHeadContexts ( ghc , pr ) if err != nil { serverError ( " " , err ) continue } pullRequestWithContexts = append ( pullRequestWithContexts , PullRequestWithContexts { Contexts : prcontexts , PullRequest : pr , } ) } data . PullRequestsWithContexts = pullRequestWithContexts } marshaledData , err := json . Marshal ( data ) if err != nil { da . log . WithError ( err ) . Error ( " " ) } if v := r . URL . Query ( ) . Get ( " " ) ; v != " " { fmt . Fprintf ( w , " " , v ) w . Write ( marshaledData ) io . WriteString ( w , " " ) } else { w . Write ( marshaledData ) } } } 
func ( da * DashboardAgent ) QueryPullRequests ( ctx context . Context , ghc githubClient , query string ) ( [ ] PullRequest , error ) { var prs [ ] PullRequest vars := map [ string ] interface { } { " " : ( githubql . String ) ( query ) , " " : ( * githubql . String ) ( nil ) , } var totalCost int var remaining int for { sq := searchQuery { } if err := ghc . Query ( ctx , & sq , vars ) ; err != nil { return nil , err } totalCost += int ( sq . RateLimit . Cost ) remaining = int ( sq . RateLimit . Remaining ) for _ , n := range sq . Search . Nodes { prs = append ( prs , n . PullRequest ) } if ! sq . Search . PageInfo . HasNextPage { break } vars [ " " ] = githubql . NewString ( sq . Search . PageInfo . EndCursor ) } da . log . Infof ( " \" \" " , query , totalCost , remaining ) return prs , nil } 
func ( da * DashboardAgent ) GetHeadContexts ( ghc githubClient , pr PullRequest ) ( [ ] Context , error ) { org := string ( pr . Repository . Owner . Login ) repo := string ( pr . Repository . Name ) combined , err := ghc . GetCombinedStatus ( org , repo , string ( pr . HeadRefOID ) ) if err != nil { return nil , fmt . Errorf ( " " , err ) } contexts := make ( [ ] Context , 0 , len ( combined . Statuses ) ) for _ , status := range combined . Statuses { contexts = append ( contexts , Context { Context : status . Context , Description : status . Description , State : strings . ToUpper ( status . State ) , } , ) } return contexts , nil } 
func ( da * DashboardAgent ) ConstructSearchQuery ( login string ) string { tokens := [ ] string { " " , " " , " " + login } for i := range da . repos { tokens = append ( tokens , fmt . Sprintf ( " \" \" " , da . repos [ i ] ) ) } return strings . Join ( tokens , " " ) } 
func LoadClusterConfigs ( kubeconfig , buildCluster string ) ( map [ string ] rest . Config , error ) { logrus . Infof ( " " ) if err != nil { logrus . WithError ( err ) . Warn ( " " ) } kubeCfgs , currentContext , err := kubeConfigs ( kubeconfig ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if err != nil { return nil , fmt . Errorf ( " " , err ) } return mergeConfigs ( localCfg , kubeCfgs , currentContext , buildCfgs ) } 
func parseLinks ( h string ) map [ string ] string { links := map [ string ] string { } for _ , m := range lre . FindAllStringSubmatch ( h , 10 ) { if len ( m ) != 3 { continue } links [ m [ 2 ] ] = m [ 1 ] } return links } 
func NewBundledStates ( description string ) BundledStates { return BundledStates { description : description , states : map [ string ] State { } , } } 
func ( b BundledStates ) ReceiveEvent ( ID string , eventName , label string , t time . Time ) bool { state , ok := b . states [ ID ] if ! ok { state = NewState ( b . description ) } state , changed := state . ReceiveEvent ( eventName , label , t ) b . states [ ID ] = state return changed } 
func ( b BundledStates ) ages ( t time . Time ) map [ string ] time . Duration { ages := map [ string ] time . Duration { } for id , state := range b . states { if ! state . Active ( ) { continue } ages [ id ] = state . Age ( t ) } return ages } 
func ( b BundledStates ) Total ( t time . Time ) ( count int , sum int64 ) { for _ , age := range b . ages ( t ) { count ++ sum += int64 ( age / time . Minute ) } return } 
func ( b BundledStates ) Percentile ( t time . Time , percentile int ) time . Duration { if percentile > 100 || percentile <= 0 { panic ( fmt . Errorf ( " " , percentile ) ) } ages := [ ] time . Duration { } for _ , age := range b . ages ( t ) { ages = append ( ages , age ) } if len ( ages ) == 0 { return 0 } sort . Sort ( ByDuration ( ages ) ) index := int ( math . Ceil ( float64 ( percentile ) * float64 ( len ( ages ) ) / 100 ) - 1 ) if index >= len ( ages ) { panic ( fmt . Errorf ( " " , index , len ( ages ) ) ) } return ages [ index ] } 
func NewMetrics ( ) * Metrics { return & Metrics { ClientMetrics : & ClientMetrics { Requests : requests , RequestRetries : requestRetries , RequestLatency : requestLatency , } , ResyncPeriod : resyncPeriod , } } 
func NewGroup ( gitAttributesContent func ( ) ( [ ] byte , error ) ) ( * Group , error ) { g := & Group { LinguistGeneratedPatterns : [ ] Pattern { } , } bs , err := gitAttributesContent ( ) if err != nil { switch err . ( type ) { case * github . FileNotFound : return g , nil default : return nil , fmt . Errorf ( " " , err ) } } if err := g . load ( bytes . NewBuffer ( bs ) ) ; err != nil { return nil , err } return g , nil } 
func ( g * Group ) load ( r io . Reader ) error { s := bufio . NewScanner ( r ) for s . Scan ( ) { } fs := strings . Fields ( l ) if len ( fs ) < 2 { continue } if attributes . Has ( " " ) { p , err := parsePattern ( fs [ 0 ] ) if err != nil { return fmt . Errorf ( " " , err ) } g . LinguistGeneratedPatterns = append ( g . LinguistGeneratedPatterns , p ) } } if err := s . Err ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( g * Group ) IsLinguistGenerated ( path string ) bool { for _ , p := range g . LinguistGeneratedPatterns { if p . Match ( path ) { return true } } return false } 
func handle ( log * logrus . Entry , ghc githubClient , cp commentPruner , ie * github . IssueEvent , mentionRe * regexp . Regexp ) error { } org := ie . Repo . Owner . Login repo := ie . Repo . Name number := ie . Issue . Number hasSigLabel := hasSigLabel ( ie . Issue . Labels ) hasNeedsSigLabel := github . HasLabel ( labels . NeedsSig , ie . Issue . Labels ) if hasSigLabel && hasNeedsSigLabel { if err := ghc . RemoveLabel ( org , repo , number , labels . NeedsSig ) ; err != nil { log . WithError ( err ) . Errorf ( " " , labels . NeedsSig ) } botName , err := ghc . BotName ( ) if err != nil { return fmt . Errorf ( " " , err ) } cp . PruneComments ( shouldPrune ( log , botName ) ) } else if ! hasSigLabel && ! hasNeedsSigLabel { if err := ghc . AddLabel ( org , repo , number , labels . NeedsSig ) ; err != nil { log . WithError ( err ) . Errorf ( " " , labels . NeedsSig ) } msg := plugins . FormatResponse ( ie . Issue . User . Login , needsSIGMessage , needsSIGDetails ) if err := ghc . CreateComment ( org , repo , number , msg ) ; err != nil { log . WithError ( err ) . Error ( " " ) } } return nil } 
func shouldPrune ( log * logrus . Entry , botName string ) func ( github . IssueComment ) bool { return func ( comment github . IssueComment ) bool { if comment . User . Login != botName { return false } return strings . Contains ( comment . Body , needsSIGMessage ) } } 
func NewDiskCache ( delegate http . RoundTripper , cacheDir string , cacheSizeGB , maxConcurrency int ) http . RoundTripper { return NewFromCache ( delegate , diskcache . NewWithDiskv ( diskv . New ( diskv . Options { BasePath : path . Join ( cacheDir , " " ) , TempDir : path . Join ( cacheDir , " " ) , CacheSizeMax : uint64 ( cacheSizeGB ) * uint64 ( 1000000000 ) , } 
func NewMemCache ( delegate http . RoundTripper , maxConcurrency int ) http . RoundTripper { return NewFromCache ( delegate , httpcache . NewMemoryCache ( ) , maxConcurrency ) } 
func NewFromCache ( delegate http . RoundTripper , cache httpcache . Cache , maxConcurrency int ) http . RoundTripper { cacheTransport := httpcache . NewTransport ( cache ) cacheTransport . Transport = newThrottlingTransport ( maxConcurrency , upstreamTransport { delegate : delegate } ) return & requestCoalescer { keys : make ( map [ string ] * responseWaiter ) , delegate : cacheTransport , } } 
func ( c * Clientset ) ProwV1 ( ) prowv1 . ProwV1Interface { return & fakeprowv1 . FakeProwV1 { Fake : & c . Fake } } 
func ( c * Clientset ) Prow ( ) prowv1 . ProwV1Interface { return & fakeprowv1 . FakeProwV1 { Fake : & c . Fake } } 
func NewOwners ( log * logrus . Entry , filenames [ ] string , r Repo , s int64 ) Owners { return Owners { filenames : filenames , repo : r , seed : s , log : log } } 
func ( o Owners ) GetApprovers ( ) map [ string ] sets . String { ownersToApprovers := map [ string ] sets . String { } for fn := range o . GetOwnersSet ( ) { ownersToApprovers [ fn ] = o . repo . Approvers ( fn ) } return ownersToApprovers } 
func ( o Owners ) GetLeafApprovers ( ) map [ string ] sets . String { ownersToApprovers := map [ string ] sets . String { } for fn := range o . GetOwnersSet ( ) { ownersToApprovers [ fn ] = o . repo . LeafApprovers ( fn ) } return ownersToApprovers } 
func ( o Owners ) GetAllPotentialApprovers ( ) [ ] string { approversOnly := [ ] string { } for _ , approverList := range o . GetLeafApprovers ( ) { for approver := range approverList { approversOnly = append ( approversOnly , approver ) } } sort . Strings ( approversOnly ) if len ( approversOnly ) == 0 { o . log . Debug ( " " ) } return approversOnly } 
func ( o Owners ) GetReverseMap ( approvers map [ string ] sets . String ) map [ string ] sets . String { approverOwnersfiles := map [ string ] sets . String { } for ownersFile , approvers := range approvers { for approver := range approvers { if _ , ok := approverOwnersfiles [ approver ] ; ok { approverOwnersfiles [ approver ] . Insert ( ownersFile ) } else { approverOwnersfiles [ approver ] = sets . NewString ( ownersFile ) } } } return approverOwnersfiles } 
func ( o Owners ) temporaryUnapprovedFiles ( approvers sets . String ) sets . String { ap := NewApprovers ( o ) for approver := range approvers { ap . AddApprover ( approver , " " , false ) } return ap . UnapprovedFiles ( ) } 
func ( o Owners ) KeepCoveringApprovers ( reverseMap map [ string ] sets . String , knownApprovers sets . String , potentialApprovers [ ] string ) sets . String { if len ( potentialApprovers ) == 0 { o . log . Debug ( " " ) } keptApprovers := sets . NewString ( ) unapproved := o . temporaryUnapprovedFiles ( knownApprovers ) for _ , suggestedApprover := range o . GetSuggestedApprovers ( reverseMap , potentialApprovers ) . List ( ) { if reverseMap [ suggestedApprover ] . Intersection ( unapproved ) . Len ( ) != 0 { keptApprovers . Insert ( suggestedApprover ) } } return keptApprovers } 
func ( o Owners ) GetSuggestedApprovers ( reverseMap map [ string ] sets . String , potentialApprovers [ ] string ) sets . String { ap := NewApprovers ( o ) for ! ap . RequirementsMet ( ) { newApprover := findMostCoveringApprover ( potentialApprovers , reverseMap , ap . UnapprovedFiles ( ) ) if newApprover == " " { o . log . Warnf ( " " , ap . UnapprovedFiles ( ) . List ( ) ) return ap . GetCurrentApproversSet ( ) } ap . AddApprover ( newApprover , " " , false ) } return ap . GetCurrentApproversSet ( ) } 
func ( o Owners ) GetOwnersSet ( ) sets . String { owners := sets . NewString ( ) for _ , fn := range o . filenames { owners . Insert ( o . repo . FindApproverOwnersForFile ( fn ) ) } o . removeSubdirs ( owners ) return owners } 
func ( o Owners ) GetShuffledApprovers ( ) [ ] string { approversList := o . GetAllPotentialApprovers ( ) order := rand . New ( rand . NewSource ( o . seed ) ) . Perm ( len ( approversList ) ) people := make ( [ ] string , 0 , len ( approversList ) ) for _ , i := range order { people = append ( people , approversList [ i ] ) } return people } 
func ( o Owners ) removeSubdirs ( dirs sets . String ) { canonicalize := func ( p string ) string { if p == " " { return " " } return p } for _ , dir := range dirs . List ( ) { path := dir for { if o . repo . IsNoParentOwners ( path ) || canonicalize ( path ) == " " { break } path = filepath . Dir ( path ) if dirs . Has ( canonicalize ( path ) ) { dirs . Delete ( dir ) break } } } } 
func ( a Approval ) String ( ) string { return fmt . Sprintf ( `*<a href="%s" title="%s">%s</a>*` , a . Reference , a . How , a . Login , ) } 
func IntersectSetsCase ( one , other sets . String ) sets . String { lower := sets . NewString ( ) for item := range other { lower . Insert ( strings . ToLower ( item ) ) } intersection := sets . NewString ( ) for item := range one { if lower . Has ( strings . ToLower ( item ) ) { intersection . Insert ( item ) } } return intersection } 
func NewApprovers ( owners Owners ) Approvers { return Approvers { owners : owners , approvers : map [ string ] Approval { } , assignees : sets . NewString ( ) , ManuallyApproved : func ( ) bool { return false } , } } 
func ( ap * Approvers ) shouldNotOverrideApproval ( login string , noIssue bool ) bool { login = strings . ToLower ( login ) approval , alreadyApproved := ap . approvers [ login ] return alreadyApproved && approval . NoIssue && ! noIssue } 
func ( ap * Approvers ) AddLGTMer ( login , reference string , noIssue bool ) { if ap . shouldNotOverrideApproval ( login , noIssue ) { return } ap . approvers [ strings . ToLower ( login ) ] = Approval { Login : login , How : " " , Reference : reference , NoIssue : noIssue , } } 
func ( ap * Approvers ) RemoveApprover ( login string ) { delete ( ap . approvers , strings . ToLower ( login ) ) } 
func ( ap * Approvers ) AddAssignees ( logins ... string ) { for _ , login := range logins { ap . assignees . Insert ( strings . ToLower ( login ) ) } } 
func ( ap Approvers ) GetCurrentApproversSet ( ) sets . String { currentApprovers := sets . NewString ( ) for approver := range ap . approvers { currentApprovers . Insert ( approver ) } return currentApprovers } 
func ( ap Approvers ) GetCurrentApproversSetCased ( ) sets . String { currentApprovers := sets . NewString ( ) for _ , approval := range ap . approvers { currentApprovers . Insert ( approval . Login ) } return currentApprovers } 
func ( ap Approvers ) GetNoIssueApproversSet ( ) sets . String { approvers := sets . NewString ( ) for approver := range ap . NoIssueApprovers ( ) { approvers . Insert ( approver ) } return approvers } 
func ( ap Approvers ) GetFilesApprovers ( ) map [ string ] sets . String { filesApprovers := map [ string ] sets . String { } currentApprovers := ap . GetCurrentApproversSetCased ( ) for fn , potentialApprovers := range ap . owners . GetApprovers ( ) { } return filesApprovers } 
func ( ap Approvers ) NoIssueApprovers ( ) map [ string ] Approval { nia := map [ string ] Approval { } reverseMap := ap . owners . GetReverseMap ( ap . owners . GetApprovers ( ) ) for login , approver := range ap . approvers { if ! approver . NoIssue { continue } if len ( reverseMap [ login ] ) == 0 { continue } nia [ login ] = approver } return nia } 
func ( ap Approvers ) UnapprovedFiles ( ) sets . String { unapproved := sets . NewString ( ) for fn , approvers := range ap . GetFilesApprovers ( ) { if len ( approvers ) == 0 { unapproved . Insert ( fn ) } } return unapproved } 
func ( ap Approvers ) GetFiles ( baseURL * url . URL , branch string ) [ ] File { allOwnersFiles := [ ] File { } filesApprovers := ap . GetFilesApprovers ( ) for _ , file := range ap . owners . GetOwnersSet ( ) . List ( ) { if len ( filesApprovers [ file ] ) == 0 { allOwnersFiles = append ( allOwnersFiles , UnapprovedFile { baseURL : baseURL , filepath : file , branch : branch , } ) } else { allOwnersFiles = append ( allOwnersFiles , ApprovedFile { baseURL : baseURL , filepath : file , approvers : filesApprovers [ file ] , branch : branch , } ) } } return allOwnersFiles } 
func ( ap Approvers ) GetCCs ( ) [ ] string { randomizedApprovers := ap . owners . GetShuffledApprovers ( ) currentApprovers := ap . GetCurrentApproversSet ( ) approversAndAssignees := currentApprovers . Union ( ap . assignees ) leafReverseMap := ap . owners . GetReverseMap ( ap . owners . GetLeafApprovers ( ) ) suggested := ap . owners . KeepCoveringApprovers ( leafReverseMap , approversAndAssignees , randomizedApprovers ) approversAndSuggested := currentApprovers . Union ( suggested ) everyone := approversAndSuggested . Union ( ap . assignees ) fullReverseMap := ap . owners . GetReverseMap ( ap . owners . GetApprovers ( ) ) keepAssignees := ap . owners . KeepCoveringApprovers ( fullReverseMap , approversAndSuggested , everyone . List ( ) ) return suggested . Union ( keepAssignees ) . List ( ) } 
func ( ap Approvers ) RequirementsMet ( ) bool { return ap . AreFilesApproved ( ) && ( ! ap . RequireIssue || ap . AssociatedIssue != 0 || len ( ap . NoIssueApprovers ( ) ) != 0 ) } 
func ( ap Approvers ) IsApproved ( ) bool { reqsMet := ap . RequirementsMet ( ) if ! reqsMet && ap . ManuallyApproved ( ) { return true } return reqsMet } 
func ( ap Approvers ) ListApprovals ( ) [ ] Approval { approvals := [ ] Approval { } for _ , approver := range ap . GetCurrentApproversSet ( ) . List ( ) { approvals = append ( approvals , ap . approvers [ approver ] ) } return approvals } 
func ( ap Approvers ) ListNoIssueApprovals ( ) [ ] Approval { approvals := [ ] Approval { } for _ , approver := range ap . GetNoIssueApproversSet ( ) . List ( ) { approvals = append ( approvals , ap . approvers [ approver ] ) } return approvals } 
func GenerateTemplate ( templ , name string , data interface { } ) ( string , error ) { buf := bytes . NewBufferString ( " " ) if messageTempl , err := template . New ( name ) . Parse ( templ ) ; err != nil { return " " , fmt . Errorf ( " " , name , err ) } else if err := messageTempl . Execute ( buf , data ) ; err != nil { return " " , fmt . Errorf ( " " , name , err ) } return buf . String ( ) , nil } 
func GetMessage ( ap Approvers , linkURL * url . URL , org , repo , branch string ) * string { linkURL . Path = org + " " + repo message , err := GenerateTemplate ( `{{if (and (not .ap.RequirementsMet) (call .ap.ManuallyApproved )) }} Approval requirements bypassed by manually added approval. {{end -}} This pull-request has been approved by:{{range $index, $approval := .ap.ListApprovals}}{{if $index}}, {{else}} {{end}}{{$approval}}{{end}} {{- if (and (not .ap.AreFilesApproved) (not (call .ap.ManuallyApproved))) }} To fully approve this pull request, please assign additional approvers. We suggest the following additional approver{{if ne 1 (len .ap.GetCCs)}}s{{end}}: {{range $index, $cc := .ap.GetCCs}}{{if $index}}, {{end}}**{{$cc}}**{{end}} If they are not already assigned, you can assign the PR to them by writing ` + " " + ` in a comment when ready. {{- end}} {{if not .ap.RequireIssue -}} {{else if .ap.AssociatedIssue -}} Associated issue: *#{{.ap.AssociatedIssue}}* {{ else if len .ap.NoIssueApprovers -}} Associated issue requirement bypassed by:{{range $index, $approval := .ap.ListNoIssueApprovals}}{{if $index}}, {{else}} {{end}}{{$approval}}{{end}} {{ else if call .ap.ManuallyApproved -}} *No associated issue*. Requirement bypassed by manually added approval. {{ else -}} *No associated issue*. Update pull-request body to add a reference to an issue, or get approval with ` + " " + ` {{ end -}} The full list of commands accepted by this bot can be found [here](https: The pull request process is described [here](https: <details {{if (and (not .ap.AreFilesApproved) (not (call .ap.ManuallyApproved))) }}open{{end}}> Needs approval from an approver in each of these files: {{range .ap.GetFiles .baseURL .branch}}{{.}}{{end}} Approvers can indicate their approval by writing ` + " " + ` in a comment Approvers can cancel approval by writing ` + " " + ` in a comment </details>` , " " , map [ string ] interface { } { " " : ap , " " : linkURL , " " : org , " " : repo , " " : branch } ) if err != nil { ap . owners . log . WithError ( err ) . Errorf ( " " ) return nil } message += getGubernatorMetadata ( ap . GetCCs ( ) ) title , err := GenerateTemplate ( " " , " " , ap ) if err != nil { ap . owners . log . WithError ( err ) . Errorf ( " " ) return nil } return notification ( ApprovalNotificationName , title , message ) } 
func getGubernatorMetadata ( toBeAssigned [ ] string ) string { bytes , err := json . Marshal ( map [ string ] [ ] string { " " : toBeAssigned } ) if err == nil { return fmt . Sprintf ( " \n " , bytes ) } return " " } 
func writeTemplate ( templatePath string , outputPath string , data interface { } ) error { } , } t , err := template . New ( filepath . Base ( templatePath ) ) . Funcs ( funcMap ) . ParseFiles ( templatePath ) if err != nil { return err } if err != nil { return err } } if err != nil { return err } defer f . Close ( ) f . Truncate ( 0 ) if err != nil { return err } return nil } 
func validate ( labels [ ] Label , parent string , seen map [ string ] string ) ( map [ string ] string , error ) { newSeen := copyStringMap ( seen ) for _ , l := range labels { name := strings . ToLower ( l . Name ) path := parent + " " + name if other , present := newSeen [ name ] ; present { return newSeen , fmt . Errorf ( " " , name , path , other ) } newSeen [ name ] = path if newSeen , err := validate ( l . Previously , path , newSeen ) ; err != nil { return newSeen , err } if len ( l . Description ) > 100 { } } return newSeen , nil } 
func ( c Configuration ) Labels ( ) [ ] Label { var labelarrays [ ] [ ] Label labelarrays = append ( labelarrays , c . Default . Labels ) for _ , repo := range c . Repos { labelarrays = append ( labelarrays , repo . Labels ) } labelmap := make ( map [ string ] Label ) for _ , labels := range labelarrays { for _ , l := range labels { name := strings . ToLower ( l . Name ) if _ , ok := labelmap [ name ] ; ! ok { labelmap [ name ] = l } } } var labels [ ] Label for _ , label := range labelmap { labels = append ( labels , label ) } sort . Slice ( labels , func ( i , j int ) bool { return labels [ i ] . Name < labels [ j ] . Name } ) return labels } 
func ( c Configuration ) validate ( orgs string ) error { if err != nil { return fmt . Errorf ( " " , err ) } sort . Strings ( sortedOrgs ) } if len ( data ) == 2 { if ! stringInSortedSlice ( data [ 0 ] , sortedOrgs ) { logrus . WithField ( " " , orgs ) . WithField ( " " , data [ 0 ] ) . WithField ( " " , repo ) . Warn ( " " ) } } } } return nil } 
func LabelsForTarget ( labels [ ] Label , target LabelTarget ) ( filteredLabels [ ] Label ) { for _ , label := range labels { if target == label . Target { filteredLabels = append ( filteredLabels , label ) } } return } 
func LoadConfig ( path string , orgs string ) ( * Configuration , error ) { if path == " " { return nil , errors . New ( " " ) } var c Configuration data , err := ioutil . ReadFile ( path ) if err != nil { return nil , err } if err = yaml . Unmarshal ( data , & c ) ; err != nil { return nil , err } if err = c . validate ( orgs ) ; err != nil { } return & c , nil } 
func GetOrg ( org string ) ( string , bool ) { data := strings . Split ( org , " " ) if len ( data ) == 2 && data [ 0 ] == " " { return data [ 1 ] , true } return org , false } 
func loadRepos ( org string , gc client ) ( [ ] string , error ) { org , isUser := GetOrg ( org ) repos , err := gc . GetRepos ( org , isUser ) if err != nil { return nil , err } var rl [ ] string for _ , r := range repos { if r . Archived { continue } rl = append ( rl , r . Name ) } return rl , nil } 
func loadLabels ( gc client , org string , repos [ ] string ) ( * RepoLabels , error ) { repoChan := make ( chan string , len ( repos ) ) for _ , repo := range repos { repoChan <- repo } close ( repoChan ) wg := sync . WaitGroup { } wg . Add ( maxConcurrentWorkers ) labels := make ( chan RepoLabels , len ( repos ) ) errChan := make ( chan error , len ( repos ) ) for i := 0 ; i < maxConcurrentWorkers ; i ++ { go func ( repositories <- chan string ) { defer wg . Done ( ) for repository := range repositories { logrus . WithField ( " " , org ) . WithField ( " " , repository ) . Info ( " " ) repoLabels , err := gc . GetRepoLabels ( org , repository ) if err != nil { logrus . WithField ( " " , org ) . WithField ( " " , repository ) . Error ( " " ) errChan <- err } labels <- RepoLabels { repository : repoLabels } } } ( repoChan ) } wg . Wait ( ) close ( labels ) close ( errChan ) rl := RepoLabels { } for data := range labels { for repo , repoLabels := range data { rl [ repo ] = repoLabels } } var overallErr error if len ( errChan ) > 0 { var listErrs [ ] error for listErr := range errChan { listErrs = append ( listErrs , listErr ) } overallErr = fmt . Errorf ( " " , listErrs ) } return & rl , overallErr } 
func kill ( repo string , label Label ) Update { logrus . WithField ( " " , repo ) . WithField ( " " , label . Name ) . Info ( " " ) return Update { Why : " " , Current : & label , repo : repo } } 
func create ( repo string , label Label ) Update { logrus . WithField ( " " , repo ) . WithField ( " " , label . Name ) . Info ( " " ) return Update { Why : " " , Wanted : & label , repo : repo } } 
func rename ( repo string , previous , wanted Label ) Update { logrus . WithField ( " " , repo ) . WithField ( " " , previous . Name ) . WithField ( " " , wanted . Name ) . Info ( " " ) return Update { Why : " " , Current : & previous , Wanted : & wanted , repo : repo } } 
func change ( repo string , label Label ) Update { logrus . WithField ( " " , repo ) . WithField ( " " , label . Name ) . WithField ( " " , label . Color ) . Info ( " " ) return Update { Why : " " , Current : & label , Wanted : & label , repo : repo } } 
func classifyLabels ( labels [ ] Label , required , archaic , dead map [ string ] Label , now time . Time , parent * Label ) ( map [ string ] Label , map [ string ] Label , map [ string ] Label ) { newRequired := copyLabelMap ( required ) newArchaic := copyLabelMap ( archaic ) newDead := copyLabelMap ( dead ) for i , l := range labels { first := parent if first == nil { first = & labels [ i ] } lower := strings . ToLower ( l . Name ) switch { case parent == nil && l . DeleteAfter == nil : case l . DeleteAfter != nil && now . After ( * l . DeleteAfter ) : newDead [ lower ] = l case parent != nil : l . parent = parent newArchaic [ lower ] = l } newRequired , newArchaic , newDead = classifyLabels ( l . Previously , newRequired , newArchaic , newDead , now , first ) } return newRequired , newArchaic , newDead } 
func ( ru RepoUpdates ) DoUpdates ( org string , gc client ) error { var numUpdates int for _ , updates := range ru { numUpdates += len ( updates ) } updateChan := make ( chan repoUpdate , numUpdates ) for repo , updates := range ru { logrus . WithField ( " " , org ) . WithField ( " " , repo ) . Infof ( " " , len ( updates ) ) for _ , item := range updates { updateChan <- repoUpdate { repo : repo , update : item } } } close ( updateChan ) wg := sync . WaitGroup { } wg . Add ( maxConcurrentWorkers ) errChan := make ( chan error , numUpdates ) for i := 0 ; i < maxConcurrentWorkers ; i ++ { go func ( updates <- chan repoUpdate ) { defer wg . Done ( ) for item := range updates { repo := item . repo update := item . update logrus . WithField ( " " , org ) . WithField ( " " , repo ) . WithField ( " " , update . Why ) . Debug ( " " ) switch update . Why { case " " : err := gc . AddRepoLabel ( org , repo , update . Wanted . Name , update . Wanted . Description , update . Wanted . Color ) if err != nil { errChan <- err } case " " , " " : err := gc . UpdateRepoLabel ( org , repo , update . Current . Name , update . Wanted . Name , update . Wanted . Description , update . Wanted . Color ) if err != nil { errChan <- err } case " " : err := gc . DeleteRepoLabel ( org , repo , update . Current . Name ) if err != nil { errChan <- err } case " " : issues , err := gc . FindIssues ( fmt . Sprintf ( " \" \" \" \" " , org , repo , update . Current . Name , update . Wanted . Name ) , " " , false ) if err != nil { errChan <- err } if len ( issues ) == 0 { if err = gc . DeleteRepoLabel ( org , repo , update . Current . Name ) ; err != nil { errChan <- err } } for _ , i := range issues { if err = gc . AddLabel ( org , repo , i . Number , update . Wanted . Name ) ; err != nil { errChan <- err continue } if err = gc . RemoveLabel ( org , repo , i . Number , update . Current . Name ) ; err != nil { errChan <- err } } default : errChan <- errors . New ( " " + update . Why ) } } } ( updateChan ) } wg . Wait ( ) close ( errChan ) var overallErr error if len ( errChan ) > 0 { var updateErrs [ ] error for updateErr := range errChan { updateErrs = append ( updateErrs , updateErr ) } overallErr = fmt . Errorf ( " " , updateErrs ) } return overallErr } 
func main ( ) { logrus . SetFormatter ( logrusutil . NewDefaultFieldsFormatter ( nil , logrus . Fields { " " : " " } ) , ) flag . Parse ( ) if * debug { logrus . SetLevel ( logrus . DebugLevel ) } config , err := LoadConfig ( * labelsPath , * orgs ) if err != nil { logrus . WithError ( err ) . Fatalf ( " " , * labelsPath ) } if * onlyRepos != " " && * skipRepos != " " { logrus . Fatalf ( " " ) } if * onlyRepos != " " && * orgs != " " { logrus . Fatalf ( " " ) } switch { case * action == " " : if err := writeDocs ( * docsTemplate , * docsOutput , * config ) ; err != nil { logrus . WithError ( err ) . Fatalf ( " " , * docsTemplate , * docsOutput ) } case * action == " " : if err := writeCSS ( * cssTemplate , * cssOutput , * config ) ; err != nil { logrus . WithError ( err ) . Fatalf ( " " , * cssTemplate , * cssOutput ) } case * action == " " : githubClient , err := newClient ( * token , * tokens , * tokenBurst , ! * confirm , * graphqlEndpoint , endpoint . Strings ( ) ... ) if err != nil { logrus . WithError ( err ) . Fatal ( " " ) } if parseError != nil { logrus . WithError ( err ) . Fatal ( " " ) } for org := range reposToSync { if err = syncOrg ( org , githubClient , * config , reposToSync [ org ] ) ; err != nil { logrus . WithError ( err ) . Fatalf ( " " , org ) } } return } skippedRepos := map [ string ] [ ] string { } if * skipRepos != " " { reposToSkip , parseError := parseCommaDelimitedList ( * skipRepos ) if parseError != nil { logrus . WithError ( err ) . Fatal ( " " ) } skippedRepos = reposToSkip } for _ , org := range strings . Split ( * orgs , " " ) { org = strings . TrimSpace ( org ) logger := logrus . WithField ( " " , org ) logger . Info ( " " ) repos , err := loadRepos ( org , githubClient ) if err != nil { logger . WithError ( err ) . Fatalf ( " " ) } if skipped , exist := skippedRepos [ org ] ; exist { repos = sets . NewString ( repos ... ) . Difference ( sets . NewString ( skipped ... ) ) . UnsortedList ( ) } if err = syncOrg ( org , githubClient , * config , repos ) ; err != nil { logrus . WithError ( err ) . Fatalf ( " " , org ) } } default : logrus . Fatalf ( " " , * action ) } } 
func parseCommaDelimitedList ( list string ) ( map [ string ] [ ] string , error ) { mapping := map [ string ] [ ] string { } for _ , r := range strings . Split ( list , " " ) { value := strings . TrimSpace ( r ) if strings . Count ( value , " " ) != 1 { return nil , fmt . Errorf ( " " , value ) } parts := strings . SplitN ( value , " " , 2 ) if others , exist := mapping [ parts [ 0 ] ] ; ! exist { mapping [ parts [ 0 ] ] = [ ] string { parts [ 1 ] } } else { mapping [ parts [ 0 ] ] = append ( others , parts [ 1 ] ) } } return mapping , nil } 
func linkify ( text string ) string { link = discard . ReplaceAllString ( link , " " ) } 
func cssEscape ( s string ) ( escaped string ) { var IsAlpha = regexp . MustCompile ( `^[a-zA-Z]+$` ) . MatchString for i , c := range s { if ( i == 0 && unicode . IsDigit ( c ) ) || ! ( unicode . IsDigit ( c ) || IsAlpha ( string ( c ) ) ) { escaped += fmt . Sprintf ( " " , c ) continue } escaped += string ( c ) } return } 
func getTextColor ( backgroundColor string ) ( string , error ) { d , err := hex . DecodeString ( backgroundColor ) if err != nil || len ( d ) != 3 { return " " , errors . New ( " " ) } for i , v := range d { color [ i ] = float64 ( v ) / 255.0 if color [ i ] <= 0.03928 { color [ i ] = color [ i ] / 12.92 } else { color [ i ] = math . Pow ( ( color [ i ] + 0.055 ) / 1.055 , 2.4 ) } } L := 0.2126 * color [ 0 ] + 0.7152 * color [ 1 ] + 0.0722 * color [ 2 ] if ( L + 0.05 ) / ( 0.0 + 0.05 ) > ( 1.0 + 0.05 ) / ( L + 0.05 ) { return " " , nil } else { return " " , nil } } 
func NewCache ( diskRoot string ) * Cache { return & Cache { diskRoot : strings . TrimSuffix ( diskRoot , string ( os . PathListSeparator ) ) , } } 
func ( c * Cache ) KeyToPath ( key string ) string { return filepath . Join ( c . diskRoot , key ) } 
func ( c * Cache ) PathToKey ( key string ) string { return strings . TrimPrefix ( key , c . diskRoot + string ( os . PathSeparator ) ) } 
func ensureDir ( dir string ) error { if exists ( dir ) { return nil } return os . MkdirAll ( dir , os . FileMode ( 0744 ) ) } 
func ( c * Cache ) Put ( key string , content io . Reader , contentSHA256 string ) error { dir := filepath . Dir ( path ) err := ensureDir ( dir ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , dir ) } if err != nil { return fmt . Errorf ( " " , err ) } if err != nil { removeTemp ( temp . Name ( ) ) return fmt . Errorf ( " " , err ) } } else { hasher := sha256 . New ( ) _ , err = io . Copy ( io . MultiWriter ( temp , hasher ) , content ) if err != nil { removeTemp ( temp . Name ( ) ) return fmt . Errorf ( " " , err ) } actualContentSHA256 := hex . EncodeToString ( hasher . Sum ( nil ) ) if actualContentSHA256 != contentSHA256 { removeTemp ( temp . Name ( ) ) return fmt . Errorf ( " " , key , contentSHA256 , actualContentSHA256 ) } } if err != nil { removeTemp ( temp . Name ( ) ) return fmt . Errorf ( " " , err ) } temp . Close ( ) err = os . Rename ( temp . Name ( ) , path ) if err != nil { removeTemp ( temp . Name ( ) ) return fmt . Errorf ( " " , err ) } return nil } 
func ( c * Cache ) Get ( key string , readHandler ReadHandler ) error { path := c . KeyToPath ( key ) f , err := os . Open ( path ) if err != nil { if os . IsNotExist ( err ) { return readHandler ( false , nil ) } return fmt . Errorf ( " " , err ) } return readHandler ( true , f ) } 
func ( c * Cache ) GetEntries ( ) [ ] EntryInfo { entries := [ ] EntryInfo { } return nil } if ! f . IsDir ( ) { atime := diskutil . GetATime ( path , time . Now ( ) ) entries = append ( entries , EntryInfo { Path : path , LastAccess : atime , } ) } return nil } ) return entries } 
func ( c * Cache ) Delete ( key string ) error { return os . Remove ( c . KeyToPath ( key ) ) } 
func NewGCSArtifact ( ctx context . Context , handle artifactHandle , link string , path string , sizeLimit int64 ) * GCSArtifact { return & GCSArtifact { handle : handle , link : link , path : path , sizeLimit : sizeLimit , ctx : ctx , } } 
func ( a * GCSArtifact ) Size ( ) ( int64 , error ) { attrs , err := a . handle . Attrs ( a . ctx ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } return attrs . Size , nil } 
func ( a * GCSArtifact ) ReadAt ( p [ ] byte , off int64 ) ( n int , err error ) { gzipped , err := a . gzipped ( ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } if gzipped { return 0 , lenses . ErrGzipOffsetRead } artifactSize , err := a . Size ( ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } if off >= artifactSize { return 0 , fmt . Errorf ( " " ) } var gotEOF bool toRead := int64 ( len ( p ) ) if toRead + off > artifactSize { return 0 , fmt . Errorf ( " " ) } else if toRead + off == artifactSize { gotEOF = true } reader , err := a . handle . NewRangeReader ( a . ctx , off , toRead ) defer reader . Close ( ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } for offset < len ( p ) { n , err = reader . Read ( p [ offset : ] ) offset += n if err != nil { if err == io . EOF && gotEOF { break } return 0 , fmt . Errorf ( " " , err ) } } if gotEOF { return offset , io . EOF } return offset , nil } 
func ( a * GCSArtifact ) ReadAtMost ( n int64 ) ( [ ] byte , error ) { var reader io . ReadCloser var p [ ] byte gzipped , err := a . gzipped ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if gzipped { reader , err = a . handle . NewReader ( a . ctx ) if err != nil { return nil , fmt . Errorf ( " " , err ) } defer reader . Close ( ) p , err = ioutil . ReadAll ( reader ) if err != nil { return nil , fmt . Errorf ( " " , err ) } artifactSize := int64 ( len ( p ) ) readRange := n if n > artifactSize { readRange = artifactSize return p [ : readRange ] , io . EOF } return p [ : readRange ] , nil } artifactSize , err := a . Size ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } readRange := n var gotEOF bool if n > artifactSize { gotEOF = true readRange = artifactSize } reader , err = a . handle . NewRangeReader ( a . ctx , 0 , readRange ) if err != nil { return nil , fmt . Errorf ( " " , err ) } defer reader . Close ( ) p , err = ioutil . ReadAll ( reader ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if gotEOF { return p , io . EOF } return p , nil } 
func ( a * GCSArtifact ) ReadAll ( ) ( [ ] byte , error ) { size , err := a . Size ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if size > a . sizeLimit { return nil , lenses . ErrFileTooLarge } reader , err := a . handle . NewReader ( a . ctx ) if err != nil { return nil , fmt . Errorf ( " " , err ) } defer reader . Close ( ) p , err := ioutil . ReadAll ( reader ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return p , nil } 
func ( a * GCSArtifact ) ReadTail ( n int64 ) ( [ ] byte , error ) { gzipped , err := a . gzipped ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if gzipped { return nil , lenses . ErrGzipOffsetRead } size , err := a . Size ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } var offset int64 if n >= size { offset = 0 } else { offset = size - n } reader , err := a . handle . NewRangeReader ( a . ctx , offset , - 1 ) defer reader . Close ( ) if err != nil && err != io . EOF { return nil , fmt . Errorf ( " " , err ) } read , err := ioutil . ReadAll ( reader ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return read , nil } 
func ( a * GCSArtifact ) gzipped ( ) ( bool , error ) { attrs , err := a . handle . Attrs ( a . ctx ) if err != nil { return false , fmt . Errorf ( " " , err ) } return attrs . ContentEncoding == " " , nil } 
func optionsForRepo ( config * plugins . Configuration , org , repo string ) * plugins . Welcome { fullName := fmt . Sprintf ( " " , org , repo ) } return & c } } return & c } } 
func ( s * prowJobLister ) List ( selector labels . Selector ) ( ret [ ] * v1 . ProwJob , err error ) { err = cache . ListAll ( s . indexer , selector , func ( m interface { } ) { ret = append ( ret , m . ( * v1 . ProwJob ) ) } ) return ret , err } 
func ( s * prowJobLister ) ProwJobs ( namespace string ) ProwJobNamespaceLister { return prowJobNamespaceLister { indexer : s . indexer , namespace : namespace } } 
func ( s prowJobNamespaceLister ) List ( selector labels . Selector ) ( ret [ ] * v1 . ProwJob , err error ) { err = cache . ListAllByNamespace ( s . indexer , s . namespace , selector , func ( m interface { } ) { ret = append ( ret , m . ( * v1 . ProwJob ) ) } ) return ret , err } 
func MetadataFromFileName ( filename string ) ( string , map [ string ] string ) { metadata := make ( map [ string ] string ) segments := strings . Split ( filename , " " ) index := len ( segments ) - 1 segment := segments [ index ] } if _ , ok := metadata [ " " ] ; ok { if index == 0 { segment = " " } else { filename = filename [ : len ( filename ) - len ( segment ) - 1 ] index -= 1 segment = segments [ index ] } } if segment != " " { mediaType := mime . TypeByExtension ( " " + segment ) if mediaType != " " { metadata [ " " ] = mediaType } } if _ , ok := metadata [ " " ] ; ! ok { if _ , ok := metadata [ " " ] ; ok { metadata [ " " ] = " " delete ( metadata , " " ) } } return filename , metadata } 
func ( br Brancher ) RunsAgainstAllBranch ( ) bool { return len ( br . SkipBranches ) == 0 && len ( br . Branches ) == 0 } 
func ( br Brancher ) ShouldRun ( branch string ) bool { if br . RunsAgainstAllBranch ( ) { return true } } if len ( br . Branches ) == 0 || br . re . MatchString ( branch ) { return true } return false } 
func ( br Brancher ) Intersects ( other Brancher ) bool { if br . RunsAgainstAllBranch ( ) || other . RunsAgainstAllBranch ( ) { return true } if len ( br . Branches ) > 0 { baseBranches := sets . NewString ( br . Branches ... ) if len ( other . Branches ) > 0 { otherBranches := sets . NewString ( other . Branches ... ) if baseBranches . Intersection ( otherBranches ) . Len ( ) > 0 { return true } return false } } } return false } if len ( other . Branches ) == 0 { } return other . Intersects ( br ) } 
func ( cm RegexpChangeMatcher ) ShouldRun ( changes ChangedFilesProvider ) ( determined bool , shouldRun bool , err error ) { if cm . CouldRun ( ) { changeList , err := changes ( ) if err != nil { return true , false , err } return true , cm . RunsAgainstChanges ( changeList ) , nil } return false , false , nil } 
func ( cm RegexpChangeMatcher ) RunsAgainstChanges ( changes [ ] string ) bool { for _ , change := range changes { if cm . reChanges . MatchString ( change ) { return true } } return false } 
func ( ps Postsubmit ) CouldRun ( baseRef string ) bool { return ps . Brancher . ShouldRun ( baseRef ) } 
func ( ps Postsubmit ) ShouldRun ( baseRef string , changes ChangedFilesProvider ) ( bool , error ) { if ! ps . CouldRun ( baseRef ) { return false , nil } if determined , shouldRun , err := ps . RegexpChangeMatcher . ShouldRun ( changes ) ; err != nil { return false , err } else if determined { return shouldRun , nil } } 
func ( ps Presubmit ) CouldRun ( baseRef string ) bool { return ps . Brancher . ShouldRun ( baseRef ) } 
func ( ps Presubmit ) ShouldRun ( baseRef string , changes ChangedFilesProvider , forced , defaults bool ) ( bool , error ) { if ! ps . CouldRun ( baseRef ) { return false , nil } if ps . AlwaysRun { return true , nil } if forced { return true , nil } if determined , shouldRun , err := ps . RegexpChangeMatcher . ShouldRun ( changes ) ; err != nil { return false , err } else if determined { return shouldRun , nil } return defaults , nil } 
func ( ps Presubmit ) TriggerMatches ( body string ) bool { return ps . Trigger != " " && ps . re . MatchString ( body ) } 
func NewGitHubDeferredChangedFilesProvider ( client githubClient , org , repo string , num int ) ChangedFilesProvider { var changedFiles [ ] string return func ( ) ( [ ] string , error ) { if err != nil { return nil , fmt . Errorf ( " " , err ) } for _ , change := range changes { changedFiles = append ( changedFiles , change . Filename ) } } return changedFiles , nil } } 
func ( c * JobConfig ) GetPresubmit ( repo , jobName string ) * Presubmit { presubmits := c . AllPresubmits ( [ ] string { repo } ) for i := range presubmits { ps := presubmits [ i ] if ps . Name == jobName { return & ps } } return nil } 
func ( c * JobConfig ) SetPresubmits ( jobs map [ string ] [ ] Presubmit ) error { nj := map [ string ] [ ] Presubmit { } for k , v := range jobs { nj [ k ] = make ( [ ] Presubmit , len ( v ) ) copy ( nj [ k ] , v ) if err := SetPresubmitRegexes ( nj [ k ] ) ; err != nil { return err } } c . Presubmits = nj return nil } 
func ( c * JobConfig ) SetPostsubmits ( jobs map [ string ] [ ] Postsubmit ) error { nj := map [ string ] [ ] Postsubmit { } for k , v := range jobs { nj [ k ] = make ( [ ] Postsubmit , len ( v ) ) copy ( nj [ k ] , v ) if err := SetPostsubmitRegexes ( nj [ k ] ) ; err != nil { return err } } c . Postsubmits = nj return nil } 
func ( c * JobConfig ) AllPresubmits ( repos [ ] string ) [ ] Presubmit { var res [ ] Presubmit for repo , v := range c . Presubmits { if len ( repos ) == 0 { res = append ( res , v ... ) } else { for _ , r := range repos { if r == repo { res = append ( res , v ... ) break } } } } return res } 
func ( c * JobConfig ) AllPostsubmits ( repos [ ] string ) [ ] Postsubmit { var res [ ] Postsubmit for repo , v := range c . Postsubmits { if len ( repos ) == 0 { res = append ( res , v ... ) } else { for _ , r := range repos { if r == repo { res = append ( res , v ... ) break } } } } return res } 
func ( c * JobConfig ) AllPeriodics ( ) [ ] Periodic { var listPeriodic func ( ps [ ] Periodic ) [ ] Periodic listPeriodic = func ( ps [ ] Periodic ) [ ] Periodic { var res [ ] Periodic for _ , p := range ps { res = append ( res , p ) } return res } return listPeriodic ( c . Periodics ) } 
func ClearCompiledRegexes ( presubmits [ ] Presubmit ) { for i := range presubmits { presubmits [ i ] . re = nil presubmits [ i ] . Brancher . re = nil presubmits [ i ] . Brancher . reSkip = nil presubmits [ i ] . RegexpChangeMatcher . reChanges = nil } } 
func ( s * SimpleConfig ) Empty ( ) bool { return len ( s . Approvers ) == 0 && len ( s . Reviewers ) == 0 && len ( s . RequiredReviewers ) == 0 && len ( s . Labels ) == 0 } 
func NewClient ( gc * git . Client , ghc * github . Client , mdYAMLEnabled func ( org , repo string ) bool , skipCollaborators func ( org , repo string ) bool , ownersDirBlacklist func ( ) prowConf . OwnersDirBlacklist , ) * Client { return & Client { git : gc , ghc : ghc , logger : logrus . WithField ( " " , " " ) , cache : make ( map [ string ] cacheEntry ) , mdYAMLEnabled : mdYAMLEnabled , skipCollaborators : skipCollaborators , ownersDirBlacklist : ownersDirBlacklist , } } 
func ( c * Client ) LoadRepoAliases ( org , repo , base string ) ( RepoAliases , error ) { log := c . logger . WithFields ( logrus . Fields { " " : org , " " : repo , " " : base } ) cloneRef := fmt . Sprintf ( " " , org , repo ) fullName := fmt . Sprintf ( " " , cloneRef , base ) sha , err := c . ghc . GetRef ( org , repo , fmt . Sprintf ( " " , base ) ) if err != nil { return nil , fmt . Errorf ( " " , fullName , err ) } c . lock . Lock ( ) defer c . lock . Unlock ( ) entry , ok := c . cache [ fullName ] if ! ok || entry . sha != sha { if err != nil { return nil , fmt . Errorf ( " " , cloneRef , err ) } defer gitRepo . Clean ( ) if err := gitRepo . Checkout ( base ) ; err != nil { return nil , err } entry . aliases = loadAliasesFrom ( gitRepo . Dir , log ) entry . sha = sha c . cache [ fullName ] = entry } return entry . aliases , nil } 
func ( c * Client ) LoadRepoOwners ( org , repo , base string ) ( RepoOwner , error ) { log := c . logger . WithFields ( logrus . Fields { " " : org , " " : repo , " " : base } ) cloneRef := fmt . Sprintf ( " " , org , repo ) fullName := fmt . Sprintf ( " " , cloneRef , base ) mdYaml := c . mdYAMLEnabled ( org , repo ) sha , err := c . ghc . GetRef ( org , repo , fmt . Sprintf ( " " , base ) ) if err != nil { return nil , fmt . Errorf ( " " , fullName , err ) } c . lock . Lock ( ) defer c . lock . Unlock ( ) entry , ok := c . cache [ fullName ] if ! ok || entry . sha != sha || entry . owners == nil || ! entry . matchesMDYAML ( mdYaml ) { gitRepo , err := c . git . Clone ( cloneRef ) if err != nil { return nil , fmt . Errorf ( " " , cloneRef , err ) } defer gitRepo . Clean ( ) reusable := entry . fullyLoaded ( ) && entry . matchesMDYAML ( mdYaml ) if err != nil { return nil , fmt . Errorf ( " " , sha , entry . sha ) } for _ , change := range changes { if mdYaml && strings . HasSuffix ( change , " " ) || strings . HasSuffix ( change , aliasesFileName ) || strings . HasSuffix ( change , ownersFileName ) { reusable = false break } } } if reusable { entry . sha = sha } else { if err := gitRepo . Checkout ( base ) ; err != nil { return nil , err } if entry . aliases == nil || entry . sha != sha { } dirBlacklistPatterns := append ( c . ownersDirBlacklist ( ) . DirBlacklist ( org , repo ) , commonDirBlacklist ... ) var dirBlacklist [ ] * regexp . Regexp for _ , pattern := range dirBlacklistPatterns { re , err := regexp . Compile ( pattern ) if err != nil { log . WithError ( err ) . Errorf ( " " , pattern ) continue } dirBlacklist = append ( dirBlacklist , re ) } entry . owners , err = loadOwnersFrom ( gitRepo . Dir , mdYaml , entry . aliases , dirBlacklist , log ) if err != nil { return nil , fmt . Errorf ( " " , fullName , err ) } entry . sha = sha c . cache [ fullName ] = entry } } if c . skipCollaborators ( org , repo ) { log . Debugf ( " " , org , repo ) return entry . owners , nil } var owners * RepoOwners if err != nil { log . WithError ( err ) . Errorf ( " " ) owners = entry . owners } else { owners = entry . owners . filterCollaborators ( collaborators ) } return owners , nil } 
func ( a RepoAliases ) ExpandAlias ( alias string ) sets . String { if a == nil { return nil } return a [ github . NormLogin ( alias ) ] } 
func ( a RepoAliases ) ExpandAliases ( logins sets . String ) sets . String { if a == nil { return logins } for _ , login := range logins . List ( ) { if expanded := a . ExpandAlias ( login ) ; len ( expanded ) > 0 { logins . Delete ( login ) logins = logins . Union ( expanded ) } } return logins } 
func ParseFullConfig ( b [ ] byte ) ( FullConfig , error ) { full := new ( FullConfig ) err := yaml . Unmarshal ( b , full ) return * full , err } 
func ParseSimpleConfig ( b [ ] byte ) ( SimpleConfig , error ) { simple := new ( SimpleConfig ) err := yaml . Unmarshal ( b , simple ) return * simple , err } 
func decodeOwnersMdConfig ( path string , config * SimpleConfig ) error { fileBytes , err := ioutil . ReadFile ( path ) if err != nil { return err } } 
func findOwnersForFile ( log * logrus . Entry , path string , ownerMap map [ string ] map [ * regexp . Regexp ] sets . String ) string { d := path for ; d != baseDirConvention ; d = canonicalize ( filepath . Dir ( d ) ) { relative , err := filepath . Rel ( d , path ) if err != nil { log . WithError ( err ) . WithField ( " " , path ) . Errorf ( " " , d ) return " " } for re , n := range ownerMap [ d ] { if re != nil && ! re . MatchString ( relative ) { continue } if len ( n ) != 0 { return d } } } return " " } 
func ( o * RepoOwners ) FindApproverOwnersForFile ( path string ) string { return findOwnersForFile ( o . log , path , o . approvers ) } 
func ( o * RepoOwners ) FindReviewersOwnersForFile ( path string ) string { return findOwnersForFile ( o . log , path , o . reviewers ) } 
func ( o * RepoOwners ) FindLabelsForFile ( path string ) sets . String { return o . entriesForFile ( path , o . labels , false ) } 
func ( o * RepoOwners ) IsNoParentOwners ( path string ) bool { return o . options [ path ] . NoParentOwners } 
func ( o * RepoOwners ) entriesForFile ( path string , people map [ string ] map [ * regexp . Regexp ] sets . String , leafOnly bool ) sets . String { d := path if ! o . enableMDYAML || ! strings . HasSuffix ( path , " " ) { d = canonicalize ( path ) } out := sets . NewString ( ) for { relative , err := filepath . Rel ( d , path ) if err != nil { o . log . WithError ( err ) . WithField ( " " , path ) . Errorf ( " " , d ) return nil } for re , s := range people [ d ] { if re == nil || re . MatchString ( relative ) { out . Insert ( s . List ( ) ... ) } } if leafOnly && out . Len ( ) > 0 { break } if d == baseDirConvention { break } if o . options [ d ] . NoParentOwners { break } d = filepath . Dir ( d ) d = canonicalize ( d ) } return out } 
func ( o * RepoOwners ) LeafApprovers ( path string ) sets . String { return o . entriesForFile ( path , o . approvers , true ) } 
func ( o * RepoOwners ) Approvers ( path string ) sets . String { return o . entriesForFile ( path , o . approvers , false ) } 
func ( o * RepoOwners ) LeafReviewers ( path string ) sets . String { return o . entriesForFile ( path , o . reviewers , true ) } 
func ( o * RepoOwners ) Reviewers ( path string ) sets . String { return o . entriesForFile ( path , o . reviewers , false ) } 
func ( o * RepoOwners ) RequiredReviewers ( path string ) sets . String { return o . entriesForFile ( path , o . requiredReviewers , false ) } 
func ( c * Coverage ) Ratio ( ) float32 { if c . NumAllStmts == 0 { return 1 } return float32 ( c . NumCoveredStmts ) / float32 ( c . NumAllStmts ) } 
func ( pe * PeriodicProwJobEvent ) FromPayload ( data [ ] byte ) error { if err := json . Unmarshal ( data , pe ) ; err != nil { return err } return nil } 
func ( pe * PeriodicProwJobEvent ) ToMessage ( ) ( * pubsub . Message , error ) { data , err := json . Marshal ( pe ) if err != nil { return nil , err } message := pubsub . Message { Data : data , Attributes : map [ string ] string { prowEventType : periodicProwJobEvent , } , } return & message , nil } 
func ( p * Privacy ) UnmarshalText ( text [ ] byte ) error { v := Privacy ( text ) if _ , ok := privacySettings [ v ] ; ! ok { return fmt . Errorf ( " " , v ) } * p = v return nil } 
func compileApplicableBlockades ( org , repo string , log * logrus . Entry , blockades [ ] plugins . Blockade ) [ ] blockade { if len ( blockades ) == 0 { return nil } orgRepo := fmt . Sprintf ( " " , org , repo ) var compiled [ ] blockade for _ , raw := range blockades { } b := blockade { } for _ , str := range raw . BlockRegexps { if reg , err := regexp . Compile ( str ) ; err != nil { log . WithError ( err ) . Errorf ( " " , str ) } else { b . blockRegexps = append ( b . blockRegexps , reg ) } } if len ( b . blockRegexps ) == 0 { continue } if raw . Explanation == " " { b . explanation = " " } else { b . explanation = raw . Explanation } for _ , str := range raw . ExceptionRegexps { if reg , err := regexp . Compile ( str ) ; err != nil { log . WithError ( err ) . Errorf ( " " , str ) } else { b . exceptionRegexps = append ( b . exceptionRegexps , reg ) } } compiled = append ( compiled , b ) } return compiled } 
func calculateBlocks ( changes [ ] github . PullRequestChange , blockades [ ] blockade ) summary { sum := make ( summary ) for _ , change := range changes { for _ , b := range blockades { if b . isBlocked ( change . Filename ) { sum [ b . explanation ] = append ( sum [ b . explanation ] , change ) } } } return sum } 
func MergeProfiles ( a [ ] * cover . Profile , b [ ] * cover . Profile ) ( [ ] * cover . Profile , error ) { var result [ ] * cover . Profile files := make ( map [ string ] * cover . Profile , len ( a ) ) for _ , profile := range a { np := deepCopyProfile ( * profile ) result = append ( result , & np ) files [ np . FileName ] = & np } needsSort := false if ok { if err := ensureProfilesMatch ( profile , dest ) ; err != nil { return nil , fmt . Errorf ( " " , profile . FileName , err ) } for i , block := range profile . Blocks { db := & dest . Blocks [ i ] db . Count += block . Count } } else { files [ np . FileName ] = & np result = append ( result , & np ) needsSort = true } } if needsSort { sort . Slice ( result , func ( i , j int ) bool { return result [ i ] . FileName < result [ j ] . FileName } ) } return result , nil } 
func MergeMultipleProfiles ( profiles [ ] [ ] * cover . Profile ) ( [ ] * cover . Profile , error ) { if len ( profiles ) < 1 { return nil , errors . New ( " " ) } result := profiles [ 0 ] for _ , profile := range profiles [ 1 : ] { var err error if result , err = MergeProfiles ( result , profile ) ; err != nil { return nil , err } } return result , nil } 
func ( a * AuthorLoggerPluginWrapper ) AddFlags ( cmd * cobra . Command ) { cmd . Flags ( ) . BoolVar ( & a . enabled , " " , false , " " ) } 
func ( a * AuthorLoggerPluginWrapper ) ReceiveIssue ( issue sql . Issue ) [ ] Point { points := a . plugin . ReceiveIssue ( issue ) if a . enabled { for i := range points { if points [ i ] . Values == nil { points [ i ] . Values = map [ string ] interface { } { } } points [ i ] . Values [ " " ] = issue . User } } return points } 
func ( a * AuthorLoggerPluginWrapper ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { points := a . plugin . ReceiveIssueEvent ( event ) if a . enabled { for i := range points { if points [ i ] . Values == nil { points [ i ] . Values = map [ string ] interface { } { } } if event . Actor != nil { points [ i ] . Values [ " " ] = * event . Actor } } } return points } 
func ( a * AuthorLoggerPluginWrapper ) ReceiveComment ( comment sql . Comment ) [ ] Point { points := a . plugin . ReceiveComment ( comment ) if a . enabled { for i := range points { if points [ i ] . Values == nil { points [ i ] . Values = map [ string ] interface { } { } } points [ i ] . Values [ " " ] = comment . User } } return points } 
func ( o * Options ) AddFlags ( fs * flag . FlagSet ) { fs . StringVar ( & o . ProcessLog , " " , " " , " " ) fs . StringVar ( & o . MarkerFile , " " , " " , " " ) fs . StringVar ( & o . MetadataFile , " " , " " , " " ) } 
func ( o * Options ) Validate ( ) error { if o . ProcessLog == " " { return errors . New ( " " ) } if o . MarkerFile == " " { return errors . New ( " " ) } return nil } 
func ( c * Controller ) processNextItem ( ) bool { key , quit := c . queue . Get ( ) if quit { return false } defer c . queue . Done ( key ) workItem := key . ( item ) prowJob , err := c . prowJobClient . GetProwJob ( workItem . prowJobId ) if err != nil { c . handleErr ( err , workItem ) return true } spec := downwardapi . NewJobSpec ( prowJob . Spec , prowJob . Status . BuildID , prowJob . Name ) result := c . client . Pods ( workItem . namespace ) . GetLogs ( workItem . podName , & api . PodLogOptions { Container : workItem . containerName } ) . Do ( ) if err := result . Error ( ) ; err != nil { c . handleErr ( err , workItem ) return true } var target string if workItem . podName == workItem . prowJobId { target = path . Join ( ContainerLogDir , fmt . Sprintf ( " " , workItem . containerName ) ) } else { target = path . Join ( ContainerLogDir , workItem . podName , fmt . Sprintf ( " " , workItem . containerName ) ) } data := gcs . DataUpload ( bytes . NewReader ( log ) ) if err := c . gcsConfig . Run ( & spec , map [ string ] gcs . UploadFunc { target : data } ) ; err != nil { c . handleErr ( err , workItem ) return true } c . queue . Forget ( key ) return true } 
func ( c * Controller ) handleErr ( err error , key item ) { if c . queue . NumRequeues ( key ) < 5 { glog . Infof ( " " , key . containerName , key . podName , err ) c . queue . AddRateLimited ( key ) return } c . queue . Forget ( key ) glog . Infof ( " " , key . containerName , key . podName , err ) } 
func CommandFilter ( body string ) Filter { return func ( p config . Presubmit ) ( bool , bool , bool ) { return p . TriggerMatches ( body ) , p . TriggerMatches ( body ) , true } } 
func AggregateFilter ( filters [ ] Filter ) Filter { return func ( presubmit config . Presubmit ) ( bool , bool , bool ) { for _ , filter := range filters { if shouldRun , forced , defaults := filter ( presubmit ) ; shouldRun { return shouldRun , forced , defaults } } return false , false , false } } 
func FilterPresubmits ( filter Filter , changes config . ChangedFilesProvider , branch string , presubmits [ ] config . Presubmit , logger * logrus . Entry ) ( [ ] config . Presubmit , [ ] config . Presubmit , error ) { var toTrigger [ ] config . Presubmit var toSkip [ ] config . Presubmit for _ , presubmit := range presubmits { matches , forced , defaults := filter ( presubmit ) if ! matches { continue } shouldRun , err := presubmit . ShouldRun ( branch , changes , forced , defaults ) if err != nil { return nil , nil , err } if shouldRun { toTrigger = append ( toTrigger , presubmit ) } else { toSkip = append ( toSkip , presubmit ) } } logger . WithFields ( logrus . Fields { " " : toTrigger , " " : toSkip } ) . Debugf ( " " , len ( presubmits ) , len ( toTrigger ) , len ( toSkip ) ) return toTrigger , toSkip , nil } 
func MakeCommand ( ) * cobra . Command { flags := & flags { } cmd := & cobra . Command { Use : " " , Short : " " , Long : `Filters a Go coverage file, removing entries that do not match the given flags.` , Run : func ( cmd * cobra . Command , args [ ] string ) { run ( flags , cmd , args ) } , } cmd . Flags ( ) . StringVarP ( & flags . OutputFile , " " , " " , " " , " " ) cmd . Flags ( ) . StringSliceVar ( & flags . IncludePaths , " " , nil , " " ) cmd . Flags ( ) . StringSliceVar ( & flags . ExcludePaths , " " , nil , " " ) return cmd } 
func ( t * EventTimeHeap ) Push ( x interface { } ) { * t = append ( * t , x . ( sql . IssueEvent ) ) } 
func ( t * EventTimeHeap ) Pop ( ) interface { } { old := * t n := len ( old ) x := old [ n - 1 ] * t = old [ 0 : n - 1 ] return x } 
func NewFakeOpenPluginWrapper ( plugin Plugin ) * FakeOpenPluginWrapper { return & FakeOpenPluginWrapper { plugin : plugin , alreadyOpen : map [ string ] bool { } , } } 
func ( o * FakeOpenPluginWrapper ) ReceiveIssue ( issue sql . Issue ) [ ] Point { if _ , ok := o . alreadyOpen [ issue . ID ] ; ! ok { o . alreadyOpen [ issue . ID ] = true } return o . plugin . ReceiveIssue ( issue ) } 
func ( o * FakeOpenPluginWrapper ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { points := [ ] Point { } } return append ( points , o . plugin . ReceiveIssueEvent ( event ) ... ) } 
func ( o * FakeOpenPluginWrapper ) ReceiveComment ( comment sql . Comment ) [ ] Point { return o . plugin . ReceiveComment ( comment ) } 
func ( o * Options ) Validate ( ) error { if o . SrcRoot == " " { return errors . New ( " " ) } if o . Log == " " { return errors . New ( " " ) } if len ( o . GitRefs ) == 0 { return errors . New ( " " ) } seen := map [ string ] sets . String { } for _ , ref := range o . GitRefs { if _ , seenOrg := seen [ ref . Org ] ; seenOrg { if seen [ ref . Org ] . Has ( ref . Repo ) { return errors . New ( " " ) } seen [ ref . Org ] . Insert ( ref . Repo ) } else { seen [ ref . Org ] = sets . NewString ( ref . Repo ) } } return nil } 
func ( o * Options ) Complete ( args [ ] string ) { o . GitRefs = o . refs . gitRefs o . KeyFiles = o . keys . data for _ , ref := range o . GitRefs { alias , err := o . clonePath . Execute ( OrgRepo { Org : ref . Org , Repo : ref . Repo } ) if err != nil { panic ( err ) } ref . PathAlias = alias alias , err = o . cloneURI . Execute ( OrgRepo { Org : ref . Org , Repo : ref . Repo } ) if err != nil { panic ( err ) } ref . CloneURI = alias } } 
func ( o * Options ) AddFlags ( fs * flag . FlagSet ) { fs . StringVar ( & o . SrcRoot , " " , " " , " " ) fs . StringVar ( & o . Log , " " , " " , " " ) fs . StringVar ( & o . GitUserName , " " , DefaultGitUserName , " " ) fs . StringVar ( & o . GitUserEmail , " " , DefaultGitUserEmail , " " ) fs . Var ( & o . refs , " " , " " ) fs . Var ( & o . keys , " " , " " ) fs . Var ( & o . clonePath , " " , " " ) fs . Var ( & o . cloneURI , " " , " " ) fs . IntVar ( & o . MaxParallelWorkers , " " , 0 , " " ) fs . StringVar ( & o . CookiePath , " " , " " , " " ) } 
func ( r * gitRefs ) Set ( value string ) error { gitRef , err := ParseRefs ( value ) if err != nil { return err } r . gitRefs = append ( r . gitRefs , * gitRef ) return nil } 
func ( r * stringSlice ) Set ( value string ) error { r . data = append ( r . data , value ) return nil } 
func ( a * orgRepoFormat ) Set ( value string ) error { templ , err := template . New ( " " ) . Parse ( value ) if err != nil { return err } a . raw = value a . format = templ return nil } 
func ensure ( binary , install string ) error { if _ , err := exec . LookPath ( binary ) ; err != nil { return fmt . Errorf ( " " , binary , install ) } return nil } 
func output ( args ... string ) ( string , error ) { cmd := exec . Command ( args [ 0 ] , args [ 1 : ] ... ) cmd . Stderr = os . Stderr cmd . Stdin = os . Stdin b , err := cmd . Output ( ) return strings . TrimSpace ( string ( b ) ) , err } 
func projects ( max int ) ( [ ] string , error ) { out , err := output ( " " , " " , " " , fmt . Sprintf ( " " , max ) , " " ) if err != nil { return nil , err } return strings . Split ( out , " \n " ) , nil } 
func selectProject ( choice string ) ( string , error ) { fmt . Print ( " " ) who , err := currentAccount ( ) if err != nil { logrus . Warn ( " " ) return " " , err } fmt . Println ( who ) var projs [ ] string if choice == " " { fmt . Printf ( " " , who ) fmt . Println ( ) const max = 20 projs , err = projects ( max ) for _ , proj := range projs { fmt . Println ( " " , proj ) } if err != nil { return " " , fmt . Errorf ( " " , err ) } if len ( projs ) == 0 { fmt . Println ( " " ) return " " , errors . New ( " " ) } if len ( projs ) == max { fmt . Println ( " " ) fmt . Println ( " " ) } def , err := currentProject ( ) if err != nil { return " " , fmt . Errorf ( " " , err ) } fmt . Printf ( " " , def ) fmt . Scanln ( & choice ) } } } } fmt . Printf ( " " , who , choice ) fmt . Println ( ) } return choice , nil } 
func currentClusters ( proj string ) ( map [ string ] cluster , error ) { clusters , err := output ( " " , " " , " " , " " , " " + proj , " " ) if err != nil { return nil , fmt . Errorf ( " " , err ) } options := map [ string ] cluster { } for _ , line := range strings . Split ( clusters , " \n " ) { if len ( line ) == 0 { continue } parts := strings . Split ( line , " \t " ) if len ( parts ) != 2 { return nil , fmt . Errorf ( " " , line ) } c := cluster { name : parts [ 0 ] , zone : parts [ 1 ] , project : proj } options [ c . name ] = c } return options , nil } 
func createCluster ( proj , choice string ) ( * cluster , error ) { const def = " " if choice == " " { fmt . Printf ( " " , def ) fmt . Scanln ( & choice ) if choice == " " { choice = def } } cmd := exec . Command ( " " , " " , " " , " " , choice ) cmd . Stdin = os . Stdin cmd . Stdout = os . Stdout cmd . Stderr = os . Stderr if err := cmd . Run ( ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } out , err := output ( " " , " " , " " , " " , choice , " " ) if err != nil { return nil , fmt . Errorf ( " " , err ) } parts := strings . Split ( out , " \t " ) if len ( parts ) != 2 { return nil , fmt . Errorf ( " " , out ) } return & cluster { name : parts [ 0 ] , zone : parts [ 1 ] , project : proj } , nil } 
func createContext ( co contextOptions ) ( string , error ) { proj , err := selectProject ( co . project ) if err != nil { logrus . Info ( " " ) return " " , fmt . Errorf ( " " , err ) } fmt . Printf ( " " , proj ) fmt . Println ( ) clusters , err := currentClusters ( proj ) if err != nil { return " " , fmt . Errorf ( " " , proj , err ) } for name := range clusters { fmt . Println ( " " , name ) } if len ( clusters ) == 0 { fmt . Println ( " " ) } var choice string create := co . create reuse := co . reuse switch { case create != " " && reuse != " " : return " " , errors . New ( " " ) case create != " " : fmt . Println ( " " + create + " " ) choice = " " case reuse != " " : fmt . Println ( " " + reuse + " " ) choice = reuse default : fmt . Print ( " " ) fmt . Scanln ( & choice ) } if choice == " " || choice == " " { cluster , err := createCluster ( proj , create ) if err != nil { return " " , fmt . Errorf ( " " , proj , err ) } return cluster . context ( ) , nil } cluster , ok := clusters [ choice ] if ! ok { return " " , fmt . Errorf ( " " , choice ) } cmd := exec . Command ( " " , " " , " " , " " , cluster . name , " " + cluster . project , " " + cluster . zone ) cmd . Stdin = os . Stdin cmd . Stdout = os . Stdout cmd . Stderr = os . Stderr if err := cmd . Run ( ) ; err != nil { return " " , fmt . Errorf ( " " , err ) } return cluster . context ( ) , nil } 
func contextConfig ( ) ( clientcmd . ClientConfigLoader , * clientcmdapi . Config , error ) { if err := ensureKubectl ( ) ; err != nil { fmt . Println ( " " ) fmt . Println ( " " , err ) if gerr := ensureGcloud ( ) ; gerr != nil { fmt . Println ( " " , gerr ) } return nil , nil , errors . New ( " " ) } l := clientcmd . NewDefaultClientConfigLoadingRules ( ) c , err := l . Load ( ) return l , c , err } 
func selectContext ( co contextOptions ) ( string , error ) { fmt . Println ( " " ) if err != nil { logrus . WithError ( err ) . Fatal ( " " ) } var ctxs [ ] string for ctx := range cfg . Contexts { ctxs = append ( ctxs , ctx ) } sort . Strings ( ctxs ) for idx , ctx := range ctxs { options [ idx ] = ctx if ctx == cfg . CurrentContext { fmt . Printf ( " " , idx , ctx ) } else { fmt . Printf ( " " , idx , ctx ) } fmt . Println ( ) } fmt . Println ( ) choice := co . context switch { case choice != " " : fmt . Println ( " " + choice + " " ) case co . create != " " || co . reuse != " " : choice = " " fmt . Println ( " " ) default : fmt . Print ( " " ) fmt . Scanln ( & choice ) } if choice == " " || choice == " " || choice == " " || choice == " " { ctx , err := createContext ( co ) if err != nil { return " " , fmt . Errorf ( " " , err ) } return ctx , nil } if _ , ok := cfg . Contexts [ choice ] ; ok { return choice , nil } idx , err := strconv . Atoi ( choice ) if err != nil { return " " , fmt . Errorf ( " " , choice ) } if ctx , ok := options [ idx ] ; ok { return ctx , nil } return " " , fmt . Errorf ( " " , idx ) } 
func applyCreate ( ctx string , args ... string ) error { create := exec . Command ( " " , append ( [ ] string { " " , " " , " " } , args ... ) ... ) create . Stderr = os . Stderr obj , err := create . StdoutPipe ( ) if err != nil { return fmt . Errorf ( " " , err ) } if err := create . Start ( ) ; err != nil { return fmt . Errorf ( " " , err ) } if err := apply ( ctx , obj ) ; err != nil { return fmt . Errorf ( " " , err ) } if err := create . Wait ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func FilterPresubmits ( honorOkToTest bool , gitHubClient GitHubClient , body string , pr * github . PullRequest , presubmits [ ] config . Presubmit , logger * logrus . Entry ) ( [ ] config . Presubmit , [ ] config . Presubmit , error ) { org , repo , sha := pr . Base . Repo . Owner . Login , pr . Base . Repo . Name , pr . Head . SHA filter , err := presubmitFilter ( honorOkToTest , gitHubClient , body , org , repo , sha , logger ) if err != nil { return nil , nil , err } number , branch := pr . Number , pr . Base . Ref changes := config . NewGitHubDeferredChangedFilesProvider ( gitHubClient , org , repo , number ) toTrigger , toSkipSuperset , err := pjutil . FilterPresubmits ( filter , changes , branch , presubmits , logger ) if err != nil { return nil , nil , err } toSkip := determineSkippedPresubmits ( toTrigger , toSkipSuperset , logger ) return toTrigger , toSkip , err } 
func determineSkippedPresubmits ( toTrigger , toSkipSuperset [ ] config . Presubmit , logger * logrus . Entry ) [ ] config . Presubmit { triggeredContexts := sets . NewString ( ) for _ , presubmit := range toTrigger { triggeredContexts . Insert ( presubmit . Context ) } var toSkip [ ] config . Presubmit for _ , presubmit := range toSkipSuperset { if triggeredContexts . Has ( presubmit . Context ) { logger . WithFields ( logrus . Fields { " " : presubmit . Context , " " : presubmit . Name } ) . Debug ( " " ) continue } toSkip = append ( toSkip , presubmit ) } return toSkip } 
func DiffProfiles ( before [ ] * cover . Profile , after [ ] * cover . Profile ) ( [ ] * cover . Profile , error ) { var diff [ ] * cover . Profile if len ( before ) != len ( after ) { return nil , fmt . Errorf ( " " , len ( before ) , len ( after ) ) } for i , beforeProfile := range before { afterProfile := after [ i ] if err := ensureProfilesMatch ( beforeProfile , afterProfile ) ; err != nil { return nil , fmt . Errorf ( " " , i , err ) } diffProfile := cover . Profile { FileName : beforeProfile . FileName , Mode : beforeProfile . Mode } for j , beforeBlock := range beforeProfile . Blocks { afterBlock := afterProfile . Blocks [ j ] diffBlock := cover . ProfileBlock { StartLine : beforeBlock . StartLine , StartCol : beforeBlock . StartCol , EndLine : beforeBlock . EndLine , EndCol : beforeBlock . EndCol , NumStmt : beforeBlock . NumStmt , Count : afterBlock . Count - beforeBlock . Count , } diffProfile . Blocks = append ( diffProfile . Blocks , diffBlock ) } diff = append ( diff , & diffProfile ) } return diff , nil } 
func Dispatch ( plugin plugins . Plugin , DB * InfluxDB , issues chan sql . Issue , eventsCommentsChannel chan interface { } ) { for { var points [ ] plugins . Point select { case issue , ok := <- issues : if ! ok { return } points = plugin . ReceiveIssue ( issue ) case event , ok := <- eventsCommentsChannel : if ! ok { return } switch event := event . ( type ) { case sql . IssueEvent : points = plugin . ReceiveIssueEvent ( event ) case sql . Comment : points = plugin . ReceiveComment ( event ) default : glog . Fatal ( " " , event ) } } for _ , point := range points { if err := DB . Push ( point . Tags , point . Values , point . Date ) ; err != nil { glog . Fatal ( " " , err ) } } } } 
func ( config * transformConfig ) run ( plugin plugins . Plugin ) error { if err := config . CheckRootFlags ( ) ; err != nil { return err } mysqldb , err := config . MySQLConfig . CreateDatabase ( ) if err != nil { return err } influxdb , err := config . InfluxConfig . CreateDatabase ( map [ string ] string { " " : config . repository } , config . metricName ) if err != nil { return err } fetcher := NewFetcher ( config . repository ) ticker := time . Tick ( time . Hour / time . Duration ( config . frequency ) ) for { } if err := influxdb . PushBatchPoints ( ) ; err != nil { return err } if config . once { break } <- ticker } return nil } 
func ( a * AuthorFilterPluginWrapper ) AddFlags ( cmd * cobra . Command ) { cmd . Flags ( ) . StringSliceVar ( & a . ignoredAuthors , " " , [ ] string { } , " " ) } 
func ( a * AuthorFilterPluginWrapper ) ReceiveIssue ( issue sql . Issue ) [ ] Point { if a . match ( issue . User ) { return nil } return a . plugin . ReceiveIssue ( issue ) } 
func ( a * AuthorFilterPluginWrapper ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { if event . Actor != nil && a . match ( * event . Actor ) { return nil } return a . plugin . ReceiveIssueEvent ( event ) } 
func ( a * AuthorFilterPluginWrapper ) ReceiveComment ( comment sql . Comment ) [ ] Point { if a . match ( comment . User ) { return nil } return a . plugin . ReceiveComment ( comment ) } 
func ( c * Client ) CreateIssue ( org , repo , title , body string , labels , assignees [ ] string ) ( * github . Issue , error ) { glog . Infof ( " \n " , c . dryRun , title , labels , assignees ) if c . dryRun { return nil , nil } issue := & github . IssueRequest { Title : & title , Body : & body , } if len ( labels ) > 0 { issue . Labels = & labels } if len ( assignees ) > 0 { issue . Assignees = & assignees } var result * github . Issue _ , err := c . retry ( fmt . Sprintf ( " " , title ) , func ( ) ( * github . Response , error ) { var resp * github . Response var err error result , resp , err = c . issueService . Create ( context . Background ( ) , org , repo , issue ) return resp , err } , ) return result , err } 
func ( c * Client ) CreateStatus ( owner , repo , ref string , status * github . RepoStatus ) ( * github . RepoStatus , error ) { glog . Infof ( " " , c . dryRun , ref , * status . Context , * status . State ) if c . dryRun { return nil , nil } var result * github . RepoStatus msg := fmt . Sprintf ( " " , ref ) _ , err := c . retry ( msg , func ( ) ( * github . Response , error ) { var resp * github . Response var err error result , resp , err = c . repoService . CreateStatus ( context . Background ( ) , owner , repo , ref , status ) return resp , err } ) return result , err } 
func ( c * Client ) ForEachPR ( owner , repo string , opts * github . PullRequestListOptions , continueOnError bool , mungePR PRMungeFunc ) error { var lastPage int if err == nil { for _ , pr := range list { if pr == nil { glog . Errorln ( " " ) } if mungeErr := mungePR ( pr ) ; mungeErr != nil { if pr . Number == nil { mungeErr = fmt . Errorf ( " " , mungeErr ) } else { mungeErr = fmt . Errorf ( " " , * pr . Number , mungeErr ) } if ! continueOnError { return nil , resp , & retryAbort { mungeErr } } glog . Errorf ( " \n " , mungeErr ) } } if resp . LastPage > 0 { lastPage = resp . LastPage } glog . Infof ( " \n " , opts . ListOptions . Page , lastPage ) } return nil , resp , err } , ) return err } 
func ( c * Client ) GetCollaborators ( org , repo string ) ( [ ] * github . User , error ) { opts := & github . ListCollaboratorsOptions { } collaborators , err := c . depaginate ( fmt . Sprintf ( " " , org , repo ) , & opts . ListOptions , func ( ) ( [ ] interface { } , * github . Response , error ) { page , resp , err := c . repoService . ListCollaborators ( context . Background ( ) , org , repo , opts ) var interfaceList [ ] interface { } if err == nil { interfaceList = make ( [ ] interface { } , 0 , len ( page ) ) for _ , user := range page { interfaceList = append ( interfaceList , user ) } } return interfaceList , resp , err } , ) result := make ( [ ] * github . User , 0 , len ( collaborators ) ) for _ , user := range collaborators { result = append ( result , user . ( * github . User ) ) } return result , err } 
func ( c * Client ) GetCombinedStatus ( owner , repo , ref string ) ( * github . CombinedStatus , error ) { var result * github . CombinedStatus listOpts := & github . ListOptions { } statuses , err := c . depaginate ( fmt . Sprintf ( " " , ref ) , listOpts , func ( ) ( [ ] interface { } , * github . Response , error ) { combined , resp , err := c . repoService . GetCombinedStatus ( context . Background ( ) , owner , repo , ref , listOpts , ) if result == nil { result = combined } var interfaceList [ ] interface { } if err == nil { interfaceList = make ( [ ] interface { } , 0 , len ( combined . Statuses ) ) for _ , status := range combined . Statuses { interfaceList = append ( interfaceList , status ) } } return interfaceList , resp , err } , ) if result != nil { result . Statuses = make ( [ ] github . RepoStatus , 0 , len ( statuses ) ) for _ , status := range statuses { result . Statuses = append ( result . Statuses , status . ( github . RepoStatus ) ) } } return result , err } 
func ( c * Client ) GetIssues ( org , repo string , opts * github . IssueListByRepoOptions ) ( [ ] * github . Issue , error ) { issues , err := c . depaginate ( fmt . Sprintf ( " " , org , repo ) , & opts . ListOptions , func ( ) ( [ ] interface { } , * github . Response , error ) { page , resp , err := c . issueService . ListByRepo ( context . Background ( ) , org , repo , opts ) var interfaceList [ ] interface { } if err == nil { interfaceList = make ( [ ] interface { } , 0 , len ( page ) ) for _ , issue := range page { interfaceList = append ( interfaceList , issue ) } } return interfaceList , resp , err } , ) result := make ( [ ] * github . Issue , 0 , len ( issues ) ) for _ , issue := range issues { result = append ( result , issue . ( * github . Issue ) ) } return result , err } 
func ( c * Client ) GetRepoLabels ( org , repo string ) ( [ ] * github . Label , error ) { opts := & github . ListOptions { } labels , err := c . depaginate ( fmt . Sprintf ( " " , org , repo ) , opts , func ( ) ( [ ] interface { } , * github . Response , error ) { page , resp , err := c . issueService . ListLabels ( context . Background ( ) , org , repo , opts ) var interfaceList [ ] interface { } if err == nil { interfaceList = make ( [ ] interface { } , 0 , len ( page ) ) for _ , label := range page { interfaceList = append ( interfaceList , label ) } } return interfaceList , resp , err } , ) result := make ( [ ] * github . Label , 0 , len ( labels ) ) for _ , label := range labels { result = append ( result , label . ( * github . Label ) ) } return result , err } 
func ( c * Client ) GetUser ( login string ) ( * github . User , error ) { var result * github . User _ , err := c . retry ( fmt . Sprintf ( " " , login ) , func ( ) ( * github . Response , error ) { var resp * github . Response var err error result , resp , err = c . userService . Get ( context . Background ( ) , login ) return resp , err } , ) return result , err } 
func checkConfigValidity ( ) error { glog . Info ( " " ) if * nodeName == " " { return fmt . Errorf ( " " ) } if * gcsPath == " " { return fmt . Errorf ( " " ) } if _ , err := os . Stat ( * gcloudAuthFilePath ) ; err != nil { return fmt . Errorf ( " " , err ) } else { glog . Infof ( " \n " , * gcloudAuthFilePath ) cmd := exec . Command ( " " , " " , " " , " " + * gcloudAuthFilePath ) var stderr , stdout bytes . Buffer cmd . Stderr , cmd . Stdout = & stderr , & stdout err = cmd . Run ( ) glog . Infof ( " \n \n " , stdout . String ( ) ) glog . Infof ( " \n \n " , stderr . String ( ) ) if err != nil { return fmt . Errorf ( " " , err ) } } return nil } 
func createSystemdLogfile ( service string , outputMode string , outputDir string ) error { if service == " " { journalCmdArgs = append ( journalCmdArgs , " " ) } else { journalCmdArgs = append ( journalCmdArgs , " " , fmt . Sprintf ( " " , service ) ) } cmd := exec . Command ( " " , journalCmdArgs ... ) if err != nil { return fmt . Errorf ( " " , service , err ) } logfile := filepath . Join ( outputDir , service + " " ) if err := ioutil . WriteFile ( logfile , output , 0444 ) ; err != nil { return fmt . Errorf ( " " , service , err ) } return nil } 
func createFullSystemdLogfile ( outputDir string ) error { cmd := exec . Command ( " " , " " , " " , * journalPath ) if err != nil { return fmt . Errorf ( " " , err ) } logfile := filepath . Join ( outputDir , " " ) if err := ioutil . WriteFile ( logfile , output , 0444 ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func createSystemdLogfiles ( outputDir string ) { services := append ( systemdServices , nodeSystemdServices ... ) for _ , service := range services { if err := createSystemdLogfile ( service , " " , outputDir ) ; err != nil { glog . Warningf ( " " , err ) } } } } if * dumpSystemdJournal { if err := createFullSystemdLogfile ( outputDir ) ; err != nil { glog . Warningf ( " " , err ) } } } 
func prepareLogfiles ( logDir string ) { glog . Info ( " " ) logfiles := nodeLogs [ : ] switch * cloudProvider { case " " , " " : logfiles = append ( logfiles , gceLogs ... ) case " " : logfiles = append ( logfiles , awsLogs ... ) default : glog . Errorf ( " " , * cloudProvider ) } } createSystemdLogfiles ( logDir ) } else { glog . Infof ( " " , err ) logfiles = append ( logfiles , kernelLog ) logfiles = append ( logfiles , initdLogs ... ) logfiles = append ( logfiles , supervisordLogs ... ) } cmd := exec . Command ( " " , " " , fmt . Sprintf ( " " , logfileFullPath , logDir ) ) if err := cmd . Run ( ) ; err != nil { glog . Warningf ( " " , logfileFullPath , err ) } } } 
func writeSuccessMarkerFile ( ) error { markerFilePath := * gcsPath + " " + * nodeName + " " cmd := exec . Command ( " " , " " , " " , " " , " " , " " , markerFilePath ) stdin , err := cmd . StdinPipe ( ) if err != nil { return fmt . Errorf ( " " , err ) } io . WriteString ( stdin , " " ) stdin . Close ( ) if err = cmd . Run ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func MakeCommand ( ) * cobra . Command { flags := & flags { } cmd := & cobra . Command { Use : " " , Short : " " , Long : `Summarize coverage profile and produce the result in junit xml format. Summary done at per-file and per-package level. Any coverage below coverage-threshold will be marked with a <failure> tag in the xml produced.` , Run : func ( cmd * cobra . Command , args [ ] string ) { run ( flags , cmd , args ) } , } cmd . Flags ( ) . StringVarP ( & flags . outputFile , " " , " " , " " , " " ) cmd . Flags ( ) . Float32VarP ( & flags . threshold , " " , " " , .8 , " " ) return cmd } 
func ( c * Configuration ) MDYAMLEnabled ( org , repo string ) bool { full := fmt . Sprintf ( " " , org , repo ) for _ , elem := range c . Owners . MDYAMLRepos { if elem == org || elem == full { return true } } return false } 
func ( r RequireMatchingLabel ) validate ( ) error { if r . Org == " " { return errors . New ( " " ) } if strings . Contains ( r . Repo , " " ) { return errors . New ( " " ) } if r . Regexp == " " { return errors . New ( " " ) } if r . MissingLabel == " " { return errors . New ( " " ) } if r . GracePeriod == " " { return errors . New ( " " ) } if ! r . PRs && ! r . Issues { return errors . New ( " " ) } if ! r . PRs && r . Branch != " " { return errors . New ( " " ) } if r . Re . MatchString ( r . MissingLabel ) { return errors . New ( " " ) } return nil } 
func warnDeprecated ( last * time . Time , freq time . Duration , msg string ) { fresh := time . Now ( ) . Sub ( * last ) <= freq warnLock . RUnlock ( ) if fresh { } defer warnLock . Unlock ( ) now := time . Now ( ) if now . Sub ( * last ) <= freq { } * last = now logrus . Warn ( msg ) } 
func ( r RequireMatchingLabel ) Describe ( ) string { str := & strings . Builder { } fmt . Fprintf ( str , " " , r . MissingLabel ) if r . MissingComment == " " { fmt . Fprint ( str , " " ) } else { fmt . Fprint ( str , " " ) } if r . Issues { fmt . Fprint ( str , " " ) if r . PRs { fmt . Fprint ( str , " " ) } } if r . PRs { if r . Branch != " " { fmt . Fprintf ( str , " " , r . Branch ) } fmt . Fprint ( str , " " ) } if r . Repo == " " { fmt . Fprintf ( str , " " , r . Org ) } else { fmt . Fprintf ( str , " " , r . Org , r . Repo ) } fmt . Fprintf ( str , " " , r . Regexp ) return str . String ( ) } 
func ( c * Configuration ) TriggerFor ( org , repo string ) Trigger { for _ , tr := range c . Triggers { for _ , r := range tr . Repos { if r == org || r == fmt . Sprintf ( " " , org , repo ) { return tr } } } return Trigger { } } 
func ( c * Configuration ) EnabledReposForPlugin ( plugin string ) ( orgs , repos [ ] string ) { for repo , plugins := range c . Plugins { found := false for _ , candidate := range plugins { if candidate == plugin { found = true break } } if found { if strings . Contains ( repo , " " ) { repos = append ( repos , repo ) } else { orgs = append ( orgs , repo ) } } } return } 
func ( c * Configuration ) EnabledReposForExternalPlugin ( plugin string ) ( orgs , repos [ ] string ) { for repo , plugins := range c . ExternalPlugins { found := false for _ , candidate := range plugins { if candidate . Name == plugin { found = true break } } if found { if strings . Contains ( repo , " " ) { repos = append ( repos , repo ) } else { orgs = append ( orgs , repo ) } } } return } 
func ( c * ConfigUpdater ) SetDefaults ( ) { if len ( c . Maps ) == 0 { cf := c . ConfigFile if cf == " " { cf = " " } else { logrus . Warnf ( `config_file is deprecated, please switch to "maps": {"%s": "config"} before July 2018` , cf ) } pf := c . PluginFile if pf == " " { pf = " " } else { logrus . Warnf ( `plugin_file is deprecated, please switch to "maps": {"%s": "plugins"} before July 2018` , pf ) } c . Maps = map [ string ] ConfigMapSpec { cf : { Name : " " , } , pf : { Name : " " , } , } } for name , spec := range c . Maps { spec . Namespaces = append ( [ ] string { spec . Namespace } , spec . AdditionalNamespaces ... ) c . Maps [ name ] = spec } } 
func validatePlugins ( plugins map [ string ] [ ] string ) error { var errors [ ] string for _ , configuration := range plugins { for _ , plugin := range configuration { if _ , ok := pluginHelp [ plugin ] ; ! ok { errors = append ( errors , fmt . Sprintf ( " " , plugin ) ) } } } for repo , repoConfig := range plugins { if strings . Contains ( repo , " " ) { org := strings . Split ( repo , " " ) [ 0 ] if dupes := findDuplicatedPluginConfig ( repoConfig , plugins [ org ] ) ; len ( dupes ) > 0 { errors = append ( errors , fmt . Sprintf ( " " , dupes , repo , org ) ) } } } if len ( errors ) > 0 { return fmt . Errorf ( " \n \t " , strings . Join ( errors , " \n \t " ) ) } return nil } 
func NewReporter ( cookiefilePath string , projects map [ string ] [ ] string , lister pjlister . ProwJobLister ) ( * Client , error ) { gc , err := client . NewClient ( projects ) if err != nil { return nil , err } gc . Start ( cookiefilePath ) return & Client { gc : gc , lister : lister , } , nil } 
func ( c * Client ) ShouldReport ( pj * v1 . ProwJob ) bool { if pj . Status . State == v1 . TriggeredState || pj . Status . State == v1 . PendingState { return false } if pj . Status . State == v1 . AbortedState { return false } return false } if pj . ObjectMeta . Labels [ client . GerritReportLabel ] == " " { } else { selector [ client . GerritReportLabel ] = pj . ObjectMeta . Labels [ client . GerritReportLabel ] } pjs , err := c . lister . List ( selector . AsSelector ( ) ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , selector ) return false } for _ , pjob := range pjs { if pjob . Status . State == v1 . TriggeredState || pjob . Status . State == v1 . PendingState { return false } } return true } 
func ( c * Client ) Report ( pj * v1 . ProwJob ) ( [ ] * v1 . ProwJob , error ) { logger := logrus . WithField ( " " , pj ) clientGerritRevision := client . GerritRevision clientGerritID := client . GerritID clientGerritInstance := client . GerritInstance pjTypeLabel := kube . ProwJobTypeLabel gerritReportLabel := client . GerritReportLabel selector := labels . Set { clientGerritRevision : pj . ObjectMeta . Labels [ clientGerritRevision ] , pjTypeLabel : pj . ObjectMeta . Labels [ pjTypeLabel ] , } if pj . ObjectMeta . Labels [ gerritReportLabel ] == " " { } else { selector [ gerritReportLabel ] = pj . ObjectMeta . Labels [ gerritReportLabel ] } if err != nil { logger . WithError ( err ) . Errorf ( " " , selector ) return nil , err } message := " " var toReportJobs [ ] * v1 . ProwJob mostRecentJob := map [ string ] * v1 . ProwJob { } for _ , pjOnRevisionWithSameLabel := range pjsOnRevisionWithSameLabel { job , ok := mostRecentJob [ pjOnRevisionWithSameLabel . Spec . Job ] if ! ok || job . CreationTimestamp . Time . Before ( pjOnRevisionWithSameLabel . CreationTimestamp . Time ) { mostRecentJob [ pjOnRevisionWithSameLabel . Spec . Job ] = pjOnRevisionWithSameLabel } } for _ , pjOnRevisionWithSameLabel := range mostRecentJob { if pjOnRevisionWithSameLabel . Status . State == v1 . AbortedState { continue } toReportJobs = append ( toReportJobs , pjOnRevisionWithSameLabel ) checkOrX := " if pjOnRevisionWithSameLabel . Status . State == v1 . SuccessState { checkOrX = " success ++ } message += fmt . Sprintf ( " \n \n " , checkOrX , pjOnRevisionWithSameLabel . Spec . Job , strings . ToUpper ( string ( pjOnRevisionWithSameLabel . Status . State ) ) , pjOnRevisionWithSameLabel . Status . URL ) } total := len ( toReportJobs ) if total <= 0 { return nil , nil } message = fmt . Sprintf ( " " , success , total , message ) gerritInstance := pj . ObjectMeta . Annotations [ clientGerritInstance ] gerritRevision := pj . ObjectMeta . Labels [ clientGerritRevision ] reportLabel := client . CodeReview if val , ok := pj . ObjectMeta . Labels [ client . GerritReportLabel ] ; ok { reportLabel = val } vote := client . LBTM if success == total { vote = client . LGTM } reviewLabels := map [ string ] string { reportLabel : vote } logger . Infof ( " " , gerritInstance , gerritID , message ) if err := c . gc . SetReview ( gerritInstance , gerritID , gerritRevision , message , reviewLabels ) ; err != nil { logger . WithError ( err ) . Errorf ( " " , reportLabel , gerritID ) if err := c . gc . SetReview ( gerritInstance , gerritID , gerritRevision , message , nil ) ; err != nil { logger . WithError ( err ) . Errorf ( " " , gerritID ) return nil , err } } logger . Infof ( " " , toReportJobs ) return toReportJobs , nil } 
func Run ( refs prowapi . Refs , dir , gitUserName , gitUserEmail , cookiePath string , env [ ] string ) Record { logrus . WithFields ( logrus . Fields { " " : refs } ) . Info ( " " ) record := Record { Refs : refs } logrus . WithFields ( logrus . Fields { " " : formattedCommand , " " : output , " " : err } ) . Info ( " " ) message := " " if err != nil { message = err . Error ( ) record . Failed = true } record . Commands = append ( record . Commands , Command { Command : formattedCommand , Output : output , Error : message } ) if err != nil { return err } } return nil } g := gitCtxForRefs ( refs , dir , env ) if err := runCommands ( g . commandsForBaseRef ( refs , gitUserName , gitUserEmail , cookiePath ) ) ; err != nil { return record } timestamp , err := g . gitHeadTimestamp ( ) if err != nil { timestamp = int ( time . Now ( ) . Unix ( ) ) } if err := runCommands ( g . commandsForPullRefs ( refs , timestamp ) ) ; err != nil { return record } finalSHA , err := g . gitRevParse ( ) if err != nil { logrus . WithError ( err ) . Warnf ( " " , refs ) } else { record . FinalSHA = finalSHA } return record } 
func PathForRefs ( baseDir string , refs prowapi . Refs ) string { var clonePath string if refs . PathAlias != " " { clonePath = refs . PathAlias } else { clonePath = fmt . Sprintf ( " " , refs . Org , refs . Repo ) } return fmt . Sprintf ( " " , baseDir , clonePath ) } 
func gitCtxForRefs ( refs prowapi . Refs , baseDir string , env [ ] string ) gitCtx { g := gitCtx { cloneDir : PathForRefs ( baseDir , refs ) , env : env , repositoryURI : fmt . Sprintf ( " " , refs . Org , refs . Repo ) , } if refs . CloneURI != " " { g . repositoryURI = refs . CloneURI } return g } 
func ( g * gitCtx ) commandsForBaseRef ( refs prowapi . Refs , gitUserName , gitUserEmail , cookiePath string ) [ ] cloneCommand { commands := [ ] cloneCommand { { dir : " " , env : g . env , command : " " , args : [ ] string { " " , g . cloneDir } } } commands = append ( commands , g . gitCommand ( " " ) ) if gitUserName != " " { commands = append ( commands , g . gitCommand ( " " , " " , gitUserName ) ) } if gitUserEmail != " " { commands = append ( commands , g . gitCommand ( " " , " " , gitUserEmail ) ) } if cookiePath != " " { commands = append ( commands , g . gitCommand ( " " , " " , cookiePath ) ) } commands = append ( commands , g . gitCommand ( " " , g . repositoryURI , " " , " " ) ) commands = append ( commands , g . gitCommand ( " " , g . repositoryURI , refs . BaseRef ) ) var target string if refs . BaseSHA != " " { target = refs . BaseSHA } else { target = " " } commands = append ( commands , g . gitCommand ( " " , " " , refs . BaseRef , target ) ) commands = append ( commands , g . gitCommand ( " " , refs . BaseRef ) ) return commands } 
func ( g * gitCtx ) gitHeadTimestamp ( ) ( int , error ) { gitShowCommand := g . gitCommand ( " " , " " , " " , " " ) _ , gitOutput , err := gitShowCommand . run ( ) if err != nil { logrus . WithError ( err ) . Debug ( " " ) return 0 , err } timestamp , convErr := strconv . Atoi ( string ( gitOutput ) ) if convErr != nil { logrus . WithError ( convErr ) . Errorf ( " " , gitOutput ) return 0 , convErr } return timestamp , nil } 
func gitTimestampEnvs ( timestamp int ) [ ] string { return [ ] string { fmt . Sprintf ( " " , timestamp ) , fmt . Sprintf ( " " , timestamp ) , } } 
func ( g * gitCtx ) gitRevParse ( ) ( string , error ) { gitRevParseCommand := g . gitCommand ( " " , " " ) _ , commit , err := gitRevParseCommand . run ( ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return " " , err } return strings . TrimSpace ( commit ) , nil } 
func ( g * gitCtx ) commandsForPullRefs ( refs prowapi . Refs , fakeTimestamp int ) [ ] cloneCommand { var commands [ ] cloneCommand for _ , prRef := range refs . Pulls { ref := fmt . Sprintf ( " " , prRef . Number ) if prRef . Ref != " " { ref = prRef . Ref } commands = append ( commands , g . gitCommand ( " " , g . repositoryURI , ref ) ) var prCheckout string if prRef . SHA != " " { prCheckout = prRef . SHA } else { prCheckout = " " } fakeTimestamp ++ gitMergeCommand := g . gitCommand ( " " , " " , prCheckout ) gitMergeCommand . env = append ( gitMergeCommand . env , gitTimestampEnvs ( fakeTimestamp ) ... ) commands = append ( commands , gitMergeCommand ) } } return commands } 
func ProduceCovList ( profiles [ ] * cover . Profile ) * CoverageList { covList := newCoverageList ( " " ) for _ , prof := range profiles { covList . Group = append ( covList . Group , summarizeBlocks ( prof ) ) } return covList } 
func popRandom ( set sets . String ) string { list := set . List ( ) sort . Strings ( list ) sel := list [ rand . Intn ( len ( list ) ) ] set . Delete ( sel ) return sel } 
func ( o * ExperimentalKubernetesOptions ) AddFlags ( fs * flag . FlagSet ) { fs . StringVar ( & o . buildCluster , " " , " " , " " ) fs . StringVar ( & o . kubeconfig , " " , " " , " " ) fs . StringVar ( & o . DeckURI , " " , " " , " " ) } 
func ( o * ExperimentalKubernetesOptions ) Validate ( dryRun bool ) error { if dryRun && o . DeckURI == " " { return errors . New ( " " ) } if o . DeckURI != " " { if _ , err := url . ParseRequestURI ( o . DeckURI ) ; err != nil { return fmt . Errorf ( " " , o . DeckURI ) } } if o . kubeconfig != " " { if _ , err := os . Stat ( o . kubeconfig ) ; err != nil { return fmt . Errorf ( " " , err ) } } if o . kubeconfig != " " && o . buildCluster != " " { return errors . New ( " " ) } return nil } 
func ( o * ExperimentalKubernetesOptions ) resolve ( dryRun bool ) ( err error ) { if o . resolved { return nil } o . dryRun = dryRun if dryRun { return nil } clusterConfigs , err := kube . LoadClusterConfigs ( o . kubeconfig , o . buildCluster ) if err != nil { return fmt . Errorf ( " " , o . kubeconfig , o . buildCluster , err ) } clients := map [ string ] kubernetes . Interface { } for context , config := range clusterConfigs { client , err := kubernetes . NewForConfig ( & config ) if err != nil { return fmt . Errorf ( " " , context , err ) } clients [ context ] = client } localCfg := clusterConfigs [ kube . InClusterContext ] pjClient , err := prow . NewForConfig ( & localCfg ) if err != nil { return err } o . prowJobClientset = pjClient o . kubernetesClientsByContext = clients o . resolved = true return nil } 
func ( o * ExperimentalKubernetesOptions ) ProwJobClientset ( namespace string , dryRun bool ) ( prowJobClientset prow . Interface , err error ) { if err := o . resolve ( dryRun ) ; err != nil { return nil , err } if o . dryRun { return nil , errors . New ( " " ) } return o . prowJobClientset , nil } 
func ( o * ExperimentalKubernetesOptions ) ProwJobClient ( namespace string , dryRun bool ) ( prowJobClient prowv1 . ProwJobInterface , err error ) { if err := o . resolve ( dryRun ) ; err != nil { return nil , err } if o . dryRun { return kube . NewDryRunProwJobClient ( o . DeckURI ) , nil } return o . prowJobClientset . ProwV1 ( ) . ProwJobs ( namespace ) , nil } 
func ( o * ExperimentalKubernetesOptions ) InfrastructureClusterClient ( dryRun bool ) ( kubernetesClient kubernetes . Interface , err error ) { if err := o . resolve ( dryRun ) ; err != nil { return nil , err } if o . dryRun { return nil , errors . New ( " " ) } return o . kubernetesClientsByContext [ kube . InClusterContext ] , nil } 
func ( o * ExperimentalKubernetesOptions ) BuildClusterClients ( namespace string , dryRun bool ) ( buildClusterClients map [ string ] corev1 . PodInterface , err error ) { if err := o . resolve ( dryRun ) ; err != nil { return nil , err } if o . dryRun { return nil , errors . New ( " " ) } buildClients := map [ string ] corev1 . PodInterface { } for context , client := range o . kubernetesClientsByContext { buildClients [ context ] = client . CoreV1 ( ) . Pods ( namespace ) } return buildClients , nil } 
func ( a * ActiveState ) Age ( t time . Time ) time . Duration { return t . Sub ( a . startTime ) } 
func ( a * ActiveState ) ReceiveEvent ( eventName , label string , t time . Time ) ( State , bool ) { if a . exit . Match ( eventName , label ) { return & InactiveState { entry : a . exit . Opposite ( ) , } , true } return a , false } 
func ( i * InactiveState ) ReceiveEvent ( eventName , label string , t time . Time ) ( State , bool ) { if i . entry . Match ( eventName , label ) { return & ActiveState { startTime : t , exit : i . entry . Opposite ( ) , } , true } return i , false } 
func ( m * MultiState ) Active ( ) bool { for _ , state := range m . states { if ! state . Active ( ) { return false } } return true } 
func ( m * MultiState ) Age ( t time . Time ) time . Duration { minAge := time . Duration ( 1 << 63 - 1 ) for _ , state := range m . states { stateAge := state . Age ( t ) if stateAge < minAge { minAge = stateAge } } return minAge } 
func ( m * MultiState ) ReceiveEvent ( eventName , label string , t time . Time ) ( State , bool ) { oneChanged := false for i := range m . states { state , changed := m . states [ i ] . ReceiveEvent ( eventName , label , t ) if changed { oneChanged = true } m . states [ i ] = state } return m , oneChanged } 
func NewState ( statesDescription string ) State { states := [ ] State { } if statesDescription == " " { } splitDescription := strings . Split ( statesDescription , " " ) for _ , description := range splitDescription { description = strings . TrimSpace ( description ) if strings . HasPrefix ( description , " " ) { states = append ( states , & ActiveState { startTime : time . Time { } , exit : NewEventMatcher ( description [ 1 : ] ) , } ) } else { states = append ( states , & InactiveState { entry : NewEventMatcher ( description ) , } ) } } return & MultiState { states : states } } 
func ( f * sharedInformerFactory ) ForResource ( resource schema . GroupVersionResource ) ( GenericInformer , error ) { switch resource { } return nil , fmt . Errorf ( " " , resource ) } 
func ( v * version ) ProwJobs ( ) ProwJobInformer { return & prowJobInformer { factory : v . factory , namespace : v . namespace , tweakListOptions : v . tweakListOptions } } 
func ItemToResourcesConfig ( i Item ) ( ResourcesConfig , error ) { conf , ok := i . ( ResourcesConfig ) if ! ok { return ResourcesConfig { } , fmt . Errorf ( " " , i ) } return conf , nil } 
func ( t TypeToResources ) Copy ( ) TypeToResources { n := TypeToResources { } for k , v := range t { n [ k ] = v } return n } 
func MakeCommand ( ) * cobra . Command { flags := & flags { } cmd := & cobra . Command { Use : " " , Short : " " , Long : `Given multiple Go coverage files from identical binaries recorded in "count" or "atomic" mode, produces a new Go coverage file in the same mode that counts how many of those coverage profiles hit a block at least once.` , Run : func ( cmd * cobra . Command , args [ ] string ) { run ( flags , cmd , args ) } , } cmd . Flags ( ) . StringVarP ( & flags . OutputFile , " " , " " , " " , " " ) return cmd } 
func NewController ( kc * kube . Client , pkcs map [ string ] * kube . Client , ghc GitHubClient , logger * logrus . Entry , cfg config . Getter , totURL , selector string , skipReport bool ) ( * Controller , error ) { if logger == nil { logger = logrus . NewEntry ( logrus . StandardLogger ( ) ) } buildClusters := map [ string ] kubeClient { } for alias , client := range pkcs { buildClusters [ alias ] = kubeClient ( client ) } return & Controller { kc : kc , pkcs : buildClusters , ghc : ghc , log : logger , config : cfg , pendingJobs : make ( map [ string ] int ) , totURL : totURL , selector : selector , skipReport : skipReport , } , nil } 
func ( c * Controller ) incrementNumPendingJobs ( job string ) { c . lock . Lock ( ) defer c . lock . Unlock ( ) c . pendingJobs [ job ] ++ } 
func ( c * Controller ) setPreviousReportState ( pj prowapi . ProwJob ) error { if err != nil { return err } if latestPJ . Status . PrevReportStates == nil { latestPJ . Status . PrevReportStates = map [ string ] prowapi . ProwJobState { } } latestPJ . Status . PrevReportStates [ reporter . GitHubReporterName ] = latestPJ . Status . State _ , err = c . kc . ReplaceProwJob ( latestPJ . ObjectMeta . Name , latestPJ ) return err } 
func ( c * Controller ) Sync ( ) error { pjs , err := c . kc . ListProwJobs ( c . selector ) if err != nil { return fmt . Errorf ( " " , err ) } selector := fmt . Sprintf ( " " , kube . CreatedByProw ) if len ( c . selector ) > 0 { selector = strings . Join ( [ ] string { c . selector , selector } , " " ) } pm := map [ string ] kube . Pod { } for alias , client := range c . pkcs { pods , err := client . ListPods ( selector ) if err != nil { return fmt . Errorf ( " " , alias , err ) } for _ , pod := range pods { pm [ pod . ObjectMeta . Name ] = pod } } for _ , pj := range pjs { if pj . Spec . Agent == prowapi . KubernetesAgent { k8sJobs = append ( k8sJobs , pj ) } } pjs = k8sJobs var syncErrs [ ] error if err := c . terminateDupes ( pjs , pm ) ; err != nil { syncErrs = append ( syncErrs , err ) } c . pjs = pjs c . pjLock . Unlock ( ) pendingCh , triggeredCh := pjutil . PartitionActive ( pjs ) errCh := make ( chan error , len ( pjs ) ) reportCh := make ( chan prowapi . ProwJob , len ( pjs ) ) c . log . Debugf ( " " , len ( pendingCh ) ) syncProwJobs ( c . log , c . syncPendingJob , maxSyncRoutines , pendingCh , reportCh , errCh , pm ) c . log . Debugf ( " " , len ( triggeredCh ) ) syncProwJobs ( c . log , c . syncTriggeredJob , maxSyncRoutines , triggeredCh , reportCh , errCh , pm ) close ( errCh ) close ( reportCh ) for err := range errCh { syncErrs = append ( syncErrs , err ) } var reportErrs [ ] error if ! c . skipReport { reportTemplate := c . config ( ) . Plank . ReportTemplate reportTypes := c . config ( ) . GitHubReporter . JobTypesToReport for report := range reportCh { if err := reportlib . Report ( c . ghc , reportTemplate , report , reportTypes ) ; err != nil { reportErrs = append ( reportErrs , err ) c . log . WithFields ( pjutil . ProwJobFields ( & report ) ) . WithError ( err ) . Warn ( " " ) } } } } if len ( syncErrs ) == 0 && len ( reportErrs ) == 0 { return nil } return fmt . Errorf ( " " , syncErrs , reportErrs ) } 
func ( c * Controller ) SyncMetrics ( ) { c . pjLock . RLock ( ) defer c . pjLock . RUnlock ( ) kube . GatherProwJobMetrics ( c . pjs ) } 
func ( c * Controller ) terminateDupes ( pjs [ ] prowapi . ProwJob , pm map [ string ] coreapi . Pod ) error { log := c . log . WithField ( " " , " " ) return pjutil . TerminateOlderPresubmitJobs ( c . kc , log , pjs , func ( toCancel prowapi . ProwJob ) error { } else if err := client . DeletePod ( pod . ObjectMeta . Name ) ; err != nil { return fmt . Errorf ( " " , err ) } } } return nil } ) } 
func syncProwJobs ( l * logrus . Entry , syncFn syncFn , maxSyncRoutines int , jobs <- chan prowapi . ProwJob , reports chan <- prowapi . ProwJob , syncErrors chan <- error , pm map [ string ] coreapi . Pod , ) { goroutines := maxSyncRoutines if goroutines > len ( jobs ) { goroutines = len ( jobs ) } wg := & sync . WaitGroup { } wg . Add ( goroutines ) l . Debugf ( " " , goroutines ) for i := 0 ; i < goroutines ; i ++ { go func ( ) { defer wg . Done ( ) for pj := range jobs { if err := syncFn ( pj , pm , reports ) ; err != nil { syncErrors <- err } } } ( ) } wg . Wait ( ) } 
func ( c * Controller ) startPod ( pj prowapi . ProwJob ) ( string , string , error ) { buildID , err := c . getBuildID ( pj . Spec . Job ) if err != nil { return " " , " " , fmt . Errorf ( " " , err ) } pod , err := decorate . ProwJobToPod ( pj , buildID ) if err != nil { return " " , " " , err } client , ok := c . pkcs [ pj . ClusterAlias ( ) ] if ! ok { return " " , " " , fmt . Errorf ( " " , pj . ClusterAlias ( ) ) } actual , err := client . CreatePod ( * pod ) if err != nil { return " " , " " , err } return buildID , actual . ObjectMeta . Name , nil } 
func DumpProfile ( profiles [ ] * cover . Profile , writer io . Writer ) error { if len ( profiles ) == 0 { return errors . New ( " " ) } if _ , err := io . WriteString ( writer , " " + profiles [ 0 ] . Mode + " \n " ) ; err != nil { return err } for _ , profile := range profiles { for _ , block := range profile . Blocks { if _ , err := fmt . Fprintf ( writer , " \n " , profile . FileName , block . StartLine , block . StartCol , block . EndLine , block . EndCol , block . NumStmt , block . Count ) ; err != nil { return err } } } return nil } 
func blocksEqual ( a cover . ProfileBlock , b cover . ProfileBlock ) bool { return a . StartCol == b . StartCol && a . StartLine == b . StartLine && a . EndCol == b . EndCol && a . EndLine == b . EndLine && a . NumStmt == b . NumStmt } 
func NewProwJobInformer ( client versioned . Interface , namespace string , resyncPeriod time . Duration , indexers cache . Indexers ) cache . SharedIndexInformer { return NewFilteredProwJobInformer ( client , namespace , resyncPeriod , indexers , nil ) } 
func NewFilteredProwJobInformer ( client versioned . Interface , namespace string , resyncPeriod time . Duration , indexers cache . Indexers , tweakListOptions internalinterfaces . TweakListOptionsFunc ) cache . SharedIndexInformer { return cache . NewSharedIndexInformer ( & cache . ListWatch { ListFunc : func ( options metav1 . ListOptions ) ( runtime . Object , error ) { if tweakListOptions != nil { tweakListOptions ( & options ) } return client . ProwV1 ( ) . ProwJobs ( namespace ) . List ( options ) } , WatchFunc : func ( options metav1 . ListOptions ) ( watch . Interface , error ) { if tweakListOptions != nil { tweakListOptions ( & options ) } return client . ProwV1 ( ) . ProwJobs ( namespace ) . Watch ( options ) } , } , & prowjobsv1 . ProwJob { } , resyncPeriod , indexers , ) } 
func New ( ja * jobs . JobAgent , cfg config . Getter , c * storage . Client , ctx context . Context ) * Spyglass { return & Spyglass { JobAgent : ja , config : cfg , PodLogArtifactFetcher : NewPodLogArtifactFetcher ( ja ) , GCSArtifactFetcher : NewGCSArtifactFetcher ( c ) , testgrid : & TestGrid { conf : cfg , client : c , ctx : ctx , } , } } 
func ( s * Spyglass ) Lenses ( matchCache map [ string ] [ ] string ) [ ] lenses . Lens { ls := [ ] lenses . Lens { } for lensName , matches := range matchCache { if len ( matches ) == 0 { continue } lens , err := lenses . GetLens ( lensName ) if err != nil { logrus . WithField ( " " , lens ) . WithError ( err ) . Error ( " " ) } else { ls = append ( ls , lens ) } } jconf := ls [ j ] . Config ( ) iname := iconf . Name jname := jconf . Name pi := iconf . Priority pj := jconf . Priority if pi == pj { return iname < jname } return pi < pj } ) return ls } 
func ( s * Spyglass ) JobPath ( src string ) ( string , error ) { src = strings . TrimSuffix ( src , " " ) keyType , key , err := splitSrc ( src ) if err != nil { return " " , fmt . Errorf ( " " , src ) } split := strings . Split ( key , " " ) switch keyType { case gcsKeyType : if len ( split ) < 4 { return " " , fmt . Errorf ( " " , key ) } logType := split [ 1 ] jobName := split [ len ( split ) - 2 ] if logType == gcs . NonPRLogs { return path . Dir ( key ) , nil } else if logType == gcs . PRLogs { return path . Join ( bktName , gcs . PRLogs , " " , jobName ) , nil } return " " , fmt . Errorf ( " " , key ) case prowKeyType : if len ( split ) < 2 { return " " , fmt . Errorf ( " " , key ) } jobName := split [ 0 ] buildID := split [ 1 ] job , err := s . jobAgent . GetProwJob ( jobName , buildID ) if err != nil { return " " , fmt . Errorf ( " " , key , err ) } if job . Spec . DecorationConfig == nil { return " " , fmt . Errorf ( " " , jobName ) } if job . Spec . DecorationConfig . GCSConfiguration == nil { return " " , fmt . Errorf ( " " , jobName ) } bktName := job . Spec . DecorationConfig . GCSConfiguration . Bucket if job . Spec . Type == prowapi . PresubmitJob { return path . Join ( bktName , gcs . PRLogs , " " , jobName ) , nil } return path . Join ( bktName , gcs . NonPRLogs , jobName ) , nil default : return " " , fmt . Errorf ( " " , src ) } } 
func ( s * Spyglass ) RunPath ( src string ) ( string , error ) { src = strings . TrimSuffix ( src , " " ) keyType , key , err := splitSrc ( src ) if err != nil { return " " , fmt . Errorf ( " " , src ) } switch keyType { case gcsKeyType : return key , nil case prowKeyType : return s . prowToGCS ( key ) default : return " " , fmt . Errorf ( " " , src ) } } 
func ( s * Spyglass ) RunToPR ( src string ) ( string , string , int , error ) { src = strings . TrimSuffix ( src , " " ) keyType , key , err := splitSrc ( src ) if err != nil { return " " , " " , 0 , fmt . Errorf ( " " , src ) } split := strings . Split ( key , " " ) if len ( split ) < 2 { return " " , " " , 0 , fmt . Errorf ( " " , src ) } switch keyType { case gcsKeyType : if logType == gcs . NonPRLogs { return " " , " " , 0 , fmt . Errorf ( " " , key ) } else if logType == gcs . PRLogs { if len ( split ) < 3 { return " " , " " , 0 , fmt . Errorf ( " " , gcs . PRLogs , key ) } prNumStr := split [ len ( split ) - 3 ] prNum , err := strconv . Atoi ( prNumStr ) if err != nil { return " " , " " , 0 , fmt . Errorf ( " " , prNumStr , key , err ) } } c := s . config ( ) . Plank . DefaultDecorationConfig . GCSConfiguration if len ( parts ) == 1 { return c . DefaultOrg , parts [ 0 ] , prNum , nil } return parts [ 0 ] , parts [ 1 ] , prNum , nil case 6 : return c . DefaultOrg , c . DefaultRepo , prNum , nil default : return " " , " " , 0 , fmt . Errorf ( " " , key ) } } else { return " " , " " , 0 , fmt . Errorf ( " " , logType ) } case prowKeyType : if len ( split ) < 2 { return " " , " " , 0 , fmt . Errorf ( " " , key ) } jobName := split [ 0 ] buildID := split [ 1 ] job , err := s . jobAgent . GetProwJob ( jobName , buildID ) if err != nil { return " " , " " , 0 , fmt . Errorf ( " " , key , err ) } if job . Spec . Refs == nil || len ( job . Spec . Refs . Pulls ) == 0 { return " " , " " , 0 , fmt . Errorf ( " " , job . Name ) } return job . Spec . Refs . Org , job . Spec . Refs . Repo , job . Spec . Refs . Pulls [ 0 ] . Number , nil default : return " " , " " , 0 , fmt . Errorf ( " " , src ) } } 
func ( sg * Spyglass ) ExtraLinks ( src string ) ( [ ] ExtraLink , error ) { artifacts , err := sg . FetchArtifacts ( src , " " , 1000000 , [ ] string { " " } ) return nil , nil } if err != nil { return nil , err } if err := json . Unmarshal ( content , & started ) ; err != nil { return nil , err } if ! ok { return nil , nil } extraLinks := make ( [ ] ExtraLink , 0 , len ( * links ) ) for _ , name := range links . Keys ( ) { m , ok := links . Meta ( name ) if ! ok { continue } s := m . Strings ( ) link := ExtraLink { Name : name , URL : s [ " " ] , Description : s [ " " ] , } if link . URL == " " || link . Name == " " { continue } extraLinks = append ( extraLinks , link ) } return extraLinks , nil } 
func ( s * Server ) ServeHTTP ( w http . ResponseWriter , r * http . Request ) { eventType , eventGUID , payload , ok , resp := github . ValidateWebhook ( w , r , s . TokenGenerator ( ) ) if counter , err := s . Metrics . WebhookCounter . GetMetricWithLabelValues ( strconv . Itoa ( resp ) ) ; err != nil { logrus . WithFields ( logrus . Fields { " " : resp , } ) . WithError ( err ) . Error ( " " ) } else { counter . Inc ( ) } if ! ok { return } fmt . Fprint ( w , " " ) if err := s . demuxEvent ( eventType , eventGUID , payload , r . Header ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } } 
func ( s * Server ) needDemux ( eventType , srcRepo string ) [ ] plugins . ExternalPlugin { var matching [ ] plugins . ExternalPlugin srcOrg := strings . Split ( srcRepo , " " ) [ 0 ] for repo , plugins := range s . Plugins . Config ( ) . ExternalPlugins { } } else { for _ , et := range p . Events { if et != eventType { continue } matching = append ( matching , p ) break } } } } return matching } 
func ( s * Server ) demuxExternal ( l * logrus . Entry , externalPlugins [ ] plugins . ExternalPlugin , payload [ ] byte , h http . Header ) { h . Set ( " " , " " ) for _ , p := range externalPlugins { s . wg . Add ( 1 ) go func ( p plugins . ExternalPlugin ) { defer s . wg . Done ( ) if err := s . dispatch ( p . Endpoint , payload , h ) ; err != nil { l . WithError ( err ) . WithField ( " " , p . Name ) . Error ( " " ) } else { l . WithField ( " " , p . Name ) . Info ( " " ) } } ( p ) } } 
func ( s * Server ) dispatch ( endpoint string , payload [ ] byte , h http . Header ) error { req , err := http . NewRequest ( http . MethodPost , endpoint , bytes . NewBuffer ( payload ) ) if err != nil { return err } req . Header = h resp , err := s . do ( req ) if err != nil { return err } defer resp . Body . Close ( ) rb , err := ioutil . ReadAll ( resp . Body ) if err != nil { return err } if resp . StatusCode < 200 || resp . StatusCode > 299 { return fmt . Errorf ( " " , resp . Status , string ( rb ) ) } return nil } 
func ( s * StatePlugin ) AddFlags ( cmd * cobra . Command ) { cmd . Flags ( ) . StringVar ( & s . desc , " " , " " , " " ) cmd . Flags ( ) . IntSliceVar ( & s . percentiles , " " , [ ] int { } , " " ) } 
func ( s * StatePlugin ) CheckFlags ( ) error { s . states = NewBundledStates ( s . desc ) return nil } 
func ( s * StatePlugin ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { label := " " if event . Label != nil { label = * event . Label } if ! s . states . ReceiveEvent ( event . IssueID , event . Event , label , event . EventCreatedAt ) { return nil } total , sum := s . states . Total ( event . EventCreatedAt ) values := map [ string ] interface { } { " " : total , " " : int ( sum ) , } for _ , percentile := range s . percentiles { values [ fmt . Sprintf ( " " , percentile ) ] = int ( s . states . Percentile ( event . EventCreatedAt , percentile ) ) } return [ ] Point { { Values : values , Date : event . EventCreatedAt , } , } } 
func ( ownersDirBlacklist OwnersDirBlacklist ) DirBlacklist ( org , repo string ) ( blacklist [ ] string ) { blacklist = append ( blacklist , ownersDirBlacklist . Default ... ) if bl , ok := ownersDirBlacklist . Repos [ org ] ; ok { blacklist = append ( blacklist , bl ... ) } if bl , ok := ownersDirBlacklist . Repos [ org + " " + repo ] ; ok { blacklist = append ( blacklist , bl ... ) } return } 
func Load ( prowConfig , jobConfig string ) ( c * Config , err error ) { } } ( ) c , err = loadConfig ( prowConfig , jobConfig ) if err != nil { return nil , err } if err := c . finalizeJobConfig ( ) ; err != nil { return nil , err } if err := c . validateComponentConfig ( ) ; err != nil { return nil , err } if err := c . validateJobConfig ( ) ; err != nil { return nil , err } return c , nil } 
func loadConfig ( prowConfig , jobConfig string ) ( * Config , error ) { stat , err := os . Stat ( prowConfig ) if err != nil { return nil , err } if stat . IsDir ( ) { return nil , fmt . Errorf ( " " , prowConfig ) } var nc Config if err := yamlToConfig ( prowConfig , & nc ) ; err != nil { return nil , err } if err := parseProwConfig ( & nc ) ; err != nil { return nil , err } } stat , err = os . Stat ( jobConfig ) if err != nil { return nil , err } if ! stat . IsDir ( ) { if err := yamlToConfig ( jobConfig , & jc ) ; err != nil { return nil , err } if err := nc . mergeJobConfig ( jc ) ; err != nil { return nil , err } return & nc , nil } err = filepath . Walk ( jobConfig , func ( path string , info os . FileInfo , err error ) error { if err != nil { logrus . WithError ( err ) . Errorf ( " " , path ) } if strings . HasPrefix ( info . Name ( ) , " " ) { } return nil } if filepath . Ext ( path ) != " " && filepath . Ext ( path ) != " " { return nil } if info . IsDir ( ) { return nil } base := filepath . Base ( path ) if uniqueBasenames . Has ( base ) { return fmt . Errorf ( " " , base ) } uniqueBasenames . Insert ( base ) var subConfig JobConfig if err := yamlToConfig ( path , & subConfig ) ; err != nil { return err } return nc . mergeJobConfig ( subConfig ) } ) if err != nil { return nil , err } return & nc , nil } 
func yamlToConfig ( path string , nc interface { } ) error { b , err := ReadFileMaybeGZIP ( path ) if err != nil { return fmt . Errorf ( " " , path , err ) } if err := yaml . Unmarshal ( b , nc ) ; err != nil { return fmt . Errorf ( " " , path , err ) } var jc * JobConfig switch v := nc . ( type ) { case * JobConfig : jc = v case * Config : jc = & v . JobConfig } for rep := range jc . Presubmits { var fix func ( * Presubmit ) fix = func ( job * Presubmit ) { job . SourcePath = path } for i := range jc . Presubmits [ rep ] { fix ( & jc . Presubmits [ rep ] [ i ] ) } } for rep := range jc . Postsubmits { var fix func ( * Postsubmit ) fix = func ( job * Postsubmit ) { job . SourcePath = path } for i := range jc . Postsubmits [ rep ] { fix ( & jc . Postsubmits [ rep ] [ i ] ) } } var fix func ( * Periodic ) fix = func ( job * Periodic ) { job . SourcePath = path } for i := range jc . Periodics { fix ( & jc . Periodics [ i ] ) } return nil } 
func ReadFileMaybeGZIP ( path string ) ( [ ] byte , error ) { b , err := ioutil . ReadFile ( path ) if err != nil { return nil , err } } if err != nil { return nil , err } return ioutil . ReadAll ( gzipReader ) } 
func ( c * Config ) mergeJobConfig ( jc JobConfig ) error { for _ , preset := range c . Presets { for label , val := range preset . Labels { pair := label + " " + val if _ , ok := validLabels [ pair ] ; ok { return fmt . Errorf ( " " , pair ) } validLabels [ pair ] = true } } } for repo , jobs := range jc . Presubmits { c . Presubmits [ repo ] = append ( c . Presubmits [ repo ] , jobs ... ) } } for repo , jobs := range jc . Postsubmits { c . Postsubmits [ repo ] = append ( c . Postsubmits [ repo ] , jobs ... ) } return nil } 
func ( c * Config ) finalizeJobConfig ( ) error { if c . decorationRequested ( ) { if c . Plank . DefaultDecorationConfig == nil { return errors . New ( " " ) } if c . Plank . DefaultDecorationConfig . UtilityImages == nil { return errors . New ( " " ) } if c . Plank . DefaultDecorationConfig . GCSConfiguration == nil { return errors . New ( " " ) } if c . Plank . DefaultDecorationConfig . GCSCredentialsSecret == " " { return errors . New ( " " ) } for _ , vs := range c . Presubmits { for i := range vs { setPresubmitDecorationDefaults ( c , & vs [ i ] ) } } for _ , js := range c . Postsubmits { for i := range js { setPostsubmitDecorationDefaults ( c , & js [ i ] ) } } for i := range c . Periodics { setPeriodicDecorationDefaults ( c , & c . Periodics [ i ] ) } } if err := SetPresubmitRegexes ( vs ) ; err != nil { return fmt . Errorf ( " " , err ) } } for _ , js := range c . Postsubmits { c . defaultPostsubmitFields ( js ) if err := SetPostsubmitRegexes ( js ) ; err != nil { return fmt . Errorf ( " " , err ) } } c . defaultPeriodicFields ( c . Periodics ) for _ , v := range c . AllPresubmits ( nil ) { if err := resolvePresets ( v . Name , v . Labels , v . Spec , v . BuildSpec , c . Presets ) ; err != nil { return err } } for _ , v := range c . AllPostsubmits ( nil ) { if err := resolvePresets ( v . Name , v . Labels , v . Spec , v . BuildSpec , c . Presets ) ; err != nil { return err } } for _ , v := range c . AllPeriodics ( ) { if err := resolvePresets ( v . Name , v . Labels , v . Spec , v . BuildSpec , c . Presets ) ; err != nil { return err } } return nil } 
func ( c * Config ) validateComponentConfig ( ) error { if c . Plank . JobURLPrefix != " " && c . Plank . JobURLPrefixConfig [ " " ] != " " { return errors . New ( `Planks job_url_prefix must be unset when job_url_prefix_config["*"] is set. The former is deprecated, use the latter` ) } for k , v := range c . Plank . JobURLPrefixConfig { if _ , err := url . Parse ( v ) ; err != nil { return fmt . Errorf ( `Invalid value for Planks job_url_prefix_config["%s"]: %v` , k , err ) } } if c . SlackReporter != nil { if err := c . SlackReporter . DefaultAndValidate ( ) ; err != nil { return fmt . Errorf ( " " , err ) } } return nil } 
func ( c * Config ) validateJobConfig ( ) error { type orgRepoJobName struct { orgRepo , jobName string } for repo , jobs := range c . Presubmits { for _ , job := range jobs { repoJobName := orgRepoJobName { repo , job . Name } for _ , existingJob := range validPresubmits [ repoJobName ] { if existingJob . Brancher . Intersects ( job . Brancher ) { return fmt . Errorf ( " " , job . Name ) } } validPresubmits [ repoJobName ] = append ( validPresubmits [ repoJobName ] , job ) } } for _ , v := range c . AllPresubmits ( nil ) { if err := validateJobBase ( v . JobBase , prowapi . PresubmitJob , c . PodNamespace ) ; err != nil { return fmt . Errorf ( " " , v . Name , err ) } if err := validateTriggering ( v ) ; err != nil { return err } } for repo , jobs := range c . Postsubmits { for _ , job := range jobs { repoJobName := orgRepoJobName { repo , job . Name } for _ , existingJob := range validPostsubmits [ repoJobName ] { if existingJob . Brancher . Intersects ( job . Brancher ) { return fmt . Errorf ( " " , job . Name ) } } validPostsubmits [ repoJobName ] = append ( validPostsubmits [ repoJobName ] , job ) } } for _ , j := range c . AllPostsubmits ( nil ) { if err := validateJobBase ( j . JobBase , prowapi . PostsubmitJob , c . PodNamespace ) ; err != nil { return fmt . Errorf ( " " , j . Name , err ) } } } validPeriodics . Insert ( p . Name ) if err := validateJobBase ( p . JobBase , prowapi . PeriodicJob , c . PodNamespace ) ; err != nil { return fmt . Errorf ( " " , p . Name , err ) } } } else if p . Cron == " " && p . Interval == " " { return fmt . Errorf ( " " , p . Name ) } else if p . Cron != " " { if _ , err := cron . Parse ( p . Cron ) ; err != nil { return fmt . Errorf ( " " , p . Cron , p . Name , err ) } } else { d , err := time . ParseDuration ( c . Periodics [ j ] . Interval ) if err != nil { return fmt . Errorf ( " " , c . Periodics [ j ] . Name , err ) } c . Periodics [ j ] . interval = d } } return nil } 
func ConfigPath ( value string ) string { if value != " " { return value } logrus . Warningf ( " " , DefaultConfigPath ) return DefaultConfigPath } 
func ValidateController ( c * Controller ) error { urlTmpl , err := template . New ( " " ) . Parse ( c . JobURLTemplateString ) if err != nil { return fmt . Errorf ( " " , err ) } c . JobURLTemplate = urlTmpl reportTmpl , err := template . New ( " " ) . Parse ( c . ReportTemplateString ) if err != nil { return fmt . Errorf ( " " , err ) } c . ReportTemplate = reportTmpl if c . MaxConcurrency < 0 { return fmt . Errorf ( " " , c . MaxConcurrency ) } if c . MaxGoroutines == 0 { c . MaxGoroutines = 20 } if c . MaxGoroutines <= 0 { return fmt . Errorf ( " " , c . MaxGoroutines ) } return nil } 
func ( c * ProwConfig ) defaultJobBase ( base * JobBase ) { if base . Agent == " " { } if base . Namespace == nil || * base . Namespace == " " { s := c . PodNamespace base . Namespace = & s } if base . Cluster == " " { base . Cluster = kube . DefaultClusterAlias } } 
func SetPresubmitRegexes ( js [ ] Presubmit ) error { for i , j := range js { if re , err := regexp . Compile ( j . Trigger ) ; err == nil { js [ i ] . re = re } else { return fmt . Errorf ( " " , j . Name , err ) } if ! js [ i ] . re . MatchString ( j . RerunCommand ) { return fmt . Errorf ( " \" \" \" \" " , j . Name , j . RerunCommand , j . Trigger ) } b , err := setBrancherRegexes ( j . Brancher ) if err != nil { return fmt . Errorf ( " " , j . Name , err ) } js [ i ] . Brancher = b c , err := setChangeRegexes ( j . RegexpChangeMatcher ) if err != nil { return fmt . Errorf ( " " , j . Name , err ) } js [ i ] . RegexpChangeMatcher = c } return nil } 
func setBrancherRegexes ( br Brancher ) ( Brancher , error ) { if len ( br . Branches ) > 0 { if re , err := regexp . Compile ( strings . Join ( br . Branches , `|` ) ) ; err == nil { br . re = re } else { return br , fmt . Errorf ( " " , err ) } } if len ( br . SkipBranches ) > 0 { if re , err := regexp . Compile ( strings . Join ( br . SkipBranches , `|` ) ) ; err == nil { br . reSkip = re } else { return br , fmt . Errorf ( " " , err ) } } return br , nil } 
func SetPostsubmitRegexes ( ps [ ] Postsubmit ) error { for i , j := range ps { b , err := setBrancherRegexes ( j . Brancher ) if err != nil { return fmt . Errorf ( " " , j . Name , err ) } ps [ i ] . Brancher = b c , err := setChangeRegexes ( j . RegexpChangeMatcher ) if err != nil { return fmt . Errorf ( " " , j . Name , err ) } ps [ i ] . RegexpChangeMatcher = c } return nil } 
func ( lens Lens ) Body ( artifacts [ ] lenses . Artifact , resourceDir string , data string ) string { var buf bytes . Buffer type MetadataViewData struct { Status string StartTime time . Time FinishedTime time . Time Elapsed time . Duration Metadata map [ string ] string } metadataViewData := MetadataViewData { Status : " " } started := gcs . Started { } finished := gcs . Finished { } for _ , a := range artifacts { read , err := a . ReadAll ( ) if err != nil { logrus . WithError ( err ) . Error ( " " ) } if a . JobPath ( ) == " " { if err = json . Unmarshal ( read , & started ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } metadataViewData . StartTime = time . Unix ( started . Timestamp , 0 ) } else if a . JobPath ( ) == " " { if err = json . Unmarshal ( read , & finished ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } if finished . Timestamp != nil { metadataViewData . FinishedTime = time . Unix ( * finished . Timestamp , 0 ) } metadataViewData . Status = finished . Result } } if ! metadataViewData . StartTime . IsZero ( ) { if metadataViewData . FinishedTime . IsZero ( ) { metadataViewData . Elapsed = time . Now ( ) . Sub ( metadataViewData . StartTime ) } else { metadataViewData . Elapsed = metadataViewData . FinishedTime . Sub ( metadataViewData . StartTime ) } metadataViewData . Elapsed = metadataViewData . Elapsed . Round ( time . Second ) } metadataViewData . Metadata = map [ string ] string { " " : started . Node } metadatas := [ ] metadata . Metadata { started . Metadata , finished . Metadata } for _ , m := range metadatas { for k , v := range m { if s , ok := v . ( string ) ; ok && v != " " { metadataViewData . Metadata [ k ] = s } } } metadataTemplate , err := template . ParseFiles ( filepath . Join ( resourceDir , " " ) ) if err != nil { return fmt . Sprintf ( " " , err ) } if err := metadataTemplate . ExecuteTemplate ( & buf , " " , metadataViewData ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } return buf . String ( ) } 
func NewBoskosHandler ( r * ranch . Ranch ) * http . ServeMux { mux := http . NewServeMux ( ) mux . Handle ( " " , handleDefault ( r ) ) mux . Handle ( " " , handleAcquire ( r ) ) mux . Handle ( " " , handleAcquireByState ( r ) ) mux . Handle ( " " , handleRelease ( r ) ) mux . Handle ( " " , handleReset ( r ) ) mux . Handle ( " " , handleUpdate ( r ) ) mux . Handle ( " " , handleMetric ( r ) ) return mux } 
func ErrorToStatus ( err error ) int { switch err . ( type ) { default : return http . StatusInternalServerError case * ranch . OwnerNotMatch : return http . StatusUnauthorized case * ranch . ResourceNotFound : return http . StatusNotFound case * ranch . ResourceTypeNotFound : return http . StatusNotFound case * ranch . StateNotMatch : return http . StatusConflict } } 
func handleDefault ( r * ranch . Ranch ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { logrus . WithField ( " " , " " ) . Infof ( " " , req . RemoteAddr ) } } 
func handleAcquire ( r * ranch . Ranch ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { logrus . WithField ( " " , " " ) . Infof ( " " , req . RemoteAddr ) if req . Method != http . MethodPost { msg := fmt . Sprintf ( " " , req . Method ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusMethodNotAllowed ) return } state := req . URL . Query ( ) . Get ( " " ) dest := req . URL . Query ( ) . Get ( " " ) owner := req . URL . Query ( ) . Get ( " " ) if rtype == " " || state == " " || dest == " " || owner == " " { msg := fmt . Sprintf ( " " , rtype , state , dest , owner ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusBadRequest ) return } logrus . Infof ( " " , state , rtype , owner , dest ) resource , err := r . Acquire ( rtype , state , dest , owner ) if err != nil { logrus . WithError ( err ) . Errorf ( " " ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) return } resJSON , err := json . Marshal ( resource ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , resource ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) if err != nil { logrus . WithError ( err ) . Warningf ( " " , resource . Name ) } return } logrus . Infof ( " " , string ( resJSON ) ) fmt . Fprint ( res , string ( resJSON ) ) } } 
func handleAcquireByState ( r * ranch . Ranch ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { logrus . WithField ( " " , " " ) . Infof ( " " , req . RemoteAddr ) if req . Method != http . MethodPost { msg := fmt . Sprintf ( " " , req . Method ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusMethodNotAllowed ) return } dest := req . URL . Query ( ) . Get ( " " ) owner := req . URL . Query ( ) . Get ( " " ) names := req . URL . Query ( ) . Get ( " " ) if state == " " || dest == " " || owner == " " || names == " " { msg := fmt . Sprintf ( " " , state , dest , owner , names ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusBadRequest ) return } rNames := strings . Split ( names , " " ) logrus . Infof ( " " , strings . Join ( rNames , " " ) , state , owner , dest ) resources , err := r . AcquireByState ( state , dest , owner , rNames ) if err != nil { logrus . WithError ( err ) . Errorf ( " " ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) return } resBytes := new ( bytes . Buffer ) if err := json . NewEncoder ( resBytes ) . Encode ( resources ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , resources ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) for _ , resource := range resources { err := r . Release ( resource . Name , state , owner ) if err != nil { logrus . WithError ( err ) . Warningf ( " " , resource . Name ) } } return } logrus . Infof ( " " , resBytes . String ( ) ) fmt . Fprint ( res , resBytes . String ( ) ) } } 
func handleRelease ( r * ranch . Ranch ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { logrus . WithField ( " " , " " ) . Infof ( " " , req . RemoteAddr ) if req . Method != http . MethodPost { msg := fmt . Sprintf ( " " , req . Method ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusMethodNotAllowed ) return } name := req . URL . Query ( ) . Get ( " " ) dest := req . URL . Query ( ) . Get ( " " ) owner := req . URL . Query ( ) . Get ( " " ) if name == " " || dest == " " || owner == " " { msg := fmt . Sprintf ( " " , name , dest , owner ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusBadRequest ) return } if err := r . Release ( name , dest , owner ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , name , dest , owner ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) return } logrus . Infof ( " " , name , dest ) } } 
func handleReset ( r * ranch . Ranch ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { logrus . WithField ( " " , " " ) . Infof ( " " , req . RemoteAddr ) if req . Method != http . MethodPost { msg := fmt . Sprintf ( " " , req . Method ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusMethodNotAllowed ) return } rtype := req . URL . Query ( ) . Get ( " " ) state := req . URL . Query ( ) . Get ( " " ) expireStr := req . URL . Query ( ) . Get ( " " ) dest := req . URL . Query ( ) . Get ( " " ) logrus . Infof ( " " , rtype , state , expireStr , dest ) if rtype == " " || state == " " || expireStr == " " || dest == " " { msg := fmt . Sprintf ( " " , rtype , state , expireStr , dest ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusBadRequest ) return } expire , err := time . ParseDuration ( expireStr ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , expireStr ) http . Error ( res , err . Error ( ) , http . StatusBadRequest ) return } rmap , err := r . Reset ( rtype , state , expire , dest ) if err != nil { logrus . WithError ( err ) . Errorf ( " " ) http . Error ( res , err . Error ( ) , http . StatusBadRequest ) return } resJSON , err := json . Marshal ( rmap ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , rmap ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) return } logrus . Infof ( " " , rtype , len ( rmap ) , dest ) fmt . Fprint ( res , string ( resJSON ) ) } } 
func handleUpdate ( r * ranch . Ranch ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { logrus . WithField ( " " , " " ) . Infof ( " " , req . RemoteAddr ) if req . Method != http . MethodPost { msg := fmt . Sprintf ( " " , req . Method ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusMethodNotAllowed ) return } name := req . URL . Query ( ) . Get ( " " ) owner := req . URL . Query ( ) . Get ( " " ) state := req . URL . Query ( ) . Get ( " " ) if name == " " || owner == " " || state == " " { msg := fmt . Sprintf ( " " , name , owner , state ) logrus . Warning ( msg ) http . Error ( res , msg , http . StatusBadRequest ) return } var userData common . UserData if req . Body != nil { err := json . NewDecoder ( req . Body ) . Decode ( & userData ) switch { case err == io . EOF : http . Error ( res , err . Error ( ) , http . StatusBadRequest ) return } } if err := r . Update ( name , owner , state , & userData ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , name , state , owner ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) return } logrus . Infof ( " " , name ) } } 
func handleMetric ( r * ranch . Ranch ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { logrus . WithField ( " " , " " ) . Infof ( " " , req . RemoteAddr ) if req . Method != http . MethodGet { logrus . Warningf ( " " , req . Method ) http . Error ( res , " " , http . StatusMethodNotAllowed ) return } rtype := req . URL . Query ( ) . Get ( " " ) if rtype == " " { msg := " " logrus . Warning ( msg ) http . Error ( res , msg , http . StatusBadRequest ) return } metric , err := r . Metric ( rtype ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , rtype ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) return } js , err := json . Marshal ( metric ) if err != nil { logrus . WithError ( err ) . Error ( " " ) http . Error ( res , err . Error ( ) , ErrorToStatus ( err ) ) return } res . Header ( ) . Set ( " " , " " ) res . Write ( js ) } } 
func DumpProfile ( destination string , profile [ ] * cover . Profile ) error { var output io . Writer if destination == " " { output = os . Stdout } else { f , err := os . Create ( destination ) if err != nil { return fmt . Errorf ( " " , destination , err ) } defer f . Close ( ) output = f } err := cov . DumpProfile ( profile , output ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func LoadProfile ( origin string ) ( [ ] * cover . Profile , error ) { filename := origin if origin == " " { if err != nil { return nil , fmt . Errorf ( " " , err ) } defer tf . Close ( ) defer os . Remove ( tf . Name ( ) ) if _ , err := io . Copy ( tf , os . Stdin ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } filename = tf . Name ( ) } return cover . ParseProfiles ( filename ) } 
func NewClient ( ) ( * Client , error ) { g , err := exec . LookPath ( " " ) if err != nil { return nil , err } t , err := ioutil . TempDir ( " " , " " ) if err != nil { return nil , err } return & Client { logger : logrus . WithField ( " " , " " ) , dir : t , git : g , base : fmt . Sprintf ( " " , github ) , repoLocks : make ( map [ string ] * sync . Mutex ) , } , nil } 
func ( c * Client ) SetCredentials ( user string , tokenGenerator func ( ) [ ] byte ) { c . credLock . Lock ( ) defer c . credLock . Unlock ( ) c . user = user c . tokenGenerator = tokenGenerator } 
func ( c * Client ) Clone ( repo string ) ( * Repo , error ) { c . lockRepo ( repo ) defer c . unlockRepo ( repo ) base := c . base user , pass := c . getCredentials ( ) if user != " " && pass != " " { base = fmt . Sprintf ( " " , user , pass , github ) } cache := filepath . Join ( c . dir , repo ) + " " if _ , err := os . Stat ( cache ) ; os . IsNotExist ( err ) { if err := os . MkdirAll ( filepath . Dir ( cache ) , os . ModePerm ) ; err != nil && ! os . IsExist ( err ) { return nil , err } remote := fmt . Sprintf ( " " , base , repo ) if b , err := retryCmd ( c . logger , " " , c . git , " " , " " , remote , cache ) ; err != nil { return nil , fmt . Errorf ( " " , err , string ( b ) ) } } else if err != nil { return nil , err } else { if b , err := retryCmd ( c . logger , cache , c . git , " " ) ; err != nil { return nil , fmt . Errorf ( " " , err , string ( b ) ) } } t , err := ioutil . TempDir ( " " , " " ) if err != nil { return nil , err } if b , err := exec . Command ( c . git , " " , cache , t ) . CombinedOutput ( ) ; err != nil { return nil , fmt . Errorf ( " " , err , string ( b ) ) } return & Repo { Dir : t , logger : c . logger , git : c . git , base : base , repo : repo , user : user , pass : pass , } , nil } 
func ( r * Repo ) Checkout ( commitlike string ) error { r . logger . Infof ( " " , commitlike ) co := r . gitCommand ( " " , commitlike ) if b , err := co . CombinedOutput ( ) ; err != nil { return fmt . Errorf ( " " , commitlike , err , string ( b ) ) } return nil } 
func ( r * Repo ) CheckoutNewBranch ( branch string ) error { r . logger . Infof ( " " , branch ) co := r . gitCommand ( " " , " " , branch ) if b , err := co . CombinedOutput ( ) ; err != nil { return fmt . Errorf ( " " , branch , err , string ( b ) ) } return nil } 
func ( r * Repo ) Merge ( commitlike string ) ( bool , error ) { r . logger . Infof ( " " , commitlike ) co := r . gitCommand ( " " , " " , " " , " " , commitlike ) b , err := co . CombinedOutput ( ) if err == nil { return true , nil } r . logger . WithError ( err ) . Infof ( " " , string ( b ) ) if b , err := r . gitCommand ( " " , " " ) . CombinedOutput ( ) ; err != nil { return false , fmt . Errorf ( " " , commitlike , err , string ( b ) ) } return false , nil } 
func ( r * Repo ) Am ( path string ) error { r . logger . Infof ( " " , path ) co := r . gitCommand ( " " , " " , path ) b , err := co . CombinedOutput ( ) if err == nil { return nil } output := string ( b ) r . logger . WithError ( err ) . Infof ( " " , output ) if b , abortErr := r . gitCommand ( " " , " " ) . CombinedOutput ( ) ; err != nil { r . logger . WithError ( abortErr ) . Warningf ( " " , string ( b ) ) } applyMsg := " " if strings . Contains ( output , applyMsg ) { i := strings . Index ( output , applyMsg ) err = fmt . Errorf ( " " , output [ : i ] ) } return err } 
func ( r * Repo ) Push ( repo , branch string ) error { if r . user == " " || r . pass == " " { return errors . New ( " " ) } r . logger . Infof ( " " , r . user , repo , branch ) remote := fmt . Sprintf ( " " , r . user , r . pass , github , r . user , repo ) co := r . gitCommand ( " " , remote , branch ) _ , err := co . CombinedOutput ( ) return err } 
func ( r * Repo ) CheckoutPullRequest ( number int ) error { r . logger . Infof ( " " , r . repo , number ) if b , err := retryCmd ( r . logger , r . Dir , r . git , " " , r . base + " " + r . repo , fmt . Sprintf ( " " , number , number ) ) ; err != nil { return fmt . Errorf ( " " , number , err , string ( b ) ) } co := r . gitCommand ( " " , fmt . Sprintf ( " " , number ) ) if b , err := co . CombinedOutput ( ) ; err != nil { return fmt . Errorf ( " " , number , err , string ( b ) ) } return nil } 
func ( r * Repo ) Config ( key , value string ) error { r . logger . Infof ( " " , key , value ) if b , err := r . gitCommand ( " " , key , value ) . CombinedOutput ( ) ; err != nil { return fmt . Errorf ( " " , key , value , err , string ( b ) ) } return nil } 
func retryCmd ( l * logrus . Entry , dir , cmd string , arg ... string ) ( [ ] byte , error ) { var b [ ] byte var err error sleepyTime := time . Second for i := 0 ; i < 3 ; i ++ { c := exec . Command ( cmd , arg ... ) c . Dir = dir b , err = c . CombinedOutput ( ) if err != nil { l . Warningf ( " " , cmd , arg , err , string ( b ) ) time . Sleep ( sleepyTime ) sleepyTime *= 2 continue } break } return b , err } 
func ( r * Repo ) MergeCommitsExistBetween ( target , head string ) ( bool , error ) { r . logger . Infof ( " " , target , head ) b , err := r . gitCommand ( " " , fmt . Sprintf ( " " , target , head ) , " " , " " ) . CombinedOutput ( ) if err != nil { return false , fmt . Errorf ( " " , target , head , err , string ( b ) ) } return len ( b ) != 0 , nil } 
func LabelsAndAnnotationsForSpec ( spec prowapi . ProwJobSpec , extraLabels , extraAnnotations map [ string ] string ) ( map [ string ] string , map [ string ] string ) { jobNameForLabel := spec . Job if len ( jobNameForLabel ) > validation . LabelValueMaxLength { logrus . WithFields ( logrus . Fields { " " : spec . Job , " " : kube . ProwJobAnnotation , " " : spec . Job , " " : jobNameForLabel , } ) . Info ( " " ) } labels := map [ string ] string { kube . CreatedByProw : " " , kube . ProwJobTypeLabel : string ( spec . Type ) , kube . ProwJobAnnotation : jobNameForLabel , } if spec . Type != prowapi . PeriodicJob && spec . Refs != nil { labels [ kube . OrgLabel ] = spec . Refs . Org labels [ kube . RepoLabel ] = spec . Refs . Repo if len ( spec . Refs . Pulls ) > 0 { labels [ kube . PullLabel ] = strconv . Itoa ( spec . Refs . Pulls [ 0 ] . Number ) } } for k , v := range extraLabels { labels [ k ] = v } if errs := validation . IsValidLabelValue ( base ) ; len ( errs ) == 0 { labels [ key ] = base continue } logrus . WithFields ( logrus . Fields { " " : key , " " : value , " " : errs , } ) . Warn ( " " ) delete ( labels , key ) } } annotations := map [ string ] string { kube . ProwJobAnnotation : spec . Job , } for k , v := range extraAnnotations { annotations [ k ] = v } return labels , annotations } 
func LabelsAndAnnotationsForJob ( pj prowapi . ProwJob ) ( map [ string ] string , map [ string ] string ) { var extraLabels map [ string ] string if extraLabels = pj . ObjectMeta . Labels ; extraLabels == nil { extraLabels = map [ string ] string { } } extraLabels [ kube . ProwJobIDLabel ] = pj . ObjectMeta . Name return LabelsAndAnnotationsForSpec ( pj . Spec , extraLabels , nil ) } 
func ProwJobToPod ( pj prowapi . ProwJob , buildID string ) ( * coreapi . Pod , error ) { if pj . Spec . PodSpec == nil { return nil , fmt . Errorf ( " " , pj . Name ) } rawEnv , err := downwardapi . EnvForSpec ( downwardapi . NewJobSpec ( pj . Spec , buildID , pj . Name ) ) if err != nil { return nil , err } spec := pj . Spec . PodSpec . DeepCopy ( ) spec . RestartPolicy = " " spec . Containers [ 0 ] . Name = kube . TestContainerName spec . AutomountServiceAccountToken = & myFalse } if pj . Spec . DecorationConfig == nil { spec . Containers [ 0 ] . Env = append ( spec . Containers [ 0 ] . Env , kubeEnv ( rawEnv ) ... ) } else { if err := decorate ( spec , & pj , rawEnv ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } } podLabels , annotations := LabelsAndAnnotationsForJob ( pj ) return & coreapi . Pod { ObjectMeta : metav1 . ObjectMeta { Name : pj . ObjectMeta . Name , Labels : podLabels , Annotations : annotations , } , Spec : * spec , } , nil } 
func CloneLogPath ( logMount coreapi . VolumeMount ) string { return filepath . Join ( logMount . MountPath , cloneLogPath ) } 
func cloneEnv ( opt clonerefs . Options ) ( [ ] coreapi . EnvVar , error ) { if err != nil { return nil , err } return kubeEnv ( map [ string ] string { clonerefs . JSONConfigEnvVar : cloneConfigEnv } ) , nil } 
func sshVolume ( secret string ) ( coreapi . Volume , coreapi . VolumeMount ) { var sshKeyMode int32 = 0400 name := strings . Join ( [ ] string { " " , secret } , " " ) mountPath := path . Join ( " " , secret ) v := coreapi . Volume { Name : name , VolumeSource : coreapi . VolumeSource { Secret : & coreapi . SecretVolumeSource { SecretName : secret , DefaultMode : & sshKeyMode , } , } , } vm := coreapi . VolumeMount { Name : name , MountPath : mountPath , ReadOnly : true , } return v , vm } 
func cookiefileVolume ( secret string ) ( coreapi . Volume , coreapi . VolumeMount , string ) { cookieSecret := parts [ 0 ] var base string if len ( parts ) == 1 { base = parts [ 0 ] } else { base = parts [ 1 ] } var cookiefileMode int32 = 0400 vol := coreapi . Volume { Name : " " , VolumeSource : coreapi . VolumeSource { Secret : & coreapi . SecretVolumeSource { SecretName : cookieSecret , DefaultMode : & cookiefileMode , } , } , } mount := coreapi . VolumeMount { Name : vol . Name , MountPath : " " , return vol , mount , path . Join ( mount . MountPath , base ) } 
func CloneRefs ( pj prowapi . ProwJob , codeMount , logMount coreapi . VolumeMount ) ( * coreapi . Container , [ ] prowapi . Refs , [ ] coreapi . Volume , error ) { if pj . Spec . DecorationConfig == nil { return nil , nil , nil , nil } if skip := pj . Spec . DecorationConfig . SkipCloning ; skip != nil && * skip { return nil , nil , nil , nil } var cloneVolumes [ ] coreapi . Volume var refs [ ] prowapi . Refs if pj . Spec . Refs != nil { refs = append ( refs , * pj . Spec . Refs ) } for _ , r := range pj . Spec . ExtraRefs { refs = append ( refs , r ) } if len ( refs ) == 0 { } if codeMount . Name == " " || codeMount . MountPath == " " { return nil , nil , nil , fmt . Errorf ( " " ) } if logMount . Name == " " || logMount . MountPath == " " { return nil , nil , nil , fmt . Errorf ( " " ) } var cloneMounts [ ] coreapi . VolumeMount var sshKeyPaths [ ] string for _ , secret := range pj . Spec . DecorationConfig . SSHKeySecrets { volume , mount := sshVolume ( secret ) cloneMounts = append ( cloneMounts , mount ) sshKeyPaths = append ( sshKeyPaths , mount . MountPath ) cloneVolumes = append ( cloneVolumes , volume ) } var cloneArgs [ ] string var cookiefilePath string if cp := pj . Spec . DecorationConfig . CookiefileSecret ; cp != " " { v , vm , vp := cookiefileVolume ( cp ) cloneMounts = append ( cloneMounts , vm ) cloneVolumes = append ( cloneVolumes , v ) cookiefilePath = vp cloneArgs = append ( cloneArgs , " " + cookiefilePath ) } env , err := cloneEnv ( clonerefs . Options { CookiePath : cookiefilePath , GitRefs : refs , GitUserEmail : clonerefs . DefaultGitUserEmail , GitUserName : clonerefs . DefaultGitUserName , HostFingerprints : pj . Spec . DecorationConfig . SSHHostFingerprints , KeyFiles : sshKeyPaths , Log : CloneLogPath ( logMount ) , SrcRoot : codeMount . MountPath , } ) if err != nil { return nil , nil , nil , fmt . Errorf ( " " , err ) } container := coreapi . Container { Name : cloneRefsName , Image : pj . Spec . DecorationConfig . UtilityImages . CloneRefs , Command : [ ] string { cloneRefsCommand } , Args : cloneArgs , Env : env , VolumeMounts : append ( [ ] coreapi . VolumeMount { logMount , codeMount } , cloneMounts ... ) , } return & container , refs , cloneVolumes , nil } 
func InjectEntrypoint ( c * coreapi . Container , timeout , gracePeriod time . Duration , prefix , previousMarker string , exitZero bool , log , tools coreapi . VolumeMount ) ( * wrapper . Options , error ) { wrapperOptions := & wrapper . Options { Args : append ( c . Command , c . Args ... ) , ProcessLog : processLog ( log , prefix ) , MarkerFile : markerFile ( log , prefix ) , MetadataFile : metadataFile ( log , prefix ) , } if err != nil { return nil , err } c . Command = [ ] string { entrypointLocation ( tools ) } c . Args = nil c . Env = append ( c . Env , kubeEnv ( map [ string ] string { entrypoint . JSONConfigEnvVar : entrypointConfigEnv } ) ... ) c . VolumeMounts = append ( c . VolumeMounts , log , tools ) return wrapperOptions , nil } 
func PlaceEntrypoint ( image string , toolsMount coreapi . VolumeMount ) coreapi . Container { return coreapi . Container { Name : " " , Image : image , Command : [ ] string { " " } , Args : [ ] string { " " , entrypointLocation ( toolsMount ) } , VolumeMounts : [ ] coreapi . VolumeMount { toolsMount } , } } 
func kubeEnv ( environment map [ string ] string ) [ ] coreapi . EnvVar { var keys [ ] string for key := range environment { keys = append ( keys , key ) } sort . Strings ( keys ) var kubeEnvironment [ ] coreapi . EnvVar for _ , key := range keys { kubeEnvironment = append ( kubeEnvironment , coreapi . EnvVar { Name : key , Value : environment [ key ] , } ) } return kubeEnvironment } 
func ( o * KubernetesOptions ) AddFlags ( fs * flag . FlagSet ) { fs . StringVar ( & o . cluster , " " , " " , " " ) fs . StringVar ( & o . kubeconfig , " " , " " , " " ) fs . StringVar ( & o . DeckURI , " " , " " , " " ) } 
func ( o * KubernetesOptions ) Validate ( dryRun bool ) error { if dryRun && o . DeckURI == " " { return errors . New ( " " ) } if o . DeckURI != " " { if _ , err := url . ParseRequestURI ( o . DeckURI ) ; err != nil { return fmt . Errorf ( " " , o . DeckURI ) } } return nil } 
func ( o * KubernetesOptions ) Client ( namespace string , dryRun bool ) ( * kube . Client , error ) { if dryRun { return kube . NewFakeClient ( o . DeckURI ) , nil } if o . cluster == " " { return kube . NewClientInCluster ( namespace ) } return kube . NewClientFromFile ( o . cluster , namespace ) } 
func handle ( gc githubClient , le * logrus . Entry , e * event ) error { needsLabel := e . draft || titleRegex . MatchString ( e . title ) if needsLabel && ! e . hasLabel { if err := gc . AddLabel ( e . org , e . repo , e . number , labels . WorkInProgress ) ; err != nil { le . Warnf ( " " , labels . WorkInProgress , err ) return err } } else if ! needsLabel && e . hasLabel { if err := gc . RemoveLabel ( e . org , e . repo , e . number , labels . WorkInProgress ) ; err != nil { le . Warnf ( " " , labels . WorkInProgress , err ) return err } } return nil } 
func SendHook ( address , eventType string , payload , hmac [ ] byte ) error { req , err := http . NewRequest ( http . MethodPost , address , bytes . NewBuffer ( payload ) ) if err != nil { return err } req . Header . Set ( " " , eventType ) req . Header . Set ( " " , " " ) req . Header . Set ( " " , github . PayloadSignature ( payload , hmac ) ) req . Header . Set ( " " , " " ) c := & http . Client { } resp , err := c . Do ( req ) if err != nil { return err } defer resp . Body . Close ( ) rb , err := ioutil . ReadAll ( resp . Body ) if err != nil { return err } if resp . StatusCode != 200 { return fmt . Errorf ( " " , resp . StatusCode , string ( bytes . TrimSpace ( rb ) ) ) } return nil } 
func format ( rtype string ) string { splits := strings . Split ( rtype , " " ) return splits [ len ( splits ) - 1 ] } 
func janitorClean ( resource * common . Resource , flags [ ] string ) error { args := append ( [ ] string { fmt . Sprintf ( " " , format ( resource . Type ) , resource . Name ) } , flags ... ) logrus . Infof ( " " , * janitorPath , strings . Join ( args , " " ) ) cmd := exec . Command ( * janitorPath , args ... ) b , err := cmd . CombinedOutput ( ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , resource . Name , string ( b ) ) } else { logrus . Tracef ( " " , string ( b ) ) logrus . Infof ( " " , resource . Name ) } return err } 
func janitor ( c boskosClient , buffer <- chan * common . Resource , fn clean , flags [ ] string ) { for { resource := <- buffer dest := common . Free if err := fn ( resource , flags ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , * janitorPath ) dest = common . Dirty } if err := c . ReleaseOne ( resource . Name , dest ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } } } 
func ( s * PushServer ) ServeHTTP ( w http . ResponseWriter , r * http . Request ) { HTTPCode := http . StatusOK subscription := " " var finalError error defer func ( ) { s . Subscriber . Metrics . ResponseCounter . With ( prometheus . Labels { subscriptionLabel : subscription , responseCodeLabel : string ( HTTPCode ) , } ) . Inc ( ) if finalError != nil { http . Error ( w , finalError . Error ( ) , HTTPCode ) } } ( ) if s . TokenGenerator != nil { token := r . URL . Query ( ) . Get ( tokenLabel ) if token != string ( s . TokenGenerator ( ) ) { finalError = fmt . Errorf ( " " ) HTTPCode = http . StatusForbidden return } } if err := json . NewDecoder ( r . Body ) . Decode ( pr ) ; err != nil { finalError = err HTTPCode = http . StatusBadRequest return } msg := pubsub . Message { Data : pr . Message . Data , ID : pr . Message . ID , Attributes : pr . Message . Attributes , } if err := s . Subscriber . handleMessage ( & pubSubMessage { Message : msg } , pr . Subscription ) ; err != nil { finalError = err HTTPCode = http . StatusNotModified return } } 
func ( c * pubSubClient ) new ( ctx context . Context , project string ) ( pubsubClientInterface , error ) { client , err := pubsub . NewClient ( ctx , project ) if err != nil { return nil , err } c . client = client return c , nil } 
func ( c * pubSubClient ) subscription ( id string ) subscriptionInterface { return & pubSubSubscription { sub : c . client . Subscription ( id ) , } } 
func ( s * PullServer ) handlePulls ( ctx context . Context , projectSubscriptions config . PubsubSubscriptions ) ( * errgroup . Group , context . Context , error ) { for project , subscriptions := range projectSubscriptions { client , err := s . Client . new ( ctx , project ) if err != nil { return errGroup , derivedCtx , err } for _ , subName := range subscriptions { sub := client . subscription ( subName ) errGroup . Go ( func ( ) error { logrus . Infof ( " " , sub . string ( ) , project ) defer logrus . Warnf ( " " , sub . string ( ) , project ) err := sub . receive ( derivedCtx , func ( ctx context . Context , msg messageInterface ) { if err = s . Subscriber . handleMessage ( msg , sub . string ( ) ) ; err != nil { s . Subscriber . Metrics . ACKMessageCounter . With ( prometheus . Labels { subscriptionLabel : sub . string ( ) } ) . Inc ( ) } else { s . Subscriber . Metrics . NACKMessageCounter . With ( prometheus . Labels { subscriptionLabel : sub . string ( ) } ) . Inc ( ) } msg . ack ( ) } ) if err != nil { logrus . WithError ( err ) . Errorf ( " " , sub . string ( ) , project ) return err } return nil } ) } } return errGroup , derivedCtx , nil } 
func ( s * PullServer ) Run ( ctx context . Context ) error { configEvent := make ( chan config . Delta , 2 ) s . Subscriber . ConfigAgent . Subscribe ( configEvent ) var err error defer func ( ) { if err != nil { logrus . WithError ( ctx . Err ( ) ) . Error ( " " ) } logrus . Warn ( " " ) } ( ) currentConfig := s . Subscriber . ConfigAgent . Config ( ) . PubSubSubscriptions errGroup , derivedCtx , err := s . handlePulls ( ctx , currentConfig ) if err != nil { return err } for { select { return err logrus . Info ( " " ) if ! reflect . DeepEqual ( currentConfig , newConfig ) { logrus . Warn ( " " ) if err != nil { return err } currentConfig = newConfig } } } } 
func specToStarted ( spec * downwardapi . JobSpec , mainRefSHA string ) gcs . Started { started := gcs . Started { Timestamp : time . Now ( ) . Unix ( ) , RepoVersion : downwardapi . GetRevisionFromSpec ( spec ) , } if mainRefSHA != " " { started . RepoVersion = mainRefSHA } } started . Repos = map [ string ] string { } if spec . Refs != nil { started . Repos [ spec . Refs . Org + " " + spec . Refs . Repo ] = spec . Refs . String ( ) } for _ , ref := range spec . ExtraRefs { started . Repos [ ref . Org + " " + ref . Repo ] = ref . String ( ) } return started } 
func ( o Options ) Run ( ) error { spec , err := downwardapi . ResolveSpecFromEnv ( ) if err != nil { return fmt . Errorf ( " " , err ) } uploadTargets := map [ string ] gcs . UploadFunc { } var failed bool var mainRefSHA string if o . Log != " " { if failed , mainRefSHA , err = processCloneLog ( o . Log , uploadTargets ) ; err != nil { return err } } started := specToStarted ( spec , mainRefSHA ) startedData , err := json . Marshal ( & started ) if err != nil { return fmt . Errorf ( " " , err ) } uploadTargets [ " " ] = gcs . DataUpload ( bytes . NewReader ( startedData ) ) if err := o . Options . Run ( spec , uploadTargets ) ; err != nil { return fmt . Errorf ( " " , err ) } if failed { return errors . New ( " " ) } return nil } 
func processCloneLog ( logfile string , uploadTargets map [ string ] gcs . UploadFunc ) ( bool , string , error ) { var cloneRecords [ ] clone . Record data , err := ioutil . ReadFile ( logfile ) if err != nil { return true , " " , fmt . Errorf ( " " , err ) } if err = json . Unmarshal ( data , & cloneRecords ) ; err != nil { return true , " " , fmt . Errorf ( " " , err ) } var failed bool var mainRefSHA string for idx , record := range cloneRecords { cloneLog . WriteString ( clone . FormatRecord ( record ) ) failed = failed || record . Failed } } uploadTargets [ " " ] = gcs . DataUpload ( bytes . NewReader ( cloneLog . Bytes ( ) ) ) uploadTargets [ " " ] = gcs . FileUpload ( logfile ) if failed { uploadTargets [ " " ] = gcs . DataUpload ( bytes . NewReader ( cloneLog . Bytes ( ) ) ) passed := ! failed now := time . Now ( ) . Unix ( ) finished := gcs . Finished { Timestamp : & now , Passed : & passed , Result : " " , } finishedData , err := json . Marshal ( & finished ) if err != nil { return true , mainRefSHA , fmt . Errorf ( " " , err ) } uploadTargets [ " " ] = gcs . DataUpload ( bytes . NewReader ( finishedData ) ) } return failed , mainRefSHA , nil } 
func hasPRChanged ( pr github . PullRequestEvent ) bool { switch pr . Action { case github . PullRequestActionOpened : return true case github . PullRequestActionReopened : return true case github . PullRequestActionSynchronize : return true default : return false } } 
func UpdateIssues ( db * gorm . DB , client ClientInterface ) { latest , err := findLatestIssueUpdate ( db , client . RepositoryName ( ) ) if err != nil { glog . Error ( " " , err ) return } c := make ( chan * github . Issue , 200 ) go client . FetchIssues ( latest , c ) for issue := range c { issueOrm , err := NewIssue ( issue , client . RepositoryName ( ) ) if err != nil { glog . Error ( " " , err ) continue } if db . Create ( issueOrm ) . Error != nil { db . Delete ( sql . Assignee { } , " " , issueOrm . ID , client . RepositoryName ( ) ) if err := db . Save ( issueOrm ) . Error ; err != nil { glog . Error ( " " , err ) } } } } 
func handleReviewEvent ( pc plugins . Agent , re github . ReviewEvent ) error { return handleReview ( pc . Logger , pc . GitHubClient , pc . OwnersClient , pc . Config . GitHubOptions , pc . PluginConfig , & re , ) } 
func findAssociatedIssue ( body , org string ) ( int , error ) { associatedIssueRegex , err := regexp . Compile ( fmt . Sprintf ( associatedIssueRegexFormat , org ) ) if err != nil { return 0 , err } match := associatedIssueRegex . FindStringSubmatch ( body ) if len ( match ) == 0 { return 0 , nil } v , err := strconv . Atoi ( match [ 1 ] ) if err != nil { return 0 , err } return v , nil } 
func handle ( log * logrus . Entry , ghc githubClient , repo approvers . Repo , githubConfig config . GitHubOptions , opts * plugins . Approve , pr * state ) error { fetchErr := func ( context string , err error ) error { return fmt . Errorf ( " " , context , pr . org , pr . repo , pr . number , err ) } changes , err := ghc . GetPullRequestChanges ( pr . org , pr . repo , pr . number ) if err != nil { return fetchErr ( " " , err ) } var filenames [ ] string for _ , change := range changes { filenames = append ( filenames , change . Filename ) } issueLabels , err := ghc . GetIssueLabels ( pr . org , pr . repo , pr . number ) if err != nil { return fetchErr ( " " , err ) } hasApprovedLabel := false for _ , label := range issueLabels { if label . Name == labels . Approved { hasApprovedLabel = true break } } botName , err := ghc . BotName ( ) if err != nil { return fetchErr ( " " , err ) } issueComments , err := ghc . ListIssueComments ( pr . org , pr . repo , pr . number ) if err != nil { return fetchErr ( " " , err ) } reviewComments , err := ghc . ListPullRequestComments ( pr . org , pr . repo , pr . number ) if err != nil { return fetchErr ( " " , err ) } reviews , err := ghc . ListReviews ( pr . org , pr . repo , pr . number ) if err != nil { return fetchErr ( " " , err ) } approversHandler := approvers . NewApprovers ( approvers . NewOwners ( log , filenames , repo , int64 ( pr . number ) , ) , ) approversHandler . AssociatedIssue , err = findAssociatedIssue ( pr . body , pr . org ) if err != nil { log . WithError ( err ) . Errorf ( " " , err ) } approversHandler . RequireIssue = opts . IssueRequired approversHandler . ManuallyApproved = humanAddedApproved ( ghc , log , pr . org , pr . repo , pr . number , botName , hasApprovedLabel ) } else { } commentsFromIssueComments := commentsFromIssueComments ( issueComments ) comments := append ( commentsFromReviewComments ( reviewComments ) , commentsFromIssueComments ... ) comments = append ( comments , commentsFromReviews ( reviews ) ... ) sort . SliceStable ( comments , func ( i , j int ) bool { return comments [ i ] . CreatedAt . Before ( comments [ j ] . CreatedAt ) } ) approveComments := filterComments ( comments , approvalMatcher ( botName , opts . LgtmActsAsApprove , opts . ConsiderReviewState ( ) ) ) addApprovers ( & approversHandler , approveComments , pr . author , opts . ConsiderReviewState ( ) ) for _ , user := range pr . assignees { approversHandler . AddAssignees ( user . Login ) } notifications := filterComments ( commentsFromIssueComments , notificationMatcher ( botName ) ) latestNotification := getLast ( notifications ) newMessage := updateNotification ( githubConfig . LinkURL , pr . org , pr . repo , pr . branch , latestNotification , approversHandler ) if newMessage != nil { for _ , notif := range notifications { if err := ghc . DeleteComment ( pr . org , pr . repo , notif . ID ) ; err != nil { log . WithError ( err ) . Errorf ( " " , pr . org , pr . repo , pr . number , notif . ID ) } } if err := ghc . CreateComment ( pr . org , pr . repo , pr . number , * newMessage ) ; err != nil { log . WithError ( err ) . Errorf ( " " , pr . org , pr . repo , pr . number , * newMessage ) } } if ! approversHandler . IsApproved ( ) { if hasApprovedLabel { if err := ghc . RemoveLabel ( pr . org , pr . repo , pr . number , labels . Approved ) ; err != nil { log . WithError ( err ) . Errorf ( " " , labels . Approved , pr . org , pr . repo , pr . number ) } } } else if ! hasApprovedLabel { if err := ghc . AddLabel ( pr . org , pr . repo , pr . number , labels . Approved ) ; err != nil { log . WithError ( err ) . Errorf ( " " , labels . Approved , pr . org , pr . repo , pr . number ) } } return nil } 
func addApprovers ( approversHandler * approvers . Approvers , approveComments [ ] * comment , author string , reviewActsAsApprove bool ) { for _ , c := range approveComments { if c . Author == " " { continue } if reviewActsAsApprove && c . ReviewState == github . ReviewStateApproved { approversHandler . AddApprover ( c . Author , c . HTMLURL , false , ) } if reviewActsAsApprove && c . ReviewState == github . ReviewStateChangesRequested { approversHandler . RemoveApprover ( c . Author ) } for _ , match := range commandRegex . FindAllStringSubmatch ( c . Body , - 1 ) { name := strings . ToUpper ( match [ 1 ] ) if name != approveCommand && name != lgtmCommand { continue } args := strings . ToLower ( strings . TrimSpace ( match [ 2 ] ) ) if strings . Contains ( args , cancelArgument ) { approversHandler . RemoveApprover ( c . Author ) continue } if c . Author == author { approversHandler . AddAuthorSelfApprover ( c . Author , c . HTMLURL , args == noIssueArgument , ) } if name == approveCommand { approversHandler . AddApprover ( c . Author , c . HTMLURL , args == noIssueArgument , ) } else { approversHandler . AddLGTMer ( c . Author , c . HTMLURL , args == noIssueArgument , ) } } } } 
func optionsForRepo ( config * plugins . Configuration , org , repo string ) * plugins . Approve { fullName := fmt . Sprintf ( " " , org , repo ) a := func ( ) * plugins . Approve { } return & c } } return & c } } ( ) if a . DeprecatedImplicitSelfApprove == nil && a . RequireSelfApproval == nil && config . UseDeprecatedSelfApprove { no := false a . DeprecatedImplicitSelfApprove = & no } if a . DeprecatedReviewActsAsApprove == nil && a . IgnoreReviewState == nil && config . UseDeprecatedReviewApprove { no := false a . DeprecatedReviewActsAsApprove = & no } return a } 
func localOnlyMain ( cfg config . Getter , o options , mux * http . ServeMux ) * http . ServeMux { mux . Handle ( " " , gziphandler . GzipHandler ( handleSimpleTemplate ( o , cfg , " " , nil ) ) ) if o . spyglass { initSpyglass ( cfg , o , mux , nil ) } return mux } 
func prodOnlyMain ( cfg config . Getter , o options , mux * http . ServeMux ) * http . ServeMux { prowJobClient , err := o . kubernetes . ProwJobClient ( cfg ( ) . ProwJobNamespace , false ) if err != nil { logrus . WithError ( err ) . Fatal ( " " ) } buildClusterClients , err := o . kubernetes . BuildClusterClients ( cfg ( ) . PodNamespace , false ) if err != nil { logrus . WithError ( err ) . Fatal ( " " ) } podLogClients := map [ string ] jobs . PodLogClient { } for clusterContext , client := range buildClusterClients { podLogClients [ clusterContext ] = & podLogClient { client : client } } ja := jobs . NewJobAgent ( & filteringProwJobLister { client : prowJobClient , hiddenRepos : sets . NewString ( cfg ( ) . Deck . HiddenRepos ... ) , hiddenOnly : o . hiddenOnly , showHidden : o . showHidden , } , podLogClients , cfg ) ja . Start ( ) mux . Handle ( " " , gziphandler . GzipHandler ( handleProwJobs ( ja ) ) ) mux . Handle ( " " , gziphandler . GzipHandler ( handleBadge ( ja ) ) ) mux . Handle ( " " , gziphandler . GzipHandler ( handleLog ( ja ) ) ) mux . Handle ( " " , gziphandler . GzipHandler ( handleRerun ( prowJobClient ) ) ) if o . spyglass { initSpyglass ( cfg , o , mux , ja ) } if o . hookURL != " " { mux . Handle ( " " , gziphandler . GzipHandler ( handlePluginHelp ( newHelpAgent ( o . hookURL ) ) ) ) } if o . tideURL != " " { ta := & tideAgent { log : logrus . WithField ( " " , " " ) , path : o . tideURL , updatePeriod : func ( ) time . Duration { return cfg ( ) . Deck . TideUpdatePeriod } , hiddenRepos : cfg ( ) . Deck . HiddenRepos , hiddenOnly : o . hiddenOnly , showHidden : o . showHidden , } ta . start ( ) mux . Handle ( " " , gziphandler . GzipHandler ( handleTidePools ( cfg , ta ) ) ) mux . Handle ( " " , gziphandler . GzipHandler ( handleTideHistory ( ta ) ) ) } if err != nil { logrus . WithError ( err ) . Fatal ( " " ) } cookieSecretRaw , err := loadToken ( o . cookieSecretFile ) if err != nil { logrus . WithError ( err ) . Fatal ( " " ) } var githubOAuthConfig config . GitHubOAuthConfig if err := yaml . Unmarshal ( githubOAuthConfigRaw , & githubOAuthConfig ) ; err != nil { logrus . WithError ( err ) . Fatal ( " " ) } if ! isValidatedGitOAuthConfig ( & githubOAuthConfig ) { logrus . Fatal ( " " ) } decodedSecret , err := base64 . StdEncoding . DecodeString ( string ( cookieSecretRaw ) ) if err != nil { logrus . WithError ( err ) . Fatal ( " " ) } if len ( decodedSecret ) == 0 { logrus . Fatal ( " " ) } cookie := sessions . NewCookieStore ( decodedSecret ) githubOAuthConfig . InitGitHubOAuthConfig ( cookie ) goa := githuboauth . NewAgent ( & githubOAuthConfig , logrus . WithField ( " " , " " ) ) oauthClient := & oauth2 . Config { ClientID : githubOAuthConfig . ClientID , ClientSecret : githubOAuthConfig . ClientSecret , RedirectURL : githubOAuthConfig . RedirectURL , Scopes : githubOAuthConfig . Scopes , Endpoint : github . Endpoint , } repoSet := make ( map [ string ] bool ) for r := range cfg ( ) . Presubmits { repoSet [ r ] = true } for _ , q := range cfg ( ) . Tide . Queries { for _ , v := range q . Repos { repoSet [ v ] = true } } var repos [ ] string for k , v := range repoSet { if v { repos = append ( repos , k ) } } prStatusAgent := prstatus . NewDashboardAgent ( repos , & githubOAuthConfig , logrus . WithField ( " " , " " ) ) mux . Handle ( " " , handleNotCached ( prStatusAgent . HandlePrStatus ( prStatusAgent ) ) ) } redirectMux . Handle ( " " , func ( oldMux * http . ServeMux , host string ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { if r . Header . Get ( " " ) == " " { redirectURL , err := url . Parse ( r . URL . String ( ) ) if err != nil { logrus . Errorf ( " " , r . URL . String ( ) ) http . Error ( w , " " , http . StatusInternalServerError ) return } redirectURL . Scheme = " " redirectURL . Host = host http . Redirect ( w , r , redirectURL . String ( ) , http . StatusMovedPermanently ) } else { oldMux . ServeHTTP ( w , r ) } } } ( mux , o . redirectHTTPTo ) ) mux = redirectMux } return mux } 
func dupeRequest ( original * http . Request ) * http . Request { r2 := new ( http . Request ) * r2 = * original r2 . URL = new ( url . URL ) * r2 . URL = * original . URL return r2 } 
func handleBadge ( ja * jobs . JobAgent ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { setHeadersNoCaching ( w ) wantJobs := r . URL . Query ( ) . Get ( " " ) if wantJobs == " " { http . Error ( w , " " , http . StatusBadRequest ) return } w . Header ( ) . Set ( " " , " " ) allJobs := ja . ProwJobs ( ) _ , _ , svg := renderBadge ( pickLatestJobs ( allJobs , wantJobs ) ) w . Write ( svg ) } } 
func handleJobHistory ( o options , cfg config . Getter , gcsClient * storage . Client ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { setHeadersNoCaching ( w ) tmpl , err := getJobHistory ( r . URL , cfg ( ) , gcsClient ) if err != nil { msg := fmt . Sprintf ( " " , err ) logrus . WithField ( " " , r . URL ) . Error ( msg ) http . Error ( w , msg , http . StatusInternalServerError ) return } handleSimpleTemplate ( o , cfg , " " , tmpl ) ( w , r ) } } 
func handleRequestJobViews ( sg * spyglass . Spyglass , cfg config . Getter , o options ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { start := time . Now ( ) setHeadersNoCaching ( w ) src := strings . TrimPrefix ( r . URL . Path , " " ) page , err := renderSpyglass ( sg , cfg , src , o ) if err != nil { logrus . WithError ( err ) . Error ( " " ) message := fmt . Sprintf ( " " , err ) http . Error ( w , message , http . StatusInternalServerError ) return } fmt . Fprint ( w , page ) elapsed := time . Since ( start ) logrus . WithFields ( logrus . Fields { " " : elapsed . String ( ) , " " : r . URL . Path , " " : src , } ) . Info ( " " ) } } 
func renderSpyglass ( sg * spyglass . Spyglass , cfg config . Getter , src string , o options ) ( string , error ) { renderStart := time . Now ( ) src = strings . TrimSuffix ( src , " " ) realPath , err := sg . ResolveSymlink ( src ) if err != nil { return " " , fmt . Errorf ( " " , err ) } src = realPath artifactNames , err := sg . ListArtifacts ( src ) if err != nil { return " " , fmt . Errorf ( " " , err ) } if len ( artifactNames ) == 0 { return " " , fmt . Errorf ( " " , src ) } viewerCache := map [ string ] [ ] string { } viewersRegistry := cfg ( ) . Deck . Spyglass . Viewers regexCache := cfg ( ) . Deck . Spyglass . RegexCache for re , viewerNames := range viewersRegistry { matches := [ ] string { } for _ , a := range artifactNames { if regexCache [ re ] . MatchString ( a ) { matches = append ( matches , a ) } } if len ( matches ) > 0 { for _ , vName := range viewerNames { viewerCache [ vName ] = matches } } } ls := sg . Lenses ( viewerCache ) lensNames := [ ] string { } for _ , l := range ls { lensNames = append ( lensNames , l . Config ( ) . Name ) } jobHistLink := " " jobPath , err := sg . JobPath ( src ) if err == nil { jobHistLink = path . Join ( " " , jobPath ) } artifactsLink := " " gcswebPrefix := cfg ( ) . Deck . Spyglass . GCSBrowserPrefix if gcswebPrefix != " " { runPath , err := sg . RunPath ( src ) if err == nil { artifactsLink = gcswebPrefix + runPath } } } prHistLink := " " org , repo , number , err := sg . RunToPR ( src ) if err == nil { prHistLink = " " + org + " " + repo + " " + strconv . Itoa ( number ) } jobName , buildID , err := sg . KeyToJob ( src ) if err != nil { return " " , fmt . Errorf ( " " , err ) } announcement := " " if cfg ( ) . Deck . Spyglass . Announcement != " " { announcementTmpl , err := template . New ( " " ) . Parse ( cfg ( ) . Deck . Spyglass . Announcement ) if err != nil { return " " , fmt . Errorf ( " " , err ) } runPath , err := sg . RunPath ( src ) if err != nil { runPath = " " } var announcementBuf bytes . Buffer err = announcementTmpl . Execute ( & announcementBuf , struct { ArtifactPath string } { ArtifactPath : runPath , } ) if err != nil { return " " , fmt . Errorf ( " " , err ) } announcement = announcementBuf . String ( ) } tgLink , err := sg . TestGridLink ( src ) if err != nil { tgLink = " " } extraLinks , err := sg . ExtraLinks ( src ) if err != nil { logrus . WithError ( err ) . WithField ( " " , src ) . Warn ( " " ) extraLinks = nil } var viewBuf bytes . Buffer type lensesTemplate struct { Lenses [ ] lenses . Lens LensNames [ ] string Source string LensArtifacts map [ string ] [ ] string JobHistLink string ArtifactsLink string PRHistLink string Announcement template . HTML TestgridLink string JobName string BuildID string ExtraLinks [ ] spyglass . ExtraLink } lTmpl := lensesTemplate { Lenses : ls , LensNames : lensNames , Source : src , LensArtifacts : viewerCache , JobHistLink : jobHistLink , ArtifactsLink : artifactsLink , PRHistLink : prHistLink , Announcement : template . HTML ( announcement ) , TestgridLink : tgLink , JobName : jobName , BuildID : buildID , ExtraLinks : extraLinks , } t := template . New ( " " ) if _ , err := prepareBaseTemplate ( o , cfg , t ) ; err != nil { return " " , fmt . Errorf ( " " , err ) } t , err = t . ParseFiles ( path . Join ( o . templateFilesLocation , " " ) ) if err != nil { return " " , fmt . Errorf ( " " , err ) } if err = t . Execute ( & viewBuf , lTmpl ) ; err != nil { return " " , fmt . Errorf ( " " , err ) } renderElapsed := time . Since ( renderStart ) logrus . WithFields ( logrus . Fields { " " : renderElapsed . String ( ) , " " : src , } ) . Info ( " " ) return viewBuf . String ( ) , nil } 
func handleArtifactView ( o options , sg * spyglass . Spyglass , cfg config . Getter ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { setHeadersNoCaching ( w ) pathSegments := strings . Split ( r . URL . Path , " " ) if len ( pathSegments ) != 2 { http . NotFound ( w , r ) return } lensName := pathSegments [ 0 ] resource := pathSegments [ 1 ] lens , err := lenses . GetLens ( lensName ) if err != nil { http . Error ( w , fmt . Sprintf ( " " , lensName , err ) , http . StatusNotFound ) return } lensConfig := lens . Config ( ) lensResourcesDir := lenses . ResourceDirForLens ( o . spyglassFilesLocation , lensConfig . Name ) reqString := r . URL . Query ( ) . Get ( " " ) var request spyglass . LensRequest err = json . Unmarshal ( [ ] byte ( reqString ) , & request ) if err != nil { http . Error ( w , fmt . Sprintf ( " " , err ) , http . StatusBadRequest ) return } artifacts , err := sg . FetchArtifacts ( request . Source , " " , cfg ( ) . Deck . Spyglass . SizeLimit , request . Artifacts ) if err != nil { http . Error ( w , fmt . Sprintf ( " " , err ) , http . StatusInternalServerError ) return } switch resource { case " " : t , err := template . ParseFiles ( path . Join ( o . templateFilesLocation , " " ) ) if err != nil { http . Error ( w , fmt . Sprintf ( " " , err ) , http . StatusInternalServerError ) return } w . Header ( ) . Set ( " " , " " ) t . Execute ( w , struct { Title string BaseURL string Head template . HTML Body template . HTML } { lensConfig . Title , " " + lensName + " " , template . HTML ( lens . Header ( artifacts , lensResourcesDir ) ) , template . HTML ( lens . Body ( artifacts , lensResourcesDir , " " ) ) , } ) case " " : data , err := ioutil . ReadAll ( r . Body ) if err != nil { http . Error ( w , fmt . Sprintf ( " " , err ) , http . StatusInternalServerError ) return } w . Header ( ) . Set ( " " , " " ) w . Write ( [ ] byte ( lens . Body ( artifacts , lensResourcesDir , string ( data ) ) ) ) case " " : data , err := ioutil . ReadAll ( r . Body ) if err != nil { http . Error ( w , fmt . Sprintf ( " " , err ) , http . StatusInternalServerError ) return } w . Write ( [ ] byte ( lens . Callback ( artifacts , lensResourcesDir , string ( data ) ) ) ) default : http . NotFound ( w , r ) } } } 
func handleLog ( lc logClient ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { setHeadersNoCaching ( w ) w . Header ( ) . Set ( " " , " " ) job := r . URL . Query ( ) . Get ( " " ) id := r . URL . Query ( ) . Get ( " " ) logger := logrus . WithFields ( logrus . Fields { " " : job , " " : id } ) if err := validateLogRequest ( r ) ; err != nil { http . Error ( w , err . Error ( ) , http . StatusBadRequest ) return } log , err := lc . GetJobLog ( job , id ) if err != nil { http . Error ( w , fmt . Sprintf ( " " , err ) , http . StatusNotFound ) logger := logger . WithError ( err ) msg := " " if strings . Contains ( err . Error ( ) , " " ) { } else { logger . Warning ( msg ) } return } if _ , err = w . Write ( log ) ; err != nil { logger . WithError ( err ) . Warning ( " " ) } } } 
func newCoverageList ( name string ) * CoverageList { return & CoverageList { Coverage : & Coverage { Name : name } , Group : [ ] Coverage { } , } } 
func ( covList * CoverageList ) summarize ( ) { covList . NumCoveredStmts = 0 covList . NumAllStmts = 0 for _ , item := range covList . Group { covList . NumCoveredStmts += item . NumCoveredStmts covList . NumAllStmts += item . NumAllStmts } } 
func ( covList * CoverageList ) Subset ( prefix string ) * CoverageList { s := newCoverageList ( " " ) for _ , c := range covList . Group { if strings . HasPrefix ( c . Name , prefix ) { covList . Group = append ( covList . Group , c ) } } return s } 
func ( covList CoverageList ) ListDirectories ( ) [ ] string { dirSet := map [ string ] bool { } for _ , cov := range covList . Group { dirSet [ path . Dir ( cov . Name ) ] = true } var result [ ] string for key := range dirSet { result = append ( result , key ) } return result } 
func readRequest ( r io . Reader , contentType string ) ( * admissionapi . AdmissionRequest , error ) { if contentType != contentTypeJSON { return nil , fmt . Errorf ( " " , contentType , contentTypeJSON ) } } body , err := ioutil . ReadAll ( r ) if err != nil { return nil , fmt . Errorf ( " " , err ) } deserializer := codecs . UniversalDeserializer ( ) if _ , _ , err := deserializer . Decode ( body , nil , & ar ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } return ar . Request , nil } 
func handle ( w http . ResponseWriter , r * http . Request ) { req , err := readRequest ( r . Body , r . Header . Get ( " " ) ) if err != nil { logrus . WithError ( err ) . Error ( " " ) } if err := writeResponse ( * req , w , onlyUpdateStatus ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } } 
func writeResponse ( ar admissionapi . AdmissionRequest , w io . Writer , decide decider ) error { response , err := decide ( ar ) if err != nil { logrus . WithError ( err ) . Error ( " " ) response = & admissionapi . AdmissionResponse { Result : & meta . Status { Message : err . Error ( ) , } , } } var result admissionapi . AdmissionReview result . Response = response result . Response . UID = ar . UID out , err := json . Marshal ( result ) if err != nil { return fmt . Errorf ( " " , err ) } if _ , err := w . Write ( out ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func onlyUpdateStatus ( req admissionapi . AdmissionRequest ) ( * admissionapi . AdmissionResponse , error ) { logger := logrus . WithFields ( logrus . Fields { " " : req . Resource , " " : req . SubResource , " " : req . Name , " " : req . Namespace , " " : req . Operation , } ) return & allow , nil } if _ , _ , err := codecs . UniversalDeserializer ( ) . Decode ( req . Object . Raw , nil , & new ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } var old prowjobv1 . ProwJob if _ , _ , err := codecs . UniversalDeserializer ( ) . Decode ( req . OldObject . Raw , nil , & old ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } if equality . Semantic . DeepEqual ( old . Spec , new . Spec ) { logrus . Info ( " " ) return & allow , nil } logger . Info ( " " ) return & reject , nil } 
func convertSuiteMeta ( suiteMeta gcs . SuitesMeta ) resultstore . Suite { out := resultstore . Suite { Name : path . Base ( suiteMeta . Path ) , Files : [ ] resultstore . File { { ContentType : " " , ID : resultstore . UUID ( ) , URL : suiteMeta . Path , for _ , suite := range suiteMeta . Suites . Suites { child := resultstore . Suite { Name : suite . Name , Duration : dur ( suite . Time ) , } switch { case suite . Failures > 0 && suite . Tests >= suite . Failures : child . Failures = append ( child . Failures , resultstore . Failure { Message : fmt . Sprintf ( " " , suite . Failures , suite . Tests , float64 ( suite . Tests - suite . Failures ) * 100.0 / float64 ( suite . Tests ) ) , } ) case suite . Failures > 0 : child . Failures = append ( child . Failures , resultstore . Failure { Message : fmt . Sprintf ( " " , suite . Failures ) , } ) } for _ , result := range suite . Results { name , tags := stripTags ( result . Name ) class := result . ClassName if class == " " { class = strings . Join ( tags , " " ) } else { class += " " + strings . Join ( tags , " " ) } c := resultstore . Case { Name : name , Class : class , Duration : dur ( result . Time ) , Result : resultstore . Completed , } const max = 5000 msg := result . Message ( max ) switch { case result . Failure != nil : } c . Failures = append ( c . Failures , resultstore . Failure { Message : msg , } ) case result . Skipped != nil : c . Result = resultstore . Skipped if msg != " " { } } child . Cases = append ( child . Cases , c ) if c . Duration > child . Duration { child . Duration = c . Duration } } if child . Duration > out . Duration { } out . Suites = append ( out . Suites , child ) } return out } 
func convert ( project , details string , url gcs . Path , result downloadResult ) ( resultstore . Invocation , resultstore . Target , resultstore . Test ) { started := result . started finished := result . finished artifacts := result . artifactURLs basePath := trailingSlash ( url . String ( ) ) artifactsPath := basePath + " " buildLog := basePath + " " bucket := url . Bucket ( ) inv := resultstore . Invocation { Project : project , Details : details , Files : [ ] resultstore . File { { ID : resultstore . InvocationLog , ContentType : " " , URL : buildLog , for i , a := range artifacts { artifacts [ i ] = " " + bucket + " " + a } for _ , a := range artifacts { } if a == buildLog { continue } inv . Files = append ( inv . Files , resultstore . File { ID : uniqPath ( a ) , ContentType : " " , URL : a , } ) } if started . Timestamp > 0 { inv . Start = time . Unix ( started . Timestamp , 0 ) if finished . Timestamp != nil { inv . Duration = time . Duration ( * finished . Timestamp - started . Timestamp ) * time . Second } } const day = 24 * 60 * 60 switch { case finished . Timestamp == nil && started . Timestamp < time . Now ( ) . Unix ( ) + day : inv . Status = resultstore . Running inv . Description = " " case finished . Passed != nil && * finished . Passed : inv . Status = resultstore . Passed inv . Description = " " case finished . Timestamp == nil : inv . Status = resultstore . Failed inv . Description = " " default : inv . Status = resultstore . Failed inv . Description = " " } test := resultstore . Test { Action : resultstore . Action { Node : started . Node , } , Suite : resultstore . Suite { Name : " " , Files : [ ] resultstore . File { { ID : resultstore . TargetLog , ContentType : " " , URL : buildLog , for _ , suiteMeta := range result . suiteMetas { child := convertSuiteMeta ( suiteMeta ) test . Suite . Suites = append ( test . Suite . Suites , child ) test . Suite . Files = append ( test . Suite . Files , child . Files ... ) } for _ , a := range artifacts { if ! strings . HasPrefix ( a , artifactsPath ) { continue } if a == buildLog { continue } for _ , sm := range result . suiteMetas { if sm . Path == a { found = true break } } if found { continue } test . Suite . Files = append ( test . Suite . Files , resultstore . File { ID : uniqPath ( a ) , ContentType : " " , URL : a , } ) } test . Suite . Start = inv . Start test . Action . Start = inv . Start test . Suite . Duration = inv . Duration test . Action . Duration = inv . Duration test . Status = inv . Status test . Description = inv . Description target := resultstore . Target { Start : inv . Start , Duration : inv . Duration , Status : inv . Status , Description : inv . Description , } return inv , target , test } 
func NewHealth ( ) * Health { healthMux := http . NewServeMux ( ) healthMux . HandleFunc ( " " , func ( w http . ResponseWriter , r * http . Request ) { fmt . Fprint ( w , " " ) } ) go func ( ) { logrus . WithError ( http . ListenAndServe ( " " + strconv . Itoa ( healthPort ) , healthMux ) ) . Fatal ( " " ) } ( ) return & Health { healthMux : healthMux , } } 
func ( h * Health ) ServeReady ( ) { h . healthMux . HandleFunc ( " " , func ( w http . ResponseWriter , r * http . Request ) { fmt . Fprint ( w , " " ) } ) } 
func NewController ( ghcSync , ghcStatus * github . Client , prowJobClient prowv1 . ProwJobInterface , cfg config . Getter , gc * git . Client , maxRecordsPerPool int , opener io . Opener , historyURI , statusURI string , logger * logrus . Entry ) ( * Controller , error ) { if logger == nil { logger = logrus . NewEntry ( logrus . StandardLogger ( ) ) } hist , err := history . New ( maxRecordsPerPool , opener , historyURI ) if err != nil { return nil , fmt . Errorf ( " " , historyURI , err ) } sc := & statusController { logger : logger . WithField ( " " , " " ) , ghc : ghcStatus , config : cfg , newPoolPending : make ( chan bool , 1 ) , shutDown : make ( chan bool ) , opener : opener , path : statusURI , } go sc . run ( ) return & Controller { logger : logger . WithField ( " " , " " ) , ghc : ghcSync , prowJobClient : prowJobClient , config : cfg , gc : gc , sc : sc , changedFiles : & changedFilesAgent { ghc : ghcSync , nextChangeCache : make ( map [ changeCacheKey ] [ ] string ) , } , History : hist , } , nil } 
func byRepoAndNumber ( prs [ ] PullRequest ) map [ string ] PullRequest { m := make ( map [ string ] PullRequest ) for _ , pr := range prs { key := prKey ( & pr ) m [ key ] = pr } return m } 
func newExpectedContext ( c string ) Context { return Context { Context : githubql . String ( c ) , State : githubql . StatusStateExpected , Description : githubql . String ( " " ) , } } 
func contextsToStrings ( contexts [ ] Context ) [ ] string { var names [ ] string for _ , c := range contexts { names = append ( names , string ( c . Context ) ) } return names } 
func ( c * Controller ) Sync ( ) error { start := time . Now ( ) defer func ( ) { duration := time . Since ( start ) c . logger . WithField ( " " , duration . String ( ) ) . Info ( " " ) tideMetrics . syncDuration . Set ( duration . Seconds ( ) ) } ( ) defer c . changedFiles . prune ( ) c . logger . Debug ( " " ) prs := make ( map [ string ] PullRequest ) for _ , query := range c . config ( ) . Tide . Queries { q := query . Query ( ) results , err := search ( c . ghc . Query , c . logger , q , time . Time { } , time . Now ( ) ) if err != nil && len ( results ) == 0 { return fmt . Errorf ( " " , q , err ) } if err != nil { c . logger . WithError ( err ) . WithField ( " " , q ) . Warning ( " " ) } for _ , pr := range results { prs [ prKey ( & pr ) ] = pr } } c . logger . WithField ( " " , time . Since ( start ) . String ( ) , ) . Debugf ( " " , len ( prs ) ) var pjs [ ] prowapi . ProwJob var blocks blockers . Blockers var err error if len ( prs ) > 0 { start := time . Now ( ) pjList , err := c . prowJobClient . List ( metav1 . ListOptions { LabelSelector : labels . Everything ( ) . String ( ) } ) if err != nil { c . logger . WithField ( " " , time . Since ( start ) . String ( ) ) . Debug ( " " ) return err } c . logger . WithField ( " " , time . Since ( start ) . String ( ) ) . Debug ( " " ) pjs = pjList . Items if label := c . config ( ) . Tide . BlockerLabel ; label != " " { c . logger . Debugf ( " " , label ) orgExcepts , repos := c . config ( ) . Tide . Queries . OrgExceptionsAndRepos ( ) orgs := make ( [ ] string , 0 , len ( orgExcepts ) ) for org := range orgExcepts { orgs = append ( orgs , org ) } orgRepoQuery := orgRepoQueryString ( orgs , repos . UnsortedList ( ) , orgExcepts ) blocks , err = blockers . FindAll ( c . ghc , c . logger , label , orgRepoQuery ) if err != nil { return err } } } if err != nil { return err } filteredPools := c . filterSubpools ( c . config ( ) . Tide . MaxGoroutines , rawPools ) c . sc . poolPRs = poolPRMap ( filteredPools ) select { case c . sc . newPoolPending <- true : default : } c . sc . Unlock ( ) subpoolsInParallel ( c . config ( ) . Tide . MaxGoroutines , filteredPools , func ( sp * subpool ) { pool , err := c . syncSubpool ( * sp , blocks . GetApplicable ( sp . org , sp . repo , sp . branch ) ) if err != nil { sp . log . WithError ( err ) . Errorf ( " " ) } poolChan <- pool } , ) close ( poolChan ) pools := make ( [ ] Pool , 0 , len ( poolChan ) ) for pool := range poolChan { pools = append ( pools , pool ) } sortPools ( pools ) c . m . Lock ( ) c . pools = pools c . m . Unlock ( ) c . History . Flush ( ) return nil } 
func ( c * Controller ) filterSubpools ( goroutines int , raw map [ string ] * subpool ) map [ string ] * subpool { filtered := make ( map [ string ] * subpool ) var lock sync . Mutex subpoolsInParallel ( goroutines , raw , func ( sp * subpool ) { if err := c . initSubpoolData ( sp ) ; err != nil { sp . log . WithError ( err ) . Error ( " " ) return } key := poolKey ( sp . org , sp . repo , sp . branch ) if spFiltered := filterSubpool ( c . ghc , sp ) ; spFiltered != nil { sp . log . WithField ( " " , key ) . WithField ( " " , spFiltered ) . Debug ( " " ) lock . Lock ( ) filtered [ key ] = spFiltered lock . Unlock ( ) } else { sp . log . WithField ( " " , key ) . WithField ( " " , spFiltered ) . Debug ( " " ) } } , ) return filtered } 
func filterSubpool ( ghc githubClient , sp * subpool ) * subpool { var toKeep [ ] PullRequest for _ , pr := range sp . prs { if ! filterPR ( ghc , sp , & pr ) { toKeep = append ( toKeep , pr ) } } if len ( toKeep ) == 0 { return nil } sp . prs = toKeep return sp } 
func filterPR ( ghc githubClient , sp * subpool , pr * PullRequest ) bool { log := sp . log . WithFields ( pr . logFields ( ) ) return true } if err != nil { log . WithError ( err ) . Error ( " " ) return true } presubmitsHaveContext := func ( context string ) bool { for _ , job := range sp . presubmits [ int ( pr . Number ) ] { if job . Context == context { return true } } return false } for _ , ctx := range unsuccessfulContexts ( contexts , sp . cc , log ) { if ctx . State != githubql . StatusStatePending { log . WithField ( " " , ctx . Context ) . Debug ( " " ) return true } if ! presubmitsHaveContext ( string ( ctx . Context ) ) { log . WithField ( " " , ctx . Context ) . Debug ( " " ) return true } } return false } 
func poolPRMap ( subpoolMap map [ string ] * subpool ) map [ string ] PullRequest { prs := make ( map [ string ] PullRequest ) for _ , sp := range subpoolMap { for _ , pr := range sp . prs { prs [ prKey ( & pr ) ] = pr } } return prs } 
func unsuccessfulContexts ( contexts [ ] Context , cc contextChecker , log * logrus . Entry ) [ ] Context { var failed [ ] Context for _ , ctx := range contexts { if string ( ctx . Context ) == statusContext { continue } if cc . IsOptional ( string ( ctx . Context ) ) { continue } if ctx . State != githubql . StatusStateSuccess { failed = append ( failed , ctx ) } } for _ , c := range cc . MissingRequiredContexts ( contextsToStrings ( contexts ) ) { failed = append ( failed , newExpectedContext ( c ) ) } log . Debugf ( " " , len ( contexts ) , contextsToStrings ( contexts ) , len ( failed ) , contextsToStrings ( failed ) ) return failed } 
func accumulateBatch ( presubmits map [ int ] [ ] config . Presubmit , prs [ ] PullRequest , pjs [ ] prowapi . ProwJob , log * logrus . Entry ) ( [ ] PullRequest , [ ] PullRequest ) { log . Debug ( " " ) if len ( presubmits ) == 0 { log . Debug ( " " ) return nil , nil } prNums := make ( map [ int ] PullRequest ) for _ , pr := range prs { prNums [ int ( pr . Number ) ] = pr } type accState struct { prs [ ] PullRequest jobStates map [ string ] simpleState } states := make ( map [ string ] * accState ) for _ , pj := range pjs { if pj . Spec . Type != prowapi . BatchJob { continue } if _ , ok := states [ ref ] ; ! ok { state := & accState { jobStates : make ( map [ string ] simpleState ) , validPulls : true , } for _ , pull := range pj . Spec . Refs . Pulls { if pr , ok := prNums [ pull . Number ] ; ok && string ( pr . HeadRefOID ) == pull . SHA { state . prs = append ( state . prs , pr ) } else if ! ok { state . validPulls = false log . WithField ( " " , ref ) . WithFields ( pr . logFields ( ) ) . Debug ( " " ) break } else { state . validPulls = false log . WithField ( " " , ref ) . WithFields ( pr . logFields ( ) ) . Debug ( " " ) break } } states [ ref ] = state } if ! states [ ref ] . validPulls { } jobState := toSimpleState ( pj . Status . State ) } } var pendingBatch , successBatch [ ] PullRequest for ref , state := range states { if ! state . validPulls { continue } requiredPresubmits := sets . NewString ( ) for _ , pr := range state . prs { for _ , job := range presubmits [ int ( pr . Number ) ] { requiredPresubmits . Insert ( job . Context ) } } overallState := successState for _ , p := range requiredPresubmits . List ( ) { if s , ok := state . jobStates [ p ] ; ! ok || s == failureState { overallState = failureState log . WithField ( " " , ref ) . Debugf ( " " , p ) break } else if s == pendingState && overallState == successState { overallState = pendingState } } switch overallState { case successState : successBatch = state . prs } } return successBatch , pendingBatch } 
func accumulate ( presubmits map [ int ] [ ] config . Presubmit , prs [ ] PullRequest , pjs [ ] prowapi . ProwJob , log * logrus . Entry ) ( successes , pendings , nones [ ] PullRequest ) { for _ , pr := range prs { for _ , pj := range pjs { if pj . Spec . Type != prowapi . PresubmitJob { continue } if pj . Spec . Refs . Pulls [ 0 ] . Number != int ( pr . Number ) { continue } if pj . Spec . Refs . Pulls [ 0 ] . SHA != string ( pr . HeadRefOID ) { continue } name := pj . Spec . Context oldState := psStates [ name ] newState := toSimpleState ( pj . Status . State ) if oldState == failureState || oldState == " " { psStates [ name ] = newState } else if oldState == pendingState && newState == successState { psStates [ name ] = successState } } for _ , ps := range presubmits [ int ( pr . Number ) ] { if s , ok := psStates [ ps . Context ] ; ! ok { overallState = failureState log . WithFields ( pr . logFields ( ) ) . Debugf ( " " , ps . Context ) break } else if s == failureState { overallState = failureState log . WithFields ( pr . logFields ( ) ) . Debugf ( " " , ps . Context ) break } else if s == pendingState { log . WithFields ( pr . logFields ( ) ) . Debugf ( " " , ps . Context ) overallState = pendingState } } if overallState == successState { successes = append ( successes , pr ) } else if overallState == pendingState { pendings = append ( pendings , pr ) } else { nones = append ( nones , pr ) } } return } 
func tryMerge ( mergeFunc func ( ) error ) ( bool , error ) { var err error const maxRetries = 3 backoff := time . Second * 4 for retry := 0 ; retry < maxRetries ; retry ++ { if err = mergeFunc ( ) ; err == nil { } } else if _ , ok = err . ( github . UnmergablePRBaseChangedError ) ; ok { if retry + 1 < maxRetries { sleep ( backoff ) backoff *= 2 } } else if _ , ok = err . ( github . UnauthorizedToPushError ) ; ok { } else if _ , ok = err . ( github . MergeCommitsForbiddenError ) ; ok { } else if _ , ok = err . ( github . UnmergablePRError ) ; ok { return true , fmt . Errorf ( " " , err ) } else { return true , err } } } 
func ( c * changedFilesAgent ) prChanges ( pr * PullRequest ) config . ChangedFilesProvider { return func ( ) ( [ ] string , error ) { cacheKey := changeCacheKey { org : string ( pr . Repository . Owner . Login ) , repo : string ( pr . Repository . Name ) , number : int ( pr . Number ) , sha : string ( pr . HeadRefOID ) , } c . RLock ( ) changedFiles , ok := c . changeCache [ cacheKey ] if ok { c . RUnlock ( ) c . Lock ( ) c . nextChangeCache [ cacheKey ] = changedFiles c . Unlock ( ) return changedFiles , nil } if changedFiles , ok = c . nextChangeCache [ cacheKey ] ; ok { c . RUnlock ( ) return changedFiles , nil } c . RUnlock ( ) if err != nil { return nil , fmt . Errorf ( " " , int ( pr . Number ) , err ) } changedFiles = make ( [ ] string , 0 , len ( changes ) ) for _ , change := range changes { changedFiles = append ( changedFiles , change . Filename ) } c . Lock ( ) c . nextChangeCache [ cacheKey ] = changedFiles c . Unlock ( ) return changedFiles , nil } } 
func ( c * changedFilesAgent ) prune ( ) { c . Lock ( ) defer c . Unlock ( ) c . changeCache = c . nextChangeCache c . nextChangeCache = make ( map [ changeCacheKey ] [ ] string ) } 
func ( c * Controller ) dividePool ( pool map [ string ] PullRequest , pjs [ ] prowapi . ProwJob ) ( map [ string ] * subpool , error ) { sps := make ( map [ string ] * subpool ) for _ , pr := range pool { org := string ( pr . Repository . Owner . Login ) repo := string ( pr . Repository . Name ) branch := string ( pr . BaseRef . Name ) branchRef := string ( pr . BaseRef . Prefix ) + string ( pr . BaseRef . Name ) fn := poolKey ( org , repo , branch ) if sps [ fn ] == nil { sha , err := c . ghc . GetRef ( org , repo , strings . TrimPrefix ( branchRef , " " ) ) if err != nil { return nil , err } sps [ fn ] = & subpool { log : c . logger . WithFields ( logrus . Fields { " " : org , " " : repo , " " : branch , " " : sha , } ) , org : org , repo : repo , branch : branch , sha : sha , } } sps [ fn ] . prs = append ( sps [ fn ] . prs , pr ) } for _ , pj := range pjs { if pj . Spec . Type != prowapi . PresubmitJob && pj . Spec . Type != prowapi . BatchJob { continue } fn := poolKey ( pj . Spec . Refs . Org , pj . Spec . Refs . Repo , pj . Spec . Refs . BaseRef ) if sps [ fn ] == nil || pj . Spec . Refs . BaseSHA != sps [ fn ] . sha { continue } sps [ fn ] . pjs = append ( sps [ fn ] . pjs , pj ) } return sps , nil } 
func headContexts ( log * logrus . Entry , ghc githubClient , pr * PullRequest ) ( [ ] Context , error ) { for _ , node := range pr . Commits . Nodes { if node . Commit . OID == pr . HeadRefOID { return node . Commit . Status . Contexts , nil } } repo := string ( pr . Repository . Name ) combined , err := ghc . GetCombinedStatus ( org , repo , string ( pr . HeadRefOID ) ) if err != nil { return nil , fmt . Errorf ( " " , err ) } contexts := make ( [ ] Context , 0 , len ( combined . Statuses ) ) for _ , status := range combined . Statuses { contexts = append ( contexts , Context { Context : githubql . String ( status . Context ) , Description : githubql . String ( status . Description ) , State : githubql . StatusState ( strings . ToUpper ( status . State ) ) , } , ) } return contexts , nil } 
func AggregateProfiles ( profiles [ ] [ ] * cover . Profile ) ( [ ] * cover . Profile , error ) { setProfiles := make ( [ ] [ ] * cover . Profile , 0 , len ( profiles ) ) for _ , p := range profiles { c := countToBoolean ( p ) setProfiles = append ( setProfiles , c ) } aggregateProfiles , err := MergeMultipleProfiles ( setProfiles ) if err != nil { return nil , err } return aggregateProfiles , nil } 
func countToBoolean ( profile [ ] * cover . Profile ) [ ] * cover . Profile { setProfile := make ( [ ] * cover . Profile , 0 , len ( profile ) ) for _ , p := range profile { pc := deepCopyProfile ( * p ) for i := range pc . Blocks { if pc . Blocks [ i ] . Count > 0 { pc . Blocks [ i ] . Count = 1 } } setProfile = append ( setProfile , & pc ) } return setProfile } 
func NewStorage ( r storage . PersistenceLayer , storage string ) ( * Storage , error ) { s := & Storage { resources : r , } if storage != " " { var data struct { Resources [ ] common . Resource } buf , err := ioutil . ReadFile ( storage ) if err == nil { logrus . Infof ( " " , string ( buf ) ) err = json . Unmarshal ( buf , & data ) if err != nil { return nil , err } } else if ! os . IsNotExist ( err ) { return nil , err } logrus . Info ( " " ) for _ , res := range data . Resources { if err := s . AddResource ( res ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , res . Name , res . State ) } logrus . Infof ( " " , res . Name , res . State ) } } return s , nil } 
func ( s * Storage ) AddResource ( resource common . Resource ) error { return s . resources . Add ( resource ) } 
func ( s * Storage ) DeleteResource ( name string ) error { return s . resources . Delete ( name ) } 
func ( s * Storage ) UpdateResource ( resource common . Resource ) error { return s . resources . Update ( resource ) } 
func ( s * Storage ) GetResource ( name string ) ( common . Resource , error ) { i , err := s . resources . Get ( name ) if err != nil { return common . Resource { } , err } var res common . Resource res , err = common . ItemToResource ( i ) if err != nil { return common . Resource { } , err } return res , nil } 
func ( s * Storage ) GetResources ( ) ( [ ] common . Resource , error ) { var resources [ ] common . Resource items , err := s . resources . List ( ) if err != nil { return resources , err } for _ , i := range items { var res common . Resource res , err = common . ItemToResource ( i ) if err != nil { return nil , err } resources = append ( resources , res ) } sort . Stable ( common . ResourceByUpdateTime ( resources ) ) return resources , nil } 
func ( s * Storage ) SyncResources ( data [ ] common . Resource ) error { s . resourcesLock . Lock ( ) defer s . resourcesLock . Unlock ( ) resources , err := s . GetResources ( ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return err } var finalError error for _ , res := range resources { valid ++ continue } toDelete := true for _ , newRes := range data { if res . Name == newRes . Name { resources [ valid ] = res valid ++ toDelete = false break } } if toDelete { logrus . Infof ( " " , res . Name ) if err := s . DeleteResource ( res . Name ) ; err != nil { finalError = multierror . Append ( finalError , err ) logrus . WithError ( err ) . Errorf ( " " , res . Name ) } } } resources = resources [ : valid ] for idx := range resources { exist := resources [ idx ] if p . Name == exist . Name { found = true logrus . Infof ( " " , p . Name ) break } } if ! found { if p . State == " " { p . State = common . Free } logrus . Infof ( " " , p . Name ) resources = append ( resources , p ) if err := s . AddResource ( p ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , p . Name ) finalError = multierror . Append ( finalError , err ) } } } return finalError } 
func ParseConfig ( configPath string ) ( [ ] common . Resource , error ) { file , err := ioutil . ReadFile ( configPath ) if err != nil { return nil , err } var data common . BoskosConfig err = yaml . Unmarshal ( file , & data ) if err != nil { return nil , err } var resources [ ] common . Resource for _ , entry := range data . Resources { resources = append ( resources , common . NewResourcesFromConfig ( entry ) ... ) } return resources , nil } 
func problemsInFiles ( r * git . Repo , files map [ string ] string ) ( map [ string ] [ ] string , error ) { problems := make ( map [ string ] [ ] string ) for f := range files { src , err := ioutil . ReadFile ( filepath . Join ( r . Dir , f ) ) if err != nil { return nil , err } if err != nil { return nil , fmt . Errorf ( " " , err ) } beforeRewrite := build . Format ( content ) var info build . RewriteInfo build . Rewrite ( content , & info ) ndata := build . Format ( content ) if ! bytes . Equal ( src , ndata ) && ! bytes . Equal ( src , beforeRewrite ) { } } return problems , nil } 
func NewPodLogArtifact ( jobName string , buildID string , sizeLimit int64 , ja jobAgent ) ( * PodLogArtifact , error ) { if jobName == " " { return nil , errInsufficientJobInfo } if buildID == " " { return nil , errInsufficientJobInfo } if sizeLimit < 0 { return nil , errInvalidSizeLimit } return & PodLogArtifact { name : jobName , buildID : buildID , sizeLimit : sizeLimit , jobAgent : ja , } , nil } 
func ( a * PodLogArtifact ) CanonicalLink ( ) string { q := url . Values { " " : [ ] string { a . name } , " " : [ ] string { a . buildID } , } u := url . URL { Path : " " , RawQuery : q . Encode ( ) , } return u . String ( ) } 
func ( a * PodLogArtifact ) ReadAt ( p [ ] byte , off int64 ) ( n int , err error ) { logs , err := a . jobAgent . GetJobLog ( a . name , a . buildID ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } r := bytes . NewReader ( logs ) readBytes , err := r . ReadAt ( p , off ) if err == io . EOF { return readBytes , io . EOF } if err != nil { return 0 , fmt . Errorf ( " " , err ) } return readBytes , nil } 
func ( a * PodLogArtifact ) ReadAll ( ) ( [ ] byte , error ) { size , err := a . Size ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if size > a . sizeLimit { return nil , lenses . ErrFileTooLarge } logs , err := a . jobAgent . GetJobLog ( a . name , a . buildID ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return logs , nil } 
func ( a * PodLogArtifact ) ReadAtMost ( n int64 ) ( [ ] byte , error ) { logs , err := a . jobAgent . GetJobLog ( a . name , a . buildID ) if err != nil { return nil , fmt . Errorf ( " " , err ) } reader := bytes . NewReader ( logs ) var byteCount int64 var p [ ] byte for byteCount < n { b , err := reader . ReadByte ( ) if err == io . EOF { return p , io . EOF } if err != nil { return nil , fmt . Errorf ( " " , err ) } p = append ( p , b ) byteCount ++ } return p , nil } 
func ( a * PodLogArtifact ) ReadTail ( n int64 ) ( [ ] byte , error ) { logs , err := a . jobAgent . GetJobLog ( a . name , a . buildID ) if err != nil { return nil , fmt . Errorf ( " " , err ) } size := int64 ( len ( logs ) ) var off int64 if n > size { off = 0 } else { off = size - n } p := make ( [ ] byte , n ) readBytes , err := bytes . NewReader ( logs ) . ReadAt ( p , off ) if err != nil && err != io . EOF { return nil , fmt . Errorf ( " " , err ) } return p [ : readBytes ] , nil } 
func ( a * PodLogArtifact ) Size ( ) ( int64 , error ) { logs , err := a . jobAgent . GetJobLog ( a . name , a . buildID ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } return int64 ( len ( logs ) ) , nil } 
func modifiedGoFiles ( ghc githubClient , org , repo string , number int , sha string ) ( map [ string ] string , error ) { changes , err := ghc . GetPullRequestChanges ( org , repo , number ) if err != nil { return nil , err } gfg , err := genfiles . NewGroup ( ghc , org , repo , sha ) if err != nil { return nil , err } modifiedFiles := make ( map [ string ] string ) for _ , change := range changes { switch { case strings . HasPrefix ( change . Filename , " " ) : continue case filepath . Ext ( change . Filename ) != " " : continue case gfg . Match ( change . Filename ) : continue case change . Status == github . PullRequestFileRemoved || change . Status == github . PullRequestFileRenamed : continue } modifiedFiles [ change . Filename ] = change . Patch } return modifiedFiles , nil } 
func newProblems ( cs [ ] github . ReviewComment , ps map [ string ] map [ int ] lint . Problem ) map [ string ] map [ int ] lint . Problem { for f , ls := range ps { res [ f ] = make ( map [ int ] lint . Problem ) for l , p := range ls { res [ f ] [ l ] = p } } for _ , c := range cs { if c . Position == nil { continue } if ! strings . Contains ( c . Body , commentTag ) { continue } delete ( res [ c . Path ] , * c . Position ) } return res } 
func problemsInFiles ( r * git . Repo , files map [ string ] string ) ( map [ string ] map [ int ] lint . Problem , [ ] github . DraftReviewComment ) { problems := make ( map [ string ] map [ int ] lint . Problem ) var lintErrorComments [ ] github . DraftReviewComment l := new ( lint . Linter ) for f , patch := range files { problems [ f ] = make ( map [ int ] lint . Problem ) src , err := ioutil . ReadFile ( filepath . Join ( r . Dir , f ) ) if err != nil { lintErrorComments = append ( lintErrorComments , github . DraftReviewComment { Path : f , Body : fmt . Sprintf ( " " , err ) , } ) } ps , err := l . Lint ( f , src ) if err != nil { reNumber := regexp . MustCompile ( `:([0-9]+):` ) matches := reNumber . FindStringSubmatch ( err . Error ( ) [ errLineIndexStart : ] ) newComment := github . DraftReviewComment { Path : f , Body : err . Error ( ) , } if len ( matches ) > 1 { errLineString := matches [ 1 ] errLine , errAtoi := strconv . Atoi ( errLineString ) if errAtoi == nil { newComment . Position = errLine } matches = reTrimError . FindStringSubmatch ( err . Error ( ) ) if len ( matches ) > 0 { newComment . Body = err . Error ( ) [ len ( matches [ 0 ] ) + errLineIndexStart : ] } } lintErrorComments = append ( lintErrorComments , newComment ) } al , err := AddedLines ( patch ) if err != nil { lintErrorComments = append ( lintErrorComments , github . DraftReviewComment { Path : f , Body : fmt . Sprintf ( " " , f , err ) , } ) } for _ , p := range ps { if pl , ok := al [ p . Position . Line ] ; ok { problems [ f ] [ pl ] = p } } } return problems , lintErrorComments } 
func AddedLines ( patch string ) ( map [ int ] int , error ) { result := make ( map [ int ] int ) if patch == " " { return result , nil } lines := strings . Split ( patch , " \n " ) for i := 0 ; i < len ( lines ) ; i ++ { } _ , oldLen , newLine , newLen , err := parseHunkLine ( lines [ i ] ) if err != nil { return nil , fmt . Errorf ( " " , i , patch , err ) } oldAdd := 0 newAdd := 0 for oldAdd < oldLen || newAdd < newLen { i ++ if i >= len ( lines ) { return nil , fmt . Errorf ( " " , patch ) } switch lines [ i ] [ 0 ] { case ' ' : oldAdd ++ newAdd ++ case '-' : oldAdd ++ case '+' : result [ newLine + newAdd ] = i newAdd ++ default : return nil , fmt . Errorf ( " " , i , patch ) } } } return result , nil } 
func undoPreset ( preset * config . Preset , labels map [ string ] string , pod * coreapi . PodSpec ) { } } for _ , e1 := range preset . Env { removeEnvNames . Insert ( e1 . Name ) } removeVolumeNames := sets . NewString ( ) for _ , volume := range preset . Volumes { removeVolumeNames . Insert ( volume . Name ) } removeVolumeMountNames := sets . NewString ( ) for _ , volumeMount := range preset . VolumeMounts { removeVolumeMountNames . Insert ( volumeMount . Name ) } for _ , volume := range pod . Volumes { if ! removeVolumeNames . Has ( volume . Name ) { filteredVolumes = append ( filteredVolumes , volume ) } } pod . Volumes = filteredVolumes for _ , env := range pod . Containers [ i ] . Env { if ! removeEnvNames . Has ( env . Name ) { filteredEnv = append ( filteredEnv , env ) } } pod . Containers [ i ] . Env = filteredEnv filteredVolumeMounts := [ ] coreapi . VolumeMount { } for _ , mount := range pod . Containers [ i ] . VolumeMounts { if ! removeVolumeMountNames . Has ( mount . Name ) { filteredVolumeMounts = append ( filteredVolumeMounts , mount ) } } pod . Containers [ i ] . VolumeMounts = filteredVolumeMounts } } 
func undoPresubmitPresets ( presets [ ] config . Preset , presubmit * config . Presubmit ) { if presubmit . Spec == nil { return } for _ , preset := range presets { undoPreset ( & preset , presubmit . Labels , presubmit . Spec ) } } 
func convertJobToSecurityJob ( j * config . Presubmit , dropLabels sets . String , defaultDecoration * prowapi . DecorationConfig , podNamespace string ) * config . Presubmit { } for k , v := range j . Labels { if ! dropLabels . Has ( fmt . Sprintf ( " " , k , v ) ) { filteredLabels [ k ] = v } } j . Labels = filteredLabels } originalName := j . Name j . RerunCommand = strings . Replace ( j . RerunCommand , " " , " " , - 1 ) j . Trigger = strings . Replace ( j . Trigger , " " , " " , - 1 ) j . Context = strings . Replace ( j . Context , " " , " " , - 1 ) if j . Namespace != nil && * j . Namespace == podNamespace { j . Namespace = nil } if j . DecorationConfig != nil { if reflect . DeepEqual ( j . DecorationConfig , defaultDecoration ) { j . DecorationConfig = nil } else if reflect . DeepEqual ( j . DecorationConfig . UtilityImages , defaultDecoration . UtilityImages ) { j . DecorationConfig . UtilityImages = nil } } container := & j . Spec . Containers [ 0 ] needGCSFlag := false needGCSSharedFlag := false needStagingFlag := false isGCPe2e := false for i , arg := range container . Args { if arg == " " { endsWithScenarioArgs = true needGCSSharedFlag = true } else if strings . HasPrefix ( arg , " " ) { needStagingFlag = true } else if strings . HasPrefix ( arg , " " ) { needGCSSharedFlag = true } } for _ , arg := range container . Args { if strings . HasPrefix ( arg , " " ) { scenario = strings . TrimPrefix ( arg , " " ) } } needGCSSharedFlag = true break } } } if scenario == " " { for _ , arg := range container . Args { if strings . Contains ( arg , " " ) { isGCPe2e = true } if strings . HasPrefix ( arg , " " ) { needStagingFlag = true } else if strings . HasPrefix ( arg , " " ) { needGCSSharedFlag = true } } } } if needGCSFlag { container . Args = append ( container . Args , " " + j . Name ) } if needGCSSharedFlag { container . Args = append ( container . Args , " " ) } if needStagingFlag { container . Args = append ( container . Args , " " + j . Name ) } } defaultMode := int32 ( 0400 ) j . Spec . Volumes = append ( j . Spec . Volumes , coreapi . Volume { Name : " " , VolumeSource : coreapi . VolumeSource { Secret : & coreapi . SecretVolumeSource { SecretName : " " , DefaultMode : & defaultMode , } , } , } , ) } return j } 
func yamlBytesStripNulls ( yamlBytes [ ] byte ) [ ] byte { nullRE := regexp . MustCompile ( " \n \n " ) return nullRE . ReplaceAll ( yamlBytes , [ ] byte { } ) } 
func ServePProf ( ) { pprofMux := http . NewServeMux ( ) pprofMux . HandleFunc ( " " , pprof . Index ) pprofMux . HandleFunc ( " " , pprof . Cmdline ) pprofMux . HandleFunc ( " " , pprof . Profile ) pprofMux . HandleFunc ( " " , pprof . Symbol ) pprofMux . HandleFunc ( " " , pprof . Trace ) go func ( ) { logrus . WithError ( http . ListenAndServe ( " " , pprofMux ) ) . Fatal ( " " ) } ( ) } 
func monitorDiskAndEvict ( c * diskcache . Cache , interval time . Duration , minPercentBlocksFree , evictUntilPercentBlocksFree float64 , ) { diskRoot := c . DiskRoot ( ) for ; true ; <- ticker . C { blocksFree , _ , _ , err := diskutil . GetDiskUsage ( diskRoot ) if err != nil { logrus . WithError ( err ) . Error ( " " ) continue } logger := logrus . WithFields ( logrus . Fields { " " : " " , " " : blocksFree , } ) logger . Info ( " " ) sort . Slice ( files , func ( i , j int ) bool { return files [ i ] . LastAccess . Before ( files [ j ] . LastAccess ) } ) } entry , files = files [ 0 ] , files [ 1 : ] err = c . Delete ( c . PathToKey ( entry . Path ) ) if err != nil { logger . WithError ( err ) . Errorf ( " " , entry . Path ) } else { promMetrics . FilesEvicted . Inc ( ) promMetrics . LastEvictedAccessAge . Set ( time . Now ( ) . Sub ( entry . LastAccess ) . Hours ( ) ) } logger = logrus . WithFields ( logrus . Fields { " " : " " , " " : blocksFree , } ) if err != nil { logrus . WithError ( err ) . Error ( " " ) continue } } logger . Info ( " " ) } } } 
func ( c * orgRepoConfig ) difference ( c2 * orgRepoConfig ) * orgRepoConfig { res := & orgRepoConfig { orgExceptions : make ( map [ string ] sets . String ) , repos : sets . NewString ( ) . Union ( c . repos ) , } for org , excepts1 := range c . orgExceptions { if excepts2 , ok := c2 . orgExceptions [ org ] ; ok { res . repos . Insert ( excepts2 . Difference ( excepts1 ) . UnsortedList ( ) ... ) } else { excepts := sets . NewString ( ) . Union ( excepts1 ) } } res . orgExceptions [ org ] = excepts } } res . repos = res . repos . Difference ( c2 . repos ) for _ , repo := range res . repos . UnsortedList ( ) { if parts := strings . SplitN ( repo , " " , 2 ) ; len ( parts ) == 2 { if excepts2 , ok := c2 . orgExceptions [ parts [ 0 ] ] ; ok && ! excepts2 . Has ( repo ) { res . repos . Delete ( repo ) } } } return res } 
func ( c * orgRepoConfig ) union ( c2 * orgRepoConfig ) * orgRepoConfig { res := & orgRepoConfig { orgExceptions : make ( map [ string ] sets . String ) , repos : sets . NewString ( ) , } for org , excepts1 := range c . orgExceptions { if excepts2 , ok := c2 . orgExceptions [ org ] ; ok { res . orgExceptions [ org ] = pruned . Intersection ( excepts2 . Difference ( c . repos ) ) } else { res . orgExceptions [ org ] = pruned } } for org , excepts2 := range c2 . orgExceptions { } } if len ( parts ) != 2 { logrus . Warnf ( " " , repo ) continue } if _ , exists := res . orgExceptions [ parts [ 0 ] ] ; ! exists { res . repos . Insert ( repo ) } } return res } 
func ensureValidConfiguration ( plugin , label , verb string , tideSubSet , tideSuperSet , pluginsSubSet * orgRepoConfig ) error { notEnabled := tideSubSet . difference ( pluginsSubSet ) . items ( ) notRequired := pluginsSubSet . intersection ( tideSuperSet ) . difference ( tideSubSet ) . items ( ) var configErrors [ ] error if len ( notEnabled ) > 0 { configErrors = append ( configErrors , fmt . Errorf ( " " , verb , label , plugin , notEnabled ) ) } if len ( notRequired ) > 0 { configErrors = append ( configErrors , fmt . Errorf ( " " , plugin , verb , label , notRequired ) ) } return errorutil . NewAggregate ( configErrors ... ) } 
func ( s * Strings ) Set ( value string ) error { if ! s . beenSet { s . beenSet = true } s . vals = append ( s . vals , value ) return nil } 
func clearStaleComments ( gc githubClient , log * logrus . Entry , pr * github . PullRequestEvent , prLabels sets . String , comments [ ] github . IssueComment ) error { } botName , err := gc . BotName ( ) if err != nil { return err } return gc . DeleteStaleComments ( pr . Repo . Owner . Login , pr . Repo . Name , pr . Number , comments , func ( c github . IssueComment ) bool { } , ) } 
func determineReleaseNoteLabel ( body string ) string { composedReleaseNote := strings . ToLower ( strings . TrimSpace ( getReleaseNote ( body ) ) ) if composedReleaseNote == " " { return ReleaseNoteLabelNeeded } if noneRe . MatchString ( composedReleaseNote ) { return releaseNoteNone } if strings . Contains ( composedReleaseNote , actionRequiredNote ) { return releaseNoteActionRequired } return releaseNote } 
func getReleaseNote ( body string ) string { potentialMatch := noteMatcherRE . FindStringSubmatch ( body ) if potentialMatch == nil { return " " } return strings . TrimSpace ( potentialMatch [ 1 ] ) } 
func NewClient ( boskosClient boskosClient ) * Client { return & Client { basic : boskosClient , resources : map [ string ] common . Resource { } , } } 
func ( c * Client ) Acquire ( rtype , state , dest string ) ( * common . Resource , error ) { var resourcesToRelease [ ] common . Resource releaseOnFailure := func ( ) { for _ , r := range resourcesToRelease { if err := c . basic . ReleaseOne ( r . Name , common . Dirty ) ; err != nil { logrus . WithError ( err ) . Warningf ( " " , r . Name ) } } } res , err := c . basic . Acquire ( rtype , state , dest ) if err != nil { return nil , err } var leasedResources common . LeasedResources if err = res . UserData . Extract ( LeasedResources , & leasedResources ) ; err != nil { if _ , ok := err . ( * common . UserDataNotFound ) ; ! ok { logrus . WithError ( err ) . Errorf ( " " , LeasedResources ) return nil , err } } resourcesToRelease = append ( resourcesToRelease , * res ) resources , err := c . basic . AcquireByState ( res . Name , dest , leasedResources ) if err != nil { releaseOnFailure ( ) return nil , err } resourcesToRelease = append ( resourcesToRelease , resources ... ) c . updateResource ( * res ) return res , nil } 
func ( c * Client ) ReleaseOne ( name , dest string ) ( allErrors error ) { res , err := c . getResource ( name ) if err != nil { allErrors = err return } resourceNames := [ ] string { name } var leasedResources common . LeasedResources if err := res . UserData . Extract ( LeasedResources , & leasedResources ) ; err != nil { if _ , ok := err . ( * common . UserDataNotFound ) ; ! ok { logrus . WithError ( err ) . Errorf ( " " , LeasedResources ) allErrors = multierror . Append ( allErrors , err ) if err := c . basic . ReleaseOne ( name , dest ) ; err != nil { logrus . WithError ( err ) . Warningf ( " " , name ) allErrors = multierror . Append ( allErrors , err ) } return } } resourceNames = append ( resourceNames , leasedResources ... ) for _ , n := range resourceNames { if err := c . basic . ReleaseOne ( n , dest ) ; err != nil { logrus . WithError ( err ) . Warningf ( " " , n ) allErrors = multierror . Append ( allErrors , err ) } } c . deleteResource ( name ) return } 
func ( c * Client ) UpdateAll ( state string ) error { return c . basic . UpdateAll ( state ) } 
func GetGitHubClient ( token string ) * github . Client { return github . NewClient ( oauth2 . NewClient ( oauth2 . NoContext , oauth2 . StaticTokenSource ( & oauth2 . Token { AccessToken : token } ) , ) , ) } 
func GetUsername ( client * github . Client ) ( string , error ) { user , _ , err := client . Users . Get ( context . Background ( ) , " " ) if err != nil { return " " , err } if user . Login == nil { return " " , errors . New ( " \" \" " ) } return * user . Login , nil } 
func CreateTokenHandler ( tokenStream io . Reader , influxdb * InfluxDB ) ( * TokenHandler , error ) { token , err := ioutil . ReadAll ( tokenStream ) if err != nil { return nil , err } client := GetGitHubClient ( strings . TrimSpace ( string ( token ) ) ) login , err := GetUsername ( client ) if err != nil { return nil , err } return & TokenHandler { gClient : client , login : login , influxdb : influxdb , } , nil } 
func CreateTokenHandlers ( tokenFiles [ ] string , influxdb * InfluxDB ) ( [ ] TokenHandler , error ) { tokens := [ ] TokenHandler { } for _ , tokenFile := range tokenFiles { f , err := os . Open ( tokenFile ) if err != nil { return nil , fmt . Errorf ( " " , tokenFile , err ) } token , err := CreateTokenHandler ( f , influxdb ) if err != nil { return nil , fmt . Errorf ( " " , tokenFile , err ) } tokens = append ( tokens , * token ) } return tokens , nil } 
func ( t TokenHandler ) Process ( ) { lastRate , err := t . getCoreRate ( ) if err != nil { glog . Fatalf ( " " , t . login , err ) } for { halfPeriod := lastRate . Reset . Time . Sub ( time . Now ( ) ) / 2 time . Sleep ( halfPeriod ) newRate , err := t . getCoreRate ( ) if err != nil { glog . Error ( " " , err ) continue } } for { newRate , err = t . getCoreRate ( ) if err == nil { break } glog . Error ( " " , err ) time . Sleep ( time . Minute ) } } lastRate = newRate } } 
func ( i * jobIndentifier ) String ( ) string { return fmt . Sprintf ( " " , i . job , i . organization , i . repository , i . pullRequest ) } 
func TerminateOlderPresubmitJobs ( pjc prowClient , log * logrus . Entry , pjs [ ] prowapi . ProwJob , cleanup ProwJobResourcesCleanup ) error { dupes := map [ jobIndentifier ] int { } for i , pj := range pjs { if pj . Complete ( ) || pj . Spec . Type != prowapi . PresubmitJob { continue } ji := jobIndentifier { job : pj . Spec . Job , organization : pj . Spec . Refs . Org , repository : pj . Spec . Refs . Repo , pullRequest : pj . Spec . Refs . Pulls [ 0 ] . Number , } prev , ok := dupes [ ji ] if ! ok { dupes [ ji ] = i continue } cancelIndex := i if ( & pjs [ prev ] . Status . StartTime ) . Before ( & pj . Status . StartTime ) { cancelIndex = prev dupes [ ji ] = i } toCancel := pjs [ cancelIndex ] } toCancel . SetComplete ( ) prevState := toCancel . Status . State toCancel . Status . State = prowapi . AbortedState log . WithFields ( ProwJobFields ( & toCancel ) ) . WithField ( " " , prevState ) . WithField ( " " , toCancel . Status . State ) . Info ( " " ) npj , err := pjc . ReplaceProwJob ( toCancel . ObjectMeta . Name , toCancel ) if err != nil { return err } pjs [ cancelIndex ] = npj } return nil } 
func PushMetrics ( component , endpoint string , interval time . Duration ) { sig := make ( chan os . Signal , 1 ) signal . Notify ( sig , os . Interrupt , syscall . SIGTERM ) for { select { case <- time . Tick ( interval ) : if err := push . FromGatherer ( component , push . HostnameGroupingKey ( ) , endpoint , prometheus . DefaultGatherer ) ; err != nil { logrus . WithField ( " " , component ) . WithError ( err ) . Error ( " " ) } case <- sig : logrus . WithField ( " " , component ) . Infof ( " " ) return } } } 
func handle ( gc gitHubClient , log * logrus . Entry , se github . StatusEvent ) error { if se . State == " " || se . Context == " " { return fmt . Errorf ( " " ) } if se . Context != claContextName { } if se . State == github . StatusPending { } org := se . Repo . Owner . Login repo := se . Repo . Name log . Info ( " " ) var issues [ ] github . Issue var err error for i := 0 ; i < maxRetries ; i ++ { issues , err = gc . FindIssues ( fmt . Sprintf ( " " , se . SHA , org , repo ) , " " , false ) if err != nil { return fmt . Errorf ( " " , err ) } if len ( issues ) > 0 { break } time . Sleep ( 10 * time . Second ) } log . Infof ( " " , len ( issues ) ) for _ , issue := range issues { l := log . WithField ( " " , issue . Number ) hasCncfYes := issue . HasLabel ( labels . ClaYes ) hasCncfNo := issue . HasLabel ( labels . ClaNo ) if hasCncfYes && se . State == github . StatusSuccess { continue } if hasCncfNo && ( se . State == github . StatusFailure || se . State == github . StatusError ) { continue } l . Info ( " " ) pr , err := gc . GetPullRequest ( org , repo , issue . Number ) if err != nil { l . WithError ( err ) . Warningf ( " " , issue . Number , org , repo ) continue } continue } number := pr . Number if se . State == github . StatusSuccess { if hasCncfNo { if err := gc . RemoveLabel ( org , repo , number , labels . ClaNo ) ; err != nil { l . WithError ( err ) . Warningf ( " " , labels . ClaNo ) } } if err := gc . AddLabel ( org , repo , number , labels . ClaYes ) ; err != nil { l . WithError ( err ) . Warningf ( " " , labels . ClaYes ) } continue } } } if err := gc . CreateComment ( org , repo , number , fmt . Sprintf ( cncfclaNotFoundMessage , plugins . AboutThisBot ) ) ; err != nil { l . WithError ( err ) . Warning ( " " ) } if err := gc . AddLabel ( org , repo , number , labels . ClaNo ) ; err != nil { l . WithError ( err ) . Warningf ( " " , labels . ClaNo ) } } return nil } 
func RateLimiter ( controllerName string ) workqueue . RateLimitingInterface { rl := workqueue . NewMaxOfRateLimiter ( workqueue . NewItemExponentialFailureRateLimiter ( 5 * time . Millisecond , 120 * time . Second ) , & workqueue . BucketRateLimiter { Limiter : rate . NewLimiter ( rate . Limit ( 1000 ) , 50000 ) } , ) return workqueue . NewNamedRateLimitingQueue ( rl , controllerName ) } 
func findRepo ( wd , path string ) ( string , error ) { opwd , err := realPath ( wd ) if err != nil { return " " , fmt . Errorf ( " " , err ) } if strings . HasPrefix ( path , " " ) { path = strings . Replace ( path , " " , " " , 1 ) } var old string pwd := opwd for old != pwd { old = pwd if strings . HasSuffix ( pwd , " " + path ) { return pwd , nil } pwd = filepath . Dir ( pwd ) } pwd = opwd for old != pwd { old = pwd check := filepath . Join ( pwd , path ) if info , err := os . Stat ( check ) ; err == nil && info . IsDir ( ) { return check , nil } pwd = filepath . Dir ( pwd ) } base := filepath . Base ( path ) pwd = opwd for old != pwd { old = pwd check := filepath . Join ( pwd , base ) if info , err := os . Stat ( check ) ; err == nil && info . IsDir ( ) { return check , nil } pwd = filepath . Dir ( pwd ) } return " " , errors . New ( " " ) } 
func checkCommitMessages ( gc gitHubClient , l * logrus . Entry , org , repo string , number int ) ( [ ] github . GitCommit , error ) { allCommits , err := gc . ListPRCommits ( org , repo , number ) if err != nil { return nil , fmt . Errorf ( " " , err ) } l . Debugf ( " " , len ( allCommits ) ) var commitsMissingDCO [ ] github . GitCommit for _ , commit := range allCommits { if ! testRe . MatchString ( commit . Commit . Message ) { c := commit . Commit c . SHA = commit . SHA commitsMissingDCO = append ( commitsMissingDCO , c ) } } l . Debugf ( " " , len ( commitsMissingDCO ) == 0 ) return commitsMissingDCO , nil } 
func checkExistingStatus ( gc gitHubClient , l * logrus . Entry , org , repo , sha string ) ( string , error ) { statuses , err := gc . ListStatuses ( org , repo , sha ) if err != nil { return " " , fmt . Errorf ( " " , err ) } existingStatus := " " for _ , status := range statuses { if status . Context != dcoContextName { continue } existingStatus = status . State break } l . Debugf ( " " , existingStatus ) return existingStatus , nil } 
func checkExistingLabels ( gc gitHubClient , l * logrus . Entry , org , repo string , number int ) ( hasYesLabel , hasNoLabel bool , err error ) { labels , err := gc . GetIssueLabels ( org , repo , number ) if err != nil { return false , false , fmt . Errorf ( " " , err ) } for _ , l := range labels { if l . Name == dcoYesLabel { hasYesLabel = true } if l . Name == dcoNoLabel { hasNoLabel = true } } return hasYesLabel , hasNoLabel , nil } 
func takeAction ( gc gitHubClient , cp commentPruner , l * logrus . Entry , org , repo string , pr github . PullRequest , commitsMissingDCO [ ] github . GitCommit , existingStatus string , hasYesLabel , hasNoLabel , addComment bool ) error { targetURL := fmt . Sprintf ( " " , org , repo ) signedOff := len ( commitsMissingDCO ) == 0 } } if ! hasYesLabel { l . Debugf ( " " , dcoYesLabel ) } } if existingStatus != github . StatusSuccess { l . Debugf ( " " ) if err := gc . CreateStatus ( org , repo , pr . Head . SHA , github . Status { Context : dcoContextName , State : github . StatusSuccess , TargetURL : targetURL , Description : dcoContextMessageSuccess , } ) ; err != nil { return fmt . Errorf ( " " , err ) } } cp . PruneComments ( shouldPrune ( l ) ) return nil } } } if hasYesLabel { l . Debugf ( " " , dcoYesLabel ) } } if existingStatus != github . StatusFailure { l . Debugf ( " " ) if err := gc . CreateStatus ( org , repo , pr . Head . SHA , github . Status { Context : dcoContextName , State : github . StatusFailure , TargetURL : targetURL , Description : dcoContextMessageFailed , } ) ; err != nil { return fmt . Errorf ( " " , err ) } } if addComment { l . Debugf ( " " ) if err := gc . CreateComment ( org , repo , pr . Number , fmt . Sprintf ( dcoNotFoundMessage , targetURL , MarkdownSHAList ( org , repo , commitsMissingDCO ) , plugins . AboutThisBot ) ) ; err != nil { l . WithError ( err ) . Warning ( " " ) } } return nil } 
func handle ( gc gitHubClient , cp commentPruner , log * logrus . Entry , org , repo string , pr github . PullRequest , addComment bool ) error { l := log . WithField ( " " , pr . Number ) commitsMissingDCO , err := checkCommitMessages ( gc , l , org , repo , pr . Number ) if err != nil { l . WithError ( err ) . Infof ( " " ) return err } existingStatus , err := checkExistingStatus ( gc , l , org , repo , pr . Head . SHA ) if err != nil { l . WithError ( err ) . Infof ( " " ) return err } hasYesLabel , hasNoLabel , err := checkExistingLabels ( gc , l , org , repo , pr . Number ) if err != nil { l . WithError ( err ) . Infof ( " " ) return err } return takeAction ( gc , cp , l , org , repo , pr , commitsMissingDCO , existingStatus , hasYesLabel , hasNoLabel , addComment ) } 
func MarkdownSHAList ( org , repo string , list [ ] github . GitCommit ) string { lines := make ( [ ] string , len ( list ) ) lineFmt := " " for i , commit := range list { if commit . SHA == " " { continue } if len ( shortSHA ) > 7 { shortSHA = shortSHA [ : 7 ] } lines [ i ] = fmt . Sprintf ( lineFmt , shortSHA , org , repo , commit . SHA , message ) } return strings . Join ( lines , " \n " ) } 
func shouldPrune ( log * logrus . Entry ) func ( github . IssueComment ) bool { return func ( comment github . IssueComment ) bool { return strings . Contains ( comment . Body , dcoMsgPruneMatch ) } } 
func PathForSpec ( spec * downwardapi . JobSpec , pathSegment RepoPathBuilder ) string { switch spec . Type { case prowapi . PeriodicJob , prowapi . PostsubmitJob : return path . Join ( NonPRLogs , spec . Job , spec . BuildID ) case prowapi . PresubmitJob : return path . Join ( PRLogs , " " , pathSegment ( spec . Refs . Org , spec . Refs . Repo ) , strconv . Itoa ( spec . Refs . Pulls [ 0 ] . Number ) , spec . Job , spec . BuildID ) case prowapi . BatchJob : return path . Join ( PRLogs , " " , " " , spec . Job , spec . BuildID ) default : logrus . Fatalf ( " " , spec . Type ) } return " " } 
func AliasForSpec ( spec * downwardapi . JobSpec ) string { switch spec . Type { case prowapi . PeriodicJob , prowapi . PostsubmitJob , prowapi . BatchJob : return " " case prowapi . PresubmitJob : return path . Join ( PRLogs , " " , spec . Job , fmt . Sprintf ( " " , spec . BuildID ) ) default : logrus . Fatalf ( " " , spec . Type ) } return " " } 
func RootForSpec ( spec * downwardapi . JobSpec ) string { switch spec . Type { case prowapi . PeriodicJob , prowapi . PostsubmitJob : return path . Join ( NonPRLogs , spec . Job ) case prowapi . PresubmitJob , prowapi . BatchJob : return path . Join ( PRLogs , " " , spec . Job ) default : logrus . Errorf ( " " , spec . Type ) } return " " } 
func NewSingleDefaultRepoPathBuilder ( defaultOrg , defaultRepo string ) RepoPathBuilder { return func ( org , repo string ) string { if org == defaultOrg && repo == defaultRepo { return " " } return fmt . Sprintf ( " " , org , repo ) } } 
func NewExplicitRepoPathBuilder ( ) RepoPathBuilder { return func ( org , repo string ) string { return fmt . Sprintf ( " " , org , repo ) } } 
func RegisterSourceOrDie ( name string , src IssueSource ) { if _ , ok := sources [ name ] ; ok { glog . Fatalf ( " " , name ) } sources [ name ] = src glog . Infof ( " " , name ) } 
func ( c * IssueCreator ) CreateAndSync ( ) { var err error if err = c . initialize ( ) ; err != nil { glog . Fatalf ( " " , err ) } glog . Info ( " " ) for srcName , src := range sources { glog . Infof ( " " , srcName ) var issues [ ] Issue if issues , err = src . Issues ( c ) ; err != nil { glog . Errorf ( " " , srcName , err ) continue } created := 0 for _ , issue := range issues { if c . sync ( issue ) { created ++ } } glog . Infof ( " " , created , len ( issues ) , srcName , ) } } 
func ( c * IssueCreator ) loadCache ( ) error { user , err := c . client . GetUser ( " " ) if err != nil { return fmt . Errorf ( " " , err ) } if user == nil { return fmt . Errorf ( " " ) } if user . Login == nil { return fmt . Errorf ( " " ) } c . authorName = * user . Login glog . Errorf ( " \n " , c . org , c . project , err ) } else { c . validLabels = make ( [ ] string , 0 , len ( validLabels ) ) for _ , label := range validLabels { if label . Name != nil && * label . Name != " " { c . validLabels = append ( c . validLabels , * label . Name ) } } } glog . Errorf ( " \n " , c . org , c . project , err ) } else { c . Collaborators = make ( [ ] string , 0 , len ( collaborators ) ) for _ , user := range collaborators { if user . Login != nil && * user . Login != " " { c . Collaborators = append ( c . Collaborators , strings . ToLower ( * user . Login ) ) } } } if err != nil { return fmt . Errorf ( " " , c . authorName , c . org , c . project , err ) } if len ( issues ) == 0 { glog . Warningf ( " \n " , c . org , c . project , c . authorName ) } c . allIssues = make ( map [ int ] * github . Issue ) for _ , i := range issues { c . allIssues [ * i . Number ] = i } return nil } 
func ( c * IssueCreator ) RegisterFlags ( ) { flag . StringVar ( & c . ownerPath , " " , " " , " " ) flag . IntVar ( & c . MaxSIGCount , " " , 3 , " " ) flag . IntVar ( & c . MaxAssignees , " " , 3 , " " ) flag . StringVar ( & c . tokenFile , " " , " " , " " ) flag . StringVar ( & c . project , " " , " " , " " ) flag . StringVar ( & c . org , " " , " " , " " ) flag . BoolVar ( & c . dryRun , " " , true , " " ) for _ , src := range sources { src . RegisterFlags ( ) } } 
func setIntersect ( a , b [ ] string ) ( filtered , removed [ ] string ) { for _ , elemA := range a { found := false for _ , elemB := range b { if elemA == elemB { found = true break } } if found { filtered = append ( filtered , elemA ) } else { removed = append ( removed , elemA ) } } return } 
func ( c * IssueCreator ) sync ( issue Issue ) bool { var closedIssues [ ] * github . Issue for _ , i := range c . allIssues { if strings . Contains ( * i . Body , id ) { switch * i . State { case " " : case " " : closedIssues = append ( closedIssues , i ) default : glog . Errorf ( " \n " , * i . State , * i . Number ) } } } if body == " " { return false } if ! strings . Contains ( body , id ) { glog . Fatalf ( " \n \n " , id , body ) } title := issue . Title ( ) owners := issue . Owners ( ) if c . Collaborators != nil { var removedOwners [ ] string owners , removedOwners = setIntersect ( owners , c . Collaborators ) if len ( removedOwners ) > 0 { glog . Errorf ( " " , title , removedOwners ) } } labels := issue . Labels ( ) if prio , ok := issue . Priority ( ) ; ok { labels = append ( labels , " " + prio ) } if c . validLabels != nil { var removedLabels [ ] string labels , removedLabels = setIntersect ( labels , c . validLabels ) if len ( removedLabels ) > 0 { glog . Errorf ( " " , title , removedLabels ) } } glog . Infof ( " \n " , title , owners ) if c . dryRun { return true } created , err := c . client . CreateIssue ( c . org , c . project , title , body , labels , owners ) if err != nil { glog . Errorf ( " \n " , id ) return false } c . allIssues [ * created . Number ] = created return true } 
func GetAWSCreds ( r * common . Resource ) ( credentials . Value , error ) { val := credentials . Value { } if r . Type != ResourceType { return val , fmt . Errorf ( " " , ResourceType , r . Type ) } accessKey , ok := r . UserData . Map . Load ( UserDataAccessIDKey ) if ! ok { return val , errors . New ( " " ) } secretKey , ok := r . UserData . Map . Load ( UserDataSecretAccessKey ) if ! ok { return val , errors . New ( " " ) } val . AccessKeyID = accessKey . ( string ) val . SecretAccessKey = secretKey . ( string ) return val , nil } 
func stopper ( ) chan struct { } { stop := make ( chan struct { } ) c := make ( chan os . Signal , 2 ) signal . Notify ( c , os . Interrupt , syscall . SIGTERM ) go func ( ) { <- c logrus . Warn ( " " ) close ( stop ) <- c logrus . Error ( " " ) os . Exit ( 1 ) } ( ) return stop } 
func newPipelineConfig ( cfg rest . Config , stop chan struct { } ) ( * pipelineConfig , error ) { bc , err := pipelineset . NewForConfig ( & cfg ) if err != nil { return nil , err } } bif . Tekton ( ) . V1alpha1 ( ) . PipelineRuns ( ) . Lister ( ) go bif . Start ( stop ) return & pipelineConfig { client : bc , informer : bif . Tekton ( ) . V1alpha1 ( ) . PipelineRuns ( ) , } , nil } 
func ( o * KubernetesClientOptions ) AddFlags ( fs * flag . FlagSet ) { fs . StringVar ( & o . masterURL , " " , " " , " " ) fs . StringVar ( & o . kubeConfig , " " , " " , " " ) } 
func ( o * KubernetesClientOptions ) Validate ( dryRun bool ) error { if dryRun && o . masterURL == " " { return errors . New ( " " ) } if o . masterURL != " " { if _ , err := url . ParseRequestURI ( o . masterURL ) ; err != nil { return fmt . Errorf ( " " , o . masterURL ) } } if o . kubeConfig != " " { if _ , err := os . Stat ( o . kubeConfig ) ; err != nil { return err } } return nil } 
func ( o * KubernetesClientOptions ) KubeClient ( ) ( kubernetes . Interface , error ) { return kube . GetKubernetesClient ( o . masterURL , o . kubeConfig ) } 
func ( o * KubernetesClientOptions ) ProwJobClient ( ) ( versioned . Interface , error ) { return kube . GetProwJobClient ( o . masterURL , o . kubeConfig ) } 
func ( bucket gcsBucket ) resolveSymLink ( symLink string ) ( string , error ) { data , err := bucket . readObject ( symLink ) if err != nil { return " " , fmt . Errorf ( " " , symLink , err ) } return prefixRe . ReplaceAllString ( u , " " ) , nil } 
func readJSON ( bucket storageBucket , key string , data interface { } ) error { rawData , err := bucket . readObject ( key ) if err != nil { return fmt . Errorf ( " " , key , err ) } err = json . Unmarshal ( rawData , & data ) if err != nil { return fmt . Errorf ( " " , key , err ) } return nil } 
func ( bucket gcsBucket ) listSubDirs ( prefix string ) ( [ ] string , error ) { if ! strings . HasSuffix ( prefix , " " ) { prefix += " " } dirs := [ ] string { } it := bucket . Objects ( context . Background ( ) , & storage . Query { Prefix : prefix , Delimiter : " " , } ) for { attrs , err := it . Next ( ) if err == iterator . Done { break } if err != nil { return dirs , err } if attrs . Prefix != " " { dirs = append ( dirs , attrs . Prefix ) } } return dirs , nil } 
func ( bucket gcsBucket ) listAll ( prefix string ) ( [ ] string , error ) { keys := [ ] string { } it := bucket . Objects ( context . Background ( ) , & storage . Query { Prefix : prefix , } ) for { attrs , err := it . Next ( ) if err == iterator . Done { break } if err != nil { return keys , err } keys = append ( keys , attrs . Name ) } return keys , nil } 
func ( bucket gcsBucket ) listBuildIDs ( root string ) ( [ ] int64 , error ) { ids := [ ] int64 { } if strings . HasPrefix ( root , logsPrefix ) { dirs , err := bucket . listSubDirs ( root ) if err != nil { return ids , fmt . Errorf ( " " , err ) } for _ , dir := range dirs { i , err := strconv . ParseInt ( path . Base ( dir ) , 10 , 64 ) if err == nil { ids = append ( ids , i ) } else { logrus . Warningf ( " " , dir ) } } } else { keys , err := bucket . listAll ( root ) if err != nil { return ids , fmt . Errorf ( " " , err ) } for _ , key := range keys { matches := linkRe . FindStringSubmatch ( key ) if len ( matches ) == 2 { i , err := strconv . ParseInt ( matches [ 1 ] , 10 , 64 ) if err == nil { ids = append ( ids , i ) } else { logrus . Warningf ( " " , key ) } } } } return ids , nil } 
func cropResults ( a [ ] int64 , max int64 ) ( [ ] int64 , int , int ) { res := [ ] int64 { } firstIndex := - 1 lastIndex := 0 for i , v := range a { if v <= max { res = append ( res , v ) if firstIndex == - 1 { firstIndex = i } lastIndex = i if len ( res ) >= resultsPerPage { break } } } return res , firstIndex , lastIndex } 
func getJobHistory ( url * url . URL , config * config . Config , gcsClient * storage . Client ) ( jobHistoryTemplate , error ) { start := time . Now ( ) tmpl := jobHistoryTemplate { } bucketName , root , top , err := parseJobHistURL ( url ) if err != nil { return tmpl , fmt . Errorf ( " " , url . String ( ) , err ) } tmpl . Name = root bucket := gcsBucket { bucketName , gcsClient . Bucket ( bucketName ) } latest , err := readLatestBuild ( bucket , root ) if err != nil { return tmpl , fmt . Errorf ( " " , err ) } if top == emptyID || top > latest { top = latest } if top != latest { tmpl . LatestLink = linkID ( url , emptyID ) } buildIDs , err := bucket . listBuildIDs ( root ) if err != nil { return tmpl , fmt . Errorf ( " " , err ) } sort . Sort ( sort . Reverse ( int64slice ( buildIDs ) ) ) if nextIndex >= 0 { next = buildIDs [ nextIndex ] } tmpl . NewerLink = linkID ( url , next ) } if lastIndex < len ( buildIDs ) - 1 { tmpl . OlderLink = linkID ( url , buildIDs [ lastIndex + 1 ] ) } tmpl . Builds = make ( [ ] buildData , len ( shownIDs ) ) tmpl . ResultsShown = len ( shownIDs ) tmpl . ResultsTotal = len ( buildIDs ) for i , buildID := range shownIDs { go func ( i int , buildID int64 ) { id := strconv . FormatInt ( buildID , 10 ) dir , err := bucket . getPath ( root , id , " " ) if err != nil { logrus . Errorf ( " " , err ) bch <- buildData { } return } b , err := getBuildData ( bucket , dir ) if err != nil { logrus . Warningf ( " " , buildID , err ) } b . index = i b . ID = id b . SpyglassLink , err = bucket . spyglassLink ( root , id ) if err != nil { logrus . Errorf ( " " , err ) } bch <- b } ( i , buildID ) } for i := 0 ; i < len ( shownIDs ) ; i ++ { b := <- bch tmpl . Builds [ b . index ] = b } elapsed := time . Now ( ) . Sub ( start ) logrus . Infof ( " " , url . Path , elapsed ) return tmpl , nil } 
func FilterProfilePaths ( profile [ ] * cover . Profile , paths [ ] string , include bool ) ( [ ] * cover . Profile , error ) { parenPaths := make ( [ ] string , len ( paths ) ) for i , path := range paths { parenPaths [ i ] = " " + path + " " } joined := strings . Join ( parenPaths , " " ) re , err := regexp . Compile ( joined ) if err != nil { return nil , err } result := make ( [ ] * cover . Profile , 0 , len ( profile ) ) for _ , p := range profile { if re . MatchString ( p . FileName ) == include { result = append ( result , p ) } } return result , nil } 
func handle ( gc githubClient , log * logrus . Entry , e * github . GenericCommentEvent , f hasLabelFunc ) error { if e . Action != github . GenericCommentActionCreated { return nil } needsLabel := false if labelRe . MatchString ( e . Body ) { needsLabel = true } else if labelCancelRe . MatchString ( e . Body ) { needsLabel = false } else { return nil } org := e . Repo . Owner . Login repo := e . Repo . Name issueLabels , err := gc . GetIssueLabels ( org , repo , e . Number ) if err != nil { return fmt . Errorf ( " " , org , repo , e . Number , err ) } hasLabel := f ( labels . Hold , issueLabels ) if hasLabel && ! needsLabel { log . Infof ( " " , labels . Hold , org , repo , e . Number ) return gc . RemoveLabel ( org , repo , e . Number , labels . Hold ) } else if ! hasLabel && needsLabel { log . Infof ( " " , labels . Hold , org , repo , e . Number ) return gc . AddLabel ( org , repo , e . Number , labels . Hold ) } return nil } 
func handle ( h * handler ) error { e := h . event org := e . Repo . Owner . Login repo := e . Repo . Name matches := h . regexp . FindAllStringSubmatch ( e . Body , - 1 ) if matches == nil { return nil } users := make ( map [ string ] bool ) for _ , re := range matches { add := re [ 1 ] != " " if re [ 2 ] == " " { users [ e . User . Login ] = add } else { for _ , login := range parseLogins ( re [ 2 ] ) { users [ login ] = add } } } var toAdd , toRemove [ ] string for login , add := range users { if add { toAdd = append ( toAdd , login ) } else { toRemove = append ( toRemove , login ) } } if len ( toRemove ) > 0 { h . log . Printf ( " " , h . userType , org , repo , e . Number , toRemove ) if err := h . remove ( org , repo , e . Number , toRemove ) ; err != nil { return err } } if len ( toAdd ) > 0 { h . log . Printf ( " " , h . userType , org , repo , e . Number , toAdd ) if err := h . add ( org , repo , e . Number , toAdd ) ; err != nil { if mu , ok := err . ( github . MissingUsers ) ; ok { msg := h . addFailureResponse ( mu ) if len ( msg ) == 0 { return nil } if err := h . gc . CreateComment ( org , repo , e . Number , plugins . FormatResponseRaw ( e . Body , e . HTMLURL , e . User . Login , msg ) ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } return err } } return nil } 
func LoadSecrets ( paths [ ] string ) ( map [ string ] [ ] byte , error ) { secretsMap := make ( map [ string ] [ ] byte , len ( paths ) ) for _ , path := range paths { secretValue , err := LoadSingleSecret ( path ) if err != nil { return nil , err } secretsMap [ path ] = secretValue } return secretsMap , nil } 
func LoadSingleSecret ( path string ) ( [ ] byte , error ) { b , err := ioutil . ReadFile ( path ) if err != nil { return nil , fmt . Errorf ( " " , path , err ) } return bytes . TrimSpace ( b ) , nil } 
func ( b * Bool ) Set ( s string ) error { v , err := strconv . ParseBool ( s ) if err != nil { return err } b . Explicit = true b . Value = v return nil } 
func NewOpener ( ctx context . Context , creds string ) ( Opener , error ) { var options [ ] option . ClientOption if creds != " " { options = append ( options , option . WithCredentialsFile ( creds ) ) } client , err := storage . NewClient ( ctx , options ... ) if err != nil { if creds != " " { return nil , err } logrus . WithError ( err ) . Debug ( " " ) client = nil } return opener { gcs : client } , nil } 
func IsNotExist ( err error ) bool { return os . IsNotExist ( err ) || err == storage . ErrObjectNotExist } 
func LogClose ( c io . Closer ) { if err := c . Close ( ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } } 
func ( o opener ) Reader ( ctx context . Context , path string ) ( io . ReadCloser , error ) { g , err := o . openGCS ( path ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if g == nil { return os . Open ( path ) } return g . NewReader ( ctx ) } 
func ( o opener ) Writer ( ctx context . Context , path string ) ( io . WriteCloser , error ) { g , err := o . openGCS ( path ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if g == nil { return os . Create ( path ) } return g . NewWriter ( ctx ) , nil } 
func ( gac * GitHubOAuthConfig ) InitGitHubOAuthConfig ( cookie * sessions . CookieStore ) { gob . Register ( & oauth2 . Token { } ) gac . CookieStore = cookie } 
func deltaDisplayed ( change * coverageChange ) string { if change . baseRatio < 0 { return " " } return fmt . Sprintf ( " " , ( change . newRatio - change . baseRatio ) * 100 ) } 
func makeTable ( baseCovList , newCovList * calculation . CoverageList , coverageThreshold float32 ) ( string , bool ) { var rows [ ] string isCoverageLow := false for _ , change := range findChanges ( baseCovList , newCovList ) { filePath := change . name rows = append ( rows , fmt . Sprintf ( " " , filePath , formatPercentage ( change . baseRatio ) , formatPercentage ( change . newRatio ) , deltaDisplayed ( change ) ) ) if change . newRatio < coverageThreshold { isCoverageLow = true } } return strings . Join ( rows , " \n " ) , isCoverageLow } 
func ContentForGitHubPost ( baseProfiles , newProfiles [ ] * cover . Profile , jobName string , coverageThreshold float32 ) ( string , bool ) { rows := [ ] string { " " , fmt . Sprintf ( " " , jobName ) , " " , " " , " " , } table , isCoverageLow := makeTable ( calculation . ProduceCovList ( baseProfiles ) , calculation . ProduceCovList ( newProfiles ) , coverageThreshold ) if table == " " { return " " , false } rows = append ( rows , table ) rows = append ( rows , " " ) return strings . Join ( rows , " \n " ) , isCoverageLow } 
func ( client * Client ) AddFlags ( cmd * cobra . Command ) { cmd . PersistentFlags ( ) . StringVar ( & client . Token , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & client . TokenFile , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & client . Org , " " , " " , " " ) cmd . PersistentFlags ( ) . StringVar ( & client . Project , " " , " " , " " ) } 
func ( client * Client ) CheckFlags ( ) error { if client . Org == " " { return fmt . Errorf ( " " ) } client . Org = strings . ToLower ( client . Org ) if client . Project == " " { return fmt . Errorf ( " " ) } client . Project = strings . ToLower ( client . Project ) return nil } 
func ( client * Client ) getGitHubClient ( ) ( * github . Client , error ) { if client . githubClient != nil { return client . githubClient , nil } token := client . Token if len ( token ) == 0 && len ( client . TokenFile ) != 0 { data , err := ioutil . ReadFile ( client . TokenFile ) if err != nil { return nil , err } token = strings . TrimSpace ( string ( data ) ) } if len ( token ) > 0 { ts := oauth2 . StaticTokenSource ( & oauth2 . Token { AccessToken : token } ) tc := oauth2 . NewClient ( oauth2 . NoContext , ts ) client . githubClient = github . NewClient ( tc ) } else { client . githubClient = github . NewClient ( nil ) } return client . githubClient , nil } 
func ( client * Client ) limitsCheckAndWait ( ) { var sleep time . Duration githubClient , err := client . getGitHubClient ( ) if err != nil { glog . Error ( " " , err ) sleep = time . Minute } else { limits , _ , err := githubClient . RateLimits ( context . Background ( ) ) if err != nil { glog . Error ( " " , err ) sleep = time . Minute } if limits != nil && limits . Core != nil && limits . Core . Remaining < tokenLimit { sleep = limits . Core . Reset . Sub ( time . Now ( ) ) glog . Warning ( " " , sleep ) } } time . Sleep ( sleep ) } 
func ( client * Client ) RepositoryName ( ) string { return fmt . Sprintf ( " " , client . Org , client . Project ) } 
func ( client * Client ) FetchIssues ( latest time . Time , c chan * github . Issue ) { opt := & github . IssueListByRepoOptions { Since : latest , Sort : " " , State : " " , Direction : " " } githubClient , err := client . getGitHubClient ( ) if err != nil { close ( c ) glog . Error ( err ) return } count := 0 for { client . limitsCheckAndWait ( ) issues , resp , err := githubClient . Issues . ListByRepo ( context . Background ( ) , client . Org , client . Project , opt , ) if err != nil { close ( c ) glog . Error ( err ) return } for _ , issue := range issues { c <- issue count ++ } if resp . NextPage == 0 { break } opt . ListOptions . Page = resp . NextPage } glog . Infof ( " " , count , latest ) close ( c ) } 
func hasID ( events [ ] * github . IssueEvent , id int ) bool { for _ , event := range events { if * event . ID == int64 ( id ) { return true } } return false } 
func ( client * Client ) FetchIssueEvents ( issueID int , latest * int , c chan * github . IssueEvent ) { opt := & github . ListOptions { PerPage : 100 } githubClient , err := client . getGitHubClient ( ) if err != nil { close ( c ) glog . Error ( err ) return } count := 0 for { client . limitsCheckAndWait ( ) events , resp , err := githubClient . Issues . ListIssueEvents ( context . Background ( ) , client . Org , client . Project , issueID , opt , ) if err != nil { glog . Errorf ( " " , err ) time . Sleep ( time . Second ) continue } for _ , event := range events { c <- event count ++ } if resp . NextPage == 0 || ( latest != nil && hasID ( events , * latest ) ) { break } opt . Page = resp . NextPage } glog . Infof ( " " , count ) close ( c ) } 
func ( client * Client ) FetchIssueComments ( issueID int , latest time . Time , c chan * github . IssueComment ) { opt := & github . IssueListCommentsOptions { Since : latest , Sort : " " , Direction : " " } githubClient , err := client . getGitHubClient ( ) if err != nil { close ( c ) glog . Error ( err ) return } count := 0 for { client . limitsCheckAndWait ( ) comments , resp , err := githubClient . Issues . ListComments ( context . Background ( ) , client . Org , client . Project , issueID , opt , ) if err != nil { close ( c ) glog . Error ( err ) return } for _ , comment := range comments { c <- comment count ++ } if resp . NextPage == 0 { break } opt . ListOptions . Page = resp . NextPage } glog . Infof ( " " , count , latest , issueID ) close ( c ) } 
func isPRChanged ( pe github . PullRequestEvent ) bool { switch pe . Action { case github . PullRequestActionOpened : return true case github . PullRequestActionReopened : return true case github . PullRequestActionSynchronize : return true case github . PullRequestActionEdited : return true default : return false } } 
func NewFetcher ( repository string ) * Fetcher { return & Fetcher { IssuesChannel : make ( chan sql . Issue , 100 ) , EventsCommentsChannel : make ( chan interface { } , 100 ) , repository : repository , } } 
func ( f * Fetcher ) fetchRecentIssues ( db * gorm . DB ) error { glog . Infof ( " " , f . lastIssue ) var issues [ ] sql . Issue query := db . Where ( " " , f . lastIssue ) . Where ( " " , f . repository ) . Order ( " " ) . Preload ( " " ) . Find ( & issues ) if query . Error != nil { return query . Error } count := len ( issues ) for _ , issue := range issues { f . IssuesChannel <- issue f . lastIssue = issue . IssueUpdatedAt } glog . Infof ( " " , count ) return nil } 
func ( f * Fetcher ) fetchRecentEventsAndComments ( db * gorm . DB ) error { glog . Infof ( " " , f . lastEvent ) glog . Infof ( " " , f . lastComment ) eventRows , err := db . Model ( sql . IssueEvent { } ) . Where ( " " , f . repository ) . Where ( " " , f . lastEvent ) . Order ( " " ) . Rows ( ) if err != nil { return fmt . Errorf ( " " , err ) } commentRows , err := db . Model ( sql . Comment { } ) . Where ( " " , f . repository ) . Where ( " " , f . lastComment ) . Order ( " " ) . Rows ( ) if err != nil { return fmt . Errorf ( " " , err ) } count := 0 comment := & sql . Comment { } if commentRows . Next ( ) { db . ScanRows ( commentRows , comment ) } else { comment = nil } event := & sql . IssueEvent { } if eventRows . Next ( ) { db . ScanRows ( eventRows , event ) } else { event = nil } for event != nil || comment != nil { if event == nil || ( comment != nil && comment . CommentCreatedAt . Before ( event . EventCreatedAt ) ) { f . EventsCommentsChannel <- * comment f . lastComment = comment . CommentCreatedAt if commentRows . Next ( ) { db . ScanRows ( commentRows , comment ) } else { comment = nil } } else { f . EventsCommentsChannel <- * event f . lastEvent = event . EventCreatedAt if eventRows . Next ( ) { db . ScanRows ( eventRows , event ) } else { event = nil } } count ++ } glog . Infof ( " " , count ) return nil } 
func ( f * Fetcher ) Fetch ( db * gorm . DB ) error { if err := f . fetchRecentIssues ( db ) ; err != nil { return err } if err := f . fetchRecentEventsAndComments ( db ) ; err != nil { return err } return nil } 
func zoneIsManaged ( z * route53 . HostedZone ) bool { if " " == name { return true } klog . Infof ( " " , name ) return false } 
func resourceRecordSetIsManaged ( rrs * route53 . ResourceRecordSet ) bool { if " " != aws . StringValue ( rrs . Type ) { return false } name := aws . StringValue ( rrs . Name ) for _ , managedNameRegex := range managedNameRegexes { if managedNameRegex . MatchString ( name ) { return true } } klog . Infof ( " " , name ) return false } 
func ( fjr * FlakyJobReporter ) RegisterFlags ( ) { flag . StringVar ( & fjr . flakyJobDataURL , " " , " " , " " ) flag . IntVar ( & fjr . syncCount , " " , 3 , " " ) } 
func ( fjr * FlakyJobReporter ) Issues ( c * creator . IssueCreator ) ( [ ] creator . Issue , error ) { fjr . creator = c json , err := ReadHTTP ( fjr . flakyJobDataURL ) if err != nil { return nil , err } flakyJobs , err := fjr . parseFlakyJobs ( json ) if err != nil { return nil , err } count := fjr . syncCount if len ( flakyJobs ) < count { count = len ( flakyJobs ) } issues := make ( [ ] creator . Issue , 0 , count ) for _ , fj := range flakyJobs [ 0 : count ] { issues = append ( issues , fj ) } return issues , nil } 
func ( fjr * FlakyJobReporter ) parseFlakyJobs ( jsonIn [ ] byte ) ( [ ] * FlakyJob , error ) { var flakeMap map [ string ] * FlakyJob err := json . Unmarshal ( jsonIn , & flakeMap ) if err != nil || flakeMap == nil { return nil , fmt . Errorf ( " " , err ) } flakyJobs := make ( [ ] * FlakyJob , 0 , len ( flakeMap ) ) for job , fj := range flakeMap { if job == " " { glog . Errorf ( " \n " ) continue } if fj == nil { glog . Errorf ( " \n " , job ) continue } if fj . Consistency == nil { glog . Errorf ( " \n " , job ) continue } if fj . FlakeCount == nil { glog . Errorf ( " \n " , job ) continue } if fj . FlakyTests == nil { glog . Errorf ( " \n " , job ) continue } fj . Name = job fj . reporter = fjr flakyJobs = append ( flakyJobs , fj ) } sort . SliceStable ( flakyJobs , func ( i , j int ) bool { if * flakyJobs [ i ] . FlakeCount == * flakyJobs [ j ] . FlakeCount { return * flakyJobs [ i ] . Consistency < * flakyJobs [ j ] . Consistency } return * flakyJobs [ i ] . FlakeCount > * flakyJobs [ j ] . FlakeCount } ) return flakyJobs , nil } 
func ( fj * FlakyJob ) Title ( ) string { return fmt . Sprintf ( " " , fj . Name , * fj . FlakeCount ) } 
func ( fj * FlakyJob ) Body ( closedIssues [ ] * githubapi . Issue ) string { for _ , closed := range closedIssues { if closed . ClosedAt . After ( cutoffTime ) { return " " } } fmt . Fprintf ( & buf , " \n \n \n " , fj . ID ( ) , * fj . FlakeCount , * fj . Consistency * 100 ) if len ( fj . FlakyTests ) > 0 { fmt . Fprint ( & buf , " \n \n \n \n " ) for _ , testName := range fj . TestsSorted ( ) { fmt . Fprintf ( & buf , " \n " , testName , fj . FlakyTests [ testName ] ) } } for _ , closed := range closedIssues { fmt . Fprintf ( & buf , " " , * closed . Number ) } fmt . Fprint ( & buf , " \n " ) } ownersMap := fj . reporter . creator . TestsOwners ( testsSorted ) if len ( ownersMap ) > 0 { fmt . Fprint ( & buf , " \n " ) for user := range ownersMap { fmt . Fprintf ( & buf , " " , user ) } fmt . Fprint ( & buf , " \n " ) } fmt . Fprintf ( & buf , " \n \n " , fj . reporter . flakyJobDataURL ) fmt . Fprintf ( & buf , " \n \n " ) return buf . String ( ) } 
func ( fj * FlakyJob ) Labels ( ) [ ] string { labels := [ ] string { " " } } return labels } 
func ReadHTTP ( url string ) ( [ ] byte , error ) { var err error retryDelay := time . Duration ( 2 ) * time . Second for retryCount := 0 ; retryCount < 5 ; retryCount ++ { if retryCount > 0 { time . Sleep ( retryDelay ) retryDelay *= time . Duration ( 2 ) } resp , err := http . Get ( url ) if resp != nil && resp . StatusCode >= 500 { } if err != nil { return nil , err } defer resp . Body . Close ( ) body , err := ioutil . ReadAll ( resp . Body ) if err != nil { continue } return body , nil } return nil , fmt . Errorf ( " " , url , err ) } 
func ( l linesByTimestamp ) String ( ) string { sort . Sort ( l ) var log string for i , line := range l { switch i { case len ( l ) - 1 : log += string ( line . actual ) default : } } return fmt . Sprintf ( " " , log ) } 
func handleMetric ( boskos * client . Client ) http . HandlerFunc { return func ( res http . ResponseWriter , req * http . Request ) { log := logrus . WithField ( " " , " " ) log . Infof ( " " , req . RemoteAddr ) if req . Method != " " { log . Warningf ( " " , req . Method ) http . Error ( res , " " , http . StatusMethodNotAllowed ) return } rtype := req . URL . Query ( ) . Get ( " " ) if rtype == " " { msg := " " log . Warning ( msg ) http . Error ( res , msg , http . StatusBadRequest ) return } log . Infof ( " " , rtype ) metric , err := boskos . Metric ( rtype ) if err != nil { log . WithError ( err ) . Errorf ( " " , rtype ) http . Error ( res , err . Error ( ) , http . StatusNotFound ) return } metricJSON , err := json . Marshal ( metric ) if err != nil { log . WithError ( err ) . Errorf ( " " , metricJSON ) http . Error ( res , err . Error ( ) , http . StatusInternalServerError ) return } log . Infof ( " " , rtype , string ( metricJSON ) ) fmt . Fprint ( res , string ( metricJSON ) ) } } 
func loadClusterConfig ( masterURL , kubeConfig string ) ( * rest . Config , error ) { clusterConfig , err := clientcmd . BuildConfigFromFlags ( masterURL , kubeConfig ) if err == nil { return clusterConfig , nil } credentials , err := clientcmd . NewDefaultClientConfigLoadingRules ( ) . Load ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } clusterConfig , err = clientcmd . NewDefaultClientConfig ( * credentials , & clientcmd . ConfigOverrides { } ) . ClientConfig ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return clusterConfig , nil } 
func GetKubernetesClient ( masterURL , kubeConfig string ) ( kubernetes . Interface , error ) { config , err := loadClusterConfig ( masterURL , kubeConfig ) if err != nil { return nil , err } if err != nil { return nil , err } logrus . Info ( " " ) return client , nil } 
func GetProwJobClient ( masterURL , kubeConfig string ) ( prowjobclientset . Interface , error ) { config , err := loadClusterConfig ( masterURL , kubeConfig ) if err != nil { return nil , err } prowjobClient , err := prowjobclientset . NewForConfig ( config ) if err != nil { return nil , err } logrus . Info ( " " ) return prowjobClient , nil } 
func parsePattern ( p string ) ( Pattern , error ) { res := pattern { } } } } if strings . Contains ( p , patternDirSep ) { res . isPath = true } res . pattern = strings . Split ( p , patternDirSep ) return & res , nil } 
func ( o * Options ) Validate ( ) error { ents := o . entries ( ) if len ( ents ) == 0 { return errors . New ( " " ) } for i , e := range ents { if err := e . Validate ( ) ; err != nil { return fmt . Errorf ( " " , i , err ) } } return o . GcsOptions . Validate ( ) } 
func ( o * Options ) AddFlags ( flags * flag . FlagSet ) { o . GcsOptions . AddFlags ( flags ) // DeprecatedWrapperOptions flags should be unused, remove immediately } 
func NewJobSpec ( spec prowapi . ProwJobSpec , buildID , prowJobID string ) JobSpec { return JobSpec { Type : spec . Type , Job : spec . Job , BuildID : buildID , ProwJobID : prowJobID , Refs : spec . Refs , ExtraRefs : spec . ExtraRefs , agent : spec . Agent , } } 
func ResolveSpecFromEnv ( ) ( * JobSpec , error ) { specEnv , ok := os . LookupEnv ( JobSpecEnv ) if ! ok { return nil , fmt . Errorf ( " " , JobSpecEnv ) } spec := & JobSpec { } if err := json . Unmarshal ( [ ] byte ( specEnv ) , spec ) ; err != nil { return nil , fmt . Errorf ( " " , JobSpecEnv , err ) } return spec , nil } 
func EnvForSpec ( spec JobSpec ) ( map [ string ] string , error ) { env := map [ string ] string { jobNameEnv : spec . Job , buildIDEnv : spec . BuildID , prowJobIDEnv : spec . ProwJobID , jobTypeEnv : string ( spec . Type ) , } } raw , err := json . Marshal ( spec ) if err != nil { return env , fmt . Errorf ( " " , err ) } env [ JobSpecEnv ] = string ( raw ) if spec . Type == prowapi . PeriodicJob { return env , nil } env [ repoOwnerEnv ] = spec . Refs . Org env [ repoNameEnv ] = spec . Refs . Repo env [ pullBaseRefEnv ] = spec . Refs . BaseRef env [ pullBaseShaEnv ] = spec . Refs . BaseSHA env [ pullRefsEnv ] = spec . Refs . String ( ) if spec . Type == prowapi . PostsubmitJob || spec . Type == prowapi . BatchJob { return env , nil } env [ pullNumberEnv ] = strconv . Itoa ( spec . Refs . Pulls [ 0 ] . Number ) env [ pullPullShaEnv ] = spec . Refs . Pulls [ 0 ] . SHA return env , nil } 
func EnvForType ( jobType prowapi . ProwJobType ) [ ] string { baseEnv := [ ] string { jobNameEnv , JobSpecEnv , jobTypeEnv , prowJobIDEnv , buildIDEnv , prowBuildIDEnv } refsEnv := [ ] string { repoOwnerEnv , repoNameEnv , pullBaseRefEnv , pullBaseShaEnv , pullRefsEnv } pullEnv := [ ] string { pullNumberEnv , pullPullShaEnv } switch jobType { case prowapi . PeriodicJob : return baseEnv case prowapi . PostsubmitJob , prowapi . BatchJob : return append ( baseEnv , refsEnv ... ) case prowapi . PresubmitJob : return append ( append ( baseEnv , refsEnv ... ) , pullEnv ... ) default : return [ ] string { } } } 
func getRevisionFromRef ( refs * prowapi . Refs ) string { if len ( refs . Pulls ) > 0 { return refs . Pulls [ 0 ] . SHA } if refs . BaseSHA != " " { return refs . BaseSHA } return refs . BaseRef } 
func GetRevisionFromSpec ( spec * JobSpec ) string { if spec . Refs != nil { return getRevisionFromRef ( spec . Refs ) } else if len ( spec . ExtraRefs ) > 0 { return getRevisionFromRef ( & spec . ExtraRefs [ 0 ] ) } return " " } 
func helpProvider ( config * plugins . Configuration , enabledRepos [ ] string ) ( * pluginhelp . PluginHelp , error ) { } 
func NewGroup ( gc ghFileClient , owner , repo , sha string ) ( * Group , error ) { g := & Group { Paths : make ( map [ string ] bool ) , FileNames : make ( map [ string ] bool ) , PathPrefixes : make ( map [ string ] bool ) , FilePrefixes : make ( map [ string ] bool ) , } bs , err := gc . GetFile ( owner , repo , genConfigFile , sha ) if err != nil { switch err . ( type ) { case * github . FileNotFound : return g , nil default : return nil , fmt . Errorf ( " " , err ) } } repoFiles , err := g . load ( bytes . NewBuffer ( bs ) ) if err != nil { return nil , err } for _ , f := range repoFiles { bs , err = gc . GetFile ( owner , repo , f , sha ) if err != nil { return nil , err } if err = g . loadPaths ( bytes . NewBuffer ( bs ) ) ; err != nil { return nil , err } } return g , nil } 
func ( g * Group ) load ( r io . Reader ) ( [ ] string , error ) { var repoPaths [ ] string s := bufio . NewScanner ( r ) for s . Scan ( ) { l := strings . TrimSpace ( s . Text ( ) ) if l == " " || l [ 0 ] == '#' { } fs := strings . Fields ( l ) if len ( fs ) != 2 { return repoPaths , & ParseError { line : l } } switch fs [ 0 ] { case " " , " " : g . PathPrefixes [ fs [ 1 ] ] = true case " " : g . FilePrefixes [ fs [ 1 ] ] = true case " " : g . FileNames [ fs [ 1 ] ] = true case " " : g . FileNames [ fs [ 1 ] ] = true case " " : default : return repoPaths , & ParseError { line : l } } } if err := s . Err ( ) ; err != nil { return repoPaths , err } return repoPaths , nil } 
func ( g * Group ) loadPaths ( r io . Reader ) error { s := bufio . NewScanner ( r ) for s . Scan ( ) { l := strings . TrimSpace ( s . Text ( ) ) if l == " " || l [ 0 ] == '#' { } g . Paths [ l ] = true } if err := s . Err ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( g * Group ) Match ( path string ) bool { if g . Paths [ path ] { return true } for prefix := range g . PathPrefixes { if strings . HasPrefix ( path , prefix ) { return true } } base := filepath . Base ( path ) if g . FileNames [ base ] { return true } for prefix := range g . FilePrefixes { if strings . HasPrefix ( base , prefix ) { return true } } return false } 
func ( config * InfluxConfig ) CreateDatabase ( tags map [ string ] string , measurement string ) ( * InfluxDB , error ) { client , err := influxdb . NewHTTPClient ( influxdb . HTTPConfig { Addr : config . Host , Username : config . User , Password : config . Password , } ) if err != nil { return nil , err } err = dropSeries ( client , measurement , config . DB , tags ) if err != nil { return nil , err } bp , err := influxdb . NewBatchPoints ( influxdb . BatchPointsConfig { Database : config . DB , Precision : " " , } ) if err != nil { return nil , err } return & InfluxDB { client : client , database : config . DB , batch : bp , tags : tags , measurement : measurement , } , err } 
func mergeTags ( defaultTags , extraTags map [ string ] string ) map [ string ] string { newTags := map [ string ] string { } for k , v := range defaultTags { newTags [ k ] = v } for k , v := range extraTags { newTags [ k ] = v } return newTags } 
func tagsToWhere ( tags map [ string ] string ) string { if len ( tags ) == 0 { return " " } sortedKeys := [ ] string { } for k := range tags { sortedKeys = append ( sortedKeys , k ) } sort . Strings ( sortedKeys ) conditions := [ ] string { } for _ , key := range sortedKeys { conditions = append ( conditions , fmt . Sprintf ( `"%s" = '%v'` , key , tags [ key ] ) ) } return " " + strings . Join ( conditions , " " ) } 
func ( i * InfluxDB ) Push ( tags map [ string ] string , fields map [ string ] interface { } , date time . Time ) error { pt , err := influxdb . NewPoint ( i . measurement , mergeTags ( i . tags , tags ) , fields , date ) if err != nil { return err } i . batch . AddPoint ( pt ) i . batchSize ++ return nil } 
func ( i * InfluxDB ) PushBatchPoints ( ) error { if err != nil { return err } glog . Infof ( " " , i . batchSize ) i . batchSize = 0 if err != nil { return err } return nil } 
func ( af * PodLogArtifactFetcher ) artifact ( jobName , buildID string , sizeLimit int64 ) ( lenses . Artifact , error ) { podLog , err := NewPodLogArtifact ( jobName , buildID , sizeLimit , af . jobAgent ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return podLog , nil } 
func roleIsManaged ( role * iam . Role ) bool { name := aws . StringValue ( role . RoleName ) path := aws . StringValue ( role . Path ) } } klog . Infof ( " " , name , path ) return false } 
func serve ( ) { http . Handle ( " " , promhttp . Handler ( ) ) logrus . WithError ( http . ListenAndServe ( " " , nil ) ) . Fatal ( " " ) } 
func gather ( c * plank . Controller ) { tick := time . Tick ( 30 * time . Second ) sig := make ( chan os . Signal , 1 ) signal . Notify ( sig , os . Interrupt , syscall . SIGTERM ) for { select { case <- tick : start := time . Now ( ) c . SyncMetrics ( ) logrus . WithField ( " " , fmt . Sprintf ( " " , time . Since ( start ) ) ) . Debug ( " " ) case <- sig : logrus . Debug ( " " ) return } } } 
func makeRequest ( policy branchprotection . Policy ) github . BranchProtectionRequest { return github . BranchProtectionRequest { EnforceAdmins : makeAdmins ( policy . Admins ) , RequiredPullRequestReviews : makeReviews ( policy . RequiredPullRequestReviews ) , RequiredStatusChecks : makeChecks ( policy . RequiredStatusChecks ) , Restrictions : makeRestrictions ( policy . Restrictions ) , } } 
func makeAdmins ( val * bool ) * bool { if v := makeBool ( val ) ; v { return & v } return nil } 
func makeChecks ( cp * branchprotection . ContextPolicy ) * github . RequiredStatusChecks { if cp == nil { return nil } return & github . RequiredStatusChecks { Contexts : append ( [ ] string { } , sets . NewString ( cp . Contexts ... ) . List ( ) ... ) , Strict : makeBool ( cp . Strict ) , } } 
func makeRestrictions ( rp * branchprotection . Restrictions ) * github . Restrictions { if rp == nil { return nil } teams := append ( [ ] string { } , sets . NewString ( rp . Teams ... ) . List ( ) ... ) users := append ( [ ] string { } , sets . NewString ( rp . Users ... ) . List ( ) ... ) return & github . Restrictions { Teams : & teams , Users : & users , } } 
func makeReviews ( rp * branchprotection . ReviewPolicy ) * github . RequiredPullRequestReviews { switch { case rp == nil : return nil case rp . Approvals == nil : logrus . Warn ( " " ) return nil case * rp . Approvals == 0 : return nil } rprr := github . RequiredPullRequestReviews { DismissStaleReviews : makeBool ( rp . DismissStale ) , RequireCodeOwnerReviews : makeBool ( rp . RequireOwners ) , RequiredApprovingReviewCount : * rp . Approvals , } if rp . DismissalRestrictions != nil { rprr . DismissalRestrictions = * makeRestrictions ( rp . DismissalRestrictions ) } return & rprr } 
func ( lens Lens ) Header ( artifacts [ ] lenses . Artifact , resourceDir string ) string { return executeTemplate ( resourceDir , " " , BuildLogsView { } ) } 
func ( lens Lens ) Body ( artifacts [ ] lenses . Artifact , resourceDir string , data string ) string { buildLogsView := BuildLogsView { LogViews : [ ] LogArtifactView { } , RawGetAllRequests : make ( map [ string ] string ) , RawGetMoreRequests : make ( map [ string ] string ) , } lines , err := logLinesAll ( a ) if err != nil { logrus . WithError ( err ) . Info ( " " ) continue } av . LineGroups = groupLines ( highlightLines ( lines , 0 ) ) av . ViewAll = true buildLogsView . LogViews = append ( buildLogsView . LogViews , av ) } return executeTemplate ( resourceDir , " " , buildLogsView ) } 
func ( lens Lens ) Callback ( artifacts [ ] lenses . Artifact , resourceDir string , data string ) string { var request LineRequest err := json . Unmarshal ( [ ] byte ( data ) , & request ) if err != nil { return " " } artifact , ok := artifactByName ( artifacts , request . Artifact ) if ! ok { return " " + request . Artifact } var lines [ ] string if request . Offset == 0 && request . Length == - 1 { lines , err = logLinesAll ( artifact ) } else { lines , err = logLines ( artifact , request . Offset , request . Length ) } if err != nil { return fmt . Sprintf ( " " , err ) } logLines := highlightLines ( lines , request . StartLine ) return executeTemplate ( resourceDir , " " , logLines ) } 
func logLinesAll ( artifact lenses . Artifact ) ( [ ] string , error ) { read , err := artifact . ReadAll ( ) if err != nil { return nil , fmt . Errorf ( " " , artifact . JobPath ( ) , err ) } logLines := strings . Split ( string ( read ) , " \n " ) return logLines , nil } 
func groupLines ( logLines [ ] LogLine ) [ ] LineGroup { } if i + d >= len ( logLines ) { break } logLines [ i + d ] . Skip = false } } } previousOffset := 0 var lineGroups [ ] LineGroup curGroup := LineGroup { } for i , line := range logLines { if line . Skip == curGroup . Skip { curGroup . LogLines = append ( curGroup . LogLines , line ) currentOffset += line . Length } else { curGroup . End = i curGroup . ByteLength = currentOffset - previousOffset - 1 previousOffset = currentOffset if curGroup . Skip { if curGroup . LinesSkipped ( ) < minLinesSkipped { curGroup . Skip = false } } if len ( curGroup . LogLines ) > 0 { lineGroups = append ( lineGroups , curGroup ) } curGroup = LineGroup { Skip : line . Skip , Start : i , LogLines : [ ] LogLine { line } , ByteOffset : currentOffset , } currentOffset += line . Length } } curGroup . End = len ( logLines ) curGroup . ByteLength = currentOffset - previousOffset - 1 if curGroup . Skip { if curGroup . LinesSkipped ( ) < minLinesSkipped { curGroup . Skip = false } } if len ( curGroup . LogLines ) > 0 { lineGroups = append ( lineGroups , curGroup ) } return lineGroups } 
func executeTemplate ( resourceDir , templateName string , data interface { } ) string { t := template . New ( " " ) _ , err := t . ParseFiles ( filepath . Join ( resourceDir , " " ) ) if err != nil { return fmt . Sprintf ( " " , err ) } var buf bytes . Buffer if err := t . ExecuteTemplate ( & buf , templateName , data ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } return buf . String ( ) } 
func ( in * ResourceObject ) DeepCopyObject ( ) runtime . Object { if c := in . deepCopy ( ) ; c != nil { return c } return nil } 
func ( in * ResourceObject ) FromItem ( i common . Item ) { r , err := common . ItemToResource ( i ) if err == nil { in . fromResource ( r ) } } 
func ( in * ResourceCollection ) SetItems ( objects [ ] Object ) { var items [ ] * ResourceObject for _ , b := range objects { items = append ( items , b . ( * ResourceObject ) ) } in . Items = items } 
func ( in * ResourceCollection ) DeepCopyObject ( ) runtime . Object { if c := in . deepCopy ( ) ; c != nil { return c } return nil } 
func useContext ( o options , ctx string ) error { _ , cmd := command ( " " , " " , " " , ctx ) return cmd . Run ( ) } 
func currentContext ( o options ) ( string , error ) { _ , cmd := command ( " " , " " , " " ) b , err := cmd . Output ( ) return strings . TrimSpace ( string ( b ) ) , err } 
func getCredentials ( o options ) error { if ! o . changeContext { cur , err := currentContext ( o ) if err != nil { return fmt . Errorf ( " " , err ) } defer useContext ( o , cur ) } if set { defer os . Setenv ( useClientCertEnv , old ) } if err := os . Setenv ( " " , " " ) ; err != nil { return fmt . Errorf ( " " , useClientCertEnv , err ) } args , cmd := command ( " " , " " , " " , " " , o . cluster , " " , o . project , " " , o . zone , ) if err := cmd . Run ( ) ; err != nil { return fmt . Errorf ( " " , strings . Join ( args , " " ) , err ) } return nil } 
func command ( bin string , args ... string ) ( [ ] string , * exec . Cmd ) { cmd := exec . Command ( bin , args ... ) cmd . Stderr = os . Stderr return append ( [ ] string { bin } , args ... ) , cmd } 
func getAccount ( ) ( string , error ) { args , cmd := command ( " " , " " , " " , " " ) b , err := cmd . Output ( ) if err != nil { return " " , fmt . Errorf ( " " , strings . Join ( args , " " ) , err ) } return strings . TrimSpace ( string ( b ) ) , nil } 
func setAccount ( account string ) error { _ , cmd := command ( " " , " " , " " , " " , account ) return cmd . Run ( ) } 
func describeCluster ( o options ) ( * describe , error ) { if o . account != " " { act , err := getAccount ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } defer setAccount ( act ) if err = setAccount ( o . account ) ; err != nil { return nil , fmt . Errorf ( " " , o . account , err ) } } args , cmd := command ( " " , " " , " " , " " , o . cluster , " " , o . project , " " , o . zone , " " , ) data , err := cmd . Output ( ) if err != nil { return nil , fmt . Errorf ( " " , strings . Join ( args , " " ) , err ) } var d describe if yaml . Unmarshal ( data , & d ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } if d . Endpoint == " " { return nil , errors . New ( " " ) } if len ( d . Auth . ClusterCACertificate ) == 0 { return nil , errors . New ( " " ) } if len ( d . Auth . ClientKey ) == 0 { return nil , errors . New ( " " ) } if len ( d . Auth . ClientCertificate ) == 0 { return nil , errors . New ( " " ) } return & d , nil } 
func do ( o options ) error { } } if err != nil { return fmt . Errorf ( " " , err ) } newCluster := kube . Cluster { Endpoint : " " + d . Endpoint , ClusterCACertificate : d . Auth . ClusterCACertificate , ClientKey : d . Auth . ClientKey , ClientCertificate : d . Auth . ClientCertificate , } if err != nil { return fmt . Errorf ( " " , err ) } if _ , err = c . ListPods ( " " ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " ) return fmt . Errorf ( " " , err ) } } if err != nil { return fmt . Errorf ( " " , o . alias , err ) } fmt . Println ( string ( data ) ) return nil } if err != nil { return fmt . Errorf ( " " , err ) } var s coreapi . Secret if err := yaml . Unmarshal ( b , & s ) ; err != nil { return fmt . Errorf ( " " , err ) } if err != nil { return fmt . Errorf ( " " , err ) } var existing [ ] string for a := range clusters { existing = append ( existing , a ) } logrus . Infof ( " " , strings . Join ( existing , " " ) ) if ok && ! o . overwrite { return fmt . Errorf ( " " , o . alias ) } clusters [ o . alias ] = newCluster logrus . Infof ( " " , o . alias ) if err != nil { return fmt . Errorf ( " " , err ) } if o . printData { return nil } buf , err := yaml . Marshal ( s ) if err != nil { return fmt . Errorf ( " " , err ) } fmt . Println ( string ( buf ) ) return nil } 
func ( ss * strslice ) Set ( value string ) error { * ss = append ( * ss , value ) return nil } 
func splitBucketObject ( path string ) ( string , string ) { path = strings . Trim ( path , " " ) parts := strings . SplitN ( path , " " , 2 ) if len ( parts ) == 0 { return " " , " " } if len ( parts ) == 1 { return parts [ 0 ] , " " } return parts [ 0 ] , parts [ 1 ] } 
func dirname ( path string ) string { leading := " " if strings . HasPrefix ( path , " " ) { leading = " " } parts := strings . Split ( strings . Trim ( path , " " ) , " " ) if len ( parts ) > 1 { return leading + strings . Join ( parts [ 0 : len ( parts ) - 1 ] , " " ) + " " } return leading } 
func parseXML ( body [ ] byte , object string ) ( * gcsDir , error ) { dir := new ( gcsDir ) if err := xml . Unmarshal ( body , & dir ) ; err != nil { return nil , err } selfIndex := - 1 for i := range dir . Contents { rec := & dir . Contents [ i ] name := strings . TrimPrefix ( rec . Name , object ) if name == " " { selfIndex = i continue } rec . Name = name if strings . HasSuffix ( name , " " ) { rec . isDir = true } } for i := range dir . CommonPrefixes { cp := & dir . CommonPrefixes [ i ] cp . Prefix = strings . TrimPrefix ( cp . Prefix , object ) } if ! isDir { return nil , nil } if selfIndex >= 0 { } return dir , nil } 
func ( dir * gcsDir ) Render ( out http . ResponseWriter , inPath string ) { htmlPageHeader ( out , dir . Name ) if ! strings . HasSuffix ( inPath , " " ) { inPath += " " } htmlContentHeader ( out , dir . Name , inPath ) if dir . NextMarker != " " { htmlNextButton ( out , gcsPath + inPath , dir . NextMarker ) } htmlGridHeader ( out ) if parent := dirname ( inPath ) ; parent != " " { url := gcsPath + parent htmlGridItem ( out , iconBack , url , " " , " " , " " ) } for i := range dir . CommonPrefixes { dir . CommonPrefixes [ i ] . Render ( out , inPath ) } for i := range dir . Contents { dir . Contents [ i ] . Render ( out , inPath ) } if dir . NextMarker != " " { htmlNextButton ( out , gcsPath + inPath , dir . NextMarker ) } htmlContentFooter ( out ) htmlPageFooter ( out ) } 
func ( rec * Record ) Render ( out http . ResponseWriter , inPath string ) { mtime := " " ts , err := time . Parse ( time . RFC3339 , rec . MTime ) if err == nil { mtime = ts . Format ( " " ) } var url , size string if rec . isDir { url = gcsPath + inPath + rec . Name size = " " } else { url = gcsBaseURL + inPath + rec . Name size = fmt . Sprintf ( " " , rec . Size ) } htmlGridItem ( out , iconFile , url , rec . Name , size , mtime ) } 
func ( pfx * Prefix ) Render ( out http . ResponseWriter , inPath string ) { url := gcsPath + inPath + pfx . Prefix htmlGridItem ( out , iconDir , url , pfx . Prefix , " " , " " ) } 
func ( tl txnLogger ) Printf ( fmt string , args ... interface { } ) { args = append ( [ ] interface { } { tl . nonce } , args ... ) log . Printf ( " " + fmt , args ... ) } 
func processRegexMatches ( matches [ ] string ) ( string , string , bool , string ) { var shouldClear = false proposedProject := matches [ 1 ] proposedColumnName := " " if len ( matches ) > 1 && proposedProject != clearKeyword { proposedColumnName = matches [ 2 ] } shouldClear = true } else { msg := invalidNumArgs return " " , " " , false , msg } } return proposedProject , proposedColumnName , shouldClear , " " } 
func ( p ProjectsFlag ) Set ( value string ) error { parts := strings . SplitN ( value , " " , 2 ) if len ( parts ) != 2 { return fmt . Errorf ( " " , value ) } host := parts [ 0 ] if _ , ok := p [ host ] ; ok { return fmt . Errorf ( " " , host ) } repos := strings . Split ( parts [ 1 ] , " " ) p [ host ] = repos return nil } 
func NewClient ( instances map [ string ] [ ] string ) ( * Client , error ) { c := & Client { handlers : map [ string ] * gerritInstanceHandler { } , } for instance := range instances { gc , err := gerrit . NewClient ( instance , nil ) if err != nil { return nil , err } c . handlers [ instance ] = & gerritInstanceHandler { instance : instance , projects : instances [ instance ] , authService : gc . Authentication , accountService : gc . Accounts , changeService : gc . Changes , projectService : gc . Projects , } } return c , nil } 
func ( c * Client ) QueryChanges ( lastUpdate time . Time , rateLimit int ) map [ string ] [ ] ChangeInfo { result := map [ string ] [ ] ChangeInfo { } for _ , h := range c . handlers { changes := h . queryAllChanges ( lastUpdate , rateLimit ) if len ( changes ) > 0 { result [ h . instance ] = [ ] ChangeInfo { } for _ , change := range changes { result [ h . instance ] = append ( result [ h . instance ] , change ) } } } return result } 
func ( c * Client ) SetReview ( instance , id , revision , message string , labels map [ string ] string ) error { h , ok := c . handlers [ instance ] if ! ok { return fmt . Errorf ( " " , instance ) } if _ , _ , err := h . changeService . SetReview ( id , revision , & gerrit . ReviewInput { Message : message , Labels : labels , } ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( c * Client ) GetBranchRevision ( instance , project , branch string ) ( string , error ) { h , ok := c . handlers [ instance ] if ! ok { return " " , fmt . Errorf ( " " , instance ) } res , _ , err := h . projectService . GetBranch ( project , branch ) if err != nil { return " " , err } return res . Revision , nil } 
func ( h * gerritInstanceHandler ) queryAllChanges ( lastUpdate time . Time , rateLimit int ) [ ] gerrit . ChangeInfo { result := [ ] gerrit . ChangeInfo { } for _ , project := range h . projects { changes , err := h . queryChangesForProject ( project , lastUpdate , rateLimit ) if err != nil { continue } result = append ( result , changes ... ) } return result } 
func NewTypeFilterWrapperPlugin ( plugin Plugin ) * TypeFilterWrapperPlugin { return & TypeFilterWrapperPlugin { plugin : plugin , pass : map [ string ] bool { } , } } 
func ( t * TypeFilterWrapperPlugin ) AddFlags ( cmd * cobra . Command ) { cmd . Flags ( ) . BoolVar ( & t . pullRequests , " " , false , " " ) cmd . Flags ( ) . BoolVar ( & t . issues , " " , false , " " ) } 
func ( t * TypeFilterWrapperPlugin ) CheckFlags ( ) error { if t . pullRequests && t . issues { return fmt . Errorf ( " " ) } return nil } 
func ( t * TypeFilterWrapperPlugin ) ReceiveIssue ( issue sql . Issue ) [ ] Point { if issue . IsPR && t . pullRequests { return nil } else if ! issue . IsPR && t . issues { return nil } else { t . pass [ issue . ID ] = true return t . plugin . ReceiveIssue ( issue ) } } 
func ( t * TypeFilterWrapperPlugin ) ReceiveIssueEvent ( event sql . IssueEvent ) [ ] Point { if ! t . pass [ event . IssueID ] { return nil } return t . plugin . ReceiveIssueEvent ( event ) } 
func ( t * TypeFilterWrapperPlugin ) ReceiveComment ( comment sql . Comment ) [ ] Point { if ! t . pass [ comment . IssueID ] { return nil } return t . plugin . ReceiveComment ( comment ) } 
func ( o * KubernetesClientOptions ) AddFlags ( fs * flag . FlagSet ) { fs . StringVar ( & o . namespace , " " , v1 . NamespaceDefault , " " ) fs . StringVar ( & o . kubeConfig , " " , " " , " " ) fs . BoolVar ( & o . inMemory , " " , false , " " ) } 
func ( o * KubernetesClientOptions ) Validate ( ) error { if o . kubeConfig != " " { if _ , err := os . Stat ( o . kubeConfig ) ; err != nil { return err } } return nil } 
func ( o * KubernetesClientOptions ) Client ( t Type ) ( ClientInterface , error ) { if o . inMemory { return newDummyClient ( t ) , nil } return o . newCRDClient ( t ) } 
func ( o * KubernetesClientOptions ) newCRDClient ( t Type ) ( * Client , error ) { config , scheme , err := createRESTConfig ( o . kubeConfig , t ) if err != nil { return nil , err } if err = registerResource ( config , t ) ; err != nil { return nil , err } restClient , err = rest . RESTClientFor ( config ) if err != nil { return nil , err } rc := Client { cl : restClient , ns : o . namespace , t : t , codec : runtime . NewParameterCodec ( scheme ) } return & rc , nil } 
func createRESTConfig ( kubeconfig string , t Type ) ( config * rest . Config , types * runtime . Scheme , err error ) { if kubeconfig == " " { config , err = rest . InClusterConfig ( ) } else { config , err = clientcmd . BuildConfigFromFlags ( " " , kubeconfig ) } if err != nil { return } version := schema . GroupVersion { Group : group , Version : version , } config . GroupVersion = & version config . APIPath = " " config . ContentType = runtime . ContentTypeJSON types = runtime . NewScheme ( ) schemeBuilder := runtime . NewSchemeBuilder ( func ( scheme * runtime . Scheme ) error { scheme . AddKnownTypes ( version , t . Object , t . Collection ) v1 . AddToGroupVersion ( scheme , version ) return nil } ) err = schemeBuilder . AddToScheme ( types ) config . NegotiatedSerializer = serializer . DirectCodecFactory { CodecFactory : serializer . NewCodecFactory ( types ) } return } 
func registerResource ( config * rest . Config , t Type ) error { c , err := apiextensionsclient . NewForConfig ( config ) if err != nil { return err } crd := & apiextensionsv1beta1 . CustomResourceDefinition { ObjectMeta : v1 . ObjectMeta { Name : fmt . Sprintf ( " " , t . Plural , group ) , } , Spec : apiextensionsv1beta1 . CustomResourceDefinitionSpec { Group : group , Version : version , Scope : apiextensionsv1beta1 . NamespaceScoped , Names : apiextensionsv1beta1 . CustomResourceDefinitionNames { Singular : t . Singular , Plural : t . Plural , Kind : t . Kind , ListKind : t . ListKind , } , } , } if _ , err := c . ApiextensionsV1beta1 ( ) . CustomResourceDefinitions ( ) . Create ( crd ) ; err != nil && ! apierrors . IsAlreadyExists ( err ) { return err } return nil } 
func newDummyClient ( t Type ) * dummyClient { c := & dummyClient { t : t , objects : make ( map [ string ] Object ) , } return c } 
func ( c * dummyClient ) Create ( obj Object ) ( Object , error ) { c . objects [ obj . GetName ( ) ] = obj return obj , nil } 
func ( c * dummyClient ) Update ( obj Object ) ( Object , error ) { _ , ok := c . objects [ obj . GetName ( ) ] if ! ok { return nil , fmt . Errorf ( " " , obj . GetName ( ) ) } c . objects [ obj . GetName ( ) ] = obj return obj , nil } 
func ( c * dummyClient ) Delete ( name string , options * v1 . DeleteOptions ) error { _ , ok := c . objects [ name ] if ok { delete ( c . objects , name ) return nil } return fmt . Errorf ( " " , name ) } 
func ( c * dummyClient ) Get ( name string ) ( Object , error ) { obj , ok := c . objects [ name ] if ok { return obj , nil } return nil , fmt . Errorf ( " " , name ) } 
func ( c * dummyClient ) List ( opts v1 . ListOptions ) ( Collection , error ) { var items [ ] Object for _ , i := range c . objects { items = append ( items , i ) } r := c . NewCollection ( ) r . SetItems ( items ) return r , nil } 
func ( c * Client ) Create ( obj Object ) ( Object , error ) { result := c . NewObject ( ) err := c . cl . Post ( ) . Namespace ( c . ns ) . Resource ( c . t . Plural ) . Name ( obj . GetName ( ) ) . Body ( obj ) . Do ( ) . Into ( result ) return result , err } 
func ( c * Client ) Delete ( name string , options * v1 . DeleteOptions ) error { return c . cl . Delete ( ) . Namespace ( c . ns ) . Resource ( c . t . Plural ) . Name ( name ) . Body ( options ) . Do ( ) . Error ( ) } 
func ( c * Client ) Get ( name string ) ( Object , error ) { result := c . NewObject ( ) err := c . cl . Get ( ) . Namespace ( c . ns ) . Resource ( c . t . Plural ) . Name ( name ) . Do ( ) . Into ( result ) return result , err } 
func ( c * Client ) List ( opts v1 . ListOptions ) ( Collection , error ) { result := c . NewCollection ( ) err := c . cl . Get ( ) . Namespace ( c . ns ) . Resource ( c . t . Plural ) . VersionedParams ( & opts , c . codec ) . Do ( ) . Into ( result ) return result , err } 
func TrustedPullRequest ( ghc githubClient , trigger plugins . Trigger , author , org , repo string , num int , l [ ] github . Label ) ( [ ] github . Label , bool , error ) { } else if orgMember { return l , true , nil } l , err = ghc . GetIssueLabels ( org , repo , num ) if err != nil { return l , false , err } } return l , github . HasLabel ( labels . OkToTest , l ) , nil } 
func buildAll ( c Client , pr * github . PullRequest , eventGUID string , elideSkippedContexts bool ) error { org , repo , number , branch := pr . Base . Repo . Owner . Login , pr . Base . Repo . Name , pr . Number , pr . Base . Ref changes := config . NewGitHubDeferredChangedFilesProvider ( c . GitHubClient , org , repo , number ) toTest , toSkipSuperset , err := pjutil . FilterPresubmits ( pjutil . TestAllFilter ( ) , changes , branch , c . Config . Presubmits [ pr . Base . Repo . FullName ] , c . Logger ) if err != nil { return err } toSkip := determineSkippedPresubmits ( toTest , toSkipSuperset , c . Logger ) return runAndSkipJobs ( c , pr , toTest , toSkip , eventGUID , elideSkippedContexts ) } 
func ( o Options ) Run ( ctx context . Context ) ( int , error ) { spec , err := downwardapi . ResolveSpecFromEnv ( ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } ctx , cancel := context . WithCancel ( ctx ) signal . Notify ( interrupt , os . Interrupt , syscall . SIGTERM ) go func ( ) { select { case s := <- interrupt : logrus . Errorf ( " " , s ) cancel ( ) case <- ctx . Done ( ) : } } ( ) if o . DeprecatedWrapperOptions != nil { } entries := o . entries ( ) passed , aborted , failures := wait ( ctx , entries ) cancel ( ) buildLog := logReader ( entries ) metadata := combineMetadata ( entries ) return failures , o . doUpload ( spec , passed , aborted , metadata , buildLog ) } 
func ( s * Storage ) AddConfig ( conf common . ResourcesConfig ) error { return s . configs . Add ( conf ) } 
func ( s * Storage ) DeleteConfig ( name string ) error { return s . configs . Delete ( name ) } 
func ( s * Storage ) UpdateConfig ( conf common . ResourcesConfig ) error { return s . configs . Update ( conf ) } 
func ( s * Storage ) GetConfig ( name string ) ( common . ResourcesConfig , error ) { i , err := s . configs . Get ( name ) if err != nil { return common . ResourcesConfig { } , err } var conf common . ResourcesConfig conf , err = common . ItemToResourcesConfig ( i ) if err != nil { return common . ResourcesConfig { } , err } return conf , nil } 
func ( s * Storage ) GetConfigs ( ) ( [ ] common . ResourcesConfig , error ) { var configs [ ] common . ResourcesConfig items , err := s . configs . List ( ) if err != nil { return configs , err } for _ , i := range items { var conf common . ResourcesConfig conf , err = common . ItemToResourcesConfig ( i ) if err != nil { return nil , err } configs = append ( configs , conf ) } return configs , nil } 
func ( s * Storage ) SyncConfigs ( newConfigs [ ] common . ResourcesConfig ) error { s . configsLock . Lock ( ) defer s . configsLock . Unlock ( ) currentConfigs , err := s . GetConfigs ( ) if err != nil { logrus . WithError ( err ) . Error ( " " ) return err } currentSet := mapset . NewSet ( ) newSet := mapset . NewSet ( ) toUpdate := mapset . NewSet ( ) configs := map [ string ] common . ResourcesConfig { } for _ , c := range currentConfigs { currentSet . Add ( c . Name ) configs [ c . Name ] = c } for _ , c := range newConfigs { newSet . Add ( c . Name ) if old , exists := configs [ c . Name ] ; exists { if ! reflect . DeepEqual ( old , c ) { toUpdate . Add ( c . Name ) configs [ c . Name ] = c } } else { configs [ c . Name ] = c } } var finalError error toDelete := currentSet . Difference ( newSet ) toAdd := newSet . Difference ( currentSet ) for _ , n := range toDelete . ToSlice ( ) { logrus . Infof ( " " , n . ( string ) ) if err := s . DeleteConfig ( n . ( string ) ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , n ) finalError = multierror . Append ( finalError , err ) } } for _ , n := range toAdd . ToSlice ( ) { rc := configs [ n . ( string ) ] logrus . Infof ( " " , n . ( string ) ) if err := s . AddConfig ( rc ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , n ) finalError = multierror . Append ( finalError , err ) } } for _ , n := range toUpdate . ToSlice ( ) { rc := configs [ n . ( string ) ] logrus . Infof ( " " , n . ( string ) ) if err := s . UpdateConfig ( rc ) ; err != nil { logrus . WithError ( err ) . Errorf ( " " , n ) finalError = multierror . Append ( finalError , err ) } } return finalError } 
func addKnownTypes ( scheme * runtime . Scheme ) error { scheme . AddKnownTypes ( SchemeGroupVersion , & ProwJob { } , & ProwJobList { } , ) metav1 . AddToGroupVersion ( scheme , SchemeGroupVersion ) return nil } 
func NewController ( continueOnError bool , addedPresubmitBlacklist sets . String , prowJobClient prowv1 . ProwJobInterface , githubClient * github . Client , configAgent * config . Agent , pluginAgent * plugins . ConfigAgent ) * Controller { return & Controller { continueOnError : continueOnError , addedPresubmitBlacklist : addedPresubmitBlacklist , prowJobTriggerer : & kubeProwJobTriggerer { prowJobClient : prowJobClient , githubClient : githubClient , configAgent : configAgent , } , githubClient : githubClient , statusMigrator : & gitHubMigrator { githubClient : githubClient , continueOnError : continueOnError , } , trustedChecker : & githubTrustedChecker { githubClient : githubClient , pluginAgent : pluginAgent , } , } } 
func ( c * Controller ) Run ( stop <- chan os . Signal , changes <- chan config . Delta ) { for { select { case change := <- changes : start := time . Now ( ) if err := c . reconcile ( change ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } logrus . WithField ( " " , fmt . Sprintf ( " " , time . Since ( start ) ) ) . Info ( " " ) case <- stop : logrus . Info ( " " ) return } } } 
func addedBlockingPresubmits ( old , new map [ string ] [ ] config . Presubmit ) map [ string ] [ ] config . Presubmit { added := map [ string ] [ ] config . Presubmit { } for repo , oldPresubmits := range old { added [ repo ] = [ ] config . Presubmit { } for _ , newPresubmit := range new [ repo ] { if ! newPresubmit . ContextRequired ( ) || newPresubmit . NeedsExplicitTrigger ( ) { continue } var found bool for _ , oldPresubmit := range oldPresubmits { if oldPresubmit . Name == newPresubmit . Name { if oldPresubmit . SkipReport && ! newPresubmit . SkipReport { added [ repo ] = append ( added [ repo ] , newPresubmit ) logrus . WithFields ( logrus . Fields { " " : repo , " " : oldPresubmit . Name , } ) . Debug ( " " ) } if oldPresubmit . RunIfChanged != newPresubmit . RunIfChanged { added [ repo ] = append ( added [ repo ] , newPresubmit ) logrus . WithFields ( logrus . Fields { " " : repo , " " : oldPresubmit . Name , } ) . Debug ( " " ) } found = true break } } if ! found { added [ repo ] = append ( added [ repo ] , newPresubmit ) logrus . WithFields ( logrus . Fields { " " : repo , " " : newPresubmit . Name , } ) . Debug ( " " ) } } } var numAdded int for _ , presubmits := range added { numAdded += len ( presubmits ) } logrus . Infof ( " " , numAdded ) return added } 
func removedBlockingPresubmits ( old , new map [ string ] [ ] config . Presubmit ) map [ string ] [ ] config . Presubmit { removed := map [ string ] [ ] config . Presubmit { } for repo , oldPresubmits := range old { removed [ repo ] = [ ] config . Presubmit { } for _ , oldPresubmit := range oldPresubmits { if ! oldPresubmit . ContextRequired ( ) { continue } var found bool for _ , newPresubmit := range new [ repo ] { if oldPresubmit . Name == newPresubmit . Name { found = true break } } if ! found { removed [ repo ] = append ( removed [ repo ] , oldPresubmit ) logrus . WithFields ( logrus . Fields { " " : repo , " " : oldPresubmit . Name , } ) . Debug ( " " ) } } } var numRemoved int for _ , presubmits := range removed { numRemoved += len ( presubmits ) } logrus . Infof ( " " , numRemoved ) return removed } 
func migratedBlockingPresubmits ( old , new map [ string ] [ ] config . Presubmit ) map [ string ] [ ] presubmitMigration { migrated := map [ string ] [ ] presubmitMigration { } for repo , oldPresubmits := range old { migrated [ repo ] = [ ] presubmitMigration { } for _ , newPresubmit := range new [ repo ] { if ! newPresubmit . ContextRequired ( ) { continue } for _ , oldPresubmit := range oldPresubmits { if oldPresubmit . Context != newPresubmit . Context && oldPresubmit . Name == newPresubmit . Name { migrated [ repo ] = append ( migrated [ repo ] , presubmitMigration { from : oldPresubmit , to : newPresubmit } ) logrus . WithFields ( logrus . Fields { " " : repo , " " : oldPresubmit . Name , " " : oldPresubmit . Context , " " : newPresubmit . Context , } ) . Debug ( " " ) } } } } var numMigrated int for _ , presubmits := range migrated { numMigrated += len ( presubmits ) } logrus . Infof ( " " , numMigrated ) return migrated } 
func Load ( loader OptionLoader ) error { if jsonConfig , provided := os . LookupEnv ( loader . ConfigVar ( ) ) ; provided { if err := loader . LoadConfig ( jsonConfig ) ; err != nil { return fmt . Errorf ( " " , loader . ConfigVar ( ) , err ) } return nil } fs := flag . NewFlagSet ( os . Args [ 0 ] , flag . ExitOnError ) loader . AddFlags ( fs ) fs . Parse ( os . Args [ 1 : ] ) loader . Complete ( fs . Args ( ) ) return nil } 
func NewController ( prowJobClient prowv1 . ProwJobInterface , jc * Client , ghc * github . Client , logger * logrus . Entry , cfg config . Getter , totURL , selector string ) ( * Controller , error ) { n , err := snowflake . NewNode ( 1 ) if err != nil { return nil , err } if logger == nil { logger = logrus . NewEntry ( logrus . StandardLogger ( ) ) } return & Controller { prowJobClient : prowJobClient , jc : jc , ghc : ghc , log : logger , cfg : cfg , selector : selector , node : n , totURL : totURL , pendingJobs : make ( map [ string ] int ) , } , nil } 
func ( c * Controller ) canExecuteConcurrently ( pj * prowapi . ProwJob ) bool { c . lock . Lock ( ) defer c . lock . Unlock ( ) if max := c . config ( ) . MaxConcurrency ; max > 0 { var running int for _ , num := range c . pendingJobs { running += num } if running >= max { c . log . WithFields ( pjutil . ProwJobFields ( pj ) ) . Debugf ( " " , running ) return false } } if pj . Spec . MaxConcurrency == 0 { c . pendingJobs [ pj . Spec . Job ] ++ return true } numPending := c . pendingJobs [ pj . Spec . Job ] if numPending >= pj . Spec . MaxConcurrency { c . log . WithFields ( pjutil . ProwJobFields ( pj ) ) . Debugf ( " " , pj . Spec . Job , numPending ) return false } c . pendingJobs [ pj . Spec . Job ] ++ return true } 
func ( c * Controller ) Sync ( ) error { pjs , err := c . prowJobClient . List ( metav1 . ListOptions { LabelSelector : c . selector } ) if err != nil { return fmt . Errorf ( " " , err ) } c . pjs = pjs . Items c . pjLock . Unlock ( ) for _ , pj := range pjs . Items { if pj . Spec . Agent == prowapi . JenkinsAgent { jenkinsJobs = append ( jenkinsJobs , pj ) } } jbs , err := c . jc . ListBuilds ( getJenkinsJobs ( jenkinsJobs ) ) if err != nil { return fmt . Errorf ( " " , err ) } var syncErrs [ ] error if err := c . terminateDupes ( jenkinsJobs , jbs ) ; err != nil { syncErrs = append ( syncErrs , err ) } pendingCh , triggeredCh := pjutil . PartitionActive ( jenkinsJobs ) errCh := make ( chan error , len ( jenkinsJobs ) ) reportCh := make ( chan prowapi . ProwJob , len ( jenkinsJobs ) ) c . log . Debugf ( " " , len ( pendingCh ) ) syncProwJobs ( c . log , c . syncPendingJob , maxSyncRoutines , pendingCh , reportCh , errCh , jbs ) c . log . Debugf ( " " , len ( triggeredCh ) ) syncProwJobs ( c . log , c . syncTriggeredJob , maxSyncRoutines , triggeredCh , reportCh , errCh , jbs ) close ( errCh ) close ( reportCh ) for err := range errCh { syncErrs = append ( syncErrs , err ) } var reportErrs [ ] error reportTemplate := c . config ( ) . ReportTemplate reportTypes := c . cfg ( ) . GitHubReporter . JobTypesToReport for report := range reportCh { if err := reportlib . Report ( c . ghc , reportTemplate , report , reportTypes ) ; err != nil { reportErrs = append ( reportErrs , err ) c . log . WithFields ( pjutil . ProwJobFields ( & report ) ) . WithError ( err ) . Warn ( " " ) } } if len ( syncErrs ) == 0 && len ( reportErrs ) == 0 { return nil } return fmt . Errorf ( " " , syncErrs , reportErrs ) } 
func getJenkinsJobs ( pjs [ ] prowapi . ProwJob ) [ ] BuildQueryParams { jenkinsJobs := [ ] BuildQueryParams { } for _ , pj := range pjs { if pj . Complete ( ) { continue } jenkinsJobs = append ( jenkinsJobs , BuildQueryParams { JobName : getJobName ( & pj . Spec ) , ProwJobID : pj . Name , } ) } return jenkinsJobs } 
func ( c * Controller ) terminateDupes ( pjs [ ] prowapi . ProwJob , jbs map [ string ] Build ) error { for i , pj := range pjs { if pj . Complete ( ) || pj . Spec . Type != prowapi . PresubmitJob { continue } n := fmt . Sprintf ( " " , pj . Spec . Job , pj . Spec . Refs . Org , pj . Spec . Refs . Repo , pj . Spec . Refs . Pulls [ 0 ] . Number ) prev , ok := dupes [ n ] if ! ok { dupes [ n ] = i continue } cancelIndex := i if ( & pjs [ prev ] . Status . StartTime ) . Before ( & pj . Status . StartTime ) { cancelIndex = prev dupes [ n ] = i } toCancel := pjs [ cancelIndex ] } } } } toCancel . SetComplete ( ) prevState := toCancel . Status . State toCancel . Status . State = prowapi . AbortedState c . log . WithFields ( pjutil . ProwJobFields ( & toCancel ) ) . WithField ( " " , prevState ) . WithField ( " " , toCancel . Status . State ) . Info ( " " ) npj , err := c . prowJobClient . Update ( & toCancel ) if err != nil { return err } pjs [ cancelIndex ] = * npj } return nil } 
func ( c * Client ) Throttle ( hourlyTokens , burst int ) { c . log ( " " , hourlyTokens , burst ) c . throttle . lock . Lock ( ) defer c . throttle . lock . Unlock ( ) previouslyThrottled := c . throttle . ticker != nil if hourlyTokens <= 0 || burst <= 0 { c . gqlc = c . throttle . graph c . throttle . ticker . Stop ( ) c . throttle . ticker = nil } return } rate := time . Hour / time . Duration ( hourlyTokens ) ticker := time . NewTicker ( rate ) throttle := make ( chan time . Time , burst ) for i := 0 ; i < burst ; i ++ { } go func ( ) { } } ( ) if ! previouslyThrottled { c . throttle . graph = c . gqlc c . client = & c . throttle c . gqlc = & c . throttle } c . throttle . ticker = ticker c . throttle . throttle = throttle } 
func NewClientWithFields ( fields logrus . Fields , getToken func ( ) [ ] byte , graphqlEndpoint string , bases ... string ) * Client { return & Client { logger : logrus . WithFields ( fields ) . WithField ( " " , " " ) , time : & standardTime { } , gqlc : githubql . NewEnterpriseClient ( graphqlEndpoint , & http . Client { Timeout : maxRequestTime , Transport : & oauth2 . Transport { Source : newReloadingTokenSource ( getToken ) } , } ) , client : & http . Client { Timeout : maxRequestTime } , bases : bases , getToken : getToken , dry : false , } } 
func NewClient ( getToken func ( ) [ ] byte , graphqlEndpoint string , bases ... string ) * Client { return NewClientWithFields ( logrus . Fields { } , getToken , graphqlEndpoint , bases ... ) } 
func NewDryRunClient ( getToken func ( ) [ ] byte , graphqlEndpoint string , bases ... string ) * Client { return NewDryRunClientWithFields ( logrus . Fields { } , getToken , graphqlEndpoint , bases ... ) } 
func NewFakeClient ( ) * Client { return & Client { logger : logrus . WithField ( " " , " " ) , time : & standardTime { } , fake : true , dry : true , } } 
func ( c * Client ) request ( r * request , ret interface { } ) ( int , error ) { statusCode , b , err := c . requestRaw ( r ) if err != nil { return statusCode , err } if ret != nil { if err := json . Unmarshal ( b , ret ) ; err != nil { return statusCode , err } } return statusCode , nil } 
func ( c * Client ) requestRaw ( r * request ) ( int , [ ] byte , error ) { if c . fake || ( c . dry && r . method != http . MethodGet ) { return r . exitCodes [ 0 ] , nil , nil } resp , err := c . requestRetry ( r . method , r . path , r . accept , r . requestBody ) if err != nil { return 0 , nil , err } defer resp . Body . Close ( ) b , err := ioutil . ReadAll ( resp . Body ) if err != nil { return 0 , nil , err } var okCode bool for _ , code := range r . exitCodes { if code == resp . StatusCode { okCode = true break } } if ! okCode { clientError := unmarshalClientError ( b ) err = requestError { ClientError : clientError , ErrorString : fmt . Sprintf ( " " , resp . StatusCode , r . exitCodes , string ( b ) ) , } } return resp . StatusCode , b , err } 
func ( c * Client ) requestRetry ( method , path , accept string , body interface { } ) ( * http . Response , error ) { var hostIndex int var resp * http . Response var err error backoff := initialDelay for retries := 0 ; retries < maxRetries ; retries ++ { if retries > 0 && resp != nil { resp . Body . Close ( ) } resp , err = c . doRequest ( method , c . bases [ hostIndex ] + path , accept , body ) if err == nil { if resp . StatusCode == 404 && retries < max404Retries { backoff *= 2 } else if resp . StatusCode == 403 { if resp . Header . Get ( " " ) == " " { if t , err = strconv . Atoi ( resp . Header . Get ( " " ) ) ; err == nil { if sleepTime < maxSleepTime { c . time . Sleep ( sleepTime ) } else { err = fmt . Errorf ( " " , sleepTime , maxSleepTime ) resp . Body . Close ( ) break } } else { err = fmt . Errorf ( " " , resp . Header . Get ( " " ) , err ) resp . Body . Close ( ) break } } else if rawTime := resp . Header . Get ( " " ) ; rawTime != " " && rawTime != " " { if t , err = strconv . Atoi ( rawTime ) ; err == nil { if sleepTime < maxSleepTime { c . time . Sleep ( sleepTime ) } else { err = fmt . Errorf ( " " , sleepTime , maxSleepTime ) resp . Body . Close ( ) break } } else { err = fmt . Errorf ( " " , rawTime , err ) resp . Body . Close ( ) break } } else if oauthScopes := resp . Header . Get ( " " ) ; len ( oauthScopes ) > 0 { authorizedScopes := resp . Header . Get ( " " ) if authorizedScopes == " " { authorizedScopes = " " } err = fmt . Errorf ( " " , authorizedScopes , oauthScopes ) resp . Body . Close ( ) break } } else if resp . StatusCode < 500 { } else { backoff *= 2 } } else { c . time . Sleep ( backoff ) backoff *= 2 } } return resp , err } 
func ( c * Client ) getUserData ( ) error { c . log ( " " ) var u User _ , err := c . request ( & request { method : http . MethodGet , path : " " , exitCodes : [ ] int { 200 } , } , & u ) if err != nil { return err } c . botName = u . Login return nil } 
func ( c * Client ) BotName ( ) ( string , error ) { c . mut . Lock ( ) defer c . mut . Unlock ( ) if c . botName == " " { if err := c . getUserData ( ) ; err != nil { return " " , fmt . Errorf ( " " , err ) } } return c . botName , nil } 
func ( c * Client ) Email ( ) ( string , error ) { c . mut . Lock ( ) defer c . mut . Unlock ( ) if c . email == " " { if err := c . getUserData ( ) ; err != nil { return " " , fmt . Errorf ( " " , err ) } } return c . email , nil } 
func ( c * Client ) IsMember ( org , user string ) ( bool , error ) { c . log ( " " , org , user ) if org == user { } code , err := c . request ( & request { method : http . MethodGet , path : fmt . Sprintf ( " " , org , user ) , exitCodes : [ ] int { 204 , 404 , 302 } , } , nil ) if err != nil { return false , err } if code == 204 { return true , nil } else if code == 404 { return false , nil } else if code == 302 { return false , fmt . Errorf ( " " , org ) } } 
func ( c * Client ) ListOrgHooks ( org string ) ( [ ] Hook , error ) { c . log ( " " , org ) return c . listHooks ( org , nil ) } 
func ( c * Client ) ListRepoHooks ( org , repo string ) ( [ ] Hook , error ) { c . log ( " " , org , repo ) return c . listHooks ( org , & repo ) } 
func ( c * Client ) EditRepoHook ( org , repo string , id int , req HookRequest ) error { c . log ( " " , org , repo , id ) return c . editHook ( org , & repo , id , req ) } 
func ( c * Client ) EditOrgHook ( org string , id int , req HookRequest ) error { c . log ( " " , org , id ) return c . editHook ( org , nil , id , req ) } 
func ( c * Client ) CreateOrgHook ( org string , req HookRequest ) ( int , error ) { c . log ( " " , org ) return c . createHook ( org , nil , req ) } 
func ( c * Client ) CreateRepoHook ( org , repo string , req HookRequest ) ( int , error ) { c . log ( " " , org , repo ) return c . createHook ( org , & repo , req ) } 
func ( c * Client ) GetOrg ( name string ) ( * Organization , error ) { c . log ( " " , name ) var retOrg Organization _ , err := c . request ( & request { method : http . MethodGet , path : fmt . Sprintf ( " " , name ) , exitCodes : [ ] int { 200 } , } , & retOrg ) if err != nil { return nil , err } return & retOrg , nil } 
func ( c * Client ) EditOrg ( name string , config Organization ) ( * Organization , error ) { c . log ( " " , name , config ) if c . dry { return & config , nil } var retOrg Organization _ , err := c . request ( & request { method : http . MethodPatch , path : fmt . Sprintf ( " " , name ) , exitCodes : [ ] int { 200 } , requestBody : & config , } , & retOrg ) if err != nil { return nil , err } return & retOrg , nil } 
func ( c * Client ) ListOrgInvitations ( org string ) ( [ ] OrgInvitation , error ) { c . log ( " " , org ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org ) var ret [ ] OrgInvitation err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] OrgInvitation { } } , func ( obj interface { } ) { ret = append ( ret , * ( obj . ( * [ ] OrgInvitation ) ) ... ) } , ) if err != nil { return nil , err } return ret , nil } 
func ( c * Client ) ListOrgMembers ( org , role string ) ( [ ] TeamMember , error ) { c . log ( " " , org , role ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org ) var teamMembers [ ] TeamMember err := c . readPaginatedResultsWithValues ( path , url . Values { " " : [ ] string { " " } , " " : [ ] string { role } , } , acceptNone , func ( ) interface { } { return & [ ] TeamMember { } } , func ( obj interface { } ) { teamMembers = append ( teamMembers , * ( obj . ( * [ ] TeamMember ) ) ... ) } , ) if err != nil { return nil , err } return teamMembers , nil } 
func ( c * Client ) HasPermission ( org , repo , user string , roles ... string ) ( bool , error ) { perm , err := c . GetUserPermission ( org , repo , user ) if err != nil { return false , err } for _ , r := range roles { if r == perm { return true , nil } } return false , nil } 
func ( c * Client ) GetUserPermission ( org , repo , user string ) ( string , error ) { c . log ( " " , org , repo , user ) var perm struct { Perm string `json:"permission"` } _ , err := c . request ( & request { method : http . MethodGet , path : fmt . Sprintf ( " " , org , repo , user ) , exitCodes : [ ] int { 200 } , } , & perm ) if err != nil { return " " , err } return perm . Perm , nil } 
func ( c * Client ) UpdateOrgMembership ( org , user string , admin bool ) ( * OrgMembership , error ) { c . log ( " " , org , user , admin ) om := OrgMembership { } if admin { om . Role = RoleAdmin } else { om . Role = RoleMember } if c . dry { return & om , nil } _ , err := c . request ( & request { method : http . MethodPut , path : fmt . Sprintf ( " " , org , user ) , requestBody : & om , exitCodes : [ ] int { 200 } , } , & om ) return & om , err } 
func ( c * Client ) RemoveOrgMembership ( org , user string ) error { c . log ( " " , org , user ) _ , err := c . request ( & request { method : http . MethodDelete , path : fmt . Sprintf ( " " , org , user ) , exitCodes : [ ] int { 204 } , } , nil ) return err } 
func ( c * Client ) CreateComment ( org , repo string , number int , comment string ) error { c . log ( " " , org , repo , number , comment ) ic := IssueComment { Body : comment , } _ , err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , org , repo , number ) , requestBody : & ic , exitCodes : [ ] int { 201 } , } , nil ) return err } 
func ( c * Client ) EditComment ( org , repo string , id int , comment string ) error { c . log ( " " , org , repo , id , comment ) ic := IssueComment { Body : comment , } _ , err := c . request ( & request { method : http . MethodPatch , path : fmt . Sprintf ( " " , org , repo , id ) , requestBody : & ic , exitCodes : [ ] int { 200 } , } , nil ) return err } 
func ( c * Client ) CreateCommentReaction ( org , repo string , id int , reaction string ) error { c . log ( " " , org , repo , id , reaction ) r := Reaction { Content : reaction } _ , err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , org , repo , id ) , accept : " " , exitCodes : [ ] int { 201 } , requestBody : & r , } , nil ) return err } 
func ( c * Client ) DeleteStaleComments ( org , repo string , number int , comments [ ] IssueComment , isStale func ( IssueComment ) bool ) error { var err error if comments == nil { comments , err = c . ListIssueComments ( org , repo , number ) if err != nil { return fmt . Errorf ( " " , err ) } } for _ , comment := range comments { if isStale ( comment ) { if err := c . DeleteComment ( org , repo , comment . ID ) ; err != nil { return fmt . Errorf ( " " , comment . ID ) } } } return nil } 
func ( c * Client ) readPaginatedResults ( path , accept string , newObj func ( ) interface { } , accumulate func ( interface { } ) ) error { values := url . Values { " " : [ ] string { " " } , } return c . readPaginatedResultsWithValues ( path , values , accept , newObj , accumulate ) } 
func ( c * Client ) readPaginatedResultsWithValues ( path string , values url . Values , accept string , newObj func ( ) interface { } , accumulate func ( interface { } ) ) error { pagedPath := path if len ( values ) > 0 { pagedPath += " " + values . Encode ( ) } for { resp , err := c . requestRetry ( http . MethodGet , pagedPath , accept , nil ) if err != nil { return err } defer resp . Body . Close ( ) if resp . StatusCode < 200 || resp . StatusCode > 299 { return fmt . Errorf ( " " , resp . Status ) } b , err := ioutil . ReadAll ( resp . Body ) if err != nil { return err } obj := newObj ( ) if err := json . Unmarshal ( b , obj ) ; err != nil { return err } accumulate ( obj ) link := parseLinks ( resp . Header . Get ( " " ) ) [ " " ] if link == " " { break } u , err := url . Parse ( link ) if err != nil { return fmt . Errorf ( " " , err ) } pagedPath = u . RequestURI ( ) } return nil } 
func ( c * Client ) GetPullRequests ( org , repo string ) ( [ ] PullRequest , error ) { c . log ( " " , org , repo ) var prs [ ] PullRequest if c . fake { return prs , nil } path := fmt . Sprintf ( " " , org , repo ) err := c . readPaginatedResults ( path , } , func ( obj interface { } ) { prs = append ( prs , * ( obj . ( * [ ] PullRequest ) ) ... ) } , ) if err != nil { return nil , err } return prs , err } 
func ( c * Client ) GetPullRequest ( org , repo string , number int ) ( * PullRequest , error ) { c . log ( " " , org , repo , number ) var pr PullRequest _ , err := c . request ( & request { return & pr , err } 
func ( c * Client ) GetPullRequestPatch ( org , repo string , number int ) ( [ ] byte , error ) { c . log ( " " , org , repo , number ) _ , patch , err := c . requestRaw ( & request { accept : " " , method : http . MethodGet , path : fmt . Sprintf ( " " , org , repo , number ) , exitCodes : [ ] int { 200 } , } ) return patch , err } 
func ( c * Client ) CreatePullRequest ( org , repo , title , body , head , base string , canModify bool ) ( int , error ) { c . log ( " " , org , repo , title ) data := struct { Title string `json:"title"` Body string `json:"body"` Head string `json:"head"` Base string `json:"base"` } { Title : title , Body : body , Head : head , Base : base , MaintainerCanModify : canModify , } var resp struct { Num int `json:"number"` } _ , err := c . request ( & request { if err != nil { return 0 , err } return resp . Num , nil } 
func ( c * Client ) UpdatePullRequest ( org , repo string , number int , title , body * string , open * bool , branch * string , canModify * bool ) error { c . log ( " " , org , repo , title ) data := struct { State * string `json:"state,omitempty"` Title * string `json:"title,omitempty"` Body * string `json:"body,omitempty"` Base * string `json:"base,omitempty"` } { Title : title , Body : body , Base : branch , MaintainerCanModify : canModify , } if open != nil && * open { op := " " data . State = & op } else if open != nil { cl := " " data . State = & cl } _ , err := c . request ( & request { return err } 
func ( c * Client ) GetPullRequestChanges ( org , repo string , number int ) ( [ ] PullRequestChange , error ) { c . log ( " " , org , repo , number ) if c . fake { return [ ] PullRequestChange { } , nil } path := fmt . Sprintf ( " " , org , repo , number ) var changes [ ] PullRequestChange err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] PullRequestChange { } } , func ( obj interface { } ) { changes = append ( changes , * ( obj . ( * [ ] PullRequestChange ) ) ... ) } , ) if err != nil { return nil , err } return changes , nil } 
func ( c * Client ) ListPullRequestComments ( org , repo string , number int ) ( [ ] ReviewComment , error ) { c . log ( " " , org , repo , number ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org , repo , number ) var comments [ ] ReviewComment err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] ReviewComment { } } , func ( obj interface { } ) { comments = append ( comments , * ( obj . ( * [ ] ReviewComment ) ) ... ) } , ) if err != nil { return nil , err } return comments , nil } 
func ( c * Client ) ListReviews ( org , repo string , number int ) ( [ ] Review , error ) { c . log ( " " , org , repo , number ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org , repo , number ) var reviews [ ] Review err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] Review { } } , func ( obj interface { } ) { reviews = append ( reviews , * ( obj . ( * [ ] Review ) ) ... ) } , ) if err != nil { return nil , err } return reviews , nil } 
func ( c * Client ) CreateStatus ( org , repo , SHA string , s Status ) error { c . log ( " " , org , repo , SHA , s ) _ , err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , org , repo , SHA ) , requestBody : & s , exitCodes : [ ] int { 201 } , } , nil ) return err } 
func ( c * Client ) ListStatuses ( org , repo , ref string ) ( [ ] Status , error ) { c . log ( " " , org , repo , ref ) path := fmt . Sprintf ( " " , org , repo , ref ) var statuses [ ] Status err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] Status { } } , func ( obj interface { } ) { statuses = append ( statuses , * ( obj . ( * [ ] Status ) ) ... ) } , ) return statuses , err } 
func ( c * Client ) GetRepo ( owner , name string ) ( Repo , error ) { c . log ( " " , owner , name ) var repo Repo _ , err := c . request ( & request { method : http . MethodGet , path : fmt . Sprintf ( " " , owner , name ) , exitCodes : [ ] int { 200 } , } , & repo ) return repo , err } 
func ( c * Client ) GetRepos ( org string , isUser bool ) ( [ ] Repo , error ) { c . log ( " " , org , isUser ) var ( repos [ ] Repo nextURL string ) if c . fake { return repos , nil } if isUser { nextURL = fmt . Sprintf ( " " , org ) } else { nextURL = fmt . Sprintf ( " " , org ) } err := c . readPaginatedResults ( nextURL , } , func ( obj interface { } ) { } , ) if err != nil { return nil , err } return repos , nil } 
func ( c * Client ) GetSingleCommit ( org , repo , SHA string ) ( SingleCommit , error ) { c . log ( " " , org , repo , SHA ) var commit SingleCommit _ , err := c . request ( & request { method : http . MethodGet , path : fmt . Sprintf ( " " , org , repo , SHA ) , exitCodes : [ ] int { 200 } , } , & commit ) return commit , err } 
func ( c * Client ) GetBranches ( org , repo string , onlyProtected bool ) ( [ ] Branch , error ) { c . log ( " " , org , repo ) var branches [ ] Branch err := c . readPaginatedResultsWithValues ( fmt . Sprintf ( " " , org , repo ) , url . Values { " " : [ ] string { strconv . FormatBool ( onlyProtected ) } , " " : [ ] string { " " } , } , acceptNone , func ( ) interface { } { } , func ( obj interface { } ) { branches = append ( branches , * ( obj . ( * [ ] Branch ) ) ... ) } , ) if err != nil { return nil , err } return branches , nil } 
func ( c * Client ) UpdateBranchProtection ( org , repo , branch string , config BranchProtectionRequest ) error { c . log ( " " , org , repo , branch , config ) _ , err := c . request ( & request { accept : " " , return err } 
func ( c * Client ) UpdateRepoLabel ( org , repo , label , newName , description , color string ) error { c . log ( " " , org , repo , label , newName , color ) _ , err := c . request ( & request { method : http . MethodPatch , path : fmt . Sprintf ( " " , org , repo , label ) , accept : " " , return err } 
func ( c * Client ) DeleteRepoLabel ( org , repo , label string ) error { c . log ( " " , org , repo , label ) _ , err := c . request ( & request { method : http . MethodDelete , accept : " " , return err } 
func ( c * Client ) GetCombinedStatus ( org , repo , ref string ) ( * CombinedStatus , error ) { c . log ( " " , org , repo , ref ) var combinedStatus CombinedStatus err := c . readPaginatedResults ( fmt . Sprintf ( " " , org , repo , ref ) , " " , func ( ) interface { } { return & CombinedStatus { } } , func ( obj interface { } ) { cs := * ( obj . ( * CombinedStatus ) ) cs . Statuses = append ( combinedStatus . Statuses , cs . Statuses ... ) combinedStatus = cs } , ) return & combinedStatus , err } 
func ( c * Client ) getLabels ( path string ) ( [ ] Label , error ) { var labels [ ] Label if c . fake { return labels , nil } err := c . readPaginatedResults ( path , " " , } , func ( obj interface { } ) { labels = append ( labels , * ( obj . ( * [ ] Label ) ) ... ) } , ) if err != nil { return nil , err } return labels , nil } 
func ( c * Client ) GetRepoLabels ( org , repo string ) ( [ ] Label , error ) { c . log ( " " , org , repo ) return c . getLabels ( fmt . Sprintf ( " " , org , repo ) ) } 
func ( c * Client ) GetIssueLabels ( org , repo string , number int ) ( [ ] Label , error ) { c . log ( " " , org , repo , number ) return c . getLabels ( fmt . Sprintf ( " " , org , repo , number ) ) } 
func ( c * Client ) RemoveLabel ( org , repo string , number int , label string ) error { c . log ( " " , org , repo , number , label ) code , body , err := c . requestRaw ( & request { method : http . MethodDelete , path : fmt . Sprintf ( " " , org , repo , number , label ) , switch { case code == 200 || code == 204 : case code == 404 : default : return fmt . Errorf ( " " , code ) } ge := & githubError { } if err := json . Unmarshal ( body , ge ) ; err != nil { return err } } } 
func ( c * Client ) AssignIssue ( org , repo string , number int , logins [ ] string ) error { c . log ( " " , org , repo , number , logins ) assigned := make ( map [ string ] bool ) var i Issue _ , err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , org , repo , number ) , requestBody : map [ string ] [ ] string { " " : logins } , exitCodes : [ ] int { 201 } , } , & i ) if err != nil { return err } for _ , assignee := range i . Assignees { assigned [ NormLogin ( assignee . Login ) ] = true } missing := MissingUsers { action : " " } for _ , login := range logins { if ! assigned [ NormLogin ( login ) ] { missing . Users = append ( missing . Users , login ) } } if len ( missing . Users ) > 0 { return missing } return nil } 
func ( c * Client ) CreateReview ( org , repo string , number int , r DraftReview ) error { c . log ( " " , org , repo , number , r ) _ , err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , org , repo , number ) , accept : " " , requestBody : r , exitCodes : [ ] int { 200 } , } , nil ) return err } 
func prepareReviewersBody ( logins [ ] string , org string ) ( map [ string ] [ ] string , error ) { body := map [ string ] [ ] string { } var errors [ ] error for _ , login := range logins { mat := teamRe . FindStringSubmatch ( login ) if mat == nil { if _ , exists := body [ " " ] ; ! exists { body [ " " ] = [ ] string { } } body [ " " ] = append ( body [ " " ] , login ) } else if mat [ 1 ] == org { if _ , exists := body [ " " ] ; ! exists { body [ " " ] = [ ] string { } } body [ " " ] = append ( body [ " " ] , mat [ 2 ] ) } else { errors = append ( errors , fmt . Errorf ( " " , login , org ) ) } } return body , errorutil . NewAggregate ( errors ... ) } 
func ( c * Client ) RequestReview ( org , repo string , number int , logins [ ] string ) error { statusCode , err := c . tryRequestReview ( org , repo , number , logins ) if err != nil && statusCode == http . StatusUnprocessableEntity { for _ , user := range logins { statusCode , err = c . tryRequestReview ( org , repo , number , [ ] string { user } ) if err != nil && statusCode == http . StatusUnprocessableEntity { } else if err != nil { return fmt . Errorf ( " " , statusCode , err ) } } if len ( missing . Users ) > 0 { return missing } return nil } return err } 
func ( c * Client ) UnrequestReview ( org , repo string , number int , logins [ ] string ) error { c . log ( " " , org , repo , number , logins ) var pr PullRequest body , err := prepareReviewersBody ( logins , org ) if len ( body ) == 0 { } _ , err = c . request ( & request { method : http . MethodDelete , path : fmt . Sprintf ( " " , org , repo , number ) , accept : " " , requestBody : body , exitCodes : [ ] int { http . StatusOK } , } , & pr ) if err != nil { return err } extras := ExtraUsers { action : " " } for _ , user := range pr . RequestedReviewers { found := false for _ , toDelete := range logins { if NormLogin ( user . Login ) == NormLogin ( toDelete ) { found = true break } } if found { extras . Users = append ( extras . Users , user . Login ) } } if len ( extras . Users ) > 0 { return extras } return nil } 
func ( c * Client ) CloseIssue ( org , repo string , number int ) error { c . log ( " " , org , repo , number ) _ , err := c . request ( & request { method : http . MethodPatch , path : fmt . Sprintf ( " " , org , repo , number ) , requestBody : map [ string ] string { " " : " " } , exitCodes : [ ] int { 200 } , } , nil ) return err } 
func stateCannotBeChangedOrOriginalError ( err error ) error { requestErr , ok := err . ( requestError ) if ok { for _ , errorMsg := range requestErr . ErrorMessages ( ) { if strings . Contains ( errorMsg , stateCannotBeChangedMessagePrefix ) { return StateCannotBeChanged { Message : errorMsg , } } } } return err } 
func ( c * Client ) GetRef ( org , repo , ref string ) ( string , error ) { c . log ( " " , org , repo , ref ) var res struct { Object map [ string ] string `json:"object"` } _ , err := c . request ( & request { method : http . MethodGet , path : fmt . Sprintf ( " " , org , repo , ref ) , exitCodes : [ ] int { 200 } , } , & res ) return res . Object [ " " ] , err } 
func ( c * Client ) DeleteRef ( org , repo , ref string ) error { c . log ( " " , org , repo , ref ) _ , err := c . request ( & request { method : http . MethodDelete , path : fmt . Sprintf ( " " , org , repo , ref ) , exitCodes : [ ] int { 204 } , } , nil ) return err } 
func ( c * Client ) FindIssues ( query , sort string , asc bool ) ( [ ] Issue , error ) { c . log ( " " , query ) path := fmt . Sprintf ( " " , url . QueryEscape ( query ) ) if sort != " " { path += " " + url . QueryEscape ( sort ) if asc { path += " " } } var issSearchResult IssuesSearchResult _ , err := c . request ( & request { method : http . MethodGet , path : path , exitCodes : [ ] int { 200 } , } , & issSearchResult ) return issSearchResult . Issues , err } 
func ( c * Client ) GetFile ( org , repo , filepath , commit string ) ( [ ] byte , error ) { c . log ( " " , org , repo , filepath , commit ) url := fmt . Sprintf ( " " , org , repo , filepath ) if commit != " " { url = fmt . Sprintf ( " " , url , commit ) } var res Content code , err := c . request ( & request { method : http . MethodGet , path : url , exitCodes : [ ] int { 200 , 404 } , } , & res ) if err != nil { return nil , err } if code == 404 { return nil , & FileNotFound { org : org , repo : repo , path : filepath , commit : commit , } } decoded , err := base64 . StdEncoding . DecodeString ( res . Content ) if err != nil { return nil , fmt . Errorf ( " " , res . Content , err ) } return decoded , nil } 
func ( c * Client ) Query ( ctx context . Context , q interface { } , vars map [ string ] interface { } ) error { } 
func ( c * Client ) CreateTeam ( org string , team Team ) ( * Team , error ) { c . log ( " " , org , team ) if team . Name == " " { return nil , errors . New ( " " ) } if c . fake { return nil , nil } else if c . dry { return & team , nil } path := fmt . Sprintf ( " " , org ) var retTeam Team _ , err := c . request ( & request { method : http . MethodPost , path : path , return & retTeam , err } 
func ( c * Client ) EditTeam ( t Team ) ( * Team , error ) { c . log ( " " , t ) if t . ID == 0 { return nil , errors . New ( " " ) } if c . dry { return & t , nil } id := t . ID t . ID = 0 ParentTeamID * int `json:"parent_team_id"` } { Team : t , ParentTeamID : t . ParentTeamID , } var retTeam Team path := fmt . Sprintf ( " " , id ) _ , err := c . request ( & request { method : http . MethodPatch , path : path , return & retTeam , err } 
func ( c * Client ) DeleteTeam ( id int ) error { c . log ( " " , id ) path := fmt . Sprintf ( " " , id ) _ , err := c . request ( & request { method : http . MethodDelete , path : path , exitCodes : [ ] int { 204 } , } , nil ) return err } 
func ( c * Client ) ListTeams ( org string ) ( [ ] Team , error ) { c . log ( " " , org ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org ) var teams [ ] Team err := c . readPaginatedResults ( path , } , func ( obj interface { } ) { teams = append ( teams , * ( obj . ( * [ ] Team ) ) ... ) } , ) if err != nil { return nil , err } return teams , nil } 
func ( c * Client ) UpdateTeamMembership ( id int , user string , maintainer bool ) ( * TeamMembership , error ) { c . log ( " " , id , user , maintainer ) if c . fake { return nil , nil } tm := TeamMembership { } if maintainer { tm . Role = RoleMaintainer } else { tm . Role = RoleMember } if c . dry { return & tm , nil } _ , err := c . request ( & request { method : http . MethodPut , path : fmt . Sprintf ( " " , id , user ) , requestBody : & tm , exitCodes : [ ] int { 200 } , } , & tm ) return & tm , err } 
func ( c * Client ) RemoveTeamMembership ( id int , user string ) error { c . log ( " " , id , user ) if c . fake { return nil } _ , err := c . request ( & request { method : http . MethodDelete , path : fmt . Sprintf ( " " , id , user ) , exitCodes : [ ] int { 204 } , } , nil ) return err } 
func ( c * Client ) ListTeamMembers ( id int , role string ) ( [ ] TeamMember , error ) { c . log ( " " , id , role ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , id ) var teamMembers [ ] TeamMember err := c . readPaginatedResultsWithValues ( path , url . Values { " " : [ ] string { " " } , " " : [ ] string { role } , } , } , func ( obj interface { } ) { teamMembers = append ( teamMembers , * ( obj . ( * [ ] TeamMember ) ) ... ) } , ) if err != nil { return nil , err } return teamMembers , nil } 
func ( c * Client ) ListTeamRepos ( id int ) ( [ ] Repo , error ) { c . log ( " " , id ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , id ) var repos [ ] Repo err := c . readPaginatedResultsWithValues ( path , url . Values { " " : [ ] string { " " } , } , } , func ( obj interface { } ) { repos = append ( repos , * ( obj . ( * [ ] Repo ) ) ... ) } , ) if err != nil { return nil , err } return repos , nil } 
func ( c * Client ) UpdateTeamRepo ( id int , org , repo string , permission RepoPermissionLevel ) error { c . log ( " " , id , org , repo , permission ) if c . fake || c . dry { return nil } data := struct { Permission string `json:"permission"` } { Permission : string ( permission ) , } _ , err := c . request ( & request { method : http . MethodPut , path : fmt . Sprintf ( " " , id , org , repo ) , requestBody : & data , exitCodes : [ ] int { 204 } , } , nil ) return err } 
func ( c * Client ) ListTeamInvitations ( id int ) ( [ ] OrgInvitation , error ) { c . log ( " " , id ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , id ) var ret [ ] OrgInvitation err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] OrgInvitation { } } , func ( obj interface { } ) { ret = append ( ret , * ( obj . ( * [ ] OrgInvitation ) ) ... ) } , ) if err != nil { return nil , err } return ret , nil } 
func ( c * Client ) Merge ( org , repo string , pr int , details MergeDetails ) error { c . log ( " " , org , repo , pr , details ) ge := githubError { } ec , err := c . request ( & request { method : http . MethodPut , path : fmt . Sprintf ( " " , org , repo , pr ) , requestBody : & details , exitCodes : [ ] int { 200 , 405 , 409 } , } , & ge ) if err != nil { return err } if ec == 405 { if strings . Contains ( ge . Message , " " ) { return UnmergablePRBaseChangedError ( ge . Message ) } if strings . Contains ( ge . Message , " " ) { return UnauthorizedToPushError ( ge . Message ) } if strings . Contains ( ge . Message , " " ) { return MergeCommitsForbiddenError ( ge . Message ) } return UnmergablePRError ( ge . Message ) } else if ec == 409 { return ModifiedHeadError ( ge . Message ) } return nil } 
func ( c * Client ) ListCollaborators ( org , repo string ) ( [ ] User , error ) { c . log ( " " , org , repo ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org , repo ) var users [ ] User err := c . readPaginatedResults ( path , } , func ( obj interface { } ) { users = append ( users , * ( obj . ( * [ ] User ) ) ... ) } , ) if err != nil { return nil , err } return users , nil } 
func ( c * Client ) CreateFork ( owner , repo string ) error { c . log ( " " , owner , repo ) _ , err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , owner , repo ) , exitCodes : [ ] int { 202 } , } , nil ) return err } 
func ( c * Client ) ListIssueEvents ( org , repo string , num int ) ( [ ] ListedIssueEvent , error ) { c . log ( " " , org , repo , num ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org , repo , num ) var events [ ] ListedIssueEvent err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] ListedIssueEvent { } } , func ( obj interface { } ) { events = append ( events , * ( obj . ( * [ ] ListedIssueEvent ) ) ... ) } , ) if err != nil { return nil , err } return events , nil } 
func ( c * Client ) IsMergeable ( org , repo string , number int , SHA string ) ( bool , error ) { backoff := time . Second * 3 maxTries := 3 for try := 0 ; try < maxTries ; try ++ { pr , err := c . GetPullRequest ( org , repo , number ) if err != nil { return false , err } if pr . Head . SHA != SHA { return false , fmt . Errorf ( " " , SHA , pr . Head . SHA ) } if pr . Merged { return false , errors . New ( " " ) } if pr . Mergable != nil { return * pr . Mergable , nil } if try + 1 < maxTries { c . time . Sleep ( backoff ) backoff *= 2 } } return false , fmt . Errorf ( " " , maxTries ) } 
func ( c * Client ) ClearMilestone ( org , repo string , num int ) error { c . log ( " " , org , repo , num ) issue := & struct { } { } _ , err := c . request ( & request { method : http . MethodPatch , path : fmt . Sprintf ( " " , org , repo , num ) , requestBody : & issue , exitCodes : [ ] int { 200 } , } , nil ) return err } 
func ( c * Client ) ListMilestones ( org , repo string ) ( [ ] Milestone , error ) { c . log ( " " , org ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , org , repo ) var milestones [ ] Milestone err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] Milestone { } } , func ( obj interface { } ) { milestones = append ( milestones , * ( obj . ( * [ ] Milestone ) ) ... ) } , ) if err != nil { return nil , err } return milestones , nil } 
func ( c * Client ) ListPRCommits ( org , repo string , number int ) ( [ ] RepositoryCommit , error ) { c . log ( " " , org , repo , number ) if c . fake { return nil , nil } var commits [ ] RepositoryCommit err := c . readPaginatedResults ( fmt . Sprintf ( " " , org , repo , number ) , acceptNone , func ( ) interface { } { } , func ( obj interface { } ) { } , ) if err != nil { return nil , err } return commits , nil } 
func ( s * reloadingTokenSource ) Token ( ) ( * oauth2 . Token , error ) { return & oauth2 . Token { AccessToken : string ( s . getToken ( ) ) , } , nil } 
func ( c * Client ) GetRepoProjects ( owner , repo string ) ( [ ] Project , error ) { c . log ( " " , owner , repo ) path := ( fmt . Sprintf ( " " , owner , repo ) ) var projects [ ] Project err := c . readPaginatedResults ( path , " " , func ( ) interface { } { return & [ ] Project { } } , func ( obj interface { } ) { projects = append ( projects , * ( obj . ( * [ ] Project ) ) ... ) } , ) if err != nil { return nil , err } return projects , nil } 
func ( c * Client ) GetOrgProjects ( org string ) ( [ ] Project , error ) { c . log ( " " , org ) path := ( fmt . Sprintf ( " " , org ) ) var projects [ ] Project err := c . readPaginatedResults ( path , " " , func ( ) interface { } { return & [ ] Project { } } , func ( obj interface { } ) { projects = append ( projects , * ( obj . ( * [ ] Project ) ) ... ) } , ) if err != nil { return nil , err } return projects , nil } 
func ( c * Client ) GetProjectColumns ( projectID int ) ( [ ] ProjectColumn , error ) { c . log ( " " , projectID ) path := ( fmt . Sprintf ( " " , projectID ) ) var projectColumns [ ] ProjectColumn err := c . readPaginatedResults ( path , " " , func ( ) interface { } { return & [ ] ProjectColumn { } } , func ( obj interface { } ) { projectColumns = append ( projectColumns , * ( obj . ( * [ ] ProjectColumn ) ) ... ) } , ) if err != nil { return nil , err } return projectColumns , nil } 
func ( c * Client ) CreateProjectCard ( columnID int , projectCard ProjectCard ) ( * ProjectCard , error ) { c . log ( " " , columnID , projectCard ) if ( projectCard . ContentType != " " ) && ( projectCard . ContentType != " " ) { return nil , errors . New ( " " ) } if c . dry { return & projectCard , nil } path := fmt . Sprintf ( " " , columnID ) var retProjectCard ProjectCard _ , err := c . request ( & request { method : http . MethodPost , path : path , accept : " " , requestBody : & projectCard , exitCodes : [ ] int { 200 } , } , & retProjectCard ) return & retProjectCard , err } 
func ( c * Client ) GetColumnProjectCard ( columnID int , cardNumber int ) ( * ProjectCard , error ) { c . log ( " " , columnID , cardNumber ) if c . fake { return nil , nil } path := fmt . Sprintf ( " " , columnID ) var cards [ ] ProjectCard err := c . readPaginatedResults ( path , acceptNone , func ( ) interface { } { return & [ ] ProjectCard { } } , func ( obj interface { } ) { cards = append ( cards , * ( obj . ( * [ ] ProjectCard ) ) ... ) } , ) if err != nil { return nil , err } for _ , card := range cards { if card . ContentID == cardNumber { return & card , nil } } return nil , nil } 
func ( c * Client ) MoveProjectCard ( projectCardID int , newColumnID int ) error { c . log ( " " , projectCardID , newColumnID ) _ , err := c . request ( & request { method : http . MethodPost , path : fmt . Sprintf ( " " , projectCardID ) , accept : " " , return err } 
func ( c * Client ) DeleteProjectCard ( projectCardID int ) error { c . log ( " " , projectCardID ) _ , err := c . request ( & request { method : http . MethodDelete , accept : " " , return err } 
func ( c * Client ) TeamHasMember ( teamID int , memberLogin string ) ( bool , error ) { c . log ( " " , teamID , memberLogin ) projectMaintainers , err := c . ListTeamMembers ( teamID , RoleAll ) if err != nil { return false , err } for _ , person := range projectMaintainers { if NormLogin ( person . Login ) == NormLogin ( memberLogin ) { return true , nil } } return false , nil } 
func ( s * Spyglass ) ListArtifacts ( src string ) ( [ ] string , error ) { keyType , key , err := splitSrc ( src ) if err != nil { return [ ] string { } , fmt . Errorf ( " " , err ) } gcsKey := " " switch keyType { case gcsKeyType : gcsKey = key case prowKeyType : if gcsKey , err = s . prowToGCS ( key ) ; err != nil { logrus . Warningf ( " " , err ) } default : return nil , fmt . Errorf ( " " , src ) } artifactNames , err := s . GCSArtifactFetcher . artifacts ( gcsKey ) logFound := false for _ , name := range artifactNames { if name == " " { logFound = true break } } if err != nil || ! logFound { artifactNames = append ( artifactNames , " " ) } return artifactNames , nil } 
func ( * Spyglass ) KeyToJob ( src string ) ( jobName string , buildID string , err error ) { src = strings . Trim ( src , " " ) parsed := strings . Split ( src , " " ) if len ( parsed ) < 2 { return " " , " " , fmt . Errorf ( " " , src ) } jobName = parsed [ len ( parsed ) - 2 ] buildID = parsed [ len ( parsed ) - 1 ] return jobName , buildID , nil } 
func ( s * Spyglass ) prowToGCS ( prowKey string ) ( string , error ) { jobName , buildID , err := s . KeyToJob ( prowKey ) if err != nil { return " " , fmt . Errorf ( " " , err ) } job , err := s . jobAgent . GetProwJob ( jobName , buildID ) if err != nil { return " " , fmt . Errorf ( " " , prowKey , err ) } url := job . Status . URL prefix := s . config ( ) . Plank . GetJobURLPrefix ( job . Spec . Refs ) if ! strings . HasPrefix ( url , prefix ) { return " " , fmt . Errorf ( " " , url , prefix ) } return url [ len ( prefix ) : ] , nil } 
func ( s * Spyglass ) FetchArtifacts ( src string , podName string , sizeLimit int64 , artifactNames [ ] string ) ( [ ] lenses . Artifact , error ) { artStart := time . Now ( ) arts := [ ] lenses . Artifact { } keyType , key , err := splitSrc ( src ) if err != nil { return arts , fmt . Errorf ( " " , err ) } jobName , buildID , err := s . KeyToJob ( src ) if err != nil { return arts , fmt . Errorf ( " " , err ) } gcsKey := " " switch keyType { case gcsKeyType : gcsKey = strings . TrimSuffix ( key , " " ) case prowKeyType : if gcsKey , err = s . prowToGCS ( key ) ; err != nil { logrus . Warningln ( err ) } default : return nil , fmt . Errorf ( " " , src ) } podLogNeeded := false for _ , name := range artifactNames { art , err := s . GCSArtifactFetcher . artifact ( gcsKey , name , sizeLimit ) if err == nil { } if err != nil { if name == " " { podLogNeeded = true } continue } arts = append ( arts , art ) } if podLogNeeded { art , err := s . PodLogArtifactFetcher . artifact ( jobName , buildID , sizeLimit ) if err != nil { logrus . Errorf ( " " , err ) } else { arts = append ( arts , art ) } } logrus . WithField ( " " , time . Since ( artStart ) ) . Infof ( " " , src ) return arts , nil } 
func ( in * DecorationConfig ) DeepCopyInto ( out * DecorationConfig ) { * out = * in out . Timeout = in . Timeout out . GracePeriod = in . GracePeriod if in . UtilityImages != nil { in , out := & in . UtilityImages , & out . UtilityImages * out = new ( UtilityImages ) * * out = * * in } if in . GCSConfiguration != nil { in , out := & in . GCSConfiguration , & out . GCSConfiguration * out = new ( GCSConfiguration ) * * out = * * in } if in . SSHKeySecrets != nil { in , out := & in . SSHKeySecrets , & out . SSHKeySecrets * out = make ( [ ] string , len ( * in ) ) copy ( * out , * in ) } if in . SSHHostFingerprints != nil { in , out := & in . SSHHostFingerprints , & out . SSHHostFingerprints * out = make ( [ ] string , len ( * in ) ) copy ( * out , * in ) } if in . SkipCloning != nil { in , out := & in . SkipCloning , & out . SkipCloning * out = new ( bool ) * * out = * * in } return } 
func ( in * DecorationConfig ) DeepCopy ( ) * DecorationConfig { if in == nil { return nil } out := new ( DecorationConfig ) in . DeepCopyInto ( out ) return out } 
func ( in * GCSConfiguration ) DeepCopy ( ) * GCSConfiguration { if in == nil { return nil } out := new ( GCSConfiguration ) in . DeepCopyInto ( out ) return out } 
func ( in * JenkinsSpec ) DeepCopy ( ) * JenkinsSpec { if in == nil { return nil } out := new ( JenkinsSpec ) in . DeepCopyInto ( out ) return out } 
func ( in * ProwJob ) DeepCopyInto ( out * ProwJob ) { * out = * in out . TypeMeta = in . TypeMeta in . ObjectMeta . DeepCopyInto ( & out . ObjectMeta ) in . Spec . DeepCopyInto ( & out . Spec ) in . Status . DeepCopyInto ( & out . Status ) return } 
func ( in * ProwJob ) DeepCopy ( ) * ProwJob { if in == nil { return nil } out := new ( ProwJob ) in . DeepCopyInto ( out ) return out } 
func ( in * ProwJob ) DeepCopyObject ( ) runtime . Object { if c := in . DeepCopy ( ) ; c != nil { return c } return nil } 
func ( in * ProwJobList ) DeepCopyInto ( out * ProwJobList ) { * out = * in out . TypeMeta = in . TypeMeta out . ListMeta = in . ListMeta if in . Items != nil { in , out := & in . Items , & out . Items * out = make ( [ ] ProwJob , len ( * in ) ) for i := range * in { ( * in ) [ i ] . DeepCopyInto ( & ( * out ) [ i ] ) } } return } 
func ( in * ProwJobList ) DeepCopy ( ) * ProwJobList { if in == nil { return nil } out := new ( ProwJobList ) in . DeepCopyInto ( out ) return out } 
func ( in * ProwJobList ) DeepCopyObject ( ) runtime . Object { if c := in . DeepCopy ( ) ; c != nil { return c } return nil } 
func ( in * ProwJobSpec ) DeepCopyInto ( out * ProwJobSpec ) { * out = * in if in . Refs != nil { in , out := & in . Refs , & out . Refs * out = new ( Refs ) ( * in ) . DeepCopyInto ( * out ) } if in . ExtraRefs != nil { in , out := & in . ExtraRefs , & out . ExtraRefs * out = make ( [ ] Refs , len ( * in ) ) for i := range * in { ( * in ) [ i ] . DeepCopyInto ( & ( * out ) [ i ] ) } } if in . PodSpec != nil { in , out := & in . PodSpec , & out . PodSpec * out = new ( corev1 . PodSpec ) ( * in ) . DeepCopyInto ( * out ) } if in . BuildSpec != nil { in , out := & in . BuildSpec , & out . BuildSpec * out = new ( v1alpha1 . BuildSpec ) ( * in ) . DeepCopyInto ( * out ) } if in . JenkinsSpec != nil { in , out := & in . JenkinsSpec , & out . JenkinsSpec * out = new ( JenkinsSpec ) * * out = * * in } if in . PipelineRunSpec != nil { in , out := & in . PipelineRunSpec , & out . PipelineRunSpec * out = new ( pipelinev1alpha1 . PipelineRunSpec ) ( * in ) . DeepCopyInto ( * out ) } if in . DecorationConfig != nil { in , out := & in . DecorationConfig , & out . DecorationConfig * out = new ( DecorationConfig ) ( * in ) . DeepCopyInto ( * out ) } return } 
func ( in * ProwJobSpec ) DeepCopy ( ) * ProwJobSpec { if in == nil { return nil } out := new ( ProwJobSpec ) in . DeepCopyInto ( out ) return out } 
func ( in * ProwJobStatus ) DeepCopyInto ( out * ProwJobStatus ) { * out = * in in . StartTime . DeepCopyInto ( & out . StartTime ) if in . CompletionTime != nil { in , out := & in . CompletionTime , & out . CompletionTime * out = ( * in ) . DeepCopy ( ) } if in . PrevReportStates != nil { in , out := & in . PrevReportStates , & out . PrevReportStates * out = make ( map [ string ] ProwJobState , len ( * in ) ) for key , val := range * in { ( * out ) [ key ] = val } } return } 
func ( in * ProwJobStatus ) DeepCopy ( ) * ProwJobStatus { if in == nil { return nil } out := new ( ProwJobStatus ) in . DeepCopyInto ( out ) return out } 
func ( in * Pull ) DeepCopy ( ) * Pull { if in == nil { return nil } out := new ( Pull ) in . DeepCopyInto ( out ) return out } 
func ( in * Refs ) DeepCopyInto ( out * Refs ) { * out = * in if in . Pulls != nil { in , out := & in . Pulls , & out . Pulls * out = make ( [ ] Pull , len ( * in ) ) copy ( * out , * in ) } return } 
func ( in * Refs ) DeepCopy ( ) * Refs { if in == nil { return nil } out := new ( Refs ) in . DeepCopyInto ( out ) return out } 
func ( in * UtilityImages ) DeepCopy ( ) * UtilityImages { if in == nil { return nil } out := new ( UtilityImages ) in . DeepCopyInto ( out ) return out } 
func upload ( rsClient * resultstore . Client , inv resultstore . Invocation , target resultstore . Target , test resultstore . Test ) ( string , error ) { targetID := test . Name const configID = resultstore . Default invName , err := rsClient . Invocations ( ) . Create ( inv ) if err != nil { return " " , fmt . Errorf ( " " , err ) } targetName , err := rsClient . Targets ( invName ) . Create ( targetID , target ) if err != nil { return resultstore . URL ( invName ) , fmt . Errorf ( " " , err ) } url := resultstore . URL ( targetName ) _ , err = rsClient . Configurations ( invName ) . Create ( configID ) if err != nil { return url , fmt . Errorf ( " " , err ) } ctName , err := rsClient . ConfiguredTargets ( targetName , configID ) . Create ( test . Action ) if err != nil { return url , fmt . Errorf ( " " , err ) } _ , err = rsClient . Actions ( ctName ) . Create ( " " , test ) if err != nil { return url , fmt . Errorf ( " " , err ) } return url , nil } 
func ( d * DecorationConfig ) ApplyDefault ( def * DecorationConfig ) * DecorationConfig { if d == nil && def == nil { return nil } var merged DecorationConfig if d != nil { merged = * d } else { merged = * def } if d == nil || def == nil { return & merged } merged . UtilityImages = merged . UtilityImages . ApplyDefault ( def . UtilityImages ) merged . GCSConfiguration = merged . GCSConfiguration . ApplyDefault ( def . GCSConfiguration ) if merged . Timeout . Duration == 0 { merged . Timeout = def . Timeout } if merged . GracePeriod . Duration == 0 { merged . GracePeriod = def . GracePeriod } if merged . GCSCredentialsSecret == " " { merged . GCSCredentialsSecret = def . GCSCredentialsSecret } if len ( merged . SSHKeySecrets ) == 0 { merged . SSHKeySecrets = def . SSHKeySecrets } if len ( merged . SSHHostFingerprints ) == 0 { merged . SSHHostFingerprints = def . SSHHostFingerprints } if merged . SkipCloning == nil { merged . SkipCloning = def . SkipCloning } if merged . CookiefileSecret == " " { merged . CookiefileSecret = def . CookiefileSecret } return & merged } 
func ( d * DecorationConfig ) Validate ( ) error { if d . UtilityImages == nil { return errors . New ( " " ) } var missing [ ] string if d . UtilityImages . CloneRefs == " " { missing = append ( missing , " " ) } if d . UtilityImages . InitUpload == " " { missing = append ( missing , " " ) } if d . UtilityImages . Entrypoint == " " { missing = append ( missing , " " ) } if d . UtilityImages . Sidecar == " " { missing = append ( missing , " " ) } if len ( missing ) > 0 { return fmt . Errorf ( " " , missing ) } if d . GCSConfiguration == nil { return errors . New ( " " ) } if d . GCSCredentialsSecret == " " { return errors . New ( " " ) } if err := d . GCSConfiguration . Validate ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( u * UtilityImages ) ApplyDefault ( def * UtilityImages ) * UtilityImages { if u == nil { return def } else if def == nil { return u } merged := * u if merged . CloneRefs == " " { merged . CloneRefs = def . CloneRefs } if merged . InitUpload == " " { merged . InitUpload = def . InitUpload } if merged . Entrypoint == " " { merged . Entrypoint = def . Entrypoint } if merged . Sidecar == " " { merged . Sidecar = def . Sidecar } return & merged } 
func ( g * GCSConfiguration ) ApplyDefault ( def * GCSConfiguration ) * GCSConfiguration { if g == nil && def == nil { return nil } var merged GCSConfiguration if g != nil { merged = * g } else { merged = * def } if g == nil || def == nil { return & merged } if merged . Bucket == " " { merged . Bucket = def . Bucket } if merged . PathPrefix == " " { merged . PathPrefix = def . PathPrefix } if merged . PathStrategy == " " { merged . PathStrategy = def . PathStrategy } if merged . DefaultOrg == " " { merged . DefaultOrg = def . DefaultOrg } if merged . DefaultRepo == " " { merged . DefaultRepo = def . DefaultRepo } return & merged } 
func ( g * GCSConfiguration ) Validate ( ) error { if g . PathStrategy != PathStrategyLegacy && g . PathStrategy != PathStrategyExplicit && g . PathStrategy != PathStrategySingle { return fmt . Errorf ( " " , PathStrategyLegacy , PathStrategyExplicit , PathStrategySingle ) } if g . PathStrategy != PathStrategyExplicit && ( g . DefaultOrg == " " || g . DefaultRepo == " " ) { return fmt . Errorf ( " " , g . PathStrategy ) } return nil } 
func ( j * ProwJob ) SetComplete ( ) { j . Status . CompletionTime = new ( metav1 . Time ) * j . Status . CompletionTime = metav1 . Now ( ) } 
func ( j * ProwJob ) ClusterAlias ( ) string { if j . Spec . Cluster == " " { return DefaultClusterAlias } return j . Spec . Cluster } 
func NewResource ( name , rtype , state , owner string , t time . Time ) Resource { return Resource { Name : name , Type : rtype , State : state , Owner : owner , LastUpdate : t , UserData : & UserData { } , } } 
func NewResourcesFromConfig ( e ResourceEntry ) [ ] Resource { var resources [ ] Resource for _ , name := range e . Names { resources = append ( resources , NewResource ( name , e . Type , e . State , " " , time . Time { } ) ) } return resources } 
func UserDataFromMap ( m UserDataMap ) * UserData { ud := & UserData { } for k , v := range m { ud . Store ( k , v ) } return ud } 
func ( r * CommaSeparatedStrings ) Set ( value string ) error { if len ( * r ) > 0 { return errors . New ( " " ) } for _ , rtype := range strings . Split ( value , " " ) { * r = append ( * r , rtype ) } return nil } 
func ( ud * UserData ) UnmarshalJSON ( data [ ] byte ) error { tmpMap := UserDataMap { } if err := json . Unmarshal ( data , & tmpMap ) ; err != nil { return err } ud . FromMap ( tmpMap ) return nil } 
func ( ud * UserData ) Extract ( id string , out interface { } ) error { content , ok := ud . Load ( id ) if ! ok { return & UserDataNotFound { id } } return yaml . Unmarshal ( [ ] byte ( content . ( string ) ) , out ) } 
func ( ud * UserData ) Set ( id string , in interface { } ) error { b , err := yaml . Marshal ( in ) if err != nil { return err } ud . Store ( id , string ( b ) ) return nil } 
func ( ud * UserData ) Update ( new * UserData ) { if new == nil { return } new . Range ( func ( key , value interface { } ) bool { if value . ( string ) != " " { ud . Store ( key , value ) } else { ud . Delete ( key ) } return true } ) } 
func ( ud * UserData ) ToMap ( ) UserDataMap { m := UserDataMap { } ud . Range ( func ( key , value interface { } ) bool { m [ key . ( string ) ] = value . ( string ) return true } ) return m } 
func ( ud * UserData ) FromMap ( m UserDataMap ) { for key , value := range m { ud . Store ( key , value ) } } 
func ItemToResource ( i Item ) ( Resource , error ) { res , ok := i . ( Resource ) if ! ok { return Resource { } , fmt . Errorf ( " " , i ) } return res , nil } 
func ( o Options ) Run ( ) error { var env [ ] string if len ( o . KeyFiles ) > 0 { var err error env , err = addSSHKeys ( o . KeyFiles ) if err != nil { logrus . WithError ( err ) . Error ( " " ) } if len ( o . HostFingerprints ) > 0 { if err := addHostFingerprints ( o . HostFingerprints ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) } } var numWorkers int if o . MaxParallelWorkers != 0 { numWorkers = o . MaxParallelWorkers } else { numWorkers = len ( o . GitRefs ) } wg := & sync . WaitGroup { } wg . Add ( numWorkers ) input := make ( chan prowapi . Refs ) output := make ( chan clone . Record , len ( o . GitRefs ) ) for i := 0 ; i < numWorkers ; i ++ { go func ( ) { defer wg . Done ( ) for ref := range input { output <- cloneFunc ( ref , o . SrcRoot , o . GitUserName , o . GitUserEmail , o . CookiePath , env ) } } ( ) } for _ , ref := range o . GitRefs { input <- ref } close ( input ) wg . Wait ( ) close ( output ) var results [ ] clone . Record for record := range output { results = append ( results , record ) } logData , err := json . Marshal ( results ) if err != nil { return fmt . Errorf ( " " , err ) } if err := ioutil . WriteFile ( o . Log , logData , 0755 ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func addSSHKeys ( paths [ ] string ) ( [ ] string , error ) { vars , err := exec . Command ( " " ) . CombinedOutput ( ) if err != nil { return [ ] string { } , fmt . Errorf ( " " , err ) } logrus . Info ( " " ) env := [ ] string { strings . TrimSpace ( parts [ 0 ] ) , strings . TrimSpace ( parts [ 2 ] ) } for _ , keyPath := range paths { } return nil } if info . IsDir ( ) { return nil } cmd := exec . Command ( " " , path ) cmd . Env = append ( cmd . Env , env ... ) if output , err := cmd . CombinedOutput ( ) ; err != nil { return fmt . Errorf ( " " , path , err , output ) } logrus . Infof ( " " , path ) return nil } ) ; err != nil { return env , fmt . Errorf ( " " , keyPath , err ) } } return env , nil } 
func ( f * TriageFiler ) Issues ( c * creator . IssueCreator ) ( [ ] creator . Issue , error ) { f . creator = c rawjson , err := ReadHTTP ( clusterDataURL ) if err != nil { return nil , err } clusters , err := f . loadClusters ( rawjson ) if err != nil { return nil , err } topclusters := topClusters ( clusters , f . topClustersCount ) issues := make ( [ ] creator . Issue , 0 , len ( topclusters ) ) for _ , clust := range topclusters { issues = append ( issues , clust ) } return issues , nil } 
func ( f * TriageFiler ) RegisterFlags ( ) { flag . IntVar ( & f . topClustersCount , " " , 3 , " " ) flag . IntVar ( & f . windowDays , " " , 1 , " " ) } 
func ( f * TriageFiler ) filterAndValidate ( windowDays int ) error { f . latestStart = int64 ( 0 ) for _ , start := range f . data . Builds . Cols . Started { if start > f . latestStart { f . latestStart = start } } cutoffTime := time . Unix ( f . latestStart , 0 ) . AddDate ( 0 , 0 , - windowDays ) . Unix ( ) validClusts := [ ] * Cluster { } for clustIndex , clust := range f . data . Clustered { if len ( clust . Identifier ) == 0 { return fmt . Errorf ( " " , clustIndex ) } if clust . Tests == nil { return fmt . Errorf ( " " , clust . Identifier ) } validTests := [ ] * Test { } for _ , test := range clust . Tests { if len ( test . Name ) == 0 { return fmt . Errorf ( " " , clust . Identifier ) } if test . Jobs == nil { return fmt . Errorf ( " " , clust . Identifier ) } validJobs := [ ] * Job { } for _ , job := range test . Jobs { if len ( job . Name ) == 0 { return fmt . Errorf ( " " , clust . Identifier , test . Name ) } } if len ( job . Builds ) == 0 { return fmt . Errorf ( " " , clust . Identifier , job . Name , test . Name ) } validBuilds := [ ] int { } rowMap , ok := f . data . Builds . Jobs [ job . Name ] if ! ok { return fmt . Errorf ( " " , job . Name ) } for _ , buildnum := range job . Builds { row , err := rowMap . rowForBuild ( buildnum ) if err != nil { return err } if f . data . Builds . Cols . Started [ row ] > cutoffTime { validBuilds = append ( validBuilds , buildnum ) } } if len ( validBuilds ) > 0 { job . Builds = validBuilds validJobs = append ( validJobs , job ) } } if len ( validJobs ) > 0 { test . Jobs = validJobs validTests = append ( validTests , test ) } } if len ( validTests ) > 0 { clust . Tests = validTests validClusts = append ( validClusts , clust ) } } f . data . Clustered = validClusts return nil } 
func ( f * TriageFiler ) loadClusters ( jsonIn [ ] byte ) ( [ ] * Cluster , error ) { var err error f . data , err = parseTriageData ( jsonIn ) if err != nil { return nil , err } if err = f . filterAndValidate ( f . windowDays ) ; err != nil { return nil , err } clust . jobs = make ( map [ string ] [ ] int ) for _ , test := range clust . Tests { for _ , job := range test . Jobs { for _ , buildnum := range job . Builds { found := false for _ , oldBuild := range clust . jobs [ job . Name ] { if oldBuild == buildnum { found = true break } } if ! found { clust . jobs [ job . Name ] = append ( clust . jobs [ job . Name ] , buildnum ) } } } } clust . totalJobs = len ( clust . jobs ) clust . totalTests = len ( clust . Tests ) clust . totalBuilds = 0 for _ , builds := range clust . jobs { clust . totalBuilds += len ( builds ) } } return f . data . Clustered , nil } 
func parseTriageData ( jsonIn [ ] byte ) ( * triageData , error ) { var data triageData if err := json . Unmarshal ( jsonIn , & data ) ; err != nil { return nil , err } if data . Builds . Cols . Started == nil { return nil , fmt . Errorf ( " " ) } if data . Builds . JobsRaw == nil { return nil , fmt . Errorf ( " " ) } if data . Builds . JobPaths == nil { return nil , fmt . Errorf ( " " ) } if data . Clustered == nil { return nil , fmt . Errorf ( " " ) } for jobID , mapper := range data . Builds . JobsRaw { switch mapper := mapper . ( type ) { case [ ] interface { } : case map [ string ] interface { } : default : return nil , fmt . Errorf ( " " , jobID , reflect . TypeOf ( mapper ) ) } } return & data , nil } 
func topClusters ( clusters [ ] * Cluster , count int ) [ ] * Cluster { less := func ( i , j int ) bool { return clusters [ i ] . totalBuilds > clusters [ j ] . totalBuilds } sort . SliceStable ( clusters , less ) if len ( clusters ) < count { count = len ( clusters ) } return clusters [ 0 : count ] } 
func ( c * Cluster ) topJobsFailed ( count int ) [ ] * Job { slice := make ( [ ] * Job , len ( c . jobs ) ) i := 0 for jobName , builds := range c . jobs { slice [ i ] = & Job { Name : jobName , Builds : builds } i ++ } less := func ( i , j int ) bool { return len ( slice [ i ] . Builds ) > len ( slice [ j ] . Builds ) } sort . SliceStable ( slice , less ) if len ( slice ) < count { count = len ( slice ) } return slice [ 0 : count ] } 
func ( c * Cluster ) Title ( ) string { return fmt . Sprintf ( " " , c . Identifier [ 0 : 6 ] , c . totalBuilds , c . totalJobs , c . totalTests , c . filer . windowDays , ) } 
func ( c * Cluster ) Body ( closedIssues [ ] * githubapi . Issue ) string { for _ , closed := range closedIssues { if closed . ClosedAt . After ( cutoffTime ) { return " " } } var buf bytes . Buffer fmt . Fprintf ( & buf , " \n " , c . ID ( ) , triageURL , c . Identifier ) fmt . Fprintf ( & buf , " \n \n \n \n " , c . Text ) fmt . Fprintf ( & buf , " \n " , c . totalTests , c . totalJobs , c . totalBuilds ) fmt . Fprintf ( & buf , " \n \n " , c . filer . windowDays , cutoffTime . Format ( timeFormat ) , time . Unix ( c . filer . latestStart , 0 ) . Format ( timeFormat ) ) for _ , test := range c . topTestsFailed ( topTestsCount ) { fmt . Fprintf ( & buf , " \n " , test . Name , len ( test . Jobs ) ) } fmt . Fprint ( & buf , " \n \n \n " ) for _ , job := range c . topJobsFailed ( topJobsCount ) { latest := 0 latestTime := int64 ( 0 ) rowMap := c . filer . data . Builds . Jobs [ job . Name ] for _ , build := range job . Builds { row , _ := rowMap . rowForBuild ( build ) buildTime := c . filer . data . Builds . Cols . Started [ row ] if buildTime > latestTime { latestTime = buildTime latest = build } } path := strings . TrimPrefix ( c . filer . data . Builds . JobPaths [ job . Name ] , " " ) fmt . Fprintf ( & buf , " \n " , job . Name , len ( job . Builds ) , time . Unix ( latestTime , 0 ) . Format ( timeFormat ) , path , latest ) } for _ , closed := range closedIssues { fmt . Fprintf ( & buf , " " , * closed . Number ) } fmt . Fprint ( & buf , " \n " ) } for _ , test := range c . topTestsFailed ( len ( c . Tests ) ) { testNames = append ( testNames , test . Name ) } ownersMap := c . filer . creator . TestsOwners ( testNames ) if len ( ownersMap ) > 0 { fmt . Fprint ( & buf , " \n " ) for user := range ownersMap { fmt . Fprintf ( & buf , " " , user ) } fmt . Fprint ( & buf , " \n " ) } fmt . Fprintf ( & buf , " \n " , triageURL , c . Identifier ) return buf . String ( ) } 
func ( c * Cluster ) Labels ( ) [ ] string { labels := [ ] string { " " } topTests := make ( [ ] string , len ( c . Tests ) ) for i , test := range c . topTestsFailed ( len ( c . Tests ) ) { topTests [ i ] = test . Name } for sig := range c . filer . creator . TestsSIGs ( topTests ) { labels = append ( labels , " " + sig ) } return labels } 
func New ( ) * Cron { return & Cron { cronAgent : cron . New ( ) , jobs : map [ string ] * jobStatus { } , logger : logrus . WithField ( " " , " " ) , } } 
func ( c * Cron ) QueuedJobs ( ) [ ] string { c . lock . Lock ( ) defer c . lock . Unlock ( ) res := [ ] string { } for k , v := range c . jobs { if v . triggered { res = append ( res , k ) } c . jobs [ k ] . triggered = false } return res } 
func ( c * Cron ) SyncConfig ( cfg * config . Config ) error { c . lock . Lock ( ) defer c . lock . Unlock ( ) for _ , p := range cfg . Periodics { if err := c . addPeriodic ( p ) ; err != nil { return err } } periodicNames := sets . NewString ( ) for _ , p := range cfg . AllPeriodics ( ) { periodicNames . Insert ( p . Name ) } existing := sets . NewString ( ) for k := range c . jobs { existing . Insert ( k ) } var removalErrors [ ] error for _ , job := range existing . Difference ( periodicNames ) . List ( ) { if err := c . removeJob ( job ) ; err != nil { removalErrors = append ( removalErrors , err ) } } return errorutil . NewAggregate ( removalErrors ... ) } 
func ( c * Cron ) HasJob ( name string ) bool { c . lock . Lock ( ) defer c . lock . Unlock ( ) _ , ok := c . jobs [ name ] return ok } 
func ( c * Cron ) addJob ( name , cron string ) error { id , err := c . cronAgent . AddFunc ( " " + cron , func ( ) { c . lock . Lock ( ) defer c . lock . Unlock ( ) c . jobs [ name ] . triggered = true c . logger . Infof ( " " , name ) } ) if err != nil { return fmt . Errorf ( " " , name , cron , err ) } c . jobs [ name ] = & jobStatus { entryID : id , cronStr : cron , c . logger . Infof ( " " , name , cron ) return nil } 
func ( c * Cron ) removeJob ( name string ) error { job , ok := c . jobs [ name ] if ! ok { return fmt . Errorf ( " " , name ) } c . cronAgent . Remove ( job . entryID ) delete ( c . jobs , name ) c . logger . Infof ( " " , name ) return nil } 
func UpdateComments ( issueID int , pullRequest bool , db * gorm . DB , client ClientInterface ) { latest := findLatestCommentUpdate ( issueID , db , client . RepositoryName ( ) ) updateIssueComments ( issueID , latest , db , client ) if pullRequest { updatePullComments ( issueID , latest , db , client ) } } 
func GatherProwJobMetrics ( pjs [ ] prowapi . ProwJob ) { for _ , pj := range pjs { if metricMap [ pj . Spec . Job ] == nil { metricMap [ pj . Spec . Job ] = make ( map [ string ] map [ string ] float64 ) } if metricMap [ pj . Spec . Job ] [ string ( pj . Spec . Type ) ] == nil { metricMap [ pj . Spec . Job ] [ string ( pj . Spec . Type ) ] = make ( map [ string ] float64 ) } metricMap [ pj . Spec . Job ] [ string ( pj . Spec . Type ) ] [ string ( pj . Status . State ) ] ++ } for job , jobMap := range metricMap { for jobType , typeMap := range jobMap { for state , count := range typeMap { prowJobs . WithLabelValues ( job , jobType , state ) . Set ( count ) } } } } 
func ( o Options ) Run ( ) int { code , err := o . ExecuteProcess ( ) if err != nil { logrus . WithError ( err ) . Error ( " " ) } if err := o . mark ( code ) ; err != nil { logrus . WithError ( err ) . Error ( " " ) return InternalErrorCode } if o . AlwaysZero { return 0 } return code } 
func ( o Options ) ExecuteProcess ( ) ( int , error ) { if o . ArtifactDir != " " { if err := os . MkdirAll ( o . ArtifactDir , os . ModePerm ) ; err != nil { return InternalErrorCode , fmt . Errorf ( " " , o . ArtifactDir , err ) } } processLogFile , err := os . Create ( o . ProcessLog ) if err != nil { return InternalErrorCode , fmt . Errorf ( " " , o . ProcessLog , err ) } defer processLogFile . Close ( ) output := io . MultiWriter ( os . Stdout , processLogFile ) logrus . SetOutput ( output ) defer logrus . SetOutput ( os . Stdout ) signal . Notify ( interrupt , os . Interrupt , syscall . SIGTERM ) if o . PreviousMarker != " " { ctx , cancel := context . WithCancel ( context . Background ( ) ) go func ( ) { select { case s := <- interrupt : logrus . Errorf ( " " , s ) cancel ( ) case <- ctx . Done ( ) : } } ( ) code , err := wrapper . WaitForMarker ( ctx , o . PreviousMarker ) cancel ( ) if err != nil { return InternalErrorCode , fmt . Errorf ( " " , o . PreviousMarker , err ) } if code != 0 { logrus . Infof ( " " , code ) return PreviousErrorCode , nil } } executable := o . Args [ 0 ] var arguments [ ] string if len ( o . Args ) > 1 { arguments = o . Args [ 1 : ] } command := exec . Command ( executable , arguments ... ) command . Stderr = output command . Stdout = output if err := command . Start ( ) ; err != nil { return InternalErrorCode , fmt . Errorf ( " " , err ) } timeout := optionOrDefault ( o . Timeout , DefaultTimeout ) gracePeriod := optionOrDefault ( o . GracePeriod , DefaultGracePeriod ) var commandErr error cancelled , aborted := false , false done := make ( chan error ) go func ( ) { done <- command . Wait ( ) } ( ) select { case err := <- done : commandErr = err case <- time . After ( timeout ) : logrus . Errorf ( " " , timeout ) cancelled = true gracefullyTerminate ( command , done , gracePeriod ) case s := <- interrupt : logrus . Errorf ( " " , s ) cancelled = true aborted = true gracefullyTerminate ( command , done , gracePeriod ) } var returnCode int if cancelled { if aborted { commandErr = errAborted returnCode = AbortedErrorCode } else { commandErr = errTimedOut returnCode = InternalErrorCode } } else { if status , ok := command . ProcessState . Sys ( ) . ( syscall . WaitStatus ) ; ok { returnCode = status . ExitStatus ( ) } else if commandErr == nil { returnCode = 0 } else { returnCode = 1 } if returnCode != 0 { commandErr = fmt . Errorf ( " " , commandErr ) } } return returnCode , commandErr } 
func optionOrDefault ( option , defaultValue time . Duration ) time . Duration { if option == 0 { return defaultValue } return option } 
func newGCSJobSource ( src string ) ( * gcsJobSource , error ) { gcsURL , err := url . Parse ( fmt . Sprintf ( " " , src ) ) if err != nil { return & gcsJobSource { } , ErrCannotParseSource } gcsPath := & gcs . Path { } err = gcsPath . SetURL ( gcsURL ) if err != nil { return & gcsJobSource { } , ErrCannotParseSource } tokens := strings . FieldsFunc ( gcsPath . Object ( ) , func ( c rune ) bool { return c == '/' } ) if len ( tokens ) < 2 { return & gcsJobSource { } , ErrCannotParseSource } buildID := tokens [ len ( tokens ) - 1 ] name := tokens [ len ( tokens ) - 2 ] return & gcsJobSource { source : src , linkPrefix : " " , bucket : gcsPath . Bucket ( ) , jobPrefix : path . Clean ( gcsPath . Object ( ) ) + " " , jobName : name , buildID : buildID , } , nil } 
func ( af * GCSArtifactFetcher ) artifacts ( key string ) ( [ ] string , error ) { src , err := newGCSJobSource ( key ) if err != nil { return nil , fmt . Errorf ( " " , key , err ) } listStart := time . Now ( ) bucketName , prefix := extractBucketPrefixPair ( src . jobPath ( ) ) artifacts := [ ] string { } bkt := af . client . Bucket ( bucketName ) q := storage . Query { Prefix : prefix , Versions : false , } objIter := bkt . Objects ( context . Background ( ) , & q ) wait := [ ] time . Duration { 16 , 32 , 64 , 128 , 256 , 256 , 512 , 512 } for i := 0 ; ; { oAttrs , err := objIter . Next ( ) if err == iterator . Done { break } if err != nil { logrus . WithFields ( fieldsForJob ( src ) ) . WithError ( err ) . Error ( " " ) if i >= len ( wait ) { return artifacts , fmt . Errorf ( " " , err ) } time . Sleep ( ( wait [ i ] + time . Duration ( rand . Intn ( 10 ) ) ) * time . Millisecond ) i ++ continue } artifacts = append ( artifacts , strings . TrimPrefix ( oAttrs . Name , prefix ) ) i = 0 } listElapsed := time . Since ( listStart ) logrus . WithField ( " " , listElapsed ) . Infof ( " " , len ( artifacts ) ) return artifacts , nil } 
func ( af * GCSArtifactFetcher ) artifact ( key string , artifactName string , sizeLimit int64 ) ( lenses . Artifact , error ) { src , err := newGCSJobSource ( key ) if err != nil { return nil , fmt . Errorf ( " " , key , err ) } bucketName , prefix := extractBucketPrefixPair ( src . jobPath ( ) ) bkt := af . client . Bucket ( bucketName ) obj := & gcsArtifactHandle { bkt . Object ( path . Join ( prefix , artifactName ) ) } artifactLink := & url . URL { Scheme : httpsScheme , Host : " " , Path : path . Join ( src . jobPath ( ) , artifactName ) , } return NewGCSArtifact ( context . Background ( ) , obj , artifactLink . String ( ) , artifactName , sizeLimit ) , nil } 
func ( src * gcsJobSource ) canonicalLink ( ) string { return path . Join ( src . linkPrefix , src . bucket , src . jobPrefix ) } 
func ( src * gcsJobSource ) jobPath ( ) string { return fmt . Sprintf ( " " , src . bucket , src . jobPrefix ) } 
func requirementDiff ( pr * PullRequest , q * config . TideQuery , cc contextChecker ) ( string , int ) { const maxLabelChars = 50 var desc string var diff int chars := len ( labels [ 0 ] ) for ; i < len ( labels ) ; i ++ { if chars + len ( labels [ i ] ) > maxLabelChars { break } chars += len ( labels [ i ] ) + 2 } return labels [ : i ] } for _ , excludedBranch := range q . ExcludedBranches { if string ( pr . BaseRef . Name ) == excludedBranch { targetBranchBlacklisted = true break } } for _ , includedBranch := range q . IncludedBranches { if string ( pr . BaseRef . Name ) == includedBranch { targetBranchWhitelisted = true break } } if targetBranchBlacklisted || ! targetBranchWhitelisted { diff += 1000 if desc == " " { desc = fmt . Sprintf ( " " , pr . BaseRef . Name ) } } if desc == " " { desc = fmt . Sprintf ( " " , q . Milestone ) } } for _ , l1 := range q . Labels { var found bool for _ , l2 := range pr . Labels . Nodes { if string ( l2 . Name ) == l1 { found = true break } } if ! found { missingLabels = append ( missingLabels , l1 ) } } diff += len ( missingLabels ) if desc == " " && len ( missingLabels ) > 0 { sort . Strings ( missingLabels ) trunced := truncate ( missingLabels ) if len ( trunced ) == 1 { desc = fmt . Sprintf ( " " , trunced [ 0 ] ) } else { desc = fmt . Sprintf ( " " , strings . Join ( trunced , " " ) ) } } var presentLabels [ ] string for _ , l1 := range q . MissingLabels { for _ , l2 := range pr . Labels . Nodes { if string ( l2 . Name ) == l1 { presentLabels = append ( presentLabels , l1 ) break } } } diff += len ( presentLabels ) if desc == " " && len ( presentLabels ) > 0 { sort . Strings ( presentLabels ) trunced := truncate ( presentLabels ) if len ( trunced ) == 1 { desc = fmt . Sprintf ( " " , trunced [ 0 ] ) } else { desc = fmt . Sprintf ( " " , strings . Join ( trunced , " " ) ) } } for _ , commit := range pr . Commits . Nodes { if commit . Commit . OID == pr . HeadRefOID { for _ , ctx := range unsuccessfulContexts ( commit . Commit . Status . Contexts , cc , logrus . New ( ) . WithFields ( pr . logFields ( ) ) ) { contexts = append ( contexts , string ( ctx . Context ) ) } } } diff += len ( contexts ) if desc == " " && len ( contexts ) > 0 { sort . Strings ( contexts ) trunced := truncate ( contexts ) if len ( trunced ) == 1 { desc = fmt . Sprintf ( " " , trunced [ 0 ] ) } else { desc = fmt . Sprintf ( " " , strings . Join ( trunced , " " ) ) } } } 
func expectedStatus ( queryMap * config . QueryMap , pr * PullRequest , pool map [ string ] PullRequest , cc contextChecker ) ( string , string ) { if _ , ok := pool [ prKey ( pr ) ] ; ! ok { minDiffCount := - 1 var minDiff string for _ , q := range queryMap . ForRepo ( string ( pr . Repository . Owner . Login ) , string ( pr . Repository . Name ) ) { diff , diffCount := requirementDiff ( pr , & q , cc ) if minDiffCount == - 1 || diffCount < minDiffCount { minDiffCount = diffCount minDiff = diff } } return github . StatusPending , fmt . Sprintf ( statusNotInPool , minDiff ) } return github . StatusSuccess , statusInPool } 
func targetURL ( c config . Getter , pr * PullRequest , log * logrus . Entry ) string { var link string if tideURL := c ( ) . Tide . TargetURL ; tideURL != " " { link = tideURL } else if baseURL := c ( ) . Tide . PRStatusBaseURL ; baseURL != " " { parseURL , err := url . Parse ( baseURL ) if err != nil { log . WithError ( err ) . Error ( " " ) } else { prQuery := fmt . Sprintf ( " " , pr . Repository . NameWithOwner , pr . Author . Login , pr . HeadRefName ) values := parseURL . Query ( ) values . Set ( " " , prQuery ) parseURL . RawQuery = values . Encode ( ) link = parseURL . String ( ) } } return link } 
func ( sc * statusController ) waitSync ( ) { for { select { case <- wait : sc . Lock ( ) pool := sc . poolPRs sc . Unlock ( ) sc . sync ( pool ) return case more := <- sc . newPoolPending : if ! more { return } } } } 
func newBuildConfig ( cfg rest . Config , stop chan struct { } ) ( * buildConfig , error ) { bc , err := buildset . NewForConfig ( & cfg ) if err != nil { return nil , err } if err != nil { return nil , err } bif . Build ( ) . V1alpha1 ( ) . Builds ( ) . Lister ( ) go bif . Start ( stop ) return & buildConfig { client : bc , informer : bif . Build ( ) . V1alpha1 ( ) . Builds ( ) , } , nil } 
func NewClient ( token string , dryRun bool ) * Client { httpClient := & http . Client { Transport : & oauth2 . Transport { Base : http . DefaultTransport , Source : oauth2 . ReuseTokenSource ( nil , oauth2 . StaticTokenSource ( & oauth2 . Token { AccessToken : token } ) ) , } , } client := github . NewClient ( httpClient ) return & Client { issueService : client . Issues , prService : client . PullRequests , repoService : client . Repositories , userService : client . Users , retries : 5 , retryInitialBackoff : time . Second , tokenReserve : 50 , dryRun : dryRun , } } 
func ( c * Client ) retry ( action string , call func ( ) ( * github . Response , error ) ) ( * github . Response , error ) { var err error var resp * github . Response for retryCount := 0 ; retryCount <= c . retries ; retryCount ++ { if resp , err = call ( ) ; err == nil { c . limitRate ( & resp . Rate ) return resp , nil } switch err := err . ( type ) { case * github . RateLimitError : c . limitRate ( & err . Rate ) case * github . TwoFactorAuthError : return resp , err case * retryAbort : return resp , err } if retryCount == c . retries { return resp , err } glog . Errorf ( " \n " , action , err ) c . sleepForAttempt ( retryCount ) } return resp , err } 
func ( c * Client ) depaginate ( action string , opts * github . ListOptions , call func ( ) ( [ ] interface { } , * github . Response , error ) ) ( [ ] interface { } , error ) { var allItems [ ] interface { } wrapper := func ( ) ( * github . Response , error ) { items , resp , err := call ( ) if err == nil { allItems = append ( allItems , items ... ) } return resp , err } opts . Page = 1 opts . PerPage = 100 lastPage := 1 for ; opts . Page <= lastPage ; opts . Page ++ { resp , err := c . retry ( action , wrapper ) if err != nil { return allItems , fmt . Errorf ( " " , opts . Page , lastPage , err ) } if resp . LastPage > 0 { lastPage = resp . LastPage } } return allItems , nil } 
func NewHelpAgent ( pa pluginAgent , ghc githubClient ) * HelpAgent { l := logrus . WithField ( " " , " " ) return & HelpAgent { log : l , pa : pa , oa : newOrgAgent ( l , ghc , newRepoDetectionLimit ) , } } 
func ( ha * HelpAgent ) GeneratePluginHelp ( ) * pluginhelp . Help { config := ha . pa . Config ( ) orgToRepos := ha . oa . orgToReposMap ( config ) normalRevMap , externalRevMap := reversePluginMaps ( config , orgToRepos ) allPlugins , pluginHelp := ha . generateNormalPluginHelp ( config , normalRevMap ) allExternalPlugins , externalPluginHelp := ha . generateExternalPluginHelp ( config , externalRevMap ) for repo , plugins := range config . Plugins { repoPlugins [ repo ] = plugins } repoExternalPlugins := map [ string ] [ ] string { " " : allExternalPlugins , } for repo , exts := range config . ExternalPlugins { for _ , ext := range exts { repoExternalPlugins [ repo ] = append ( repoExternalPlugins [ repo ] , ext . Name ) } } return & pluginhelp . Help { AllRepos : allRepos ( config , orgToRepos ) , RepoPlugins : repoPlugins , RepoExternalPlugins : repoExternalPlugins , PluginHelp : pluginHelp , ExternalPluginHelp : externalPluginHelp , } } 
func reversePluginMaps ( config * plugins . Configuration , orgToRepos map [ string ] sets . String ) ( normal , external map [ string ] [ ] string ) { normal = map [ string ] [ ] string { } for repo , enabledPlugins := range config . Plugins { var repos [ ] string if ! strings . Contains ( repo , " " ) { if flattened , ok := orgToRepos [ repo ] ; ok { repos = flattened . List ( ) } } else { repos = [ ] string { repo } } for _ , plugin := range enabledPlugins { normal [ plugin ] = append ( normal [ plugin ] , repos ... ) } } external = map [ string ] [ ] string { } for repo , extPlugins := range config . ExternalPlugins { var repos [ ] string if flattened , ok := orgToRepos [ repo ] ; ok { repos = flattened . List ( ) } else { repos = [ ] string { repo } } for _ , plugin := range extPlugins { external [ plugin . Name ] = append ( external [ plugin . Name ] , repos ... ) } } return } 
func orgsInConfig ( config * plugins . Configuration ) sets . String { orgs := sets . NewString ( ) for repo := range config . Plugins { if ! strings . Contains ( repo , " " ) { orgs . Insert ( repo ) } } for repo := range config . ExternalPlugins { if ! strings . Contains ( repo , " " ) { orgs . Insert ( repo ) } } return orgs } 
func ( r * requestCoalescer ) RoundTrip ( req * http . Request ) ( * http . Response , error ) { } var cacheMode = ModeError resp , err := func ( ) ( * http . Response , error ) { key := req . URL . String ( ) r . Lock ( ) waiter , ok := r . keys [ key ] if ok { } waiter . L . Lock ( ) r . Unlock ( ) waiter . waiting = true waiter . L . Unlock ( ) } resp , err := http . ReadResponse ( bufio . NewReader ( bytes . NewBuffer ( waiter . resp ) ) , nil ) if err != nil { logrus . WithField ( " " , key ) . WithError ( err ) . Error ( " " ) return nil , err } cacheMode = ModeCoalesced return resp , nil } r . keys [ key ] = waiter r . Unlock ( ) resp , err := r . delegate . RoundTrip ( req ) delete ( r . keys , key ) r . Unlock ( ) waiter . L . Lock ( ) if waiter . waiting { if err != nil { waiter . resp , waiter . err = nil , err } else { } waiter . Broadcast ( ) } waiter . L . Unlock ( ) if err != nil { logrus . WithField ( " " , key ) . WithError ( err ) . Error ( " " ) return nil , err } cacheMode = cacheResponseMode ( resp . Header ) return resp , nil } ( ) cacheCounter . WithLabelValues ( string ( cacheMode ) ) . Inc ( ) if resp != nil { resp . Header . Set ( CacheModeHeader , string ( cacheMode ) ) } return resp , err } 
func ( o * Options ) Validate ( ) error { if len ( o . Args ) == 0 { return errors . New ( " " ) } return o . Options . Validate ( ) } 
func ( o * Options ) AddFlags ( flags * flag . FlagSet ) { flags . DurationVar ( & o . Timeout , " " , DefaultTimeout , " " ) flags . DurationVar ( & o . GracePeriod , " " , DefaultGracePeriod , " " ) flags . StringVar ( & o . ArtifactDir , " " , " " , " " ) o . Options . AddFlags ( flags ) } 
func getPullCommitHash ( pull string ) ( string , error ) { match := pullCommitRe . FindStringSubmatch ( pull ) if len ( match ) != 2 { expected := " " return " " , fmt . Errorf ( " " , pull , expected ) } return match [ 1 ] , nil } 
func listJobBuilds ( bucket storageBucket , jobPrefixes [ ] string ) [ ] jobBuilds { jobch := make ( chan jobBuilds ) defer close ( jobch ) for i , jobPrefix := range jobPrefixes { go func ( i int , jobPrefix string ) { buildPrefixes , err := bucket . listSubDirs ( jobPrefix ) if err != nil { logrus . WithError ( err ) . Warningf ( " " , jobPrefix ) } jobch <- jobBuilds { name : path . Base ( jobPrefix ) , buildPrefixes : buildPrefixes , } } ( i , jobPrefix ) } jobs := [ ] jobBuilds { } for range jobPrefixes { job := <- jobch jobs = append ( jobs , job ) } return jobs } 
func getPRBuildData ( bucket storageBucket , jobs [ ] jobBuilds ) [ ] buildData { buildch := make ( chan buildData ) defer close ( buildch ) expected := 0 for _ , job := range jobs { for j , buildPrefix := range job . buildPrefixes { go func ( j int , jobName , buildPrefix string ) { build , err := getBuildData ( bucket , buildPrefix ) if err != nil { logrus . WithError ( err ) . Warningf ( " " , buildPrefix ) } split := strings . Split ( strings . TrimSuffix ( buildPrefix , " " ) , " " ) build . SpyglassLink = path . Join ( spyglassPrefix , bucket . getName ( ) , buildPrefix ) build . ID = split [ len ( split ) - 1 ] build . jobName = jobName build . prefix = buildPrefix build . index = j buildch <- build } ( j , job . name , buildPrefix ) expected ++ } } builds := [ ] buildData { } for k := 0 ; k < expected ; k ++ { build := <- buildch builds = append ( builds , build ) } return builds } 
func parsePullURL ( u * url . URL ) ( org , repo string , pr int , err error ) { var prStr string vals := u . Query ( ) if org = vals . Get ( " " ) ; org == " " { return " " , " " , 0 , fmt . Errorf ( " " ) } if repo = vals . Get ( " " ) ; repo == " " { return " " , " " , 0 , fmt . Errorf ( " " ) } prStr = vals . Get ( " " ) pr , err = strconv . Atoi ( prStr ) if err != nil { return " " , " " , 0 , fmt . Errorf ( " " , prStr , err ) } return org , repo , pr , nil } 
func getGCSDirsForPR ( config * config . Config , org , repo string , pr int ) ( map [ string ] sets . String , error ) { toSearch := make ( map [ string ] sets . String ) fullRepo := org + " " + repo presubmits , ok := config . Presubmits [ fullRepo ] if ! ok { return toSearch , fmt . Errorf ( " " , fullRepo ) } for _ , presubmit := range presubmits { var gcsConfig * v1 . GCSConfiguration if presubmit . DecorationConfig != nil && presubmit . DecorationConfig . GCSConfiguration != nil { gcsConfig = presubmit . DecorationConfig . GCSConfiguration } else { } gcsPath , _ , _ := gcsupload . PathsForJob ( gcsConfig , & downwardapi . JobSpec { Type : v1 . PresubmitJob , Job : presubmit . Name , Refs : & v1 . Refs { Repo : repo , Org : org , Pulls : [ ] v1 . Pull { { Number : pr } , } , } , } , " " ) gcsPath , _ = path . Split ( path . Clean ( gcsPath ) ) if _ , ok := toSearch [ gcsConfig . Bucket ] ; ! ok { toSearch [ gcsConfig . Bucket ] = sets . String { } } toSearch [ gcsConfig . Bucket ] . Insert ( gcsPath ) } return toSearch , nil } 
func imgPostContInfo ( d * Daemon , r * http . Request , req api . ImagesPost , op * operation , builddir string ) ( * api . Image , error ) { info := api . Image { } info . Properties = map [ string ] string { } project := projectParam ( r ) name := req . Source . Name ctype := req . Source . Type if ctype == " " || name == " " { return nil , fmt . Errorf ( " " ) } switch ctype { case " " : if ! shared . IsSnapshot ( name ) { return nil , fmt . Errorf ( " " ) } case " " : if shared . IsSnapshot ( name ) { return nil , fmt . Errorf ( " " ) } default : return nil , fmt . Errorf ( " " ) } info . Filename = req . Filename switch req . Public { case true : info . Public = true case false : info . Public = false } c , err := containerLoadByProjectAndName ( d . State ( ) , project , name ) if err != nil { return nil , err } if err != nil { return nil , err } defer os . Remove ( imageFile . Name ( ) ) sumSize := func ( path string , fi os . FileInfo , err error ) error { if err == nil { totalSize += fi . Size ( ) } return nil } err = filepath . Walk ( c . RootfsPath ( ) , sumSize ) if err != nil { return nil , err } imageProgressWriter := & ioprogress . ProgressWriter { Tracker : & ioprogress . ProgressTracker { Handler : func ( value , speed int64 ) { percent := int64 ( 0 ) processed := int64 ( 0 ) if totalSize > 0 { percent = value processed = totalSize * ( percent / 100.0 ) } else { processed = value } shared . SetProgressMetadata ( metadata , " " , " " , percent , processed , speed ) op . UpdateMetadata ( metadata ) } , Length : totalSize , } , } sha256 := sha256 . New ( ) var compress string var writer io . Writer if req . CompressionAlgorithm != " " { compress = req . CompressionAlgorithm } else { compress , err = cluster . ConfigGetString ( d . cluster , " " ) if err != nil { return nil , err } } var compressErr error if compress != " " { wg . Add ( 1 ) tarReader , tarWriter := io . Pipe ( ) imageProgressWriter . WriteCloser = tarWriter writer = imageProgressWriter compressWriter := io . MultiWriter ( imageFile , sha256 ) go func ( ) { defer wg . Done ( ) compressErr = compressFile ( compress , tarReader , compressWriter ) } ( ) } else { imageProgressWriter . WriteCloser = imageFile writer = io . MultiWriter ( imageProgressWriter , sha256 ) } err = c . Export ( writer , req . Properties ) wg . Wait ( ) if err != nil { return nil , err } if compressErr != nil { return nil , err } imageFile . Close ( ) fi , err := os . Stat ( imageFile . Name ( ) ) if err != nil { return nil , err } info . Size = fi . Size ( ) info . Fingerprint = fmt . Sprintf ( " " , sha256 . Sum ( nil ) ) _ , _ , err = d . cluster . ImageGet ( project , info . Fingerprint , false , true ) if err != db . ErrNoSuchObject { if err != nil { return nil , err } return & info , fmt . Errorf ( " " , info . Fingerprint ) } finalName := shared . VarPath ( " " , info . Fingerprint ) err = shared . FileMove ( imageFile . Name ( ) , finalName ) if err != nil { return nil , err } info . Architecture , _ = osarch . ArchitectureName ( c . Architecture ( ) ) info . Properties = req . Properties if err != nil { return nil , err } return & info , nil } 
func imageCreateInPool ( d * Daemon , info * api . Image , storagePool string ) error { if storagePool == " " { return fmt . Errorf ( " " ) } if err != nil { return err } if err != nil { return err } return nil } 
func autoUpdateImage ( d * Daemon , op * operation , id int , info * api . Image , project string ) error { fingerprint := info . Fingerprint _ , source , err := d . cluster . ImageSourceGet ( id ) if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : fingerprint } ) return err } if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : fingerprint } ) return err } if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : fingerprint } ) return err } } logger . Debug ( " " , log . Ctx { " " : fingerprint , " " : source . Server , " " : source . Protocol , " " : source . Alias } ) } metadata := map [ string ] interface { } { " " : result } op . UpdateMetadata ( metadata ) } for _ , poolName := range poolNames { newInfo , err := d . ImageDownload ( op , source . Server , source . Protocol , source . Certificate , " " , source . Alias , false , true , poolName , false , project ) if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : fingerprint } ) continue } hash = newInfo . Fingerprint if hash == fingerprint { logger . Debug ( " " , log . Ctx { " " : fingerprint } ) continue } newId , _ , err := d . cluster . ImageGet ( " " , hash , false , true ) if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : hash } ) continue } if info . Cached { err = d . cluster . ImageLastAccessInit ( hash ) if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : hash } ) continue } } err = d . cluster . ImageLastAccessUpdate ( hash , info . LastUsedAt ) if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : hash } ) continue } err = d . cluster . ImageAliasesMove ( id , newId ) if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : hash } ) continue } if err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : fingerprint } ) } } } return nil } if shared . PathExists ( fname ) { err = os . Remove ( fname ) if err != nil { logger . Debugf ( " " , fname , err ) } } if shared . PathExists ( fname ) { err = os . Remove ( fname ) if err != nil { logger . Debugf ( " " , fname , err ) } } } setRefreshResult ( true ) return nil } 
func imageDeleteFromDisk ( fingerprint string ) { if shared . PathExists ( fname ) { err := os . Remove ( fname ) if err != nil && ! os . IsNotExist ( err ) { logger . Errorf ( " " , fname , err ) } } if shared . PathExists ( fname ) { err := os . Remove ( fname ) if err != nil && ! os . IsNotExist ( err ) { logger . Errorf ( " " , fname , err ) } } } 
func networksGet ( d * Daemon , r * http . Request ) Response { recursion := util . IsRecursionRequest ( r ) ifs , err := networkGetInterfaces ( d . cluster ) if err != nil { return InternalError ( err ) } resultString := [ ] string { } resultMap := [ ] api . Network { } for _ , iface := range ifs { if ! recursion { resultString = append ( resultString , fmt . Sprintf ( " " , version . APIVersion , iface ) ) } else { net , err := doNetworkGet ( d , iface ) if err != nil { continue } resultMap = append ( resultMap , net ) } } if ! recursion { return SyncResponse ( true , resultString ) } return SyncResponse ( true , resultMap ) } 
func doNetworksCreate ( d * Daemon , req api . NetworksPost , withDatabase bool ) error { if err != nil { return err } err = n . Start ( ) if err != nil { n . Delete ( withDatabase ) return err } return nil } 
func networkLoadByName ( s * state . State , name string ) ( * network , error ) { id , dbInfo , err := s . Cluster . NetworkGet ( name ) if err != nil { return nil , err } n := network { state : s , id : id , name : name , description : dbInfo . Description , config : dbInfo . Config } return & n , nil } 
func OpenNode ( dir string , fresh func ( * Node ) error , legacyPatches map [ int ] * LegacyPatch ) ( * Node , * Dump , error ) { db , err := node . Open ( dir ) if err != nil { return nil , nil , err } legacyHook := legacyPatchHook ( db , legacyPatches ) hook := func ( version int , tx * sql . Tx ) error { if version == node . UpdateFromPreClustering { logger . Debug ( " " ) var err error dump , err = LoadPreClusteringData ( tx ) if err != nil { return err } } return legacyHook ( version , tx ) } initial , err := node . EnsureSchema ( db , dir , hook ) if err != nil { return nil , nil , err } node := & Node { db : db , dir : dir , } if initial == 0 { if fresh != nil { err := fresh ( node ) if err != nil { return nil , nil , err } } } db . SetMaxOpenConns ( 1 ) db . SetMaxIdleConns ( 1 ) return node , dump , nil } 
func ( n * Node ) Transaction ( f func ( * NodeTx ) error ) error { nodeTx := & NodeTx { } return query . Transaction ( n . db , func ( tx * sql . Tx ) error { nodeTx . tx = tx return f ( nodeTx ) } ) } 
func OpenCluster ( name string , store dqlite . ServerStore , address , dir string , timeout time . Duration , options ... dqlite . DriverOption ) ( * Cluster , error ) { db , err := cluster . Open ( name , store , options ... ) if err != nil { return nil , errors . Wrap ( err , " " ) } for i := 0 ; ; i ++ { if i > 5 { logPriority = 2 if i > 15 && ! ( ( i % 5 ) == 0 ) { logPriority = 0 } } err = db . Ping ( ) if err == nil { break } cause := errors . Cause ( err ) if cause != dqlite . ErrNoAvailableLeader { return nil , err } switch logPriority { case 1 : logger . Debugf ( " " , i , err ) case 2 : logger . Warnf ( " " , i , err ) } time . Sleep ( 2 * time . Second ) select { case <- timer : return nil , fmt . Errorf ( " " ) default : } } nodesVersionsMatch , err := cluster . EnsureSchema ( db , address , dir ) if err != nil { return nil , errors . Wrap ( err , " " ) } db . SetMaxOpenConns ( 1 ) db . SetMaxIdleConns ( 1 ) if ! nodesVersionsMatch { cluster := & Cluster { db : db , stmts : map [ int ] * sql . Stmt { } , } return cluster , ErrSomeNodesAreBehind } stmts , err := cluster . PrepareStmts ( db ) if err != nil { return nil , errors . Wrap ( err , " " ) } cluster := & Cluster { db : db , stmts : stmts , } if err != nil { return errors . Wrap ( err , " " ) } if len ( nodes ) == 1 && nodes [ 0 ] . Address == " " { return nil } for _ , node := range nodes { if node . Address == address { cluster . nodeID = node . ID return nil } } return fmt . Errorf ( " " , address ) } ) if err != nil { return nil , err } return cluster , err } 
func ForLocalInspectionWithPreparedStmts ( db * sql . DB ) ( * Cluster , error ) { c := ForLocalInspection ( db ) stmts , err := cluster . PrepareStmts ( c . db ) if err != nil { return nil , errors . Wrap ( err , " " ) } c . stmts = stmts return c , nil } 
func ( c * Cluster ) SetDefaultTimeout ( timeout time . Duration ) { driver := c . db . Driver ( ) . ( * dqlite . Driver ) driver . SetContextTimeout ( timeout ) } 
func ( c * Cluster ) Transaction ( f func ( * ClusterTx ) error ) error { c . mu . RLock ( ) defer c . mu . RUnlock ( ) return c . transaction ( f ) } 
func ( c * Cluster ) EnterExclusive ( ) error { logger . Debug ( " " ) ch := make ( chan struct { } ) go func ( ) { c . mu . Lock ( ) ch <- struct { } { } } ( ) timeout := 20 * time . Second select { case <- ch : return nil case <- time . After ( timeout ) : return fmt . Errorf ( " " , timeout ) } } 
func ( c * Cluster ) ExitExclusive ( f func ( * ClusterTx ) error ) error { logger . Debug ( " " ) defer c . mu . Unlock ( ) return c . transaction ( f ) } 
func ( c * Cluster ) Close ( ) error { for _ , stmt := range c . stmts { stmt . Close ( ) } return c . db . Close ( ) } 
func TxCommit ( tx * sql . Tx ) error { err := tx . Commit ( ) if err == nil || err == sql . ErrTxDone { } return err } 
func queryScan ( db * sql . DB , q string , inargs [ ] interface { } , outfmt [ ] interface { } ) ( [ ] [ ] interface { } , error ) { return doDbQueryScan ( db , q , inargs , outfmt ) } 
func ( c * Config ) ParseRemote ( raw string ) ( string , string , error ) { result := strings . SplitN ( raw , " " , 2 ) if len ( result ) == 1 { return c . DefaultRemote , raw , nil } _ , ok := c . Remotes [ result [ 0 ] ] if ! ok { } return " " , " " , fmt . Errorf ( " \" \" " , result [ 0 ] ) } return result [ 0 ] , result [ 1 ] , nil } 
func ( c * Config ) GetContainerServer ( name string ) ( lxd . ContainerServer , error ) { if ! ok { return nil , fmt . Errorf ( " \" \" " , name ) } } if err != nil { return nil , err } if err != nil { return nil , err } if remote . Project != " " && remote . Project != " " { d = d . UseProject ( remote . Project ) } if c . ProjectOverride != " " { d = d . UseProject ( c . ProjectOverride ) } return d , nil } } d , err := lxd . ConnectLXD ( remote . Addr , args ) if err != nil { return nil , err } if remote . Project != " " && remote . Project != " " { d = d . UseProject ( remote . Project ) } if c . ProjectOverride != " " { d = d . UseProject ( c . ProjectOverride ) } return d , nil } 
func ( c * Config ) GetImageServer ( name string ) ( lxd . ImageServer , error ) { if ! ok { return nil , fmt . Errorf ( " \" \" " , name ) } if err != nil { return nil , err } if err != nil { return nil , err } if remote . Project != " " && remote . Project != " " { d = d . UseProject ( remote . Project ) } if c . ProjectOverride != " " { d = d . UseProject ( c . ProjectOverride ) } return d , nil } if err != nil { return nil , err } return d , nil } if err != nil { return nil , err } return d , nil } if err != nil { return nil , err } if remote . Project != " " && remote . Project != " " { d = d . UseProject ( remote . Project ) } if c . ProjectOverride != " " { d = d . UseProject ( c . ProjectOverride ) } return d , nil } 
func ( s * OS ) initAppArmor ( ) { _ , err := exec . LookPath ( " " ) if os . Getenv ( " " ) == " " { logger . Warnf ( " " ) } else if ! shared . IsDir ( " " ) { logger . Warnf ( " " ) } else if err != nil { logger . Warnf ( " " ) } else { s . AppArmorAvailable = true } s . AppArmorStacking = appArmorCanStack ( ) if shared . PathExists ( " " ) { contentBytes , err := ioutil . ReadFile ( " " ) if err == nil && string ( contentBytes ) == " \n " { s . AppArmorStacked = true } } if ! haveMacAdmin ( ) { if s . AppArmorAvailable { logger . Warnf ( " " ) } } else if s . RunningInUserNS && ! s . AppArmorStacked { if s . AppArmorAvailable { logger . Warnf ( " " ) } } else { s . AppArmorAdmin = true } profile := util . AppArmorProfile ( ) if profile != " " && profile != " " { if s . AppArmorAvailable { logger . Warnf ( " " ) } s . AppArmorConfined = true } } 
func appArmorCanStack ( ) bool { contentBytes , err := ioutil . ReadFile ( " " ) if err != nil { return false } if string ( contentBytes ) != " \n " { return false } contentBytes , err = ioutil . ReadFile ( " " ) if err != nil { return false } content := string ( contentBytes ) parts := strings . Split ( strings . TrimSpace ( content ) , " " ) if len ( parts ) == 0 { logger . Warn ( " " , log . Ctx { " " : content } ) return false } major , err := strconv . Atoi ( parts [ 0 ] ) if err != nil { logger . Warn ( " " , log . Ctx { " " : content } ) return false } minor := 0 if len ( parts ) == 2 { minor , err = strconv . Atoi ( parts [ 1 ] ) if err != nil { logger . Warn ( " " , log . Ctx { " " : content } ) return false } } return major >= 1 && minor >= 2 } 
func containerDeviceAdd ( client lxd . ContainerServer , name string , devName string , dev map [ string ] string ) error { if err != nil { return err } if ok { return fmt . Errorf ( i18n . G ( " " ) , devName ) } container . Devices [ devName ] = dev op , err := client . UpdateContainer ( name , container . Writable ( ) , etag ) if err != nil { return err } return op . Wait ( ) } 
func profileDeviceAdd ( client lxd . ContainerServer , name string , devName string , dev map [ string ] string ) error { if err != nil { return err } if ok { return fmt . Errorf ( i18n . G ( " " ) , devName ) } err = client . UpdateProfile ( name , profile . Writable ( ) , profileEtag ) if err != nil { return err } return nil } 
func ensureImageAliases ( client lxd . ContainerServer , aliases [ ] api . ImageAlias , fingerprint string ) error { if len ( aliases ) == 0 { return nil } names := make ( [ ] string , len ( aliases ) ) for i , alias := range aliases { names [ i ] = alias . Name } sort . Strings ( names ) resp , err := client . GetImageAliases ( ) if err != nil { return err } if err != nil { fmt . Println ( fmt . Sprintf ( i18n . G ( " " ) , alias . Name ) ) } } aliasPost . Name = alias . Name aliasPost . Target = fingerprint err := client . CreateImageAlias ( aliasPost ) if err != nil { fmt . Println ( fmt . Sprintf ( i18n . G ( " " ) , alias . Name ) ) } } return nil } 
func GetExistingAliases ( aliases [ ] string , allAliases [ ] api . ImageAliasesEntry ) [ ] api . ImageAliasesEntry { existing := [ ] api . ImageAliasesEntry { } for _ , alias := range allAliases { name := alias . Name pos := sort . SearchStrings ( aliases , name ) if pos < len ( aliases ) && aliases [ pos ] == name { existing = append ( existing , alias ) } } return existing } 
func ( o StatusCode ) String ( ) string { return map [ StatusCode ] string { OperationCreated : " " , Started : " " , Stopped : " " , Running : " " , Cancelling : " " , Pending : " " , Success : " " , Failure : " " , Cancelled : " " , Starting : " " , Stopping : " " , Aborting : " " , Freezing : " " , Frozen : " " , Thawed : " " , Error : " " , } [ o ] } 
func ( c * Cluster ) ImagesGet ( project string , public bool ) ( [ ] string , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return nil , err } q := ` SELECT fingerprint FROM images JOIN projects ON projects.id = images.project_id WHERE projects.name = ? ` if public == true { q += " " } var fp string inargs := [ ] interface { } { project } outfmt := [ ] interface { } { fp } dbResults , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return [ ] string { } , err } results := [ ] string { } for _ , r := range dbResults { results = append ( results , r [ 0 ] . ( string ) ) } return results , nil } 
func ( c * Cluster ) ImagesGetExpired ( expiry int64 ) ( [ ] string , error ) { q := `SELECT fingerprint, last_use_date, upload_date FROM images WHERE cached=1` var fpStr string var useStr string var uploadStr string inargs := [ ] interface { } { } outfmt := [ ] interface { } { fpStr , useStr , uploadStr } dbResults , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return [ ] string { } , err } results := [ ] string { } for _ , r := range dbResults { if r [ 1 ] != " " { timestamp = r [ 1 ] } var imageExpiry time . Time err = imageExpiry . UnmarshalText ( [ ] byte ( timestamp . ( string ) ) ) if err != nil { return [ ] string { } , err } imageExpiry = imageExpiry . Add ( time . Duration ( expiry * 24 ) * time . Hour ) } results = append ( results , r [ 0 ] . ( string ) ) } return results , nil } 
func ( c * Cluster ) ImageSourceInsert ( id int , server string , protocol string , certificate string , alias string ) error { stmt := `INSERT INTO images_source (image_id, server, protocol, certificate, alias) values (?, ?, ?, ?, ?)` protocolInt := - 1 for protoInt , protoString := range ImageSourceProtocol { if protoString == protocol { protocolInt = protoInt } } if protocolInt == - 1 { return fmt . Errorf ( " " , protocol ) } err := exec ( c . db , stmt , id , server , protocolInt , certificate , alias ) return err } 
func ( c * Cluster ) ImageSourceGet ( imageID int ) ( int , api . ImageSource , error ) { q := `SELECT id, server, protocol, certificate, alias FROM images_source WHERE image_id=?` id := 0 protocolInt := - 1 result := api . ImageSource { } arg1 := [ ] interface { } { imageID } arg2 := [ ] interface { } { & id , & result . Server , & protocolInt , & result . Certificate , & result . Alias } err := dbQueryRowScan ( c . db , q , arg1 , arg2 ) if err != nil { if err == sql . ErrNoRows { return - 1 , api . ImageSource { } , ErrNoSuchObject } return - 1 , api . ImageSource { } , err } protocol , found := ImageSourceProtocol [ protocolInt ] if ! found { return - 1 , api . ImageSource { } , fmt . Errorf ( " " , protocolInt ) } result . Protocol = protocol return id , result , nil } 
func ( c * Cluster ) ImageSourceGetCachedFingerprint ( server string , protocol string , alias string ) ( string , error ) { protocolInt := - 1 for protoInt , protoString := range ImageSourceProtocol { if protoString == protocol { protocolInt = protoInt } } if protocolInt == - 1 { return " " , fmt . Errorf ( " " , protocol ) } q := `SELECT images.fingerprint FROM images_source INNER JOIN images ON images_source.image_id=images.id WHERE server=? AND protocol=? AND alias=? AND auto_update=1 ORDER BY creation_date DESC` fingerprint := " " arg1 := [ ] interface { } { server , protocolInt , alias } arg2 := [ ] interface { } { & fingerprint } err := dbQueryRowScan ( c . db , q , arg1 , arg2 ) if err != nil { if err == sql . ErrNoRows { return " " , ErrNoSuchObject } return " " , err } return fingerprint , nil } 
func ( c * Cluster ) ImageExists ( project string , fingerprint string ) ( bool , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return false , err } var exists bool query := ` SELECT COUNT(*) > 0 FROM images JOIN projects ON projects.id = images.project_id WHERE projects.name = ? AND fingerprint=? ` inargs := [ ] interface { } { project , fingerprint } outargs := [ ] interface { } { & exists } err = dbQueryRowScan ( c . db , query , inargs , outargs ) if err == sql . ErrNoRows { return exists , ErrNoSuchObject } return exists , err } 
func ( c * Cluster ) ImageGet ( project , fingerprint string , public bool , strictMatching bool ) ( int , * api . Image , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return - 1 , nil , err } var create , expire , used , upload * time . Time id := - 1 arch := - 1 inargs := [ ] interface { } { project } query := ` SELECT images.id, fingerprint, filename, size, cached, public, auto_update, architecture, creation_date, expiry_date, last_use_date, upload_date FROM images JOIN projects ON projects.id = images.project_id WHERE projects.name = ?` if strictMatching { inargs = append ( inargs , fingerprint ) query += " " } else { inargs = append ( inargs , fingerprint + " " ) query += " " } if public { query += " " } err = dbQueryRowScan ( c . db , query , inargs , outfmt ) if err != nil { if err == sql . ErrNoRows { return - 1 , nil , ErrNoSuchObject } return - 1 , nil , err } SELECT COUNT(images.id) FROM images JOIN projects ON projects.id = images.project_id WHERE projects.name = ? AND fingerprint LIKE ? ` count := 0 outfmt := [ ] interface { } { & count } err = dbQueryRowScan ( c . db , query , inargs , outfmt ) if err != nil { return - 1 , nil , err } if count > 1 { return - 1 , nil , fmt . Errorf ( " " ) } } err = c . imageFill ( id , & image , create , expire , used , upload , arch ) if err != nil { return - 1 , nil , errors . Wrapf ( err , " " ) } return id , & image , nil } 
func ( c * Cluster ) ImageGetFromAnyProject ( fingerprint string ) ( int , * api . Image , error ) { var create , expire , used , upload * time . Time id := - 1 arch := - 1 inargs := [ ] interface { } { fingerprint } query := ` SELECT images.id, fingerprint, filename, size, cached, public, auto_update, architecture, creation_date, expiry_date, last_use_date, upload_date FROM images WHERE fingerprint = ? LIMIT 1` err := dbQueryRowScan ( c . db , query , inargs , outfmt ) if err != nil { if err == sql . ErrNoRows { return - 1 , nil , ErrNoSuchObject } return - 1 , nil , err } err = c . imageFill ( id , & image , create , expire , used , upload , arch ) if err != nil { return - 1 , nil , errors . Wrapf ( err , " " ) } return id , & image , nil } 
func ( c * Cluster ) imageFill ( id int , image * api . Image , create , expire , used , upload * time . Time , arch int ) error { } else { image . CreatedAt = time . Time { } } if expire != nil { image . ExpiresAt = * expire } else { image . ExpiresAt = time . Time { } } if used != nil { image . LastUsedAt = * used } else { image . LastUsedAt = time . Time { } } image . Architecture , _ = osarch . ArchitectureName ( arch ) var key , value , name , desc string inargs := [ ] interface { } { id } outfmt := [ ] interface { } { key , value } results , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return err } properties := map [ string ] string { } for _ , r := range results { key = r [ 0 ] . ( string ) value = r [ 1 ] . ( string ) properties [ key ] = value } image . Properties = properties inargs = [ ] interface { } { id } outfmt = [ ] interface { } { name , desc } results , err = queryScan ( c . db , q , inargs , outfmt ) if err != nil { return err } aliases := [ ] api . ImageAlias { } for _ , r := range results { name = r [ 0 ] . ( string ) desc = r [ 1 ] . ( string ) a := api . ImageAlias { Name : name , Description : desc } aliases = append ( aliases , a ) } image . Aliases = aliases _ , source , err := c . ImageSourceGet ( id ) if err == nil { image . UpdateSource = & source } return nil } 
func ( c * Cluster ) ImageLocate ( fingerprint string ) ( string , error ) { stmt := ` SELECT nodes.address FROM nodes LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id LEFT JOIN images ON images_nodes.image_id = images.id WHERE images.fingerprint = ? ` var localAddress string var addresses [ ] string err := c . Transaction ( func ( tx * ClusterTx ) error { offlineThreshold , err := tx . NodeOfflineThreshold ( ) if err != nil { return err } localAddress , err = tx . NodeAddress ( ) if err != nil { return err } allAddresses , err := query . SelectStrings ( tx . tx , stmt , fingerprint ) if err != nil { return err } for _ , address := range allAddresses { node , err := tx . NodeByAddress ( address ) if err != nil { return err } if address != localAddress && node . IsOffline ( offlineThreshold ) { continue } addresses = append ( addresses , address ) } return err } ) if err != nil { return " " , err } if len ( addresses ) == 0 { return " " , fmt . Errorf ( " " ) } for _ , address := range addresses { if address == localAddress { return " " , nil } } return addresses [ 0 ] , nil } 
func ( c * Cluster ) ImageAssociateNode ( project , fingerprint string ) error { imageID , _ , err := c . ImageGet ( project , fingerprint , false , true ) if err != nil { return err } err = c . Transaction ( func ( tx * ClusterTx ) error { _ , err := tx . tx . Exec ( " " , imageID , c . nodeID ) return err } ) return err } 
func ( c * Cluster ) ImageDelete ( id int ) error { err := exec ( c . db , " " , id ) if err != nil { return err } return nil } 
func ( c * Cluster ) ImageAliasesGet ( project string ) ( [ ] string , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return nil , err } q := ` SELECT images_aliases.name FROM images_aliases JOIN projects ON projects.id=images_aliases.project_id WHERE projects.name=? ` var name string inargs := [ ] interface { } { project } outfmt := [ ] interface { } { name } results , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return nil , err } names := [ ] string { } for _ , res := range results { names = append ( names , res [ 0 ] . ( string ) ) } return names , nil } 
func ( c * Cluster ) ImageAliasGet ( project , name string , isTrustedClient bool ) ( int , api . ImageAliasesEntry , error ) { id := - 1 entry := api . ImageAliasesEntry { } err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return id , entry , err } q := `SELECT images_aliases.id, images.fingerprint, images_aliases.description FROM images_aliases INNER JOIN images ON images_aliases.image_id=images.id INNER JOIN projects ON images_aliases.project_id=projects.id WHERE projects.name=? AND images_aliases.name=?` if ! isTrustedClient { q = q + ` AND images.public=1` } var fingerprint , description string arg1 := [ ] interface { } { project , name } arg2 := [ ] interface { } { & id , & fingerprint , & description } err = dbQueryRowScan ( c . db , q , arg1 , arg2 ) if err != nil { if err == sql . ErrNoRows { return - 1 , entry , ErrNoSuchObject } return - 1 , entry , err } entry . Name = name entry . Target = fingerprint entry . Description = description return id , entry , nil } 
func ( c * Cluster ) ImageAliasRename ( id int , name string ) error { err := exec ( c . db , " " , name , id ) return err } 
func ( c * Cluster ) ImageAliasDelete ( project , name string ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return err } err = exec ( c . db , ` DELETE FROM images_aliases WHERE project_id = (SELECT id FROM projects WHERE name = ?) AND name = ? ` , project , name ) return err } 
func ( c * Cluster ) ImageAliasesMove ( source int , destination int ) error { err := exec ( c . db , " " , destination , source ) return err } 
func ( c * Cluster ) ImageAliasAdd ( project , name string , imageID int , desc string ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return err } stmt := ` INSERT INTO images_aliases (name, image_id, description, project_id) VALUES (?, ?, ?, (SELECT id FROM projects WHERE name = ?)) ` err = exec ( c . db , stmt , name , imageID , desc , project ) return err } 
func ( c * Cluster ) ImageAliasUpdate ( id int , imageID int , desc string ) error { stmt := `UPDATE images_aliases SET image_id=?, description=? WHERE id=?` err := exec ( c . db , stmt , imageID , desc , id ) return err } 
func ( c * Cluster ) ImageLastAccessUpdate ( fingerprint string , date time . Time ) error { stmt := `UPDATE images SET last_use_date=? WHERE fingerprint=?` err := exec ( c . db , stmt , date , fingerprint ) return err } 
func ( c * Cluster ) ImageLastAccessInit ( fingerprint string ) error { stmt := `UPDATE images SET cached=1, last_use_date=strftime("%s") WHERE fingerprint=?` err := exec ( c . db , stmt , fingerprint ) return err } 
func ( c * Cluster ) ImageUpdate ( id int , fname string , sz int64 , public bool , autoUpdate bool , architecture string , createdAt time . Time , expiresAt time . Time , properties map [ string ] string ) error { arch , err := osarch . ArchitectureId ( architecture ) if err != nil { arch = 0 } err = c . Transaction ( func ( tx * ClusterTx ) error { publicInt := 0 if public { publicInt = 1 } autoUpdateInt := 0 if autoUpdate { autoUpdateInt = 1 } stmt , err := tx . tx . Prepare ( `UPDATE images SET filename=?, size=?, public=?, auto_update=?, architecture=?, creation_date=?, expiry_date=? WHERE id=?` ) if err != nil { return err } defer stmt . Close ( ) _ , err = stmt . Exec ( fname , sz , publicInt , autoUpdateInt , arch , createdAt , expiresAt , id ) if err != nil { return err } _ , err = tx . tx . Exec ( `DELETE FROM images_properties WHERE image_id=?` , id ) if err != nil { return err } stmt2 , err := tx . tx . Prepare ( `INSERT INTO images_properties (image_id, type, key, value) VALUES (?, ?, ?, ?)` ) if err != nil { return err } defer stmt2 . Close ( ) for key , value := range properties { _ , err = stmt2 . Exec ( id , 0 , key , value ) if err != nil { return err } } return nil } ) return err } 
func ( c * Cluster ) ImageInsert ( project , fp string , fname string , sz int64 , public bool , autoUpdate bool , architecture string , createdAt time . Time , expiresAt time . Time , properties map [ string ] string ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasImages ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return err } arch , err := osarch . ArchitectureId ( architecture ) if err != nil { arch = 0 } err = c . Transaction ( func ( tx * ClusterTx ) error { publicInt := 0 if public { publicInt = 1 } autoUpdateInt := 0 if autoUpdate { autoUpdateInt = 1 } stmt , err := tx . tx . Prepare ( `INSERT INTO images (project_id, fingerprint, filename, size, public, auto_update, architecture, creation_date, expiry_date, upload_date) VALUES ((SELECT id FROM projects WHERE name = ?), ?, ?, ?, ?, ?, ?, ?, ?, ?)` ) if err != nil { return err } defer stmt . Close ( ) result , err := stmt . Exec ( project , fp , fname , sz , publicInt , autoUpdateInt , arch , createdAt , expiresAt , time . Now ( ) . UTC ( ) ) if err != nil { return err } id64 , err := result . LastInsertId ( ) if err != nil { return err } id := int ( id64 ) if len ( properties ) > 0 { pstmt , err := tx . tx . Prepare ( `INSERT INTO images_properties (image_id, type, key, value) VALUES (?, 0, ?, ?)` ) if err != nil { return err } defer pstmt . Close ( ) for k , v := range properties { if err != nil { return err } } } _ , err = tx . tx . Exec ( " " , id , c . nodeID ) if err != nil { return err } return nil } ) return err } 
func ( c * Cluster ) ImageGetPools ( imageFingerprint string ) ( [ ] int64 , error ) { poolID := int64 ( - 1 ) query := " " inargs := [ ] interface { } { c . nodeID , imageFingerprint , StoragePoolVolumeTypeImage } outargs := [ ] interface { } { poolID } result , err := queryScan ( c . db , query , inargs , outargs ) if err != nil { return [ ] int64 { } , err } poolIDs := [ ] int64 { } for _ , r := range result { poolIDs = append ( poolIDs , r [ 0 ] . ( int64 ) ) } return poolIDs , nil } 
func ( c * Cluster ) ImageGetPoolNamesFromIDs ( poolIDs [ ] int64 ) ( [ ] string , error ) { var poolName string query := " " poolNames := [ ] string { } for _ , poolID := range poolIDs { inargs := [ ] interface { } { poolID } outargs := [ ] interface { } { poolName } result , err := queryScan ( c . db , query , inargs , outargs ) if err != nil { return [ ] string { } , err } for _ , r := range result { poolNames = append ( poolNames , r [ 0 ] . ( string ) ) } } return poolNames , nil } 
func ( c * Cluster ) ImageUploadedAt ( id int , uploadedAt time . Time ) error { err := exec ( c . db , " " , uploadedAt , id ) return err } 
func ( c * Cluster ) ImagesGetOnCurrentNode ( ) ( map [ string ] [ ] string , error ) { return c . ImagesGetByNodeID ( c . nodeID ) } 
func ( c * Cluster ) ImagesGetByNodeID ( id int64 ) ( map [ string ] [ ] string , error ) { images := make ( map [ string ] [ ] string ) err := c . Transaction ( func ( tx * ClusterTx ) error { stmt := ` SELECT images.fingerprint, projects.name FROM images LEFT JOIN images_nodes ON images.id = images_nodes.image_id LEFT JOIN nodes ON images_nodes.node_id = nodes.id LEFT JOIN projects ON images.project_id = projects.id WHERE nodes.id = ? ` rows , err := tx . tx . Query ( stmt , id ) if err != nil { return err } var fingerprint string var projectName string for rows . Next ( ) { err := rows . Scan ( & fingerprint , & projectName ) if err != nil { return err } images [ fingerprint ] = append ( images [ fingerprint ] , projectName ) } return rows . Err ( ) } ) return images , err } 
func ( c * Cluster ) ImageGetNodesWithImage ( fingerprint string ) ( [ ] string , error ) { q := ` SELECT DISTINCT nodes.address FROM nodes LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id LEFT JOIN images ON images_nodes.image_id = images.id WHERE images.fingerprint = ? ` return c . getNodesByImageFingerprint ( q , fingerprint ) } 
func ( c * Cluster ) ImageGetNodesWithoutImage ( fingerprint string ) ( [ ] string , error ) { q := ` SELECT DISTINCT nodes.address FROM nodes WHERE nodes.address NOT IN ( SELECT DISTINCT nodes.address FROM nodes LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id LEFT JOIN images ON images_nodes.image_id = images.id WHERE images.fingerprint = ?) ` return c . getNodesByImageFingerprint ( q , fingerprint ) } 
func ( g * Group ) Add ( f Func , schedule Schedule ) * Task { i := len ( g . tasks ) g . tasks = append ( g . tasks , Task { f : f , schedule : schedule , reset : make ( chan struct { } , 16 ) , return & g . tasks [ i ] } 
func ( g * Group ) Start ( ) { ctx := context . Background ( ) ctx , g . cancel = context . WithCancel ( ctx ) g . wg . Add ( len ( g . tasks ) ) g . mu . Lock ( ) if g . running == nil { g . running = make ( map [ int ] bool ) } g . mu . Unlock ( ) for i := range g . tasks { g . mu . Lock ( ) if g . running [ i ] { g . mu . Unlock ( ) continue } g . running [ i ] = true task := g . tasks [ i ] g . mu . Unlock ( ) go func ( i int ) { task . loop ( ctx ) g . wg . Done ( ) g . mu . Lock ( ) g . running [ i ] = false g . mu . Unlock ( ) } ( i ) } } 
func ( g * Group ) Stop ( timeout time . Duration ) error { if g . cancel == nil { } g . cancel ( ) graceful := make ( chan struct { } , 1 ) go func ( ) { g . wg . Wait ( ) close ( graceful ) } ( ) defer cancel ( ) select { case <- ctx . Done ( ) : running := [ ] string { } for i , value := range g . running { if value { running = append ( running , strconv . Itoa ( i ) ) } } return fmt . Errorf ( " " , strings . Join ( running , " " ) ) case <- graceful : return nil } } 
func zfsIsEnabled ( ) bool { out , err := exec . LookPath ( " " ) if err != nil || len ( out ) == 0 { return false } return true } 
func zfsToolVersionGet ( ) ( string , error ) { if err != nil { return " " , err } return strings . TrimSpace ( string ( out ) ) , nil } 
func zfsModuleVersionGet ( ) ( string , error ) { var zfsVersion string if shared . PathExists ( " " ) { out , err := ioutil . ReadFile ( " " ) if err != nil { return " " , fmt . Errorf ( " " ) } zfsVersion = string ( out ) } else { out , err := shared . RunCommand ( " " , " " , " " , " " ) if err != nil { return " " , fmt . Errorf ( " " ) } zfsVersion = out } return strings . TrimSpace ( zfsVersion ) , nil } 
func zfsPoolVolumeCreate ( dataset string , properties ... string ) ( string , error ) { cmd := [ ] string { " " , " " } for _ , prop := range properties { cmd = append ( cmd , [ ] string { " " , prop } ... ) } cmd = append ( cmd , [ ] string { " " , dataset } ... ) return shared . RunCommand ( cmd [ 0 ] , cmd [ 1 : ] ... ) } 
func zfsPoolVolumeExists ( dataset string ) ( bool , error ) { output , err := shared . RunCommand ( " " , " " , " " , " " ) if err != nil { return false , err } for _ , name := range strings . Split ( output , " \n " ) { if name == dataset { return true , nil } } return false , nil } 
func ( c * ClusterTx ) NetworkIDsNotPending ( ) ( map [ string ] int64 , error ) { networks := [ ] struct { id int64 name string } { } dest := func ( i int ) [ ] interface { } { networks = append ( networks , struct { id int64 name string } { } ) return [ ] interface { } { & networks [ i ] . id , & networks [ i ] . name } } stmt , err := c . tx . Prepare ( " " ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , networkPending ) if err != nil { return nil , err } ids := map [ string ] int64 { } for _ , network := range networks { ids [ network . name ] = network . id } return ids , nil } 
func ( c * ClusterTx ) NetworkConfigAdd ( networkID , nodeID int64 , config map [ string ] string ) error { return networkConfigAdd ( c . tx , networkID , nodeID , config ) } 
func ( c * ClusterTx ) NetworkNodeJoin ( networkID , nodeID int64 ) error { columns := [ ] string { " " , " " } values := [ ] interface { } { networkID , nodeID } _ , err := query . UpsertObject ( c . tx , " " , columns , values ) return err } 
func ( c * ClusterTx ) NetworkCreatePending ( node , name string , conf map [ string ] string ) error { state int } { } var errConsistency error dest := func ( i int ) [ ] interface { } { } return [ ] interface { } { & network . id , & network . state } } stmt , err := c . tx . Prepare ( " " ) if err != nil { return err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , name ) if err != nil { return err } if errConsistency != nil { return errConsistency } var networkID = network . id if networkID == 0 { values := [ ] interface { } { name } networkID , err = query . UpsertObject ( c . tx , " " , columns , values ) if err != nil { return err } } else { } } if err != nil { return err } if err != nil { return err } if count != 0 { return ErrAlreadyDefined } values := [ ] interface { } { networkID , nodeInfo . ID } _ , err = query . UpsertObject ( c . tx , " " , columns , values ) if err != nil { return err } err = c . NetworkConfigAdd ( networkID , nodeInfo . ID , conf ) if err != nil { return err } return nil } 
func ( c * ClusterTx ) NetworkCreated ( name string ) error { return c . networkState ( name , networkCreated ) } 
func ( c * ClusterTx ) NetworkErrored ( name string ) error { return c . networkState ( name , networkErrored ) } 
func ( c * Cluster ) networks ( where string , args ... interface { } ) ( [ ] string , error ) { q := " " inargs := [ ] interface { } { } if where != " " { q += fmt . Sprintf ( " " , where ) for _ , arg := range args { inargs = append ( inargs , arg ) } } var name string outfmt := [ ] interface { } { name } result , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return [ ] string { } , err } response := [ ] string { } for _ , r := range result { response = append ( response , r [ 0 ] . ( string ) ) } return response , nil } 
func ( c * Cluster ) NetworkGet ( name string ) ( int64 , * api . Network , error ) { description := sql . NullString { } id := int64 ( - 1 ) state := 0 q := " " arg1 := [ ] interface { } { name } arg2 := [ ] interface { } { & id , & description , & state } err := dbQueryRowScan ( c . db , q , arg1 , arg2 ) if err != nil { if err == sql . ErrNoRows { return - 1 , nil , ErrNoSuchObject } return - 1 , nil , err } config , err := c . NetworkConfigGet ( id ) if err != nil { return - 1 , nil , err } network := api . Network { Name : name , Managed : true , Type : " " , } network . Description = description . String network . Config = config switch state { case networkPending : network . Status = " " case networkCreated : network . Status = " " default : network . Status = " " } nodes , err := c . networkNodes ( id ) if err != nil { return - 1 , nil , err } network . Locations = nodes return id , & network , nil } 
func ( c * Cluster ) networkNodes ( networkID int64 ) ( [ ] string , error ) { stmt := ` SELECT nodes.name FROM nodes JOIN networks_nodes ON networks_nodes.node_id = nodes.id WHERE networks_nodes.network_id = ? ` var nodes [ ] string err := c . Transaction ( func ( tx * ClusterTx ) error { var err error nodes , err = query . SelectStrings ( tx . tx , stmt , networkID ) return err } ) if err != nil { return nil , err } return nodes , nil } 
func ( c * Cluster ) NetworkGetInterface ( devName string ) ( int64 , * api . Network , error ) { id := int64 ( - 1 ) name := " " value := " " q := " \" \" " arg1 := [ ] interface { } { c . nodeID } arg2 := [ ] interface { } { id , name , value } result , err := queryScan ( c . db , q , arg1 , arg2 ) if err != nil { return - 1 , nil , err } for _ , r := range result { for _ , entry := range strings . Split ( r [ 2 ] . ( string ) , " " ) { entry = strings . TrimSpace ( entry ) if entry == devName { id = r [ 0 ] . ( int64 ) name = r [ 1 ] . ( string ) } } } if id == - 1 { return - 1 , nil , fmt . Errorf ( " " , devName ) } config , err := c . NetworkConfigGet ( id ) if err != nil { return - 1 , nil , err } network := api . Network { Name : name , Managed : true , Type : " " , } network . Config = config return id , & network , nil } 
func ( c * Cluster ) NetworkConfigGet ( id int64 ) ( map [ string ] string , error ) { var key , value string query := ` SELECT key, value FROM networks_config WHERE network_id=? AND (node_id=? OR node_id IS NULL)` inargs := [ ] interface { } { id , c . nodeID } outfmt := [ ] interface { } { key , value } results , err := queryScan ( c . db , query , inargs , outfmt ) if err != nil { return nil , fmt . Errorf ( " " , id ) } if len ( results ) == 0 { query := " " var r int results , err := queryScan ( c . db , query , [ ] interface { } { id } , [ ] interface { } { r } ) if err != nil { return nil , err } if len ( results ) == 0 { return nil , ErrNoSuchObject } } config := map [ string ] string { } for _ , r := range results { key = r [ 0 ] . ( string ) value = r [ 1 ] . ( string ) config [ key ] = value } return config , nil } 
func ( c * Cluster ) NetworkCreate ( name , description string , config map [ string ] string ) ( int64 , error ) { var id int64 err := c . Transaction ( func ( tx * ClusterTx ) error { result , err := tx . tx . Exec ( " " , name , description , networkCreated ) if err != nil { return err } id , err := result . LastInsertId ( ) if err != nil { return err } values := [ ] interface { } { id , c . nodeID } _ , err = query . UpsertObject ( tx . tx , " " , columns , values ) if err != nil { return err } err = networkConfigAdd ( tx . tx , id , c . nodeID , config ) if err != nil { return err } return nil } ) if err != nil { id = - 1 } return id , err } 
func ( c * Cluster ) NetworkUpdate ( name , description string , config map [ string ] string ) error { id , _ , err := c . NetworkGet ( name ) if err != nil { return err } err = c . Transaction ( func ( tx * ClusterTx ) error { err = NetworkUpdateDescription ( tx . tx , id , description ) if err != nil { return err } err = NetworkConfigClear ( tx . tx , id , c . nodeID ) if err != nil { return err } err = networkConfigAdd ( tx . tx , id , c . nodeID , config ) if err != nil { return err } return nil } ) return err } 
func NetworkUpdateDescription ( tx * sql . Tx , id int64 , description string ) error { _ , err := tx . Exec ( " " , description , id ) return err } 
func NetworkConfigClear ( tx * sql . Tx , networkID , nodeID int64 ) error { _ , err := tx . Exec ( " " , networkID , nodeID ) if err != nil { return err } return nil } 
func ( c * Cluster ) NetworkDelete ( name string ) error { id , _ , err := c . NetworkGet ( name ) if err != nil { return err } err = exec ( c . db , " " , id ) if err != nil { return err } return nil } 
func ( c * Cluster ) NetworkRename ( oldName string , newName string ) error { id , _ , err := c . NetworkGet ( oldName ) if err != nil { return err } err = c . Transaction ( func ( tx * ClusterTx ) error { _ , err = tx . tx . Exec ( " " , newName , id ) return err } ) return err } 
func ( r * ProtocolLXD ) GetContainers ( ) ( [ ] api . Container , error ) { containers := [ ] api . Container { } if err != nil { return nil , err } return containers , nil } 
func ( r * ProtocolLXD ) GetContainersFull ( ) ( [ ] api . ContainerFull , error ) { containers := [ ] api . ContainerFull { } if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } return containers , nil } 
func ( r * ProtocolLXD ) GetContainer ( name string ) ( * api . Container , string , error ) { container := api . Container { } if err != nil { return nil , " " , err } return & container , etag , nil } 
func ( r * ProtocolLXD ) CreateContainerFromBackup ( args ContainerBackupArgs ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if args . PoolName == " " { if err != nil { return nil , err } return op , nil } if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } req , err := http . NewRequest ( " " , reqURL , args . BackupFile ) if err != nil { return nil , err } req . Header . Set ( " " , " " ) req . Header . Set ( " " , args . PoolName ) } if err != nil { return nil , err } defer resp . Body . Close ( ) if err != nil { return nil , err } if err != nil { return nil , err } return & op , nil } 
func ( r * ProtocolLXD ) CreateContainer ( container api . ContainersPost ) ( Operation , error ) { if container . Source . ContainerOnly { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) CreateContainerFromImage ( source ImageServer , image api . Image , req api . ContainersPost ) ( RemoteOperation , error ) { req . Source . Alias = " " op , err := r . CreateContainer ( req ) if err != nil { return nil , err } rop := remoteOperation { targetOp : op , chDone : make ( chan bool ) , } close ( rop . chDone ) } ( ) return & rop , nil } } else { req . Source . Fingerprint = image . Fingerprint req . Source . Alias = " " } if err != nil { return nil , err } req . Source . Protocol = info . Protocol req . Source . Certificate = info . Certificate if err != nil { return nil , err } req . Source . Secret = secret } return r . tryCreateContainer ( req , info . Addresses ) } 
func ( r * ProtocolLXD ) CopyContainer ( source ContainerServer , container api . Container , args * ContainerCopyArgs ) ( RemoteOperation , error ) { req . Source . BaseImage = container . Config [ " " ] } if ! source . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } if shared . StringInSlice ( args . Mode , [ ] string { " " , " " } ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if ! source . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } if args . Mode == " " && ! source . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if args . Refresh { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if ! source . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } } req . Source . Live = args . Live req . Source . ContainerOnly = args . ContainerOnly req . Source . Refresh = args . Refresh } if req . Source . Live { req . Source . Live = container . StatusCode == api . Running } sourceInfo , err := source . GetConnectionInfo ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } destInfo , err := r . GetConnectionInfo ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } } req . Source . Project = sourceInfo . Project } req . Source . Source = container . Name if err != nil { return nil , err } rop := remoteOperation { targetOp : op , chDone : make ( chan bool ) , } close ( rop . chDone ) } ( ) return & rop , nil } if err != nil { return nil , err } req . Source . Mode = " " req . Source . Refresh = args . Refresh op , err := r . CreateContainer ( req ) if err != nil { return nil , err } opAPI := op . Get ( ) targetSecrets := map [ string ] string { } for k , v := range opAPI . Metadata { targetSecrets [ k ] = v . ( string ) } target . Operation = opAPI . ID target . Websockets = targetSecrets target . Certificate = info . Certificate sourceReq . Target = & target return r . tryMigrateContainer ( source , container . Name , sourceReq , info . Addresses ) } if err != nil { return nil , err } op , err := source . MigrateContainer ( container . Name , sourceReq ) if err != nil { return nil , err } opAPI := op . Get ( ) sourceSecrets := map [ string ] string { } for k , v := range opAPI . Metadata { sourceSecrets [ k ] = v . ( string ) } req . Source . Mode = " " if err != nil { return nil , err } targetOpAPI := targetOp . Get ( ) for k , v := range targetOpAPI . Metadata { targetSecrets [ k ] = v . ( string ) } if err != nil { return nil , err } close ( rop . chDone ) } ( ) return & rop , nil } req . Source . Mode = " " req . Source . Operation = opAPI . ID req . Source . Websockets = sourceSecrets req . Source . Certificate = info . Certificate return r . tryCreateContainer ( req , info . Addresses ) } 
func ( r * ProtocolLXD ) UpdateContainer ( name string , container api . ContainerPut , ETag string ) ( Operation , error ) { if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) RenameContainer ( name string , container api . ContainerPost ) ( Operation , error ) { } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) ExecContainer ( containerName string , exec api . ContainerExecPost , args * ContainerExecArgs ) ( Operation , error ) { if exec . RecordOutput { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } if err != nil { return nil , err } opAPI := op . Get ( ) value , ok := opAPI . Metadata [ " " ] if ok { values := value . ( map [ string ] interface { } ) for k , v := range values { fds [ k ] = v . ( string ) } } if err != nil { return nil , err } go args . Control ( conn ) } if exec . Interactive { if err != nil { return nil , err } <- shared . WebsocketRecvStream ( args . Stdout , conn ) conn . Close ( ) if args . DataDone != nil { close ( args . DataDone ) } } ( ) } else { if args . DataDone != nil { close ( args . DataDone ) } } } else { conns := [ ] * websocket . Conn { } if err != nil { return nil , err } conns = append ( conns , conn ) dones [ 0 ] = shared . WebsocketSendStream ( conn , args . Stdin , - 1 ) } if err != nil { return nil , err } conns = append ( conns , conn ) dones [ 1 ] = shared . WebsocketRecvStream ( args . Stdout , conn ) } if err != nil { return nil , err } conns = append ( conns , conn ) dones [ 2 ] = shared . WebsocketRecvStream ( args . Stderr , conn ) } } <- chDone } if fds [ " " ] != " " { if args . Stdin != nil { args . Stdin . Close ( ) } } ( ) } for _ , conn := range conns { conn . Close ( ) } if args . DataDone != nil { close ( args . DataDone ) } } ( ) } } return op , nil } 
func ( r * ProtocolLXD ) GetContainerFile ( containerName string , path string ) ( io . ReadCloser , * ContainerFileResponse , error ) { if err != nil { return nil , nil , err } requestURL , err = r . setQueryAttributes ( requestURL ) if err != nil { return nil , nil , err } req , err := http . NewRequest ( " " , requestURL , nil ) if err != nil { return nil , nil , err } } if err != nil { return nil , nil , err } if err != nil { return nil , nil , err } } fileResp := ContainerFileResponse { UID : uid , GID : gid , Mode : mode , Type : fileType , } if fileResp . Type == " " { decoder := json . NewDecoder ( resp . Body ) err = decoder . Decode ( & response ) if err != nil { return nil , nil , err } err = response . MetadataAsStruct ( & entries ) if err != nil { return nil , nil , err } fileResp . Entries = entries return nil , & fileResp , err } return resp . Body , & fileResp , err } 
func ( r * ProtocolLXD ) CreateContainerFile ( containerName string , path string , args ContainerFileArgs ) error { if args . Type == " " { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } } if args . Type == " " { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } } if args . WriteMode == " " { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } } requestURL , err := r . setQueryAttributes ( requestURL ) if err != nil { return err } req , err := http . NewRequest ( " " , requestURL , args . Content ) if err != nil { return err } } } if args . GID > - 1 { req . Header . Set ( " " , fmt . Sprintf ( " " , args . GID ) ) } if args . Mode > - 1 { req . Header . Set ( " " , fmt . Sprintf ( " " , args . Mode ) ) } if args . Type != " " { req . Header . Set ( " " , args . Type ) } if args . WriteMode != " " { req . Header . Set ( " " , args . WriteMode ) } if err != nil { return err } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) DeleteContainerFile ( containerName string , path string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) GetContainerSnapshotNames ( containerName string ) ( [ ] string , error ) { urls := [ ] string { } if err != nil { return nil , err } for _ , uri := range urls { fields := strings . Split ( uri , fmt . Sprintf ( " " , url . QueryEscape ( containerName ) ) ) names = append ( names , fields [ len ( fields ) - 1 ] ) } return names , nil } 
func ( r * ProtocolLXD ) GetContainerSnapshots ( containerName string ) ( [ ] api . ContainerSnapshot , error ) { snapshots := [ ] api . ContainerSnapshot { } if err != nil { return nil , err } return snapshots , nil } 
func ( r * ProtocolLXD ) GetContainerSnapshot ( containerName string , name string ) ( * api . ContainerSnapshot , string , error ) { snapshot := api . ContainerSnapshot { } if err != nil { return nil , " " , err } return & snapshot , etag , nil } 
func ( r * ProtocolLXD ) CreateContainerSnapshot ( containerName string , snapshot api . ContainerSnapshotsPost ) ( Operation , error ) { } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) CopyContainerSnapshot ( source ContainerServer , containerName string , snapshot api . ContainerSnapshot , args * ContainerSnapshotCopyArgs ) ( RemoteOperation , error ) { cName := containerName sName := fields [ len ( fields ) - 1 ] if snapshot . Stateful && args . Live { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } req . ContainerPut . Stateful = snapshot . Stateful req . Source . Live = args . Live } req . Source . BaseImage = snapshot . Config [ " " ] } if ! source . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } if args . Mode == " " && ! source . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } } sourceInfo , err := source . GetConnectionInfo ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } destInfo , err := r . GetConnectionInfo ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } container , _ , err := source . GetContainer ( cName ) if err != nil { return nil , fmt . Errorf ( " " , err ) } } req . Source . Project = sourceInfo . Project } req . Source . Source = fmt . Sprintf ( " " , cName , sName ) if err != nil { return nil , err } rop := remoteOperation { targetOp : op , chDone : make ( chan bool ) , } close ( rop . chDone ) } ( ) return & rop , nil } if snapshot . Stateful && args . Live { sourceReq . Live = args . Live } if err != nil { return nil , err } req . Source . Mode = " " op , err := r . CreateContainer ( req ) if err != nil { return nil , err } opAPI := op . Get ( ) targetSecrets := map [ string ] string { } for k , v := range opAPI . Metadata { targetSecrets [ k ] = v . ( string ) } target . Operation = opAPI . ID target . Websockets = targetSecrets target . Certificate = info . Certificate sourceReq . Target = & target return r . tryMigrateContainerSnapshot ( source , cName , sName , sourceReq , info . Addresses ) } if err != nil { return nil , err } op , err := source . MigrateContainerSnapshot ( cName , sName , sourceReq ) if err != nil { return nil , err } opAPI := op . Get ( ) sourceSecrets := map [ string ] string { } for k , v := range opAPI . Metadata { sourceSecrets [ k ] = v . ( string ) } req . Source . Mode = " " if err != nil { return nil , err } targetOpAPI := targetOp . Get ( ) for k , v := range targetOpAPI . Metadata { targetSecrets [ k ] = v . ( string ) } if err != nil { return nil , err } close ( rop . chDone ) } ( ) return & rop , nil } req . Source . Mode = " " req . Source . Operation = opAPI . ID req . Source . Websockets = sourceSecrets req . Source . Certificate = info . Certificate return r . tryCreateContainer ( req , info . Addresses ) } 
func ( r * ProtocolLXD ) MigrateContainerSnapshot ( containerName string , name string , container api . ContainerSnapshotPost ) ( Operation , error ) { } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) UpdateContainerSnapshot ( containerName string , name string , container api . ContainerSnapshotPut , ETag string ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) GetContainerState ( name string ) ( * api . ContainerState , string , error ) { state := api . ContainerState { } if err != nil { return nil , " " , err } return & state , etag , nil } 
func ( r * ProtocolLXD ) UpdateContainerState ( name string , state api . ContainerStatePut , ETag string ) ( Operation , error ) { if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) GetContainerLogfiles ( name string ) ( [ ] string , error ) { urls := [ ] string { } if err != nil { return nil , err } for _ , uri := range logfiles { fields := strings . Split ( uri , fmt . Sprintf ( " " , url . QueryEscape ( name ) ) ) logfiles = append ( logfiles , fields [ len ( fields ) - 1 ] ) } return logfiles , nil } 
func ( r * ProtocolLXD ) GetContainerLogfile ( name string , filename string ) ( io . ReadCloser , error ) { url , err := r . setQueryAttributes ( url ) if err != nil { return nil , err } req , err := http . NewRequest ( " " , url , nil ) if err != nil { return nil , err } } if err != nil { return nil , err } if err != nil { return nil , err } } return resp . Body , err } 
func ( r * ProtocolLXD ) GetContainerMetadata ( name string ) ( * api . ImageMetadata , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } metadata := api . ImageMetadata { } url := fmt . Sprintf ( " " , url . QueryEscape ( name ) ) etag , err := r . queryStruct ( " " , url , nil , " " , & metadata ) if err != nil { return nil , " " , err } return & metadata , etag , err } 
func ( r * ProtocolLXD ) SetContainerMetadata ( name string , metadata api . ImageMetadata , ETag string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } url := fmt . Sprintf ( " " , url . QueryEscape ( name ) ) _ , _ , err := r . query ( " " , url , metadata , ETag ) if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) GetContainerTemplateFiles ( containerName string ) ( [ ] string , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } templates := [ ] string { } url := fmt . Sprintf ( " " , url . QueryEscape ( containerName ) ) _ , err := r . queryStruct ( " " , url , nil , " " , & templates ) if err != nil { return nil , err } return templates , nil } 
func ( r * ProtocolLXD ) CreateContainerTemplateFile ( containerName string , templateName string , content io . ReadSeeker ) error { return r . setContainerTemplateFile ( containerName , templateName , content , " " ) } 
func ( r * ProtocolLXD ) DeleteContainerTemplateFile ( name string , templateName string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } _ , _ , err := r . query ( " " , fmt . Sprintf ( " " , url . QueryEscape ( name ) , url . QueryEscape ( templateName ) ) , nil , " " ) return err } 
func ( r * ProtocolLXD ) ConsoleContainer ( containerName string , console api . ContainerConsolePost , args * ContainerConsoleArgs ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } opAPI := op . Get ( ) if args == nil || args . Terminal == nil { return nil , fmt . Errorf ( " " ) } if args . Control == nil { return nil , fmt . Errorf ( " " ) } value , ok := opAPI . Metadata [ " " ] if ok { values := value . ( map [ string ] interface { } ) for k , v := range values { fds [ k ] = v . ( string ) } } var controlConn * websocket . Conn } controlConn , err = r . GetOperationWebsocket ( opAPI . ID , fds [ " " ] ) if err != nil { return nil , err } go args . Control ( controlConn ) if err != nil { return nil , err } msg := websocket . FormatCloseMessage ( websocket . CloseNormalClosure , " " ) controlConn . Close ( ) } ( args . ConsoleDisconnect ) <- shared . WebsocketRecvStream ( args . Terminal , conn ) conn . Close ( ) } ( ) return op , nil } 
func ( r * ProtocolLXD ) GetContainerConsoleLog ( containerName string , args * ContainerConsoleLogArgs ) ( io . ReadCloser , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } url , err := r . setQueryAttributes ( url ) if err != nil { return nil , err } req , err := http . NewRequest ( " " , url , nil ) if err != nil { return nil , err } } if err != nil { return nil , err } if err != nil { return nil , err } } return resp . Body , err } 
func ( r * ProtocolLXD ) DeleteContainerConsoleLog ( containerName string , args * ContainerConsoleLogArgs ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) GetContainerBackups ( containerName string ) ( [ ] api . ContainerBackup , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } _ , err := r . queryStruct ( " " , fmt . Sprintf ( " " , url . QueryEscape ( containerName ) ) , nil , " " , & backups ) if err != nil { return nil , err } return backups , nil } 
func ( r * ProtocolLXD ) GetContainerBackup ( containerName string , name string ) ( * api . ContainerBackup , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } etag , err := r . queryStruct ( " " , fmt . Sprintf ( " " , url . QueryEscape ( containerName ) , url . QueryEscape ( name ) ) , nil , " " , & backup ) if err != nil { return nil , " " , err } return & backup , etag , nil } 
func ( r * ProtocolLXD ) CreateContainerBackup ( containerName string , backup api . ContainerBackupsPost ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) RenameContainerBackup ( containerName string , name string , backup api . ContainerBackupPost ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) DeleteContainerBackup ( containerName string , name string ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) GetContainerBackupFile ( containerName string , name string , req * BackupFileRequest ) ( * BackupFileResponse , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if r . project != " " { uri += fmt . Sprintf ( " " , url . QueryEscape ( r . project ) ) } if err != nil { return nil , err } if r . httpUserAgent != " " { request . Header . Set ( " " , r . httpUserAgent ) } if err != nil { return nil , err } defer response . Body . Close ( ) defer close ( doneCh ) if response . StatusCode != http . StatusOK { _ , _ , err := lxdParseResponse ( response ) if err != nil { return nil , err } } if req . ProgressHandler != nil { body = & ioprogress . ProgressReader { ReadCloser : response . Body , Tracker : & ioprogress . ProgressTracker { Length : response . ContentLength , Handler : func ( percent int64 , speed int64 ) { req . ProgressHandler ( ioprogress . ProgressData { Text : fmt . Sprintf ( " " , percent , shared . GetByteSizeString ( speed , 2 ) ) } ) } , } , } } size , err := io . Copy ( req . BackupFile , body ) if err != nil { return nil , err } resp := BackupFileResponse { } resp . Size = size return & resp , nil } 
func Camel ( s string ) string { words := strings . Split ( s , " " ) for i := range words { words [ i ] = Capital ( words [ i ] ) } return strings . Join ( words , " " ) } 
func Snake ( name string ) string { var ret bytes . Buffer multipleUpper := false var lastUpper rune var beforeUpper rune for _ , c := range name { if lastUpper != 0 { lastInRow := ! isUpper if ret . Len ( ) > 0 && ( firstInRow || lastInRow ) && beforeUpper != '_' { ret . WriteByte ( '_' ) } ret . WriteRune ( unicode . ToLower ( lastUpper ) ) } lastUpper = c continue } ret . WriteRune ( c ) lastUpper = 0 beforeUpper = c multipleUpper = false } if lastUpper != 0 { ret . WriteRune ( unicode . ToLower ( lastUpper ) ) } return string ( ret . Bytes ( ) ) } 
func rsyncLocalCopy ( source string , dest string , bwlimit string ) ( string , error ) { err := os . MkdirAll ( dest , 0755 ) if err != nil { return " " , err } rsyncVerbosity := " " if debug { rsyncVerbosity = " " } if bwlimit == " " { bwlimit = " " } msg , err := shared . RunCommand ( " " , " " , " " , " " , " " , " " , " " , " " , " " , " " , bwlimit , rsyncVerbosity , shared . AddSlash ( source ) , dest ) if err != nil { runError , ok := err . ( shared . RunError ) if ok { exitError , ok := runError . Err . ( * exec . ExitError ) if ok { waitStatus := exitError . Sys ( ) . ( syscall . WaitStatus ) if waitStatus . ExitStatus ( ) == 24 { return msg , nil } } } return msg , err } return msg , nil } 
func RsyncSend ( name string , path string , conn * websocket . Conn , readWrapper func ( io . ReadCloser ) io . ReadCloser , features [ ] string , bwlimit string , execPath string ) error { cmd , dataSocket , stderr , err := rsyncSendSetup ( name , path , bwlimit , execPath , features ) if err != nil { return err } if dataSocket != nil { defer dataSocket . Close ( ) } readPipe := io . ReadCloser ( dataSocket ) if readWrapper != nil { readPipe = readWrapper ( dataSocket ) } readDone , writeDone := shared . WebsocketMirror ( conn , dataSocket , readPipe , nil , nil ) chError := make ( chan error , 1 ) go func ( ) { err = cmd . Wait ( ) if err != nil { dataSocket . Close ( ) readPipe . Close ( ) } chError <- err } ( ) output , err := ioutil . ReadAll ( stderr ) if err != nil { cmd . Process . Kill ( ) } err = <- chError if err != nil { logger . Errorf ( " " , path , err , string ( output ) ) } <- readDone <- writeDone return err } 
func RsyncRecv ( path string , conn * websocket . Conn , writeWrapper func ( io . WriteCloser ) io . WriteCloser , features [ ] string ) error { args := [ ] string { " " , " " , " " , " " , " " , " " , } if features != nil && len ( features ) > 0 { args = append ( args , rsyncFeatureArgs ( features ) ... ) } args = append ( args , [ ] string { " " , path } ... ) cmd := exec . Command ( " " , args ... ) stdin , err := cmd . StdinPipe ( ) if err != nil { return err } stdout , err := cmd . StdoutPipe ( ) if err != nil { return err } stderr , err := cmd . StderrPipe ( ) if err != nil { return err } if err := cmd . Start ( ) ; err != nil { return err } writePipe := io . WriteCloser ( stdin ) if writeWrapper != nil { writePipe = writeWrapper ( stdin ) } readDone , writeDone := shared . WebsocketMirror ( conn , writePipe , stdout , nil , nil ) output , err := ioutil . ReadAll ( stderr ) if err != nil { cmd . Process . Kill ( ) cmd . Wait ( ) return err } err = cmd . Wait ( ) if err != nil { logger . Errorf ( " " , path , err , string ( output ) ) } <- readDone <- writeDone return err } 
func patchesGetNames ( ) [ ] string { names := make ( [ ] string , len ( patches ) ) for i , patch := range patches { names [ i ] = patch . name } return names } 
func patchRenameCustomVolumeLVs ( name string , d * Daemon ) error { for _ , poolName := range pools { poolID , pool , err := d . cluster . StoragePoolGet ( poolName ) if err != nil { return err } sType , err := storageStringToType ( pool . Driver ) if err != nil { return err } if sType != storageTypeLvm { continue } volumes , err := d . cluster . StoragePoolNodeVolumesGetType ( storagePoolVolumeTypeCustom , poolID ) if err != nil { return err } vgName := poolName if pool . Config [ " " ] != " " { vgName = pool . Config [ " " ] } for _ , volume := range volumes { oldName := fmt . Sprintf ( " " , vgName , volume ) newName := fmt . Sprintf ( " " , vgName , containerNameToLVName ( volume ) ) exists , err := storageLVExists ( newName ) if err != nil { return err } if exists || oldName == newName { continue } err = lvmLVRename ( vgName , oldName , newName ) if err != nil { return err } logger . Info ( " " , log . Ctx { " " : oldName , " " : newName } ) } } return nil } 
func patchShrinkLogsDBFile ( name string , d * Daemon ) error { dir := filepath . Join ( d . os . VarDir , " " , " " ) info , err := os . Stat ( filepath . Join ( dir , " " ) ) if err != nil { if os . IsNotExist ( err ) { } return errors . Wrap ( err , " " ) } if info . Size ( ) < 1024 * 1024 * 100 { } snaps , err := raft . NewFileSnapshotStoreWithLogger ( dir , 2 , stdlog . New ( ioutil . Discard , " " , 0 ) ) if err != nil { return errors . Wrap ( err , " " ) } metas , err := snaps . List ( ) if err != nil { return errors . Wrap ( err , " " ) } if len ( metas ) == 0 { return nil } meta := metas [ 0 ] if err != nil { return errors . Wrap ( err , " " ) } defer logsCur . Close ( ) pathNew := filepath . Join ( dir , " " ) logsNew , err := raftboltdb . New ( raftboltdb . Options { Path : pathNew , BoltOptions : & bolt . Options { Timeout : 10 * time . Second } , } ) if err != nil { return errors . Wrap ( err , " " ) } defer logsNew . Close ( ) lastIndex , err := logsCur . LastIndex ( ) if err != nil { return errors . Wrap ( err , " " ) } for index := meta . Index ; index <= lastIndex ; index ++ { log := & raft . Log { } err := logsCur . GetLog ( index , log ) if err != nil { return errors . Wrapf ( err , " " , index ) } err = logsNew . StoreLog ( log ) if err != nil { return errors . Wrapf ( err , " " , index ) } } term , err := logsCur . GetUint64 ( [ ] byte ( " " ) ) if err != nil { return errors . Wrap ( err , " " ) } err = logsNew . SetUint64 ( [ ] byte ( " " ) , term ) if err != nil { return errors . Wrap ( err , " " ) } logsCur . Close ( ) logsNew . Close ( ) err = os . Remove ( pathCur ) if err != nil { return errors . Wrap ( err , " " ) } err = os . Rename ( pathNew , pathCur ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func patchLvmNodeSpecificConfigKeys ( name string , d * Daemon ) error { tx , err := d . cluster . Begin ( ) if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } for _ , poolID := range poolIDs { if err != nil { return errors . Wrap ( err , " " ) } for _ , key := range [ ] string { " " , " " } { value , ok := config [ key ] if ! ok { continue } DELETE FROM storage_pools_config WHERE key=? AND storage_pool_id=? AND node_id IS NULL ` , key , poolID ) if err != nil { return errors . Wrapf ( err , " " , key ) } INSERT INTO storage_pools_config(storage_pool_id, node_id, key, value) VALUES(?, ?, ?, ?) ` , poolID , nodeID , key , value ) if err != nil { return errors . Wrapf ( err , " " , key ) } } } } err = tx . Commit ( ) if err != nil { return errors . Wrap ( err , " " ) } return err } 
func patchStorageApiUpdateStorageConfigs ( name string , d * Daemon ) error { pools , err := d . cluster . StoragePools ( ) if err != nil { if err == db . ErrNoSuchObject { return nil } logger . Errorf ( " " , err ) return err } for _ , poolName := range pools { poolID , pool , err := d . cluster . StoragePoolGet ( poolName ) if err != nil { logger . Errorf ( " " , err ) return err } } if err != nil { return err } } } case " " : } case " " : } } if pool . Config [ " " ] == " " { pool . Config [ " " ] = " " } case " " : } if ! shared . IsTrue ( pool . Config [ " " ] ) { pool . Config [ " " ] = " " } } } if err != nil { return err } if err != nil { if err == db . ErrNoSuchObject { continue } return err } for _ , volume := range volumes { } if err != nil { return err } } case " " : } case " " : } case " " : } if ! shared . IsTrue ( volume . Config [ " " ] ) { volume . Config [ " " ] = " " } } } if err != nil { return err } } } return nil } 
func ( r * ProtocolLXD ) GetConnectionInfo ( ) ( * ConnectionInfo , error ) { info := ConnectionInfo { } info . Certificate = r . httpCertificate info . Protocol = " " info . URL = r . httpHost info . SocketPath = r . httpUnixPath info . Project = r . project if info . Project == " " { info . Project = " " } urls := [ ] string { } if r . httpProtocol == " " { urls = append ( urls , r . httpHost ) } if r . server != nil && len ( r . server . Environment . Addresses ) > 0 { for _ , addr := range r . server . Environment . Addresses { url := fmt . Sprintf ( " " , addr ) if ! shared . StringInSlice ( url , urls ) { urls = append ( urls , url ) } } } info . Addresses = urls return & info , nil } 
func ( r * ProtocolLXD ) GetHTTPClient ( ) ( * http . Client , error ) { if r . http == nil { return nil , fmt . Errorf ( " " ) } return r . http , nil } 
func ( r * ProtocolLXD ) do ( req * http . Request ) ( * http . Response , error ) { if r . bakeryClient != nil { r . addMacaroonHeaders ( req ) return r . bakeryClient . Do ( req ) } return r . http . Do ( req ) } 
func ( r * ProtocolLXD ) RawQuery ( method string , path string , data interface { } , ETag string ) ( * api . Response , string , error ) { return r . rawQuery ( method , url , data , ETag ) } 
func ( r * ProtocolLXD ) RawWebsocket ( path string ) ( * websocket . Conn , error ) { return r . websocket ( path ) } 
func ( r * ProtocolLXD ) RawOperation ( method string , path string , data interface { } , ETag string ) ( Operation , string , error ) { return r . queryOperation ( method , path , data , ETag ) } 
func lxdParseResponse ( resp * http . Response ) ( * api . Response , string , error ) { response := api . Response { } err := decoder . Decode ( & response ) if err != nil { } return nil , " " , err } } return & response , etag , nil } 
func ProfileToAPI ( profile * Profile ) * api . Profile { p := & api . Profile { Name : profile . Name , UsedBy : profile . UsedBy , } p . Description = profile . Description p . Config = profile . Config p . Devices = profile . Devices return p } 
func ( c * Cluster ) Profiles ( project string ) ( [ ] string , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return nil , err } q := fmt . Sprintf ( ` SELECT profiles.name FROM profiles JOIN projects ON projects.id = profiles.project_id WHERE projects.name = ? ` ) inargs := [ ] interface { } { project } var name string outfmt := [ ] interface { } { name } result , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return [ ] string { } , err } response := [ ] string { } for _ , r := range result { response = append ( response , r [ 0 ] . ( string ) ) } return response , nil } 
func ( c * Cluster ) ProfileGet ( project , name string ) ( int64 , * api . Profile , error ) { var result * api . Profile var id int64 err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } profile , err := tx . ProfileGet ( project , name ) if err != nil { return err } result = ProfileToAPI ( profile ) id = int64 ( profile . ID ) return nil } ) if err != nil { return - 1 , nil , err } return id , result , nil } 
func ( c * Cluster ) ProfilesGet ( project string , names [ ] string ) ( [ ] api . Profile , error ) { profiles := make ( [ ] api . Profile , len ( names ) ) err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } for i , name := range names { profile , err := tx . ProfileGet ( project , name ) if err != nil { return errors . Wrapf ( err , " " , name ) } profiles [ i ] = * ProfileToAPI ( profile ) } return nil } ) if err != nil { return nil , err } return profiles , nil } 
func ( c * Cluster ) ProfileConfig ( project , name string ) ( map [ string ] string , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return nil , err } var key , value string query := ` SELECT key, value FROM profiles_config JOIN profiles ON profiles_config.profile_id=profiles.id JOIN projects ON projects.id = profiles.project_id WHERE projects.name=? AND profiles.name=?` inargs := [ ] interface { } { project , name } outfmt := [ ] interface { } { key , value } results , err := queryScan ( c . db , query , inargs , outfmt ) if err != nil { return nil , errors . Wrapf ( err , " " , name ) } if len ( results ) == 0 { query := " " var id int results , err := queryScan ( c . db , query , [ ] interface { } { name } , [ ] interface { } { id } ) if err != nil { return nil , err } if len ( results ) == 0 { return nil , ErrNoSuchObject } } config := map [ string ] string { } for _ , r := range results { key = r [ 0 ] . ( string ) value = r [ 1 ] . ( string ) config [ key ] = value } return config , nil } 
func ProfileConfigClear ( tx * sql . Tx , id int64 ) error { _ , err := tx . Exec ( " " , id ) if err != nil { return err } _ , err = tx . Exec ( `DELETE FROM profiles_devices_config WHERE id IN (SELECT profiles_devices_config.id FROM profiles_devices_config JOIN profiles_devices ON profiles_devices_config.profile_device_id=profiles_devices.id WHERE profiles_devices.profile_id=?)` , id ) if err != nil { return err } _ , err = tx . Exec ( " " , id ) if err != nil { return err } return nil } 
func ProfileConfigAdd ( tx * sql . Tx , id int64 , config map [ string ] string ) error { str := fmt . Sprintf ( " " ) stmt , err := tx . Prepare ( str ) defer stmt . Close ( ) if err != nil { return err } for k , v := range config { if v == " " { continue } _ , err = stmt . Exec ( id , k , v ) if err != nil { return err } } return nil } 
func ( c * Cluster ) ProfileContainersGet ( project , profile string ) ( map [ string ] [ ] string , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } return nil } ) if err != nil { return nil , err } q := `SELECT containers.name, projects.name FROM containers JOIN containers_profiles ON containers.id == containers_profiles.container_id JOIN projects ON projects.id == containers.project_id WHERE containers_profiles.profile_id == (SELECT profiles.id FROM profiles JOIN projects ON projects.id == profiles.project_id WHERE profiles.name=? AND projects.name=?) AND containers.type == 0` results := map [ string ] [ ] string { } inargs := [ ] interface { } { profile , project } var name string outfmt := [ ] interface { } { name , name } output , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return nil , err } for _ , r := range output { if results [ r [ 1 ] . ( string ) ] == nil { results [ r [ 1 ] . ( string ) ] = [ ] string { } } results [ r [ 1 ] . ( string ) ] = append ( results [ r [ 1 ] . ( string ) ] , r [ 0 ] . ( string ) ) } return results , nil } 
func ( c * Cluster ) ProfileCleanupLeftover ( ) error { stmt := ` DELETE FROM profiles_config WHERE profile_id NOT IN (SELECT id FROM profiles); DELETE FROM profiles_devices WHERE profile_id NOT IN (SELECT id FROM profiles); DELETE FROM profiles_devices_config WHERE profile_device_id NOT IN (SELECT id FROM profiles_devices); ` err := exec ( c . db , stmt ) if err != nil { return err } return nil } 
func ProfilesExpandConfig ( config map [ string ] string , profiles [ ] api . Profile ) map [ string ] string { expandedConfig := map [ string ] string { } for i , profile := range profiles { profileConfigs [ i ] = profile . Config } for i := range profileConfigs { for k , v := range profileConfigs [ i ] { expandedConfig [ k ] = v } } } return expandedConfig } 
func ProfilesExpandDevices ( devices types . Devices , profiles [ ] api . Profile ) types . Devices { expandedDevices := types . Devices { } for i , profile := range profiles { profileDevices [ i ] = profile . Devices } for i := range profileDevices { for k , v := range profileDevices [ i ] { expandedDevices [ k ] = v } } } return expandedDevices } 
func ( r * ProtocolLXD ) GetServer ( ) ( * api . Server , string , error ) { server := api . Server { } if err != nil { return nil , " " , err } server . Environment . CertificateFingerprint , err = shared . CertFingerprintStr ( server . Environment . Certificate ) if err != nil { return nil , " " , err } } if ! server . Public && len ( server . AuthMethods ) == 0 { } return & server , etag , nil } 
func ( r * ProtocolLXD ) UpdateServer ( server api . ServerPut , ETag string ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) HasExtension ( extension string ) bool { } for _ , entry := range r . server . APIExtensions { if entry == extension { return true } } return false } 
func ( r * ProtocolLXD ) GetServerResources ( ) ( * api . Resources , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } resources := api . Resources { } if err != nil { return nil , err } return & resources , nil } 
func ( r * ProtocolLXD ) UseProject ( name string ) ContainerServer { return & ProtocolLXD { server : r . server , http : r . http , httpCertificate : r . httpCertificate , httpHost : r . httpHost , httpProtocol : r . httpProtocol , httpUserAgent : r . httpUserAgent , bakeryClient : r . bakeryClient , bakeryInteractor : r . bakeryInteractor , requireAuthenticated : r . requireAuthenticated , clusterTarget : r . clusterTarget , project : name , } } 
func sqliteOpen ( path string ) ( * sql . DB , error ) { timeout := 5 } 
func Bootstrap ( state * state . State , gateway * Gateway , name string ) error { } err := membershipCheckNoLeftoverClusterCert ( state . OS . VarDir ) if err != nil { return err } var address string err = state . Node . Transaction ( func ( tx * db . NodeTx ) error { if err != nil { return errors . Wrap ( err , " " ) } address = config . ClusterAddress ( ) if err != nil { return err } if err != nil { return errors . Wrap ( err , " " ) } return nil } ) if err != nil { return err } if err != nil { return err } if err != nil { return errors . Wrap ( err , " " ) } return nil } ) if err != nil { return err } if err != nil { return errors . Wrap ( err , " " ) } err = gateway . Shutdown ( ) if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } err = gateway . waitLeadership ( ) if err != nil { return err } } err := os . Symlink ( " " + ext , filepath . Join ( state . OS . VarDir , " " + ext ) ) if err != nil { return errors . Wrap ( err , " " ) } } return err } ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func Accept ( state * state . State , gateway * Gateway , name , address string , schema , api int ) ( [ ] db . RaftNode , error ) { } if address == " " { return nil , fmt . Errorf ( " " ) } if err != nil { return err } if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } return nil } ) if err != nil { return nil , err } if err != nil { return nil , errors . Wrap ( err , " " ) } if len ( nodes ) < membershipMaxRaftNodes { err = state . Node . Transaction ( func ( tx * db . NodeTx ) error { id , err := tx . RaftNodeAdd ( address ) if err != nil { return err } nodes = append ( nodes , db . RaftNode { ID : id , Address : address } ) return nil } ) if err != nil { return nil , errors . Wrap ( err , " " ) } } return nodes , nil } 
func Join ( state * state . State , gateway * Gateway , cert * shared . CertInfo , name string , nodes [ ] db . RaftNode ) error { } var address string err := state . Node . Transaction ( func ( tx * db . NodeTx ) error { if err != nil { return errors . Wrap ( err , " " ) } address = config . ClusterAddress ( ) if err != nil { return err } if err != nil { return errors . Wrap ( err , " " ) } return nil } ) if err != nil { return err } var networks map [ string ] map [ string ] string var operations [ ] db . Operation err = state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { pools , err = tx . StoragePoolsNodeConfig ( ) if err != nil { return err } networks , err = tx . NetworksNodeConfig ( ) if err != nil { return err } operations , err = tx . Operations ( ) if err != nil { return err } return nil } ) if err != nil { return err } if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } err = os . RemoveAll ( state . OS . GlobalDatabaseDir ( ) ) if err != nil { return errors . Wrap ( err , " " ) } err = gateway . init ( ) if err != nil { return errors . Wrap ( err , " " ) } target := " " for _ , node := range nodes { if node . Address == address { id = strconv . Itoa ( int ( node . ID ) ) } else { target = node . Address } } if id != " " { logger . Info ( " " , log15 . Ctx { " " : id , " " : address , " " : target } ) changer := gateway . raft . MembershipChanger ( ) err := changer . Join ( raft . ServerID ( id ) , raft . ServerAddress ( target ) , 5 * time . Second ) if err != nil { return err } } else { logger . Info ( " " ) } err = state . Cluster . ExitExclusive ( func ( tx * db . ClusterTx ) error { node , err := tx . NodePendingByAddress ( address ) if err != nil { return errors . Wrap ( err , " " ) } state . Cluster . NodeID ( node . ID ) tx . NodeID ( node . ID ) if err != nil { return errors . Wrap ( err , " " ) } for name , id := range ids { err := tx . StoragePoolNodeJoin ( id , node . ID ) if err != nil { return errors . Wrap ( err , " " ) } driver , err := tx . StoragePoolDriver ( id ) if err != nil { return errors . Wrap ( err , " " ) } if driver == " " { if err != nil { return errors . Wrap ( err , " " ) } } else { if ! ok { return fmt . Errorf ( " " , name ) } err = tx . StoragePoolConfigAdd ( id , node . ID , config ) if err != nil { return errors . Wrap ( err , " " ) } } } if err != nil { return errors . Wrap ( err , " " ) } for name , id := range ids { config , ok := networks [ name ] if ! ok { return fmt . Errorf ( " " , name ) } err := tx . NetworkNodeJoin ( id , node . ID ) if err != nil { return errors . Wrap ( err , " " ) } err = tx . NetworkConfigAdd ( id , node . ID , config ) if err != nil { return errors . Wrap ( err , " " ) } } if err != nil { return errors . Wrapf ( err , " " , operation . UUID ) } } if err != nil { return errors . Wrapf ( err , " " ) } return nil } ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func Rebalance ( state * state . State , gateway * Gateway ) ( string , [ ] db . RaftNode , error ) { if err != nil { return " " , nil , errors . Wrap ( err , " " ) } if len ( currentRaftNodes ) >= membershipMaxRaftNodes { } currentRaftAddresses := make ( [ ] string , len ( currentRaftNodes ) ) for i , node := range currentRaftNodes { currentRaftAddresses [ i ] = node . Address } err = state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { config , err := ConfigLoad ( tx ) if err != nil { return errors . Wrap ( err , " " ) } nodes , err := tx . Nodes ( ) if err != nil { return errors . Wrap ( err , " " ) } } if node . IsOffline ( config . OfflineThreshold ( ) ) { continue } logger . Debugf ( " " , node . Name , node . Address ) address = node . Address break } return nil } ) if err != nil { return " " , nil , err } if address == " " { } err = gateway . db . Transaction ( func ( tx * db . NodeTx ) error { id , err := tx . RaftNodeAdd ( address ) if err != nil { return errors . Wrap ( err , " " ) } updatedRaftNodes = append ( updatedRaftNodes , db . RaftNode { ID : id , Address : address } ) err = tx . RaftNodesReplace ( updatedRaftNodes ) if err != nil { return errors . Wrap ( err , " " ) } return nil } ) if err != nil { return " " , nil , err } return address , updatedRaftNodes , nil } 
func Promote ( state * state . State , gateway * Gateway , nodes [ ] db . RaftNode ) error { logger . Info ( " " ) } err := state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error address , err = tx . NodeAddress ( ) if err != nil { return errors . Wrap ( err , " " ) } return nil } ) if err != nil { return err } } target := " " for _ , node := range nodes { if node . Address == address { id = strconv . Itoa ( int ( node . ID ) ) } else { target = node . Address } } } if err != nil { return errors . Wrap ( err , " " ) } return nil } ) if err != nil { return err } if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } logger . Info ( " " , log15 . Ctx { " " : id , " " : address , " " : target } ) changer := gateway . raft . MembershipChanger ( ) err = changer . Join ( raft . ServerID ( id ) , raft . ServerAddress ( target ) , 5 * time . Second ) if err != nil { return err } return err } ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func Leave ( state * state . State , gateway * Gateway , name string , force bool ) ( string , error ) { logger . Debugf ( " " , name ) err := state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { if err != nil { return err } if err != nil { return err } } address = node . Address return nil } ) if err != nil { return " " , err } raftNodeRemoveIndex := - 1 err = state . Node . Transaction ( func ( tx * db . NodeTx ) error { var err error raftNodes , err = tx . RaftNodes ( ) if err != nil { return errors . Wrap ( err , " " ) } for i , node := range raftNodes { if node . Address == address { raftNodeRemoveIndex = i break } } return nil } ) if err != nil { return " " , err } if raftNodeRemoveIndex == - 1 { } id := strconv . Itoa ( int ( raftNodes [ raftNodeRemoveIndex ] . ID ) ) logger . Info ( " " , log15 . Ctx { " " : id , " " : address , " " : target } ) dial , err := raftDial ( gateway . cert ) if err != nil { return " " , err } err = rafthttp . ChangeMembership ( raftmembership . LeaveRequest , raftEndpoint , dial , raft . ServerID ( id ) , address , target , 5 * time . Second ) if err != nil { return " " , err } return address , nil } 
func Purge ( cluster * db . Cluster , name string ) error { logger . Debugf ( " " , name ) return cluster . Transaction ( func ( tx * db . ClusterTx ) error { if err != nil { return errors . Wrapf ( err , " " , name ) } err = tx . NodeClear ( node . ID ) if err != nil { return errors . Wrapf ( err , " " , name ) } err = tx . NodeRemove ( node . ID ) if err != nil { return errors . Wrapf ( err , " " , name ) } return nil } ) } 
func List ( state * state . State ) ( [ ] api . ClusterMember , error ) { addresses := [ ] string { } err := state . Node . Transaction ( func ( tx * db . NodeTx ) error { nodes , err := tx . RaftNodes ( ) if err != nil { return errors . Wrap ( err , " " ) } for _ , node := range nodes { addresses = append ( addresses , node . Address ) } return nil } ) if err != nil { return nil , err } var nodes [ ] db . NodeInfo var offlineThreshold time . Duration err = state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { nodes , err = tx . Nodes ( ) if err != nil { return err } offlineThreshold , err = tx . NodeOfflineThreshold ( ) if err != nil { return err } return nil } ) if err != nil { return nil , err } result := make ( [ ] api . ClusterMember , len ( nodes ) ) now := time . Now ( ) version := nodes [ 0 ] . Version ( ) for i , node := range nodes { result [ i ] . ServerName = node . Name result [ i ] . URL = fmt . Sprintf ( " " , node . Address ) result [ i ] . Database = shared . StringInSlice ( node . Address , addresses ) if node . IsOffline ( offlineThreshold ) { result [ i ] . Status = " " result [ i ] . Message = fmt . Sprintf ( " " , now . Sub ( node . Heartbeat ) ) } else { result [ i ] . Status = " " result [ i ] . Message = " " } n , err := util . CompareVersions ( version , node . Version ( ) ) if err != nil { result [ i ] . Status = " " result [ i ] . Message = " " continue } if n == 1 { } } } n , err := util . CompareVersions ( version , node . Version ( ) ) if err != nil { continue } if n == 2 { result [ i ] . Status = " " result [ i ] . Message = " " } } return result , nil } 
func Count ( state * state . State ) ( int , error ) { var count int err := state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error count , err = tx . NodesCount ( ) return err } ) return count , err } 
func Enabled ( node * db . Node ) ( bool , error ) { enabled := false err := node . Transaction ( func ( tx * db . NodeTx ) error { addresses , err := tx . RaftNodeAddresses ( ) if err != nil { return err } enabled = len ( addresses ) > 0 return nil } ) return enabled , err } 
func membershipCheckNodeStateForBootstrapOrJoin ( tx * db . NodeTx , address string ) error { nodes , err := tx . RaftNodes ( ) if err != nil { return errors . Wrap ( err , " " ) } hasClusterAddress := address != " " hasRaftNodes := len ( nodes ) > 0 } if ! hasClusterAddress { return fmt . Errorf ( " " ) } if hasRaftNodes { return fmt . Errorf ( " " ) } return nil } 
func membershipCheckClusterStateForBootstrapOrJoin ( tx * db . ClusterTx ) error { nodes , err := tx . Nodes ( ) if err != nil { return errors . Wrap ( err , " " ) } if len ( nodes ) != 1 { return fmt . Errorf ( " " ) } return nil } 
func membershipCheckClusterStateForAccept ( tx * db . ClusterTx , name string , address string , schema int , api int ) error { nodes , err := tx . Nodes ( ) if err != nil { return errors . Wrap ( err , " " ) } if len ( nodes ) == 1 && nodes [ 0 ] . Address == " " { return fmt . Errorf ( " " ) } for _ , node := range nodes { if node . Name == name { return fmt . Errorf ( " " , name ) } if node . Address == address { return fmt . Errorf ( " " , address ) } if node . Schema != schema { return fmt . Errorf ( " " , node . Schema ) } if node . APIExtensions != api { return fmt . Errorf ( " " , node . APIExtensions ) } } return nil } 
func membershipCheckClusterStateForLeave ( tx * db . ClusterTx , nodeID int64 ) error { if err != nil { return err } if message != " " { return fmt . Errorf ( message ) } if err != nil { return err } if len ( nodes ) == 1 { return fmt . Errorf ( " " ) } return nil } 
func membershipCheckNoLeftoverClusterCert ( dir string ) error { } } return nil } 
func ConfigLoad ( tx * db . NodeTx ) ( * Config , error ) { if err != nil { return nil , fmt . Errorf ( " " , err ) } m , err := config . SafeLoad ( ConfigSchema , values ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return & Config { tx : tx , m : m } , nil } 
func ( c * Config ) Replace ( values map [ string ] interface { } ) ( map [ string ] string , error ) { return c . update ( values ) } 
func ( c * Config ) Patch ( patch map [ string ] interface { } ) ( map [ string ] string , error ) { values := c . Dump ( ) for name , value := range patch { values [ name ] = value } return c . update ( values ) } 
func HTTPSAddress ( node * db . Node ) ( string , error ) { var config * Config err := node . Transaction ( func ( tx * db . NodeTx ) error { var err error config , err = ConfigLoad ( tx ) return err } ) if err != nil { return " " , err } return config . HTTPSAddress ( ) , nil } 
func ( c * Cluster ) CertificatesGet ( ) ( certs [ ] * CertInfo , err error ) { err = c . Transaction ( func ( tx * ClusterTx ) error { rows , err := tx . tx . Query ( " " , ) if err != nil { return err } defer rows . Close ( ) for rows . Next ( ) { cert := new ( CertInfo ) rows . Scan ( & cert . ID , & cert . Fingerprint , & cert . Type , & cert . Name , & cert . Certificate , ) certs = append ( certs , cert ) } return rows . Err ( ) } ) if err != nil { return certs , err } return certs , nil } 
func ( c * Cluster ) CertificateGet ( fingerprint string ) ( cert * CertInfo , err error ) { cert = new ( CertInfo ) inargs := [ ] interface { } { fingerprint + " " } outfmt := [ ] interface { } { & cert . ID , & cert . Fingerprint , & cert . Type , & cert . Name , & cert . Certificate , } query := ` SELECT id, fingerprint, type, name, certificate FROM certificates WHERE fingerprint LIKE ?` if err = dbQueryRowScan ( c . db , query , inargs , outfmt ) ; err != nil { if err == sql . ErrNoRows { return nil , ErrNoSuchObject } return nil , err } return cert , err } 
func ( c * Cluster ) CertSave ( cert * CertInfo ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { stmt , err := tx . tx . Prepare ( ` INSERT INTO certificates ( fingerprint, type, name, certificate ) VALUES (?, ?, ?, ?)` , ) if err != nil { return err } defer stmt . Close ( ) _ , err = stmt . Exec ( cert . Fingerprint , cert . Type , cert . Name , cert . Certificate , ) if err != nil { return err } return nil } ) return err } 
func ( c * Cluster ) CertDelete ( fingerprint string ) error { err := exec ( c . db , " " , fingerprint ) if err != nil { return err } return nil } 
func ( c * Cluster ) CertUpdate ( fingerprint string , certName string , certType int ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { _ , err := tx . tx . Exec ( " " , certName , certType , fingerprint ) return err } ) return err } 
func createDevLxdlListener ( dir string ) ( net . Listener , error ) { path := filepath . Join ( dir , " " , " " ) if err != nil { return nil , err } listener , err := socketUnixListen ( path ) if err != nil { return nil , err } err = socketUnixSetPermissions ( path , 0666 ) if err != nil { listener . Close ( ) return nil , err } return listener , nil } 
func newRaft ( database * db . Node , cert * shared . CertInfo , latency float64 ) ( * raftInstance , error ) { if latency <= 0 { return nil , fmt . Errorf ( " " ) } err := database . Transaction ( func ( tx * db . NodeTx ) error { var err error info , err = node . DetermineRaftNode ( tx ) return err } ) if err != nil { return nil , err } } logger . Debug ( " " , log15 . Ctx { " " : info . ID , " " : info . Address } ) if err != nil { return nil , err } return instance , nil } 
func raftInstanceInit ( db * db . Node , node * db . RaftNode , cert * shared . CertInfo , latency float64 ) ( * raftInstance , error ) { raftLogger := raftLogger ( ) config . Logger = raftLogger config . LocalID = raft . ServerID ( strconv . Itoa ( int ( node . ID ) ) ) var membershipChanger func ( * raft . Raft ) var layer * rafthttp . Layer var transport raft . Transport addr := node . Address if addr == " " { transport = raftMemoryTransport ( ) } else { dial , err := raftDial ( cert ) if err != nil { return nil , err } transport , handler , layer , err = raftNetworkTransport ( db , addr , log . New ( & raftLogWriter { } , " " , 0 ) , timeout , dial ) if err != nil { return nil , err } membershipChanger = func ( raft * raft . Raft ) { raftmembership . HandleChangeRequests ( raft , handler . Requests ( ) ) } } err := raft . ValidateConfig ( config ) if err != nil { return nil , errors . Wrap ( err , " " ) } legacyDir := filepath . Join ( db . Dir ( ) , " " , " " ) if shared . PathExists ( legacyDir ) { if shared . PathExists ( dir ) { return nil , fmt . Errorf ( " " ) } logger . Info ( " " ) err := os . Rename ( legacyDir , dir ) if err != nil { return nil , errors . Wrap ( err , " " ) } } if err != nil { return nil , err } } if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrap ( err , " " ) } } serial ++ fsm := dqlite . NewFSM ( registry ) if err != nil { logs . Close ( ) return nil , errors . Wrap ( err , " " ) } if membershipChanger != nil { } instance := & raftInstance { layer : layer , handler : raftHandler ( cert , handler ) , membershipChanger : membershipChanger , logs : logs , registry : registry , fsm : fsm , raft : raft , } return instance , nil } 
func ( i * raftInstance ) Servers ( ) ( [ ] raft . Server , error ) { if i . raft . State ( ) != raft . Leader { return nil , raft . ErrNotLeader } future := i . raft . GetConfiguration ( ) err := future . Error ( ) if err != nil { return nil , err } configuration := future . Configuration ( ) return configuration . Servers , nil } 
func ( i * raftInstance ) HandlerFunc ( ) http . HandlerFunc { if i . handler == nil { return nil } return i . handler . ServeHTTP } 
func ( i * raftInstance ) Shutdown ( ) error { logger . Debug ( " " ) errCh := make ( chan error ) timer := time . After ( timeout ) go func ( ) { errCh <- i . raft . Shutdown ( ) . Error ( ) } ( ) select { case err := <- errCh : if err != nil { return errors . Wrap ( err , " " ) } case <- timer : logger . Debug ( " " ) return fmt . Errorf ( " " , timeout ) } err := i . logs . Close ( ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func raftDial ( cert * shared . CertInfo ) ( rafthttp . Dial , error ) { config , err := tlsClientConfig ( cert ) if err != nil { return nil , err } dial := rafthttp . NewDialTLS ( config ) return dial , nil } 
func raftNetworkTransport ( db * db . Node , address string , logger * log . Logger , timeout time . Duration , dial rafthttp . Dial ) ( raft . Transport , * rafthttp . Handler , * rafthttp . Layer , error ) { handler := rafthttp . NewHandlerWithLogger ( logger ) addr , err := net . ResolveTCPAddr ( " " , address ) if err != nil { return nil , nil , nil , errors . Wrap ( err , " " ) } layer := rafthttp . NewLayer ( raftEndpoint , addr , handler , dial ) config := & raft . NetworkTransportConfig { Logger : logger , Stream : layer , MaxPool : 2 , Timeout : timeout , ServerAddressProvider : & raftAddressProvider { db : db } , } transport := raft . NewNetworkTransportWithConfig ( config ) return transport , handler , layer , nil } 
func raftConfig ( latency float64 ) * raft . Config { config := raft . DefaultConfig ( ) scale := func ( duration * time . Duration ) { * duration = time . Duration ( ( math . Ceil ( float64 ( * duration ) * latency ) ) ) } durations := [ ] * time . Duration { & config . HeartbeatTimeout , & config . ElectionTimeout , & config . CommitTimeout , & config . LeaderLeaseTimeout , } for _ , duration := range durations { scale ( duration ) } config . SnapshotThreshold = 1024 config . TrailingLogs = 512 return config } 
func raftMaybeBootstrap ( conf * raft . Config , logs * raftboltdb . BoltStore , snaps raft . SnapshotStore , trans raft . Transport ) error { if err != nil { return errors . Wrap ( err , " " ) } if hasExistingState { return nil } server := raft . Server { ID : conf . LocalID , Address : trans . LocalAddr ( ) , } configuration := raft . Configuration { Servers : [ ] raft . Server { server } , } return raft . BootstrapCluster ( conf , logs , logs , snaps , trans , configuration ) } 
func CPUResource ( ) ( * api . ResourcesCPU , error ) { c := api . ResourcesCPU { } threads , err := getThreads ( ) if err != nil { return nil , err } var cur * api . ResourcesCPUSocket c . Total = uint64 ( len ( threads ) ) for _ , v := range threads { if uint64 ( len ( c . Sockets ) ) <= v . socketID { c . Sockets = append ( c . Sockets , api . ResourcesCPUSocket { } ) cur = & c . Sockets [ v . socketID ] for _ , thread := range threads { if thread . socketID != v . socketID { continue } socketCores [ thread . coreID ] = true } cur . Cores = uint64 ( len ( socketCores ) ) } else { cur = & c . Sockets [ v . socketID ] } cur . Socket = v . socketID cur . NUMANode = v . numaNode cur . Threads ++ cur . Name = v . name cur . Vendor = v . vendor cur . Frequency = v . frequency cur . FrequencyTurbo = v . frequencyTurbo } return & c , nil } 
func MemoryResource ( ) ( * api . ResourcesMemory , error ) { var buffers uint64 var cached uint64 var free uint64 var total uint64 f , err := os . Open ( " " ) if err != nil { return nil , err } defer f . Close ( ) cleanLine := func ( l string ) ( string , error ) { l = strings . TrimSpace ( l ) idx := strings . LastIndex ( l , " " ) if idx < 0 { return " " , fmt . Errorf ( `Failed to detect "kB" suffix` ) } return strings . TrimSpace ( l [ : idx ] ) , nil } mem := api . ResourcesMemory { } scanner := bufio . NewScanner ( f ) found := 0 for scanner . Scan ( ) { var err error line := scanner . Text ( ) if strings . HasPrefix ( line , " " ) { line , err = cleanLine ( line [ len ( " " ) : ] ) if err != nil { return nil , err } total , err = strconv . ParseUint ( line , 10 , 64 ) if err != nil { return nil , err } found ++ } else if strings . HasPrefix ( line , " " ) { line , err = cleanLine ( line [ len ( " " ) : ] ) if err != nil { return nil , err } free , err = strconv . ParseUint ( line , 10 , 64 ) if err != nil { return nil , err } found ++ } else if strings . HasPrefix ( line , " " ) { line , err = cleanLine ( line [ len ( " " ) : ] ) if err != nil { return nil , err } cached , err = strconv . ParseUint ( line , 10 , 64 ) if err != nil { return nil , err } found ++ } else if strings . HasPrefix ( line , " " ) { line , err = cleanLine ( line [ len ( " " ) : ] ) if err != nil { return nil , err } buffers , err = strconv . ParseUint ( line , 10 , 64 ) if err != nil { return nil , err } found ++ } if found == 4 { break } } mem . Total = total * 1024 mem . Used = ( total - free - cached - buffers ) * 1024 return & mem , err } 
func ( r * ProtocolLXD ) GetOperationUUIDs ( ) ( [ ] string , error ) { urls := [ ] string { } if err != nil { return nil , err } for _ , url := range urls { fields := strings . Split ( url , " " ) uuids = append ( uuids , fields [ len ( fields ) - 1 ] ) } return uuids , nil } 
func ( r * ProtocolLXD ) GetOperations ( ) ( [ ] api . Operation , error ) { apiOperations := map [ string ] [ ] api . Operation { } if err != nil { return nil , err } for _ , v := range apiOperations { for _ , operation := range v { operations = append ( operations , operation ) } } return operations , nil } 
func ( r * ProtocolLXD ) GetOperation ( uuid string ) ( * api . Operation , string , error ) { op := api . Operation { } if err != nil { return nil , " " , err } return & op , etag , nil } 
func ( r * ProtocolLXD ) GetOperationWebsocket ( uuid string , secret string ) ( * websocket . Conn , error ) { path := fmt . Sprintf ( " " , url . QueryEscape ( uuid ) ) if secret != " " { path = fmt . Sprintf ( " " , path , url . QueryEscape ( secret ) ) } return r . websocket ( path ) } 
func ( r * ProtocolLXD ) DeleteOperation ( uuid string ) error { if err != nil { return err } return nil } 
func tryMount ( src string , dst string , fs string , flags uintptr , options string ) error { var err error for i := 0 ; i < 20 ; i ++ { err = syscall . Mount ( src , dst , fs , flags , options ) if err == nil { break } time . Sleep ( 500 * time . Millisecond ) } if err != nil { return err } return nil } 
func lxdUsesPool ( dbObj * db . Cluster , onDiskPoolName string , driver string , onDiskProperty string ) ( bool , string , error ) { pools , err := dbObj . StoragePools ( ) if err != nil && err != db . ErrNoSuchObject { return false , " " , err } for _ , pool := range pools { _ , pl , err := dbObj . StoragePoolGet ( pool ) if err != nil { continue } if pl . Driver != driver { continue } if pl . Config [ onDiskProperty ] == onDiskPoolName { return true , pl . Name , nil } } return false , " " , nil } 
func storagePoolVolumesGet ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) poolName := mux . Vars ( r ) [ " " ] recursion := util . IsRecursionRequest ( r ) if err != nil { return SmartError ( err ) } if err != nil && err != db . ErrNoSuchObject { return SmartError ( err ) } imageVolumes , err := d . cluster . StoragePoolVolumesGet ( " " , poolID , [ ] int { storagePoolVolumeTypeImage } ) if err != nil && err != db . ErrNoSuchObject { return SmartError ( err ) } projectImages , err := d . cluster . ImagesGet ( project , false ) if err != nil { return SmartError ( err ) } for _ , volume := range imageVolumes { if shared . StringInSlice ( volume . Name , projectImages ) { volumes = append ( volumes , volume ) } } resultString := [ ] string { } for _ , volume := range volumes { apiEndpoint , err := storagePoolVolumeTypeNameToAPIEndpoint ( volume . Type ) if err != nil { return InternalError ( err ) } if apiEndpoint == storagePoolVolumeAPIEndpointContainers { apiEndpoint = " " } else if apiEndpoint == storagePoolVolumeAPIEndpointImages { apiEndpoint = " " } if ! recursion { volName , snapName , ok := containerGetParentAndSnapshotName ( volume . Name ) if ok { resultString = append ( resultString , fmt . Sprintf ( " " , version . APIVersion , poolName , apiEndpoint , volName , snapName ) ) } else { resultString = append ( resultString , fmt . Sprintf ( " " , version . APIVersion , poolName , apiEndpoint , volume . Name ) ) } } else { volumeUsedBy , err := storagePoolVolumeUsedByGet ( d . State ( ) , project , volume . Name , volume . Type ) if err != nil { return InternalError ( err ) } volume . UsedBy = volumeUsedBy } } if ! recursion { return SyncResponse ( true , resultString ) } return SyncResponse ( true , volumes ) } 
func storagePoolVolumesTypeGet ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) recursion := util . IsRecursionRequest ( r ) if err != nil { return BadRequest ( err ) } } if err != nil { return SmartError ( err ) } if err != nil { return SmartError ( err ) } resultString := [ ] string { } resultMap := [ ] * api . StorageVolume { } for _ , volume := range volumes { if ! recursion { apiEndpoint , err := storagePoolVolumeTypeToAPIEndpoint ( volumeType ) if err != nil { return InternalError ( err ) } if apiEndpoint == storagePoolVolumeAPIEndpointContainers { apiEndpoint = " " } else if apiEndpoint == storagePoolVolumeAPIEndpointImages { apiEndpoint = " " } resultString = append ( resultString , fmt . Sprintf ( " " , version . APIVersion , poolName , apiEndpoint , volume ) ) } else { _ , vol , err := d . cluster . StoragePoolNodeVolumeGetType ( volume , volumeType , poolID ) if err != nil { continue } volumeUsedBy , err := storagePoolVolumeUsedByGet ( d . State ( ) , project , vol . Name , vol . Type ) if err != nil { return SmartError ( err ) } vol . UsedBy = volumeUsedBy resultMap = append ( resultMap , vol ) } } if ! recursion { return SyncResponse ( true , resultString ) } return SyncResponse ( true , resultMap ) } 
func storagePoolVolumesTypePost ( d * Daemon , r * http . Request ) Response { response := ForwardedResponseIfTargetIsRemote ( d , r ) if response != nil { return response } req := api . StorageVolumesPost { } if err != nil { return BadRequest ( err ) } } if strings . Contains ( req . Name , " " ) { return BadRequest ( fmt . Errorf ( " " ) ) } req . Type = mux . Vars ( r ) [ " " ] } poolName := mux . Vars ( r ) [ " " ] switch req . Source . Type { case " " : return doVolumeCreateOrCopy ( d , poolName , & req ) case " " : return doVolumeCreateOrCopy ( d , poolName , & req ) case " " : return doVolumeMigration ( d , poolName , & req ) default : return BadRequest ( fmt . Errorf ( " " , req . Source . Type ) ) } } 
func storagePoolVolumeTypePost ( d * Daemon , r * http . Request , volumeTypeName string ) Response { fields := strings . Split ( mux . Vars ( r ) [ " " ] , " " ) if len ( fields ) == 3 && fields [ 1 ] == " " { } else if len ( fields ) > 1 { volumeName = fmt . Sprintf ( " " , fields [ 0 ] , shared . SnapshotDelimiter , fields [ 1 ] ) } else if len ( fields ) > 0 { } else { return BadRequest ( fmt . Errorf ( " " , mux . Vars ( r ) [ " " ] ) ) } req := api . StorageVolumePost { } if err != nil { return BadRequest ( err ) } } if strings . Contains ( req . Name , " " ) { return BadRequest ( fmt . Errorf ( " " ) ) } } if req . Pool != " " { poolID , err = d . cluster . StoragePoolGetID ( req . Pool ) } else { poolID , err = d . cluster . StoragePoolGetID ( poolName ) } if err != nil { return SmartError ( err ) } err = json . NewEncoder ( & buf ) . Encode ( req ) if err != nil { return SmartError ( err ) } r . Body = shared . BytesReadCloser { Buf : & buf } response := ForwardedResponseIfTargetIsRemote ( d , r ) if response != nil { return response } if err != nil { return BadRequest ( err ) } response = ForwardedResponseIfVolumeIsRemote ( d , r , poolID , volumeName , volumeType ) if response != nil { return response } s , err := storagePoolVolumeInit ( d . State ( ) , " " , poolName , volumeName , storagePoolVolumeTypeCustom ) if err != nil { return InternalError ( err ) } if err != nil { return InternalError ( err ) } resources := map [ string ] [ ] string { } resources [ " " ] = [ ] string { fmt . Sprintf ( " " , poolName , volumeName ) } if req . Target != nil { if err != nil { return InternalError ( err ) } op , err := operationCreate ( d . cluster , " " , operationClassTask , db . OperationVolumeMigrate , resources , nil , ws . DoStorage , nil , nil ) if err != nil { return InternalError ( err ) } return OperationResponse ( op ) } if err != nil { return InternalError ( err ) } return OperationResponse ( op ) } if err != db . ErrNoSuchObject { if err != nil { return InternalError ( err ) } return Conflict ( fmt . Errorf ( " " , req . Name ) ) } doWork := func ( ) error { ctsUsingVolume , err := storagePoolVolumeUsedByRunningContainersWithProfilesGet ( d . State ( ) , poolName , volumeName , storagePoolVolumeTypeNameCustom , true ) if err != nil { return err } if len ( ctsUsingVolume ) > 0 { return fmt . Errorf ( " " ) } err = storagePoolVolumeUpdateUsers ( d , poolName , volumeName , req . Pool , req . Name ) if err != nil { return err } if req . Pool == " " || req . Pool == poolName { err := s . StoragePoolVolumeRename ( req . Name ) if err != nil { storagePoolVolumeUpdateUsers ( d , req . Pool , req . Name , poolName , volumeName ) return err } } else { moveReq := api . StorageVolumesPost { } moveReq . Name = req . Name moveReq . Type = " " moveReq . Source . Name = volumeName moveReq . Source . Pool = poolName err := storagePoolVolumeCreateInternal ( d . State ( ) , req . Pool , & moveReq ) if err != nil { storagePoolVolumeUpdateUsers ( d , req . Pool , req . Name , poolName , volumeName ) return err } err = s . StoragePoolVolumeDelete ( ) if err != nil { return err } } return nil } if req . Pool == " " { err = doWork ( ) if err != nil { return SmartError ( err ) } return SyncResponseLocation ( true , nil , fmt . Sprintf ( " " , version . APIVersion , poolName , storagePoolVolumeAPIEndpointCustom ) ) } run := func ( op * operation ) error { return doWork ( ) } op , err := operationCreate ( d . cluster , " " , operationClassTask , db . OperationVolumeMove , nil , nil , run , nil , nil ) if err != nil { return InternalError ( err ) } return OperationResponse ( op ) } 
func storagePoolVolumeTypeGet ( d * Daemon , r * http . Request , volumeTypeName string ) Response { project := projectParam ( r ) fields := strings . Split ( mux . Vars ( r ) [ " " ] , " " ) if len ( fields ) == 3 && fields [ 1 ] == " " { } else if len ( fields ) > 1 { volumeName = fmt . Sprintf ( " " , fields [ 0 ] , shared . SnapshotDelimiter , fields [ 1 ] ) } else if len ( fields ) > 0 { } else { return BadRequest ( fmt . Errorf ( " " , mux . Vars ( r ) [ " " ] ) ) } if err != nil { return BadRequest ( err ) } } if err != nil { return SmartError ( err ) } response := ForwardedResponseIfTargetIsRemote ( d , r ) if response != nil { return response } response = ForwardedResponseIfVolumeIsRemote ( d , r , poolID , volumeName , volumeType ) if response != nil { return response } if err != nil { return SmartError ( err ) } volumeUsedBy , err := storagePoolVolumeUsedByGet ( d . State ( ) , project , volume . Name , volume . Type ) if err != nil { return SmartError ( err ) } volume . UsedBy = volumeUsedBy etag := [ ] interface { } { volumeName , volume . Type , volume . Config } return SyncResponseETag ( true , volume , etag ) } 
func storagePoolVolumeTypePut ( d * Daemon , r * http . Request , volumeTypeName string ) Response { fields := strings . Split ( mux . Vars ( r ) [ " " ] , " " ) if len ( fields ) == 3 && fields [ 1 ] == " " { } else if len ( fields ) > 1 { volumeName = fmt . Sprintf ( " " , fields [ 0 ] , shared . SnapshotDelimiter , fields [ 1 ] ) } else if len ( fields ) > 0 { } else { return BadRequest ( fmt . Errorf ( " " , mux . Vars ( r ) [ " " ] ) ) } if err != nil { return BadRequest ( err ) } } poolID , pool , err := d . cluster . StoragePoolGet ( poolName ) if err != nil { return SmartError ( err ) } response := ForwardedResponseIfTargetIsRemote ( d , r ) if response != nil { return response } response = ForwardedResponseIfVolumeIsRemote ( d , r , poolID , volumeName , volumeType ) if response != nil { return response } if err != nil { return SmartError ( err ) } err = util . EtagCheck ( r , etag ) if err != nil { return PreconditionFailed ( err ) } req := api . StorageVolumePut { } if err := json . NewDecoder ( r . Body ) . Decode ( & req ) ; err != nil { return BadRequest ( err ) } if req . Restore != " " { ctsUsingVolume , err := storagePoolVolumeUsedByRunningContainersWithProfilesGet ( d . State ( ) , poolName , volume . Name , storagePoolVolumeTypeNameCustom , true ) if err != nil { return InternalError ( err ) } if len ( ctsUsingVolume ) != 0 { return BadRequest ( fmt . Errorf ( " " ) ) } err = storagePoolVolumeRestore ( d . State ( ) , poolName , volumeName , volumeType , req . Restore ) if err != nil { return SmartError ( err ) } } else { if err != nil { return BadRequest ( err ) } err = storagePoolVolumeUpdate ( d . State ( ) , poolName , volumeName , volumeType , req . Description , req . Config ) if err != nil { return SmartError ( err ) } } return EmptySyncResponse } 
func storagePoolVolumeTypeDelete ( d * Daemon , r * http . Request , volumeTypeName string ) Response { project := projectParam ( r ) fields := strings . Split ( mux . Vars ( r ) [ " " ] , " " ) if len ( fields ) == 3 && fields [ 1 ] == " " { } else if len ( fields ) > 0 { } else { return BadRequest ( fmt . Errorf ( " " , mux . Vars ( r ) [ " " ] ) ) } if err != nil { return BadRequest ( err ) } } response := ForwardedResponseIfTargetIsRemote ( d , r ) if response != nil { return response } poolID , _ , err := d . cluster . StoragePoolGet ( poolName ) if err != nil { return SmartError ( err ) } response = ForwardedResponseIfVolumeIsRemote ( d , r , poolID , volumeName , volumeType ) if response != nil { return response } switch volumeType { case storagePoolVolumeTypeCustom : } volumeUsedBy , err := storagePoolVolumeUsedByGet ( d . State ( ) , project , volumeName , volumeTypeName ) if err != nil { return SmartError ( err ) } if len ( volumeUsedBy ) > 0 { if len ( volumeUsedBy ) != 1 || volumeType != storagePoolVolumeTypeImage || volumeUsedBy [ 0 ] != fmt . Sprintf ( " " , version . APIVersion , volumeName ) { return BadRequest ( fmt . Errorf ( `The storage volume is ` + `still in use by containers or profiles` ) ) } } s , err := storagePoolVolumeInit ( d . State ( ) , " " , poolName , volumeName , volumeType ) if err != nil { return NotFound ( err ) } switch volumeType { case storagePoolVolumeTypeCustom : var snapshots [ ] string if err != nil { return SmartError ( err ) } for _ , snapshot := range snapshots { s , err := storagePoolVolumeInit ( d . State ( ) , project , poolName , snapshot , volumeType ) if err != nil { return NotFound ( err ) } err = s . StoragePoolVolumeSnapshotDelete ( ) if err != nil { return SmartError ( err ) } } err = s . StoragePoolVolumeDelete ( ) case storagePoolVolumeTypeImage : err = s . ImageDelete ( volumeName ) default : return BadRequest ( fmt . Errorf ( `Storage volumes of type "%s" ` + `cannot be deleted with the storage api` , volumeTypeName ) ) } if err != nil { return SmartError ( err ) } return EmptySyncResponse } 
func ( c * ClusterTx ) ProjectURIs ( filter ProjectFilter ) ( [ ] string , error ) { if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil { stmt = c . stmt ( projectNamesByName ) args = [ ] interface { } { filter . Name , } } else { stmt = c . stmt ( projectNames ) args = [ ] interface { } { } } code := cluster . EntityTypes [ " " ] formatter := cluster . EntityFormatURIs [ code ] return query . SelectURIs ( stmt , formatter , args ... ) } 
func ( c * ClusterTx ) ProjectList ( filter ProjectFilter ) ( [ ] api . Project , error ) { if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil { stmt = c . stmt ( projectObjectsByName ) args = [ ] interface { } { filter . Name , } } else { stmt = c . stmt ( projectObjects ) args = [ ] interface { } { } } return [ ] interface { } { & objects [ i ] . Description , & objects [ i ] . Name , } } if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { value := configObjects [ objects [ i ] . Name ] if value == nil { value = map [ string ] string { } } objects [ i ] . Config = value } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { value := usedByObjects [ objects [ i ] . Name ] if value == nil { value = [ ] string { } } objects [ i ] . UsedBy = value } return objects , nil } 
func ( c * ClusterTx ) ProjectGet ( name string ) ( * api . Project , error ) { filter := ProjectFilter { } filter . Name = name objects , err := c . ProjectList ( filter ) if err != nil { return nil , errors . Wrap ( err , " " ) } switch len ( objects ) { case 0 : return nil , ErrNoSuchObject case 1 : return & objects [ 0 ] , nil default : return nil , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) ProjectExists ( name string ) ( bool , error ) { _ , err := c . ProjectID ( name ) if err != nil { if err == ErrNoSuchObject { return false , nil } return false , err } return true , nil } 
func ( c * ClusterTx ) ProjectCreate ( object api . ProjectsPost ) ( int64 , error ) { if err != nil { return - 1 , errors . Wrap ( err , " " ) } if exists { return - 1 , fmt . Errorf ( " " ) } args := make ( [ ] interface { } , 2 ) args [ 1 ] = object . Name if err != nil { return - 1 , errors . Wrap ( err , " " ) } id , err := result . LastInsertId ( ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } for key , value := range object . Config { _ , err := stmt . Exec ( id , key , value ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } } return id , nil } 
func ( c * ClusterTx ) ProjectUsedByRef ( filter ProjectFilter ) ( map [ string ] [ ] string , error ) { Value string } , 0 ) if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil { stmt = c . stmt ( projectUsedByRefByName ) args = [ ] interface { } { filter . Name , } } else { stmt = c . stmt ( projectUsedByRef ) args = [ ] interface { } { } } Value string } { } ) return [ ] interface { } { & objects [ i ] . Name , & objects [ i ] . Value , } } if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , object := range objects { item , ok := index [ object . Name ] if ! ok { item = [ ] string { } } index [ object . Name ] = append ( item , object . Value ) } return index , nil } 
func ( c * ClusterTx ) ProjectRename ( name string , to string ) error { stmt := c . stmt ( projectRename ) result , err := stmt . Exec ( to , name ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) ProjectDelete ( name string ) error { stmt := c . stmt ( projectDelete ) result , err := stmt . Exec ( name ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func PasswordCheck ( secret string , password string ) error { } if err != nil { return err } salt := buff [ 0 : 32 ] hash , err := scrypt . Key ( [ ] byte ( password ) , salt , 1 << 14 , 8 , 1 , 64 ) if err != nil { return err } if ! bytes . Equal ( hash , buff [ 32 : ] ) { return fmt . Errorf ( " " ) } return nil } 
func LoadCert ( dir string ) ( * shared . CertInfo , error ) { prefix := " " if shared . PathExists ( filepath . Join ( dir , " " ) ) { prefix = " " } cert , err := shared . KeyPairAndCA ( dir , prefix , shared . CertServer ) if err != nil { return nil , errors . Wrap ( err , " " ) } return cert , nil } 
func WriteCert ( dir , prefix string , cert , key , ca [ ] byte ) error { err := ioutil . WriteFile ( filepath . Join ( dir , prefix + " " ) , cert , 0644 ) if err != nil { return err } err = ioutil . WriteFile ( filepath . Join ( dir , prefix + " " ) , key , 0600 ) if err != nil { return err } if ca != nil { err = ioutil . WriteFile ( filepath . Join ( dir , prefix + " " ) , ca , 0644 ) if err != nil { return err } } return nil } 
func NewDaemon ( config * DaemonConfig , os * sys . OS ) * Daemon { return & Daemon { config : config , os : os , setupChan : make ( chan struct { } ) , readyChan : make ( chan struct { } ) , shutdownChan : make ( chan struct { } ) , } } 
func DefaultDaemon ( ) * Daemon { config := DefaultDaemonConfig ( ) os := sys . DefaultOS ( ) return NewDaemon ( config , os ) } 
func AllowProjectPermission ( feature string , permission string ) func ( d * Daemon , r * http . Request ) Response { return func ( d * Daemon , r * http . Request ) Response { } } return EmptySyncResponse } } 
func ( d * Daemon ) checkTrustedClient ( r * http . Request ) error { trusted , _ , _ , err := d . Authenticate ( r ) if ! trusted || err != nil { if err != nil { return err } return fmt . Errorf ( " " ) } return nil } 
func ( d * Daemon ) Authenticate ( r * http . Request ) ( bool , string , string , error ) { clusterCerts := map [ string ] x509 . Certificate { " " : * cert } for i := range r . TLS . PeerCertificates { trusted , _ := util . CheckTrustState ( * r . TLS . PeerCertificates [ i ] , clusterCerts ) if trusted { return true , " " , " " , nil } } } } } } } if d . externalAuth != nil && r . Header . Get ( httpbakery . BakeryProtocolHeader ) != " " { authChecker := d . externalAuth . bakery . Checker . Auth ( httpbakery . RequestMacaroons ( r ) ... ) ops := [ ] bakery . Op { { Entity : r . URL . Path , Action : r . Method , } } info , err := authChecker . Allow ( ctx , ops ... ) if err != nil { } if info != nil && info . Identity != nil { } } if trusted { return true , username , " " , nil } } } 
func ( d * Daemon ) State ( ) * state . State { return state . NewState ( d . db , d . cluster , d . maas , d . os , d . endpoints ) } 
func ( d * Daemon ) UnixSocket ( ) string { path := os . Getenv ( " " ) if path != " " { return path } return filepath . Join ( d . os . VarDir , " " ) } 
func ( d * Daemon ) Stop ( ) error { logger . Info ( " " ) errs := [ ] error { } trackError := func ( err error ) { if err != nil { errs = append ( errs , err ) } } if d . endpoints != nil { trackError ( d . endpoints . Down ( ) ) } trackError ( d . tasks . Stop ( 3 * time . Second ) ) trackError ( d . clusterTasks . Stop ( 3 * time . Second ) ) shouldUnmount := false if d . cluster != nil { go func ( ) { n , err := d . numRunningContainers ( ) ch <- err != nil || n == 0 } ( ) select { case shouldUnmount = <- ch : case <- time . After ( 2 * time . Second ) : shouldUnmount = true } logger . Infof ( " " ) err := d . cluster . Close ( ) } else { trackError ( err ) } } if d . db != nil { trackError ( d . db . Close ( ) ) } if d . gateway != nil { trackError ( d . gateway . Shutdown ( ) ) } if d . endpoints != nil { trackError ( d . endpoints . Down ( ) ) } if d . endpoints != nil { trackError ( d . endpoints . Down ( ) ) } if shouldUnmount { logger . Infof ( " " ) syscall . Unmount ( shared . VarPath ( " " ) , syscall . MNT_DETACH ) syscall . Unmount ( shared . VarPath ( " " ) , syscall . MNT_DETACH ) logger . Infof ( " " ) } else { logger . Debugf ( " " ) } var err error if n := len ( errs ) ; n > 0 { format := " " if n > 1 { format += fmt . Sprintf ( " " , n ) } err = fmt . Errorf ( format , errs [ 0 ] ) } if err != nil { logger . Errorf ( " " , err ) } return err } 
func ( d * Daemon ) setupExternalAuthentication ( authEndpoint string , authPubkey string , expiry int64 , domains string ) error { for _ , domain := range strings . Split ( domains , " " ) { if domain == " " { continue } authDomains = append ( authDomains , strings . TrimSpace ( domain ) ) } return nil } if err != nil { return err } idmClientWrapper := & IdentityClientWrapper { client : idmClient , ValidDomains : authDomains , } if err != nil { return err } pkCache := bakery . NewThirdPartyStore ( ) pkLocator := httpbakery . NewThirdPartyLocator ( nil , pkCache ) if authPubkey != " " { err := pkKey . UnmarshalText ( [ ] byte ( authPubkey ) ) if err != nil { return err } } } } , } , } ) return nil } 
func ( d * Daemon ) setupRBACServer ( rbacURL string , rbacKey string , rbacExpiry int64 , rbacAgentURL string , rbacAgentUsername string , rbacAgentPrivateKey string , rbacAgentPublicKey string ) error { if d . rbac != nil || rbacURL == " " || rbacAgentURL == " " || rbacAgentUsername == " " || rbacAgentPrivateKey == " " || rbacAgentPublicKey == " " { return nil } if err != nil { return err } err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error result , err = tx . ProjectMap ( ) return err } ) return result , err } if err != nil { return err } server . StartStatusCheck ( ) d . rbac = server if err != nil { return err } return nil } 
func ( d * Daemon ) setupMAASController ( server string , key string , machine string ) error { var err error d . maas = nil if err != nil { return err } } } if err != nil { d . maas = nil return err } d . maas = controller return nil } 
func initializeDbObject ( d * Daemon ) ( * db . Dump , error ) { logger . Info ( " " ) } logger . Info ( " " ) err := os . Rename ( d . os . LegacyLocalDatabasePath ( ) , d . os . LocalDatabasePath ( ) ) if err != nil { return nil , errors . Wrap ( err , " " ) } } for i , patch := range legacyPatches { legacy [ i ] = & db . LegacyPatch { Hook : func ( node * sql . DB ) error { defer func ( ) { d . cluster = cluster } ( ) d . db = db . ForLegacyPatches ( node ) d . cluster = db . ForLocalInspection ( node ) return patch ( d ) } , } } for _ , i := range legacyPatchesNeedingDB { legacy [ i ] . NeedsDB = true } if err != nil { return err } } return nil } var err error var dump * db . Dump d . db , dump , err = db . OpenNode ( filepath . Join ( d . os . VarDir , " " ) , freshHook , legacy ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return dump , nil } 
func ( s * rbdMigrationSourceDriver ) rbdSend ( conn * websocket . Conn , volumeName string , volumeParentName string , readWrapper func ( io . ReadCloser ) io . ReadCloser ) error { args := [ ] string { " " , " " , s . ceph . ClusterName , volumeName , } if volumeParentName != " " { args = append ( args , " " , volumeParentName ) } cmd := exec . Command ( " " , args ... ) stdout , err := cmd . StdoutPipe ( ) if err != nil { return err } readPipe := io . ReadCloser ( stdout ) if readWrapper != nil { readPipe = readWrapper ( stdout ) } stderr , err := cmd . StderrPipe ( ) if err != nil { return err } err = cmd . Start ( ) if err != nil { return err } <- shared . WebsocketSendStream ( conn , readPipe , 4 * 1024 * 1024 ) output , err := ioutil . ReadAll ( stderr ) if err != nil { logger . Debugf ( `Failed to read stderr output from "rbd export-diff": %s` , err ) } err = cmd . Wait ( ) if err != nil { logger . Errorf ( `Failed to perform "rbd export-diff": %s` , string ( output ) ) } return err } 
func WriteJSON ( w http . ResponseWriter , body interface { } , debug bool ) error { var output io . Writer var captured * bytes . Buffer output = w if debug { captured = & bytes . Buffer { } output = io . MultiWriter ( w , captured ) } err := json . NewEncoder ( output ) . Encode ( body ) if captured != nil { shared . DebugJson ( captured ) } return err } 
func EtagHash ( data interface { } ) ( string , error ) { etag := sha256 . New ( ) err := json . NewEncoder ( etag ) . Encode ( data ) if err != nil { return " " , err } return fmt . Sprintf ( " " , etag . Sum ( nil ) ) , nil } 
func EtagCheck ( r * http . Request , data interface { } ) error { match := r . Header . Get ( " " ) if match == " " { return nil } hash , err := EtagHash ( data ) if err != nil { return err } if hash != match { return fmt . Errorf ( " " , hash , match ) } return nil } 
func HTTPClient ( certificate string , proxy proxyFunc ) ( * http . Client , error ) { var err error var cert * x509 . Certificate if certificate != " " { certBlock , _ := pem . Decode ( [ ] byte ( certificate ) ) if certBlock == nil { return nil , fmt . Errorf ( " " ) } cert , err = x509 . ParseCertificate ( certBlock . Bytes ) if err != nil { return nil , err } } tlsConfig , err := shared . GetTLSConfig ( " " , " " , " " , cert ) if err != nil { return nil , err } tr := & http . Transport { TLSClientConfig : tlsConfig , Dial : shared . RFC3493Dialer , Proxy : proxy , DisableKeepAlives : true , } myhttp := http . Client { Transport : tr , } return nil } return & myhttp , nil } 
func CheckTrustState ( cert x509 . Certificate , trustedCerts map [ string ] x509 . Certificate ) ( bool , string ) { } for k , v := range trustedCerts { if bytes . Compare ( cert . Raw , v . Raw ) == 0 { logger . Debug ( " " , log . Ctx { " " : k } ) return true , k } } return false , " " } 
func IsRecursionRequest ( r * http . Request ) bool { recursionStr := r . FormValue ( " " ) recursion , err := strconv . Atoi ( recursionStr ) if err != nil { return false } return recursion != 0 } 
func ListenAddresses ( value string ) ( [ ] string , error ) { addresses := make ( [ ] string , 0 ) if value == " " { return addresses , nil } localHost , localPort , err := net . SplitHostPort ( value ) if err != nil { localHost = value localPort = shared . DefaultPort } if localHost == " " || localHost == " " || localHost == " " { ifaces , err := net . Interfaces ( ) if err != nil { return addresses , err } for _ , i := range ifaces { addrs , err := i . Addrs ( ) if err != nil { continue } for _ , addr := range addrs { var ip net . IP switch v := addr . ( type ) { case * net . IPNet : ip = v . IP case * net . IPAddr : ip = v . IP } if ! ip . IsGlobalUnicast ( ) { continue } if ip . To4 ( ) == nil { if localHost == " " { continue } addresses = append ( addresses , fmt . Sprintf ( " " , ip , localPort ) ) } else { addresses = append ( addresses , fmt . Sprintf ( " " , ip , localPort ) ) } } } } else { if strings . Contains ( localHost , " " ) { addresses = append ( addresses , fmt . Sprintf ( " " , localHost , localPort ) ) } else { addresses = append ( addresses , fmt . Sprintf ( " " , localHost , localPort ) ) } } return addresses , nil } 
func GetListeners ( start int ) [ ] net . Listener { defer func ( ) { os . Unsetenv ( " " ) os . Unsetenv ( " " ) } ( ) pid , err := strconv . Atoi ( os . Getenv ( " " ) ) if err != nil { return nil } if pid != os . Getpid ( ) { return nil } fds , err := strconv . Atoi ( os . Getenv ( " " ) ) if err != nil { return nil } listeners := [ ] net . Listener { } for i := start ; i < start + fds ; i ++ { syscall . CloseOnExec ( i ) file := os . NewFile ( uintptr ( i ) , fmt . Sprintf ( " " , i ) ) listener , err := net . FileListener ( file ) if err != nil { continue } listeners = append ( listeners , listener ) } return listeners } 
func internalSQLGet ( d * Daemon , r * http . Request ) Response { database := r . FormValue ( " " ) if ! shared . StringInSlice ( database , [ ] string { " " , " " } ) { return BadRequest ( fmt . Errorf ( " " ) ) } schemaFormValue := r . FormValue ( " " ) schemaOnly , err := strconv . Atoi ( schemaFormValue ) if err != nil { schemaOnly = 0 } var schema string var db * sql . DB if database == " " { db = d . cluster . DB ( ) schema = cluster . FreshSchema ( ) } else { db = d . db . DB ( ) schema = node . FreshSchema ( ) } tx , err := db . Begin ( ) if err != nil { return SmartError ( errors . Wrap ( err , " " ) ) } defer tx . Rollback ( ) dump , err := query . Dump ( tx , schema , schemaOnly == 1 ) if err != nil { return SmartError ( errors . Wrapf ( err , " " , database ) ) } return SyncResponse ( true , internalSQLDump { Text : dump } ) } 
func internalSQLPost ( d * Daemon , r * http . Request ) Response { req := & internalSQLQuery { } if err != nil { return BadRequest ( err ) } if ! shared . StringInSlice ( req . Database , [ ] string { " " , " " } ) { return BadRequest ( fmt . Errorf ( " " ) ) } if req . Query == " " { return BadRequest ( fmt . Errorf ( " " ) ) } var db * sql . DB if req . Database == " " { db = d . cluster . DB ( ) } else { db = d . db . DB ( ) } batch := internalSQLBatch { } if req . Query == " " { d . gateway . Sync ( ) return SyncResponse ( true , batch ) } for _ , query := range strings . Split ( req . Query , " " ) { query = strings . TrimLeft ( query , " " ) if query == " " { continue } result := internalSQLResult { } tx , err := db . Begin ( ) if err != nil { return SmartError ( err ) } if strings . HasPrefix ( strings . ToUpper ( query ) , " " ) { err = internalSQLSelect ( tx , query , & result ) tx . Rollback ( ) } else { err = internalSQLExec ( tx , query , & result ) if err != nil { tx . Rollback ( ) } else { err = tx . Commit ( ) } } if err != nil { return SmartError ( err ) } batch . Results = append ( batch . Results , result ) } return SyncResponse ( true , batch ) } 
func KeyPairAndCA ( dir , prefix string , kind CertKind ) ( * CertInfo , error ) { certFilename := filepath . Join ( dir , prefix + " " ) keyFilename := filepath . Join ( dir , prefix + " " ) if err != nil { return nil , err } if err != nil { return nil , err } var ca * x509 . Certificate if PathExists ( caFilename ) { ca , err = ReadCert ( caFilename ) if err != nil { return nil , err } } info := & CertInfo { keypair : keypair , ca : ca , } return info , nil } 
func ( c * CertInfo ) PublicKey ( ) [ ] byte { data := c . KeyPair ( ) . Certificate [ 0 ] return pem . EncodeToMemory ( & pem . Block { Type : " " , Bytes : data } ) } 
func ( c * CertInfo ) PrivateKey ( ) [ ] byte { ecKey , ok := c . KeyPair ( ) . PrivateKey . ( * ecdsa . PrivateKey ) if ok { data , err := x509 . MarshalECPrivateKey ( ecKey ) if err != nil { return nil } return pem . EncodeToMemory ( & pem . Block { Type : " " , Bytes : data } ) } rsaKey , ok := c . KeyPair ( ) . PrivateKey . ( * rsa . PrivateKey ) if ok { data := x509 . MarshalPKCS1PrivateKey ( rsaKey ) return pem . EncodeToMemory ( & pem . Block { Type : " " , Bytes : data } ) } return nil } 
func ( c * CertInfo ) Fingerprint ( ) string { fingerprint , err := CertFingerprintStr ( string ( c . PublicKey ( ) ) ) } return fingerprint } 
func mynames ( ) ( [ ] string , error ) { h , err := os . Hostname ( ) if err != nil { return nil , err } ret := [ ] string { h } ifs , err := net . Interfaces ( ) if err != nil { return nil , err } for _ , iface := range ifs { if IsLoopback ( & iface ) { continue } addrs , err := iface . Addrs ( ) if err != nil { return nil , err } for _ , addr := range addrs { ret = append ( ret , addr . String ( ) ) } } return ret , nil } 
func GenCert ( certf string , keyf string , certtype bool ) error { dir := path . Dir ( certf ) err := os . MkdirAll ( dir , 0750 ) if err != nil { return err } dir = path . Dir ( keyf ) err = os . MkdirAll ( dir , 0750 ) if err != nil { return err } certBytes , keyBytes , err := GenerateMemCert ( certtype ) if err != nil { return err } certOut , err := os . Create ( certf ) if err != nil { return fmt . Errorf ( " " , certf , err ) } certOut . Write ( certBytes ) certOut . Close ( ) keyOut , err := os . OpenFile ( keyf , os . O_WRONLY | os . O_CREATE | os . O_TRUNC , 0600 ) if err != nil { return fmt . Errorf ( " " , keyf , err ) } keyOut . Write ( keyBytes ) keyOut . Close ( ) return nil } 
func GenerateMemCert ( client bool ) ( [ ] byte , [ ] byte , error ) { privk , err := ecdsa . GenerateKey ( elliptic . P384 ( ) , rand . Reader ) if err != nil { return nil , nil , fmt . Errorf ( " " , err ) } hosts , err := mynames ( ) if err != nil { return nil , nil , fmt . Errorf ( " " , err ) } validFrom := time . Now ( ) validTo := validFrom . Add ( 10 * 365 * 24 * time . Hour ) serialNumberLimit := new ( big . Int ) . Lsh ( big . NewInt ( 1 ) , 128 ) serialNumber , err := rand . Int ( rand . Reader , serialNumberLimit ) if err != nil { return nil , nil , fmt . Errorf ( " " , err ) } userEntry , err := user . Current ( ) var username string if err == nil { username = userEntry . Username if username == " " { username = " " } } else { username = " " } hostname , err := os . Hostname ( ) if err != nil { hostname = " " } template := x509 . Certificate { SerialNumber : serialNumber , Subject : pkix . Name { Organization : [ ] string { " " } , CommonName : fmt . Sprintf ( " " , username , hostname ) , } , NotBefore : validFrom , NotAfter : validTo , KeyUsage : x509 . KeyUsageKeyEncipherment | x509 . KeyUsageDigitalSignature , BasicConstraintsValid : true , } if client { template . ExtKeyUsage = [ ] x509 . ExtKeyUsage { x509 . ExtKeyUsageClientAuth } } else { template . ExtKeyUsage = [ ] x509 . ExtKeyUsage { x509 . ExtKeyUsageServerAuth } } for _ , h := range hosts { if ip , _ , err := net . ParseCIDR ( h ) ; err == nil { if ! ip . IsLinkLocalUnicast ( ) && ! ip . IsLinkLocalMulticast ( ) { template . IPAddresses = append ( template . IPAddresses , ip ) } } else { template . DNSNames = append ( template . DNSNames , h ) } } derBytes , err := x509 . CreateCertificate ( rand . Reader , & template , & template , & privk . PublicKey , privk ) if err != nil { return nil , nil , fmt . Errorf ( " " , err ) } data , err := x509 . MarshalECPrivateKey ( privk ) if err != nil { return nil , nil , err } cert := pem . EncodeToMemory ( & pem . Block { Type : " " , Bytes : derBytes } ) key := pem . EncodeToMemory ( & pem . Block { Type : " " , Bytes : data } ) return cert , key , nil } 
func PrintServerInfo ( c lxd . ContainerServer ) error { server , _ , err := c . GetServer ( ) if err != nil { return err } env := server . Environment fmt . Printf ( " \n " ) fmt . Printf ( " \n " , env . Server ) fmt . Printf ( " \n " , env . ServerVersion ) fmt . Printf ( " \n " , env . Kernel ) fmt . Printf ( " \n " , env . KernelArchitecture ) fmt . Printf ( " \n " , env . KernelVersion ) fmt . Printf ( " \n " , env . Storage ) fmt . Printf ( " \n " , env . StorageVersion ) fmt . Printf ( " \n " , env . Driver ) fmt . Printf ( " \n " , env . DriverVersion ) fmt . Printf ( " \n " ) return nil } 
func LaunchContainers ( c lxd . ContainerServer , count int , parallel int , image string , privileged bool , start bool , freeze bool ) ( time . Duration , error ) { var duration time . Duration batchSize , err := getBatchSize ( parallel ) if err != nil { return duration , err } printTestConfig ( count , batchSize , image , privileged , freeze ) fingerprint , err := ensureImage ( c , image ) if err != nil { return duration , err } batchStart := func ( index int , wg * sync . WaitGroup ) { defer wg . Done ( ) name := getContainerName ( count , index ) err := createContainer ( c , fingerprint , name , privileged ) if err != nil { logf ( " " , name , err ) return } if start { err := startContainer ( c , name ) if err != nil { logf ( " " , name , err ) return } if freeze { err := freezeContainer ( c , name ) if err != nil { logf ( " " , name , err ) return } } } } duration = processBatch ( count , batchSize , batchStart ) return duration , nil } 
func CreateContainers ( c lxd . ContainerServer , count int , parallel int , fingerprint string , privileged bool ) ( time . Duration , error ) { var duration time . Duration batchSize , err := getBatchSize ( parallel ) if err != nil { return duration , err } batchCreate := func ( index int , wg * sync . WaitGroup ) { defer wg . Done ( ) name := getContainerName ( count , index ) err := createContainer ( c , fingerprint , name , privileged ) if err != nil { logf ( " " , name , err ) return } } duration = processBatch ( count , batchSize , batchCreate ) return duration , nil } 
func GetContainers ( c lxd . ContainerServer ) ( [ ] api . Container , error ) { containers := [ ] api . Container { } allContainers , err := c . GetContainers ( ) if err != nil { return containers , err } for _ , container := range allContainers { if container . Config [ userConfigKey ] == " " { containers = append ( containers , container ) } } return containers , nil } 
func StartContainers ( c lxd . ContainerServer , containers [ ] api . Container , parallel int ) ( time . Duration , error ) { var duration time . Duration batchSize , err := getBatchSize ( parallel ) if err != nil { return duration , err } count := len ( containers ) logf ( " " , count ) batchStart := func ( index int , wg * sync . WaitGroup ) { defer wg . Done ( ) container := containers [ index ] if ! container . IsActive ( ) { err := startContainer ( c , container . Name ) if err != nil { logf ( " " , container . Name , err ) return } } } duration = processBatch ( count , batchSize , batchStart ) return duration , nil } 
func Params ( n int ) string { tokens := make ( [ ] string , n ) for i := 0 ; i < n ; i ++ { tokens [ i ] = " " } return fmt . Sprintf ( " " , strings . Join ( tokens , " " ) ) } 
func setQueryParam ( uri , param , value string ) ( string , error ) { fields , err := url . Parse ( uri ) if err != nil { return " " , err } values := fields . Query ( ) values . Set ( param , url . QueryEscape ( value ) ) fields . RawQuery = values . Encode ( ) return fields . String ( ) , nil } 
func ( r * ProtocolLXD ) GetImages ( ) ( [ ] api . Image , error ) { images := [ ] api . Image { } _ , err := r . queryStruct ( " " , " " , nil , " " , & images ) if err != nil { return nil , err } return images , nil } 
func ( r * ProtocolLXD ) GetImageFingerprints ( ) ( [ ] string , error ) { urls := [ ] string { } if err != nil { return nil , err } for _ , url := range urls { fields := strings . Split ( url , " " ) fingerprints = append ( fingerprints , fields [ len ( fields ) - 1 ] ) } return fingerprints , nil } 
func ( r * ProtocolLXD ) GetImage ( fingerprint string ) ( * api . Image , string , error ) { return r . GetPrivateImage ( fingerprint , " " ) } 
func ( r * ProtocolLXD ) GetImageFile ( fingerprint string , req ImageFileRequest ) ( * ImageFileResponse , error ) { return r . GetPrivateImageFile ( fingerprint , " " , req ) } 
func ( r * ProtocolLXD ) GetImageSecret ( fingerprint string ) ( string , error ) { op , err := r . CreateImageSecret ( fingerprint ) if err != nil { return " " , err } opAPI := op . Get ( ) return opAPI . Metadata [ " " ] . ( string ) , nil } 
func ( r * ProtocolLXD ) GetPrivateImage ( fingerprint string , secret string ) ( * api . Image , string , error ) { image := api . Image { } var err error path , err = r . setQueryAttributes ( path ) if err != nil { return nil , " " , err } if secret != " " { path , err = setQueryParam ( path , " " , secret ) if err != nil { return nil , " " , err } } if err != nil { return nil , " " , err } return & image , etag , nil } 
func ( r * ProtocolLXD ) GetPrivateImageFile ( fingerprint string , secret string , req ImageFileRequest ) ( * ImageFileResponse , error ) { } uri := fmt . Sprintf ( " " , url . QueryEscape ( fingerprint ) ) var err error uri , err = r . setQueryAttributes ( uri ) if err != nil { return nil , err } if err == nil { resp , err := lxdDownloadImage ( fingerprint , unixURI , r . httpUserAgent , devlxdHTTP , req ) if err == nil { return resp , nil } } } if secret != " " { uri , err = setQueryParam ( uri , " " , secret ) if err != nil { return nil , err } } return lxdDownloadImage ( fingerprint , uri , r . httpUserAgent , r . http , req ) } 
func ( r * ProtocolLXD ) GetImageAliases ( ) ( [ ] api . ImageAliasesEntry , error ) { aliases := [ ] api . ImageAliasesEntry { } if err != nil { return nil , err } return aliases , nil } 
func ( r * ProtocolLXD ) GetImageAlias ( name string ) ( * api . ImageAliasesEntry , string , error ) { alias := api . ImageAliasesEntry { } if err != nil { return nil , " " , err } return & alias , etag , nil } 
func ( r * ProtocolLXD ) CreateImage ( image api . ImagesPost , args * ImageCreateArgs ) ( Operation , error ) { if image . CompressionAlgorithm != " " { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } if err != nil { return nil , err } return op , nil } } var contentType string if args . RootfsFile == nil { contentType = " " } else { if err != nil { return nil , err } defer os . Remove ( tmpfile . Name ( ) ) if err != nil { return nil , err } _ , err = io . Copy ( fw , args . MetaFile ) if err != nil { return nil , err } if err != nil { return nil , err } _ , err = io . Copy ( fw , args . RootfsFile ) if err != nil { return nil , err } if err != nil { return nil , err } _ , err = tmpfile . Seek ( 0 , 0 ) if err != nil { return nil , err } } , } , } } else { body = tmpfile } contentType = w . FormDataContentType ( ) } if err != nil { return nil , err } req , err := http . NewRequest ( " " , reqURL , body ) if err != nil { return nil , err } if image . Public { req . Header . Set ( " " , " " ) } if image . Filename != " " { req . Header . Set ( " " , image . Filename ) } if len ( image . Properties ) > 0 { imgProps := url . Values { } for k , v := range image . Properties { imgProps . Set ( k , v ) } req . Header . Set ( " " , imgProps . Encode ( ) ) } } if err != nil { return nil , err } defer resp . Body . Close ( ) if err != nil { return nil , err } if err != nil { return nil , err } return & op , nil } 
func ( r * ProtocolLXD ) tryCopyImage ( req api . ImagesPost , urls [ ] string ) ( RemoteOperation , error ) { if len ( urls ) == 0 { return nil , fmt . Errorf ( " " ) } rop := remoteOperation { chDone : make ( chan bool ) , } go func ( ) { defer close ( rop . chPost ) if rop . err != nil { return } if err != nil { return } alias . Name = entry . Name alias . Target = fingerprint r . CreateImageAlias ( alias ) } } ( ) } errors := map [ string ] error { } for _ , serverURL := range urls { req . Source . Server = serverURL op , err := r . CreateImage ( req , nil ) if err != nil { errors [ serverURL ] = err continue } rop . targetOp = op for _ , handler := range rop . handlers { rop . targetOp . AddHandler ( handler ) } err = rop . targetOp . Wait ( ) if err != nil { errors [ serverURL ] = err continue } success = true break } if ! success { rop . err = remoteOperationError ( " " , errors ) } close ( rop . chDone ) } ( ) return & rop , nil } 
func ( r * ProtocolLXD ) CopyImage ( source ImageServer , image api . Image , args * ImageCopyArgs ) ( RemoteOperation , error ) { } if err != nil { return nil , err } if err != nil { return nil , err } req . Source . Secret = secret } req . AutoUpdate = args . AutoUpdate req . Public = args . Public if args . CopyAliases { req . Aliases = image . Aliases if args . Aliases != nil { req . Aliases = append ( req . Aliases , args . Aliases ... ) } } } return r . tryCopyImage ( req , info . Addresses ) } 
func ( r * ProtocolLXD ) UpdateImage ( fingerprint string , image api . ImagePut , ETag string ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) DeleteImage ( fingerprint string ) ( Operation , error ) { if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) RefreshImage ( fingerprint string ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) CreateImageAlias ( alias api . ImageAliasesPost ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) UpdateImageAlias ( name string , alias api . ImageAliasesEntryPut , ETag string ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) RenameImageAlias ( name string , alias api . ImageAliasesEntryPost ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) DeleteImageAlias ( name string ) error { if err != nil { return err } return nil } 
func Open ( dir string ) ( * sql . DB , error ) { path := filepath . Join ( dir , " " ) db , err := sqliteOpen ( path ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return db , nil } 
func EnsureSchema ( db * sql . DB , dir string , hook schema . Hook ) ( int , error ) { backupDone := false schema := Schema ( ) schema . File ( filepath . Join ( dir , " " ) ) schema . Hook ( func ( version int , tx * sql . Tx ) error { if ! backupDone { logger . Infof ( " \" \" " ) path := filepath . Join ( dir , " " ) err := shared . FileCopy ( path , path + " " ) if err != nil { return err } backupDone = true } if version == - 1 { logger . Debugf ( " " ) } else { logger . Debugf ( " " , version , version + 1 ) } if err != nil { } } return nil } ) return schema . Ensure ( db ) } 
func FilesystemDetect ( path string ) ( string , error ) { fs := syscall . Statfs_t { } err := syscall . Statfs ( path , & fs ) if err != nil { return " " , err } switch fs . Type { case FilesystemSuperMagicBtrfs : return " " , nil case FilesystemSuperMagicZfs : return " " , nil case FilesystemSuperMagicTmpfs : return " " , nil case FilesystemSuperMagicExt4 : return " " , nil case FilesystemSuperMagicXfs : return " " , nil case FilesystemSuperMagicNfs : return " " , nil default : logger . Debugf ( " " , fs . Type ) return string ( fs . Type ) , nil } } 
func Schema ( ) * schema . Schema { schema := schema . NewFromMap ( updates ) schema . Fresh ( freshSchema ) return schema } 
func updateFromV37 ( tx * sql . Tx ) error { count , err := query . Count ( tx , " " , " " ) if err != nil { return errors . Wrap ( err , " " ) } if count == 0 { } INSERT INTO config (key, value) SELECT 'cluster.https_address', value FROM config WHERE key = 'core.https_address' ` ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func ArchitectureGetLocal ( ) ( string , error ) { uname , err := shared . Uname ( ) if err != nil { return ArchitectureDefault , err } return uname . Machine , nil } 
func NewController ( url string , key string , machine string ) ( * Controller , error ) { baseURL := fmt . Sprintf ( " " , url ) if err != nil { } return nil , fmt . Errorf ( " " , baseURL , strings . Split ( strings . Split ( err . Error ( ) , " " ) [ 1 ] , " " ) [ 0 ] ) } srvRaw , err := gomaasapi . NewAuthenticatedClient ( baseURL , key ) if err != nil { return nil , err } if err != nil { return nil , err } if len ( machines ) != 1 { return nil , fmt . Errorf ( " " , machine ) } c . srv = srv c . srvRaw = * srvRaw c . machine = machines [ 0 ] c . url = baseURL return & c , err } 
func ( c * Controller ) CreateContainer ( name string , interfaces [ ] ContainerInterface ) error { if err != nil { return err } if err != nil { return err } if err != nil { return err } defer func ( ) { if success == true { return } c . DeleteContainer ( name ) } ( ) if err != nil { return err } } if err != nil { return err } if ! ok { return fmt . Errorf ( " " , entry . MACAddress ( ) ) } if err != nil { return err } } } success = true return nil } 
func ( c * Controller ) DefinedContainer ( name string ) ( bool , error ) { devs , err := c . machine . Devices ( gomaasapi . DevicesArgs { Hostname : [ ] string { name } } ) if err != nil { return false , err } if len ( devs ) == 1 { return true , nil } return false , nil } 
func ( c * Controller ) UpdateContainer ( name string , interfaces [ ] ContainerInterface ) error { if err != nil { return err } if err != nil { return err } device , err := c . getDevice ( name ) if err != nil { return err } for _ , entry := range device . InterfaceSet ( ) { if ! ok { if err != nil { return err } continue } for _ , link := range entry . Links ( ) { for _ , subnet := range iface . Subnets { if subnet . Name == link . Subnet ( ) . Name ( ) { if subnet . Address == " " || subnet . Address == link . IPAddress ( ) { found = true } break } } if err != nil { return err } continue } } if ok { continue } if err != nil { return err } } } if ok { } if err != nil { return err } if err != nil { return err } } } return nil } 
func ( c * Controller ) RenameContainer ( name string , newName string ) error { device , err := c . getDevice ( name ) if err != nil { return err } if err != nil { return err } values := url . Values { } values . Set ( " " , newName ) _ , err = c . srvRaw . Put ( uri , values ) if err != nil { return err } return nil } 
func ( c * Controller ) DeleteContainer ( name string ) error { device , err := c . getDevice ( name ) if err != nil { return err } err = device . Delete ( ) if err != nil { return err } return nil } 
func NewFromMap ( versionsToUpdates map [ int ] Update ) * Schema { for version := range versionsToUpdates { versions = append ( versions , version ) } for i , version := range versions { } updates = append ( updates , versionsToUpdates [ version ] ) } return & Schema { updates : updates , } } 
func ( s * Schema ) Add ( update Update ) { s . updates = append ( s . updates , update ) } 
func ( s * Schema ) Ensure ( db * sql . DB ) ( int , error ) { var current int aborted := false err := query . Transaction ( db , func ( tx * sql . Tx ) error { err := execFromFile ( tx , s . path , s . hook ) if err != nil { return errors . Wrapf ( err , " " , s . path ) } err = ensureSchemaTableExists ( tx ) if err != nil { return err } current , err = queryCurrentVersion ( tx ) if err != nil { return err } if s . check != nil { err := s . check ( current , tx ) if err == ErrGracefulAbort { return nil } if err != nil { return err } } if err != nil { return fmt . Errorf ( " " , err ) } } else { err = ensureUpdatesAreApplied ( tx , current , s . updates , s . hook ) if err != nil { return err } } return nil } ) if err != nil { return - 1 , err } if aborted { return current , ErrGracefulAbort } return current , nil } 
func ( s * Schema ) Dump ( db * sql . DB ) ( string , error ) { var statements [ ] string err := query . Transaction ( db , func ( tx * sql . Tx ) error { err := checkAllUpdatesAreApplied ( tx , s . updates ) if err != nil { return err } statements , err = selectTablesSQL ( tx ) return err } ) if err != nil { return " " , err } for i , statement := range statements { statements [ i ] = formatSQL ( statement ) } INSERT INTO schema (version, updated_at) VALUES (%d, strftime("%%s")) ` , len ( s . updates ) ) ) return strings . Join ( statements , " \n " ) , nil } 
func ( s * Schema ) Trim ( version int ) [ ] Update { trimmed := s . updates [ version : ] s . updates = s . updates [ : version ] s . fresh = " " return trimmed } 
func ( s * Schema ) ExerciseUpdate ( version int , hook func ( * sql . DB ) ) ( * sql . DB , error ) { if err != nil { return nil , fmt . Errorf ( " " , err ) } _ , err = s . Ensure ( db ) if err != nil { return nil , fmt . Errorf ( " " , err ) } } _ , err = s . Ensure ( db ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return db , nil } 
func ensureSchemaTableExists ( tx * sql . Tx ) error { exists , err := DoesSchemaTableExist ( tx ) if err != nil { return fmt . Errorf ( " " , err ) } if ! exists { err := createSchemaTable ( tx ) if err != nil { return fmt . Errorf ( " " , err ) } } return nil } 
func queryCurrentVersion ( tx * sql . Tx ) ( int , error ) { versions , err := selectSchemaVersions ( tx ) if err != nil { return - 1 , fmt . Errorf ( " " , err ) } if hasVersion ( 30 ) && hasVersion ( 32 ) && ! hasVersion ( 31 ) { err = insertSchemaVersion ( tx , 31 ) if err != nil { return - 1 , fmt . Errorf ( " " ) } versions , err = selectSchemaVersions ( tx ) if err != nil { return - 1 , fmt . Errorf ( " " , err ) } } if err != nil { return - 1 , fmt . Errorf ( " " , err ) } if count == 1 { if err != nil { return - 1 , fmt . Errorf ( " " ) } versions = append ( versions , 38 ) } } current := 0 if len ( versions ) > 0 { err = checkSchemaVersionsHaveNoHoles ( versions ) if err != nil { return - 1 , err } current = versions [ len ( versions ) - 1 ] } return current , nil } 
func ensureUpdatesAreApplied ( tx * sql . Tx , current int , updates [ ] Update , hook Hook ) error { if current > len ( updates ) { return fmt . Errorf ( " " , current , len ( updates ) ) } } if err != nil { return fmt . Errorf ( " " , current , err ) } } err := update ( tx ) if err != nil { return fmt . Errorf ( " " , current , err ) } current ++ err = insertSchemaVersion ( tx , current ) if err != nil { return fmt . Errorf ( " " , current ) } } return nil } 
func checkSchemaVersionsHaveNoHoles ( versions [ ] int ) error { } } return nil } 
func checkAllUpdatesAreApplied ( tx * sql . Tx , updates [ ] Update ) error { versions , err := selectSchemaVersions ( tx ) if err != nil { return fmt . Errorf ( " " , err ) } if len ( versions ) == 0 { return fmt . Errorf ( " " ) } err = checkSchemaVersionsHaveNoHoles ( versions ) if err != nil { return err } current := versions [ len ( versions ) - 1 ] if current != len ( updates ) { return fmt . Errorf ( " " , current , len ( updates ) ) } return nil } 
func formatSQL ( statement string ) string { lines := strings . Split ( statement , " \n " ) for i , line := range lines { if strings . Contains ( line , " " ) { } lines [ i ] = strings . Replace ( line , " " , " \n " , - 1 ) } return strings . Join ( lines , " \n " ) } 
func GetPathMode ( path string ) ( os . FileMode , error ) { s , err := os . Open ( path ) if err != nil { return os . FileMode ( 0000 ) , err } defer s . Close ( ) fi , err := s . Stat ( ) if err != nil { return os . FileMode ( 0000 ) , err } mode , _ , _ := GetOwnerMode ( fi ) return mode , nil } 
func llistxattr ( path string , list [ ] byte ) ( sz int , err error ) { var _p0 * byte _p0 , err = syscall . BytePtrFromString ( path ) if err != nil { return } var _p1 unsafe . Pointer if len ( list ) > 0 { _p1 = unsafe . Pointer ( & list [ 0 ] ) } else { _p1 = unsafe . Pointer ( nil ) } r0 , _ , e1 := syscall . Syscall ( syscall . SYS_LLISTXATTR , uintptr ( unsafe . Pointer ( _p0 ) ) , uintptr ( _p1 ) , uintptr ( len ( list ) ) ) sz = int ( r0 ) if e1 != 0 { err = e1 } return } 
func GetAllXattr ( path string ) ( xattrs map [ string ] string , err error ) { e1 := fmt . Errorf ( " " ) if err != nil || pre < 0 { return nil , err } if pre == 0 { return nil , nil } dest := make ( [ ] byte , pre ) post , err := llistxattr ( path , dest ) if err != nil || post < 0 { return nil , err } if post != pre { return nil , e1 } split := strings . Split ( string ( dest ) , " \x00 " ) if split == nil { return nil , fmt . Errorf ( " " ) } } xattrs = make ( map [ string ] string , len ( split ) ) for _ , x := range split { xattr := string ( x ) if err != nil || pre < 0 { return nil , err } dest = make ( [ ] byte , pre ) post := 0 if pre > 0 { post , err = syscall . Getxattr ( path , xattr , dest ) if err != nil || post < 0 { return nil , err } } if post != pre { return nil , e1 } xattrs [ xattr ] = string ( dest ) } return xattrs , nil } 
func GetErrno ( err error ) ( errno error , iserrno bool ) { sysErr , ok := err . ( * os . SyscallError ) if ok { return sysErr . Err , true } pathErr , ok := err . ( * os . PathError ) if ok { return pathErr . Err , true } tmpErrno , ok := err . ( syscall . Errno ) if ok { return tmpErrno , true } return nil , false } 
func Uname ( ) ( * Utsname , error ) { uname := syscall . Utsname { } err := syscall . Uname ( & uname ) if err != nil { return nil , err } return & Utsname { Sysname : intArrayToString ( uname . Sysname ) , Nodename : intArrayToString ( uname . Nodename ) , Release : intArrayToString ( uname . Release ) , Version : intArrayToString ( uname . Version ) , Machine : intArrayToString ( uname . Machine ) , Domainname : intArrayToString ( uname . Domainname ) , } , nil } 
func ( s * storageCeph ) doCrossPoolContainerCopy ( target container , source container , containerOnly bool , refresh bool , refreshSnapshots [ ] container ) error { sourcePool , err := source . StoragePool ( ) if err != nil { return err } if err != nil { return err } ourMount , err := srcStorage . StoragePoolMount ( ) if err != nil { return err } if ourMount { defer srcStorage . StoragePoolUmount ( ) } targetPool , err := target . StoragePool ( ) if err != nil { return err } var snapshots [ ] container if refresh { snapshots = refreshSnapshots } else { snapshots , err = source . Snapshots ( ) if err != nil { return err } if err != nil { return err } } if err != nil { return err } destContainerMntPoint := getContainerMountPoint ( target . Project ( ) , targetPool , target . Name ( ) ) bwlimit := s . pool . Config [ " " ] _ , err = rsyncLocalCopy ( srcSnapshotMntPoint , destContainerMntPoint , bwlimit ) if err != nil { return err } msg , fsFreezeErr := shared . TryRunCommand ( " " , " " , destContainerMntPoint ) logger . Debugf ( " " , msg , fsFreezeErr ) err = s . doContainerSnapshotCreate ( target . Project ( ) , fmt . Sprintf ( " " , target . Name ( ) , snapOnlyName ) , target . Name ( ) ) if fsFreezeErr == nil { msg , fsFreezeErr := shared . TryRunCommand ( " " , " " , destContainerMntPoint ) logger . Debugf ( " " , msg , fsFreezeErr ) } if err != nil { return err } } } srcContainerMntPoint := getContainerMountPoint ( source . Project ( ) , sourcePool , source . Name ( ) ) _ , err = rsyncLocalCopy ( srcContainerMntPoint , destContainerMntPoint , bwlimit ) if err != nil { if ! refresh { s . StoragePoolVolumeDelete ( ) } logger . Errorf ( " \" \" \" \" " , s . volume . Name , s . pool . Name , err ) return err } return nil } 
func ( s * storageCeph ) ContainerBackupLoad ( info backupInfo , data io . ReadSeeker , tarArgs [ ] string ) error { if err != nil { return err } if err != nil { return err } containerMntPoint := getContainerMountPoint ( info . Project , s . pool . Name , info . Name ) err = shared . RunCommandWithFds ( data , nil , " " , args ... ) if err != nil { logger . Errorf ( " \" \" \" \" " , cur , containerMntPoint , err ) return err } msg , fsFreezeErr := shared . TryRunCommand ( " " , " " , containerMntPoint ) logger . Debugf ( " " , msg , fsFreezeErr ) if fsFreezeErr == nil { msg , fsFreezeErr := shared . TryRunCommand ( " " , " " , containerMntPoint ) logger . Debugf ( " " , msg , fsFreezeErr ) } if err != nil { return err } } err = shared . RunCommandWithFds ( data , nil , " " , args ... ) if err != nil { logger . Errorf ( " \" \" \" \" " , containerMntPoint , err ) return err } return nil } 
func RegisterStmt ( sql string ) int { code := len ( stmts ) stmts [ code ] = sql return code } 
func PrepareStmts ( db * sql . DB ) ( map [ int ] * sql . Stmt , error ) { index := map [ int ] * sql . Stmt { } for code , sql := range stmts { stmt , err := db . Prepare ( sql ) if err != nil { return nil , errors . Wrapf ( err , " " , sql ) } index [ code ] = stmt } return index , nil } 
func NewGateway ( db * db . Node , cert * shared . CertInfo , options ... Option ) ( * Gateway , error ) { ctx , cancel := context . WithCancel ( context . Background ( ) ) o := newOptions ( ) for _ , option := range options { option ( o ) } gateway := & Gateway { db : db , cert : cert , options : o , ctx : ctx , cancel : cancel , upgradeCh : make ( chan struct { } , 16 ) , acceptCh : make ( chan net . Conn ) , store : & dqliteServerStore { } , } err := gateway . init ( ) if err != nil { return nil , err } return gateway , nil } 
func ( g * Gateway ) HandlerFuncs ( ) map [ string ] http . HandlerFunc { database := func ( w http . ResponseWriter , r * http . Request ) { if ! tlsCheckCert ( r , g . cert ) { http . Error ( w , " " , http . StatusForbidden ) return } err := shared . ReadToJSON ( r . Body , & nodes ) if err != nil { http . Error ( w , " " , http . StatusBadRequest ) return } logger . Debugf ( " " , nodes ) err = g . db . Transaction ( func ( tx * db . NodeTx ) error { return tx . RaftNodesReplace ( nodes ) } ) if err != nil { http . Error ( w , " " , http . StatusInternalServerError ) return } return } return } return } return } return } if err != nil { http . Error ( w , " " , http . StatusInternalServerError ) return } util . WriteJSON ( w , map [ string ] string { " " : leader } , false ) return } if r . Header . Get ( " " ) != " " { http . Error ( w , " " , http . StatusBadRequest ) return } hijacker , ok := w . ( http . Hijacker ) if ! ok { http . Error ( w , " " , http . StatusInternalServerError ) return } conn , _ , err := hijacker . Hijack ( ) if err != nil { message := errors . Wrap ( err , " " ) . Error ( ) http . Error ( w , message , http . StatusInternalServerError ) return } if n , err := conn . Write ( data ) ; err != nil || n != len ( data ) { conn . Close ( ) return } g . acceptCh <- conn } raft := func ( w http . ResponseWriter , r * http . Request ) { err := g . db . Transaction ( func ( tx * db . NodeTx ) error { nodes , err := tx . RaftNodes ( ) if err != nil { return err } address = nodes [ 0 ] . Address return nil } ) if err != nil { http . Error ( w , " " , http . StatusInternalServerError ) return } url := & url . URL { Scheme : " " , Path : r . URL . Path , RawQuery : r . URL . RawQuery , Host : address , } http . Redirect ( w , r , url . String ( ) , http . StatusPermanentRedirect ) return } return } g . raft . HandlerFunc ( ) ( w , r ) } return map [ string ] http . HandlerFunc { databaseEndpoint : database , raftEndpoint : raft , } } 
func ( g * Gateway ) DialFunc ( ) dqlite . DialFunc { return func ( ctx context . Context , address string ) ( net . Conn , error ) { } return dqliteNetworkDial ( ctx , address , g . cert ) } } 
func ( g * Gateway ) Shutdown ( ) error { logger . Debugf ( " " ) if g . raft != nil { err := g . raft . Shutdown ( ) if err != nil { return errors . Wrap ( err , " " ) } } if g . server != nil { g . Sync ( ) g . server . Close ( ) } return nil } 
func ( g * Gateway ) Sync ( ) { if g . server == nil { return } dir := filepath . Join ( g . db . Dir ( ) , " " ) err := g . server . Dump ( " " , dir ) if err != nil { } } 
func ( g * Gateway ) Reset ( cert * shared . CertInfo ) error { err := g . Shutdown ( ) if err != nil { return err } err = os . RemoveAll ( filepath . Join ( g . db . Dir ( ) , " " ) ) if err != nil { return err } err = g . db . Transaction ( func ( tx * db . NodeTx ) error { return tx . RaftNodesReplace ( nil ) } ) if err != nil { return err } g . cert = cert return g . init ( ) } 
func ( g * Gateway ) LeaderAddress ( ) ( string , error ) { } ctx , cancel := context . WithTimeout ( g . ctx , 5 * time . Second ) defer cancel ( ) if address != " " { return address , nil } time . Sleep ( time . Second ) } return " " , ctx . Err ( ) } if err != nil { return " " , err } addresses := [ ] string { } err = g . db . Transaction ( func ( tx * db . NodeTx ) error { nodes , err := tx . RaftNodes ( ) if err != nil { return err } for _ , node := range nodes { addresses = append ( addresses , node . Address ) } return nil } ) if err != nil { return " " , errors . Wrap ( err , " " ) } if len ( addresses ) == 0 { } for _ , address := range addresses { url := fmt . Sprintf ( " " , address , databaseEndpoint ) request , err := http . NewRequest ( " " , url , nil ) if err != nil { return " " , err } request = request . WithContext ( ctx ) client := & http . Client { Transport : & http . Transport { TLSClientConfig : config } } response , err := client . Do ( request ) if err != nil { logger . Debugf ( " " , address ) continue } if response . StatusCode != http . StatusOK { logger . Debugf ( " " , address ) continue } info := map [ string ] string { } err = shared . ReadToJSON ( response . Body , & info ) if err != nil { logger . Debugf ( " " , address ) continue } leader := info [ " " ] if leader == " " { logger . Debugf ( " " , address ) continue } return leader , nil } return " " , fmt . Errorf ( " " ) } 
func ( g * Gateway ) init ( ) error { logger . Debugf ( " " ) raft , err := newRaft ( g . db , g . cert , g . options . latency ) if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } if raft . HandlerFunc ( ) == nil { g . memoryDial = dqliteMemoryDial ( listener ) g . store . inMemory = dqlite . NewInmemServerStore ( ) g . store . Set ( context . Background ( ) , [ ] dqlite . ServerInfo { { Address : " " } } ) } else { go runDqliteProxy ( listener , g . acceptCh ) g . store . inMemory = nil } provider := & raftAddressProvider { db : g . db } server , err := dqlite . NewServer ( raft . Raft ( ) , raft . Registry ( ) , listener , dqlite . WithServerAddressProvider ( provider ) , dqlite . WithServerLogFunc ( DqliteLog ) , ) if err != nil { return errors . Wrap ( err , " " ) } g . server = server g . raft = raft } else { g . server = nil g . raft = nil g . store . inMemory = nil } g . store . onDisk = dqlite . NewServerStore ( g . db . DB ( ) , " " , " " , " " ) return nil } 
func ( g * Gateway ) waitLeadership ( ) error { n := 80 sleep := 250 * time . Millisecond for i := 0 ; i < n ; i ++ { if g . raft . raft . State ( ) == raft . Leader { return nil } time . Sleep ( sleep ) } return fmt . Errorf ( " " , time . Duration ( n ) * sleep ) } 
func ( g * Gateway ) currentRaftNodes ( ) ( [ ] db . RaftNode , error ) { if g . raft == nil { return nil , raft . ErrNotLeader } servers , err := g . raft . Servers ( ) if err != nil { return nil , err } provider := raftAddressProvider { db : g . db } nodes := make ( [ ] db . RaftNode , len ( servers ) ) for i , server := range servers { address , err := provider . ServerAddr ( server . ID ) if err != nil { if err != db . ErrNoSuchObject { return nil , errors . Wrap ( err , " " ) } } id , err := strconv . Atoi ( string ( server . ID ) ) if err != nil { return nil , errors . Wrap ( err , " " ) } nodes [ i ] . ID = int64 ( id ) nodes [ i ] . Address = string ( address ) } return nodes , nil } 
func ( g * Gateway ) cachedRaftNodes ( ) ( [ ] string , error ) { var addresses [ ] string err := g . db . Transaction ( func ( tx * db . NodeTx ) error { var err error addresses , err = tx . RaftNodeAddresses ( ) return err } ) if err != nil { return nil , errors . Wrap ( err , " " ) } return addresses , nil } 
func dqliteMemoryDial ( listener net . Listener ) dqlite . DialFunc { return func ( ctx context . Context , address string ) ( net . Conn , error ) { return net . Dial ( " " , listener . Addr ( ) . String ( ) ) } } 
func DqliteLog ( l dqlite . LogLevel , format string , a ... interface { } ) { format = fmt . Sprintf ( " " , format ) switch l { case dqlite . LogDebug : logger . Debugf ( format , a ... ) case dqlite . LogInfo : logger . Debugf ( format , a ... ) case dqlite . LogWarn : logger . Warnf ( format , a ... ) case dqlite . LogError : logger . Errorf ( format , a ... ) } } 
func ( r * Response ) MetadataAsMap ( ) ( map [ string ] interface { } , error ) { ret := map [ string ] interface { } { } err := r . MetadataAsStruct ( & ret ) if err != nil { return nil , err } return ret , nil } 
func ( r * Response ) MetadataAsOperation ( ) ( * Operation , error ) { op := Operation { } err := r . MetadataAsStruct ( & op ) if err != nil { return nil , err } return & op , nil } 
func ( r * Response ) MetadataAsStringSlice ( ) ( [ ] string , error ) { sl := [ ] string { } err := r . MetadataAsStruct ( & sl ) if err != nil { return nil , err } return sl , nil } 
func ( r * Response ) MetadataAsStruct ( target interface { } ) error { return json . Unmarshal ( r . Metadata , & target ) } 
func ( r * CSVReport ) Load ( ) error { file , err := os . Open ( r . Filename ) if err != nil { return err } defer file . Close ( ) reader := csv . NewReader ( file ) for line := 1 ; err != io . EOF ; line ++ { record , err := reader . Read ( ) if err == io . EOF { break } else if err != nil { return err } err = r . addRecord ( record ) if err != nil { return err } } logf ( " " , r . Filename ) return nil } 
func ( r * CSVReport ) Write ( ) error { file , err := os . OpenFile ( r . Filename , os . O_WRONLY | os . O_CREATE | os . O_TRUNC , 0640 ) if err != nil { return err } defer file . Close ( ) writer := csv . NewWriter ( file ) err = writer . WriteAll ( r . records ) if err != nil { return err } logf ( " " , r . Filename ) return nil } 
func ( r * CSVReport ) AddRecord ( label string , elapsed time . Duration ) error { if len ( r . records ) == 0 { r . addRecord ( csvFields ) } record := [ ] string { fmt . Sprintf ( " " , time . Now ( ) . UnixNano ( ) / int64 ( time . Millisecond ) ) , return r . addRecord ( record ) } 
func LoadConfig ( path string ) ( * Config , error ) { if err != nil { return nil , fmt . Errorf ( " " , err ) } err = yaml . Unmarshal ( content , & c ) if err != nil { return nil , fmt . Errorf ( " " , err ) } for k , r := range c . Remotes { if ! r . Public && r . AuthType == " " { r . AuthType = " " c . Remotes [ k ] = r } } } } c . Remotes [ k ] = v } if ok && images . Protocol != ImagesRemote . Protocol && images . Addr == ImagesRemote . Addr { c . Remotes [ " " ] = ImagesRemote c . SaveConfig ( path ) } return c , nil } 
func ( c * Config ) SaveConfig ( path string ) error { err := shared . DeepCopy ( c , & conf ) if err != nil { return fmt . Errorf ( " " , err ) } } delete ( conf . Remotes , k ) } if err != nil { return fmt . Errorf ( " " , err ) } defer f . Close ( ) if err != nil { return fmt . Errorf ( " " , err ) } _ , err = f . Write ( data ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( l ChrootLoader ) Abs ( base string , name string ) string { return filepath . Clean ( fmt . Sprintf ( " " , l . Path , name ) ) } 
func ( l ChrootLoader ) Get ( path string ) ( io . Reader , error ) { if err != nil { return nil , err } basePath , err := filepath . EvalSymlinks ( l . Path ) if err != nil { return nil , err } } if err != nil { return nil , err } return bytes . NewReader ( buf ) , nil } 
func ( c * Config ) ConfigPath ( paths ... string ) string { path := [ ] string { c . ConfigDir } path = append ( path , paths ... ) return filepath . Join ( path ... ) } 
func ( c * Config ) ServerCertPath ( remote string ) string { return c . ConfigPath ( " " , fmt . Sprintf ( " " , remote ) ) } 
func NewConfig ( configDir string , defaults bool ) * Config { config := & Config { ConfigDir : configDir } if defaults { config . Remotes = DefaultRemotes config . DefaultRemote = " " } return config } 
func DetermineRaftNode ( tx * db . NodeTx ) ( * db . RaftNode , error ) { config , err := ConfigLoad ( tx ) if err != nil { return nil , err } address := config . ClusterAddress ( ) } nodes , err := tx . RaftNodes ( ) if err != nil { return nil , err } } } } return nil , nil } 
func ( s * migrationSourceWs ) checkForPreDumpSupport ( ) ( bool , int ) { err := s . container . Migrate ( & criuMigrationArgs ) if err != nil { } if tmp != " " { use_pre_dumps = shared . IsTrue ( tmp ) } var max_iterations int if tmp != " " { max_iterations , _ = strconv . Atoi ( tmp ) } else { } if max_iterations > 999 { } logger . Debugf ( " " , max_iterations ) return use_pre_dumps , max_iterations } 
func readCriuStatsDump ( path string ) ( uint64 , uint64 , error ) { statsDump := shared . AddSlash ( path ) + " " in , err := ioutil . ReadFile ( statsDump ) if err != nil { logger . Errorf ( " " , err . Error ( ) ) return 0 , 0 , err } logger . Errorf ( msg ) return 0 , 0 , fmt . Errorf ( msg ) } logger . Errorf ( msg ) return 0 , 0 , fmt . Errorf ( msg ) } statsEntry := & migration . StatsEntry { } if err = proto . Unmarshal ( in [ 12 : 12 + size ] , statsEntry ) ; err != nil { logger . Errorf ( " " , err . Error ( ) ) return 0 , 0 , err } written := statsEntry . GetDump ( ) . GetPagesWritten ( ) skipped := statsEntry . GetDump ( ) . GetPagesSkippedParent ( ) return written , skipped , nil } 
func ( s * migrationSourceWs ) preDumpLoop ( args * preDumpLoopArgs ) ( bool , error ) { logger . Debugf ( " " , args . preDumpDir ) final := args . final err := s . container . Migrate ( & criuMigrationArgs ) if err != nil { return final , err } state := s . container . DaemonState ( ) err = RsyncSend ( ctName , shared . AddSlash ( args . checkpointDir ) , s . criuConn , nil , args . rsyncFeatures , args . bwlimit , state . OS . ExecPath ) if err != nil { return final , err } dumpPath += shared . AddSlash ( args . dumpDir ) written , skipped_parent , err := readCriuStatsDump ( dumpPath ) if err != nil { return final , err } logger . Debugf ( " " , written ) logger . Debugf ( " " , skipped_parent ) total_pages := written + skipped_parent percentage_skipped := int ( 100 - ( ( 100 * written ) / total_pages ) ) logger . Debugf ( " " , percentage_skipped ) tmp := s . container . ExpandedConfig ( ) [ " " ] if tmp != " " { threshold , _ = strconv . Atoi ( tmp ) } else { } if percentage_skipped > threshold { logger . Debugf ( " " , percentage_skipped , threshold ) logger . Debugf ( " " ) final = true } sync := migration . MigrationSync { FinalPreDump : proto . Bool ( final ) , } data , err := proto . Marshal ( & sync ) if err != nil { return final , err } err = s . criuConn . WriteMessage ( websocket . BinaryMessage , data ) if err != nil { s . sendControl ( err ) return final , err } logger . Debugf ( " " ) return final , nil } 
func ( r * ProtocolSimpleStreams ) GetConnectionInfo ( ) ( * ConnectionInfo , error ) { info := ConnectionInfo { } info . Addresses = [ ] string { r . httpHost } info . Certificate = r . httpCertificate info . Protocol = " " info . URL = r . httpHost return & info , nil } 
func newRoot ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , Long : `This is the entry point for all "go:generate" directives used in LXD's source code.` , RunE : func ( cmd * cobra . Command , args [ ] string ) error { return fmt . Errorf ( " " ) } , } cmd . AddCommand ( newDb ( ) ) return cmd } 
func APIExtensionsCount ( ) int { count := len ( APIExtensions ) if artificialBump != " " { n , err := strconv . Atoi ( artificialBump ) if err == nil { count += n } } return count } 
func DotGo ( updates map [ int ] Update , name string ) error { if err != nil { return fmt . Errorf ( " " , err ) } schema := NewFromMap ( updates ) _ , err = schema . Ensure ( db ) if err != nil { return err } dump , err := schema . Dump ( db ) if err != nil { return err } file , err := os . Create ( path . Join ( path . Dir ( filename ) , name + " " ) ) if err != nil { return fmt . Errorf ( " " , err ) } pkg := path . Base ( path . Dir ( filename ) ) _ , err = file . Write ( [ ] byte ( fmt . Sprintf ( dotGoTemplate , pkg , dump ) ) ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func SelectURIs ( stmt * sql . Stmt , f func ( a ... interface { } ) string , args ... interface { } ) ( [ ] string , error ) { rows , err := stmt . Query ( args ... ) if err != nil { return nil , errors . Wrapf ( err , " " ) } defer rows . Close ( ) columns , err := rows . Columns ( ) if err != nil { return nil , errors . Wrap ( err , " " ) } params := make ( [ ] interface { } , len ( columns ) ) dest := make ( [ ] interface { } , len ( params ) ) for i := range params { params [ i ] = " " dest [ i ] = & params [ i ] } uris := [ ] string { } for rows . Next ( ) { err := rows . Scan ( dest ... ) if err != nil { return nil , errors . Wrapf ( err , " " ) } uri := f ( params ... ) uris = append ( uris , uri ) } err = rows . Err ( ) if err != nil { return nil , errors . Wrapf ( err , " " ) } return uris , nil } 
func SelectStrings ( tx * sql . Tx , query string , args ... interface { } ) ( [ ] string , error ) { values := [ ] string { } scan := func ( rows * sql . Rows ) error { var value string err := rows . Scan ( & value ) if err != nil { return err } values = append ( values , value ) return nil } err := scanSingleColumn ( tx , query , args , " " , scan ) if err != nil { return nil , err } return values , nil } 
func InsertStrings ( tx * sql . Tx , stmt string , values [ ] string ) error { n := len ( values ) if n == 0 { return nil } params := make ( [ ] string , n ) args := make ( [ ] interface { } , n ) for i , value := range values { params [ i ] = " " args [ i ] = value } stmt = fmt . Sprintf ( stmt , strings . Join ( params , " " ) ) _ , err := tx . Exec ( stmt , args ... ) return err } 
func scanSingleColumn ( tx * sql . Tx , query string , args [ ] interface { } , typeName string , scan scanFunc ) error { rows , err := tx . Query ( query , args ... ) if err != nil { return err } defer rows . Close ( ) for rows . Next ( ) { err := scan ( rows ) if err != nil { return err } } err = rows . Err ( ) if err != nil { return err } return nil } 
func CallerStackHandler ( format string , h Handler ) Handler { return FuncHandler ( func ( r * Record ) error { s := stack . Callers ( ) . TrimBelow ( stack . Call ( r . CallPC [ 0 ] ) ) . TrimRuntime ( ) if len ( s ) > 0 { buf := & bytes . Buffer { } buf . WriteByte ( '[' ) for i , pc := range s { if i > 0 { buf . WriteByte ( ' ' ) } fmt . Fprintf ( buf , format , pc ) } buf . WriteByte ( ']' ) r . Ctx = append ( r . Ctx , " " , buf . String ( ) ) } return h . Log ( r ) } ) } 
func LazyHandler ( h Handler ) Handler { return FuncHandler ( func ( r * Record ) error { for i := 1 ; i < len ( r . Ctx ) ; i += 2 { lz , ok := r . Ctx [ i ] . ( Lazy ) if ok { v , err := evaluateLazy ( lz ) if err != nil { hadErr = true r . Ctx [ i ] = err } else { if cs , ok := v . ( stack . Trace ) ; ok { v = cs . TrimBelow ( stack . Call ( r . CallPC [ 0 ] ) ) . TrimRuntime ( ) } r . Ctx [ i ] = v } } } if hadErr { r . Ctx = append ( r . Ctx , errorKey , " " ) } return h . Log ( r ) } ) } 
func ( pc Call ) Format ( s fmt . State , c rune ) { fn := runtime . FuncForPC ( pcFix ) if fn == nil { fmt . Fprintf ( s , " " , c ) return } switch c { case 's' , 'v' : file , line := fn . FileLine ( pcFix ) switch { case s . Flag ( '#' ) : impCnt := strings . Count ( fn . Name ( ) , sep ) + 1 pathCnt := strings . Count ( file , sep ) for pathCnt > impCnt { i := strings . Index ( file , sep ) if i == - 1 { break } file = file [ i + len ( sep ) : ] pathCnt -- } default : const sep = " " if i := strings . LastIndex ( file , sep ) ; i != - 1 { file = file [ i + len ( sep ) : ] } } fmt . Fprint ( s , file ) if c == 'v' { fmt . Fprint ( s , " " , line ) } case 'd' : _ , line := fn . FileLine ( pcFix ) fmt . Fprint ( s , line ) case 'n' : name := fn . Name ( ) if ! s . Flag ( '+' ) { const pathSep = " " if i := strings . LastIndex ( name , pathSep ) ; i != - 1 { name = name [ i + len ( pathSep ) : ] } const pkgSep = " " if i := strings . Index ( name , pkgSep ) ; i != - 1 { name = name [ i + len ( pkgSep ) : ] } } fmt . Fprint ( s , name ) } } 
func Callers ( ) Trace { pcs := poolBuf ( ) pcs = pcs [ : cap ( pcs ) ] n := runtime . Callers ( 2 , pcs ) cs := make ( [ ] Call , n ) for i , pc := range pcs [ : n ] { cs [ i ] = Call ( pc ) } putPoolBuf ( pcs ) return cs } 
func ( pc Call ) name ( ) string { pcFix := uintptr ( pc ) - 1 fn := runtime . FuncForPC ( pcFix ) if fn == nil { return " " } return fn . Name ( ) } 
func ( pcs Trace ) Format ( s fmt . State , c rune ) { s . Write ( [ ] byte ( " " ) ) for i , pc := range pcs { if i > 0 { s . Write ( [ ] byte ( " " ) ) } pc . Format ( s , c ) } s . Write ( [ ] byte ( " " ) ) } 
func ( pcs Trace ) TrimBelow ( pc Call ) Trace { for len ( pcs ) > 0 && pcs [ 0 ] != pc { pcs = pcs [ 1 : ] } return pcs } 
func ( pcs Trace ) TrimAbove ( pc Call ) Trace { for len ( pcs ) > 0 && pcs [ len ( pcs ) - 1 ] != pc { pcs = pcs [ : len ( pcs ) - 1 ] } return pcs } 
func ( pcs Trace ) TrimBelowName ( name string ) Trace { for len ( pcs ) > 0 && pcs [ 0 ] . name ( ) != name { pcs = pcs [ 1 : ] } return pcs } 
func ( pcs Trace ) TrimAboveName ( name string ) Trace { for len ( pcs ) > 0 && pcs [ len ( pcs ) - 1 ] . name ( ) != name { pcs = pcs [ : len ( pcs ) - 1 ] } return pcs } 
func ( pcs Trace ) TrimRuntime ( ) Trace { for len ( pcs ) > 0 && inGoroot ( pcs [ len ( pcs ) - 1 ] . file ( ) ) { pcs = pcs [ : len ( pcs ) - 1 ] } return pcs } 
func ShiftOwner ( basepath string , path string , uid int , gid int ) error { cbasepath := C . CString ( basepath ) defer C . free ( unsafe . Pointer ( cbasepath ) ) cpath := C . CString ( path ) defer C . free ( unsafe . Pointer ( cpath ) ) r := C . shiftowner ( cbasepath , cpath , C . int ( uid ) , C . int ( gid ) ) if r != 0 { return fmt . Errorf ( " " , path ) } return nil } 
func GetCaps ( path string ) ( [ ] byte , error ) { xattrs , err := shared . GetAllXattr ( path ) if err != nil { return nil , err } valueStr , ok := xattrs [ " " ] if ! ok { return nil , nil } return [ ] byte ( valueStr ) , nil } 
func SetCaps ( path string , caps [ ] byte , uid int64 ) error { cpath := C . CString ( path ) defer C . free ( unsafe . Pointer ( cpath ) ) ccaps := C . CString ( string ( caps ) ) defer C . free ( unsafe . Pointer ( ccaps ) ) r := C . set_vfs_ns_caps ( cpath , ccaps , C . ssize_t ( len ( caps ) ) , C . uint32_t ( uid ) ) if r != 0 { return fmt . Errorf ( " " , path ) } return nil } 
func ShiftACL ( path string , shiftIds func ( uid int64 , gid int64 ) ( int64 , int64 ) ) error { err := shiftAclType ( path , C . ACL_TYPE_ACCESS , shiftIds ) if err != nil { return err } err = shiftAclType ( path , C . ACL_TYPE_DEFAULT , shiftIds ) if err != nil { return err } return nil } 
func ( pt * ProgressReader ) Read ( p [ ] byte ) ( int , error ) { pt . Tracker . update ( n ) } return n , err } 
func Supported ( path string ) ( bool , error ) { if err != nil { return false , err } defer C . free ( unsafe . Pointer ( cDevPath ) ) return C . quota_supported ( cDevPath ) == 0 , nil } 
func GetProject ( path string ) ( uint32 , error ) { defer C . free ( unsafe . Pointer ( cPath ) ) id := C . quota_get_path ( cPath ) if id < 0 { return 0 , fmt . Errorf ( " " , path ) } return uint32 ( id ) , nil } 
func SetProject ( path string , id uint32 ) error { defer C . free ( unsafe . Pointer ( cPath ) ) if C . quota_set_path ( cPath , C . uint32_t ( id ) ) != 0 { return fmt . Errorf ( " " , id , path ) } return nil } 
func DeleteProject ( path string , id uint32 ) error { if err != nil { return err } if err != nil { return err } return nil } 
func GetProjectUsage ( path string , id uint32 ) ( int64 , error ) { if err != nil { return - 1 , err } defer C . free ( unsafe . Pointer ( cDevPath ) ) size := C . quota_get_usage ( cDevPath , C . uint32_t ( id ) ) if size < 0 { return - 1 , fmt . Errorf ( " " , id , path ) } return int64 ( size ) , nil } 
func SetProjectQuota ( path string , id uint32 , bytes int64 ) error { if err != nil { return err } defer C . free ( unsafe . Pointer ( cDevPath ) ) if C . quota_set ( cDevPath , C . uint32_t ( id ) , C . int ( bytes / 1024 ) ) != 0 { return fmt . Errorf ( " " , id , path ) } return nil } 
func backupLoadByName ( s * state . State , project , name string ) ( * backup , error ) { if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrap ( err , " " ) } } 
func backupCreate ( s * state . State , args db . ContainerBackupArgs , sourceContainer container ) error { if err != nil { if err == db . ErrAlreadyDefined { return fmt . Errorf ( " " , args . Name ) } return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } if err != nil { s . Cluster . ContainerBackupRemove ( args . Name ) return errors . Wrap ( err , " " ) } return nil } 
func ( b * backup ) Rename ( newName string ) error { oldBackupPath := shared . VarPath ( " " , b . name ) newBackupPath := shared . VarPath ( " " , newName ) if ! shared . PathExists ( backupsPath ) { err := os . MkdirAll ( backupsPath , 0700 ) if err != nil { return err } } if err != nil { return err } if empty { err := os . Remove ( backupsPath ) if err != nil { return err } } if err != nil { return err } return nil } 
func ( b * backup ) Delete ( ) error { return doBackupDelete ( b . state , b . name , b . container . Name ( ) ) } 
func backupFixStoragePool ( c * db . Cluster , b backupInfo , useDefaultPool bool ) error { var poolName string if useDefaultPool { if err != nil { return err } _ , v , err := shared . GetRootDiskDevice ( profile . Devices ) if err != nil { return err } poolName = v [ " " ] } else { poolName = b . Pool } if err != nil { return err } f := func ( path string ) error { if err != nil { return err } rootDiskDeviceFound := false if backup . Container . Devices != nil { devName , _ , err := shared . GetRootDiskDevice ( backup . Container . Devices ) if err == nil { backup . Container . Devices [ devName ] [ " " ] = poolName rootDiskDeviceFound = true } } if backup . Container . ExpandedDevices != nil { devName , _ , err := shared . GetRootDiskDevice ( backup . Container . ExpandedDevices ) if err == nil { backup . Container . ExpandedDevices [ devName ] [ " " ] = poolName rootDiskDeviceFound = true } } if ! rootDiskDeviceFound { return fmt . Errorf ( " " ) } file , err := os . Create ( path ) if err != nil { return err } defer file . Close ( ) data , err := yaml . Marshal ( & backup ) if err != nil { return err } _ , err = file . Write ( data ) if err != nil { return err } return nil } err = f ( shared . VarPath ( " " , pool . Name , " " , b . Name , " " ) ) if err != nil { return err } for _ , snap := range b . Snapshots { err = f ( shared . VarPath ( " " , pool . Name , " " , b . Name , snap , " " ) ) if err != nil { return err } } return nil } 
func Count ( tx * sql . Tx , table string , where string , args ... interface { } ) ( int , error ) { stmt := fmt . Sprintf ( " " , table ) if where != " " { stmt += fmt . Sprintf ( " " , where ) } rows , err := tx . Query ( stmt , args ... ) if err != nil { return - 1 , err } defer rows . Close ( ) } var count int err = rows . Scan ( & count ) if err != nil { return - 1 , fmt . Errorf ( " " ) } if rows . Next ( ) { return - 1 , fmt . Errorf ( " " ) } err = rows . Err ( ) if err != nil { return - 1 , err } return count , nil } 
func CountAll ( tx * sql . Tx ) ( map [ string ] int , error ) { tables , err := SelectStrings ( tx , " " ) if err != nil { return nil , errors . Wrap ( err , " " ) } counts := map [ string ] int { } for _ , table := range tables { count , err := Count ( tx , table , " " ) if err != nil { return nil , errors . Wrapf ( err , " " , table ) } counts [ table ] = count } return counts , nil } 
func InitTLSConfig ( ) * tls . Config { return & tls . Config { MinVersion : tls . VersionTLS12 , CipherSuites : [ ] uint16 { tls . TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 , tls . TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA , tls . TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 , tls . TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA , tls . TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 , tls . TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA , tls . TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 , tls . TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA , } , PreferServerCipherSuites : true , } } 
func ( s * storageLvm ) copyContainerThinpool ( target container , source container , readonly bool ) error { err := s . createSnapshotContainer ( target , source , readonly ) if err != nil { logger . Errorf ( " " , err ) return err } poolName := s . getOnDiskPoolName ( ) containerName := target . Name ( ) containerLvmName := containerNameToLVName ( containerName ) containerLvDevPath := getLvmDevPath ( target . Project ( ) , poolName , storagePoolVolumeAPIEndpointContainers , containerLvmName ) if err != nil { return err } if ourUmount { defer s . ContainerMount ( source ) } } msg , err := fsGenerateNewUUID ( LVFilesystem , containerLvDevPath ) if err != nil { logger . Errorf ( " \" \" \" \" \" \" " , LVFilesystem , containerName , s . pool . Name , msg ) return err } return nil } 
func ( s * storageLvm ) copyContainerLv ( target container , source container , readonly bool , refresh bool ) error { exists , err := storageLVExists ( getLvmDevPath ( target . Project ( ) , s . getOnDiskPoolName ( ) , storagePoolVolumeAPIEndpointContainers , containerNameToLVName ( target . Name ( ) ) ) ) if err != nil { return err } if err != nil { return err } } targetName := target . Name ( ) targetStart , err := target . StorageStart ( ) if err != nil { return err } if targetStart { defer target . StorageStop ( ) } sourceName := source . Name ( ) sourceStart , err := source . StorageStart ( ) if err != nil { return err } if sourceStart { defer source . StorageStop ( ) } sourcePool , err := source . StoragePool ( ) if err != nil { return err } sourceContainerMntPoint := getContainerMountPoint ( source . Project ( ) , sourcePool , sourceName ) if source . IsSnapshot ( ) { sourceContainerMntPoint = getSnapshotMountPoint ( source . Project ( ) , sourcePool , sourceName ) } targetContainerMntPoint := getContainerMountPoint ( target . Project ( ) , s . pool . Name , targetName ) if target . IsSnapshot ( ) { targetContainerMntPoint = getSnapshotMountPoint ( source . Project ( ) , s . pool . Name , targetName ) } if source . IsRunning ( ) { err = source . Freeze ( ) if err != nil { return err } defer source . Unfreeze ( ) } bwlimit := s . pool . Config [ " " ] output , err := rsyncLocalCopy ( sourceContainerMntPoint , targetContainerMntPoint , bwlimit ) if err != nil { return fmt . Errorf ( " " , string ( output ) , err ) } if readonly { targetLvmName := containerNameToLVName ( targetName ) poolName := s . getOnDiskPoolName ( ) output , err := shared . TryRunCommand ( " " , " " , fmt . Sprintf ( " " , poolName , storagePoolVolumeAPIEndpointContainers , targetLvmName ) ) if err != nil { logger . Errorf ( " \" \" " , targetName , output ) return err } } return nil } 
func ( s * storageLvm ) copyContainer ( target container , source container , refresh bool ) error { targetPool , err := target . StoragePool ( ) if err != nil { return err } targetContainerMntPoint := getContainerMountPoint ( target . Project ( ) , targetPool , target . Name ( ) ) err = createContainerMountpoint ( targetContainerMntPoint , target . Path ( ) , target . IsPrivileged ( ) ) if err != nil { return err } sourcePool , err := source . StoragePool ( ) if err != nil { return err } if s . useThinpool && targetPool == sourcePool && ! refresh { } else { } if err != nil { return err } err = target . TemplateApply ( " " ) if err != nil { return err } return nil } 
func ( s * storageLvm ) copyVolume ( sourcePool string , source string ) error { targetMntPoint := getStoragePoolVolumeMountPoint ( s . pool . Name , s . volume . Name ) err := os . MkdirAll ( targetMntPoint , 0711 ) if err != nil { return err } if s . useThinpool && sourcePool == s . pool . Name { err = s . copyVolumeThinpool ( source , s . volume . Name , false ) } else { err = s . copyVolumeLv ( sourcePool , source , s . volume . Name , false ) } if err != nil { return err } return nil } 
func ( r * ProtocolSimpleStreams ) GetImageFingerprints ( ) ( [ ] string , error ) { if err != nil { return nil , err } for _ , img := range images { fingerprints = append ( fingerprints , img . Fingerprint ) } return fingerprints , nil } 
func ( r * ProtocolSimpleStreams ) GetImage ( fingerprint string ) ( * api . Image , string , error ) { image , err := r . ssClient . GetImage ( fingerprint ) if err != nil { return nil , " " , err } return image , " " , err } 
func ( r * ProtocolSimpleStreams ) GetImageFile ( fingerprint string , req ImageFileRequest ) ( * ImageFileResponse , error ) { } if err == nil { resp , err := lxdDownloadImage ( fingerprint , unixURI , r . httpUserAgent , devlxdHTTP , req ) if err == nil { return resp , nil } } } if err != nil { return nil , err } size , err := shared . DownloadFileHash ( r . http , r . httpUserAgent , req . ProgressHandler , req . Canceler , filename , url , hash , sha256 . New ( ) , target ) if err != nil { } size , err = shared . DownloadFileHash ( r . http , r . httpUserAgent , req . ProgressHandler , req . Canceler , filename , url , hash , sha256 . New ( ) , target ) if err != nil { return - 1 , err } } return size , nil } if ok && req . MetaFile != nil { size , err := download ( meta . Path , " " , meta . Sha256 , req . MetaFile ) if err != nil { return nil , err } parts := strings . Split ( meta . Path , " " ) resp . MetaName = parts [ len ( parts ) - 1 ] resp . MetaSize = size } if ok && req . RootfsFile != nil { _ , err := exec . LookPath ( " " ) if err == nil && req . DeltaSourceRetriever != nil { for filename , file := range files { if ! strings . HasPrefix ( filename , " " ) { continue } srcPath := req . DeltaSourceRetriever ( srcFingerprint , " " ) if srcPath == " " { continue } if err != nil { return nil , err } defer deltaFile . Close ( ) defer os . Remove ( deltaFile . Name ( ) ) if err != nil { return nil , err } if err != nil { return nil , err } defer patchedFile . Close ( ) defer os . Remove ( patchedFile . Name ( ) ) if err != nil { return nil , err } if err != nil { return nil , err } parts := strings . Split ( rootfs . Path , " " ) resp . RootfsName = parts [ len ( parts ) - 1 ] resp . RootfsSize = size downloaded = true } } if err != nil { return nil , err } parts := strings . Split ( rootfs . Path , " " ) resp . RootfsName = parts [ len ( parts ) - 1 ] resp . RootfsSize = size } } return & resp , nil } 
func ( r * ProtocolSimpleStreams ) GetPrivateImage ( fingerprint string , secret string ) ( * api . Image , string , error ) { return nil , " " , fmt . Errorf ( " " ) } 
func ( r * ProtocolSimpleStreams ) GetPrivateImageFile ( fingerprint string , secret string , req ImageFileRequest ) ( * ImageFileResponse , error ) { return nil , fmt . Errorf ( " " ) } 
func ( r * ProtocolSimpleStreams ) GetImageAliasNames ( ) ( [ ] string , error ) { if err != nil { return nil , err } for _ , alias := range aliases { names = append ( names , alias . Name ) } return names , nil } 
func ( r * ProtocolSimpleStreams ) GetImageAlias ( name string ) ( * api . ImageAliasesEntry , string , error ) { alias , err := r . ssClient . GetAlias ( name ) if err != nil { return nil , " " , err } return alias , " " , err } 
func ProtoRecv ( ws * websocket . Conn , msg proto . Message ) error { mt , r , err := ws . NextReader ( ) if err != nil { return err } if mt != websocket . BinaryMessage { return fmt . Errorf ( " " ) } buf , err := ioutil . ReadAll ( r ) if err != nil { return err } err = proto . Unmarshal ( buf , msg ) if err != nil { return err } return nil } 
func ProtoSend ( ws * websocket . Conn , msg proto . Message ) error { w , err := ws . NextWriter ( websocket . BinaryMessage ) if err != nil { return err } defer w . Close ( ) data , err := proto . Marshal ( msg ) if err != nil { return err } err = shared . WriteAll ( w , data ) if err != nil { return err } return nil } 
func ProtoSendControl ( ws * websocket . Conn , err error ) { message := " " if err != nil { message = err . Error ( ) } msg := MigrationControl { Success : proto . Bool ( err == nil ) , Message : proto . String ( message ) , } ProtoSend ( ws , & msg ) } 
func LoadPreClusteringData ( tx * sql . Tx ) ( * Dump , error ) { DELETE FROM containers_config WHERE container_id NOT IN (SELECT id FROM containers); DELETE FROM containers_devices WHERE container_id NOT IN (SELECT id FROM containers); DELETE FROM containers_devices_config WHERE container_device_id NOT IN (SELECT id FROM containers_devices); DELETE FROM containers_profiles WHERE container_id NOT IN (SELECT id FROM containers); DELETE FROM containers_profiles WHERE profile_id NOT IN (SELECT id FROM profiles); DELETE FROM images_aliases WHERE image_id NOT IN (SELECT id FROM images); DELETE FROM images_properties WHERE image_id NOT IN (SELECT id FROM images); DELETE FROM images_source WHERE image_id NOT IN (SELECT id FROM images); DELETE FROM networks_config WHERE network_id NOT IN (SELECT id FROM networks); DELETE FROM profiles_config WHERE profile_id NOT IN (SELECT id FROM profiles); DELETE FROM profiles_devices WHERE profile_id NOT IN (SELECT id FROM profiles); DELETE FROM profiles_devices_config WHERE profile_device_id NOT IN (SELECT id FROM profiles_devices); DELETE FROM storage_pools_config WHERE storage_pool_id NOT IN (SELECT id FROM storage_pools); DELETE FROM storage_volumes WHERE storage_pool_id NOT IN (SELECT id FROM storage_pools); DELETE FROM storage_volumes_config WHERE storage_volume_id NOT IN (SELECT id FROM storage_volumes); ` ) if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , table := range preClusteringTables { logger . Debugf ( " " , table ) data := [ ] [ ] interface { } { } stmt := fmt . Sprintf ( " " , table ) rows , err := tx . Query ( stmt ) if err != nil { return nil , errors . Wrapf ( err , " " , table ) } columns , err := rows . Columns ( ) if err != nil { rows . Close ( ) return nil , errors . Wrapf ( err , " " , table ) } dump . Schema [ table ] = columns for rows . Next ( ) { values := make ( [ ] interface { } , len ( columns ) ) row := make ( [ ] interface { } , len ( columns ) ) for i := range values { row [ i ] = & values [ i ] } err := rows . Scan ( row ... ) if err != nil { rows . Close ( ) return nil , errors . Wrapf ( err , " " , table ) } data = append ( data , values ) } err = rows . Err ( ) if err != nil { rows . Close ( ) return nil , errors . Wrapf ( err , " " , table ) } rows . Close ( ) dump . Data [ table ] = data } return dump , nil } 
func ( c * Cluster ) ImportPreClusteringData ( dump * Dump ) error { tx , err := c . db . Begin ( ) if err != nil { return errors . Wrap ( err , " " ) } if err != nil { tx . Rollback ( ) return errors . Wrap ( err , " " ) } for _ , table := range preClusteringTables { logger . Debugf ( " " , table ) for i , row := range dump . Data [ table ] { for i , element := range row { if ok { row [ i ] = string ( bytes ) } } columns := dump . Schema [ table ] nullNodeID := false appendNodeID := func ( ) { columns = append ( columns , " " ) if nullNodeID { row = append ( row , nil ) } else { row = append ( row , int64 ( 1 ) ) } } switch table { case " " : skip := false for i , column := range columns { value , ok := row [ i ] . ( string ) if ! ok { continue } if column == " " && shared . StringInSlice ( value , keys ) { skip = true } } if skip { continue } case " " : appendNodeID ( ) case " " : for i , column := range columns { if column == " " { index = i break } } key := row [ index ] . ( string ) if ! shared . StringInSlice ( key , NetworkNodeConfigKeys ) { nullNodeID = true break } appendNodeID ( ) case " " : for i , column := range columns { if column == " " { index = i break } } key := row [ index ] . ( string ) if ! shared . StringInSlice ( key , StoragePoolNodeConfigKeys ) { nullNodeID = true break } appendNodeID ( ) case " " : fallthrough case " " : columns = append ( columns , " " ) row = append ( row , storagePoolCreated ) case " " : appendNodeID ( ) } if shared . StringInSlice ( table , preClusteringTablesRequiringProjectID ) { row = append ( row , 1 ) } stmt := fmt . Sprintf ( " " , table , strings . Join ( columns , " " ) ) stmt += fmt . Sprintf ( " " , query . Params ( len ( columns ) ) ) result , err := tx . Exec ( stmt , row ... ) if err != nil { tx . Rollback ( ) return errors . Wrapf ( err , " " , i , table ) } n , err := result . RowsAffected ( ) if err != nil { tx . Rollback ( ) return errors . Wrapf ( err , " " , i , table ) } if n != 1 { tx . Rollback ( ) return fmt . Errorf ( " " , i , table ) } importNodeAssociation ( entity , columns , row , tx ) } } } return tx . Commit ( ) } 
func importNodeAssociation ( entity string , columns [ ] string , row [ ] interface { } , tx * sql . Tx ) error { stmt := fmt . Sprintf ( " " , entity , entity ) var id int64 for i , column := range columns { if column == " " { id = row [ i ] . ( int64 ) break } } if id == 0 { return fmt . Errorf ( " " , entity ) } _ , err := tx . Exec ( stmt , id ) if err != nil { return errors . Wrapf ( err , " " , entity ) } return nil } 
func ( er stdinMirror ) Read ( p [ ] byte ) ( int , error ) { n , err := er . r . Read ( p ) v := rune ( p [ 0 ] ) if v == '\u0001' && ! * er . foundEscape { * er . foundEscape = true return 0 , err } if v == 'q' && * er . foundEscape { select { case er . consoleDisconnect <- true : return 0 , err default : return 0 , err } } * er . foundEscape = false return n , err } 
func doContainersGetFromNode ( project , node string , cert * shared . CertInfo ) ( [ ] api . Container , error ) { f := func ( ) ( [ ] api . Container , error ) { client , err := cluster . Connect ( node , cert , true ) if err != nil { return nil , errors . Wrapf ( err , " " , node ) } client = client . UseProject ( project ) containers , err := client . GetContainers ( ) if err != nil { return nil , errors . Wrapf ( err , " " , node ) } return containers , nil } timeout := time . After ( 30 * time . Second ) done := make ( chan struct { } ) var containers [ ] api . Container var err error go func ( ) { containers , err = f ( ) done <- struct { } { } } ( ) select { case <- timeout : err = fmt . Errorf ( " " , node ) case <- done : } return containers , err } 
func DevLxdServer ( d * Daemon ) * http . Server { return & http . Server { Handler : devLxdAPI ( d ) , ConnState : pidMapper . ConnStateHandler , } } 
func extractUnderlyingFd ( unixConnPtr * net . UnixConn ) ( int , error ) { conn := reflect . Indirect ( reflect . ValueOf ( unixConnPtr ) ) netFdPtr := conn . FieldByName ( " " ) if ! netFdPtr . IsValid ( ) { return - 1 , fmt . Errorf ( " " ) } netFd := reflect . Indirect ( netFdPtr ) fd := netFd . FieldByName ( " " ) if ! fd . IsValid ( ) { if ! pfdPtr . IsValid ( ) { return - 1 , fmt . Errorf ( " " ) } pfd := reflect . Indirect ( pfdPtr ) fd = pfd . FieldByName ( " " ) if ! fd . IsValid ( ) { return - 1 , fmt . Errorf ( " " ) } } return int ( fd . Int ( ) ) , nil } 
func extractUnderlyingConn ( w http . ResponseWriter ) * net . UnixConn { v := reflect . Indirect ( reflect . ValueOf ( w ) ) connPtr := v . FieldByName ( " " ) conn := reflect . Indirect ( connPtr ) rwc := conn . FieldByName ( " " ) netConnPtr := ( * net . Conn ) ( unsafe . Pointer ( rwc . UnsafeAddr ( ) ) ) unixConnPtr := ( * netConnPtr ) . ( * net . UnixConn ) return unixConnPtr } 
func Retry ( f func ( ) error ) error { for i := 0 ; i < 5 ; i ++ { err = f ( ) if err != nil { logger . Debugf ( " " , err ) if IsRetriableError ( err ) { logger . Debugf ( " " , err ) time . Sleep ( 250 * time . Millisecond ) continue } } break } return err } 
func IsRetriableError ( err error ) bool { err = errors . Cause ( err ) if err == nil { return false } if err == sqlite3 . ErrLocked || err == sqlite3 . ErrBusy { return true } if strings . Contains ( err . Error ( ) , " " ) { return true } if strings . Contains ( err . Error ( ) , " " ) { return true } } return false } 
func storagePoolVolumeUsedByGet ( s * state . State , project , volumeName string , volumeTypeName string ) ( [ ] string , error ) { if snap { return [ ] string { fmt . Sprintf ( " " , version . APIVersion , cName , sName ) } , nil } return [ ] string { fmt . Sprintf ( " " , version . APIVersion , cName ) } , nil } } if err != nil { return [ ] string { } , err } volumeUsedBy := [ ] string { } for _ , ct := range ctsUsingVolume { volumeUsedBy = append ( volumeUsedBy , fmt . Sprintf ( " " , version . APIVersion , ct ) ) } profiles , err := profilesUsingPoolVolumeGetNames ( s . Cluster , volumeName , volumeTypeName ) if err != nil { return [ ] string { } , err } if len ( volumeUsedBy ) == 0 && len ( profiles ) == 0 { return [ ] string { } , nil } for _ , pName := range profiles { volumeUsedBy = append ( volumeUsedBy , fmt . Sprintf ( " " , version . APIVersion , pName ) ) } return volumeUsedBy , nil } 
func storagePoolVolumeSnapshotsGet ( s * state . State , pool string , volume string , volType int ) ( [ ] string , error ) { poolID , err := s . Cluster . StoragePoolGetID ( pool ) if err != nil { return nil , err } snapshots , err := s . Cluster . StoragePoolVolumeSnapshotsGetType ( volume , volType , poolID ) if err != nil { return nil , err } return snapshots , nil } 
func AppArmorProfile ( ) string { contents , err := ioutil . ReadFile ( " " ) if err == nil { return strings . TrimSpace ( string ( contents ) ) } return " " } 
func getSnapshotSubvolumePath ( project , poolName string , containerName string ) string { return shared . VarPath ( " " , poolName , " " , projectPrefix ( project , containerName ) ) } 
func ( s * storageBtrfs ) StoragePoolVolumeCreate ( ) error { logger . Infof ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) _ , err := s . StoragePoolMount ( ) if err != nil { return err } isSnapshot := shared . IsSnapshot ( s . volume . Name ) if isSnapshot { customSubvolumePath = s . getCustomSnapshotSubvolumePath ( s . pool . Name ) } else { customSubvolumePath = s . getCustomSubvolumePath ( s . pool . Name ) } if ! shared . PathExists ( customSubvolumePath ) { err := os . MkdirAll ( customSubvolumePath , 0700 ) if err != nil { return err } } if isSnapshot { customSubvolumeName = getStoragePoolVolumeSnapshotMountPoint ( s . pool . Name , s . volume . Name ) } else { customSubvolumeName = getStoragePoolVolumeMountPoint ( s . pool . Name , s . volume . Name ) } err = btrfsSubVolumeCreate ( customSubvolumeName ) if err != nil { return err } if err != nil { return err } err = s . StorageEntitySetQuota ( storagePoolVolumeTypeCustom , size , nil ) if err != nil { return err } } logger . Infof ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) return nil } 
func ( s * storageBtrfs ) ContainerStorageReady ( container container ) bool { containerMntPoint := getContainerMountPoint ( container . Project ( ) , s . pool . Name , container . Name ( ) ) return isBtrfsSubVolume ( containerMntPoint ) } 
func ( s * storageBtrfs ) ContainerCreateFromImage ( container container , fingerprint string , tracker * ioprogress . ProgressTracker ) error { logger . Debugf ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) source := s . pool . Config [ " " ] if source == " " { return fmt . Errorf ( " \" \" " ) } _ , err := s . StoragePoolMount ( ) if err != nil { return errors . Wrap ( err , " " ) } if ! shared . PathExists ( containerSubvolumePath ) { err := os . MkdirAll ( containerSubvolumePath , containersDirMode ) if err != nil { return errors . Wrap ( err , " " ) } } imageStoragePoolLockID := getImageCreateLockID ( s . pool . Name , fingerprint ) lxdStorageMapLock . Lock ( ) if waitChannel , ok := lxdStorageOngoingOperationMap [ imageStoragePoolLockID ] ; ok { lxdStorageMapLock . Unlock ( ) if _ , ok := <- waitChannel ; ok { logger . Warnf ( " " ) } } else { lxdStorageOngoingOperationMap [ imageStoragePoolLockID ] = make ( chan bool ) lxdStorageMapLock . Unlock ( ) var imgerr error if ! shared . PathExists ( imageMntPoint ) || ! isBtrfsSubVolume ( imageMntPoint ) { imgerr = s . ImageCreate ( fingerprint , tracker ) } lxdStorageMapLock . Lock ( ) if waitChannel , ok := lxdStorageOngoingOperationMap [ imageStoragePoolLockID ] ; ok { close ( waitChannel ) delete ( lxdStorageOngoingOperationMap , imageStoragePoolLockID ) } lxdStorageMapLock . Unlock ( ) if imgerr != nil { return errors . Wrap ( imgerr , " " ) } } err = s . btrfsPoolVolumesSnapshot ( imageMntPoint , containerSubvolumeName , false , false ) if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } logger . Debugf ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) err = container . TemplateApply ( " " ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func ( s * storageBtrfs ) ContainerSnapshotRename ( snapshotContainer container , newName string ) error { logger . Debugf ( " \" \" " , s . volume . Name , s . volume . Name , newName ) if err != nil { return err } newSnapshotSubvolumeName := getSnapshotMountPoint ( snapshotContainer . Project ( ) , s . pool . Name , newName ) err = os . Rename ( oldSnapshotSubvolumeName , newSnapshotSubvolumeName ) if err != nil { return err } logger . Debugf ( " \" \" " , s . volume . Name , s . volume . Name , newName ) return nil } 
func ( s * storageBtrfs ) ContainerSnapshotCreateEmpty ( snapshotContainer container ) error { logger . Debugf ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) if err != nil { return err } snapshotSubvolumePath := getSnapshotSubvolumePath ( snapshotContainer . Project ( ) , s . pool . Name , sourceName ) snapshotSubvolumeName := getSnapshotMountPoint ( snapshotContainer . Project ( ) , s . pool . Name , snapshotContainer . Name ( ) ) if ! shared . PathExists ( snapshotSubvolumePath ) { err := os . MkdirAll ( snapshotSubvolumePath , containersDirMode ) if err != nil { return err } } err = btrfsSubVolumeCreate ( snapshotSubvolumeName ) if err != nil { return err } snapshotMntPointSymlinkTarget := shared . VarPath ( " " , s . pool . Name , " " , projectPrefix ( snapshotContainer . Project ( ) , sourceName ) ) snapshotMntPointSymlink := shared . VarPath ( " " , projectPrefix ( snapshotContainer . Project ( ) , sourceName ) ) if ! shared . PathExists ( snapshotMntPointSymlink ) { err := createContainerMountpoint ( snapshotMntPointSymlinkTarget , snapshotMntPointSymlink , snapshotContainer . IsPrivileged ( ) ) if err != nil { return err } } logger . Debugf ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) return nil } 
func btrfsSubVolumesDelete ( subvol string ) error { if err != nil { return err } sort . Sort ( sort . Reverse ( sort . StringSlice ( subsubvols ) ) ) for _ , subsubvol := range subsubvols { err := btrfsSubVolumeDelete ( path . Join ( subvol , subsubvol ) ) if err != nil { return err } } if err != nil { return err } return nil } 
func btrfsSnapshot ( source string , dest string , readonly bool ) error { var output string var err error if readonly { output , err = shared . RunCommand ( " " , " " , " " , " " , source , dest ) } else { output , err = shared . RunCommand ( " " , " " , " " , source , dest ) } if err != nil { return fmt . Errorf ( " " , source , dest , output , ) } return err } 
func isBtrfsSubVolume ( subvolPath string ) bool { fs := syscall . Stat_t { } err := syscall . Lstat ( subvolPath , & fs ) if err != nil { return false } } return true } 
func SafeLoad ( schema Schema , values map [ string ] string ) ( Map , error ) { m , err := Load ( schema , values ) if err != nil { errors , ok := err . ( ErrorList ) if ! ok { return m , err } for _ , error := range errors { message := fmt . Sprintf ( " " , error . Reason ) logger . Error ( message , log . Ctx { " " : error . Name } ) } } return m , nil } 
func SelectConfig ( tx * sql . Tx , table string , where string , args ... interface { } ) ( map [ string ] string , error ) { query := fmt . Sprintf ( " " , table ) if where != " " { query += fmt . Sprintf ( " " , where ) } rows , err := tx . Query ( query , args ... ) if err != nil { return nil , err } defer rows . Close ( ) values := map [ string ] string { } for rows . Next ( ) { var key string var value string err := rows . Scan ( & key , & value ) if err != nil { return nil , err } values [ key ] = value } err = rows . Err ( ) if err != nil { return nil , err } return values , nil } 
func UpdateConfig ( tx * sql . Tx , table string , values map [ string ] string ) error { changes := map [ string ] string { } deletes := [ ] string { } for key , value := range values { if value == " " { deletes = append ( deletes , key ) continue } changes [ key ] = value } err := upsertConfig ( tx , table , changes ) if err != nil { return errors . Wrap ( err , " " ) } err = deleteConfig ( tx , table , deletes ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func upsertConfig ( tx * sql . Tx , table string , values map [ string ] string ) error { if len ( values ) == 0 { return nil } query := fmt . Sprintf ( " " , table ) exprs := [ ] string { } params := [ ] interface { } { } for key , value := range values { exprs = append ( exprs , " " ) params = append ( params , key ) params = append ( params , value ) } query += strings . Join ( exprs , " " ) _ , err := tx . Exec ( query , params ... ) return err } 
func deleteConfig ( tx * sql . Tx , table string , keys [ ] string ) error { n := len ( keys ) if n == 0 { return nil } query := fmt . Sprintf ( " " , table , Params ( n ) ) values := make ( [ ] interface { } , n ) for i , key := range keys { values [ i ] = key } _ , err := tx . Exec ( query , values ... ) return err } 
func FormatSection ( header string , content string ) string { out := " " } } out += line + " \n " } if header != " " { } else { } return out } 
func ( r * ProtocolLXD ) GetProjects ( ) ( [ ] api . Project , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } projects := [ ] api . Project { } if err != nil { return nil , err } return projects , nil } 
func ( r * ProtocolLXD ) GetProject ( name string ) ( * api . Project , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } project := api . Project { } if err != nil { return nil , " " , err } return & project , etag , nil } 
func ( r * ProtocolLXD ) CreateProject ( project api . ProjectsPost ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) UpdateProject ( name string , project api . ProjectPut , ETag string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) RenameProject ( name string , project api . ProjectPost ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if err != nil { return nil , err } return op , nil } 
func ( er Reader ) Read ( p [ ] byte ) ( int , error ) { again : n , err := er . Reader . Read ( p ) if err == nil { return n , nil } if ok && ( errno == syscall . EAGAIN || errno == syscall . EINTR ) { goto again } return n , err } 
func ( ew Writer ) Write ( p [ ] byte ) ( int , error ) { again : n , err := ew . Writer . Write ( p ) if err == nil { return n , nil } if ok && ( errno == syscall . EAGAIN || errno == syscall . EINTR ) { goto again } return n , err } 
func NewCanceler ( ) * Canceler { c := Canceler { } c . lock . Lock ( ) c . reqChCancel = make ( map [ * http . Request ] chan struct { } ) c . lock . Unlock ( ) return & c } 
func ( c * Canceler ) Cancelable ( ) bool { c . lock . Lock ( ) length := len ( c . reqChCancel ) c . lock . Unlock ( ) return length > 0 } 
func ( c * Canceler ) Cancel ( ) error { if ! c . Cancelable ( ) { return fmt . Errorf ( " " ) } c . lock . Lock ( ) for req , ch := range c . reqChCancel { close ( ch ) delete ( c . reqChCancel , req ) } c . lock . Unlock ( ) return nil } 
func CancelableDownload ( c * Canceler , client * http . Client , req * http . Request ) ( * http . Response , chan bool , error ) { chDone := make ( chan bool ) chCancel := make ( chan struct { } ) if c != nil { c . lock . Lock ( ) c . reqChCancel [ req ] = chCancel c . lock . Unlock ( ) } req . Cancel = chCancel go func ( ) { <- chDone if c != nil { c . lock . Lock ( ) delete ( c . reqChCancel , req ) c . lock . Unlock ( ) } } ( ) resp , err := client . Do ( req ) return resp , chDone , err } 
func clusterGet ( d * Daemon , r * http . Request ) Response { name := " " err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error name , err = tx . NodeName ( ) return err } ) if err != nil { return SmartError ( err ) } } memberConfig , err := clusterGetMemberConfig ( d . cluster ) if err != nil { return SmartError ( err ) } cluster := api . Cluster { ServerName : name , Enabled : name != " " , MemberConfig : memberConfig , } return SyncResponseETag ( true , cluster , cluster ) } 
func clusterGetMemberConfig ( cluster * db . Cluster ) ( [ ] api . ClusterMemberConfigKey , error ) { var pools map [ string ] map [ string ] string var networks map [ string ] map [ string ] string keys := [ ] api . ClusterMemberConfigKey { } err := cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error pools , err = tx . StoragePoolsNodeConfig ( ) if err != nil { return errors . Wrapf ( err , " " ) } networks , err = tx . NetworksNodeConfig ( ) if err != nil { return errors . Wrapf ( err , " " ) } return nil } ) if err != nil { return nil , err } for pool , config := range pools { for key := range config { if strings . HasPrefix ( key , " " ) { continue } key := api . ClusterMemberConfigKey { Entity : " " , Name : pool , Key : key , Description : fmt . Sprintf ( " \" \" \" \" " , key , pool ) , } keys = append ( keys , key ) } } for network , config := range networks { for key := range config { if strings . HasPrefix ( key , " " ) { continue } key := api . ClusterMemberConfigKey { Entity : " " , Name : network , Key : key , Description : fmt . Sprintf ( " \" \" \" \" " , key , network ) , } keys = append ( keys , key ) } } return keys , nil } 
func clusterPut ( d * Daemon , r * http . Request ) Response { req := api . ClusterPut { } if err != nil { return BadRequest ( err ) } } if req . ServerName != " " && ! req . Enabled { return BadRequest ( fmt . Errorf ( " " ) ) } } } return clusterPutJoin ( d , req ) } 
func clusterPutDisable ( d * Daemon ) Response { if err != nil { return SmartError ( err ) } if ! shared . PathExists ( path ) { continue } err := os . Remove ( path ) if err != nil { return InternalError ( err ) } } cert , err := util . LoadCert ( d . os . VarDir ) if err != nil { return InternalError ( errors . Wrap ( err , " " ) ) } err = d . gateway . Reset ( cert ) if err != nil { return SmartError ( err ) } if err != nil { return SmartError ( err ) } store := d . gateway . ServerStore ( ) d . cluster , err = db . OpenCluster ( " " , store , address , " " , d . config . DqliteSetupTimeout , dqlite . WithDialFunc ( d . gateway . DialFunc ( ) ) , dqlite . WithContext ( d . gateway . Context ( ) ) , ) if err != nil { return SmartError ( err ) } return EmptySyncResponse } 
func clusterInitMember ( d , client lxd . ContainerServer , memberConfig [ ] api . ClusterMemberConfigKey ) error { data := initDataNode { } if err != nil { return errors . Wrap ( err , " " ) } } } logger . Debugf ( " " , pool . Name ) post := api . StoragePoolsPost { StoragePoolPut : pool . StoragePoolPut , Driver : pool . Driver , Name : pool . Name , } delete ( post . Config , " " ) } if config . Name != pool . Name { continue } if ! shared . StringInSlice ( config . Key , db . StoragePoolNodeConfigKeys ) { logger . Warnf ( " " , config . Key , config . Name ) continue } post . Config [ config . Key ] = config . Value } data . StoragePools = append ( data . StoragePools , post ) } if err != nil { return errors . Wrap ( err , " " ) } } post := api . NetworksPost { NetworkPut : network . NetworkPut , Managed : true , Name : network . Name , Type : network . Type , } } if config . Name != network . Name { continue } if ! shared . StringInSlice ( config . Key , db . NetworkNodeConfigKeys ) { logger . Warnf ( " " , config . Key , config . Name ) continue } post . Config [ config . Key ] = config . Value } data . Networks = append ( data . Networks , post ) } revert , err := initDataNodeApply ( d , data ) if err != nil { revert ( ) return errors . Wrap ( err , " " ) } return nil } 
func clusterAcceptMember ( client lxd . ContainerServer , name , address string , schema , apiExt int , pools [ ] api . StoragePool , networks [ ] api . Network ) ( * internalClusterPostAcceptResponse , error ) { req := internalClusterPostAcceptRequest { Name : name , Address : address , Schema : schema , API : apiExt , StoragePools : pools , Networks : networks , } info := & internalClusterPostAcceptResponse { } resp , _ , err := client . RawQuery ( " " , " " , req , " " ) if err != nil { return nil , err } err = resp . MetadataAsStruct ( & info ) if err != nil { return nil , err } return info , nil } 
func tryClusterRebalance ( d * Daemon ) error { leader , err := d . gateway . LeaderAddress ( ) if err != nil { } cert := d . endpoints . NetworkCert ( ) client , err := cluster . Connect ( leader , cert , true ) if err != nil { return errors . Wrap ( err , " " ) } _ , _ , err = client . RawQuery ( " " , " " , nil , " " ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func internalClusterPostRebalance ( d * Daemon , r * http . Request ) Response { if err != nil { return SmartError ( err ) } leader , err := d . gateway . LeaderAddress ( ) if err != nil { return InternalError ( err ) } if localAddress != leader { logger . Debugf ( " " , leader ) url := & url . URL { Scheme : " " , Path : " " , Host : leader , } return SyncResponseRedirect ( url . String ( ) ) } logger . Debugf ( " " ) if err != nil { return SmartError ( err ) } if address == " " { return SyncResponse ( true , nil ) } for _ , node := range nodes { post . RaftNodes = append ( post . RaftNodes , internalRaftNode { ID : node . ID , Address : node . Address , } ) } cert := d . endpoints . NetworkCert ( ) client , err := cluster . Connect ( address , cert , false ) if err != nil { return SmartError ( err ) } _ , _ , err = client . RawQuery ( " " , " " , post , " " ) if err != nil { return SmartError ( err ) } return SyncResponse ( true , nil ) } 
func internalClusterPostPromote ( d * Daemon , r * http . Request ) Response { req := internalClusterPostPromoteRequest { } if err != nil { return BadRequest ( err ) } } nodes := make ( [ ] db . RaftNode , len ( req . RaftNodes ) ) for i , node := range req . RaftNodes { nodes [ i ] . ID = node . ID nodes [ i ] . Address = node . Address } err = cluster . Promote ( d . State ( ) , d . gateway , nodes ) if err != nil { return SmartError ( err ) } return SyncResponse ( true , nil ) } 
func Packages ( ) ( map [ string ] * ast . Package , error ) { packages := map [ string ] * ast . Package { } for _ , name := range defaultPackages { pkg , err := lex . Parse ( name ) if err != nil { return nil , errors . Wrapf ( err , " " , name ) } parts := strings . Split ( name , " " ) packages [ parts [ len ( parts ) - 1 ] ] = pkg } return packages , nil } 
func Filters ( pkg * ast . Package , entity string ) [ ] [ ] string { objects := pkg . Scope . Objects filters := [ ] [ ] string { } prefix := fmt . Sprintf ( " " , entity ) for name := range objects { if ! strings . HasPrefix ( name , prefix ) { continue } rest := name [ len ( prefix ) : ] filters = append ( filters , strings . Split ( rest , " " ) ) } sort . SliceStable ( filters , func ( i , j int ) bool { return len ( filters [ i ] ) > len ( filters [ j ] ) } ) return filters } 
func Parse ( pkg * ast . Package , name string ) ( * Mapping , error ) { str := findStruct ( pkg . Scope , name ) if str == nil { return nil , fmt . Errorf ( " " , name ) } fields , err := parseStruct ( str ) if err != nil { return nil , errors . Wrapf ( err , " " , name ) } m := & Mapping { Package : pkg . Name , Name : name , Fields : fields , } return m , nil } 
func findStruct ( scope * ast . Scope , name string ) * ast . StructType { obj := scope . Lookup ( name ) if obj == nil { return nil } typ , ok := obj . Decl . ( * ast . TypeSpec ) if ! ok { return nil } str , ok := typ . Type . ( * ast . StructType ) if ! ok { return nil } return str } 
func parseStruct ( str * ast . StructType ) ( [ ] * Field , error ) { fields := make ( [ ] * Field , 0 ) for _ , f := range str . Fields . List { if len ( f . Names ) == 0 { if ! ok { continue } typ , ok := ident . Obj . Decl . ( * ast . TypeSpec ) if ! ok { continue } parentStr , ok := typ . Type . ( * ast . StructType ) if ! ok { continue } parentFields , err := parseStruct ( parentStr ) if err != nil { return nil , errors . Wrapf ( err , " " ) } fields = append ( fields , parentFields ... ) continue } if len ( f . Names ) != 1 { return nil , fmt . Errorf ( " " , f . Names ) } field , err := parseField ( f ) if err != nil { return nil , err } fields = append ( fields , field ) } return fields , nil } 
func ( r * ProtocolLXD ) GetProfileNames ( ) ( [ ] string , error ) { urls := [ ] string { } if err != nil { return nil , err } for _ , url := range urls { fields := strings . Split ( url , " " ) names = append ( names , strings . Split ( fields [ len ( fields ) - 1 ] , " " ) [ 0 ] ) } return names , nil } 
func ( r * ProtocolLXD ) GetProfiles ( ) ( [ ] api . Profile , error ) { profiles := [ ] api . Profile { } if err != nil { return nil , err } return profiles , nil } 
func ( r * ProtocolLXD ) GetProfile ( name string ) ( * api . Profile , string , error ) { profile := api . Profile { } if err != nil { return nil , " " , err } return & profile , etag , nil } 
func ( r * ProtocolLXD ) CreateProfile ( profile api . ProfilesPost ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) UpdateProfile ( name string , profile api . ProfilePut , ETag string ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) RenameProfile ( name string , profile api . ProfilePost ) error { if err != nil { return err } return nil } 
func Load ( schema Schema , values map [ string ] string ) ( Map , error ) { m := Map { schema : schema , } return m , err } 
func ( m * Map ) Change ( changes map [ string ] interface { } ) ( map [ string ] string , error ) { values := make ( map [ string ] string , len ( m . schema ) ) errors := ErrorList { } for name , change := range changes { key , ok := m . schema [ name ] } } if s . Kind ( ) != reflect . String { errors . add ( name , nil , fmt . Sprintf ( " " , s . Kind ( ) ) ) continue } values [ name ] = change . ( string ) } if errors . Len ( ) > 0 { return nil , errors } if ! ok { values [ name ] = key . Default } } names , err := m . update ( values ) changed := map [ string ] string { } for _ , name := range names { changed [ name ] = m . GetRaw ( name ) } return changed , err } 
func ( m * Map ) Dump ( ) map [ string ] interface { } { values := map [ string ] interface { } { } for name , key := range m . schema { value := m . GetRaw ( name ) if value != key . Default { if key . Hidden { values [ name ] = true } else { values [ name ] = value } } } return values } 
func ( m * Map ) GetRaw ( name string ) string { key := m . schema . mustGetKey ( name ) value , ok := m . values [ name ] if ! ok { value = key . Default } return value } 
func ( m * Map ) GetString ( name string ) string { m . schema . assertKeyType ( name , String ) return m . GetRaw ( name ) } 
func ( m * Map ) GetBool ( name string ) bool { m . schema . assertKeyType ( name , Bool ) return shared . IsTrue ( m . GetRaw ( name ) ) } 
func ( m * Map ) GetInt64 ( name string ) int64 { m . schema . assertKeyType ( name , Int64 ) n , err := strconv . ParseInt ( m . GetRaw ( name ) , 10 , 64 ) if err != nil { panic ( fmt . Sprintf ( " " , err ) ) } return n } 
func ( m * Map ) update ( values map [ string ] string ) ( [ ] string , error ) { if initial { m . values = make ( map [ string ] string , len ( values ) ) } names := [ ] string { } for name , value := range values { changed , err := m . set ( name , value , initial ) if err != nil { errors . add ( name , value , err . Error ( ) ) continue } if changed { names = append ( names , name ) } } sort . Strings ( names ) var err error if errors . Len ( ) > 0 { errors . sort ( ) err = errors } return names , err } 
func ( m * Map ) set ( name string , value string , initial bool ) ( bool , error ) { key , ok := m . schema [ name ] if ! ok { return false , fmt . Errorf ( " " ) } err := key . validate ( value ) if err != nil { return false , err } if key . Type == Bool { value = normalizeBool ( value ) current = normalizeBool ( current ) } } if err != nil { return false , err } } if value == " " { delete ( m . values , name ) } else { m . values [ name ] = value } return true , nil } 
func DoesSchemaTableExist ( tx * sql . Tx ) ( bool , error ) { statement := ` SELECT COUNT(name) FROM sqlite_master WHERE type = 'table' AND name = 'schema' ` rows , err := tx . Query ( statement ) if err != nil { return false , err } defer rows . Close ( ) if ! rows . Next ( ) { return false , fmt . Errorf ( " " ) } var count int err = rows . Scan ( & count ) if err != nil { return false , err } return count == 1 , nil } 
func selectSchemaVersions ( tx * sql . Tx ) ( [ ] int , error ) { statement := ` SELECT version FROM schema ORDER BY version ` return query . SelectIntegers ( tx , statement ) } 
func selectTablesSQL ( tx * sql . Tx ) ( [ ] string , error ) { statement := ` SELECT sql FROM sqlite_master WHERE type IN ('table', 'index', 'view') AND name != 'schema' AND name NOT LIKE 'sqlite_%' ORDER BY name ` return query . SelectStrings ( tx , statement ) } 
func createSchemaTable ( tx * sql . Tx ) error { statement := ` CREATE TABLE schema ( id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, version INTEGER NOT NULL, updated_at DATETIME NOT NULL, UNIQUE (version) ) ` _ , err := tx . Exec ( statement ) return err } 
func insertSchemaVersion ( tx * sql . Tx , new int ) error { statement := ` INSERT INTO schema (version, updated_at) VALUES (?, strftime("%s")) ` _ , err := tx . Exec ( statement , new ) return err } 
func execFromFile ( tx * sql . Tx , path string , hook Hook ) error { if ! shared . PathExists ( path ) { return nil } bytes , err := ioutil . ReadFile ( path ) if err != nil { return errors . Wrap ( err , " " ) } if hook != nil { err := hook ( - 1 , tx ) if err != nil { return errors . Wrap ( err , " " ) } } _ , err = tx . Exec ( string ( bytes ) ) if err != nil { return err } err = os . Remove ( path ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func NewState ( node * db . Node , cluster * db . Cluster , maas * maas . Controller , os * sys . OS , endpoints * endpoints . Endpoints ) * State { return & State { Node : node , Cluster : cluster , MAAS : maas , OS : os , Endpoints : endpoints , } } 
func lxcSetConfigItem ( c * lxc . Container , key string , value string ) error { if c == nil { return fmt . Errorf ( " " ) } if ! util . RuntimeLiblxcVersionAtLeast ( 2 , 1 , 0 ) { switch key { case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " case " " : key = " " } } if strings . HasPrefix ( key , " " ) { if ! util . RuntimeLiblxcVersionAtLeast ( 2 , 1 , 0 ) { return fmt . Errorf ( `Process limits require liblxc >= 2.1` ) } } err := c . SetConfigItem ( key , value ) if err != nil { return fmt . Errorf ( " " , key , value ) } return nil } 
func containerLXCCreate ( s * state . State , args db . ContainerArgs ) ( container , error ) { } if c . creationDate . IsZero ( ) { c . creationDate = time . Time { } } if c . lastUsedDate . IsZero ( ) { c . lastUsedDate = time . Time { } } ctxMap := log . Ctx { " " : args . Project , " " : c . name , " " : c . ephemeral , } logger . Info ( " " , ctxMap ) if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } err = containerValidDevices ( s . Cluster , c . expandedDevices , false , true ) if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , errors . Wrap ( err , " " ) } if err != nil { c . Delete ( ) return nil , err } if rootDiskDevice [ " " ] == " " { c . Delete ( ) return nil , fmt . Errorf ( " " ) } storagePool := rootDiskDevice [ " " ] if err != nil { c . Delete ( ) return nil , err } err = storageVolumeFillDefault ( storagePool , volumeConfig , pool ) if err != nil { c . Delete ( ) return nil , err } if err != nil { c . Delete ( ) return nil , err } if err != nil { c . Delete ( ) s . Cluster . StoragePoolVolumeDelete ( args . Project , args . Name , storagePoolVolumeTypeContainer , poolID ) logger . Error ( " " , ctxMap ) return nil , err } c . storage = cStorage base := int64 ( 0 ) if ! c . IsPrivileged ( ) { idmap , base , err = findIdmap ( s , args . Name , c . expandedConfig [ " " ] , c . expandedConfig [ " " ] , c . expandedConfig [ " " ] , c . expandedConfig [ " " ] , ) if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } } var jsonIdmap string if idmap != nil { idmapBytes , err := json . Marshal ( idmap . Idmap ) if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } jsonIdmap = string ( idmapBytes ) } else { jsonIdmap = " " } err = c . ConfigKeySet ( " " , jsonIdmap ) if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } err = c . ConfigKeySet ( " " , fmt . Sprintf ( " " , base ) ) if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } } if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } if err != nil { c . Delete ( ) logger . Error ( " " , ctxMap ) return nil , err } } logger . Info ( " " , ctxMap ) eventSendLifecycle ( c . project , " " , fmt . Sprintf ( " " , c . name ) , nil ) return c , nil } 
func containerLXCUnload ( c * containerLXC ) { runtime . SetFinalizer ( c , nil ) if c . c != nil { c . c . Release ( ) c . c = nil } } 
func containerLXCInstantiate ( s * state . State , args db . ContainerArgs ) * containerLXC { return & containerLXC { state : s , id : args . ID , project : args . Project , name : args . Name , description : args . Description , ephemeral : args . Ephemeral , architecture : args . Architecture , cType : args . Ctype , creationDate : args . CreationDate , lastUsedDate : args . LastUsedDate , profiles : args . Profiles , localConfig : args . Config , localDevices : args . Devices , stateful : args . Stateful , node : args . Node , expiryDate : args . ExpiryDate , } } 
func ( c * containerLXC ) initStorage ( ) error { if c . storage != nil { return nil } s , err := storagePoolVolumeContainerLoadInit ( c . state , c . Project ( ) , c . Name ( ) ) if err != nil { return err } c . storage = s return nil } 
func ( c * containerLXC ) expandConfig ( profiles [ ] api . Profile ) error { if profiles == nil && len ( c . profiles ) > 0 { var err error profiles , err = c . state . Cluster . ProfilesGet ( c . project , c . profiles ) if err != nil { return err } } c . expandedConfig = db . ProfilesExpandConfig ( c . localConfig , profiles ) return nil } 
func ( c * containerLXC ) setupUnixDevice ( prefix string , dev types . Device , major int , minor int , path string , createMustSucceed bool , defaultMode bool ) error { if c . isCurrentlyPrivileged ( ) && ! c . state . OS . RunningInUserNS && c . state . OS . CGroupDevicesController { err := lxcSetConfigItem ( c . c , " " , fmt . Sprintf ( " " , major , minor ) ) if err != nil { return err } } temp := types . Device { } err := shared . DeepCopy ( & dev , & temp ) if err != nil { return err } temp [ " " ] = fmt . Sprintf ( " " , major ) temp [ " " ] = fmt . Sprintf ( " " , minor ) temp [ " " ] = path paths , err := c . createUnixDevice ( prefix , temp , defaultMode ) if err != nil { logger . Debug ( " " , log . Ctx { " " : err , " " : prefix } ) if createMustSucceed { return err } return nil } devPath := shared . EscapePathFstab ( paths [ 0 ] ) tgtPath := shared . EscapePathFstab ( paths [ 1 ] ) val := fmt . Sprintf ( " " , devPath , tgtPath ) return lxcSetConfigItem ( c . c , " " , val ) } 
func ( c * containerLXC ) startCommon ( ) ( string , error ) { if err != nil { return " " , errors . Wrap ( err , " " ) } } } case " " : if m [ " " ] != " " && ! shared . PathExists ( fmt . Sprintf ( " " , m [ " " ] ) ) { return " " , fmt . Errorf ( " " , m [ " " ] , name ) } case " " , " " : srcPath , exist := m [ " " ] if ! exist { srcPath = m [ " " ] } if srcPath != " " && m [ " " ] != " " && ! shared . IsTrue ( m [ " " ] ) { err = deviceInotifyAddClosestLivingAncestor ( c . state , filepath . Dir ( srcPath ) ) if err != nil { logger . Errorf ( " \" \" " , srcPath ) return " " , fmt . Errorf ( " " , srcPath , err ) } } else if srcPath != " " && m [ " " ] == " " && m [ " " ] == " " && ! shared . PathExists ( srcPath ) { return " " , fmt . Errorf ( " " , srcPath , name ) } } } if kernelModules != " " { for _ , module := range strings . Split ( kernelModules , " " ) { module = strings . TrimPrefix ( module , " " ) err := util . LoadModule ( module ) if err != nil { return " " , fmt . Errorf ( " " , module , err ) } } } var ourStart bool newSize , ok := c . LocalConfig ( ) [ " " ] if ok { err := c . initStorage ( ) if err != nil { return " " , errors . Wrap ( err , " " ) } size , err := shared . ParseByteSizeString ( newSize ) if err != nil { return " " , err } err = c . storage . StorageEntitySetQuota ( storagePoolVolumeTypeContainer , size , c ) if err != nil { return " " , errors . Wrap ( err , " " ) } if err != nil { return " " , errors . Wrap ( err , " " ) } delete ( c . expandedConfig , " " ) } nextIdmap , err := c . NextIdmap ( ) if err != nil { return " " , errors . Wrap ( err , " " ) } diskIdmap , err := c . DiskIdmap ( ) if err != nil { return " " , errors . Wrap ( err , " " ) } if ! nextIdmap . Equals ( diskIdmap ) && ! ( diskIdmap == nil && c . state . OS . Shiftfs ) { if shared . IsTrue ( c . expandedConfig [ " " ] ) { return " " , fmt . Errorf ( " " ) } logger . Debugf ( " " ) c . updateProgress ( " " ) ourStart , err = c . StorageStart ( ) if err != nil { return " " , errors . Wrap ( err , " " ) } if diskIdmap != nil { if c . Storage ( ) . GetStorageType ( ) == storageTypeZfs { err = diskIdmap . UnshiftRootfs ( c . RootfsPath ( ) , zfsIdmapSetSkipper ) } else { err = diskIdmap . UnshiftRootfs ( c . RootfsPath ( ) , nil ) } if err != nil { if ourStart { c . StorageStop ( ) } return " " , err } } if nextIdmap != nil && ! c . state . OS . Shiftfs { if c . Storage ( ) . GetStorageType ( ) == storageTypeZfs { err = nextIdmap . ShiftRootfs ( c . RootfsPath ( ) , zfsIdmapSetSkipper ) } else { err = nextIdmap . ShiftRootfs ( c . RootfsPath ( ) , nil ) } if err != nil { if ourStart { c . StorageStop ( ) } return " " , err } } jsonDiskIdmap := " " if nextIdmap != nil && ! c . state . OS . Shiftfs { idmapBytes , err := json . Marshal ( nextIdmap . Idmap ) if err != nil { return " " , err } jsonDiskIdmap = string ( idmapBytes ) } err = c . ConfigKeySet ( " " , jsonDiskIdmap ) if err != nil { return " " , errors . Wrapf ( err , " " , c . name , c . id ) } c . updateProgress ( " " ) } var idmapBytes [ ] byte if nextIdmap == nil { idmapBytes = [ ] byte ( " " ) } else { idmapBytes , err = json . Marshal ( nextIdmap . Idmap ) if err != nil { return " " , err } } if c . localConfig [ " " ] != string ( idmapBytes ) { err = c . ConfigKeySet ( " " , string ( idmapBytes ) ) if err != nil { return " " , errors . Wrapf ( err , " " , c . name , c . id ) } } } c . removeDiskDevices ( ) c . removeNetworkFilters ( ) c . removeProxyDevices ( ) var usbs [ ] usbDevice var sriov [ ] string diskDevices := map [ string ] types . Device { } if shared . StringInSlice ( m [ " " ] , [ ] string { " " , " " } ) { if err != nil { } srcPath := m [ " " ] if srcPath == " " { srcPath = m [ " " ] } srcPath = shared . HostPath ( srcPath ) err = deviceInotifyAddClosestLivingAncestor ( c . state , srcPath ) if err != nil { logger . Errorf ( " \" \" " , srcPath ) return " " , err } continue } devPath := paths [ 0 ] if c . isCurrentlyPrivileged ( ) && ! c . state . OS . RunningInUserNS && c . state . OS . CGroupDevicesController { if err != nil { if m [ " " ] == " " || shared . IsTrue ( m [ " " ] ) { return " " , err } } else { err = lxcSetConfigItem ( c . c , " " , fmt . Sprintf ( " " , dType , dMajor , dMinor ) ) if err != nil { return " " , fmt . Errorf ( " " ) } } } } else if m [ " " ] == " " { if usbs == nil { usbs , err = deviceLoadUsb ( ) if err != nil { return " " , err } } for _ , usb := range usbs { if ( m [ " " ] != " " && usb . vendor != m [ " " ] ) || ( m [ " " ] != " " && usb . product != m [ " " ] ) { continue } err := c . setupUnixDevice ( fmt . Sprintf ( " " , k ) , m , usb . major , usb . minor , usb . path , shared . IsTrue ( m [ " " ] ) , false ) if err != nil { return " " , err } } } else if m [ " " ] == " " { allGpus := deviceWantsAllGPUs ( m ) gpus , nvidiaDevices , err := deviceLoadGpu ( allGpus ) if err != nil { return " " , err } sawNvidia := false found := false for _ , gpu := range gpus { if ( m [ " " ] != " " && gpu . vendorID != m [ " " ] ) || ( m [ " " ] != " " && gpu . pci != m [ " " ] ) || ( m [ " " ] != " " && gpu . productID != m [ " " ] ) || ( m [ " " ] != " " && gpu . id != m [ " " ] ) { continue } found = true err := c . setupUnixDevice ( fmt . Sprintf ( " " , k ) , m , gpu . major , gpu . minor , gpu . path , true , false ) if err != nil { return " " , err } if ! gpu . isNvidia { continue } if gpu . nvidia . path != " " { err = c . setupUnixDevice ( fmt . Sprintf ( " " , k ) , m , gpu . nvidia . major , gpu . nvidia . minor , gpu . nvidia . path , true , false ) if err != nil { return " " , err } } else if ! allGpus { errMsg := fmt . Errorf ( " \" \" " ) logger . Errorf ( " " , errMsg ) return " " , errMsg } sawNvidia = true } if sawNvidia { for _ , gpu := range nvidiaDevices { if shared . IsTrue ( c . expandedConfig [ " " ] ) { if ! gpu . isCard { continue } } err := c . setupUnixDevice ( fmt . Sprintf ( " " , k ) , m , gpu . major , gpu . minor , gpu . path , true , false ) if err != nil { return " " , err } } } if ! found { msg := " " logger . Error ( msg ) return " " , fmt . Errorf ( msg ) } } else if m [ " " ] == " " { if m [ " " ] != " " { diskDevices [ k ] = m } } else if m [ " " ] == " " || m [ " " ] == " " { var err error var infiniband map [ string ] IBF if m [ " " ] == " " { infiniband , err = deviceLoadInfiniband ( ) if err != nil { return " " , err } } networkKeyPrefix := " " if ! util . RuntimeLiblxcVersionAtLeast ( 2 , 1 , 0 ) { networkKeyPrefix = " " } m , err = c . fillNetworkDevice ( k , m ) if err != nil { return " " , err } networkidx := - 1 reserved := [ ] string { } if m [ " " ] != " " && m [ " " ] != " " { continue } if m [ " " ] != " " { continue } reserved = append ( reserved , m [ " " ] ) } for _ , dName := range c . expandedDevices . DeviceNames ( ) { m := c . expandedDevices [ dName ] if m [ " " ] != " " && m [ " " ] != " " { continue } networkidx ++ if shared . StringInSlice ( dName , sriov ) { continue } else { sriov = append ( sriov , dName ) } if m [ " " ] != " " { continue } m , err = c . fillSriovNetworkDevice ( dName , m , reserved ) if err != nil { return " " , err } val := c . c . ConfigItem ( fmt . Sprintf ( " " , networkKeyPrefix , networkidx ) ) if len ( val ) == 0 || val [ 0 ] != " " { return " " , fmt . Errorf ( " " ) } if err != nil { return " " , err } if m [ " " ] == " " { key := m [ " " ] ifDev , ok := infiniband [ key ] if ! ok { return " " , fmt . Errorf ( " \" \" " , key ) } err := c . addInfinibandDevices ( dName , & ifDev , false ) if err != nil { return " " , err } } } if m [ " " ] == " " && m [ " " ] == " " { key := m [ " " ] ifDev , ok := infiniband [ key ] if ! ok { return " " , fmt . Errorf ( " \" \" " , key ) } err := c . addInfinibandDevices ( k , & ifDev , false ) if err != nil { return " " , err } } if m [ " " ] == " " && shared . IsTrue ( m [ " " ] ) { for i := 0 ; i < len ( c . c . ConfigItem ( networkKeyPrefix ) ) ; i ++ { val := c . c . ConfigItem ( fmt . Sprintf ( " " , networkKeyPrefix , i ) ) if len ( val ) == 0 || val [ 0 ] != m [ " " ] { continue } val = c . c . ConfigItem ( fmt . Sprintf ( " " , networkKeyPrefix , i ) ) if len ( val ) == 0 || val [ 0 ] != m [ " " ] { continue } val = c . c . ConfigItem ( fmt . Sprintf ( " " , networkKeyPrefix , i ) ) if len ( val ) == 0 { continue } vethName = val [ 0 ] break } if vethName == " " { return " " , fmt . Errorf ( " " ) } err = c . createNetworkFilter ( vethName , m [ " " ] , m [ " " ] ) if err != nil { return " " , err } } if ! shared . PathExists ( fmt . Sprintf ( " " , device ) ) { _ , err := shared . RunCommand ( " " , " " , " " , " " , m [ " " ] , " " , device , " " , " " , " " , " " , m [ " " ] ) if err != nil { return " " , err } } } } } err = c . addDiskDevices ( diskDevices , func ( name string , d types . Device ) error { _ , err := c . createDiskDevice ( name , d ) return err } ) if err != nil { return " " , err } if err != nil { return " " , err } err = os . MkdirAll ( c . DevicesPath ( ) , 0711 ) if err != nil { return " " , err } err = os . MkdirAll ( c . ShmountsPath ( ) , 0711 ) if err != nil { return " " , err } if shared . PathExists ( logfile ) { os . Remove ( logfile + " " ) err := os . Rename ( logfile , logfile + " " ) if err != nil { return " " , err } } if err != nil { return " " , err } err = c . c . SaveConfigFile ( configPath ) if err != nil { os . Remove ( configPath ) return " " , err } if err != nil { if ourStart { c . StorageStop ( ) } return " " , err } if c . isCurrentlyPrivileged ( ) { mode = 0700 } else { mode = 0711 } err = os . Chmod ( c . Path ( ) , mode ) if err != nil { if ourStart { c . StorageStop ( ) } return " " , err } if err != nil { if ourStart { c . StorageStop ( ) } return " " , err } if ! c . IsStateful ( ) && shared . PathExists ( c . StatePath ( ) ) { os . RemoveAll ( c . StatePath ( ) ) } _ , err = c . StorageStop ( ) if err != nil { return " " , err } if err != nil { return " " , fmt . Errorf ( " " , err ) } return configPath , nil } 
func ( c * containerLXC ) Stop ( stateful bool ) error { var ctxMap log . Ctx } if err != nil { return err } ctxMap = log . Ctx { " " : c . project , " " : c . name , " " : op . action , " " : c . creationDate , " " : c . ephemeral , " " : c . lastUsedDate , " " : stateful } logger . Info ( " " , ctxMap ) os . RemoveAll ( stateDir ) err := os . MkdirAll ( stateDir , 0700 ) if err != nil { op . Done ( err ) logger . Error ( " " , ctxMap ) return err } criuMigrationArgs := CriuMigrationArgs { cmd : lxc . MIGRATE_DUMP , stateDir : stateDir , function : " " , stop : true , actionScript : false , dumpDir : " " , preDumpDir : " " , } if err != nil { op . Done ( err ) logger . Error ( " " , ctxMap ) return err } err = op . Wait ( ) if err != nil && c . IsRunning ( ) { logger . Error ( " " , ctxMap ) return err } c . stateful = true err = c . state . Cluster . ContainerSetStateful ( c . id , true ) if err != nil { op . Done ( err ) logger . Error ( " " , ctxMap ) return err } op . Done ( nil ) logger . Info ( " " , ctxMap ) eventSendLifecycle ( c . project , " " , fmt . Sprintf ( " " , c . name ) , nil ) return nil } else if shared . PathExists ( c . StatePath ( ) ) { os . RemoveAll ( c . StatePath ( ) ) } if err != nil { op . Done ( err ) logger . Error ( " " , ctxMap ) return err } } else if c . state . OS . CGroupFreezerController { go func ( ) { c . Freeze ( ) freezer <- true } ( ) select { case <- freezer : case <- time . After ( time . Second * 5 ) : c . Unfreeze ( ) } } if err := c . c . Stop ( ) ; err != nil { op . Done ( err ) logger . Error ( " " , ctxMap ) return err } err = op . Wait ( ) if err != nil && c . IsRunning ( ) { logger . Error ( " " , ctxMap ) return err } logger . Info ( " " , ctxMap ) eventSendLifecycle ( c . project , " " , fmt . Sprintf ( " " , c . name ) , nil ) return nil } 
func ( c * containerLXC ) OnNetworkUp ( deviceName string , hostName string ) error { device := c . expandedDevices [ deviceName ] device [ " " ] = hostName return c . setupHostVethDevice ( device ) } 
func ( c * containerLXC ) setupHostVethDevice ( device types . Device ) error { } } if err != nil { return err } if err != nil { return err } return nil } 
func ( c * containerLXC ) Freeze ( ) error { ctxMap := log . Ctx { " " : c . project , " " : c . name , " " : c . creationDate , " " : c . ephemeral , " " : c . lastUsedDate } } return nil } } logger . Info ( " " , ctxMap ) if err != nil { ctxMap [ " " ] = err logger . Error ( " " , ctxMap ) return err } err = c . c . Freeze ( ) if err != nil { ctxMap [ " " ] = err logger . Error ( " " , ctxMap ) return err } logger . Info ( " " , ctxMap ) eventSendLifecycle ( c . project , " " , fmt . Sprintf ( " " , c . name ) , nil ) return err } 
func ( c * containerLXC ) getLxcState ( ) ( lxc . State , error ) { if c . IsSnapshot ( ) { return lxc . StateMap [ " " ] , nil } if err != nil { return lxc . StateMap [ " " ] , err } monitor := make ( chan lxc . State , 1 ) go func ( c * lxc . Container ) { monitor <- c . State ( ) } ( c . c ) select { case state := <- monitor : return state , nil case <- time . After ( 5 * time . Second ) : return lxc . StateMap [ " " ] , LxcMonitorStateError } } 
func ( c * containerLXC ) Storage ( ) storage { if c . storage == nil { c . initStorage ( ) } return c . storage } 
func ( c * containerLXC ) StorageStartSensitive ( ) ( bool , error ) { if err != nil { return false , err } var isOurOperation bool if c . IsSnapshot ( ) { isOurOperation , err = c . storage . ContainerSnapshotStart ( c ) } else { isOurOperation , err = c . storage . ContainerMount ( c ) } return isOurOperation , err } 
func ( c * containerLXC ) insertMount ( source , target , fstype string , flags int ) error { var err error if pid == - 1 { } if lxc . HasApiExtension ( " " ) { cname := projectPrefix ( c . Project ( ) , c . Name ( ) ) configPath := filepath . Join ( c . LogPath ( ) , " " ) if fstype == " " { fstype = " " } if ! strings . HasPrefix ( target , " " ) { target = " " + target } _ , err := shared . RunCommand ( c . state . OS . ExecPath , " " , " " , cname , c . state . OS . LxcPath , configPath , source , target , fstype , fmt . Sprintf ( " " , flags ) ) if err != nil { return err } } else { if shared . IsDir ( source ) { tmpMount , err = ioutil . TempDir ( c . ShmountsPath ( ) , " " ) if err != nil { return fmt . Errorf ( " " , err ) } } else { f , err := ioutil . TempFile ( c . ShmountsPath ( ) , " " ) if err != nil { return fmt . Errorf ( " " , err ) } tmpMount = f . Name ( ) f . Close ( ) } defer os . Remove ( tmpMount ) if err != nil { return fmt . Errorf ( " " , err ) } defer syscall . Unmount ( tmpMount , syscall . MNT_DETACH ) pidStr := fmt . Sprintf ( " " , pid ) out , err := shared . RunCommand ( c . state . OS . ExecPath , " " , " " , pidStr , mntsrc , target ) if out != " " { for _ , line := range strings . Split ( strings . TrimRight ( out , " \n " ) , " \n " ) { logger . Debugf ( " " , line ) } } if err != nil { return err } } return nil } 
func ( c * containerLXC ) deviceExistsInDevicesFolder ( prefix string , path string ) bool { relativeDestPath := strings . TrimPrefix ( path , " " ) devName := fmt . Sprintf ( " " , strings . Replace ( prefix , " " , " " , - 1 ) , strings . Replace ( relativeDestPath , " " , " " , - 1 ) ) devPath := filepath . Join ( c . DevicesPath ( ) , devName ) return shared . PathExists ( devPath ) } 
func ( c * containerLXC ) createUnixDevice ( prefix string , m types . Device , defaultMode bool ) ( [ ] string , error ) { var err error var major , minor int } } } srcPath := m [ " " ] if srcPath == " " { srcPath = m [ " " ] } srcPath = shared . HostPath ( srcPath ) if err != nil { return nil , fmt . Errorf ( " " , m [ " " ] , err ) } } else if m [ " " ] == " " || m [ " " ] == " " { return nil , fmt . Errorf ( " " , m [ " " ] ) } else { major , err = strconv . Atoi ( m [ " " ] ) if err != nil { return nil , fmt . Errorf ( " " , m [ " " ] , m [ " " ] ) } minor , err = strconv . Atoi ( m [ " " ] ) if err != nil { return nil , fmt . Errorf ( " " , m [ " " ] , m [ " " ] ) } } if m [ " " ] != " " { tmp , err := deviceModeOct ( m [ " " ] ) if err != nil { return nil , fmt . Errorf ( " " , m [ " " ] , m [ " " ] ) } mode = os . FileMode ( tmp ) } else if ! defaultMode { mode , err = shared . GetPathMode ( srcPath ) if err != nil { errno , isErrno := shared . GetErrno ( err ) if ! isErrno || errno != syscall . ENOENT { return nil , fmt . Errorf ( " " , m [ " " ] , err ) } mode = os . FileMode ( 0660 ) } } if m [ " " ] == " " { mode |= syscall . S_IFBLK } else { mode |= syscall . S_IFCHR } gid := 0 if m [ " " ] != " " { uid , err = strconv . Atoi ( m [ " " ] ) if err != nil { return nil , fmt . Errorf ( " " , m [ " " ] , m [ " " ] ) } } if m [ " " ] != " " { gid , err = strconv . Atoi ( m [ " " ] ) if err != nil { return nil , fmt . Errorf ( " " , m [ " " ] , m [ " " ] ) } } if err != nil { return nil , fmt . Errorf ( " " , err ) } } destPath := m [ " " ] if destPath == " " { destPath = m [ " " ] } relativeDestPath := strings . TrimPrefix ( destPath , " " ) devName := fmt . Sprintf ( " " , strings . Replace ( prefix , " " , " " , - 1 ) , strings . Replace ( relativeDestPath , " " , " " , - 1 ) ) devPath := filepath . Join ( c . DevicesPath ( ) , devName ) if err := syscall . Mknod ( devPath , uint32 ( mode ) , encoded_device_number ) ; err != nil { return nil , fmt . Errorf ( " " , devPath , m [ " " ] , err ) } if err := os . Chown ( devPath , uid , gid ) ; err != nil { return nil , fmt . Errorf ( " " , devPath , err ) } } idmapset , err := c . CurrentIdmap ( ) if err != nil { return nil , err } if idmapset != nil { if err := idmapset . ShiftFile ( devPath ) ; err != nil { } } } else { f , err := os . Create ( devPath ) if err != nil { return nil , err } f . Close ( ) err = deviceMountDisk ( srcPath , devPath , false , false , " " ) if err != nil { return nil , err } } return [ ] string { devPath , relativeDestPath } , nil } 
func ( c * containerLXC ) createNetworkDevice ( name string , m types . Device ) ( string , error ) { var dev , n1 string if shared . StringInSlice ( m [ " " ] , [ ] string { " " , " " , " " } ) { } else { n1 = deviceNextVeth ( ) } } if m [ " " ] == " " { dev = m [ " " ] } _ , err := shared . RunCommand ( " " , " " , " " , " " , n1 , " " , " " , " " , " " , n2 ) if err != nil { return " " , fmt . Errorf ( " " , err ) } _ , err = shared . RunCommand ( " " , " " , " " , " " , n1 , " " ) if err != nil { return " " , fmt . Errorf ( " " , n1 , err ) } if m [ " " ] == " " { err = networkAttachInterface ( m [ " " ] , n1 ) if err != nil { deviceRemoveInterface ( n2 ) return " " , fmt . Errorf ( " " , err ) } } dev = n2 } if m [ " " ] != " " { device = networkGetHostDevice ( m [ " " ] , m [ " " ] ) if ! shared . PathExists ( fmt . Sprintf ( " " , device ) ) { _ , err := shared . RunCommand ( " " , " " , " " , " " , m [ " " ] , " " , device , " " , " " , " " , " " , m [ " " ] ) if err != nil { return " " , err } } } } if err != nil { return " " , fmt . Errorf ( " " , err ) } dev = n1 } } if err != nil { deviceRemoveInterface ( dev ) return " " , fmt . Errorf ( " " , err ) } } if err != nil { deviceRemoveInterface ( dev ) return " " , fmt . Errorf ( " " , err ) } if err != nil { return " " , err } } return dev , nil } 
func ( c * containerLXC ) createDiskDevice ( name string , m types . Device ) ( string , error ) { devName := fmt . Sprintf ( " " , strings . Replace ( name , " " , " " , - 1 ) , strings . Replace ( relativeDestPath , " " , " " , - 1 ) ) devPath := filepath . Join ( c . DevicesPath ( ) , devName ) srcPath := shared . HostPath ( m [ " " ] ) isReadOnly := shared . IsTrue ( m [ " " ] ) isRecursive := shared . IsTrue ( m [ " " ] ) isFile := false if m [ " " ] == " " { isFile = ! shared . IsDir ( srcPath ) && ! deviceIsBlockdev ( srcPath ) } else { } volumeTypeName := " " volumeName := filepath . Clean ( m [ " " ] ) slash := strings . Index ( volumeName , " " ) if ( slash > 0 ) && ( len ( volumeName ) > slash ) { } switch volumeTypeName { case storagePoolVolumeTypeNameContainer : return " " , fmt . Errorf ( " " ) case " " : fallthrough case storagePoolVolumeTypeNameCustom : srcPath = shared . VarPath ( " " , m [ " " ] , volumeTypeName , volumeName ) case storagePoolVolumeTypeNameImage : return " " , fmt . Errorf ( " " ) default : return " " , fmt . Errorf ( " \" \" " , volumeTypeName ) } s , err := storagePoolVolumeAttachInit ( c . state , m [ " " ] , volumeName , volumeType , c ) if err != nil && ! isOptional { return " " , fmt . Errorf ( " \" \" \" \" \" \" " , volumeName , volumeTypeName , m [ " " ] , err ) } else if err == nil { _ , err = s . StoragePoolVolumeMount ( ) if err != nil { msg := fmt . Sprintf ( " \" \" \" \" \" \" " , volumeName , volumeTypeName , m [ " " ] , err ) if ! isOptional { logger . Errorf ( msg ) return " " , err } logger . Warnf ( msg ) } } } } return " " , fmt . Errorf ( " " , srcPath , name ) } if err != nil { return " " , err } } if err != nil { return " " , err } } if err != nil { return " " , err } f . Close ( ) } else { err := os . Mkdir ( devPath , 0700 ) if err != nil { return " " , err } } if err != nil { return " " , err } return devPath , nil } 
func ( c * containerLXC ) getDiskLimits ( ) ( map [ string ] deviceBlockLimit , error ) { result := map [ string ] deviceBlockLimit { } dents , err := ioutil . ReadDir ( " " ) if err != nil { return nil , err } for _ , f := range dents { fPath := filepath . Join ( " " , f . Name ( ) ) if shared . PathExists ( fmt . Sprintf ( " " , fPath ) ) { continue } if ! shared . PathExists ( fmt . Sprintf ( " " , fPath ) ) { continue } block , err := ioutil . ReadFile ( fmt . Sprintf ( " " , fPath ) ) if err != nil { return nil , err } validBlocks = append ( validBlocks , strings . TrimSuffix ( string ( block ) , " \n " ) ) } for _ , k := range c . expandedDevices . DeviceNames ( ) { m := c . expandedDevices [ k ] if m [ " " ] != " " { continue } m [ " " ] = m [ " " ] } if err != nil { return nil , err } if source == " " { source = c . RootfsPath ( ) } } if err != nil { if readBps == 0 && readIops == 0 && writeBps == 0 && writeIops == 0 { } else { return nil , err } } device := deviceBlockLimit { readBps : readBps , readIops : readIops , writeBps : writeBps , writeIops : writeIops } for _ , block := range blocks { blockStr := " " if shared . StringInSlice ( block , validBlocks ) { } else { fields [ 1 ] = " " if shared . StringInSlice ( fmt . Sprintf ( " " , fields [ 0 ] , fields [ 1 ] ) , validBlocks ) { blockStr = fmt . Sprintf ( " " , fields [ 0 ] , fields [ 1 ] ) } } if blockStr == " " { return nil , fmt . Errorf ( " " , block ) } if blockLimits [ blockStr ] == nil { blockLimits [ blockStr ] = [ ] deviceBlockLimit { } } blockLimits [ blockStr ] = append ( blockLimits [ blockStr ] , device ) } } for _ , limit := range limits { if limit . readBps > 0 { readBpsCount += 1 readBpsTotal += limit . readBps } if limit . readIops > 0 { readIopsCount += 1 readIopsTotal += limit . readIops } if limit . writeBps > 0 { writeBpsCount += 1 writeBpsTotal += limit . writeBps } if limit . writeIops > 0 { writeIopsCount += 1 writeIopsTotal += limit . writeIops } } device := deviceBlockLimit { } if readBpsCount > 0 { device . readBps = readBpsTotal / readBpsCount } if readIopsCount > 0 { device . readIops = readIopsTotal / readIopsCount } if writeBpsCount > 0 { device . writeBps = writeBpsTotal / writeBpsCount } if writeIopsCount > 0 { device . writeIops = writeIopsTotal / writeIopsCount } result [ block ] = device } return result , nil } 
func ( c * containerLXC ) setNetworkPriority ( ) error { } } if networkPriority == " " { networkPriority = " " } networkInt , err := strconv . Atoi ( networkPriority ) if err != nil { return err } if err != nil { return err } var last_error error for _ , netif := range netifs { err = c . CGroupSet ( " " , fmt . Sprintf ( " " , netif . Name , networkInt ) ) if err == nil { success = true } else { last_error = err } } if ! success { return fmt . Errorf ( " " , last_error ) } return nil } 
func ( c * containerLXC ) setNetworkRoutes ( m types . Device ) error { if ! shared . PathExists ( fmt . Sprintf ( " " , m [ " " ] ) ) { return fmt . Errorf ( " " , m [ " " ] ) } if err != nil { return err } if err != nil { return err } _ , err := shared . RunCommand ( " " , " " , " " , " " , " " , m [ " " ] , route , " " , " " ) if err != nil { return err } } } _ , err := shared . RunCommand ( " " , " " , " " , " " , " " , m [ " " ] , route , " " , " " ) if err != nil { return err } } } return nil } 
func ( c * containerLXC ) Path ( ) string { name := projectPrefix ( c . Project ( ) , c . Name ( ) ) return containerPath ( name , c . IsSnapshot ( ) ) } 
func ( c * containerLXC ) maasInterfaces ( ) ( [ ] maas . ContainerInterface , error ) { interfaces := [ ] maas . ContainerInterface { } for k , m := range c . expandedDevices { if m [ " " ] != " " { continue } if m [ " " ] == " " && m [ " " ] == " " { continue } m , err := c . fillNetworkDevice ( k , m ) if err != nil { return nil , err } subnets := [ ] maas . ContainerInterfaceSubnet { } subnets = append ( subnets , subnet ) } subnets = append ( subnets , subnet ) } iface := maas . ContainerInterface { Name : m [ " " ] , MACAddress : m [ " " ] , Subnets : subnets , } interfaces = append ( interfaces , iface ) } return interfaces , nil } 
func getSystemHandler ( syslog string , debug bool , format log . Format ) log . Handler { } return log . Must . SyslogHandler ( syslog , format ) } return nil } 
func findNvidiaMinorOld ( ) ( string , error ) { var minor string if err != nil { return " " , err } rp := regexp . MustCompile ( " " ) for _ , ent := range ents { matches := rp . FindStringSubmatch ( ent . Name ( ) ) if matches == nil { continue } if minor != " " { return " " , fmt . Errorf ( " " ) } minor = matches [ 1 ] } if minor == " " { return " " , fmt . Errorf ( " " ) } return minor , nil } 
func findNvidiaMinor ( pci string ) ( string , error ) { nvidiaPath := fmt . Sprintf ( " " , pci ) buf , err := ioutil . ReadFile ( nvidiaPath ) if err != nil { return " " , err } strBuf := strings . TrimSpace ( string ( buf ) ) idx := strings . Index ( strBuf , " " ) if idx != - 1 { idx += len ( " " ) strBuf = strBuf [ idx : ] strBuf = strings . TrimSpace ( strBuf ) parts := strings . SplitN ( strBuf , " \n " , 2 ) _ , err = strconv . Atoi ( parts [ 0 ] ) if err == nil { return parts [ 0 ] , nil } } minor , err := findNvidiaMinorOld ( ) if err == nil { return minor , nil } return " " , err } 
func GetLogger ( syslog string , logfile string , verbose bool , debug bool , customHandler log . Handler ) ( logger . Logger , error ) { Log := log . New ( ) var handlers [ ] log . Handler var syshandler log . Handler if syshandler != nil { handlers = append ( handlers , syshandler ) } } if ! debug { handlers = append ( handlers , log . LvlFilterHandler ( log . LvlInfo , log . Must . FileHandler ( logfile , LogfmtFormat ( ) ) , ) , ) } else { handlers = append ( handlers , log . Must . FileHandler ( logfile , LogfmtFormat ( ) ) ) } } if term . IsTty ( os . Stderr . Fd ( ) ) { format = TerminalFormat ( ) } if verbose || debug { if ! debug { handlers = append ( handlers , log . LvlFilterHandler ( log . LvlInfo , log . StreamHandler ( os . Stderr , format ) , ) , ) } else { handlers = append ( handlers , log . StreamHandler ( os . Stderr , format ) ) } } else { handlers = append ( handlers , log . LvlFilterHandler ( log . LvlWarn , log . StreamHandler ( os . Stderr , format ) , ) , ) } if customHandler != nil { handlers = append ( handlers , customHandler ) } Log . SetHandler ( log . MultiHandler ( handlers ... ) ) return Log , nil } 
func SetLogger ( newLogger logger . Logger ) func ( ) { origLog := logger . Log logger . Log = newLogger return func ( ) { logger . Log = origLog } } 
func WaitRecord ( ch chan * log . Record , timeout time . Duration ) * log . Record { select { case record := <- ch : return record case <- time . After ( timeout ) : return nil } } 
func AddContext ( logger logger . Logger , ctx log . Ctx ) logger . Logger { log15logger , ok := logger . ( log . Logger ) if ! ok { logger . Error ( " " , log . Ctx { " " : log15logger , " " : ctx } ) return logger } return log15logger . New ( ctx ) } 
func NewDottedVersion ( versionString string ) ( * DottedVersion , error ) { formatError := fmt . Errorf ( " " , versionString ) split := strings . Split ( versionString , " " ) if len ( split ) < 2 { return nil , formatError } maj , err := strconv . Atoi ( split [ 0 ] ) if err != nil { return nil , formatError } min , err := strconv . Atoi ( split [ 1 ] ) if err != nil { return nil , formatError } patch := - 1 if len ( split ) == 3 { patch , err = strconv . Atoi ( split [ 2 ] ) if err != nil { return nil , formatError } } return & DottedVersion { Major : maj , Minor : min , Patch : patch , } , nil } 
func Parse ( s string ) ( * DottedVersion , error ) { r , _ := regexp . Compile ( `^([0-9]+.[0-9]+(.[0-9]+))?.*` ) matches := r . FindAllStringSubmatch ( s , - 1 ) if len ( matches [ 0 ] ) < 2 { return nil , fmt . Errorf ( " " ) } return NewDottedVersion ( matches [ 0 ] [ 1 ] ) } 
func ( v * DottedVersion ) String ( ) string { version := fmt . Sprintf ( " " , v . Major , v . Minor ) if v . Patch != - 1 { version += fmt . Sprintf ( " " , v . Patch ) } return version } 
func ( v * DottedVersion ) Compare ( other * DottedVersion ) int { result := compareInts ( v . Major , other . Major ) if result != 0 { return result } result = compareInts ( v . Minor , other . Minor ) if result != 0 { return result } return compareInts ( v . Patch , other . Patch ) } 
func prepareLoopDev ( source string , flags int ) ( * os . File , error ) { cLoopDev := C . malloc ( C . size_t ( C . LO_NAME_SIZE ) ) if cLoopDev == nil { return nil , fmt . Errorf ( " " ) } defer C . free ( cLoopDev ) cSource := C . CString ( source ) defer C . free ( unsafe . Pointer ( cSource ) ) loopFd , _ := C . find_associated_loop_device ( cSource , ( * C . char ) ( cLoopDev ) ) if loopFd >= 0 { return os . NewFile ( uintptr ( loopFd ) , C . GoString ( ( * C . char ) ( cLoopDev ) ) ) , nil } loopFd , err := C . prepare_loop_dev_retry ( cSource , ( * C . char ) ( cLoopDev ) , C . int ( flags ) ) if loopFd < 0 { if err != nil { return nil , errors . Wrapf ( err , " " , source ) } return nil , fmt . Errorf ( " " , source ) } return os . NewFile ( uintptr ( loopFd ) , C . GoString ( ( * C . char ) ( cLoopDev ) ) ) , nil } 
func projectCreateDefaultProfile ( tx * db . ClusterTx , project string ) error { profile . Project = project profile . Name = " " profile . Description = fmt . Sprintf ( " " , project ) profile . Config = map [ string ] string { } profile . Devices = types . Devices { } _ , err := tx . ProfileCreate ( profile ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func projectChange ( d * Daemon , project * api . Project , req api . ProjectPut ) Response { } if ! projectIsEmpty ( project ) && featuresChanged { return BadRequest ( fmt . Errorf ( " " ) ) } if err != nil { return BadRequest ( err ) } if err != nil { return errors . Wrap ( err , " " ) } if req . Config [ " " ] != project . Config [ " " ] { if req . Config [ " " ] == " " { err = projectCreateDefaultProfile ( tx , project . Name ) if err != nil { return err } } else { if err != nil { return errors . Wrap ( err , " " ) } } } return nil } ) if err != nil { return SmartError ( err ) } return EmptySyncResponse } 
func projectIsEmpty ( project * api . Project ) bool { if len ( project . UsedBy ) > 0 { } return false } return true } 
func projectPrefix ( project string , s string ) string { if project != " " { s = fmt . Sprintf ( " " , project , s ) } return s } 
func ( r * ProtocolLXD ) GetCertificateFingerprints ( ) ( [ ] string , error ) { certificates := [ ] string { } if err != nil { return nil , err } for _ , fingerprint := range certificates { fields := strings . Split ( fingerprint , " " ) fingerprints = append ( fingerprints , fields [ len ( fields ) - 1 ] ) } return fingerprints , nil } 
func ( r * ProtocolLXD ) GetCertificates ( ) ( [ ] api . Certificate , error ) { certificates := [ ] api . Certificate { } if err != nil { return nil , err } return certificates , nil } 
func ( r * ProtocolLXD ) GetCertificate ( fingerprint string ) ( * api . Certificate , string , error ) { certificate := api . Certificate { } if err != nil { return nil , " " , err } return & certificate , etag , nil } 
func ( r * ProtocolLXD ) CreateCertificate ( certificate api . CertificatesPost ) error { if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) UpdateCertificate ( fingerprint string , certificate api . CertificatePut , ETag string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) DeleteCertificate ( fingerprint string ) error { if err != nil { return err } return nil } 
func containerMetadataTemplatesGet ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) name := mux . Vars ( r ) [ " " ] if err != nil { return SmartError ( err ) } if response != nil { return response } if err != nil { return SmartError ( err ) } if err != nil { return SmartError ( err ) } if ourStart { defer c . StorageStop ( ) } if templateName == " " { filesInfo , err := ioutil . ReadDir ( templatesPath ) if err != nil { return InternalError ( err ) } templates := [ ] string { } for _ , info := range filesInfo { if ! info . IsDir ( ) { templates = append ( templates , info . Name ( ) ) } } return SyncResponse ( true , templates ) } if err != nil { return SmartError ( err ) } if ! shared . PathExists ( templatePath ) { return NotFound ( fmt . Errorf ( " " , templatePath ) ) } if err != nil { return SmartError ( err ) } defer template . Close ( ) tempfile , err := ioutil . TempFile ( " " , " " ) if err != nil { return SmartError ( err ) } defer tempfile . Close ( ) _ , err = io . Copy ( tempfile , template ) if err != nil { return InternalError ( err ) } files := make ( [ ] fileResponseEntry , 1 ) files [ 0 ] . identifier = templateName files [ 0 ] . path = tempfile . Name ( ) files [ 0 ] . filename = templateName return FileResponse ( r , files , nil , true ) } 
func containerMetadataTemplatesPostPut ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) name := mux . Vars ( r ) [ " " ] if err != nil { return SmartError ( err ) } if response != nil { return response } if err != nil { return SmartError ( err ) } if err != nil { return SmartError ( err ) } if ourStart { defer c . StorageStop ( ) } if templateName == " " { return BadRequest ( fmt . Errorf ( " " ) ) } if err != nil { return SmartError ( err ) } if r . Method == " " && shared . PathExists ( templatePath ) { return BadRequest ( fmt . Errorf ( " " ) ) } if err != nil { return SmartError ( err ) } defer template . Close ( ) _ , err = io . Copy ( template , r . Body ) if err != nil { return InternalError ( err ) } return EmptySyncResponse } 
func containerMetadataTemplatesDelete ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) name := mux . Vars ( r ) [ " " ] if err != nil { return SmartError ( err ) } if response != nil { return response } if err != nil { return SmartError ( err ) } if err != nil { return SmartError ( err ) } if ourStart { defer c . StorageStop ( ) } if templateName == " " { return BadRequest ( fmt . Errorf ( " " ) ) } templatePath , err := getContainerTemplatePath ( c , templateName ) if err != nil { return SmartError ( err ) } if ! shared . PathExists ( templatePath ) { return NotFound ( fmt . Errorf ( " " , templatePath ) ) } if err != nil { return InternalError ( err ) } return EmptySyncResponse } 
func getContainerTemplatePath ( c container , filename string ) ( string , error ) { if strings . Contains ( filename , " " ) { return " " , fmt . Errorf ( " " ) } return filepath . Join ( c . Path ( ) , " " , filename ) , nil } 
func ( e Error ) Error ( ) string { message := fmt . Sprintf ( " " , e . Name ) if e . Value != nil { message += fmt . Sprintf ( " " , e . Value ) } return message + fmt . Sprintf ( " " , e . Reason ) } 
func ( l ErrorList ) Error ( ) string { switch len ( l ) { case 0 : return " " case 1 : return l [ 0 ] . Error ( ) } return fmt . Sprintf ( " " , l [ 0 ] , len ( l ) - 1 ) } 
func ( l * ErrorList ) add ( name string , value interface { } , reason string ) { * l = append ( * l , & Error { name , value , reason } ) } 
func UpdateSchema ( ) error { err := cluster . SchemaDotGo ( ) if err != nil { return errors . Wrap ( err , " " ) } err = node . SchemaDotGo ( ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func doProfileUpdateCluster ( d * Daemon , project , name string , old api . ProfilePut ) error { nodeName := " " err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error nodeName , err = tx . NodeName ( ) return err } ) if err != nil { return errors . Wrap ( err , " " ) } containers , err := getProfileContainersInfo ( d . cluster , project , name ) if err != nil { return errors . Wrapf ( err , " " , name ) } failures := map [ string ] error { } for _ , args := range containers { err := doProfileUpdateContainer ( d , name , old , nodeName , args ) if err != nil { failures [ args . Name ] = err } } if len ( failures ) != 0 { msg := " \n " for cname , err := range failures { msg += fmt . Sprintf ( " \n " , cname , err ) } return fmt . Errorf ( " " , msg ) } return nil } 
func doProfileUpdateContainer ( d * Daemon , name string , old api . ProfilePut , nodeName string , args db . ContainerArgs ) error { if args . Node != " " && args . Node != nodeName { } profiles , err := d . cluster . ProfilesGet ( args . Project , args . Profiles ) if err != nil { return err } for i , profileName := range args . Profiles { if profileName == name { profiles [ i ] . Devices = old . Devices break } } c := containerLXCInstantiate ( d . State ( ) , args ) c . expandConfig ( profiles ) c . expandDevices ( profiles ) return c . Update ( db . ContainerArgs { Architecture : c . Architecture ( ) , Config : c . LocalConfig ( ) , Description : c . Description ( ) , Devices : c . LocalDevices ( ) , Ephemeral : c . IsEphemeral ( ) , Profiles : c . Profiles ( ) , Project : c . Project ( ) , } , true ) } 
func getProfileContainersInfo ( cluster * db . Cluster , project , profile string ) ( [ ] db . ContainerArgs , error ) { if err != nil { return nil , errors . Wrapf ( err , " " , profile ) } containers := [ ] db . ContainerArgs { } err = cluster . Transaction ( func ( tx * db . ClusterTx ) error { for ctProject , ctNames := range names { for _ , ctName := range ctNames { container , err := tx . ContainerGet ( ctProject , ctName ) if err != nil { return err } containers = append ( containers , db . ContainerToArgs ( container ) ) } } return nil } ) if err != nil { return nil , errors . Wrapf ( err , " " ) } return containers , nil } 
func CancelableWait ( rawOp interface { } , progress * ProgressRenderer ) error { var op lxd . Operation var rop lxd . RemoteOperation case lxd . RemoteOperation : rop = v default : return fmt . Errorf ( " " ) } signal . Notify ( chSignal , os . Interrupt ) go func ( ) { if op != nil { chOperation <- op . Wait ( ) } else { chOperation <- rop . Wait ( ) } close ( chOperation ) } ( ) count := 0 for { var err error select { case err := <- chOperation : return err case <- chSignal : if op != nil { err = op . Cancel ( ) } else { err = rop . CancelTarget ( ) } if err == nil { return fmt . Errorf ( i18n . G ( " " ) ) } count ++ if count == 3 { return fmt . Errorf ( i18n . G ( " " ) ) } if progress != nil { progress . Warn ( fmt . Sprintf ( i18n . G ( " " ) , err ) , time . Second * 5 ) } } } } 
func ( r * ProtocolLXD ) GetNetworkNames ( ) ( [ ] string , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } urls := [ ] string { } if err != nil { return nil , err } for _ , url := range urls { fields := strings . Split ( url , " " ) names = append ( names , fields [ len ( fields ) - 1 ] ) } return names , nil } 
func ( r * ProtocolLXD ) GetNetworks ( ) ( [ ] api . Network , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } networks := [ ] api . Network { } if err != nil { return nil , err } return networks , nil } 
func ( r * ProtocolLXD ) GetNetwork ( name string ) ( * api . Network , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } network := api . Network { } if err != nil { return nil , " " , err } return & network , etag , nil } 
func ( r * ProtocolLXD ) GetNetworkLeases ( name string ) ( [ ] api . NetworkLease , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } leases := [ ] api . NetworkLease { } if err != nil { return nil , err } return leases , nil } 
func ( r * ProtocolLXD ) GetNetworkState ( name string ) ( * api . NetworkState , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } state := api . NetworkState { } if err != nil { return nil , err } return & state , nil } 
func ( r * ProtocolLXD ) CreateNetwork ( network api . NetworksPost ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) UpdateNetwork ( name string , network api . NetworkPut , ETag string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) RenameNetwork ( name string , network api . NetworkPost ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func Open ( name string , store dqlite . ServerStore , options ... dqlite . DriverOption ) ( * sql . DB , error ) { driver , err := dqlite . NewDriver ( store , options ... ) if err != nil { return nil , errors . Wrap ( err , " " ) } driverName := dqliteDriverName ( ) sql . Register ( driverName , driver ) } db , err := sql . Open ( driverName , name ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return db , nil } 
func EnsureSchema ( db * sql . DB , address string , dir string ) ( bool , error ) { someNodesAreBehind := false apiExtensions := version . APIExtensionsCount ( ) backupDone := false hook := ( func ( version int , tx * sql . Tx ) error { if err != nil { return errors . Wrap ( err , " " ) } if ! isUpdate { return nil } n , err := selectUnclusteredNodesCount ( tx ) if err != nil { return errors . Wrap ( err , " " ) } if n > 1 { } else if n == 1 { clustered = false } err := shared . DirCopy ( filepath . Join ( dir , " " ) , filepath . Join ( dir , " " ) , ) if err != nil { return errors . Wrap ( err , " " ) } backupDone = true } if version == - 1 { logger . Debugf ( " " ) } else { logger . Debugf ( " " , version , version + 1 ) } return nil } ) check := func ( current int , tx * sql . Tx ) error { } if err != nil { return errors . Wrap ( err , " " ) } if n > 1 { } else if n == 1 { address = " " } if err != nil { return errors . Wrap ( err , " " ) } err = checkClusterIsUpgradable ( tx , [ 2 ] int { len ( updates ) , apiExtensions } ) if err == errSomeNodesAreBehind { someNodesAreBehind = true return schema . ErrGracefulAbort } return err } schema := Schema ( ) schema . File ( filepath . Join ( dir , " " ) ) schema . Check ( check ) schema . Hook ( hook ) var initial int err := query . Retry ( func ( ) error { var err error initial , err = schema . Ensure ( db ) return err } ) if someNodesAreBehind { return false , nil } if err != nil { return false , err } if err != nil { return false , err } stmt := ` INSERT INTO nodes(id, name, address, schema, api_extensions) VALUES(1, 'none', '0.0.0.0', ?, ?) ` _ , err = tx . Exec ( stmt , SchemaVersion , apiExtensions ) if err != nil { tx . Rollback ( ) return false , err } INSERT INTO projects (name, description) VALUES ('default', 'Default LXD project'); INSERT INTO projects_config (project_id, key, value) VALUES (1, 'features.images', 'true'); INSERT INTO projects_config (project_id, key, value) VALUES (1, 'features.profiles', 'true'); ` _ , err = tx . Exec ( stmt ) if err != nil { tx . Rollback ( ) return false , err } INSERT INTO profiles (name, description, project_id) VALUES ('default', 'Default LXD profile', 1) ` _ , err = tx . Exec ( stmt ) if err != nil { tx . Rollback ( ) return false , err } err = tx . Commit ( ) if err != nil { return false , err } } return true , err } 
func URLEncode ( path string , query map [ string ] string ) ( string , error ) { u , err := url . Parse ( path ) if err != nil { return " " , err } params := url . Values { } for key , value := range query { params . Add ( key , value ) } u . RawQuery = params . Encode ( ) return u . String ( ) , nil } 
func IsUnixSocket ( path string ) bool { stat , err := os . Stat ( path ) if err != nil { return false } return ( stat . Mode ( ) & os . ModeSocket ) == os . ModeSocket } 
func HostPath ( path string ) string { } } snapName := os . Getenv ( " " ) if snap == " " || snapName != " " { return path } if ppid < 1 { return path } pwd , err := os . Readlink ( fmt . Sprintf ( " " , ppid ) ) if err != nil { return path } path = filepath . Clean ( strings . Join ( [ ] string { pwd , path } , string ( os . PathSeparator ) ) ) } } } return fmt . Sprintf ( " " , path ) } 
func VarPath ( path ... string ) string { varDir := os . Getenv ( " " ) if varDir == " " { varDir = " " } items := [ ] string { varDir } items = append ( items , path ... ) return filepath . Join ( items ... ) } 
func CachePath ( path ... string ) string { varDir := os . Getenv ( " " ) logDir := " " if varDir != " " { logDir = filepath . Join ( varDir , " " ) } items := [ ] string { logDir } items = append ( items , path ... ) return filepath . Join ( items ... ) } 
func RandomCryptoString ( ) ( string , error ) { buf := make ( [ ] byte , 32 ) n , err := rand . Read ( buf ) if err != nil { return " " , err } if n != len ( buf ) { return " " , fmt . Errorf ( " " ) } return hex . EncodeToString ( buf ) , nil } 
func FileMove ( oldPath string , newPath string ) error { err := os . Rename ( oldPath , newPath ) if err == nil { return nil } err = FileCopy ( oldPath , newPath ) if err != nil { return err } os . Remove ( oldPath ) return nil } 
func FileCopy ( source string , dest string ) error { s , err := os . Open ( source ) if err != nil { return err } defer s . Close ( ) fi , err := s . Stat ( ) if err != nil { return err } d , err := os . Create ( dest ) if err != nil { if os . IsExist ( err ) { d , err = os . OpenFile ( dest , os . O_WRONLY , fi . Mode ( ) ) if err != nil { return err } } else { return err } } defer d . Close ( ) _ , err = io . Copy ( d , s ) if err != nil { return err } if runtime . GOOS != " " { _ , uid , gid := GetOwnerMode ( fi ) return d . Chown ( uid , gid ) } return nil } 
func DirCopy ( source string , dest string ) error { if err != nil { return errors . Wrapf ( err , " " ) } if ! info . IsDir ( ) { return fmt . Errorf ( " " ) } if err != nil { return errors . Wrapf ( err , " " , dest ) } } if err != nil { return errors . Wrapf ( err , " " , dest ) } if err != nil { return errors . Wrapf ( err , " " , source ) } for _ , entry := range entries { sourcePath := filepath . Join ( source , entry . Name ( ) ) destPath := filepath . Join ( dest , entry . Name ( ) ) if entry . IsDir ( ) { err := DirCopy ( sourcePath , destPath ) if err != nil { return errors . Wrapf ( err , " " , sourcePath , destPath ) } } else { err := FileCopy ( sourcePath , destPath ) if err != nil { return errors . Wrapf ( err , " " , sourcePath , destPath ) } } } return nil } 
func StringMapHasStringKey ( m map [ string ] string , keys ... string ) bool { for _ , k := range keys { if _ , ok := m [ k ] ; ok { return true } } return false } 
func DeepCopy ( src , dest interface { } ) error { buff := new ( bytes . Buffer ) enc := gob . NewEncoder ( buff ) dec := gob . NewDecoder ( buff ) if err := enc . Encode ( src ) ; err != nil { return err } if err := dec . Decode ( dest ) ; err != nil { return err } return nil } 
func TextEditor ( inPath string , inContent [ ] byte ) ( [ ] byte , error ) { var f * os . File var err error var path string if editor == " " { editor = os . Getenv ( " " ) if editor == " " { for _ , p := range [ ] string { " " , " " , " " , " " } { _ , err := exec . LookPath ( p ) if err == nil { editor = p break } } if editor == " " { return [ ] byte { } , fmt . Errorf ( " " ) } } } if inPath == " " { if err != nil { return [ ] byte { } , err } err = os . Chmod ( f . Name ( ) , 0600 ) if err != nil { f . Close ( ) os . Remove ( f . Name ( ) ) return [ ] byte { } , err } f . Write ( inContent ) f . Close ( ) path = fmt . Sprintf ( " " , f . Name ( ) ) os . Rename ( f . Name ( ) , path ) defer os . Remove ( path ) } else { path = inPath } cmdParts := strings . Fields ( editor ) cmd := exec . Command ( cmdParts [ 0 ] , append ( cmdParts [ 1 : ] , path ) ... ) cmd . Stdin = os . Stdin cmd . Stdout = os . Stdout cmd . Stderr = os . Stderr err = cmd . Run ( ) if err != nil { return [ ] byte { } , err } content , err := ioutil . ReadFile ( path ) if err != nil { return [ ] byte { } , err } return content , nil } 
func ParseByteSizeString ( input string ) ( int64 , error ) { } for i , chr := range [ ] byte ( input ) { _ , err := strconv . Atoi ( string ( [ ] byte { chr } ) ) if err != nil { suffixLen = len ( input ) - i break } } if suffixLen == len ( input ) { return - 1 , fmt . Errorf ( " " , input ) } valueInt , err := strconv . ParseInt ( value , 10 , 64 ) if err != nil { return - 1 , fmt . Errorf ( " " , input ) } switch suffix { case " " , " " , " " : multiplicator = 1 case " " : multiplicator = 1000 case " " : multiplicator = 1000 * 1000 case " " : multiplicator = 1000 * 1000 * 1000 case " " : multiplicator = 1000 * 1000 * 1000 * 1000 case " " : multiplicator = 1000 * 1000 * 1000 * 1000 * 1000 case " " : multiplicator = 1000 * 1000 * 1000 * 1000 * 1000 * 1000 case " " : multiplicator = 1024 case " " : multiplicator = 1024 * 1024 case " " : multiplicator = 1024 * 1024 * 1024 case " " : multiplicator = 1024 * 1024 * 1024 * 1024 case " " : multiplicator = 1024 * 1024 * 1024 * 1024 * 1024 case " " : multiplicator = 1024 * 1024 * 1024 * 1024 * 1024 * 1024 default : return - 1 , fmt . Errorf ( " " , input ) } return valueInt * multiplicator , nil } 
func RemoveDuplicatesFromString ( s string , sep string ) string { dup := sep + sep for s = strings . Replace ( s , dup , sep , - 1 ) ; strings . Contains ( s , dup ) ; s = strings . Replace ( s , dup , sep , - 1 ) { } return s } 
func WriteTempFile ( dir string , prefix string , content string ) ( string , error ) { f , err := ioutil . TempFile ( dir , prefix ) if err != nil { return " " , err } defer f . Close ( ) _ , err = f . WriteString ( content ) return f . Name ( ) , err } 
func EscapePathFstab ( path string ) string { r := strings . NewReplacer ( " " , " \\ " , " \t " , " \\ " , " \n " , " \\ " , " \\ " , " \\ \\ " ) return r . Replace ( path ) } 
func RenderTemplate ( template string , ctx pongo2 . Context ) ( string , error ) { if err != nil { return " " , err } if err != nil { return ret , err } } return ret , err } 
func Every ( interval time . Duration , options ... EveryOption ) Schedule { every := & every { } for _ , option := range options { option ( every ) } first := true return func ( ) ( time . Duration , error ) { var err error if first && every . skipFirst { err = ErrSkip } first = false return interval , err } } 
func ( s * storageLvm ) StorageCoreInit ( ) error { s . sType = storageTypeLvm typeName , err := storageTypeToString ( s . sType ) if err != nil { return err } s . sTypeName = typeName if lvmVersion != " " { s . sTypeVersion = lvmVersion return nil } output , err := shared . RunCommand ( " " , " " ) if err != nil { return fmt . Errorf ( " \n " , err , output ) } lines := strings . Split ( output , " \n " ) s . sTypeVersion = " " for idx , line := range lines { fields := strings . SplitAfterN ( line , " " , 2 ) if len ( fields ) < 2 { continue } if idx > 0 { s . sTypeVersion += " " } s . sTypeVersion += strings . TrimSpace ( fields [ 1 ] ) } lvmVersion = s . sTypeVersion return nil } 
func ( s * storageLvm ) StoragePoolMount ( ) ( bool , error ) { source := s . pool . Config [ " " ] if source == " " { return false , fmt . Errorf ( " \" \" " ) } if ! filepath . IsAbs ( source ) { return true , nil } poolMountLockID := getPoolMountLockID ( s . pool . Name ) lxdStorageMapLock . Lock ( ) if waitChannel , ok := lxdStorageOngoingOperationMap [ poolMountLockID ] ; ok { lxdStorageMapLock . Unlock ( ) if _ , ok := <- waitChannel ; ok { logger . Warnf ( " " ) } } lxdStorageOngoingOperationMap [ poolMountLockID ] = make ( chan bool ) lxdStorageMapLock . Unlock ( ) removeLockFromMap := func ( ) { lxdStorageMapLock . Lock ( ) if waitChannel , ok := lxdStorageOngoingOperationMap [ poolMountLockID ] ; ok { close ( waitChannel ) delete ( lxdStorageOngoingOperationMap , poolMountLockID ) } lxdStorageMapLock . Unlock ( ) } defer removeLockFromMap ( ) if filepath . IsAbs ( source ) && ! shared . IsBlockdevPath ( source ) { if loopErr != nil { return false , loopErr } if loopErr != nil { return false , loopErr } s . loopInfo = loopF } return true , nil } 
func Dump ( tx * sql . Tx , schema string , schemaOnly bool ) ( string , error ) { schemas := dumpParseSchema ( schema ) BEGIN TRANSACTION; ` if err != nil { return " " , errors . Wrapf ( err , " " ) } dump += tableDump for table := range schemas { tables = append ( tables , table ) } sort . Strings ( tables ) for _ , table := range tables { if schemaOnly { continue } tableDump , err := dumpTable ( tx , table , schemas [ table ] ) if err != nil { return " " , errors . Wrapf ( err , " " , table ) } dump += tableDump } if err != nil { return " " , errors . Wrapf ( err , " " ) } dump += tableDump } return dump , nil } 
func dumpParseSchema ( schema string ) map [ string ] string { tables := map [ string ] string { } for _ , statement := range strings . Split ( schema , " " ) { statement = strings . Trim ( statement , " \n " ) + " " if ! strings . HasPrefix ( statement , " " ) { continue } table := strings . Split ( statement , " " ) [ 2 ] tables [ table ] = statement } return tables } 
func dumpTable ( tx * sql . Tx , table , schema string ) ( string , error ) { statements := [ ] string { schema } if err != nil { return " " , errors . Wrap ( err , " " ) } defer rows . Close ( ) if err != nil { return " " , errors . Wrap ( err , " " ) } row := make ( [ ] interface { } , len ( columns ) ) for i := range raw { row [ i ] = & raw [ i ] } err := rows . Scan ( row ... ) if err != nil { return " " , errors . Wrapf ( err , " " , i ) } values := make ( [ ] string , len ( columns ) ) for j , v := range raw { switch v := v . ( type ) { case int64 : values [ j ] = strconv . FormatInt ( v , 10 ) case string : values [ j ] = fmt . Sprintf ( " " , v ) case [ ] byte : values [ j ] = fmt . Sprintf ( " " , string ( v ) ) case time . Time : values [ j ] = strconv . FormatInt ( v . Unix ( ) , 10 ) default : if v != nil { return " " , fmt . Errorf ( " " , columns [ j ] , i ) } values [ j ] = " " } } statement := fmt . Sprintf ( " " , table , strings . Join ( values , " " ) ) statements = append ( statements , statement ) } return strings . Join ( statements , " \n " ) + " \n " , nil } 
func ( c * ClusterTx ) ProjectHasProfiles ( name string ) ( bool , error ) { return projectHasProfiles ( c . tx , name ) } 
func ( c * ClusterTx ) ProjectNames ( ) ( [ ] string , error ) { stmt := " " names , err := query . SelectStrings ( c . tx , stmt ) if err != nil { return nil , errors . Wrap ( err , " " ) } return names , nil } 
func ( c * ClusterTx ) ProjectMap ( ) ( map [ int64 ] string , error ) { stmt := " " rows , err := c . tx . Query ( stmt ) if err != nil { return nil , err } defer rows . Close ( ) result := map [ int64 ] string { } for i := 0 ; rows . Next ( ) ; i ++ { var id int64 var name string err := rows . Scan ( & id , & name ) if err != nil { return nil , err } result [ id ] = name } err = rows . Err ( ) if err != nil { return nil , err } return result , nil } 
func ( c * ClusterTx ) ProjectHasImages ( name string ) ( bool , error ) { project , err := c . ProjectGet ( name ) if err != nil { return false , errors . Wrap ( err , " " ) } enabled := project . Config [ " " ] == " " return enabled , nil } 
func ( c * ClusterTx ) ProjectUpdate ( name string , object api . ProjectPut ) error { stmt := c . stmt ( projectUpdate ) result , err := stmt . Exec ( object . Description , name ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } id , err := c . ProjectID ( name ) if err != nil { return errors . Wrap ( err , " " ) } DELETE FROM projects_config WHERE projects_config.project_id = ? ` , id ) if err != nil { return errors . Wrap ( err , " " ) } for key , value := range object . Config { _ , err := stmt . Exec ( id , key , value ) if err != nil { return errors . Wrap ( err , " " ) } } return nil } 
func ( r * ProtocolLXD ) GetCluster ( ) ( * api . Cluster , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } cluster := & api . Cluster { } etag , err := r . queryStruct ( " " , " " , nil , " " , & cluster ) if err != nil { return nil , " " , err } return cluster , etag , nil } 
func ( r * ProtocolLXD ) UpdateCluster ( cluster api . ClusterPut , ETag string ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if cluster . ServerAddress != " " || cluster . ClusterPassword != " " || len ( cluster . MemberConfig ) > 0 { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } op , _ , err := r . queryOperation ( " " , " " , cluster , " " ) if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) DeleteClusterMember ( name string , force bool ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } params := " " if force { params += " " } _ , err := r . queryStruct ( " " , fmt . Sprintf ( " " , name , params ) , nil , " " , nil ) if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) GetClusterMemberNames ( ) ( [ ] string , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } urls := [ ] string { } _ , err := r . queryStruct ( " " , " " , nil , " " , & urls ) if err != nil { return nil , err } return urls , nil } 
func ( r * ProtocolLXD ) GetClusterMembers ( ) ( [ ] api . ClusterMember , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } members := [ ] api . ClusterMember { } _ , err := r . queryStruct ( " " , " " , nil , " " , & members ) if err != nil { return nil , err } return members , nil } 
func ( r * ProtocolLXD ) GetClusterMember ( name string ) ( * api . ClusterMember , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } member := api . ClusterMember { } etag , err := r . queryStruct ( " " , fmt . Sprintf ( " " , name ) , nil , " " , & member ) if err != nil { return nil , " " , err } return & member , etag , nil } 
func ( r * ProtocolLXD ) RenameClusterMember ( name string , member api . ClusterMemberPost ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } _ , _ , err := r . query ( " " , fmt . Sprintf ( " " , name ) , member , " " ) if err != nil { return err } return nil } 
func GetState ( fd int ) ( * State , error ) { state , err := terminal . GetState ( fd ) if err != nil { return nil , err } currentState := State ( * state ) return & currentState , nil } 
func MakeRaw ( fd int ) ( * State , error ) { state , err := terminal . MakeRaw ( fd ) if err != nil { return nil , err } oldState := State ( * state ) return & oldState , nil } 
func Restore ( fd int , state * State ) error { newState := terminal . State ( * state ) return terminal . Restore ( fd , & newState ) } 
func ( e * EventListener ) AddHandler ( types [ ] string , function func ( api . Event ) ) ( * EventTarget , error ) { if function == nil { return nil , fmt . Errorf ( " " ) } defer e . targetsLock . Unlock ( ) return & target , nil } 
func ( e * EventListener ) RemoveHandler ( target * EventTarget ) error { if target == nil { return fmt . Errorf ( " " ) } defer e . targetsLock . Unlock ( ) e . targets [ len ( e . targets ) - 1 ] = nil e . targets = e . targets [ : len ( e . targets ) - 1 ] return nil } } return fmt . Errorf ( " " ) } 
func ( e * EventListener ) Disconnect ( ) { if e . disconnected { return } defer e . r . eventListenersLock . Unlock ( ) e . r . eventListeners [ len ( e . r . eventListeners ) - 1 ] = nil e . r . eventListeners = e . r . eventListeners [ : len ( e . r . eventListeners ) - 1 ] break } } e . disconnected = true close ( e . chActive ) } 
func CompareVersions ( version1 , version2 [ 2 ] int ) ( int , error ) { schema1 , extensions1 := version1 [ 0 ] , version1 [ 1 ] schema2 , extensions2 := version2 [ 0 ] , version2 [ 1 ] if schema1 == schema2 && extensions1 == extensions2 { return 0 , nil } if schema1 >= schema2 && extensions1 >= extensions2 { return 1 , nil } if schema1 <= schema2 && extensions1 <= extensions2 { return 2 , nil } return - 1 , fmt . Errorf ( " " ) } 
func ( c * Config ) HasClientCertificate ( ) bool { certf := c . ConfigPath ( " " ) keyf := c . ConfigPath ( " " ) if ! shared . PathExists ( certf ) || ! shared . PathExists ( keyf ) { return false } return true } 
func ( c * Config ) GenerateClientCertificate ( ) error { if c . HasClientCertificate ( ) { return nil } certf := c . ConfigPath ( " " ) keyf := c . ConfigPath ( " " ) return shared . FindOrGenCert ( certf , keyf , true ) } 
func LoadModule ( module string ) error { if shared . PathExists ( fmt . Sprintf ( " " , module ) ) { return nil } _ , err := shared . RunCommand ( " " , module ) return err } 
func Parse ( name string ) ( * ast . Package , error ) { base := os . Getenv ( " " ) if base == " " { base = " " } dir := filepath . Join ( base , " " , name ) fset := token . NewFileSet ( ) paths , err := filepath . Glob ( filepath . Join ( dir , " " ) ) if err != nil { return nil , errors . Wrap ( err , " " ) } files := map [ string ] * ast . File { } for _ , path := range paths { } file , err := parser . ParseFile ( fset , path , nil , parser . ParseComments ) if err != nil { return nil , fmt . Errorf ( " " , path ) } files [ path ] = file } return pkg , nil } 
func ( e * Endpoints ) PprofAddress ( ) string { e . mu . RLock ( ) defer e . mu . RUnlock ( ) listener := e . listeners [ pprof ] if listener == nil { return " " } return listener . Addr ( ) . String ( ) } 
func ( e * Endpoints ) PprofUpdateAddress ( address string ) error { if address != " " { address = util . CanonicalNetworkAddress ( address ) } oldAddress := e . NetworkAddress ( ) if address == oldAddress { return nil } logger . Infof ( " " ) e . mu . Lock ( ) defer e . mu . Unlock ( ) } var listener net . Listener for i := 0 ; i < 10 ; i ++ { if err == nil { break } time . Sleep ( 100 * time . Millisecond ) } if err != nil { return nil , fmt . Errorf ( " " , err ) } return & listener , nil } if err != nil { if err1 == nil { e . listeners [ pprof ] = * listener e . serveHTTP ( pprof ) } return err } e . listeners [ pprof ] = * listener e . serveHTTP ( pprof ) } return nil } 
func NewMethod ( database , pkg , entity , kind string , config map [ string ] string ) ( * Method , error ) { packages , err := Packages ( ) if err != nil { return nil , err } method := & Method { db : database , pkg : pkg , entity : entity , kind : kind , config : config , packages : packages , } return method , nil } 
func ( m * Method ) Generate ( buf * file . Buffer ) error { if strings . HasSuffix ( m . kind , " " ) { return m . ref ( buf ) } switch m . kind { case " " : return m . uris ( buf ) case " " : return m . list ( buf ) case " " : return m . get ( buf ) case " " : return m . id ( buf ) case " " : return m . exists ( buf ) case " " : return m . create ( buf ) case " " : return m . rename ( buf ) case " " : return m . update ( buf ) case " " : return m . delete ( buf ) default : return fmt . Errorf ( " " , m . kind ) } } 
func ( m * Method ) fillSliceReferenceField ( buf * file . Buffer , nk [ ] * Field , field * Field ) error { objectsVar := fmt . Sprintf ( " " , lex . Minuscule ( field . Name ) ) methodName := fmt . Sprintf ( " " , lex . Capital ( m . entity ) , field . Name ) buf . L ( " " , field . Name ) buf . L ( " " , objectsVar , methodName ) buf . L ( " " ) buf . L ( " \" \" " , field . Name ) buf . L ( " " ) buf . N ( ) buf . L ( " " ) needle := " " for i , key := range nk [ : len ( nk ) - 1 ] { needle += fmt . Sprintf ( " " , key . Name ) subIndexTyp := indexType ( nk [ i + 1 : ] , field . Type . Name ) buf . L ( " " , objectsVar , needle ) buf . L ( " " ) buf . L ( " " , subIndexTyp ) buf . L ( " " , objectsVar , needle ) buf . L ( " " ) buf . N ( ) } needle += fmt . Sprintf ( " " , nk [ len ( nk ) - 1 ] . Name ) buf . L ( " " , objectsVar , needle ) buf . L ( " " ) buf . L ( " " , field . Type . Name ) buf . L ( " " ) buf . L ( " " , field . Name ) buf . L ( " " ) buf . N ( ) return nil } 
func ( c * ClusterTx ) StoragePoolsNodeConfig ( ) ( map [ string ] map [ string ] string , error ) { names , err := query . SelectStrings ( c . tx , " " ) if err != nil { return nil , err } pools := make ( map [ string ] map [ string ] string , len ( names ) ) for _ , name := range names { table := ` storage_pools_config JOIN storage_pools ON storage_pools.id=storage_pools_config.storage_pool_id ` config , err := query . SelectConfig ( c . tx , table , " " , name , c . nodeID ) if err != nil { return nil , err } pools [ name ] = config } return pools , nil } 
func ( c * ClusterTx ) StoragePoolID ( name string ) ( int64 , error ) { stmt := " " ids , err := query . SelectIntegers ( c . tx , stmt , name ) if err != nil { return - 1 , err } switch len ( ids ) { case 0 : return - 1 , ErrNoSuchObject case 1 : return int64 ( ids [ 0 ] ) , nil default : return - 1 , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) StoragePoolDriver ( id int64 ) ( string , error ) { stmt := " " drivers , err := query . SelectStrings ( c . tx , stmt , id ) if err != nil { return " " , err } switch len ( drivers ) { case 0 : return " " , ErrNoSuchObject case 1 : return drivers [ 0 ] , nil default : return " " , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) StoragePoolIDsNotPending ( ) ( map [ string ] int64 , error ) { pools := [ ] struct { id int64 name string } { } dest := func ( i int ) [ ] interface { } { pools = append ( pools , struct { id int64 name string } { } ) return [ ] interface { } { & pools [ i ] . id , & pools [ i ] . name } } stmt , err := c . tx . Prepare ( " " ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , storagePoolPending ) if err != nil { return nil , err } ids := map [ string ] int64 { } for _ , pool := range pools { ids [ pool . name ] = pool . id } return ids , nil } 
func ( c * ClusterTx ) StoragePoolNodeJoin ( poolID , nodeID int64 ) error { columns := [ ] string { " " , " " } values := [ ] interface { } { poolID , nodeID } _ , err := query . UpsertObject ( c . tx , " " , columns , values ) if err != nil { return errors . Wrap ( err , " " ) } return nil } 
func ( c * ClusterTx ) StoragePoolNodeJoinCeph ( poolID , nodeID int64 ) error { nodeIDs , err := query . SelectIntegers ( c . tx , stmt , poolID ) if err != nil { return errors . Wrap ( err , " " ) } if len ( nodeIDs ) == 0 { return fmt . Errorf ( " " ) } otherNodeID := nodeIDs [ 0 ] INSERT INTO storage_volumes(name, storage_pool_id, node_id, type, description, project_id) SELECT name, storage_pool_id, ?, type, description, 1 FROM storage_volumes WHERE storage_pool_id=? AND node_id=? ` , nodeID , poolID , otherNodeID ) if err != nil { return errors . Wrap ( err , " " ) } SELECT id FROM storage_volumes WHERE storage_pool_id=? AND node_id=? ORDER BY name, type ` volumeIDs , err := query . SelectIntegers ( c . tx , stmt , poolID , nodeID ) if err != nil { return errors . Wrap ( err , " " ) } otherVolumeIDs , err := query . SelectIntegers ( c . tx , stmt , poolID , otherNodeID ) if err != nil { return errors . Wrap ( err , " " ) } if len ( volumeIDs ) != len ( otherVolumeIDs ) { } for i , otherVolumeID := range otherVolumeIDs { config , err := query . SelectConfig ( c . tx , " " , " " , otherVolumeID ) if err != nil { return errors . Wrap ( err , " " ) } for key , value := range config { _ , err := c . tx . Exec ( ` INSERT INTO storage_volumes_config(storage_volume_id, key, value) VALUES(?, ?, ?) ` , volumeIDs [ i ] , key , value ) if err != nil { return errors . Wrap ( err , " " ) } } } return nil } 
func ( c * ClusterTx ) StoragePoolConfigAdd ( poolID , nodeID int64 , config map [ string ] string ) error { return storagePoolConfigAdd ( c . tx , poolID , nodeID , config ) } 
func ( c * ClusterTx ) StoragePoolCreatePending ( node , name , driver string , conf map [ string ] string ) error { driver string state int } { } var errConsistency error dest := func ( i int ) [ ] interface { } { } return [ ] interface { } { & pool . id , & pool . driver , & pool . state } } stmt , err := c . tx . Prepare ( " " ) if err != nil { return err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , name ) if err != nil { return err } if errConsistency != nil { return errConsistency } var poolID = pool . id if poolID == 0 { values := [ ] interface { } { name , driver } poolID , err = query . UpsertObject ( c . tx , " " , columns , values ) if err != nil { return err } } else { } if pool . state != storagePoolPending { return fmt . Errorf ( " " ) } } if err != nil { return err } if err != nil { return err } if count != 0 { return ErrAlreadyDefined } values := [ ] interface { } { poolID , nodeInfo . ID } _ , err = query . UpsertObject ( c . tx , " " , columns , values ) if err != nil { return err } err = c . StoragePoolConfigAdd ( poolID , nodeInfo . ID , conf ) if err != nil { return err } return nil } 
func ( c * ClusterTx ) StoragePoolCreated ( name string ) error { return c . storagePoolState ( name , storagePoolCreated ) } 
func ( c * ClusterTx ) StoragePoolErrored ( name string ) error { return c . storagePoolState ( name , storagePoolErrored ) } 
func ( c * ClusterTx ) StoragePoolNodeConfigs ( poolID int64 ) ( map [ string ] map [ string ] string , error ) { if err != nil { return nil , err } SELECT nodes.name FROM nodes LEFT JOIN storage_pools_nodes ON storage_pools_nodes.node_id = nodes.id LEFT JOIN storage_pools ON storage_pools_nodes.storage_pool_id = storage_pools.id WHERE storage_pools.id = ? AND storage_pools.state = ? ` defined , err := query . SelectStrings ( c . tx , stmt , poolID , storagePoolPending ) if err != nil { return nil , err } for _ , node := range nodes { if ! shared . StringInSlice ( node . Name , defined ) { missing = append ( missing , node . Name ) } } if len ( missing ) > 0 { return nil , fmt . Errorf ( " " , strings . Join ( missing , " " ) ) } configs := map [ string ] map [ string ] string { } for _ , node := range nodes { config , err := query . SelectConfig ( c . tx , " " , " " , poolID , node . ID ) if err != nil { return nil , err } configs [ node . Name ] = config } return configs , nil } 
func ( c * Cluster ) storagePools ( where string , args ... interface { } ) ( [ ] string , error ) { var name string stmt := " " inargs := [ ] interface { } { } outargs := [ ] interface { } { name } if where != " " { stmt += fmt . Sprintf ( " " , where ) for _ , arg := range args { inargs = append ( inargs , arg ) } } result , err := queryScan ( c . db , stmt , inargs , outargs ) if err != nil { return [ ] string { } , err } if len ( result ) == 0 { return [ ] string { } , ErrNoSuchObject } pools := [ ] string { } for _ , r := range result { pools = append ( pools , r [ 0 ] . ( string ) ) } return pools , nil } 
func ( c * Cluster ) StoragePoolsGetDrivers ( ) ( [ ] string , error ) { var poolDriver string query := " " inargs := [ ] interface { } { } outargs := [ ] interface { } { poolDriver } result , err := queryScan ( c . db , query , inargs , outargs ) if err != nil { return [ ] string { } , err } if len ( result ) == 0 { return [ ] string { } , ErrNoSuchObject } drivers := [ ] string { } for _ , driver := range result { drivers = append ( drivers , driver [ 0 ] . ( string ) ) } return drivers , nil } 
func ( c * Cluster ) StoragePoolGetID ( poolName string ) ( int64 , error ) { poolID := int64 ( - 1 ) query := " " inargs := [ ] interface { } { poolName } outargs := [ ] interface { } { & poolID } err := dbQueryRowScan ( c . db , query , inargs , outargs ) if err != nil { if err == sql . ErrNoRows { return - 1 , ErrNoSuchObject } } return poolID , nil } 
func ( c * Cluster ) StoragePoolGet ( poolName string ) ( int64 , * api . StoragePool , error ) { var poolDriver string poolID := int64 ( - 1 ) description := sql . NullString { } var state int query := " " inargs := [ ] interface { } { poolName } outargs := [ ] interface { } { & poolID , & poolDriver , & description , & state } err := dbQueryRowScan ( c . db , query , inargs , outargs ) if err != nil { if err == sql . ErrNoRows { return - 1 , nil , ErrNoSuchObject } return - 1 , nil , err } config , err := c . StoragePoolConfigGet ( poolID ) if err != nil { return - 1 , nil , err } storagePool := api . StoragePool { Name : poolName , Driver : poolDriver , } storagePool . Description = description . String storagePool . Config = config switch state { case storagePoolPending : storagePool . Status = " " case storagePoolCreated : storagePool . Status = " " default : storagePool . Status = " " } nodes , err := c . storagePoolNodes ( poolID ) if err != nil { return - 1 , nil , err } storagePool . Locations = nodes return poolID , & storagePool , nil } 
func ( c * Cluster ) storagePoolNodes ( poolID int64 ) ( [ ] string , error ) { stmt := ` SELECT nodes.name FROM nodes JOIN storage_pools_nodes ON storage_pools_nodes.node_id = nodes.id WHERE storage_pools_nodes.storage_pool_id = ? ` var nodes [ ] string err := c . Transaction ( func ( tx * ClusterTx ) error { var err error nodes , err = query . SelectStrings ( tx . tx , stmt , poolID ) return err } ) if err != nil { return nil , err } return nodes , nil } 
func ( c * Cluster ) StoragePoolConfigGet ( poolID int64 ) ( map [ string ] string , error ) { var key , value string query := " " inargs := [ ] interface { } { poolID , c . nodeID } outargs := [ ] interface { } { key , value } results , err := queryScan ( c . db , query , inargs , outargs ) if err != nil { return nil , err } config := map [ string ] string { } for _ , r := range results { key = r [ 0 ] . ( string ) value = r [ 1 ] . ( string ) config [ key ] = value } return config , nil } 
func ( c * Cluster ) StoragePoolCreate ( poolName string , poolDescription string , poolDriver string , poolConfig map [ string ] string ) ( int64 , error ) { var id int64 err := c . Transaction ( func ( tx * ClusterTx ) error { result , err := tx . tx . Exec ( " " , poolName , poolDescription , poolDriver , storagePoolCreated ) if err != nil { return err } id , err = result . LastInsertId ( ) if err != nil { return err } values := [ ] interface { } { id , c . nodeID } _ , err = query . UpsertObject ( tx . tx , " " , columns , values ) if err != nil { return err } err = storagePoolConfigAdd ( tx . tx , id , c . nodeID , poolConfig ) if err != nil { return err } return nil } ) if err != nil { id = - 1 } return id , nil } 
func storagePoolConfigAdd ( tx * sql . Tx , poolID , nodeID int64 , poolConfig map [ string ] string ) error { str := " " stmt , err := tx . Prepare ( str ) defer stmt . Close ( ) if err != nil { return err } for k , v := range poolConfig { if v == " " { continue } var nodeIDValue interface { } if ! shared . StringInSlice ( k , StoragePoolNodeConfigKeys ) { nodeIDValue = nil } else { nodeIDValue = nodeID } _ , err = stmt . Exec ( poolID , nodeIDValue , k , v ) if err != nil { return err } } return nil } 
func storagePoolDriverGet ( tx * sql . Tx , id int64 ) ( string , error ) { stmt := " " drivers , err := query . SelectStrings ( tx , stmt , id ) if err != nil { return " " , err } switch len ( drivers ) { case 0 : return " " , ErrNoSuchObject case 1 : return drivers [ 0 ] , nil default : return " " , fmt . Errorf ( " " ) } } 
func ( c * Cluster ) StoragePoolUpdate ( poolName , description string , poolConfig map [ string ] string ) error { poolID , _ , err := c . StoragePoolGet ( poolName ) if err != nil { return err } err = c . Transaction ( func ( tx * ClusterTx ) error { err = StoragePoolUpdateDescription ( tx . tx , poolID , description ) if err != nil { return err } err = StoragePoolConfigClear ( tx . tx , poolID , c . nodeID ) if err != nil { return err } err = storagePoolConfigAdd ( tx . tx , poolID , c . nodeID , poolConfig ) if err != nil { return err } return nil } ) return err } 
func StoragePoolConfigClear ( tx * sql . Tx , poolID , nodeID int64 ) error { _ , err := tx . Exec ( " " , poolID , nodeID ) if err != nil { return err } return nil } 
func ( c * Cluster ) StoragePoolDelete ( poolName string ) ( * api . StoragePool , error ) { poolID , pool , err := c . StoragePoolGet ( poolName ) if err != nil { return nil , err } err = exec ( c . db , " " , poolID ) if err != nil { return nil , err } return pool , nil } 
func ( c * Cluster ) StoragePoolVolumesGetNames ( poolID int64 ) ( [ ] string , error ) { var volumeName string query := " " inargs := [ ] interface { } { poolID , c . nodeID } outargs := [ ] interface { } { volumeName } result , err := queryScan ( c . db , query , inargs , outargs ) if err != nil { return [ ] string { } , err } var out [ ] string for _ , r := range result { out = append ( out , r [ 0 ] . ( string ) ) } return out , nil } 
func ( c * Cluster ) StoragePoolVolumesGet ( project string , poolID int64 , volumeTypes [ ] int ) ( [ ] * api . StorageVolume , error ) { var nodeIDs [ ] int err := c . Transaction ( func ( tx * ClusterTx ) error { var err error nodeIDs , err = query . SelectIntegers ( tx . tx , ` SELECT DISTINCT node_id FROM storage_volumes JOIN projects ON projects.id = storage_volumes.project_id WHERE (projects.name=? OR storage_volumes.type=?) AND storage_pool_id=? ` , project , StoragePoolVolumeTypeCustom , poolID ) return err } ) if err != nil { return nil , err } volumes := [ ] * api . StorageVolume { } for _ , nodeID := range nodeIDs { nodeVolumes , err := c . storagePoolVolumesGet ( project , poolID , int64 ( nodeID ) , volumeTypes ) if err != nil { return nil , err } volumes = append ( volumes , nodeVolumes ... ) } return volumes , nil } 
func ( c * Cluster ) StoragePoolNodeVolumesGet ( poolID int64 , volumeTypes [ ] int ) ( [ ] * api . StorageVolume , error ) { return c . storagePoolVolumesGet ( " " , poolID , c . nodeID , volumeTypes ) } 
func ( c * Cluster ) storagePoolVolumesGet ( project string , poolID , nodeID int64 , volumeTypes [ ] int ) ( [ ] * api . StorageVolume , error ) { for _ , volumeType := range volumeTypes { volumeNames , err := c . StoragePoolVolumesGetType ( project , volumeType , poolID , nodeID ) if err != nil && err != sql . ErrNoRows { return nil , errors . Wrap ( err , " " ) } for _ , volumeName := range volumeNames { _ , volume , err := c . StoragePoolVolumeGetType ( project , volumeName , volumeType , poolID , nodeID ) if err != nil { return nil , errors . Wrap ( err , " " ) } result = append ( result , volume ) } } if len ( result ) == 0 { return result , ErrNoSuchObject } return result , nil } 
func ( c * Cluster ) StoragePoolVolumesGetType ( project string , volumeType int , poolID , nodeID int64 ) ( [ ] string , error ) { var poolName string query := ` SELECT storage_volumes.name FROM storage_volumes JOIN projects ON projects.id=storage_volumes.project_id WHERE (projects.name=? OR storage_volumes.type=?) AND storage_pool_id=? AND node_id=? AND type=? ` inargs := [ ] interface { } { project , StoragePoolVolumeTypeCustom , poolID , nodeID , volumeType } outargs := [ ] interface { } { poolName } result , err := queryScan ( c . db , query , inargs , outargs ) if err != nil { return [ ] string { } , err } response := [ ] string { } for _ , r := range result { response = append ( response , r [ 0 ] . ( string ) ) } return response , nil } 
func ( c * Cluster ) StoragePoolVolumeSnapshotsGetType ( volumeName string , volumeType int , poolID int64 ) ( [ ] string , error ) { result := [ ] string { } regexp := volumeName + shared . SnapshotDelimiter length := len ( regexp ) query := " " inargs := [ ] interface { } { poolID , c . nodeID , volumeType , true , length , regexp } outfmt := [ ] interface { } { volumeName } dbResults , err := queryScan ( c . db , query , inargs , outfmt ) if err != nil { return result , err } for _ , r := range dbResults { result = append ( result , r [ 0 ] . ( string ) ) } return result , nil } 
func ( c * Cluster ) StoragePoolNodeVolumesGetType ( volumeType int , poolID int64 ) ( [ ] string , error ) { return c . StoragePoolVolumesGetType ( " " , volumeType , poolID , c . nodeID ) } 
func ( c * Cluster ) StoragePoolVolumeGetType ( project string , volumeName string , volumeType int , poolID , nodeID int64 ) ( int64 , * api . StorageVolume , error ) { } volumeID , err := c . StoragePoolVolumeGetTypeID ( project , volumeName , volumeType , poolID , nodeID ) if err != nil { return - 1 , nil , err } volumeNode , err := c . StorageVolumeNodeGet ( volumeID ) if err != nil { return - 1 , nil , err } volumeConfig , err := c . StorageVolumeConfigGet ( volumeID ) if err != nil { return - 1 , nil , err } volumeDescription , err := c . StorageVolumeDescriptionGet ( volumeID ) if err != nil { return - 1 , nil , err } volumeTypeName , err := StoragePoolVolumeTypeToName ( volumeType ) if err != nil { return - 1 , nil , err } storageVolume := api . StorageVolume { Type : volumeTypeName , } storageVolume . Name = volumeName storageVolume . Description = volumeDescription storageVolume . Config = volumeConfig storageVolume . Location = volumeNode return volumeID , & storageVolume , nil } 
func ( c * Cluster ) StoragePoolNodeVolumeGetType ( volumeName string , volumeType int , poolID int64 ) ( int64 , * api . StorageVolume , error ) { return c . StoragePoolNodeVolumeGetTypeByProject ( " " , volumeName , volumeType , poolID ) } 
func ( c * Cluster ) StoragePoolNodeVolumeGetTypeByProject ( project , volumeName string , volumeType int , poolID int64 ) ( int64 , * api . StorageVolume , error ) { return c . StoragePoolVolumeGetType ( project , volumeName , volumeType , poolID , c . nodeID ) } 
func ( c * Cluster ) StoragePoolVolumeUpdate ( volumeName string , volumeType int , poolID int64 , volumeDescription string , volumeConfig map [ string ] string ) error { volumeID , _ , err := c . StoragePoolNodeVolumeGetType ( volumeName , volumeType , poolID ) if err != nil { return err } err = c . Transaction ( func ( tx * ClusterTx ) error { err = storagePoolVolumeReplicateIfCeph ( tx . tx , volumeID , " " , volumeName , volumeType , poolID , func ( volumeID int64 ) error { err = StorageVolumeConfigClear ( tx . tx , volumeID ) if err != nil { return err } err = StorageVolumeConfigAdd ( tx . tx , volumeID , volumeConfig ) if err != nil { return err } return StorageVolumeDescriptionUpdate ( tx . tx , volumeID , volumeDescription ) } ) if err != nil { return err } return nil } ) return err } 
func ( c * Cluster ) StoragePoolVolumeDelete ( project , volumeName string , volumeType int , poolID int64 ) error { volumeID , _ , err := c . StoragePoolNodeVolumeGetTypeByProject ( project , volumeName , volumeType , poolID ) if err != nil { return err } err = c . Transaction ( func ( tx * ClusterTx ) error { err := storagePoolVolumeReplicateIfCeph ( tx . tx , volumeID , project , volumeName , volumeType , poolID , func ( volumeID int64 ) error { _ , err := tx . tx . Exec ( " " , volumeID ) return err } ) return err } ) return err } 
func ( c * Cluster ) StoragePoolVolumeRename ( project , oldVolumeName string , newVolumeName string , volumeType int , poolID int64 ) error { volumeID , _ , err := c . StoragePoolNodeVolumeGetTypeByProject ( project , oldVolumeName , volumeType , poolID ) if err != nil { return err } err = c . Transaction ( func ( tx * ClusterTx ) error { err := storagePoolVolumeReplicateIfCeph ( tx . tx , volumeID , project , oldVolumeName , volumeType , poolID , func ( volumeID int64 ) error { _ , err := tx . tx . Exec ( " " , newVolumeName , volumeID , volumeType ) return err } ) return err } ) return err } 
func storagePoolVolumeReplicateIfCeph ( tx * sql . Tx , volumeID int64 , project , volumeName string , volumeType int , poolID int64 , f func ( int64 ) error ) error { driver , err := storagePoolDriverGet ( tx , poolID ) if err != nil { return err } volumeIDs := [ ] int64 { volumeID } if err != nil { return err } } for _ , volumeID := range volumeIDs { err := f ( volumeID ) if err != nil { return err } } return nil } 
func ( c * Cluster ) StoragePoolVolumeCreate ( project , volumeName , volumeDescription string , volumeType int , snapshot bool , poolID int64 , volumeConfig map [ string ] string ) ( int64 , error ) { var thisVolumeID int64 err := c . Transaction ( func ( tx * ClusterTx ) error { nodeIDs := [ ] int { int ( c . nodeID ) } driver , err := storagePoolDriverGet ( tx . tx , poolID ) if err != nil { return err } if err != nil { return err } } for _ , nodeID := range nodeIDs { result , err := tx . tx . Exec ( ` INSERT INTO storage_volumes (storage_pool_id, node_id, type, snapshot, name, description, project_id) VALUES (?, ?, ?, ?, ?, ?, (SELECT id FROM projects WHERE name = ?)) ` , poolID , nodeID , volumeType , snapshot , volumeName , volumeDescription , project ) if err != nil { return err } volumeID , err := result . LastInsertId ( ) if err != nil { return err } if int64 ( nodeID ) == c . nodeID { } err = StorageVolumeConfigAdd ( tx . tx , volumeID , volumeConfig ) if err != nil { tx . tx . Rollback ( ) return err } } return nil } ) if err != nil { thisVolumeID = - 1 } return thisVolumeID , err } 
func ( c * Cluster ) StoragePoolVolumeGetTypeID ( project string , volumeName string , volumeType int , poolID , nodeID int64 ) ( int64 , error ) { volumeID := int64 ( - 1 ) query := `SELECT storage_volumes.id FROM storage_volumes JOIN storage_pools ON storage_volumes.storage_pool_id = storage_pools.id JOIN projects ON storage_volumes.project_id = projects.id WHERE projects.name=? AND storage_volumes.storage_pool_id=? AND storage_volumes.node_id=? AND storage_volumes.name=? AND storage_volumes.type=?` inargs := [ ] interface { } { project , poolID , nodeID , volumeName , volumeType } outargs := [ ] interface { } { & volumeID } err := dbQueryRowScan ( c . db , query , inargs , outargs ) if err != nil { if err == sql . ErrNoRows { return - 1 , ErrNoSuchObject } return - 1 , err } return volumeID , nil } 
func ( c * Cluster ) StoragePoolNodeVolumeGetTypeID ( volumeName string , volumeType int , poolID int64 ) ( int64 , error ) { return c . StoragePoolVolumeGetTypeID ( " " , volumeName , volumeType , poolID , c . nodeID ) } 
func StoragePoolVolumeTypeToName ( volumeType int ) ( string , error ) { switch volumeType { case StoragePoolVolumeTypeContainer : return StoragePoolVolumeTypeNameContainer , nil case StoragePoolVolumeTypeImage : return StoragePoolVolumeTypeNameImage , nil case StoragePoolVolumeTypeCustom : return StoragePoolVolumeTypeNameCustom , nil } return " " , fmt . Errorf ( " " ) } 
func DevicesAdd ( tx * sql . Tx , w string , cID int64 , devices types . Devices ) error { stmt1 , err := tx . Prepare ( str1 ) if err != nil { return err } defer stmt1 . Close ( ) stmt2 , err := tx . Prepare ( str2 ) if err != nil { return err } defer stmt2 . Close ( ) if err != nil { return err } result , err := stmt1 . Exec ( cID , k , t ) if err != nil { return err } id64 , err := result . LastInsertId ( ) if err != nil { return fmt . Errorf ( " " , k ) } id := int ( id64 ) for ck , cv := range v { } _ , err = stmt2 . Exec ( id , ck , cv ) if err != nil { return err } } } return nil } 
func ( c * Cluster ) Devices ( project , qName string , isprofile bool ) ( types . Devices , error ) { err := c . Transaction ( func ( tx * ClusterTx ) error { enabled , err := tx . ProjectHasProfiles ( project ) if err != nil { return err } if ! enabled { project = " " } return nil } ) if err != nil { return nil , err } var q string if isprofile { q = `SELECT profiles_devices.id, profiles_devices.name, profiles_devices.type FROM profiles_devices JOIN profiles ON profiles_devices.profile_id = profiles.id JOIN projects ON projects.id=profiles.project_id WHERE projects.name=? AND profiles.name=?` } else { q = `SELECT containers_devices.id, containers_devices.name, containers_devices.type FROM containers_devices JOIN containers ON containers_devices.container_id = containers.id JOIN projects ON projects.id=containers.project_id WHERE projects.name=? AND containers.name=?` } var id , dtype int var name , stype string inargs := [ ] interface { } { project , qName } outfmt := [ ] interface { } { id , name , dtype } results , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return nil , err } devices := types . Devices { } for _ , r := range results { id = r [ 0 ] . ( int ) name = r [ 1 ] . ( string ) stype , err = dbDeviceTypeToString ( r [ 2 ] . ( int ) ) if err != nil { return nil , err } newdev , err := dbDeviceConfig ( c . db , id , isprofile ) if err != nil { return nil , err } newdev [ " " ] = stype devices [ name ] = newdev } return devices , nil } 
func ( n * Node ) Patches ( ) ( [ ] string , error ) { inargs := [ ] interface { } { } outfmt := [ ] interface { } { " " } query := fmt . Sprintf ( " " ) result , err := queryScan ( n . db , query , inargs , outfmt ) if err != nil { return [ ] string { } , err } response := [ ] string { } for _ , r := range result { response = append ( response , r [ 0 ] . ( string ) ) } return response , nil } 
func ( n * Node ) PatchesMarkApplied ( patch string ) error { stmt := `INSERT INTO patches (name, applied_at) VALUES (?, strftime("%s"));` _ , err := n . db . Exec ( stmt , patch ) return err } 
func entityType ( pkg string , entity string ) string { typ := lex . Capital ( entity ) if pkg != " " { typ = pkg + " " + typ } return typ } 
func entityPost ( entity string ) string { return fmt . Sprintf ( " " , lex . Capital ( lex . Plural ( entity ) ) ) } 
func stmtCodeVar ( entity string , kind string , filters ... string ) string { name := fmt . Sprintf ( " " , entity , lex . Camel ( kind ) ) if len ( filters ) > 0 { name += " " name += strings . Join ( filters , " " ) } return name } 
func activeCriteria ( filter [ ] string ) string { expr := " " for i , name := range filter { if i > 0 { expr += " " } expr += fmt . Sprintf ( " " , name ) } return expr } 
func destFunc ( slice string , typ string , fields [ ] * Field ) string { f := fmt . Sprintf ( `func(i int) []interface{} { %s = append(%s, %s{}) return []interface{}{ ` , slice , slice , typ ) for _ , field := range fields { f += fmt . Sprintf ( " \n " , slice , field . Name ) } f += " \n " f += " " return f } 
func indexType ( fields [ ] * Field , typ string ) string { index := " " for range fields { index += " " } index += typ return index } 
func CompareConfigs ( config1 , config2 map [ string ] string , exclude [ ] string ) error { if exclude == nil { exclude = [ ] string { } } delta := [ ] string { } for key , value := range config1 { if shared . StringInSlice ( key , exclude ) { continue } if config2 [ key ] != value { delta = append ( delta , key ) } } for key , value := range config2 { if shared . StringInSlice ( key , exclude ) { continue } if config1 [ key ] != value { present := false for i := range delta { if delta [ i ] == key { present = true } break } if ! present { delta = append ( delta , key ) } } } sort . Strings ( delta ) if len ( delta ) > 0 { return fmt . Errorf ( " " , strings . Join ( delta , " " ) ) } return nil } 
func CopyConfig ( config map [ string ] string ) map [ string ] string { copy := map [ string ] string { } for key , value := range config { copy [ key ] = value } return copy } 
func NewNotifier ( state * state . State , cert * shared . CertInfo , policy NotifierPolicy ) ( Notifier , error ) { address , err := node . ClusterAddress ( state . Node ) if err != nil { return nil , errors . Wrap ( err , " " ) } return nullNotifier , nil } peers := [ ] string { } err = state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { offlineThreshold , err := tx . NodeOfflineThreshold ( ) if err != nil { return err } nodes , err := tx . Nodes ( ) if err != nil { return err } for _ , node := range nodes { if node . Address == address || node . Address == " " { continue } if node . IsOffline ( offlineThreshold ) { switch policy { case NotifyAll : return fmt . Errorf ( " " , node . Address ) case NotifyAlive : continue } } peers = append ( peers , node . Address ) } return nil } ) if err != nil { return nil , err } notifier := func ( hook func ( lxd . ContainerServer ) error ) error { errs := make ( [ ] error , len ( peers ) ) wg := sync . WaitGroup { } wg . Add ( len ( peers ) ) for i , address := range peers { logger . Debugf ( " " , address ) go func ( i int , address string ) { defer wg . Done ( ) client , err := Connect ( address , cert , true ) if err != nil { errs [ i ] = errors . Wrapf ( err , " " , address ) return } err = hook ( client ) if err != nil { errs [ i ] = errors . Wrapf ( err , " " , address ) } } ( i , address ) } wg . Wait ( ) continue } return err } } return nil } return notifier , nil } 
func Events ( endpoints * endpoints . Endpoints , cluster * db . Cluster , f func ( int64 , api . Event ) ) ( task . Func , task . Schedule ) { listeners := map [ int64 ] * lxd . EventListener { } go func ( ) { eventsUpdateListeners ( endpoints , cluster , listeners , f ) ch <- struct { } { } } ( ) select { case <- ch : case <- ctx . Done ( ) : } } schedule := task . Every ( time . Second ) return update , schedule } 
func eventsConnect ( address string , cert * shared . CertInfo ) ( * lxd . EventListener , error ) { client , err := Connect ( address , cert , true ) if err != nil { return nil , err } return client . GetEvents ( ) } 
func ( e * IdmapEntry ) shift_into_ns ( id int64 ) ( int64 , error ) { if id < e . Nsid || id >= e . Nsid + e . Maprange { } return id - e . Nsid + e . Hostid , nil } 
func Extend ( slice [ ] IdmapEntry , element IdmapEntry ) [ ] IdmapEntry { n := len ( slice ) if n == cap ( slice ) { copy ( newSlice , slice ) slice = newSlice } slice = slice [ 0 : n + 1 ] slice [ n ] = element return slice } 
func ( m * IdmapSet ) AddSafe ( i IdmapEntry ) error { result := [ ] IdmapEntry { } added := false for _ , e := range m . Idmap { if ! e . Intersects ( i ) { result = append ( result , e ) continue } if e . HostidsIntersect ( i ) { return ErrHostIdIsSubId } added = true lower := IdmapEntry { Isuid : e . Isuid , Isgid : e . Isgid , Hostid : e . Hostid , Nsid : e . Nsid , Maprange : i . Nsid - e . Nsid , } upper := IdmapEntry { Isuid : e . Isuid , Isgid : e . Isgid , Hostid : e . Hostid + lower . Maprange + i . Maprange , Nsid : i . Nsid + i . Maprange , Maprange : e . Maprange - i . Maprange - lower . Maprange , } if lower . Maprange > 0 { result = append ( result , lower ) } result = append ( result , i ) if upper . Maprange > 0 { result = append ( result , upper ) } } if ! added { result = append ( result , i ) } m . Idmap = result return nil } 
func getFromShadow ( fname string , username string ) ( [ ] [ ] int64 , error ) { entries := [ ] [ ] int64 { } f , err := os . Open ( fname ) if err != nil { return nil , err } defer f . Close ( ) scanner := bufio . NewScanner ( f ) for scanner . Scan ( ) { if len ( s [ 0 ] ) == 0 { continue } if len ( s ) < 3 { return nil , fmt . Errorf ( " " , fname , s ) } if strings . EqualFold ( s [ 0 ] , username ) { if err != nil { continue } if err != nil { continue } entries = append ( entries , [ ] int64 { int64 ( entryStart ) , int64 ( entrySize ) } ) } } if len ( entries ) == 0 { return nil , fmt . Errorf ( " " , username , path . Base ( fname ) ) } return entries , nil } 
func getFromProc ( fname string ) ( [ ] [ ] int64 , error ) { entries := [ ] [ ] int64 { } f , err := os . Open ( fname ) if err != nil { return nil , err } defer f . Close ( ) scanner := bufio . NewScanner ( f ) for scanner . Scan ( ) { if len ( s [ 0 ] ) == 0 { continue } if len ( s ) < 3 { return nil , fmt . Errorf ( " " , fname , s ) } if err != nil { continue } if err != nil { continue } if err != nil { continue } entries = append ( entries , [ ] int64 { int64 ( entryStart ) , int64 ( entryHost ) , int64 ( entrySize ) } ) } if len ( entries ) == 0 { return nil , fmt . Errorf ( " " ) } return entries , nil } 
func DefaultIdmapSet ( rootfs string , username string ) ( * IdmapSet , error ) { idmapset := new ( IdmapSet ) if username == " " { currentUser , err := user . Current ( ) if err != nil { return nil , err } username = currentUser . Username } subgidPath := path . Join ( rootfs , " " ) if shared . PathExists ( subuidPath ) && shared . PathExists ( subgidPath ) { if err != nil { return nil , err } for _ , entry := range entries { } e := IdmapEntry { Isuid : true , Nsid : 0 , Hostid : entry [ 0 ] , Maprange : entry [ 1 ] } idmapset . Idmap = Extend ( idmapset . Idmap , e ) } if err != nil { return nil , err } for _ , entry := range entries { } e := IdmapEntry { Isgid : true , Nsid : 0 , Hostid : entry [ 0 ] , Maprange : entry [ 1 ] } idmapset . Idmap = Extend ( idmapset . Idmap , e ) } return idmapset , nil } if err != nil { idmapset . Idmap = Extend ( idmapset . Idmap , e ) e = IdmapEntry { Isuid : false , Isgid : true , Nsid : 0 , Hostid : 1000000 , Maprange : 1000000000 } idmapset . Idmap = Extend ( idmapset . Idmap , e ) return idmapset , nil } if err != nil { return nil , err } if reflect . DeepEqual ( kernelRanges , fullKernelRanges ) { idmapset . Idmap = Extend ( idmapset . Idmap , e ) e = IdmapEntry { Isuid : false , Isgid : true , Nsid : 0 , Hostid : 1000000 , Maprange : 1000000000 } idmapset . Idmap = Extend ( idmapset . Idmap , e ) return idmapset , nil } } } } } idmapset . Idmap = Extend ( idmapset . Idmap , e ) } } } } } idmapset . Idmap = Extend ( idmapset . Idmap , e ) } return idmapset , nil } 
func CurrentIdmapSet ( ) ( * IdmapSet , error ) { idmapset := new ( IdmapSet ) if shared . PathExists ( " " ) { if err != nil { return nil , err } for _ , entry := range entries { e := IdmapEntry { Isuid : true , Nsid : entry [ 0 ] , Hostid : entry [ 1 ] , Maprange : entry [ 2 ] } idmapset . Idmap = Extend ( idmapset . Idmap , e ) } } else { idmapset . Idmap = Extend ( idmapset . Idmap , e ) } if shared . PathExists ( " " ) { if err != nil { return nil , err } for _ , entry := range entries { e := IdmapEntry { Isgid : true , Nsid : entry [ 0 ] , Hostid : entry [ 1 ] , Maprange : entry [ 2 ] } idmapset . Idmap = Extend ( idmapset . Idmap , e ) } } else { idmapset . Idmap = Extend ( idmapset . Idmap , e ) } return idmapset , nil } 
func ( s * storageDir ) StorageCoreInit ( ) error { s . sType = storageTypeDir typeName , err := storageTypeToString ( s . sType ) if err != nil { return err } s . sTypeName = typeName s . sTypeVersion = " " return nil } 
func ( s * storageDir ) StoragePoolInit ( ) error { err := s . StorageCoreInit ( ) if err != nil { return err } return nil } 
func ( s * storageDir ) StoragePoolVolumeCreate ( ) error { logger . Infof ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) _ , err := s . StoragePoolMount ( ) if err != nil { return err } source := s . pool . Config [ " " ] if source == " " { return fmt . Errorf ( " \" \" " ) } isSnapshot := shared . IsSnapshot ( s . volume . Name ) var storageVolumePath string if isSnapshot { storageVolumePath = getStoragePoolVolumeSnapshotMountPoint ( s . pool . Name , s . volume . Name ) } else { storageVolumePath = getStoragePoolVolumeMountPoint ( s . pool . Name , s . volume . Name ) } err = os . MkdirAll ( storageVolumePath , 0711 ) if err != nil { return err } err = s . initQuota ( storageVolumePath , s . volumeID ) if err != nil { return err } logger . Infof ( " \" \" \" \" " , s . volume . Name , s . pool . Name ) return nil } 
func UserId ( name string ) ( int , error ) { var pw C . struct_passwd var result * C . struct_passwd bufSize := C . sysconf ( C . _SC_GETPW_R_SIZE_MAX ) if bufSize < 0 { bufSize = 4096 } buf := C . malloc ( C . size_t ( bufSize ) ) if buf == nil { return - 1 , fmt . Errorf ( " " ) } defer C . free ( buf ) cname := C . CString ( name ) defer C . free ( unsafe . Pointer ( cname ) ) again : rv , errno := C . getpwnam_r ( cname , & pw , ( * C . char ) ( buf ) , C . size_t ( bufSize ) , & result ) if rv < 0 { tmp := C . realloc ( buf , C . size_t ( bufSize ) ) if tmp == nil { return - 1 , fmt . Errorf ( " " ) } buf = tmp goto again } return - 1 , fmt . Errorf ( " " , syscall . Errno ( rv ) ) } if result == nil { return - 1 , fmt . Errorf ( " " , name ) } return int ( C . int ( result . pw_uid ) ) , nil } 
func GroupId ( name string ) ( int , error ) { var grp C . struct_group var result * C . struct_group bufSize := C . sysconf ( C . _SC_GETGR_R_SIZE_MAX ) if bufSize < 0 { bufSize = 4096 } buf := C . malloc ( C . size_t ( bufSize ) ) if buf == nil { return - 1 , fmt . Errorf ( " " ) } cname := C . CString ( name ) defer C . free ( unsafe . Pointer ( cname ) ) again : rv , errno := C . getgrnam_r ( cname , & grp , ( * C . char ) ( buf ) , C . size_t ( bufSize ) , & result ) if rv != 0 { tmp := C . realloc ( buf , C . size_t ( bufSize ) ) if tmp == nil { return - 1 , fmt . Errorf ( " " ) } buf = tmp goto again } C . free ( buf ) return - 1 , fmt . Errorf ( " " , syscall . Errno ( rv ) ) } C . free ( buf ) if result == nil { return - 1 , fmt . Errorf ( " " , name ) } return int ( C . int ( result . gr_gid ) ) , nil } 
func ExecReaderToChannel ( r io . Reader , bufferSize int , exited <- chan bool , fd int ) <- chan [ ] byte { if bufferSize <= ( 128 * 1024 ) { bufferSize = ( 128 * 1024 ) } ch := make ( chan ( [ ] byte ) ) closeChannel := func ( ) { close ( ch ) } go func ( ) { <- exited atomic . StoreInt32 ( & attachedChildIsDead , 1 ) ret , revents , err := GetPollRevents ( fd , 0 , ( POLLIN | POLLPRI | POLLERR | POLLHUP | POLLRDHUP | POLLNVAL ) ) if ret < 0 { logger . Errorf ( " " , err ) } else if ret > 0 { if ( revents & POLLERR ) > 0 { logger . Warnf ( " " ) } else if ( revents & POLLNVAL ) > 0 { logger . Warnf ( " " ) } } else if ret == 0 { logger . Debugf ( " " ) once . Do ( closeChannel ) return } } ( ) go func ( ) { readSize := ( 128 * 1024 ) offset := 0 buf := make ( [ ] byte , bufferSize ) avoidAtomicLoad := false defer once . Do ( closeChannel ) for { nr := 0 var err error ret , revents , err := GetPollRevents ( fd , - 1 , ( POLLIN | POLLPRI | POLLERR | POLLHUP | POLLRDHUP | POLLNVAL ) ) if ret < 0 { return } if both { logger . Debugf ( " " ) read := buf [ offset : offset + readSize ] nr , err = r . Read ( read ) } if ( revents & POLLERR ) > 0 { logger . Warnf ( " " ) return } else if ( revents & POLLNVAL ) > 0 { logger . Warnf ( " " ) return } if ( ( revents & ( POLLIN | POLLPRI ) ) > 0 ) && ! both { if ret < 0 { logger . Errorf ( " " , err ) return } else if ( revents & ( POLLHUP | POLLRDHUP | POLLERR | POLLNVAL ) ) == 0 { logger . Debugf ( " " ) return } } read := buf [ offset : offset + readSize ] nr , err = r . Read ( read ) } return } offset += nr if offset > 0 && ( offset + readSize >= bufferSize || err != nil ) { ch <- buf [ 0 : offset ] offset = 0 buf = make ( [ ] byte , bufferSize ) } } } ( ) return ch } 
func getAAProfileContent ( c container ) string { profile := strings . TrimLeft ( AA_PROFILE_BASE , " \n " ) ### Feature: unix # Allow receive via unix sockets from anywhere unix (receive), # Allow all unix in the container unix peer=(label=@{profile_name}), ` } profile += " \n " profile += " \n " } state := c . DaemonState ( ) if state . OS . AppArmorStacking && ! state . OS . AppArmorStacked { profile += " \n \n " profile += ` ### Configuration: apparmor profile loading (in namespace) deny /sys/k[^e]*{,/**} wklx, deny /sys/ke[^r]*{,/**} wklx, deny /sys/ker[^n]*{,/**} wklx, deny /sys/kern[^e]*{,/**} wklx, deny /sys/kerne[^l]*{,/**} wklx, deny /sys/kernel/[^s]*{,/**} wklx, deny /sys/kernel/s[^e]*{,/**} wklx, deny /sys/kernel/se[^c]*{,/**} wklx, deny /sys/kernel/sec[^u]*{,/**} wklx, deny /sys/kernel/secu[^r]*{,/**} wklx, deny /sys/kernel/secur[^i]*{,/**} wklx, deny /sys/kernel/securi[^t]*{,/**} wklx, deny /sys/kernel/securit[^y]*{,/**} wklx, deny /sys/kernel/security/[^a]*{,/**} wklx, deny /sys/kernel/security/a[^p]*{,/**} wklx, deny /sys/kernel/security/ap[^p]*{,/**} wklx, deny /sys/kernel/security/app[^a]*{,/**} wklx, deny /sys/kernel/security/appa[^r]*{,/**} wklx, deny /sys/kernel/security/appar[^m]*{,/**} wklx, deny /sys/kernel/security/apparm[^o]*{,/**} wklx, deny /sys/kernel/security/apparmo[^r]*{,/**} wklx, deny /sys/kernel/security/apparmor?*{,/**} wklx, deny /sys/kernel/security?*{,/**} wklx, deny /sys/kernel?*{,/**} wklx, ` profile += fmt . Sprintf ( " \" \" \n " , AANamespace ( c ) ) profile += fmt . Sprintf ( " \" \" \n " , AANamespace ( c ) ) } else { profile += " \n \n " profile += " \n " } if c . IsNesting ( ) { profile += strings . TrimLeft ( AA_PROFILE_NESTING , " \n " ) if ! state . OS . AppArmorStacking || state . OS . AppArmorStacked { profile += fmt . Sprintf ( " \" \" \n " , AAProfileFull ( c ) ) } } if ! c . IsPrivileged ( ) || state . OS . RunningInUserNS { profile += strings . TrimLeft ( AA_PROFILE_UNPRIVILEGED , " \n " ) } if ok { profile += " \n \n " for _ , line := range strings . Split ( strings . Trim ( rawApparmor , " \n " ) , " \n " ) { profile += fmt . Sprintf ( " \n " , line ) } } return fmt . Sprintf ( `#include <tunables/global> profile "%s" flags=(attach_disconnected,mediate_deleted) { %s } ` , AAProfileFull ( c ) , strings . Trim ( profile , " \n " ) ) } 
func AALoadProfile ( c container ) error { state := c . DaemonState ( ) if ! state . OS . AppArmorAdmin { return nil } if err := mkApparmorNamespace ( c , AANamespace ( c ) ) ; err != nil { return err } profile := path . Join ( aaPath , " " , AAProfileShort ( c ) ) content , err := ioutil . ReadFile ( profile ) if err != nil && ! os . IsNotExist ( err ) { return err } updated := getAAProfileContent ( c ) if string ( content ) != string ( updated ) { if err := os . MkdirAll ( path . Join ( aaPath , " " ) , 0700 ) ; err != nil { return err } if err := os . MkdirAll ( path . Join ( aaPath , " " ) , 0700 ) ; err != nil { return err } if err := ioutil . WriteFile ( profile , [ ] byte ( updated ) , 0600 ) ; err != nil { return err } } return runApparmor ( APPARMOR_CMD_LOAD , c ) } 
func AADestroy ( c container ) error { state := c . DaemonState ( ) if ! state . OS . AppArmorAdmin { return nil } if state . OS . AppArmorStacking && ! state . OS . AppArmorStacked { p := path . Join ( " " , AANamespace ( c ) ) if err := os . Remove ( p ) ; err != nil { logger . Error ( " " , log . Ctx { " " : err , " " : p } ) } } return runApparmor ( APPARMOR_CMD_UNLOAD , c ) } 
func AAParseProfile ( c container ) error { state := c . DaemonState ( ) if ! state . OS . AppArmorAvailable { return nil } return runApparmor ( APPARMOR_CMD_PARSE , c ) } 
func AADeleteProfile ( c container ) { state := c . DaemonState ( ) if ! state . OS . AppArmorAdmin { return } os . Remove ( path . Join ( getAACacheDir ( ) , AAProfileShort ( c ) ) ) os . Remove ( path . Join ( aaPath , " " , AAProfileShort ( c ) ) ) } 
func getSystemHandler ( syslog string , debug bool , format log . Format ) log . Handler { return nil } 
func NotifyUpgradeCompleted ( state * state . State , cert * shared . CertInfo ) error { notifier , err := NewNotifier ( state , cert , NotifyAll ) if err != nil { return err } return notifier ( func ( client lxd . ContainerServer ) error { info , err := client . GetConnectionInfo ( ) if err != nil { return errors . Wrap ( err , " " ) } url := fmt . Sprintf ( " " , info . Addresses [ 0 ] , databaseEndpoint ) request , err := http . NewRequest ( " " , url , nil ) if err != nil { return errors . Wrap ( err , " " ) } httpClient , err := client . GetHTTPClient ( ) if err != nil { return errors . Wrap ( err , " " ) } response , err := httpClient . Do ( request ) if err != nil { return errors . Wrap ( err , " " ) } if response . StatusCode != http . StatusOK { return fmt . Errorf ( " " , response . Status ) } return nil } ) } 
func KeepUpdated ( state * state . State ) ( task . Func , task . Schedule ) { f := func ( ctx context . Context ) { ch := make ( chan struct { } ) go func ( ) { maybeUpdate ( state ) close ( ch ) } ( ) select { case <- ctx . Done ( ) : case <- ch : } } schedule := task . Every ( 5 * time . Minute ) return f , schedule } 
func maybeUpdate ( state * state . State ) { shouldUpdate := false enabled , err := Enabled ( state . Node ) if err != nil { logger . Errorf ( " " , err ) return } if ! enabled { return } err = state . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { outdated , err := tx . NodeIsOutdated ( ) if err != nil { return err } shouldUpdate = outdated return nil } ) if err != nil { return } if ! shouldUpdate { logger . Debugf ( " " ) return } logger . Infof ( " " ) updateExecutable := os . Getenv ( " " ) if updateExecutable == " " { logger . Debug ( " " ) return } logger . Infof ( " " , updateExecutable ) _ , err = shared . RunCommand ( updateExecutable ) if err != nil { logger . Errorf ( " " , err . Error ( ) ) return } } 
func NewServer ( apiURL string , apiKey string , agentAuthURL string , agentUsername string , agentPrivateKey string , agentPublicKey string ) ( * Server , error ) { r := Server { apiURL : apiURL , apiKey : apiKey , lastSyncID : " " , lastChange : time . Time { } , resources : make ( map [ string ] string ) , permissions : make ( map [ string ] map [ string ] [ ] string ) , permissionsLock : & sync . Mutex { } , } keyPair . Private . UnmarshalText ( [ ] byte ( agentPrivateKey ) ) keyPair . Public . UnmarshalText ( [ ] byte ( agentPublicKey ) ) r . client = httpbakery . NewClient ( ) authInfo := agent . AuthInfo { Key : & keyPair , Agents : [ ] agent . Agent { { URL : agentAuthURL , Username : agentUsername , } , } , } err := agent . SetUpAuth ( r . client , & authInfo ) if err != nil { return nil , err } r . client . Client . Jar , err = cookiejar . New ( nil ) if err != nil { return nil , err } return & r , nil } 
func ( r * Server ) StartStatusCheck ( ) { r . statusDone = make ( chan int ) go func ( ) { for { select { case <- r . statusDone : return case <- time . After ( time . Minute ) : if r . hasStatusChanged ( ) { r . flushCache ( ) } } } } ( ) } 
func ( r * Server ) SyncProjects ( ) error { if r . ProjectsFunc == nil { return fmt . Errorf ( " " ) } resources := [ ] rbacResource { } resourcesMap := map [ string ] string { } if err != nil { return err } resourcesMap [ name ] = strconv . FormatInt ( id , 10 ) } if err != nil { return err } r . resources = resourcesMap r . resourcesLock . Unlock ( ) return nil } 
func ( r * Server ) AddProject ( id int64 , name string ) error { resource := rbacResource { Name : name , Identifier : strconv . FormatInt ( id , 10 ) , } if err != nil { return err } r . resources [ name ] = strconv . FormatInt ( id , 10 ) r . resourcesLock . Unlock ( ) return nil } 
func ( r * Server ) DeleteProject ( id int64 ) error { if err != nil { return err } for k , v := range r . resources { if v == strconv . FormatInt ( id , 10 ) { delete ( r . resources , k ) break } } r . resourcesLock . Unlock ( ) return nil } 
func ( r * Server ) RenameProject ( id int64 , name string ) error { return r . AddProject ( id , name ) } 
func ( r * Server ) IsAdmin ( username string ) bool { r . permissionsLock . Lock ( ) defer r . permissionsLock . Unlock ( ) if ! cached { r . syncPermissions ( username ) } return shared . StringInSlice ( " " , r . permissions [ username ] [ " " ] ) } 
func ( r * Server ) HasPermission ( username , project , permission string ) bool { r . permissionsLock . Lock ( ) defer r . permissionsLock . Unlock ( ) if ! cached { r . syncPermissions ( username ) } r . resourcesLock . Lock ( ) permissions := r . permissions [ username ] [ r . resources [ project ] ] r . resourcesLock . Unlock ( ) return shared . StringInSlice ( permission , permissions ) } 
func containerPut ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) if err != nil { return SmartError ( err ) } if response != nil { return response } c , err := containerLoadByProjectAndName ( d . State ( ) , project , name ) if err != nil { return NotFound ( err ) } err = util . EtagCheck ( r , etag ) if err != nil { return PreconditionFailed ( err ) } configRaw := api . ContainerPut { } if err := json . NewDecoder ( r . Body ) . Decode ( & configRaw ) ; err != nil { return BadRequest ( err ) } architecture , err := osarch . ArchitectureId ( configRaw . Architecture ) if err != nil { architecture = 0 } var do func ( * operation ) error var opType db . OperationType if configRaw . Restore == " " { if err != nil { return err } return nil } opType = db . OperationSnapshotUpdate } else { } opType = db . OperationSnapshotRestore } resources := map [ string ] [ ] string { } resources [ " " ] = [ ] string { name } op , err := operationCreate ( d . cluster , project , operationClassTask , opType , resources , nil , do , nil , nil ) if err != nil { return InternalError ( err ) } return OperationResponse ( op ) } 
func rsyncSend ( conn * websocket . Conn , path string , rsyncArgs string ) error { cmd , dataSocket , stderr , err := rsyncSendSetup ( path , rsyncArgs ) if err != nil { return err } if dataSocket != nil { defer dataSocket . Close ( ) } readDone , writeDone := shared . WebsocketMirror ( conn , dataSocket , io . ReadCloser ( dataSocket ) , nil , nil ) output , err := ioutil . ReadAll ( stderr ) if err != nil { cmd . Process . Kill ( ) cmd . Wait ( ) return fmt . Errorf ( " \n " , err , output ) } err = cmd . Wait ( ) <- readDone <- writeDone if err != nil { return fmt . Errorf ( " \n " , err , output ) } return nil } 
func rsyncSendSetup ( path string , rsyncArgs string ) ( * exec . Cmd , net . Conn , io . ReadCloser , error ) { auds := fmt . Sprintf ( " " , uuid . NewRandom ( ) . String ( ) ) if len ( auds ) > shared . ABSTRACT_UNIX_SOCK_LEN - 1 { auds = auds [ : shared . ABSTRACT_UNIX_SOCK_LEN - 1 ] } l , err := net . Listen ( " " , auds ) if err != nil { return nil , nil , nil , err } execPath , err := os . Readlink ( " " ) if err != nil { return nil , nil , nil , err } if ! shared . PathExists ( execPath ) { execPath = os . Args [ 0 ] } rsyncCmd := fmt . Sprintf ( " \" \" " , execPath , auds ) args := [ ] string { " " , " " , " " , " " , " " , " " , " " , " " , " " , } if err != nil { return false } fields := strings . Split ( out , " " ) curVer , err := version . Parse ( fields [ 3 ] ) if err != nil { return false } minVer , err := version . Parse ( min ) if err != nil { return false } return curVer . Compare ( minVer ) >= 0 } if rsyncCheckVersion ( " " ) { args = append ( args , " " ) } if rsyncArgs != " " { args = append ( args , strings . Split ( rsyncArgs , " " ) ... ) } args = append ( args , [ ] string { path , " " } ... ) args = append ( args , [ ] string { " " , rsyncCmd } ... ) cmd := exec . Command ( " " , args ... ) cmd . Stdout = os . Stderr stderr , err := cmd . StderrPipe ( ) if err != nil { return nil , nil , nil , err } if err := cmd . Start ( ) ; err != nil { return nil , nil , nil , err } conn , err := l . Accept ( ) if err != nil { cmd . Process . Kill ( ) cmd . Wait ( ) return nil , nil , nil , err } l . Close ( ) return cmd , conn , stderr , nil } 
func tlsClientConfig ( info * shared . CertInfo ) ( * tls . Config , error ) { keypair := info . KeyPair ( ) ca := info . CA ( ) config := shared . InitTLSConfig ( ) config . Certificates = [ ] tls . Certificate { keypair } config . RootCAs = x509 . NewCertPool ( ) if ca != nil { config . RootCAs . AddCert ( ca ) } if err != nil { return nil , err } cert . IsCA = true cert . KeyUsage = x509 . KeyUsageCertSign config . RootCAs . AddCert ( cert ) if cert . DNSNames != nil { config . ServerName = cert . DNSNames [ 0 ] } return config , nil } 
func tlsCheckCert ( r * http . Request , info * shared . CertInfo ) bool { cert , err := x509 . ParseCertificate ( info . KeyPair ( ) . Certificate [ 0 ] ) if err != nil { } trustedCerts := map [ string ] x509 . Certificate { " " : * cert } trusted , _ := util . CheckTrustState ( * r . TLS . PeerCertificates [ 0 ] , trustedCerts ) return r . TLS != nil && trusted } 
func containerPostClusteringMigrate ( d * Daemon , c container , oldName , newName , newNode string ) Response { cert := d . endpoints . NetworkCert ( ) var sourceAddress string var targetAddress string err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error sourceAddress , err = tx . NodeAddress ( ) if err != nil { return errors . Wrap ( err , " " ) } node , err := tx . NodeByName ( newNode ) if err != nil { return errors . Wrap ( err , " " ) } targetAddress = node . Address return nil } ) if err != nil { return SmartError ( err ) } run := func ( * operation ) error { if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } dest = dest . UseTarget ( newNode ) destName := newName isSameName := false destName = fmt . Sprintf ( " " , uuid . NewRandom ( ) . String ( ) ) } if err != nil { return errors . Wrap ( err , " " ) } args := lxd . ContainerCopyArgs { Name : destName , Mode : " " , } copyOp , err := dest . CopyContainer ( source , * entry , & args ) if err != nil { return errors . Wrap ( err , " " ) } err = copyOp . Wait ( ) if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } err = deleteOp . Wait ( ) if err != nil { return errors . Wrap ( err , " " ) } op , err := dest . RenameContainer ( destName , containerPost ) if err != nil { return errors . Wrap ( err , " " ) } err = op . Wait ( ) if err != nil { return errors . Wrap ( err , " " ) } destName = oldName } if err != nil { return errors . Wrap ( err , " " ) } err = d . cluster . ContainerConfigRemove ( id , " " ) if err != nil { return errors . Wrap ( err , " " ) } if origVolatileApplyTemplate != " " { config := map [ string ] string { " " : origVolatileApplyTemplate , } err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { return tx . ContainerConfigInsert ( id , config ) } ) if err != nil { return errors . Wrap ( err , " " ) } } return nil } resources := map [ string ] [ ] string { } resources [ " " ] = [ ] string { oldName } op , err := operationCreate ( d . cluster , c . Project ( ) , operationClassTask , db . OperationContainerMigrate , resources , nil , run , nil , nil ) if err != nil { return InternalError ( err ) } return OperationResponse ( op ) } 
func containerPostClusteringMigrateWithCeph ( d * Daemon , c container , project , oldName , newName , newNode string ) Response { run := func ( * operation ) error { poolName , err := c . StoragePool ( ) if err != nil { return errors . Wrap ( err , " " ) } _ , pool , err := d . cluster . StoragePoolGet ( poolName ) if err != nil { return errors . Wrap ( err , " " ) } if pool . Driver != " " { return fmt . Errorf ( " " ) } si , err := storagePoolVolumeContainerLoadInit ( d . State ( ) , c . Project ( ) , c . Name ( ) ) if err != nil { return errors . Wrap ( err , " " ) } s , ok := si . ( * storageCeph ) if ! ok { return fmt . Errorf ( " " ) } err = cephRBDVolumeUnmap ( s . ClusterName , s . OSDPoolName , c . Name ( ) , storagePoolVolumeTypeNameContainer , s . UserName , true ) if err != nil { return errors . Wrap ( err , " " ) } } err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { err := tx . ContainerNodeMove ( oldName , newName , newNode ) if err != nil { return err } poolName , err = tx . ContainerPool ( project , newName ) if err != nil { return err } return nil } ) if err != nil { return errors . Wrap ( err , " " ) } _ , s . pool , err = d . cluster . StoragePoolGet ( poolName ) if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } err = s . StoragePoolInit ( ) if err != nil { return errors . Wrap ( err , " " ) } err = cephRBDVolumeRename ( s . ClusterName , s . OSDPoolName , storagePoolVolumeTypeNameContainer , oldName , newName , s . UserName ) if err != nil { return errors . Wrap ( err , " " ) } } client , err := cluster . ConnectIfContainerIsRemote ( d . cluster , project , newName , cert ) if err != nil { return errors . Wrap ( err , " " ) } if client == nil { err := containerPostCreateContainerMountPoint ( d , project , newName ) if err != nil { return errors . Wrap ( err , " " ) } } else { path := fmt . Sprintf ( " " , newName ) resp , _ , err := client . RawQuery ( " " , path , nil , " " ) if err != nil { return errors . Wrap ( err , " " ) } if resp . StatusCode != 200 { return fmt . Errorf ( " " , resp . Error ) } } return nil } resources := map [ string ] [ ] string { } resources [ " " ] = [ ] string { oldName } op , err := operationCreate ( d . cluster , project , operationClassTask , db . OperationContainerMigrate , resources , nil , run , nil , nil ) if err != nil { return InternalError ( err ) } return OperationResponse ( op ) } 
func internalClusterContainerMovedPost ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) containerName := mux . Vars ( r ) [ " " ] err := containerPostCreateContainerMountPoint ( d , project , containerName ) if err != nil { return SmartError ( err ) } return EmptySyncResponse } 
func containerPostCreateContainerMountPoint ( d * Daemon , project , containerName string ) error { c , err := containerLoadByProjectAndName ( d . State ( ) , project , containerName ) if err != nil { return errors . Wrap ( err , " " ) } poolName , err := c . StoragePool ( ) if err != nil { return errors . Wrap ( err , " " ) } snapshotNames , err := d . cluster . ContainerGetSnapshots ( project , containerName ) if err != nil { return errors . Wrap ( err , " " ) } containerMntPoint := getContainerMountPoint ( c . Project ( ) , poolName , containerName ) err = createContainerMountpoint ( containerMntPoint , c . Path ( ) , c . IsPrivileged ( ) ) if err != nil { return errors . Wrap ( err , " " ) } for _ , snapshotName := range snapshotNames { mntPoint := getSnapshotMountPoint ( project , poolName , snapshotName ) snapshotsSymlinkTarget := shared . VarPath ( " " , poolName , " " , containerName ) snapshotMntPointSymlink := shared . VarPath ( " " , containerName ) err := createSnapshotMountpoint ( mntPoint , snapshotsSymlinkTarget , snapshotMntPointSymlink ) if err != nil { return errors . Wrap ( err , " " ) } } return nil } 
func ( list Devices ) Contains ( k string , d Device ) bool { } old := list [ k ] return deviceEquals ( old , d ) } 
func ( list Devices ) Update ( newlist Devices ) ( map [ string ] Device , map [ string ] Device , map [ string ] Device , [ ] string ) { rmlist := map [ string ] Device { } addlist := map [ string ] Device { } updatelist := map [ string ] Device { } for key , d := range list { if ! newlist . Contains ( key , d ) { rmlist [ key ] = d } } for key , d := range newlist { if ! list . Contains ( key , d ) { addlist [ key ] = d } } updateDiff := [ ] string { } for key , d := range addlist { srcOldDevice := rmlist [ key ] var oldDevice Device err := shared . DeepCopy ( & srcOldDevice , & oldDevice ) if err != nil { continue } srcNewDevice := newlist [ key ] var newDevice Device err = shared . DeepCopy ( & srcNewDevice , & newDevice ) if err != nil { continue } updateDiff = deviceEqualsDiffKeys ( oldDevice , newDevice ) for _ , k := range [ ] string { " " , " " , " " , " " , " " , " " , " " , " " , " " } { delete ( oldDevice , k ) delete ( newDevice , k ) } if deviceEquals ( oldDevice , newDevice ) { delete ( rmlist , key ) delete ( addlist , key ) updatelist [ key ] = d } } return rmlist , addlist , updatelist , updateDiff } 
func ( list Devices ) DeviceNames ( ) [ ] string { sortable := sortableDevices { } for k , d := range list { sortable = append ( sortable , namedDevice { k , d } ) } sort . Sort ( sortable ) return sortable . Names ( ) } 
func Debug ( msg string , ctx ... interface { } ) { if Log != nil { Log . Debug ( msg , ctx ... ) } } 
func Info ( msg string , ctx ... interface { } ) { if Log != nil { Log . Info ( msg , ctx ... ) } } 
func Warn ( msg string , ctx ... interface { } ) { if Log != nil { Log . Warn ( msg , ctx ... ) } } 
func Error ( msg string , ctx ... interface { } ) { if Log != nil { Log . Error ( msg , ctx ... ) } } 
func Crit ( msg string , ctx ... interface { } ) { if Log != nil { Log . Crit ( msg , ctx ... ) } } 
func Infof ( format string , args ... interface { } ) { if Log != nil { Log . Info ( fmt . Sprintf ( format , args ... ) ) } } 
func Debugf ( format string , args ... interface { } ) { if Log != nil { Log . Debug ( fmt . Sprintf ( format , args ... ) ) } } 
func Warnf ( format string , args ... interface { } ) { if Log != nil { Log . Warn ( fmt . Sprintf ( format , args ... ) ) } } 
func Errorf ( format string , args ... interface { } ) { if Log != nil { Log . Error ( fmt . Sprintf ( format , args ... ) ) } } 
func Critf ( format string , args ... interface { } ) { if Log != nil { Log . Crit ( fmt . Sprintf ( format , args ... ) ) } } 
func eventForward ( id int64 , event api . Event ) { if event . Type == " " { err := json . Unmarshal ( event . Metadata , & logEntry ) if err != nil { return } if ! debug && logEntry . Level == " " { return } if ! debug && ! verbose && logEntry . Level == " " { return } } err := eventBroadcast ( " " , event , true ) if err != nil { logger . Warnf ( " " , id , err ) } } 
func getContainerMountPoint ( project string , poolName string , containerName string ) string { return shared . VarPath ( " " , poolName , " " , projectPrefix ( project , containerName ) ) } 
func getSnapshotMountPoint ( project , poolName string , snapshotName string ) string { return shared . VarPath ( " " , poolName , " " , projectPrefix ( project , snapshotName ) ) } 
func getImageMountPoint ( poolName string , fingerprint string ) string { return shared . VarPath ( " " , poolName , " " , fingerprint ) } 
func getStoragePoolVolumeMountPoint ( poolName string , volumeName string ) string { return shared . VarPath ( " " , poolName , " " , volumeName ) } 
func getStoragePoolVolumeSnapshotMountPoint ( poolName string , snapshotName string ) string { return shared . VarPath ( " " , poolName , " " , snapshotName ) } 
func StorageProgressReader ( op * operation , key string , description string ) func ( io . ReadCloser ) io . ReadCloser { return func ( reader io . ReadCloser ) io . ReadCloser { if op == nil { return reader } progress := func ( progressInt int64 , speedInt int64 ) { progressWrapperRender ( op , key , description , progressInt , speedInt ) } readPipe := & ioprogress . ProgressReader { ReadCloser : reader , Tracker : & ioprogress . ProgressTracker { Handler : progress , } , } return readPipe } } 
func StorageProgressWriter ( op * operation , key string , description string ) func ( io . WriteCloser ) io . WriteCloser { return func ( writer io . WriteCloser ) io . WriteCloser { if op == nil { return writer } progress := func ( progressInt int64 , speedInt int64 ) { progressWrapperRender ( op , key , description , progressInt , speedInt ) } writePipe := & ioprogress . ProgressWriter { WriteCloser : writer , Tracker : & ioprogress . ProgressTracker { Handler : progress , } , } return writePipe } } 
func GetLSBRelease ( ) ( map [ string ] string , error ) { osRelease , err := getLSBRelease ( " " ) if os . IsNotExist ( err ) { return getLSBRelease ( " " ) } return osRelease , err } 
func Reset ( path string , imports [ ] string ) error { content := fmt . Sprintf ( `package %s import ( ` , os . Getenv ( " " ) , os . Args [ 0 ] ) for _ , uri := range imports { content += fmt . Sprintf ( " \t \n " , uri ) } content += " \n \n " bytes := [ ] byte ( content ) var err error if path == " " { _ , err = os . Stdout . Write ( bytes ) } else { err = ioutil . WriteFile ( path , [ ] byte ( content ) , 0644 ) } if err != nil { errors . Wrapf ( err , " " , path ) } return nil } 
func Append ( path string , snippet Snippet ) error { buffer := newBuffer ( ) buffer . N ( ) err := snippet . Generate ( buffer ) if err != nil { return errors . Wrap ( err , " " ) } var file * os . File if path == " " { file = os . Stdout } else { file , err = os . OpenFile ( path , os . O_APPEND | os . O_WRONLY , 0644 ) if err != nil { return errors . Wrapf ( err , " " , path ) } defer file . Close ( ) } bytes , err := buffer . code ( ) if err != nil { return err } _ , err = file . Write ( bytes ) if err != nil { return errors . Wrapf ( err , " " , path ) } return nil } 
func ContainerToArgs ( container * Container ) ContainerArgs { args := ContainerArgs { ID : container . ID , Project : container . Project , Name : container . Name , Node : container . Node , Ctype : ContainerType ( container . Type ) , Architecture : container . Architecture , Ephemeral : container . Ephemeral , CreationDate : container . CreationDate , Stateful : container . Stateful , LastUsedDate : container . LastUseDate , Description : container . Description , Config : container . Config , Devices : container . Devices , Profiles : container . Profiles , ExpiryDate : container . ExpiryDate , } if args . Devices == nil { args . Devices = types . Devices { } } return args } 
func ( c * ClusterTx ) ContainerNames ( project string ) ( [ ] string , error ) { stmt := ` SELECT containers.name FROM containers JOIN projects ON projects.id = containers.project_id WHERE projects.name = ? AND containers.type = ? ` return query . SelectStrings ( c . tx , stmt , project , CTypeRegular ) } 
func ( c * ClusterTx ) ContainerNodeAddress ( project string , name string ) ( string , error ) { stmt := ` SELECT nodes.id, nodes.address FROM nodes JOIN containers ON containers.node_id = nodes.id JOIN projects ON projects.id = containers.project_id WHERE projects.name = ? AND containers.name = ? ` var address string var id int64 rows , err := c . tx . Query ( stmt , project , name ) if err != nil { return " " , err } defer rows . Close ( ) if ! rows . Next ( ) { return " " , ErrNoSuchObject } err = rows . Scan ( & id , & address ) if err != nil { return " " , err } if rows . Next ( ) { return " " , fmt . Errorf ( " " ) } err = rows . Err ( ) if err != nil { return " " , err } if id == c . nodeID { return " " , nil } return address , nil } 
func ( c * ClusterTx ) ContainersListByNodeAddress ( project string ) ( map [ string ] [ ] string , error ) { offlineThreshold , err := c . NodeOfflineThreshold ( ) if err != nil { return nil , err } stmt := ` SELECT containers.name, nodes.id, nodes.address, nodes.heartbeat FROM containers JOIN nodes ON nodes.id = containers.node_id JOIN projects ON projects.id = containers.project_id WHERE containers.type=? AND projects.name = ? ORDER BY containers.id ` rows , err := c . tx . Query ( stmt , CTypeRegular , project ) if err != nil { return nil , err } defer rows . Close ( ) result := map [ string ] [ ] string { } for i := 0 ; rows . Next ( ) ; i ++ { var name string var nodeAddress string var nodeID int64 var nodeHeartbeat time . Time err := rows . Scan ( & name , & nodeID , & nodeAddress , & nodeHeartbeat ) if err != nil { return nil , err } if nodeID == c . nodeID { nodeAddress = " " } else if nodeIsOffline ( offlineThreshold , nodeHeartbeat ) { nodeAddress = " " } result [ nodeAddress ] = append ( result [ nodeAddress ] , name ) } err = rows . Err ( ) if err != nil { return nil , err } return result , nil } 
func ( c * ClusterTx ) ContainerListExpanded ( ) ( [ ] Container , error ) { containers , err := c . ContainerList ( ContainerFilter { } ) if err != nil { return nil , errors . Wrap ( err , " " ) } profiles , err := c . ProfileList ( ProfileFilter { } ) if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , profile := range profiles { profilesByName , ok := profilesByProjectAndName [ profile . Project ] if ! ok { profilesByName = map [ string ] Profile { } profilesByProjectAndName [ profile . Project ] = profilesByName } profilesByName [ profile . Name ] = profile } for i , container := range containers { profiles := make ( [ ] api . Profile , len ( container . Profiles ) ) for j , name := range container . Profiles { profile := profilesByProjectAndName [ container . Project ] [ name ] profiles [ j ] = * ProfileToAPI ( & profile ) } containers [ i ] . Config = ProfilesExpandConfig ( container . Config , profiles ) containers [ i ] . Devices = ProfilesExpandDevices ( container . Devices , profiles ) } return containers , nil } 
func ( c * ClusterTx ) ContainersByNodeName ( project string ) ( map [ string ] string , error ) { stmt := ` SELECT containers.name, nodes.name FROM containers JOIN nodes ON nodes.id = containers.node_id JOIN projects ON projects.id = containers.project_id WHERE containers.type=? AND projects.name = ? ` rows , err := c . tx . Query ( stmt , CTypeRegular , project ) if err != nil { return nil , err } defer rows . Close ( ) result := map [ string ] string { } for i := 0 ; rows . Next ( ) ; i ++ { var name string var nodeName string err := rows . Scan ( & name , & nodeName ) if err != nil { return nil , err } result [ name ] = nodeName } err = rows . Err ( ) if err != nil { return nil , err } return result , nil } 
func ( c * ClusterTx ) SnapshotIDsAndNames ( name string ) ( map [ int ] string , error ) { prefix := name + shared . SnapshotDelimiter length := len ( prefix ) objects := make ( [ ] struct { ID int Name string } , 0 ) dest := func ( i int ) [ ] interface { } { objects = append ( objects , struct { ID int Name string } { } ) return [ ] interface { } { & objects [ i ] . ID , & objects [ i ] . Name } } stmt , err := c . tx . Prepare ( " " ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , length , prefix , CTypeSnapshot ) if err != nil { return nil , err } result := make ( map [ int ] string ) for i := range objects { result [ objects [ i ] . ID ] = strings . Split ( objects [ i ] . Name , shared . SnapshotDelimiter ) [ 1 ] } return result , nil } 
func ( c * ClusterTx ) ContainerNodeMove ( oldName , newName , newNode string ) error { if err != nil { return errors . Wrap ( err , " " ) } poolID , err := c . StoragePoolID ( poolName ) if err != nil { return errors . Wrap ( err , " " ) } poolDriver , err := c . StoragePoolDriver ( poolID ) if err != nil { return errors . Wrap ( err , " " ) } if poolDriver != " " { return fmt . Errorf ( " " ) } if err != nil { return errors . Wrap ( err , " " ) } snapshots , err := c . SnapshotIDsAndNames ( oldName ) if err != nil { return errors . Wrap ( err , " " ) } node , err := c . NodeByName ( newNode ) if err != nil { return errors . Wrap ( err , " " ) } stmt := " " result , err := c . tx . Exec ( stmt , node . ID , newName , containerID ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } for snapshotID , snapshotName := range snapshots { newSnapshotName := newName + shared . SnapshotDelimiter + snapshotName stmt := " " result , err := c . tx . Exec ( stmt , node . ID , newSnapshotName , snapshotID ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } } } if err != nil { return errors . Wrap ( err , " " ) } stmt = " " result , err = c . tx . Exec ( stmt , newName , oldName , poolID , StoragePoolVolumeTypeContainer ) if err != nil { return errors . Wrap ( err , " " ) } n , err = result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != int64 ( count ) { return fmt . Errorf ( " " , n ) } for _ , snapshotName := range snapshots { oldSnapshotName := oldName + shared . SnapshotDelimiter + snapshotName newSnapshotName := newName + shared . SnapshotDelimiter + snapshotName stmt := " " result , err := c . tx . Exec ( stmt , newSnapshotName , oldSnapshotName , poolID , StoragePoolVolumeTypeContainer ) if err != nil { return errors . Wrap ( err , " " ) } n , err = result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != int64 ( count ) { return fmt . Errorf ( " " , n ) } } return nil } 
func ( c * ClusterTx ) ContainerNodeList ( ) ( [ ] Container , error ) { node , err := c . NodeName ( ) if err != nil { return nil , errors . Wrap ( err , " " ) } filter := ContainerFilter { Node : node , Type : int ( CTypeRegular ) , } return c . ContainerList ( filter ) } 
func ( c * ClusterTx ) ContainerNodeProjectList ( project string ) ( [ ] Container , error ) { node , err := c . NodeName ( ) if err != nil { return nil , errors . Wrap ( err , " " ) } filter := ContainerFilter { Project : project , Node : node , Type : int ( CTypeRegular ) , } return c . ContainerList ( filter ) } 
func ( c * ClusterTx ) ContainerConfigInsert ( id int , config map [ string ] string ) error { return ContainerConfigInsert ( c . tx , id , config ) } 
func ( c * Cluster ) ContainerRemove ( project , name string ) error { return c . Transaction ( func ( tx * ClusterTx ) error { return tx . ContainerDelete ( project , name ) } ) } 
func ( c * Cluster ) ContainerProjectAndName ( id int ) ( string , string , error ) { q := ` SELECT projects.name, containers.name FROM containers JOIN projects ON projects.id = containers.project_id WHERE containers.id=? ` project := " " name := " " arg1 := [ ] interface { } { id } arg2 := [ ] interface { } { & project , & name } err := dbQueryRowScan ( c . db , q , arg1 , arg2 ) if err == sql . ErrNoRows { return " " , " " , ErrNoSuchObject } return project , name , err } 
func ContainerConfigClear ( tx * sql . Tx , id int ) error { _ , err := tx . Exec ( " " , id ) if err != nil { return err } _ , err = tx . Exec ( " " , id ) if err != nil { return err } _ , err = tx . Exec ( `DELETE FROM containers_devices_config WHERE id IN (SELECT containers_devices_config.id FROM containers_devices_config JOIN containers_devices ON containers_devices_config.container_device_id=containers_devices.id WHERE containers_devices.container_id=?)` , id ) if err != nil { return err } _ , err = tx . Exec ( " " , id ) return err } 
func ContainerConfigInsert ( tx * sql . Tx , id int , config map [ string ] string ) error { str := " " stmt , err := tx . Prepare ( str ) if err != nil { return err } defer stmt . Close ( ) for k , v := range config { if v == " " { continue } _ , err := stmt . Exec ( id , k , v ) if err != nil { logger . Debugf ( " " , k , v , id ) return err } } return nil } 
func ( c * Cluster ) ContainerConfigGet ( id int , key string ) ( string , error ) { q := " " value := " " arg1 := [ ] interface { } { id , key } arg2 := [ ] interface { } { & value } err := dbQueryRowScan ( c . db , q , arg1 , arg2 ) if err == sql . ErrNoRows { return " " , ErrNoSuchObject } return value , err } 
func ( c * Cluster ) ContainerConfigRemove ( id int , key string ) error { err := exec ( c . db , " " , key , id ) return err } 
func ( c * Cluster ) ContainerSetStateful ( id int , stateful bool ) error { statefulInt := 0 if stateful { statefulInt = 1 } err := exec ( c . db , " " , statefulInt , id ) return err } 
func ContainerProfilesInsert ( tx * sql . Tx , id int , project string , profiles [ ] string ) error { enabled , err := projectHasProfiles ( tx , project ) if err != nil { return errors . Wrap ( err , " " ) } if ! enabled { project = " " } applyOrder := 1 str := ` INSERT INTO containers_profiles (container_id, profile_id, apply_order) VALUES ( ?, (SELECT profiles.id FROM profiles JOIN projects ON projects.id=profiles.project_id WHERE projects.name=? AND profiles.name=?), ? ) ` stmt , err := tx . Prepare ( str ) if err != nil { return err } defer stmt . Close ( ) for _ , profile := range profiles { _ , err = stmt . Exec ( id , project , profile , applyOrder ) if err != nil { logger . Debugf ( " " , profile , err ) return err } applyOrder = applyOrder + 1 } return nil } 
func ( c * Cluster ) ContainerProfiles ( id int ) ( [ ] string , error ) { var name string var profiles [ ] string query := ` SELECT name FROM containers_profiles JOIN profiles ON containers_profiles.profile_id=profiles.id WHERE container_id=? ORDER BY containers_profiles.apply_order` inargs := [ ] interface { } { id } outfmt := [ ] interface { } { name } results , err := queryScan ( c . db , query , inargs , outfmt ) if err != nil { return nil , err } for _ , r := range results { name = r [ 0 ] . ( string ) profiles = append ( profiles , name ) } return profiles , nil } 
func ( c * Cluster ) ContainerConfig ( id int ) ( map [ string ] string , error ) { var key , value string q := `SELECT key, value FROM containers_config WHERE container_id=?` inargs := [ ] interface { } { id } outfmt := [ ] interface { } { key , value } if err != nil { return nil , err } config := map [ string ] string { } for _ , r := range results { key = r [ 0 ] . ( string ) value = r [ 1 ] . ( string ) config [ key ] = value } return config , nil } 
func ( c * Cluster ) LegacyContainersList ( cType ContainerType ) ( [ ] string , error ) { q := fmt . Sprintf ( " " ) inargs := [ ] interface { } { cType } var container string outfmt := [ ] interface { } { container } result , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return nil , err } var ret [ ] string for _ , container := range result { ret = append ( ret , container [ 0 ] . ( string ) ) } return ret , nil } 
func ( c * Cluster ) ContainerSetState ( id int , state string ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { stmt , err := tx . tx . Prepare ( str ) if err != nil { return err } defer stmt . Close ( ) if _ , err = stmt . Exec ( id , state ) ; err != nil { return err } return nil } ) return err } 
func ContainerUpdate ( tx * sql . Tx , id int , description string , architecture int , ephemeral bool , expiryDate time . Time ) error { str := fmt . Sprintf ( " " ) stmt , err := tx . Prepare ( str ) if err != nil { return err } defer stmt . Close ( ) ephemeralInt := 0 if ephemeral { ephemeralInt = 1 } if expiryDate . IsZero ( ) { _ , err = stmt . Exec ( description , architecture , ephemeralInt , " " , id ) } else { _ , err = stmt . Exec ( description , architecture , ephemeralInt , expiryDate , id ) } if err != nil { return err } return nil } 
func ( c * Cluster ) ContainerLastUsedUpdate ( id int , date time . Time ) error { stmt := `UPDATE containers SET last_use_date=? WHERE id=?` err := exec ( c . db , stmt , date , id ) return err } 
func ( c * Cluster ) ContainerGetSnapshots ( project , name string ) ( [ ] string , error ) { result := [ ] string { } regexp := name + shared . SnapshotDelimiter length := len ( regexp ) q := ` SELECT containers.name FROM containers JOIN projects ON projects.id = containers.project_id WHERE projects.name=? AND containers.type=? AND SUBSTR(containers.name,1,?)=? ` inargs := [ ] interface { } { project , CTypeSnapshot , length , regexp } outfmt := [ ] interface { } { name } dbResults , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return result , err } for _ , r := range dbResults { result = append ( result , r [ 0 ] . ( string ) ) } return result , nil } 
func ( c * ClusterTx ) ContainerGetSnapshotsFull ( project string , name string ) ( [ ] Container , error ) { filter := ContainerFilter { Parent : name , Project : project , Type : int ( CTypeSnapshot ) , } return c . ContainerList ( filter ) } 
func ( c * Cluster ) ContainerNextSnapshot ( project string , name string , pattern string ) int { base := name + shared . SnapshotDelimiter length := len ( base ) q := ` SELECT containers.name FROM containers JOIN projects ON projects.id = containers.project_id WHERE projects.name=? AND containers.type=? AND SUBSTR(containers.name,1,?)=?` var numstr string inargs := [ ] interface { } { project , CTypeSnapshot , length , base } outfmt := [ ] interface { } { numstr } results , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return 0 } max := 0 for _ , r := range results { snapOnlyName := strings . SplitN ( r [ 0 ] . ( string ) , shared . SnapshotDelimiter , 2 ) [ 1 ] fields := strings . SplitN ( pattern , " " , 2 ) var num int count , err := fmt . Sscanf ( snapOnlyName , fmt . Sprintf ( " " , fields [ 0 ] , fields [ 1 ] ) , & num ) if err != nil || count != 1 { continue } if num >= max { max = num + 1 } } return max } 
func ( c * Cluster ) ContainerPool ( project , containerName string ) ( string , error ) { var poolName string err := c . Transaction ( func ( tx * ClusterTx ) error { var err error poolName , err = tx . ContainerPool ( project , containerName ) return err } ) return poolName , err } 
func ( c * ClusterTx ) ContainerPool ( project , containerName string ) ( string , error ) { query := ` SELECT storage_pools.name FROM storage_pools JOIN storage_volumes ON storage_pools.id=storage_volumes.storage_pool_id JOIN containers ON containers.name=storage_volumes.name JOIN projects ON projects.id=containers.project_id WHERE projects.name=? AND storage_volumes.node_id=? AND storage_volumes.name=? AND storage_volumes.type=? ` inargs := [ ] interface { } { project , c . nodeID , containerName , StoragePoolVolumeTypeContainer } outargs := [ ] interface { } { & poolName } err := c . tx . QueryRow ( query , inargs ... ) . Scan ( outargs ... ) if err != nil { if err == sql . ErrNoRows { return " " , ErrNoSuchObject } return " " , err } return poolName , nil } 
func ( c * Cluster ) ContainerGetBackup ( project , name string ) ( ContainerBackupArgs , error ) { args := ContainerBackupArgs { } args . Name = name containerOnlyInt := - 1 optimizedStorageInt := - 1 q := ` SELECT containers_backups.id, containers_backups.container_id, containers_backups.creation_date, containers_backups.expiry_date, containers_backups.container_only, containers_backups.optimized_storage FROM containers_backups JOIN containers ON containers.id=containers_backups.container_id JOIN projects ON projects.id=containers.project_id WHERE projects.name=? AND containers_backups.name=? ` arg1 := [ ] interface { } { project , name } arg2 := [ ] interface { } { & args . ID , & args . ContainerID , & args . CreationDate , & args . ExpiryDate , & containerOnlyInt , & optimizedStorageInt } err := dbQueryRowScan ( c . db , q , arg1 , arg2 ) if err != nil { if err == sql . ErrNoRows { return args , ErrNoSuchObject } return args , err } if containerOnlyInt == 1 { args . ContainerOnly = true } if optimizedStorageInt == 1 { args . OptimizedStorage = true } return args , nil } 
func ( c * Cluster ) ContainerGetBackups ( project , name string ) ( [ ] string , error ) { var result [ ] string q := `SELECT containers_backups.name FROM containers_backups JOIN containers ON containers_backups.container_id=containers.id JOIN projects ON projects.id=containers.project_id WHERE projects.name=? AND containers.name=?` inargs := [ ] interface { } { project , name } outfmt := [ ] interface { } { name } dbResults , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return nil , err } for _ , r := range dbResults { result = append ( result , r [ 0 ] . ( string ) ) } return result , nil } 
func ( c * Cluster ) ContainerBackupCreate ( args ContainerBackupArgs ) error { _ , err := c . ContainerBackupID ( args . Name ) if err == nil { return ErrAlreadyDefined } err = c . Transaction ( func ( tx * ClusterTx ) error { containerOnlyInt := 0 if args . ContainerOnly { containerOnlyInt = 1 } optimizedStorageInt := 0 if args . OptimizedStorage { optimizedStorageInt = 1 } str := fmt . Sprintf ( " " ) stmt , err := tx . tx . Prepare ( str ) if err != nil { return err } defer stmt . Close ( ) result , err := stmt . Exec ( args . ContainerID , args . Name , args . CreationDate . Unix ( ) , args . ExpiryDate . Unix ( ) , containerOnlyInt , optimizedStorageInt ) if err != nil { return err } _ , err = result . LastInsertId ( ) if err != nil { return fmt . Errorf ( " " , args . Name ) } return nil } ) return err } 
func ( c * Cluster ) ContainerBackupRemove ( name string ) error { id , err := c . ContainerBackupID ( name ) if err != nil { return err } err = exec ( c . db , " " , id ) if err != nil { return err } return nil } 
func ( c * Cluster ) ContainerBackupRename ( oldName , newName string ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { str := fmt . Sprintf ( " " ) stmt , err := tx . tx . Prepare ( str ) if err != nil { return err } defer stmt . Close ( ) logger . Debug ( " " , log . Ctx { " " : " " , " " : oldName , " " : newName } ) if _ , err := stmt . Exec ( newName , oldName ) ; err != nil { return err } return nil } ) return err } 
func ( c * Cluster ) ContainerBackupsGetExpired ( ) ( [ ] string , error ) { var result [ ] string var name string var expiryDate string q := `SELECT containers_backups.name, containers_backups.expiry_date FROM containers_backups` outfmt := [ ] interface { } { name , expiryDate } dbResults , err := queryScan ( c . db , q , nil , outfmt ) if err != nil { return nil , err } for _ , r := range dbResults { timestamp := r [ 1 ] var backupExpiry time . Time err = backupExpiry . UnmarshalText ( [ ] byte ( timestamp . ( string ) ) ) if err != nil { return [ ] string { } , err } if backupExpiry . IsZero ( ) { } } } return result , nil } 
func DefaultOS ( ) * OS { newOS := & OS { VarDir : shared . VarPath ( ) , CacheDir : shared . CachePath ( ) , LogDir : shared . LogPath ( ) , } newOS . InotifyWatch . Fd = - 1 newOS . InotifyWatch . Targets = make ( map [ string ] * InotifyTargetInfo ) return newOS } 
func ( s * OS ) Init ( ) error { err := s . initDirs ( ) if err != nil { return err } s . Architectures , err = util . GetArchitectures ( ) if err != nil { return err } s . LxcPath = filepath . Join ( s . VarDir , " " ) s . BackingFS , err = util . FilesystemDetect ( s . LxcPath ) if err != nil { logger . Error ( " " , log . Ctx { " " : err } ) } s . IdmapSet = util . GetIdmapSet ( ) s . ExecPath = util . GetExecPath ( ) s . RunningInUserNS = shared . RunningInUserNS ( ) s . initAppArmor ( ) s . initCGroup ( ) return nil } 
func ( op * operation ) AddHandler ( function func ( api . Operation ) ) ( * EventTarget , error ) { if err != nil { return nil , err } defer op . handlerLock . Unlock ( ) } err := json . Unmarshal ( event . Metadata , & newOp ) if err != nil || newOp . ID != op . ID { return } function ( newOp ) } return op . listener . AddHandler ( [ ] string { " " } , wrapped ) } 
func ( op * operation ) GetWebsocket ( secret string ) ( * websocket . Conn , error ) { return op . r . GetOperationWebsocket ( op . ID , secret ) } 
func ( op * operation ) RemoveHandler ( target * EventTarget ) error { defer op . handlerLock . Unlock ( ) } return op . listener . RemoveHandler ( target ) } 
func ( op * operation ) Refresh ( ) error { if err != nil { return err } return nil } 
func ( op * operation ) Wait ( ) error { } return nil } if err != nil { return err } <- op . chActive } return nil } 
func ( op * remoteOperation ) AddHandler ( function func ( api . Operation ) ) ( * EventTarget , error ) { var err error var target * EventTarget if err != nil { return nil , err } } else { } return target , nil } 
func ( op * remoteOperation ) CancelTarget ( ) error { if op . targetOp == nil { return fmt . Errorf ( " " ) } return op . targetOp . Cancel ( ) } 
func ( op * remoteOperation ) GetTarget ( ) ( * api . Operation , error ) { if op . targetOp == nil { return nil , fmt . Errorf ( " " ) } opAPI := op . targetOp . Get ( ) return & opAPI , nil } 
func ( op * remoteOperation ) Wait ( ) error { <- op . chDone if op . chPost != nil { <- op . chPost } return op . err } 
func Up ( config * Config ) ( * Endpoints , error ) { if config . Dir == " " { return nil , fmt . Errorf ( " " ) } if config . UnixSocket == " " { return nil , fmt . Errorf ( " " ) } if config . RestServer == nil { return nil , fmt . Errorf ( " " ) } if config . DevLxdServer == nil { return nil , fmt . Errorf ( " " ) } if config . Cert == nil { return nil , fmt . Errorf ( " " ) } endpoints := & Endpoints { systemdListenFDsStart : util . SystemdListenFDsStart , } err := endpoints . up ( config ) if err != nil { endpoints . Down ( ) return nil , err } return endpoints , nil } 
func ( e * Endpoints ) up ( config * Config ) error { e . mu . Lock ( ) defer e . mu . Unlock ( ) e . servers = map [ kind ] * http . Server { devlxd : config . DevLxdServer , local : config . RestServer , network : config . RestServer , cluster : config . RestServer , pprof : pprofCreateServer ( ) , } e . cert = config . Cert e . inherited = map [ kind ] bool { } var err error if len ( systemdListeners ) > 0 { e . listeners = activatedListeners ( systemdListeners , e . cert ) for kind := range e . listeners { e . inherited [ kind ] = true } } else { e . listeners = map [ kind ] net . Listener { } e . listeners [ local ] , err = localCreateListener ( config . UnixSocket , config . LocalUnixSocketGroup ) if err != nil { return fmt . Errorf ( " " , err ) } } if err != nil { return err } if config . NetworkAddress != " " { listener , ok := e . listeners [ network ] if ok { logger . Infof ( " " ) listener . Close ( ) e . inherited [ network ] = false } isCovered := util . IsAddressCovered ( config . ClusterAddress , config . NetworkAddress ) if config . ClusterAddress != " " && ! isCovered { e . listeners [ cluster ] , err = clusterCreateListener ( config . ClusterAddress , e . cert ) if err != nil { return err } logger . Infof ( " " ) e . serveHTTP ( cluster ) } } if config . DebugAddress != " " { e . listeners [ pprof ] , err = pprofCreateListener ( config . DebugAddress ) if err != nil { return err } logger . Infof ( " " ) e . serveHTTP ( pprof ) } logger . Infof ( " " ) e . serveHTTP ( devlxd ) logger . Infof ( " " ) e . serveHTTP ( local ) e . serveHTTP ( network ) return nil } 
func ( e * Endpoints ) Down ( ) error { e . mu . Lock ( ) defer e . mu . Unlock ( ) if e . listeners [ network ] != nil || e . listeners [ local ] != nil { logger . Infof ( " " ) err := e . closeListener ( network ) if err != nil { return err } err = e . closeListener ( local ) if err != nil { return err } } if e . listeners [ cluster ] != nil { logger . Infof ( " " ) err := e . closeListener ( cluster ) if err != nil { return err } } if e . listeners [ devlxd ] != nil { logger . Infof ( " " ) err := e . closeListener ( devlxd ) if err != nil { return err } } if e . listeners [ pprof ] != nil { logger . Infof ( " " ) err := e . closeListener ( pprof ) if err != nil { return err } } if e . tomb != nil { e . tomb . Kill ( nil ) e . tomb . Wait ( ) } return nil } 
func ( e * Endpoints ) serveHTTP ( kind kind ) { listener := e . listeners [ kind ] if listener == nil { return } ctx := log . Ctx { " " : listener . Addr ( ) } if e . inherited [ kind ] { ctx [ " " ] = true } message := fmt . Sprintf ( " " , descriptions [ kind ] ) logger . Info ( message , ctx ) server := e . servers [ kind ] } e . tomb . Go ( func ( ) error { server . Serve ( listener ) return nil } ) } 
func ( e * Endpoints ) closeListener ( kind kind ) error { listener := e . listeners [ kind ] if listener == nil { return nil } delete ( e . listeners , kind ) logger . Info ( " " , log . Ctx { " " : listener . Addr ( ) } ) return listener . Close ( ) } 
func activatedListeners ( systemdListeners [ ] net . Listener , cert * shared . CertInfo ) map [ kind ] net . Listener { listeners := map [ kind ] net . Listener { } for _ , listener := range systemdListeners { var kind kind switch listener . ( type ) { case * net . UnixListener : kind = local case * net . TCPListener : kind = network listener = networkTLSListener ( listener , cert ) default : continue } listeners [ kind ] = listener } return listeners } 
func ( c * Config ) CandidServer ( ) ( string , string , int64 , string ) { return c . m . GetString ( " " ) , c . m . GetString ( " " ) , c . m . GetInt64 ( " " ) , c . m . GetString ( " " ) } 
func ( c * Config ) RBACServer ( ) ( string , string , int64 , string , string , string , string ) { return c . m . GetString ( " " ) , c . m . GetString ( " " ) , c . m . GetInt64 ( " " ) , c . m . GetString ( " " ) , c . m . GetString ( " " ) , c . m . GetString ( " " ) , c . m . GetString ( " " ) } 
func ( c * Config ) AutoUpdateInterval ( ) time . Duration { n := c . m . GetInt64 ( " " ) return time . Duration ( n ) * time . Hour } 
func ( c * Config ) MAASController ( ) ( string , string ) { url := c . m . GetString ( " " ) key := c . m . GetString ( " " ) return url , key } 
func ( c * Config ) OfflineThreshold ( ) time . Duration { n := c . m . GetInt64 ( " " ) return time . Duration ( n ) * time . Second } 
func ConfigGetString ( cluster * db . Cluster , key string ) ( string , error ) { config , err := configGet ( cluster ) if err != nil { return " " , err } return config . m . GetString ( key ) , nil } 
func ConfigGetBool ( cluster * db . Cluster , key string ) ( bool , error ) { config , err := configGet ( cluster ) if err != nil { return false , err } return config . m . GetBool ( key ) , nil } 
func ConfigGetInt64 ( cluster * db . Cluster , key string ) ( int64 , error ) { config , err := configGet ( cluster ) if err != nil { return 0 , err } return config . m . GetInt64 ( key ) , nil } 
func ( e * Endpoints ) ClusterAddress ( ) string { e . mu . RLock ( ) defer e . mu . RUnlock ( ) listener := e . listeners [ cluster ] if listener == nil { return " " } return listener . Addr ( ) . String ( ) } 
func Debug ( msg string , ctx ... interface { } ) { if Log != nil { pc , fn , line , _ := runtime . Caller ( 1 ) msg := fmt . Sprintf ( " " , fn , line , runtime . FuncForPC ( pc ) . Name ( ) , msg ) Log . Debug ( msg , ctx ... ) } } 
func Infof ( format string , args ... interface { } ) { if Log != nil { msg := fmt . Sprintf ( format , args ... ) pc , fn , line , _ := runtime . Caller ( 1 ) msg = fmt . Sprintf ( " " , fn , line , runtime . FuncForPC ( pc ) . Name ( ) , msg ) Log . Info ( msg ) } } 
func RestServer ( d * Daemon ) * http . Server { mux := mux . NewRouter ( ) mux . StrictSlash ( false ) mux . HandleFunc ( " " , func ( w http . ResponseWriter , r * http . Request ) { w . Header ( ) . Set ( " " , " " ) SyncResponse ( true , [ ] string { " " } ) . Render ( w ) } ) for endpoint , f := range d . gateway . HandlerFuncs ( ) { mux . HandleFunc ( endpoint , f ) } for _ , c := range api10 { d . createCmd ( mux , " " , c ) } for _ , c := range apiInternal { d . createCmd ( mux , " " , c ) } mux . NotFoundHandler = http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { logger . Info ( " " , log . Ctx { " " : r . URL } ) w . Header ( ) . Set ( " " , " " ) NotFound ( nil ) . Render ( w ) } ) return & http . Server { Handler : & lxdHttpServer { r : mux , d : d } } } 
func projectParam ( request * http . Request ) string { project := queryParam ( request , " " ) if project == " " { project = " " } return project } 
func queryParam ( request * http . Request , key string ) string { var values url . Values var err error if request . URL != nil { values , err = url . ParseQuery ( request . URL . RawQuery ) if err != nil { logger . Warnf ( " " , request . URL . RawQuery , err ) return " " } } if values == nil { values = make ( url . Values ) } return values . Get ( key ) } 
func newDb ( ) * cobra . Command { cmd := & cobra . Command { Use : " " , Short : " " , RunE : func ( cmd * cobra . Command , args [ ] string ) error { return fmt . Errorf ( " " ) } , } cmd . AddCommand ( newDbSchema ( ) ) cmd . AddCommand ( newDbMapper ( ) ) return cmd } 
func ( t OperationType ) Description ( ) string { switch t { case OperationClusterBootstrap : return " " case OperationClusterJoin : return " " case OperationBackupCreate : return " " case OperationBackupRename : return " " case OperationBackupRestore : return " " case OperationBackupRemove : return " " case OperationConsoleShow : return " " case OperationContainerCreate : return " " case OperationContainerUpdate : return " " case OperationContainerRename : return " " case OperationContainerMigrate : return " " case OperationContainerLiveMigrate : return " " case OperationContainerFreeze : return " " case OperationContainerUnfreeze : return " " case OperationContainerDelete : return " " case OperationContainerStart : return " " case OperationContainerStop : return " " case OperationContainerRestart : return " " case OperationCommandExec : return " " case OperationSnapshotCreate : return " " case OperationSnapshotRename : return " " case OperationSnapshotRestore : return " " case OperationSnapshotTransfer : return " " case OperationSnapshotUpdate : return " " case OperationSnapshotDelete : return " " case OperationImageDownload : return " " case OperationImageDelete : return " " case OperationImageToken : return " " case OperationImageRefresh : return " " case OperationVolumeCopy : return " " case OperationVolumeCreate : return " " case OperationVolumeMigrate : return " " case OperationVolumeMove : return " " case OperationVolumeSnapshotCreate : return " " case OperationVolumeSnapshotDelete : return " " case OperationVolumeSnapshotUpdate : return " " case OperationProjectRename : return " " case OperationImagesExpire : return " " case OperationImagesPruneLeftover : return " " case OperationImagesUpdate : return " " case OperationImagesSynchronize : return " " case OperationLogsExpire : return " " case OperationInstanceTypesUpdate : return " " case OperationBackupsExpire : return " " case OperationSnapshotsExpire : return " " default : return " " } } 
func ( t OperationType ) Permission ( ) string { switch t { case OperationBackupCreate : return " " case OperationBackupRename : return " " case OperationBackupRestore : return " " case OperationBackupRemove : return " " case OperationConsoleShow : return " " case OperationContainerFreeze : return " " case OperationContainerUnfreeze : return " " case OperationContainerStart : return " " case OperationContainerStop : return " " case OperationContainerRestart : return " " case OperationCommandExec : return " " case OperationSnapshotCreate : return " " case OperationSnapshotRename : return " " case OperationSnapshotTransfer : return " " case OperationSnapshotUpdate : return " " case OperationSnapshotDelete : return " " case OperationContainerCreate : return " " case OperationContainerUpdate : return " " case OperationContainerRename : return " " case OperationContainerMigrate : return " " case OperationContainerLiveMigrate : return " " case OperationContainerDelete : return " " case OperationSnapshotRestore : return " " case OperationImageDownload : return " " case OperationImageDelete : return " " case OperationImageToken : return " " case OperationImageRefresh : return " " case OperationImagesUpdate : return " " case OperationImagesSynchronize : return " " } return " " } 
func ( c * ClusterTx ) OperationsUUIDs ( ) ( [ ] string , error ) { stmt := " " return query . SelectStrings ( c . tx , stmt , c . nodeID ) } 
func ( c * ClusterTx ) OperationNodes ( project string ) ( [ ] string , error ) { stmt := ` SELECT DISTINCT nodes.address FROM operations LEFT OUTER JOIN projects ON projects.id = operations.project_id JOIN nodes ON nodes.id = operations.node_id WHERE projects.name = ? OR operations.project_id IS NULL ` return query . SelectStrings ( c . tx , stmt , project ) } 
func ( c * ClusterTx ) OperationByUUID ( uuid string ) ( Operation , error ) { null := Operation { } operations , err := c . operations ( " " , uuid ) if err != nil { return null , err } switch len ( operations ) { case 0 : return null , ErrNoSuchObject case 1 : return operations [ 0 ] , nil default : return null , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) OperationAdd ( project , uuid string , typ OperationType ) ( int64 , error ) { var projectID interface { } if project != " " { var err error projectID , err = c . ProjectID ( project ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } } else { projectID = nil } columns := [ ] string { " " , " " , " " , " " } values := [ ] interface { } { uuid , c . nodeID , typ , projectID } return query . UpsertObject ( c . tx , " " , columns , values ) } 
func ( c * ClusterTx ) OperationRemove ( uuid string ) error { result , err := c . tx . Exec ( " " , uuid ) if err != nil { return err } n , err := result . RowsAffected ( ) if err != nil { return err } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) operations ( where string , args ... interface { } ) ( [ ] Operation , error ) { operations := [ ] Operation { } dest := func ( i int ) [ ] interface { } { operations = append ( operations , Operation { } ) return [ ] interface { } { & operations [ i ] . ID , & operations [ i ] . UUID , & operations [ i ] . NodeAddress , & operations [ i ] . Type , } } sql := ` SELECT operations.id, uuid, nodes.address, type FROM operations JOIN nodes ON nodes.id = node_id ` if where != " " { sql += fmt . Sprintf ( " " , where ) } sql += " " stmt , err := c . tx . Prepare ( sql ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , args ... ) if err != nil { return nil , errors . Wrap ( err , " " ) } return operations , nil } 
func expireLogsTask ( state * state . State ) ( task . Func , task . Schedule ) { f := func ( ctx context . Context ) { opRun := func ( op * operation ) error { return expireLogs ( ctx , state ) } op , err := operationCreate ( state . Cluster , " " , operationClassTask , db . OperationLogsExpire , nil , nil , opRun , nil , nil ) if err != nil { logger . Error ( " " , log . Ctx { " " : err } ) return } logger . Infof ( " " ) _ , err = op . Run ( ) if err != nil { logger . Error ( " " , log . Ctx { " " : err } ) } logger . Infof ( " " ) } return f , task . Daily ( ) } 
func absPath ( path string ) string { elems := strings . Split ( filename , string ( filepath . Separator ) ) for i := len ( elems ) - 1 ; i >= 0 ; i -- { if elems [ i ] == " " { elems = append ( [ ] string { string ( filepath . Separator ) } , elems [ : i ] ... ) elems = append ( elems , path ) return filepath . Join ( elems ... ) } } log . Fatalf ( " " ) return " " } 
func ( s Schema ) Keys ( ) [ ] string { keys := make ( [ ] string , len ( s ) ) i := 0 for key := range s { keys [ i ] = key i ++ } sort . Strings ( keys ) return keys } 
func ( s Schema ) Defaults ( ) map [ string ] interface { } { values := make ( map [ string ] interface { } , len ( s ) ) for name , key := range s { values [ name ] = key . Default } return values } 
func ( s Schema ) mustGetKey ( name string ) Key { key , ok := s [ name ] if ! ok { panic ( fmt . Sprintf ( " " , name ) ) } return key } 
func ( s Schema ) assertKeyType ( name string , code Type ) { key := s . mustGetKey ( name ) if key . Type != code { panic ( fmt . Sprintf ( " " , name , key . Type , code ) ) } } 
func ( v * Key ) validate ( value string ) error { validator := v . Validator if validator == nil { } } switch v . Type { case String : case Bool : if ! shared . StringInSlice ( strings . ToLower ( value ) , booleans ) { return fmt . Errorf ( " " ) } case Int64 : _ , err := strconv . ParseInt ( value , 10 , 64 ) if err != nil { return fmt . Errorf ( " " ) } default : panic ( fmt . Sprintf ( " " , v . Type ) ) } if v . Deprecated != " " && value != v . Default { return fmt . Errorf ( " " , v . Deprecated ) } } 
func ( r * ProtocolLXD ) GetStoragePoolVolumes ( pool string ) ( [ ] api . StorageVolume , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } volumes := [ ] api . StorageVolume { } if err != nil { return nil , err } return volumes , nil } 
func ( r * ProtocolLXD ) GetStoragePoolVolume ( pool string , volType string , name string ) ( * api . StorageVolume , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } volume := api . StorageVolume { } etag , err := r . queryStruct ( " " , path , nil , " " , & volume ) if err != nil { return nil , " " , err } return & volume , etag , nil } 
func ( r * ProtocolLXD ) CreateStoragePoolVolume ( pool string , volume api . StorageVolumesPost ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } _ , _ , err := r . query ( " " , path , volume , " " ) if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) CreateStoragePoolVolumeSnapshot ( pool string , volumeType string , volumeName string , snapshot api . StorageVolumeSnapshotsPost ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } op , _ , err := r . queryOperation ( " " , path , snapshot , " " ) if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) GetStoragePoolVolumeSnapshots ( pool string , volumeType string , volumeName string ) ( [ ] api . StorageVolumeSnapshot , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } snapshots := [ ] api . StorageVolumeSnapshot { } path := fmt . Sprintf ( " " , url . QueryEscape ( pool ) , url . QueryEscape ( volumeType ) , url . QueryEscape ( volumeName ) ) _ , err := r . queryStruct ( " " , path , nil , " " , & snapshots ) if err != nil { return nil , err } return snapshots , nil } 
func ( r * ProtocolLXD ) GetStoragePoolVolumeSnapshot ( pool string , volumeType string , volumeName string , snapshotName string ) ( * api . StorageVolumeSnapshot , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } snapshot := api . StorageVolumeSnapshot { } path := fmt . Sprintf ( " " , url . QueryEscape ( pool ) , url . QueryEscape ( volumeType ) , url . QueryEscape ( volumeName ) , url . QueryEscape ( snapshotName ) ) etag , err := r . queryStruct ( " " , path , nil , " " , & snapshot ) if err != nil { return nil , " " , err } return & snapshot , etag , nil } 
func ( r * ProtocolLXD ) UpdateStoragePoolVolumeSnapshot ( pool string , volumeType string , volumeName string , snapshotName string , volume api . StorageVolumeSnapshotPut , ETag string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } _ , _ , err := r . queryOperation ( " " , path , volume , ETag ) if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) MigrateStoragePoolVolume ( pool string , volume api . StorageVolumePost ) ( Operation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } } op , _ , err := r . queryOperation ( " " , path , volume , " " ) if err != nil { return nil , err } return op , nil } 
func ( r * ProtocolLXD ) CopyStoragePoolVolume ( pool string , source ContainerServer , sourcePool string , volume api . StorageVolume , args * StoragePoolVolumeCopyArgs ) ( RemoteOperation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if args != nil && args . VolumeOnly && ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } req := api . StorageVolumesPost { Name : args . Name , Type : volume . Type , Source : api . StorageVolumeSource { Name : volume . Name , Type : " " , Pool : sourcePool , VolumeOnly : args . VolumeOnly , } , } req . Config = volume . Config req . Description = volume . Description if r == source { if err != nil { return nil , err } rop := remoteOperation { targetOp : op , chDone : make ( chan bool ) , } close ( rop . chDone ) } ( ) return & rop , nil } if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } sourceReq := api . StorageVolumePost { Migration : true , Name : volume . Name , Pool : sourcePool , VolumeOnly : args . VolumeOnly , } if err != nil { return nil , err } req . Source . Mode = " " if err != nil { return nil , err } opAPI := op . Get ( ) targetSecrets := map [ string ] string { } for k , v := range opAPI . Metadata { targetSecrets [ k ] = v . ( string ) } target . Operation = opAPI . ID target . Websockets = targetSecrets target . Certificate = info . Certificate sourceReq . Target = & target return r . tryMigrateStoragePoolVolume ( source , sourcePool , sourceReq , info . Addresses ) } if err != nil { return nil , err } if err != nil { return nil , err } opAPI := op . Get ( ) for k , v := range opAPI . Metadata { sourceSecrets [ k ] = v . ( string ) } req . Source . Mode = " " if err != nil { return nil , err } targetOpAPI := targetOp . Get ( ) for k , v := range targetOpAPI . Metadata { targetSecrets [ k ] = v . ( string ) } if err != nil { return nil , err } close ( rop . chDone ) } ( ) return & rop , nil } req . Source . Mode = " " req . Source . Operation = opAPI . ID req . Source . Websockets = sourceSecrets req . Source . Certificate = info . Certificate return r . tryCreateStoragePoolVolume ( pool , req , info . Addresses ) } 
func ( r * ProtocolLXD ) MoveStoragePoolVolume ( pool string , source ContainerServer , sourcePool string , volume api . StorageVolume , args * StoragePoolVolumeMoveArgs ) ( RemoteOperation , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } if r != source { return nil , fmt . Errorf ( " " ) } req := api . StorageVolumePost { Name : args . Name , Pool : pool , } if err != nil { return nil , err } rop := remoteOperation { targetOp : op , chDone : make ( chan bool ) , } close ( rop . chDone ) } ( ) return & rop , nil } 
func ( r * ProtocolLXD ) UpdateStoragePoolVolume ( pool string , volType string , name string , volume api . StorageVolumePut , ETag string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if volume . Restore != " " && ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } _ , _ , err := r . query ( " " , path , volume , ETag ) if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) DeleteStoragePoolVolume ( pool string , volType string , name string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } _ , _ , err := r . query ( " " , path , nil , " " ) if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) RenameStoragePoolVolume ( pool string , volType string , name string , volume api . StorageVolumePost ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } path := fmt . Sprintf ( " " , url . QueryEscape ( pool ) , url . QueryEscape ( volType ) , url . QueryEscape ( name ) ) if err != nil { return err } return nil } 
func storagePoolUsedByGet ( state * state . State , poolID int64 , poolName string ) ( [ ] string , error ) { if err != nil && err != db . ErrNoSuchObject { return [ ] string { } , err } if err != nil { return [ ] string { } , err } slicelen := len ( volumes ) + len ( profiles ) if slicelen == 0 { return [ ] string { } , nil } for i := 0 ; i < len ( volumes ) ; i ++ { apiEndpoint , _ := storagePoolVolumeTypeNameToAPIEndpoint ( volumes [ i ] . Type ) switch apiEndpoint { case storagePoolVolumeAPIEndpointContainers : if strings . Index ( volumes [ i ] . Name , shared . SnapshotDelimiter ) > 0 { parentName , snapOnlyName , _ := containerGetParentAndSnapshotName ( volumes [ i ] . Name ) poolUsedBy [ i ] = fmt . Sprintf ( " " , version . APIVersion , parentName , snapOnlyName ) } else { poolUsedBy [ i ] = fmt . Sprintf ( " " , version . APIVersion , volumes [ i ] . Name ) } case storagePoolVolumeAPIEndpointImages : poolUsedBy [ i ] = fmt . Sprintf ( " " , version . APIVersion , volumes [ i ] . Name ) case storagePoolVolumeAPIEndpointCustom : poolUsedBy [ i ] = fmt . Sprintf ( " " , version . APIVersion , poolName , volumes [ i ] . Type , volumes [ i ] . Name ) default : } } for i := 0 ; i < len ( profiles ) ; i ++ { poolUsedBy [ i + len ( volumes ) ] = fmt . Sprintf ( " " , version . APIVersion , profiles [ i ] ) } return poolUsedBy , err } 
func doStoragePoolCreateInternal ( state * state . State , poolName , poolDescription string , driver string , config map [ string ] string , isNotification bool ) error { tryUndo := true s , err := storagePoolInit ( state , poolName ) if err != nil { return err } return os . MkdirAll ( volumeMntPoint , 0711 ) } err = s . StoragePoolCreate ( ) if err != nil { return err } defer func ( ) { if ! tryUndo { return } s . StoragePoolDelete ( ) } ( ) configDiff , _ := storageConfigDiff ( config , postCreateConfig ) if len ( configDiff ) > 0 { if err != nil { return fmt . Errorf ( " " , poolName , err ) } } return nil } 
func dbStoragePoolCreateAndUpdateCache ( db * db . Cluster , poolName string , poolDescription string , poolDriver string , poolConfig map [ string ] string ) ( int64 , error ) { id , err := db . StoragePoolCreate ( poolName , poolDescription , poolDriver , poolConfig ) if err != nil { return id , err } return id , nil } 
func dbStoragePoolDeleteAndUpdateCache ( db * db . Cluster , poolName string ) error { _ , err := db . StoragePoolDelete ( poolName ) if err != nil { return err } return err } 
func operationGet ( d * Daemon , r * http . Request ) Response { id := mux . Vars ( r ) [ " " ] var body * api . Operation if err == nil { _ , body , err = op . Render ( ) if err != nil { return SmartError ( err ) } return SyncResponse ( true , body ) } err = d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { operation , err := tx . OperationByUUID ( id ) if err != nil { return err } address = operation . NodeAddress return nil } ) if err != nil { return SmartError ( err ) } cert := d . endpoints . NetworkCert ( ) client , err := cluster . Connect ( address , cert , false ) if err != nil { return SmartError ( err ) } body , _ , err = client . GetOperation ( id ) if err != nil { return SmartError ( err ) } return SyncResponse ( true , body ) } 
func containerGetParentAndSnapshotName ( name string ) ( string , string , bool ) { fields := strings . SplitN ( name , shared . SnapshotDelimiter , 2 ) if len ( fields ) == 1 { return name , " " , false } return fields [ 0 ] , fields [ 1 ] , true } 
func containerCreateAsEmpty ( d * Daemon , args db . ContainerArgs ) ( container , error ) { if err != nil { return nil , err } if err != nil { c . Delete ( ) return nil , err } if err != nil { c . Delete ( ) return nil , err } return c , nil } 
func containerLoadFromAllProjects ( s * state . State ) ( [ ] container , error ) { var projects [ ] string err := s . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error projects , err = tx . ProjectNames ( ) return err } ) if err != nil { return nil , err } containers := [ ] container { } for _ , project := range projects { projectContainers , err := containerLoadByProject ( s , project ) if err != nil { return nil , errors . Wrapf ( nil , " " , project ) } containers = append ( containers , projectContainers ... ) } return containers , nil } 
func containerLoadNodeAll ( s * state . State ) ( [ ] container , error ) { err := s . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error cts , err = tx . ContainerNodeList ( ) if err != nil { return err } return nil } ) if err != nil { return nil , err } return containerLoadAllInternal ( cts , s ) } 
func containerLoadNodeProjectAll ( s * state . State , project string ) ( [ ] container , error ) { err := s . Cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error cts , err = tx . ContainerNodeProjectList ( project ) if err != nil { return err } return nil } ) if err != nil { return nil , err } return containerLoadAllInternal ( cts , s ) } 
func Heartbeat ( gateway * Gateway , cluster * db . Cluster ) ( task . Func , task . Schedule ) { heartbeat := func ( ctx context . Context ) { if gateway . server == nil || gateway . memoryDial != nil { } raftNodes , err := gateway . currentRaftNodes ( ) if err == raft . ErrNotLeader { return } logger . Debugf ( " " ) if err != nil { logger . Warnf ( " " , err ) return } err = gateway . db . Transaction ( func ( tx * db . NodeTx ) error { return tx . RaftNodesReplace ( raftNodes ) } ) if err != nil { logger . Warnf ( " " , err ) return } var nodes [ ] db . NodeInfo var nodeAddress string err = cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error nodes , err = tx . Nodes ( ) if err != nil { return err } nodeAddress , err = tx . NodeAddress ( ) if err != nil { return err } return nil } ) if err != nil { logger . Warnf ( " " , err ) return } heartbeats := make ( [ ] time . Time , len ( nodes ) ) heartbeatsLock := sync . Mutex { } heartbeatsWg := sync . WaitGroup { } for i , node := range nodes { heartbeats [ i ] = time . Now ( ) heartbeatsLock . Unlock ( ) continue } go func ( i int , address string ) { defer heartbeatsWg . Done ( ) logger . Debugf ( " " , address ) err := heartbeatNode ( ctx , address , gateway . cert , raftNodes ) if err == nil { heartbeatsLock . Lock ( ) heartbeats [ i ] = time . Now ( ) heartbeatsLock . Unlock ( ) logger . Debugf ( " " , address ) } else { logger . Debugf ( " " , address , err ) } } ( i , node . Address ) } heartbeatsWg . Wait ( ) return } err = cluster . Transaction ( func ( tx * db . ClusterTx ) error { for i , node := range nodes { if heartbeats [ i ] . Equal ( time . Time { } ) { continue } err := tx . NodeHeartbeat ( node . Address , heartbeats [ i ] ) if err != nil { return err } } return nil } ) if err != nil { logger . Warnf ( " " , err ) } logger . Debugf ( " " ) } go func ( ) { heartbeat ( ctx ) ch <- struct { } { } } ( ) select { case <- ch : case <- ctx . Done ( ) : } } schedule := task . Every ( time . Duration ( heartbeatInterval ) * time . Second ) return heartbeatWrapper , schedule } 
func heartbeatNode ( taskCtx context . Context , address string , cert * shared . CertInfo , raftNodes [ ] db . RaftNode ) error { logger . Debugf ( " " , address ) config , err := tlsClientConfig ( cert ) if err != nil { return err } url := fmt . Sprintf ( " " , address , databaseEndpoint ) client := & http . Client { Transport : & http . Transport { TLSClientConfig : config } } buffer := bytes . Buffer { } err = json . NewEncoder ( & buffer ) . Encode ( raftNodes ) if err != nil { return err } request , err := http . NewRequest ( " " , url , bytes . NewReader ( buffer . Bytes ( ) ) ) if err != nil { return err } ctx , cancel := context . WithTimeout ( context . Background ( ) , 2 * time . Second ) defer cancel ( ) request = request . WithContext ( ctx ) request . Close = true go func ( ) { response , err := client . Do ( request ) if err != nil { errCh <- errors . Wrap ( err , " " ) return } defer response . Body . Close ( ) if response . StatusCode != http . StatusOK { errCh <- fmt . Errorf ( " " , response . Status ) return } errCh <- nil } ( ) select { case err := <- errCh : return err case <- taskCtx . Done ( ) : return taskCtx . Err ( ) } } 
func ( c * cmdList ) dotPrefixMatch ( short string , full string ) bool { fullMembs := strings . Split ( full , " " ) shortMembs := strings . Split ( short , " " ) if len ( fullMembs ) != len ( shortMembs ) { return false } for i := range fullMembs { if ! strings . HasPrefix ( fullMembs [ i ] , shortMembs [ i ] ) { return false } } return true } 
func ( s * storageZfs ) StorageCoreInit ( ) error { s . sType = storageTypeZfs typeName , err := storageTypeToString ( s . sType ) if err != nil { return err } s . sTypeName = typeName if zfsVersion != " " { s . sTypeVersion = zfsVersion return nil } util . LoadModule ( " " ) if ! zfsIsEnabled ( ) { return fmt . Errorf ( " \" \" " ) } s . sTypeVersion , err = zfsToolVersionGet ( ) if err != nil { s . sTypeVersion , err = zfsModuleVersionGet ( ) if err != nil { return err } } zfsVersion = s . sTypeVersion return nil } 
func ( s * storageZfs ) StoragePoolInit ( ) error { err := s . StorageCoreInit ( ) if err != nil { return err } } return nil } 
func ( s * storageZfs ) ContainerMount ( c container ) ( bool , error ) { return s . doContainerMount ( c . Project ( ) , c . Name ( ) , c . IsPrivileged ( ) ) } 
func ( s * storageZfs ) ContainerStorageReady ( container container ) bool { volumeName := projectPrefix ( container . Project ( ) , container . Name ( ) ) fs := fmt . Sprintf ( " " , volumeName ) return zfsFilesystemEntityExists ( s . getOnDiskPoolName ( ) , fs ) } 
func ( s * storageZfs ) ImageCreate ( fingerprint string , tracker * ioprogress . ProgressTracker ) error { logger . Debugf ( " \" \" \" \" " , fingerprint , s . pool . Name ) poolName := s . getOnDiskPoolName ( ) imageMntPoint := getImageMountPoint ( s . pool . Name , fingerprint ) fs := fmt . Sprintf ( " " , fingerprint ) revert := true subrevert := true err := s . createImageDbPoolVolume ( fingerprint ) if err != nil { return err } defer func ( ) { if ! subrevert { return } s . deleteImageDbPoolVolume ( fingerprint ) } ( ) if zfsFilesystemEntityExists ( poolName , fmt . Sprintf ( " " , fs ) ) { if err := zfsPoolVolumeRename ( poolName , fmt . Sprintf ( " " , fs ) , fs , true ) ; err != nil { return err } defer func ( ) { if ! revert { return } s . ImageDelete ( fingerprint ) } ( ) if err != nil { return err } revert = false subrevert = false return nil } if ! shared . PathExists ( imageMntPoint ) { err := os . MkdirAll ( imageMntPoint , 0700 ) if err != nil { return err } defer func ( ) { if ! subrevert { return } os . RemoveAll ( imageMntPoint ) } ( ) } tmpImageDir , err := ioutil . TempDir ( tmp , " " ) if err != nil { return err } defer os . RemoveAll ( tmpImageDir ) imagePath := shared . VarPath ( " " , fingerprint ) msg , err := zfsPoolVolumeCreate ( dataset , " " ) if err != nil { logger . Errorf ( " \" \" \" \" " , dataset , s . pool . Name , msg ) return err } subrevert = false defer func ( ) { if ! revert { return } s . ImageDelete ( fingerprint ) } ( ) if err != nil { return err } } if err != nil { return err } } } } if err != nil { return err } revert = false logger . Debugf ( " \" \" \" \" " , fingerprint , s . pool . Name ) return nil } 
func AskBool ( question string , defaultAnswer string ) bool { for { answer := askQuestion ( question , defaultAnswer ) if shared . StringInSlice ( strings . ToLower ( answer ) , [ ] string { " " , " " } ) { return true } else if shared . StringInSlice ( strings . ToLower ( answer ) , [ ] string { " " , " " } ) { return false } invalidInput ( ) } } 
func AskChoice ( question string , choices [ ] string , defaultAnswer string ) string { for { answer := askQuestion ( question , defaultAnswer ) if shared . StringInSlice ( answer , choices ) { return answer } invalidInput ( ) } } 
func AskInt ( question string , min int64 , max int64 , defaultAnswer string ) int64 { for { answer := askQuestion ( question , defaultAnswer ) result , err := strconv . ParseInt ( answer , 10 , 64 ) if err == nil && ( min == - 1 || result >= min ) && ( max == - 1 || result <= max ) { return result } invalidInput ( ) } } 
func AskString ( question string , defaultAnswer string , validate func ( string ) error ) string { for { answer := askQuestion ( question , defaultAnswer ) if validate != nil { error := validate ( answer ) if error != nil { fmt . Fprintf ( os . Stderr , " \n \n " , error ) continue } return answer } if len ( answer ) != 0 { return answer } invalidInput ( ) } } 
func AskPassword ( question string ) string { for { fmt . Printf ( question ) pwd , _ := terminal . ReadPassword ( 0 ) fmt . Println ( " " ) inFirst := string ( pwd ) inFirst = strings . TrimSuffix ( inFirst , " \n " ) fmt . Printf ( " " ) pwd , _ = terminal . ReadPassword ( 0 ) fmt . Println ( " " ) inSecond := string ( pwd ) inSecond = strings . TrimSuffix ( inSecond , " \n " ) if inFirst == inSecond { return inFirst } invalidInput ( ) } } 
func AskPasswordOnce ( question string ) string { fmt . Printf ( question ) pwd , _ := terminal . ReadPassword ( 0 ) fmt . Println ( " " ) return string ( pwd ) } 
func askQuestion ( question , defaultAnswer string ) string { fmt . Printf ( question ) return readAnswer ( defaultAnswer ) } 
func readAnswer ( defaultAnswer string ) string { answer , _ := stdin . ReadString ( '\n' ) answer = strings . TrimSuffix ( answer , " \n " ) answer = strings . TrimSpace ( answer ) if answer == " " { answer = defaultAnswer } return answer } 
func profilesGet ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) recursion := util . IsRecursionRequest ( r ) var result interface { } err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { hasProfiles , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! hasProfiles { project = " " } filter := db . ProfileFilter { Project : project , } if recursion { profiles , err := tx . ProfileList ( filter ) if err != nil { return err } apiProfiles := make ( [ ] * api . Profile , len ( profiles ) ) for i , profile := range profiles { apiProfiles [ i ] = db . ProfileToAPI ( & profile ) } result = apiProfiles } else { result , err = tx . ProfileURIs ( filter ) } return err } ) if err != nil { return SmartError ( err ) } return SyncResponse ( true , result ) } 
func profilePost ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) name := mux . Vars ( r ) [ " " ] if name == " " { return Forbidden ( errors . New ( " " ) ) } req := api . ProfilePost { } if err := json . NewDecoder ( r . Body ) . Decode ( & req ) ; err != nil { return BadRequest ( err ) } } if strings . Contains ( req . Name , " " ) { return BadRequest ( fmt . Errorf ( " " ) ) } if shared . StringInSlice ( req . Name , [ ] string { " " , " " } ) { return BadRequest ( fmt . Errorf ( " " , req . Name ) ) } err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { hasProfiles , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! hasProfiles { project = " " } if err == nil { return fmt . Errorf ( " " , req . Name ) } return tx . ProfileRename ( project , name , req . Name ) } ) if err != nil { return SmartError ( err ) } return SyncResponseLocation ( true , nil , fmt . Sprintf ( " " , version . APIVersion , req . Name ) ) } 
func profileDelete ( d * Daemon , r * http . Request ) Response { project := projectParam ( r ) name := mux . Vars ( r ) [ " " ] if name == " " { return Forbidden ( errors . New ( " " ) ) } err := d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { hasProfiles , err := tx . ProjectHasProfiles ( project ) if err != nil { return errors . Wrap ( err , " " ) } if ! hasProfiles { project = " " } profile , err := tx . ProfileGet ( project , name ) if err != nil { return err } if len ( profile . UsedBy ) > 0 { return fmt . Errorf ( " " ) } return tx . ProfileDelete ( project , name ) } ) if err != nil { return SmartError ( err ) } return EmptySyncResponse } 
func IsRootDiskDevice ( device map [ string ] string ) bool { if device [ " " ] == " " && device [ " " ] == " " && device [ " " ] == " " { return true } return false } 
func GetRootDiskDevice ( devices map [ string ] map [ string ] string ) ( string , map [ string ] string , error ) { var devName string var dev map [ string ] string for n , d := range devices { if IsRootDiskDevice ( d ) { if devName != " " { return " " , nil , fmt . Errorf ( " " ) } devName = n dev = d } } if devName != " " { return devName , dev , nil } return " " , nil , fmt . Errorf ( " " ) } 
func ConfigKeyChecker ( key string ) ( func ( value string ) error , error ) { if f , ok := KnownContainerConfigKeys [ key ] ; ok { return f , nil } if strings . HasPrefix ( key , " " ) { if strings . HasSuffix ( key , " " ) { return IsAny , nil } if strings . HasSuffix ( key , " " ) { return IsAny , nil } if strings . HasSuffix ( key , " " ) { return IsAny , nil } } if strings . HasPrefix ( key , " " ) { return IsAny , nil } if strings . HasPrefix ( key , " " ) { return IsAny , nil } if strings . HasPrefix ( key , " " ) { return IsAny , nil } if strings . HasPrefix ( key , " " ) && ( len ( key ) > len ( " " ) ) { return IsAny , nil } return nil , fmt . Errorf ( " " , key ) } 
func ForwardedResponse ( client lxd . ContainerServer , request * http . Request ) Response { return & forwardedResponse { client : client , request : request , } } 
func ForwardedResponseIfTargetIsRemote ( d * Daemon , request * http . Request ) Response { targetNode := queryParam ( request , " " ) if targetNode == " " { return nil } if err != nil { return SmartError ( err ) } if address != " " { client , err := cluster . Connect ( address , cert , false ) if err != nil { return SmartError ( err ) } return ForwardedResponse ( client , request ) } return nil } 
func ForwardedResponseIfContainerIsRemote ( d * Daemon , r * http . Request , project , name string ) ( Response , error ) { cert := d . endpoints . NetworkCert ( ) client , err := cluster . ConnectIfContainerIsRemote ( d . cluster , project , name , cert ) if err != nil { return nil , err } if client == nil { return nil , nil } return ForwardedResponse ( client , r ) , nil } 
func ForwardedResponseIfVolumeIsRemote ( d * Daemon , r * http . Request , poolID int64 , volumeName string , volumeType int ) Response { if queryParam ( r , " " ) != " " { return nil } cert := d . endpoints . NetworkCert ( ) client , err := cluster . ConnectIfVolumeIsRemote ( d . cluster , poolID , volumeName , volumeType , cert ) if err != nil && err != db . ErrNoSuchObject { return SmartError ( err ) } if client == nil { return nil } return ForwardedResponse ( client , r ) } 
func ForwardedOperationResponse ( project string , op * api . Operation ) Response { return & forwardedOperationResponse { op : op , project : project , } } 
func SmartError ( err error ) Response { switch errors . Cause ( err ) { case nil : return EmptySyncResponse case os . ErrNotExist , sql . ErrNoRows , db . ErrNoSuchObject : return NotFound ( nil ) case os . ErrPermission : return Forbidden ( nil ) case db . ErrAlreadyDefined , sqlite3 . ErrConstraintUnique : return Conflict ( nil ) case dqlite . ErrNoAvailableLeader : return Unavailable ( err ) default : return InternalError ( err ) } } 
func KeyValue ( s string ) ( string , string , error ) { parts := strings . Split ( s , " " ) if len ( parts ) != 2 { return " " , " " , fmt . Errorf ( " " , s ) } return parts [ 0 ] , parts [ 1 ] , nil } 
func ( p * ProgressRenderer ) Done ( msg string ) { defer p . lock . Unlock ( ) } } } } if len ( msg ) > p . maxLength { p . maxLength = len ( msg ) } else { fmt . Printf ( " \r " , strings . Repeat ( " " , p . maxLength ) ) } fmt . Print ( " \r " ) fmt . Print ( msg ) } 
func ( p * ProgressRenderer ) Update ( status string ) { if timeout . Seconds ( ) > 0 { time . Sleep ( timeout ) } defer p . lock . Unlock ( ) } } } p . terminal = 1 } if p . terminal != 1 { return } if p . Format != " " { msg = p . Format } msg = fmt . Sprintf ( msg , status ) } if len ( msg ) > p . maxLength { p . maxLength = len ( msg ) } else { fmt . Printf ( " \r " , strings . Repeat ( " " , p . maxLength ) ) } fmt . Print ( msg ) } 
func ( p * ProgressRenderer ) Warn ( status string , timeout time . Duration ) { defer p . lock . Unlock ( ) } msg := fmt . Sprintf ( " " , status ) } if len ( msg ) > p . maxLength { p . maxLength = len ( msg ) } else { fmt . Printf ( " \r " , strings . Repeat ( " " , p . maxLength ) ) } fmt . Print ( msg ) } 
func ( p * ProgressRenderer ) UpdateProgress ( progress ioprogress . ProgressData ) { p . Update ( progress . Text ) } 
func ( p * ProgressRenderer ) UpdateOp ( op api . Operation ) { if op . Metadata == nil { return } for key , value := range op . Metadata { if ! strings . HasSuffix ( key , " " ) { continue } p . Update ( value . ( string ) ) break } } 
func ( d * Daemon ) ImageDownload ( op * operation , server string , protocol string , certificate string , secret string , alias string , forContainer bool , autoUpdate bool , storagePool string , preferCached bool , project string ) ( * api . Image , error ) { var err error var ctxMap log . Ctx var remote lxd . ImageServer var info * api . Image } imageStreamCache , err := imageGetStreamCache ( d ) if err != nil { imageStreamCacheLock . Unlock ( ) return nil , err } entry , _ := imageStreamCache [ server ] if entry == nil || entry . Expiry . Before ( time . Now ( ) ) { if err != nil { return nil , err } if err != nil { return nil , err } if err != nil { return nil , err } fingerprints := [ ] string { } for _ , image := range images { fingerprints = append ( fingerprints , image . Fingerprint ) } imageStreamCache [ server ] = entry imageSaveStreamCache ( d . os , imageStreamCache ) return entry , nil } newEntry , err := refresh ( ) if err == nil { } else if entry != nil { entry . Expiry = time . Now ( ) . Add ( time . Hour ) } else { return nil , err } } else { remote , err = lxd . ConnectSimpleStreams ( server , & lxd . ConnectionArgs { TLSServerCert : entry . Certificate , UserAgent : version . UserAgent , Proxy : d . proxy , } ) if err != nil { imageStreamCacheLock . Unlock ( ) return nil , err } } imageStreamCacheLock . Unlock ( ) } fp = entry . Target break } for _ , entry := range entry . Fingerprints { if strings . HasPrefix ( entry , fp ) { matches = append ( matches , entry ) } } if len ( matches ) == 1 { fp = matches [ 0 ] } else if len ( matches ) > 1 { return nil , fmt . Errorf ( " " ) } else { return nil , fmt . Errorf ( " " ) } } else if protocol == " " { if err != nil { return nil , err } if err == nil { fp = entry . Target } if err != nil { return nil , err } fp = info . Fingerprint } } if err != nil { return nil , err } if preferCached && interval > 0 && alias != fp { cachedFingerprint , err := d . cluster . ImageSourceGetCachedFingerprint ( server , protocol , alias ) if err == nil && cachedFingerprint != fp { fp = cachedFingerprint } } if err == db . ErrNoSuchObject { if err == nil { if err != nil { return nil , err } var id int id , imgInfo , err = d . cluster . ImageGet ( project , fp , false , true ) if err != nil { return nil , err } err = d . cluster . ImageSourceInsert ( id , server , protocol , certificate , alias ) if err != nil { return nil , err } } } if err == nil { logger . Debug ( " " , log . Ctx { " " : fp } ) info = imgInfo } if err != nil { return nil , err } if err != nil { return nil , err } if shared . Int64InSlice ( poolID , poolIDs ) { logger . Debugf ( " \" \" " , storagePool ) return info , nil } err = imageCreateInPool ( d , info , storagePool ) if err != nil { logger . Debugf ( " \" \" " , storagePool , err ) return nil , err } logger . Debugf ( " \" \" " , storagePool ) return info , nil } if waitChannel , ok := imagesDownloading [ fp ] ; ok { logger . Debug ( " " , log . Ctx { " " : fp } ) if err != nil { } else { } } else { imagesDownloadingLock . Unlock ( ) } imagesDownloading [ fp ] = make ( chan bool ) imagesDownloadingLock . Unlock ( ) if waitChannel , ok := imagesDownloading [ fp ] ; ok { close ( waitChannel ) delete ( imagesDownloading , fp ) } imagesDownloadingLock . Unlock ( ) } ( ) } else { ctxMap = log . Ctx { " " : op . url , " " : fp , " " : op . id , " " : alias , " " : server } } logger . Info ( " " , ctxMap ) destName := filepath . Join ( destDir , fp ) failure := true cleanup := func ( ) { if failure { os . Remove ( destName ) os . Remove ( destName + " " ) } } defer cleanup ( ) } meta := op . metadata if meta == nil { meta = make ( map [ string ] interface { } ) } if meta [ " " ] != progress . Text { meta [ " " ] = progress . Text op . UpdateMetadata ( meta ) } } var canceler * cancel . Canceler if op != nil { canceler = cancel . NewCanceler ( ) op . canceler = canceler } if protocol == " " || protocol == " " { if err != nil { return nil , err } defer dest . Close ( ) destRootfs , err := os . Create ( destName + " " ) if err != nil { return nil , err } defer destRootfs . Close ( ) if err != nil { return nil , err } alias = info . Fingerprint } else { info , _ , err = remote . GetImage ( fp ) if err != nil { return nil , err } } } request := lxd . ImageFileRequest { MetaFile : io . WriteSeeker ( dest ) , RootfsFile : io . WriteSeeker ( destRootfs ) , ProgressHandler : progress , Canceler : canceler , DeltaSourceRetriever : func ( fingerprint string , file string ) string { path := shared . VarPath ( " " , fmt . Sprintf ( " " , fingerprint , file ) ) if shared . PathExists ( path ) { return path } return " " } , } if secret != " " { resp , err = remote . GetPrivateImageFile ( fp , secret , request ) } else { resp , err = remote . GetImageFile ( fp , request ) } if err != nil { return nil , err } if err != nil { return nil , err } } } else if protocol == " " { if err != nil { return nil , err } req , err := http . NewRequest ( " " , server , nil ) if err != nil { return nil , err } req . Header . Set ( " " , version . UserAgent ) defer close ( doneCh ) if err != nil { return nil , err } if raw . StatusCode != http . StatusOK { return nil , fmt . Errorf ( " " , server , raw . Status ) } } , } , } if err != nil { return nil , err } defer f . Close ( ) if err != nil { return nil , err } if result != fp { return nil , fmt . Errorf ( " " , server , result , fp ) } if err != nil { return nil , err } info = & api . Image { } info . Fingerprint = fp info . Size = size info . Architecture = imageMeta . Architecture info . CreatedAt = time . Unix ( imageMeta . CreationDate , 0 ) info . ExpiresAt = time . Unix ( imageMeta . ExpiryDate , 0 ) info . Properties = imageMeta . Properties } } if err != nil { return nil , err } if newDestName != destName { err = shared . FileMove ( destName , newDestName ) if err != nil { return nil , err } if shared . PathExists ( destName + " " ) { err = shared . FileMove ( destName + " " , newDestName + " " ) if err != nil { return nil , err } } } if err != nil { return nil , err } err = d . cluster . ImageSourceInsert ( id , server , protocol , certificate , alias ) if err != nil { return nil , err } } if err != nil { return nil , err } } if err != nil { return nil , err } } logger . Info ( " " , ctxMap ) return info , nil } 
func updateFromV6 ( tx * sql . Tx ) error { if err != nil { return errors . Wrap ( err , " " ) } SELECT id FROM storage_pools WHERE driver='zfs' ` ) if err != nil { return errors . Wrap ( err , " " ) } for _ , poolID := range poolIDs { if err != nil { return errors . Wrap ( err , " " ) } poolName , ok := config [ " " ] if ! ok { continue } DELETE FROM storage_pools_config WHERE key='zfs.pool_name' AND storage_pool_id=? AND node_id IS NULL ` , poolID ) if err != nil { return errors . Wrap ( err , " " ) } INSERT INTO storage_pools_config(storage_pool_id, node_id, key, value) VALUES(?, ?, 'zfs.pool_name', ?) ` , poolID , nodeID , poolName ) if err != nil { return errors . Wrap ( err , " " ) } } } return nil } 
func updateFromV5 ( tx * sql . Tx ) error { if err != nil { return errors . Wrap ( err , " " ) } SELECT storage_volumes.id FROM storage_volumes JOIN storage_pools ON storage_volumes.storage_pool_id=storage_pools.id WHERE storage_pools.driver='ceph' ` ) if err != nil { return errors . Wrap ( err , " " ) } Name string StoragePoolID int NodeID int Type int Description string } , len ( volumeIDs ) ) sql := ` SELECT storage_volumes.id, storage_volumes.name, storage_volumes.storage_pool_id, storage_volumes.node_id, storage_volumes.type, storage_volumes.description FROM storage_volumes JOIN storage_pools ON storage_volumes.storage_pool_id=storage_pools.id WHERE storage_pools.driver='ceph' ` stmt , err := tx . Prepare ( sql ) if err != nil { return err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , func ( i int ) [ ] interface { } { return [ ] interface { } { & volumes [ i ] . ID , & volumes [ i ] . Name , & volumes [ i ] . StoragePoolID , & volumes [ i ] . NodeID , & volumes [ i ] . Type , & volumes [ i ] . Description , } } ) if err != nil { return errors . Wrap ( err , " " ) } columns := [ ] string { " " , " " , " " , " " , " " } for _ , volume := range volumes { for _ , nodeID := range nodeIDs { if volume . NodeID == nodeID { } values := [ ] interface { } { volume . Name , volume . StoragePoolID , nodeID , volume . Type , volume . Description , } id , err := query . UpsertObject ( tx , " " , columns , values ) if err != nil { return errors . Wrap ( err , " " ) } _ , ok := created [ volume . ID ] if ! ok { created [ volume . ID ] = make ( [ ] int64 , 0 ) } created [ volume . ID ] = append ( created [ volume . ID ] , id ) } } if err != nil { errors . Wrap ( err , " " ) } for _ , newID := range newIDs { for key , value := range config { _ , err := tx . Exec ( ` INSERT INTO storage_volumes_config(storage_volume_id, key, value) VALUES(?, ?, ?) ` , newID , key , value ) if err != nil { return errors . Wrap ( err , " " ) } } } } return nil } 
func localCreateListener ( path string , group string ) ( net . Listener , error ) { err := CheckAlreadyRunning ( path ) if err != nil { return nil , err } err = socketUnixRemoveStale ( path ) if err != nil { return nil , err } listener , err := socketUnixListen ( path ) if err != nil { return nil , err } err = localSetAccess ( path , group ) if err != nil { listener . Close ( ) return nil , err } return listener , nil } 
func localSetAccess ( path string , group string ) error { err := socketUnixSetPermissions ( path , 0660 ) if err != nil { return err } err = socketUnixSetOwnership ( path , group ) if err != nil { return err } return nil } 
func NewStmt ( database , pkg , entity , kind string , config map [ string ] string ) ( * Stmt , error ) { packages , err := Packages ( ) if err != nil { return nil , err } stmt := & Stmt { db : database , pkg : pkg , entity : entity , kind : kind , config : config , packages : packages , } return stmt , nil } 
func ( s * Stmt ) Generate ( buf * file . Buffer ) error { if strings . HasPrefix ( s . kind , " " ) { return s . objects ( buf ) } if strings . HasPrefix ( s . kind , " " ) && strings . HasSuffix ( s . kind , " " ) { return s . createRef ( buf ) } if strings . HasSuffix ( s . kind , " " ) || strings . Contains ( s . kind , " " ) { return s . ref ( buf ) } if strings . HasPrefix ( s . kind , " " ) { return s . names ( buf ) } switch s . kind { case " " : return s . create ( buf ) case " " : return s . id ( buf ) case " " : return s . rename ( buf ) case " " : return s . update ( buf ) case " " : return s . delete ( buf ) default : return fmt . Errorf ( " " , s . kind ) } } 
func ( s * Stmt ) register ( buf * file . Buffer , sql string , filters ... string ) { kind := strings . Replace ( s . kind , " " , " " , - 1 ) if kind == " " { kind = " " } buf . L ( " \n \n " , stmtCodeVar ( s . entity , kind , filters ... ) , s . db , sql ) } 
func ConnectLXD ( url string , args * ConnectionArgs ) ( ContainerServer , error ) { logger . Debugf ( " " ) return httpsLXD ( url , args ) } 
func ConnectLXDUnix ( path string , args * ConnectionArgs ) ( ContainerServer , error ) { logger . Debugf ( " " ) } if path == " " { lxdDir := os . Getenv ( " " ) if lxdDir == " " { lxdDir = " " } path = filepath . Join ( lxdDir , " " ) } } if err != nil { return nil , err } server . http = httpClient if err != nil { return nil , err } } return & server , nil } 
func ConnectPublicLXD ( url string , args * ConnectionArgs ) ( ImageServer , error ) { logger . Debugf ( " " ) return httpsLXD ( url , args ) } 
func ConnectSimpleStreams ( url string , args * ConnectionArgs ) ( ImageServer , error ) { logger . Debugf ( " " ) } if err != nil { return nil , err } server . http = httpClient server . ssClient = ssClient return & server , nil } 
func httpsLXD ( url string , args * ConnectionArgs ) ( ContainerServer , error ) { } if args . AuthType == " " { server . RequireAuthenticated ( true ) } if err != nil { return nil , err } if args . CookieJar != nil { httpClient . Jar = args . CookieJar } server . http = httpClient if args . AuthType == " " { server . setupBakeryClient ( ) } if err != nil { return nil , err } } return & server , nil } 
func moveClusterContainer ( conf * config . Config , sourceResource , destResource , target string ) error { if err != nil { return err } if err != nil { return err } } } if err != nil { return errors . Wrap ( err , i18n . G ( " " ) ) } } req := api . ContainerPost { Name : destName , Migration : true } op , err := source . MigrateContainer ( sourceName , req ) if err != nil { return errors . Wrap ( err , i18n . G ( " " ) ) } err = op . Wait ( ) if err != nil { return errors . Wrap ( err , i18n . G ( " " ) ) } return nil } 
func ( c Container ) IsActive ( ) bool { switch c . StatusCode { case Stopped : return false case Error : return false default : return true } } 
func ( n * NodeTx ) RaftNodes ( ) ( [ ] RaftNode , error ) { nodes := [ ] RaftNode { } dest := func ( i int ) [ ] interface { } { nodes = append ( nodes , RaftNode { } ) return [ ] interface { } { & nodes [ i ] . ID , & nodes [ i ] . Address } } stmt , err := n . tx . Prepare ( " " ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest ) if err != nil { return nil , errors . Wrap ( err , " " ) } return nodes , nil } 
func ( n * NodeTx ) RaftNodeAddress ( id int64 ) ( string , error ) { stmt := " " addresses , err := query . SelectStrings ( n . tx , stmt , id ) if err != nil { return " " , err } switch len ( addresses ) { case 0 : return " " , ErrNoSuchObject case 1 : return addresses [ 0 ] , nil default : } } 
func ( n * NodeTx ) RaftNodeFirst ( address string ) error { columns := [ ] string { " " , " " } values := [ ] interface { } { int64 ( 1 ) , address } id , err := query . UpsertObject ( n . tx , " " , columns , values ) if err != nil { return err } if id != 1 { return fmt . Errorf ( " " ) } return nil } 
func ( n * NodeTx ) RaftNodeAdd ( address string ) ( int64 , error ) { columns := [ ] string { " " } values := [ ] interface { } { address } return query . UpsertObject ( n . tx , " " , columns , values ) } 
func ( n * NodeTx ) RaftNodeDelete ( id int64 ) error { deleted , err := query . DeleteObject ( n . tx , " " , id ) if err != nil { return err } if ! deleted { return ErrNoSuchObject } return nil } 
func ( n * NodeTx ) RaftNodesReplace ( nodes [ ] RaftNode ) error { _ , err := n . tx . Exec ( " " ) if err != nil { return err } columns := [ ] string { " " , " " } for _ , node := range nodes { values := [ ] interface { } { node . ID , node . Address } _ , err := query . UpsertObject ( n . tx , " " , columns , values ) if err != nil { return err } } return nil } 
func ( s * OS ) initCGroup ( ) { flags := [ ] * bool { & s . CGroupBlkioController , & s . CGroupCPUController , & s . CGroupCPUacctController , & s . CGroupCPUsetController , & s . CGroupDevicesController , & s . CGroupFreezerController , & s . CGroupMemoryController , & s . CGroupNetPrioController , & s . CGroupPidsController , & s . CGroupSwapAccounting , } for i , flag := range flags { * flag = shared . PathExists ( " " + cGroups [ i ] . path ) if ! * flag { logger . Warnf ( cGroups [ i ] . warn ) } } } 
func sqliteDirectAccess ( conn * sqlite3 . SQLiteConn ) error { if err != nil { return err } if err != nil { return err } if err != nil { return err } return nil } 
func ( c * ClusterTx ) ContainerList ( filter ContainerFilter ) ( [ ] Container , error ) { if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } if filter . Node != " " { criteria [ " " ] = filter . Node } if filter . Parent != " " { criteria [ " " ] = filter . Parent } if filter . Type != - 1 { criteria [ " " ] = filter . Type } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerObjectsByProjectAndNameAndType ) args = [ ] interface { } { filter . Project , filter . Name , filter . Type , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerObjectsByProjectAndTypeAndParent ) args = [ ] interface { } { filter . Project , filter . Type , len ( filter . Parent ) + 1 , filter . Parent + " " , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerObjectsByProjectAndNodeAndType ) args = [ ] interface { } { filter . Project , filter . Node , filter . Type , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerObjectsByNodeAndType ) args = [ ] interface { } { filter . Node , filter . Type , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerObjectsByProjectAndType ) args = [ ] interface { } { filter . Project , filter . Type , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerObjectsByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil { stmt = c . stmt ( containerObjectsByType ) args = [ ] interface { } { filter . Type , } } else { stmt = c . stmt ( containerObjects ) args = [ ] interface { } { } } return [ ] interface { } { & objects [ i ] . ID , & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Node , & objects [ i ] . Type , & objects [ i ] . Architecture , & objects [ i ] . Ephemeral , & objects [ i ] . CreationDate , & objects [ i ] . Stateful , & objects [ i ] . LastUseDate , & objects [ i ] . Description , & objects [ i ] . ExpiryDate , } } if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { _ , ok := configObjects [ objects [ i ] . Project ] if ! ok { subIndex := map [ string ] map [ string ] string { } configObjects [ objects [ i ] . Project ] = subIndex } value := configObjects [ objects [ i ] . Project ] [ objects [ i ] . Name ] if value == nil { value = map [ string ] string { } } objects [ i ] . Config = value } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { _ , ok := devicesObjects [ objects [ i ] . Project ] if ! ok { subIndex := map [ string ] map [ string ] map [ string ] string { } devicesObjects [ objects [ i ] . Project ] = subIndex } value := devicesObjects [ objects [ i ] . Project ] [ objects [ i ] . Name ] if value == nil { value = map [ string ] map [ string ] string { } } objects [ i ] . Devices = value } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { _ , ok := profilesObjects [ objects [ i ] . Project ] if ! ok { subIndex := map [ string ] [ ] string { } profilesObjects [ objects [ i ] . Project ] = subIndex } value := profilesObjects [ objects [ i ] . Project ] [ objects [ i ] . Name ] if value == nil { value = [ ] string { } } objects [ i ] . Profiles = value } return objects , nil } 
func ( c * ClusterTx ) ContainerGet ( project string , name string ) ( * Container , error ) { filter := ContainerFilter { } filter . Project = project filter . Name = name filter . Type = - 1 objects , err := c . ContainerList ( filter ) if err != nil { return nil , errors . Wrap ( err , " " ) } switch len ( objects ) { case 0 : return nil , ErrNoSuchObject case 1 : return & objects [ 0 ] , nil default : return nil , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) ContainerID ( project string , name string ) ( int64 , error ) { stmt := c . stmt ( containerID ) rows , err := stmt . Query ( project , name ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } defer rows . Close ( ) } var id int64 err = rows . Scan ( & id ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } if rows . Next ( ) { return - 1 , fmt . Errorf ( " " ) } err = rows . Err ( ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } return id , nil } 
func ( c * ClusterTx ) ContainerExists ( project string , name string ) ( bool , error ) { _ , err := c . ContainerID ( project , name ) if err != nil { if err == ErrNoSuchObject { return false , nil } return false , err } return true , nil } 
func ( c * ClusterTx ) ContainerCreate ( object Container ) ( int64 , error ) { if err != nil { return - 1 , errors . Wrap ( err , " " ) } if exists { return - 1 , fmt . Errorf ( " " ) } args := make ( [ ] interface { } , 11 ) args [ 1 ] = object . Name args [ 2 ] = object . Node args [ 3 ] = object . Type args [ 4 ] = object . Architecture args [ 5 ] = object . Ephemeral args [ 6 ] = object . CreationDate args [ 7 ] = object . Stateful args [ 8 ] = object . LastUseDate args [ 9 ] = object . Description args [ 10 ] = object . ExpiryDate if err != nil { return - 1 , errors . Wrap ( err , " " ) } id , err := result . LastInsertId ( ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } for key , value := range object . Config { _ , err := stmt . Exec ( id , key , value ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } } if ! ok { return - 1 , fmt . Errorf ( " " , name ) } typCode , err := dbDeviceTypeToInt ( typ ) if err != nil { return - 1 , errors . Wrapf ( err , " " , typ ) } stmt = c . stmt ( containerCreateDevicesRef ) result , err := stmt . Exec ( id , name , typCode ) if err != nil { return - 1 , errors . Wrapf ( err , " " , name ) } deviceID , err := result . LastInsertId ( ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } stmt = c . stmt ( containerCreateDevicesConfigRef ) for key , value := range config { _ , err := stmt . Exec ( deviceID , key , value ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } } } if err != nil { return - 1 , errors . Wrap ( err , " " ) } return id , nil } 
func ( c * ClusterTx ) ContainerProfilesRef ( filter ContainerFilter ) ( map [ string ] map [ string ] [ ] string , error ) { Name string Value string } , 0 ) if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } if filter . Parent != " " { criteria [ " " ] = filter . Parent } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerProfilesRefByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerProfilesRefByProjectAndNode ) args = [ ] interface { } { filter . Project , filter . Node , } } else if criteria [ " " ] != nil { stmt = c . stmt ( containerProfilesRefByProject ) args = [ ] interface { } { filter . Project , } } else if criteria [ " " ] != nil { stmt = c . stmt ( containerProfilesRefByNode ) args = [ ] interface { } { filter . Node , } } else { stmt = c . stmt ( containerProfilesRef ) args = [ ] interface { } { } } Name string Value string } { } ) return [ ] interface { } { & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Value , } } if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , object := range objects { _ , ok := index [ object . Project ] if ! ok { subIndex := map [ string ] [ ] string { } index [ object . Project ] = subIndex } item , ok := index [ object . Project ] [ object . Name ] if ! ok { item = [ ] string { } } index [ object . Project ] [ object . Name ] = append ( item , object . Value ) } return index , nil } 
func ( c * ClusterTx ) ContainerConfigRef ( filter ContainerFilter ) ( map [ string ] map [ string ] map [ string ] string , error ) { Name string Key string Value string } , 0 ) if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } if filter . Parent != " " { criteria [ " " ] = filter . Parent } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerConfigRefByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerConfigRefByProjectAndNode ) args = [ ] interface { } { filter . Project , filter . Node , } } else if criteria [ " " ] != nil { stmt = c . stmt ( containerConfigRefByNode ) args = [ ] interface { } { filter . Node , } } else if criteria [ " " ] != nil { stmt = c . stmt ( containerConfigRefByProject ) args = [ ] interface { } { filter . Project , } } else { stmt = c . stmt ( containerConfigRef ) args = [ ] interface { } { } } Name string Key string Value string } { } ) return [ ] interface { } { & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Key , & objects [ i ] . Value , } } if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , object := range objects { _ , ok := index [ object . Project ] if ! ok { subIndex := map [ string ] map [ string ] string { } index [ object . Project ] = subIndex } item , ok := index [ object . Project ] [ object . Name ] if ! ok { item = map [ string ] string { } } index [ object . Project ] [ object . Name ] = item item [ object . Key ] = object . Value } return index , nil } 
func ( c * ClusterTx ) ContainerDevicesRef ( filter ContainerFilter ) ( map [ string ] map [ string ] map [ string ] map [ string ] string , error ) { Name string Device string Type int Key string Value string } , 0 ) if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } if filter . Parent != " " { criteria [ " " ] = filter . Parent } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerDevicesRefByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( containerDevicesRefByProjectAndNode ) args = [ ] interface { } { filter . Project , filter . Node , } } else if criteria [ " " ] != nil { stmt = c . stmt ( containerDevicesRefByNode ) args = [ ] interface { } { filter . Node , } } else if criteria [ " " ] != nil { stmt = c . stmt ( containerDevicesRefByProject ) args = [ ] interface { } { filter . Project , } } else { stmt = c . stmt ( containerDevicesRef ) args = [ ] interface { } { } } Name string Device string Type int Key string Value string } { } ) return [ ] interface { } { & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Device , & objects [ i ] . Type , & objects [ i ] . Key , & objects [ i ] . Value , } } if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , object := range objects { _ , ok := index [ object . Project ] if ! ok { subIndex := map [ string ] map [ string ] map [ string ] string { } index [ object . Project ] = subIndex } item , ok := index [ object . Project ] [ object . Name ] if ! ok { item = map [ string ] map [ string ] string { } } index [ object . Project ] [ object . Name ] = item config , ok := item [ object . Device ] if ! ok { if err != nil { return nil , errors . Wrapf ( err , " " , object . Type ) } config = map [ string ] string { } config [ " " ] = deviceType item [ object . Device ] = config } if object . Key != " " { config [ object . Key ] = object . Value } } return index , nil } 
func ( m * Mapping ) NaturalKey ( ) [ ] * Field { key := [ ] * Field { } for _ , field := range m . Fields { if field . Config . Get ( " " ) != " " { key = append ( key , field ) } } if len ( key ) == 0 { } return key } 
func ( m * Mapping ) ContainsFields ( fields [ ] * Field ) bool { matches := map [ * Field ] bool { } for _ , field := range m . Fields { for _ , other := range fields { if field . Name == other . Name && field . Type . Name == other . Type . Name { matches [ field ] = true } } } return len ( matches ) == len ( fields ) } 
func ( m * Mapping ) FieldByName ( name string ) * Field { for _ , field := range m . Fields { if field . Name == name { return field } } return nil } 
func ( m * Mapping ) FieldColumnName ( name string ) string { field := m . FieldByName ( name ) return fmt . Sprintf ( " " , entityTable ( m . Name ) , field . Column ( ) ) } 
func ( m * Mapping ) FilterFieldByName ( name string ) ( * Field , error ) { field := m . FieldByName ( name ) if field == nil { return nil , fmt . Errorf ( " " , name ) } if field . Type . Code != TypeColumn { return nil , fmt . Errorf ( " " , name ) } return field , nil } 
func ( m * Mapping ) ColumnFields ( exclude ... string ) [ ] * Field { fields := [ ] * Field { } for _ , field := range m . Fields { if shared . StringInSlice ( field . Name , exclude ) { continue } if field . Type . Code == TypeColumn { fields = append ( fields , field ) } } return fields } 
func ( m * Mapping ) ScalarFields ( ) [ ] * Field { fields := [ ] * Field { } for _ , field := range m . Fields { if field . Config . Get ( " " ) != " " { fields = append ( fields , field ) } } return fields } 
func ( m * Mapping ) RefFields ( ) [ ] * Field { fields := [ ] * Field { } for _ , field := range m . Fields { if field . Type . Code == TypeSlice || field . Type . Code == TypeMap { fields = append ( fields , field ) } } return fields } 
func ( f * Field ) Column ( ) string { if f . Type . Code != TypeColumn { panic ( " " ) } column := lex . Snake ( f . Name ) join := f . Config . Get ( " " ) if join != " " { column = fmt . Sprintf ( " " , join , column ) } return column } 
func ( f * Field ) ZeroValue ( ) string { if f . Type . Code != TypeColumn { panic ( " " ) } switch f . Type . Name { case " " : return `""` case " " : default : panic ( " " ) } } 
func FieldColumns ( fields [ ] * Field ) string { columns := make ( [ ] string , len ( fields ) ) for i , field := range fields { columns [ i ] = field . Column ( ) } return strings . Join ( columns , " " ) } 
func FieldArgs ( fields [ ] * Field ) string { args := make ( [ ] string , len ( fields ) ) for i , field := range fields { args [ i ] = fmt . Sprintf ( " " , lex . Minuscule ( field . Name ) , field . Type . Name ) } return strings . Join ( args , " " ) } 
func FieldParams ( fields [ ] * Field ) string { args := make ( [ ] string , len ( fields ) ) for i , field := range fields { args [ i ] = lex . Minuscule ( field . Name ) } return strings . Join ( args , " " ) } 
func FieldCriteria ( fields [ ] * Field ) string { criteria := make ( [ ] string , len ( fields ) ) for i , field := range fields { criteria [ i ] = fmt . Sprintf ( " " , field . Column ( ) ) } return strings . Join ( criteria , " " ) } 
func api10ResourcesGet ( d * Daemon , r * http . Request ) Response { if response != nil { return response } cpu , err := util . CPUResource ( ) if err != nil { return SmartError ( err ) } cards , _ , err := deviceLoadGpu ( false ) if err != nil { return SmartError ( err ) } gpus := api . ResourcesGPU { } gpus . Cards = [ ] api . ResourcesGPUCard { } processedCards := map [ uint64 ] bool { } for _ , card := range cards { id , err := strconv . ParseUint ( card . id , 10 , 64 ) if err != nil { continue } if processedCards [ id ] { continue } gpu := api . ResourcesGPUCard { } gpu . ID = id gpu . Driver = card . driver gpu . DriverVersion = card . driverVersion gpu . PCIAddress = card . pci gpu . Vendor = card . vendorName gpu . VendorID = card . vendorID gpu . Product = card . productName gpu . ProductID = card . productID gpu . NUMANode = card . numaNode if card . isNvidia { gpu . Nvidia = & api . ResourcesGPUCardNvidia { CUDAVersion : card . nvidia . cudaVersion , NVRMVersion : card . nvidia . nvrmVersion , Brand : card . nvidia . brand , Model : card . nvidia . model , UUID : card . nvidia . uuid , Architecture : card . nvidia . architecture , } } gpus . Cards = append ( gpus . Cards , gpu ) gpus . Total += 1 processedCards [ id ] = true } mem , err := util . MemoryResource ( ) if err != nil { return SmartError ( err ) } res . CPU = * cpu res . GPU = gpus res . Memory = * mem return SyncResponse ( true , res ) } 
func storagePoolResourcesGet ( d * Daemon , r * http . Request ) Response { if response != nil { return response } s , err := storagePoolInit ( d . State ( ) , poolName ) if err != nil { return InternalError ( err ) } err = s . StoragePoolCheck ( ) if err != nil { return InternalError ( err ) } res , err := s . StoragePoolResources ( ) if err != nil { return InternalError ( err ) } return SyncResponse ( true , & res ) } 
func initDataNodeApply ( d lxd . ContainerServer , config initDataNode ) ( func ( ) , error ) { revert := func ( ) { } } if err != nil { return revert , errors . Wrap ( err , " " ) } } ) err = shared . DeepCopy ( currentServer . Writable ( ) , & newServer ) if err != nil { return revert , errors . Wrap ( err , " " ) } for k , v := range config . Config { newServer . Config [ k ] = fmt . Sprintf ( " " , v ) } if err != nil { return revert , errors . Wrap ( err , " " ) } } if err != nil { return revert , errors . Wrap ( err , " " ) } if err != nil { return errors . Wrapf ( err , " " , network . Name ) } } ) return nil } if err != nil { return errors . Wrapf ( err , " " , network . Name ) } } ) err = shared . DeepCopy ( currentNetwork . Writable ( ) , & newNetwork ) if err != nil { return errors . Wrapf ( err , " " , network . Name ) } } } if err != nil { return errors . Wrapf ( err , " " , network . Name ) } return nil } for _ , network := range config . Networks { if err != nil { return revert , err } continue } if err != nil { return revert , err } } } if err != nil { return revert , errors . Wrap ( err , " " ) } if err != nil { return errors . Wrapf ( err , " " , storagePool . Name ) } } ) return nil } if err != nil { return errors . Wrapf ( err , " " , storagePool . Name ) } } } ) err = shared . DeepCopy ( currentStoragePool . Writable ( ) , & newStoragePool ) if err != nil { return errors . Wrapf ( err , " " , storagePool . Name ) } } } if err != nil { return errors . Wrapf ( err , " " , storagePool . Name ) } return nil } for _ , storagePool := range config . StoragePools { if err != nil { return revert , err } continue } if err != nil { return revert , err } } } if err != nil { return revert , errors . Wrap ( err , " " ) } if err != nil { return errors . Wrapf ( err , " " , profile . Name ) } } ) return nil } if err != nil { return errors . Wrapf ( err , " " , profile . Name ) } } ) err = shared . DeepCopy ( currentProfile . Writable ( ) , & newProfile ) if err != nil { return errors . Wrapf ( err , " " , profile . Name ) } } } if ! ok { newProfile . Devices [ k ] = v continue } } } if err != nil { return errors . Wrapf ( err , " " , profile . Name ) } return nil } for _ , profile := range config . Profiles { if err != nil { return revert , err } continue } if err != nil { return revert , err } } } return nil , nil } 
func initDataClusterApply ( d lxd . ContainerServer , config * initDataCluster ) error { if config == nil || ! config . Enabled { return nil } if err != nil { return errors . Wrap ( err , " " ) } if err != nil { return errors . Wrap ( err , " " ) } err = op . Wait ( ) if err != nil { return errors . Wrap ( err , " " ) } } return nil } 
func TerminalFormat ( ) Format { return FormatFunc ( func ( r * Record ) [ ] byte { var color = 0 switch r . Lvl { case LvlCrit : color = 35 case LvlError : color = 31 case LvlWarn : color = 33 case LvlInfo : color = 32 case LvlDebug : color = 36 } b := & bytes . Buffer { } lvl := strings . ToUpper ( r . Lvl . String ( ) ) if color > 0 { fmt . Fprintf ( b , " \x1b \x1b " , color , lvl , r . Time . Format ( termTimeFormat ) , r . Msg ) } else { fmt . Fprintf ( b , " " , lvl , r . Time . Format ( termTimeFormat ) , r . Msg ) } } return b . Bytes ( ) } ) } 
func JsonFormatEx ( pretty , lineSeparated bool ) Format { jsonMarshal := json . Marshal if pretty { jsonMarshal = func ( v interface { } ) ( [ ] byte , error ) { return json . MarshalIndent ( v , " " , " " ) } } return FormatFunc ( func ( r * Record ) [ ] byte { props := make ( map [ string ] interface { } ) props [ r . KeyNames . Time ] = r . Time props [ r . KeyNames . Lvl ] = r . Lvl props [ r . KeyNames . Msg ] = r . Msg for i := 0 ; i < len ( r . Ctx ) ; i += 2 { k , ok := r . Ctx [ i ] . ( string ) if ! ok { props [ errorKey ] = fmt . Sprintf ( " " , r . Ctx [ i ] ) } props [ k ] = formatJsonValue ( r . Ctx [ i + 1 ] ) } b , err := jsonMarshal ( props ) if err != nil { b , _ = jsonMarshal ( map [ string ] string { errorKey : err . Error ( ) , } ) return b } if lineSeparated { b = append ( b , '\n' ) } return b } ) } 
func formatLogfmtValue ( value interface { } ) string { if value == nil { return " " } value = formatShared ( value ) switch v := value . ( type ) { case bool : return strconv . FormatBool ( v ) case float32 : return strconv . FormatFloat ( float64 ( v ) , floatFormat , 3 , 64 ) case float64 : return strconv . FormatFloat ( v , floatFormat , 3 , 64 ) case int , int8 , int16 , int32 , int64 , uint , uint8 , uint16 , uint32 , uint64 : return fmt . Sprintf ( " " , value ) case string : return escapeString ( v ) default : return escapeString ( fmt . Sprintf ( " " , value ) ) } } 
func ResolveTarget ( cluster * db . Cluster , target string ) ( string , error ) { address := " " err := cluster . Transaction ( func ( tx * db . ClusterTx ) error { name , err := tx . NodeName ( ) if err != nil { return err } if target == name { return nil } node , err := tx . NodeByName ( target ) if err != nil { if err == db . ErrNoSuchObject { return fmt . Errorf ( " " , target ) } return err } if node . Name != name { address = node . Address } return nil } ) return address , err } 
func ( pt * ProgressWriter ) Write ( p [ ] byte ) ( int , error ) { pt . Tracker . update ( n ) } return n , err } 
func updateNodeVersion ( tx * sql . Tx , address string , apiExtensions int ) error { stmt := " " result , err := tx . Exec ( stmt , len ( updates ) , apiExtensions , address ) if err != nil { return err } n , err := result . RowsAffected ( ) if err != nil { return err } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func selectNodesVersions ( tx * sql . Tx ) ( [ ] [ 2 ] int , error ) { versions := [ ] [ 2 ] int { } dest := func ( i int ) [ ] interface { } { versions = append ( versions , [ 2 ] int { } ) return [ ] interface { } { & versions [ i ] [ 0 ] , & versions [ i ] [ 1 ] } } stmt , err := tx . Prepare ( " " ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest ) if err != nil { return nil , err } return versions , nil } 
func GetArchitectures ( ) ( [ ] int , error ) { architectures := [ ] int { } architectureName , err := osarch . ArchitectureGetLocal ( ) if err != nil { return nil , err } architecture , err := osarch . ArchitectureId ( architectureName ) if err != nil { return nil , err } architectures = append ( architectures , architecture ) personalities , err := osarch . ArchitecturePersonalities ( architecture ) if err != nil { return nil , err } for _ , personality := range personalities { architectures = append ( architectures , personality ) } return architectures , nil } 
func GetIdmapSet ( ) * idmap . IdmapSet { idmapSet , err := idmap . DefaultIdmapSet ( " " , " " ) if err != nil { logger . Warn ( " " , log . Ctx { " " : err . Error ( ) } ) logger . Warnf ( " " ) idmapSet = nil } else { kernelIdmapSet , err := idmap . CurrentIdmapSet ( ) if err == nil { logger . Infof ( " " ) for _ , lxcmap := range kernelIdmapSet . ToLxcString ( ) { logger . Infof ( fmt . Sprintf ( " " , lxcmap ) ) } } if len ( idmapSet . Idmap ) == 0 { logger . Warnf ( " " ) logger . Warnf ( " " ) idmapSet = nil } else { logger . Infof ( " " ) for _ , lxcmap := range idmapSet . Idmap { suffix := " " if lxcmap . Usable ( ) != nil { suffix = " " } for _ , lxcEntry := range lxcmap . ToLxcString ( ) { logger . Infof ( " " , lxcEntry , suffix ) } } err = idmapSet . Usable ( ) if err != nil { logger . Warnf ( " " ) logger . Warnf ( " " ) idmapSet = nil } } } return idmapSet } 
func RuntimeLiblxcVersionAtLeast ( major int , minor int , micro int ) bool { version := golxc . Version ( ) version = strings . Replace ( version , " " , " " , 1 ) parts := strings . Split ( version , " " ) partsLen := len ( parts ) if partsLen == 0 { return false } develParts := strings . Split ( parts [ partsLen - 1 ] , " " ) if len ( develParts ) == 2 && develParts [ 1 ] == " " { return true } maj := - 1 min := - 1 mic := - 1 for i , v := range parts { if i > 2 { break } num , err := strconv . Atoi ( v ) if err != nil { return false } switch i { case 0 : maj = num case 1 : min = num case 2 : mic = num } } if maj > major { return true } if maj < major { return false } if min > minor { return true } if min < minor { return false } if mic > micro { return true } if mic < micro { return false } return true } 
func GetExecPath ( ) string { execPath := os . Getenv ( " " ) if execPath != " " { return execPath } execPath , err := os . Readlink ( " " ) if err != nil { execPath = " " } return execPath } 
func Connect ( address string , cert * shared . CertInfo , notify bool ) ( lxd . ContainerServer , error ) { args := & lxd . ConnectionArgs { TLSServerCert : string ( cert . PublicKey ( ) ) , TLSClientCert : string ( cert . PublicKey ( ) ) , TLSClientKey : string ( cert . PrivateKey ( ) ) , SkipGetServer : true , } if notify { args . UserAgent = " " } url := fmt . Sprintf ( " " , address ) return lxd . ConnectLXD ( url , args ) } 
func ConnectIfContainerIsRemote ( cluster * db . Cluster , project , name string , cert * shared . CertInfo ) ( lxd . ContainerServer , error ) { var address string err := cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error address , err = tx . ContainerNodeAddress ( project , name ) return err } ) if err != nil { return nil , err } if address == " " { } return Connect ( address , cert , false ) } 
func ConnectIfVolumeIsRemote ( cluster * db . Cluster , poolID int64 , volumeName string , volumeType int , cert * shared . CertInfo ) ( lxd . ContainerServer , error ) { var addresses [ ] string err := cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error addresses , err = tx . StorageVolumeNodeAddresses ( poolID , " " , volumeName , volumeType ) return err } ) if err != nil { return nil , err } if len ( addresses ) > 1 { var driver string err := cluster . Transaction ( func ( tx * db . ClusterTx ) error { var err error driver , err = tx . StoragePoolDriver ( poolID ) return err } ) if err != nil { return nil , err } if driver == " " { return nil , nil } return nil , fmt . Errorf ( " " , volumeName ) } address := addresses [ 0 ] if address == " " { return nil , nil } return Connect ( address , cert , false ) } 
func SetupTrust ( cert , targetAddress , targetCert , targetPassword string ) error { target , err := lxd . ConnectLXD ( fmt . Sprintf ( " " , targetAddress ) , args ) if err != nil { return errors . Wrap ( err , " " ) } block , _ := pem . Decode ( [ ] byte ( cert ) ) if block == nil { return errors . Wrap ( err , " " ) } certificate := base64 . StdEncoding . EncodeToString ( block . Bytes ) post := api . CertificatesPost { Password : targetPassword , Certificate : certificate , } fingerprint , err := shared . CertFingerprintStr ( cert ) if err != nil { return errors . Wrap ( err , " " ) } post . Name = fmt . Sprintf ( " " , fingerprint ) post . Type = " " err = target . CreateCertificate ( post ) if err != nil && err . Error ( ) != " " { return errors . Wrap ( err , " " ) } return nil } 
func ( r * ProtocolLXD ) GetStoragePools ( ) ( [ ] api . StoragePool , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } pools := [ ] api . StoragePool { } if err != nil { return nil , err } return pools , nil } 
func ( r * ProtocolLXD ) GetStoragePool ( name string ) ( * api . StoragePool , string , error ) { if ! r . HasExtension ( " " ) { return nil , " " , fmt . Errorf ( " \" \" " ) } pool := api . StoragePool { } if err != nil { return nil , " " , err } return & pool , etag , nil } 
func ( r * ProtocolLXD ) CreateStoragePool ( pool api . StoragePoolsPost ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if pool . Driver == " " && ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) UpdateStoragePool ( name string , pool api . StoragePoolPut , ETag string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) DeleteStoragePool ( name string ) error { if ! r . HasExtension ( " " ) { return fmt . Errorf ( " \" \" " ) } if err != nil { return err } return nil } 
func ( r * ProtocolLXD ) GetStoragePoolResources ( name string ) ( * api . ResourcesStoragePool , error ) { if ! r . HasExtension ( " " ) { return nil , fmt . Errorf ( " \" \" " ) } res := api . ResourcesStoragePool { } if err != nil { return nil , err } return & res , nil } 
func ( s * OS ) initDirs ( ) error { dirs := [ ] struct { path string mode os . FileMode } { { s . VarDir , 0711 } , { filepath . Join ( s . VarDir , " " ) , 0700 } , { s . CacheDir , 0700 } , { filepath . Join ( s . VarDir , " " ) , 0711 } , { filepath . Join ( s . VarDir , " " ) , 0700 } , { filepath . Join ( s . VarDir , " " ) , 0711 } , { filepath . Join ( s . VarDir , " " ) , 0755 } , { filepath . Join ( s . VarDir , " " ) , 0700 } , { filepath . Join ( s . VarDir , " " ) , 0700 } , { s . LogDir , 0700 } , { filepath . Join ( s . VarDir , " " ) , 0711 } , { filepath . Join ( s . VarDir , " " ) , 0700 } , { filepath . Join ( s . VarDir , " " ) , 0711 } , { filepath . Join ( s . VarDir , " " ) , 0700 } , { filepath . Join ( s . VarDir , " " ) , 0711 } , } for _ , dir := range dirs { err := os . Mkdir ( dir . path , dir . mode ) if err != nil && ! os . IsExist ( err ) { return errors . Wrapf ( err , " " , dir . path ) } } return nil } 
func ( n * NodeTx ) Config ( ) ( map [ string ] string , error ) { return query . SelectConfig ( n . tx , " " , " " ) } 
func ( n * NodeTx ) UpdateConfig ( values map [ string ] string ) error { return query . UpdateConfig ( n . tx , " " , values ) } 
func ( c * ClusterTx ) Config ( ) ( map [ string ] string , error ) { return query . SelectConfig ( c . tx , " " , " " ) } 
func ( c * ClusterTx ) UpdateConfig ( values map [ string ] string ) error { return query . UpdateConfig ( c . tx , " " , values ) } 
func ConfigValueSet ( c * Cluster , key string , value string ) error { err := c . Transaction ( func ( tx * ClusterTx ) error { _ , err := tx . tx . Exec ( " " , key ) if err != nil { return err } if value != " " { str := `INSERT INTO config (key, value) VALUES (?, ?);` stmt , err := tx . tx . Prepare ( str ) if err != nil { return err } defer stmt . Close ( ) _ , err = stmt . Exec ( key , value ) if err != nil { return err } } return nil } ) return err } 
func storagePoolsGet ( d * Daemon , r * http . Request ) Response { recursion := util . IsRecursionRequest ( r ) pools , err := d . cluster . StoragePools ( ) if err != nil && err != db . ErrNoSuchObject { return SmartError ( err ) } resultString := [ ] string { } resultMap := [ ] api . StoragePool { } for _ , pool := range pools { if ! recursion { resultString = append ( resultString , fmt . Sprintf ( " " , version . APIVersion , pool ) ) } else { plID , pl , err := d . cluster . StoragePoolGet ( pool ) if err != nil { continue } if err != nil { return SmartError ( err ) } pl . UsedBy = poolUsedBy resultMap = append ( resultMap , * pl ) } } if ! recursion { return SyncResponse ( true , resultString ) } return SyncResponse ( true , resultMap ) } 
func storagePoolsPost ( d * Daemon , r * http . Request ) Response { storagePoolCreateLock . Lock ( ) defer storagePoolCreateLock . Unlock ( ) req := api . StoragePoolsPost { } if err != nil { return BadRequest ( err ) } } if strings . Contains ( req . Name , " " ) { return BadRequest ( fmt . Errorf ( " " ) ) } if req . Driver == " " { return BadRequest ( fmt . Errorf ( " " ) ) } url := fmt . Sprintf ( " " , version . APIVersion , req . Name ) response := SyncResponseLocation ( true , nil , url ) if isClusterNotification ( r ) { if err != nil { return BadRequest ( err ) } err = doStoragePoolCreateInternal ( d . State ( ) , req . Name , req . Description , req . Driver , req . Config , true ) if err != nil { return SmartError ( err ) } return response } targetNode := queryParam ( r , " " ) if targetNode == " " { count , err := cluster . Count ( d . State ( ) ) if err != nil { return SmartError ( err ) } if count == 1 { } else { } if err != nil { return InternalError ( err ) } return response } } } err = storagePoolValidate ( req . Name , req . Driver , req . Config ) if err != nil { return BadRequest ( err ) } err = d . cluster . Transaction ( func ( tx * db . ClusterTx ) error { return tx . StoragePoolCreatePending ( targetNode , req . Name , req . Driver , req . Config ) } ) if err != nil { if err == db . ErrAlreadyDefined { return BadRequest ( fmt . Errorf ( " " , targetNode ) ) } return SmartError ( err ) } return response } 
func storagePoolGet ( d * Daemon , r * http . Request ) Response { if response != nil { return response } poolName := mux . Vars ( r ) [ " " ] if err != nil { return SmartError ( err ) } if err != nil && err != db . ErrNoSuchObject { return SmartError ( err ) } pool . UsedBy = poolUsedBy targetNode := queryParam ( r , " " ) clustered , err := cluster . Enabled ( d . db ) if err != nil { return SmartError ( err ) } } } etag := [ ] interface { } { pool . Name , pool . Driver , pool . Config } return SyncResponseETag ( true , & pool , etag ) } 
func storagePoolPut ( d * Daemon , r * http . Request ) Response { poolName := mux . Vars ( r ) [ " " ] if err != nil { return SmartError ( err ) } req := api . StoragePoolPut { } if err := json . NewDecoder ( r . Body ) . Decode ( & req ) ; err != nil { return BadRequest ( err ) } clustered , err := cluster . Enabled ( d . db ) if err != nil { return SmartError ( err ) } config := dbInfo . Config if clustered { err := storagePoolValidateClusterConfig ( req . Config ) if err != nil { return BadRequest ( err ) } config = storagePoolClusterConfigForEtag ( config ) } err = util . EtagCheck ( r , etag ) if err != nil { return PreconditionFailed ( err ) } if err != nil { return BadRequest ( err ) } config = req . Config if clustered { } notifier , err := cluster . NewNotifier ( d . State ( ) , cert , cluster . NotifyAll ) if err != nil { return SmartError ( err ) } err = notifier ( func ( client lxd . ContainerServer ) error { return client . UpdateStoragePool ( poolName , req , r . Header . Get ( " " ) ) } ) if err != nil { return SmartError ( err ) } } withDB := ! isClusterNotification ( r ) err = storagePoolUpdate ( d . State ( ) , poolName , req . Description , config , withDB ) if err != nil { return InternalError ( err ) } return EmptySyncResponse } 
func storagePoolValidateClusterConfig ( reqConfig map [ string ] string ) error { for key := range reqConfig { if shared . StringInSlice ( key , db . StoragePoolNodeConfigKeys ) { return fmt . Errorf ( " " , key ) } } return nil } 
func storagePoolClusterConfigForEtag ( dbConfig map [ string ] string ) map [ string ] string { config := util . CopyConfig ( dbConfig ) for _ , key := range db . StoragePoolNodeConfigKeys { delete ( config , key ) } return config } 
func storagePoolClusterFillWithNodeConfig ( dbConfig , reqConfig map [ string ] string ) map [ string ] string { config := util . CopyConfig ( reqConfig ) for _ , key := range db . StoragePoolNodeConfigKeys { config [ key ] = dbConfig [ key ] } return config } 
func storagePoolDelete ( d * Daemon , r * http . Request ) Response { poolName := mux . Vars ( r ) [ " " ] poolID , err := d . cluster . StoragePoolGetID ( poolName ) if err != nil { return NotFound ( err ) } if response != nil { return response } } if err != nil { return SmartError ( err ) } if pool . Status == " " { _ , err := d . cluster . StoragePoolDelete ( poolName ) if err != nil { return SmartError ( err ) } return EmptySyncResponse } s , err := storagePoolInit ( d . State ( ) , poolName ) if err != nil { return InternalError ( err ) } if shared . PathExists ( poolMntPoint ) { err := os . RemoveAll ( poolMntPoint ) if err != nil { return SmartError ( err ) } } return EmptySyncResponse } volumeNames , err := d . cluster . StoragePoolVolumesGetNames ( poolID ) if err != nil { return InternalError ( err ) } for _ , volume := range volumeNames { _ , imgInfo , err := d . cluster . ImageGet ( " " , volume , false , false ) if err != nil { return InternalError ( err ) } err = doDeleteImageFromPool ( d . State ( ) , imgInfo . Fingerprint , poolName ) if err != nil { return InternalError ( err ) } } err = s . StoragePoolDelete ( ) if err != nil { return InternalError ( err ) } } if err != nil { return SmartError ( err ) } if clustered { notifier , err := cluster . NewNotifier ( d . State ( ) , d . endpoints . NetworkCert ( ) , cluster . NotifyAll ) if err != nil { return SmartError ( err ) } err = notifier ( func ( client lxd . ContainerServer ) error { _ , _ , err := client . GetServer ( ) if err != nil { return err } return client . DeleteStoragePool ( poolName ) } ) if err != nil { return SmartError ( err ) } } err = dbStoragePoolDeleteAndUpdateCache ( d . cluster , poolName ) if err != nil { return SmartError ( err ) } return EmptySyncResponse } 
func ( r * ProtocolLXD ) GetEvents ( ) ( * EventListener , error ) { defer r . eventListenersLock . Unlock ( ) if r . eventListeners != nil { return & listener , nil } if err != nil { return nil , err } conn , err := r . websocket ( url ) if err != nil { return nil , err } go func ( ) { for { select { case <- time . After ( time . Minute ) : case <- stopCh : break } r . eventListenersLock . Lock ( ) if len ( r . eventListeners ) == 0 { r . eventListeners = nil r . eventListenersLock . Unlock ( ) break } r . eventListenersLock . Unlock ( ) } } ( ) if err != nil { defer r . eventListenersLock . Unlock ( ) listener . disconnected = true close ( listener . chActive ) } conn . Close ( ) close ( stopCh ) return } err = json . Unmarshal ( data , & event ) if err != nil { continue } } for _ , listener := range r . eventListeners { listener . targetsLock . Lock ( ) for _ , target := range listener . targets { if target . types != nil && ! shared . StringInSlice ( event . Type , target . types ) { continue } go target . function ( event ) } listener . targetsLock . Unlock ( ) } r . eventListenersLock . Unlock ( ) } } ( ) return & listener , nil } 
func LogfmtFormat ( ) log . Format { return log . FormatFunc ( func ( r * log . Record ) [ ] byte { common := [ ] interface { } { r . KeyNames . Time , r . Time , r . KeyNames . Lvl , r . Lvl , r . KeyNames . Msg , r . Msg } buf := & bytes . Buffer { } logfmt ( buf , common , 0 , false ) buf . Truncate ( buf . Len ( ) - 1 ) buf . WriteByte ( ' ' ) logfmt ( buf , r . Ctx , 0 , true ) return buf . Bytes ( ) } ) } 
func ( c * ClusterTx ) StorageVolumeNodeAddresses ( poolID int64 , project , name string , typ int ) ( [ ] string , error ) { nodes := [ ] struct { id int64 address string } { } dest := func ( i int ) [ ] interface { } { nodes = append ( nodes , struct { id int64 address string } { } ) return [ ] interface { } { & nodes [ i ] . id , & nodes [ i ] . address } } sql := ` SELECT nodes.id, nodes.address FROM nodes JOIN storage_volumes ON storage_volumes.node_id=nodes.id JOIN projects ON projects.id = storage_volumes.project_id WHERE storage_volumes.storage_pool_id=? AND projects.name=? AND storage_volumes.name=? AND storage_volumes.type=? ` stmt , err := c . tx . Prepare ( sql ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , poolID , project , name , typ ) if err != nil { return nil , err } addresses := [ ] string { } for _ , node := range nodes { address := node . address if node . id == c . nodeID { address = " " } addresses = append ( addresses , address ) } sort . Strings ( addresses ) if len ( addresses ) == 0 { return nil , ErrNoSuchObject } return addresses , nil } 
func ( c * Cluster ) StorageVolumeNodeGet ( volumeID int64 ) ( string , error ) { name := " " query := ` SELECT nodes.name FROM storage_volumes JOIN nodes ON nodes.id=storage_volumes.node_id WHERE storage_volumes.id=? ` inargs := [ ] interface { } { volumeID } outargs := [ ] interface { } { & name } err := dbQueryRowScan ( c . db , query , inargs , outargs ) if err != nil { if err == sql . ErrNoRows { return " " , ErrNoSuchObject } return " " , err } return name , nil } 
func ( c * Cluster ) StorageVolumeConfigGet ( volumeID int64 ) ( map [ string ] string , error ) { var key , value string query := " " inargs := [ ] interface { } { volumeID } outargs := [ ] interface { } { key , value } results , err := queryScan ( c . db , query , inargs , outargs ) if err != nil { return nil , err } config := map [ string ] string { } for _ , r := range results { key = r [ 0 ] . ( string ) value = r [ 1 ] . ( string ) config [ key ] = value } return config , nil } 
func ( c * Cluster ) StorageVolumeDescriptionGet ( volumeID int64 ) ( string , error ) { description := sql . NullString { } query := " " inargs := [ ] interface { } { volumeID } outargs := [ ] interface { } { & description } err := dbQueryRowScan ( c . db , query , inargs , outargs ) if err != nil { if err == sql . ErrNoRows { return " " , ErrNoSuchObject } return " " , err } return description . String , nil } 
func ( c * Cluster ) StorageVolumeNextSnapshot ( name string , typ int ) int { base := name + shared . SnapshotDelimiter + " " length := len ( base ) q := fmt . Sprintf ( " " ) var numstr string inargs := [ ] interface { } { typ , true , length , base } outfmt := [ ] interface { } { numstr } results , err := queryScan ( c . db , q , inargs , outfmt ) if err != nil { return 0 } max := 0 for _ , r := range results { numstr = r [ 0 ] . ( string ) if len ( numstr ) <= length { continue } substr := numstr [ length : ] var num int count , err := fmt . Sscanf ( substr , " " , & num ) if err != nil || count != 1 { continue } if num >= max { max = num + 1 } } return max } 
func ( c * Cluster ) StorageVolumeIsAvailable ( pool , volume string ) ( bool , error ) { isAvailable := false err := c . Transaction ( func ( tx * ClusterTx ) error { id , err := tx . StoragePoolID ( pool ) if err != nil { return errors . Wrapf ( err , " " , pool ) } driver , err := tx . StoragePoolDriver ( id ) if err != nil { return errors . Wrapf ( err , " " , pool ) } if driver != " " { isAvailable = true return nil } node , err := tx . NodeName ( ) if err != nil { return errors . Wrapf ( err , " " ) } containers , err := tx . ContainerListExpanded ( ) if err != nil { return errors . Wrapf ( err , " " ) } for _ , container := range containers { for _ , device := range container . Devices { if device [ " " ] != " " { continue } if device [ " " ] != pool { continue } if device [ " " ] != volume { continue } if container . Node != node { } } } isAvailable = true return nil } ) if err != nil { return false , err } return isAvailable , nil } 
func StorageVolumeDescriptionUpdate ( tx * sql . Tx , volumeID int64 , description string ) error { _ , err := tx . Exec ( " " , description , volumeID ) return err } 
func StorageVolumeConfigAdd ( tx * sql . Tx , volumeID int64 , volumeConfig map [ string ] string ) error { str := " " stmt , err := tx . Prepare ( str ) defer stmt . Close ( ) if err != nil { return err } for k , v := range volumeConfig { if v == " " { continue } _ , err = stmt . Exec ( volumeID , k , v ) if err != nil { return err } } return nil } 
func StorageVolumeConfigClear ( tx * sql . Tx , volumeID int64 ) error { _ , err := tx . Exec ( " " , volumeID ) if err != nil { return err } return nil } 
func storageVolumeIDsGet ( tx * sql . Tx , project , volumeName string , volumeType int , poolID int64 ) ( [ ] int64 , error ) { ids , err := query . SelectIntegers ( tx , ` SELECT storage_volumes.id FROM storage_volumes JOIN projects ON projects.id = storage_volumes.project_id WHERE projects.name=? AND storage_volumes.name=? AND storage_volumes.type=? AND storage_pool_id=? ` , project , volumeName , volumeType , poolID ) if err != nil { return nil , err } ids64 := make ( [ ] int64 , len ( ids ) ) for i , id := range ids { ids64 [ i ] = int64 ( id ) } return ids64 , nil } 
func ( c * Cluster ) StorageVolumeCleanupImages ( fingerprints [ ] string ) error { stmt := fmt . Sprintf ( " " , query . Params ( len ( fingerprints ) ) ) args := [ ] interface { } { StoragePoolVolumeTypeImage } for _ , fingerprint := range fingerprints { args = append ( args , fingerprint ) } err := exec ( c . db , stmt , args ... ) return err } 
func ( c * Cluster ) StorageVolumeMoveToLVMThinPoolNameKey ( ) error { err := exec ( c . db , " " ) if err != nil { return err } err = exec ( c . db , " " ) if err != nil { return err } return nil } 
func ( b * Buffer ) L ( format string , a ... interface { } ) { fmt . Fprintf ( b . buf , format , a ... ) b . N ( ) } 
func ( b * Buffer ) code ( ) ( [ ] byte , error ) { code , err := format . Source ( b . buf . Bytes ( ) ) if err != nil { return nil , errors . Wrap ( err , " " ) } return code , nil } 
func Pretty ( input interface { } ) string { pretty , err := json . MarshalIndent ( input , " \t " , " \t " ) if err != nil { return fmt . Sprintf ( " " , input ) } return fmt . Sprintf ( " \n \t " , pretty ) } 
func ( e * Endpoints ) NetworkPublicKey ( ) [ ] byte { e . mu . RLock ( ) defer e . mu . RUnlock ( ) return e . cert . PublicKey ( ) } 
func ( e * Endpoints ) NetworkPrivateKey ( ) [ ] byte { e . mu . RLock ( ) defer e . mu . RUnlock ( ) return e . cert . PrivateKey ( ) } 
func ( e * Endpoints ) NetworkCert ( ) * shared . CertInfo { e . mu . RLock ( ) defer e . mu . RUnlock ( ) return e . cert } 
func ( e * Endpoints ) NetworkAddress ( ) string { e . mu . RLock ( ) defer e . mu . RUnlock ( ) listener := e . listeners [ network ] if listener == nil { return " " } return listener . Addr ( ) . String ( ) } 
func ( e * Endpoints ) NetworkUpdateAddress ( address string ) error { if address != " " { address = util . CanonicalNetworkAddress ( address ) } oldAddress := e . NetworkAddress ( ) if address == oldAddress { return nil } clusterAddress := e . ClusterAddress ( ) logger . Infof ( " " ) e . mu . Lock ( ) defer e . mu . Unlock ( ) } } var listener net . Listener for i := 0 ; i < 10 ; i ++ { if err == nil { break } time . Sleep ( 100 * time . Millisecond ) } if err != nil { return nil , fmt . Errorf ( " " , err ) } return & listener , nil } if err != nil { if err1 == nil { e . listeners [ network ] = networkTLSListener ( * listener , e . cert ) e . serveHTTP ( network ) } return err } e . listeners [ network ] = networkTLSListener ( * listener , e . cert ) e . serveHTTP ( network ) } return nil } 
func ( e * Endpoints ) NetworkUpdateCert ( cert * shared . CertInfo ) { e . mu . Lock ( ) defer e . mu . Unlock ( ) e . cert = cert listener , ok := e . listeners [ network ] if ! ok { return } listener . ( * networkListener ) . Config ( cert ) if ! ok { return } listener . ( * networkListener ) . Config ( cert ) } 
func networkCreateListener ( address string , cert * shared . CertInfo ) net . Listener { listener , err := net . Listen ( " " , util . CanonicalNetworkAddress ( address ) ) if err != nil { logger . Error ( " " , log . Ctx { " " : err } ) return nil } return networkTLSListener ( listener , cert ) } 
func ( l * networkListener ) Accept ( ) ( net . Conn , error ) { c , err := l . Listener . Accept ( ) if err != nil { return nil , err } l . mu . RLock ( ) defer l . mu . RUnlock ( ) config := l . config return tls . Server ( c , config ) , nil } 
func ( l * networkListener ) Config ( cert * shared . CertInfo ) { config := util . ServerTLSConfig ( cert ) l . mu . Lock ( ) defer l . mu . Unlock ( ) l . config = config } 
func Start ( f Func , schedule Schedule ) ( func ( time . Duration ) error , func ( ) ) { group := Group { } task := group . Add ( f , schedule ) group . Start ( ) stop := group . Stop reset := task . Reset return stop , reset } 
func ( n NodeInfo ) IsOffline ( threshold time . Duration ) bool { return nodeIsOffline ( threshold , n . Heartbeat ) } 
func ( c * ClusterTx ) NodeByAddress ( address string ) ( NodeInfo , error ) { null := NodeInfo { } nodes , err := c . nodes ( false , " " , address ) if err != nil { return null , err } switch len ( nodes ) { case 0 : return null , ErrNoSuchObject case 1 : return nodes [ 0 ] , nil default : return null , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) NodePendingByAddress ( address string ) ( NodeInfo , error ) { null := NodeInfo { } nodes , err := c . nodes ( true , " " , address ) if err != nil { return null , err } switch len ( nodes ) { case 0 : return null , ErrNoSuchObject case 1 : return nodes [ 0 ] , nil default : return null , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) NodeByName ( name string ) ( NodeInfo , error ) { null := NodeInfo { } nodes , err := c . nodes ( false , " " , name ) if err != nil { return null , err } switch len ( nodes ) { case 0 : return null , ErrNoSuchObject case 1 : return nodes [ 0 ] , nil default : return null , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) NodeName ( ) ( string , error ) { stmt := " " names , err := query . SelectStrings ( c . tx , stmt , c . nodeID ) if err != nil { return " " , err } switch len ( names ) { case 0 : return " " , nil case 1 : return names [ 0 ] , nil default : return " " , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) NodeAddress ( ) ( string , error ) { stmt := " " addresses , err := query . SelectStrings ( c . tx , stmt , c . nodeID ) if err != nil { return " " , err } switch len ( addresses ) { case 0 : return " " , nil case 1 : return addresses [ 0 ] , nil default : return " " , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) NodeIsOutdated ( ) ( bool , error ) { nodes , err := c . nodes ( false , " " ) if err != nil { return false , errors . Wrap ( err , " " ) } for _ , node := range nodes { if node . ID == c . nodeID { version = node . Version ( ) } } if version [ 0 ] == 0 || version [ 1 ] == 0 { return false , fmt . Errorf ( " " ) } } n , err := util . CompareVersions ( node . Version ( ) , version ) if err != nil { errors . Wrapf ( err , " " , node . Name ) } if n == 1 { } } return false , nil } 
func ( c * ClusterTx ) NodesCount ( ) ( int , error ) { count , err := query . Count ( c . tx , " " , " " ) if err != nil { return 0 , errors . Wrap ( err , " " ) } return count , nil } 
func ( c * ClusterTx ) NodeRename ( old , new string ) error { count , err := query . Count ( c . tx , " " , " " , new ) if err != nil { return errors . Wrap ( err , " " ) } if count != 0 { return ErrAlreadyDefined } stmt := `UPDATE nodes SET name=? WHERE name=?` result , err := c . tx . Exec ( stmt , new , old ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) nodes ( pending bool , where string , args ... interface { } ) ( [ ] NodeInfo , error ) { nodes := [ ] NodeInfo { } dest := func ( i int ) [ ] interface { } { nodes = append ( nodes , NodeInfo { } ) return [ ] interface { } { & nodes [ i ] . ID , & nodes [ i ] . Name , & nodes [ i ] . Address , & nodes [ i ] . Description , & nodes [ i ] . Schema , & nodes [ i ] . APIExtensions , & nodes [ i ] . Heartbeat , } } if pending { args = append ( [ ] interface { } { 1 } , args ... ) } else { args = append ( [ ] interface { } { 0 } , args ... ) } sql := ` SELECT id, name, address, description, schema, api_extensions, heartbeat FROM nodes WHERE pending=? ` if where != " " { sql += fmt . Sprintf ( " " , where ) } sql += " " stmt , err := c . tx . Prepare ( sql ) if err != nil { return nil , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest , args ... ) if err != nil { return nil , errors . Wrap ( err , " " ) } return nodes , nil } 
func ( c * ClusterTx ) NodeAdd ( name string , address string ) ( int64 , error ) { columns := [ ] string { " " , " " , " " , " " } values := [ ] interface { } { name , address , cluster . SchemaVersion , version . APIExtensionsCount ( ) } return query . UpsertObject ( c . tx , " " , columns , values ) } 
func ( c * ClusterTx ) NodePending ( id int64 , pending bool ) error { value := 0 if pending { value = 1 } result , err := c . tx . Exec ( " " , value , id ) if err != nil { return err } n , err := result . RowsAffected ( ) if err != nil { return err } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) NodeUpdate ( id int64 , name string , address string ) error { result , err := c . tx . Exec ( " " , name , address , id ) if err != nil { return err } n , err := result . RowsAffected ( ) if err != nil { return err } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) NodeRemove ( id int64 ) error { result , err := c . tx . Exec ( " " , id ) if err != nil { return err } n , err := result . RowsAffected ( ) if err != nil { return err } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) NodeHeartbeat ( address string , heartbeat time . Time ) error { stmt := " " result , err := c . tx . Exec ( stmt , heartbeat , address ) if err != nil { return err } n , err := result . RowsAffected ( ) if err != nil { return err } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) NodeIsEmpty ( id int64 ) ( string , error ) { if err != nil { return " " , errors . Wrapf ( err , " " , id ) } if len ( containers ) > 0 { message := fmt . Sprintf ( " " , strings . Join ( containers , " " ) ) return message , nil } nodeID int64 } { } dest := func ( i int ) [ ] interface { } { images = append ( images , struct { fingerprint string nodeID int64 } { } ) return [ ] interface { } { & images [ i ] . fingerprint , & images [ i ] . nodeID } } stmt , err := c . tx . Prepare ( ` SELECT fingerprint, node_id FROM images JOIN images_nodes ON images.id=images_nodes.image_id` ) if err != nil { return " " , err } defer stmt . Close ( ) err = query . SelectObjects ( stmt , dest ) if err != nil { return " " , errors . Wrapf ( err , " " , id ) } index := map [ string ] [ ] int64 { } for _ , image := range images { index [ image . fingerprint ] = append ( index [ image . fingerprint ] , image . nodeID ) } fingerprints := [ ] string { } for fingerprint , ids := range index { if len ( ids ) > 1 { continue } if ids [ 0 ] == id { fingerprints = append ( fingerprints , fingerprint ) } } if len ( fingerprints ) > 0 { message := fmt . Sprintf ( " " , strings . Join ( fingerprints , " " ) ) return message , nil } if err != nil { return " " , errors . Wrapf ( err , " " , id ) } if len ( volumes ) > 0 { message := fmt . Sprintf ( " " , strings . Join ( volumes , " " ) ) return message , nil } return " " , nil } 
func ( c * ClusterTx ) NodeClear ( id int64 ) error { _ , err := c . tx . Exec ( " " , id ) if err != nil { return err } if err != nil { return err } if err != nil { return err } if err != nil { return err } if count > 0 { continue } _ , err = c . tx . Exec ( " " , id ) if err != nil { return err } } return nil } 
func ( c * ClusterTx ) NodeOfflineThreshold ( ) ( time . Duration , error ) { threshold := time . Duration ( DefaultOfflineThreshold ) * time . Second values , err := query . SelectStrings ( c . tx , " " ) if err != nil { return - 1 , err } if len ( values ) > 0 { seconds , err := strconv . Atoi ( values [ 0 ] ) if err != nil { return - 1 , err } threshold = time . Duration ( seconds ) * time . Second } return threshold , nil } 
func ( c * ClusterTx ) NodeWithLeastContainers ( ) ( string , error ) { threshold , err := c . NodeOfflineThreshold ( ) if err != nil { return " " , errors . Wrap ( err , " " ) } nodes , err := c . Nodes ( ) if err != nil { return " " , errors . Wrap ( err , " " ) } name := " " containers := - 1 for _ , node := range nodes { if node . IsOffline ( threshold ) { continue } if err != nil { return " " , errors . Wrap ( err , " " ) } if err != nil { return " " , errors . Wrap ( err , " " ) } count := created + pending if containers == - 1 || count < containers { containers = count name = node . Name } } return name , nil } 
func ( c * ClusterTx ) NodeUpdateVersion ( id int64 , version [ 2 ] int ) error { stmt := " " result , err := c . tx . Exec ( stmt , version [ 0 ] , version [ 1 ] , id ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " ) } return nil } 
func Transaction ( db * sql . DB , f func ( * sql . Tx ) error ) error { tx , err := db . Begin ( ) if err != nil { return errors . Wrap ( err , " " ) } err = f ( tx ) if err != nil { return rollback ( tx , err ) } err = tx . Commit ( ) if err == sql . ErrTxDone { err = nil } return err } 
func rollback ( tx * sql . Tx , reason error ) error { err := tx . Rollback ( ) if err != nil { logger . Warnf ( " " , reason , err ) } return reason } 
func ( c * ClusterTx ) ProfileURIs ( filter ProfileFilter ) ( [ ] string , error ) { if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( profileNamesByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil { stmt = c . stmt ( profileNamesByProject ) args = [ ] interface { } { filter . Project , } } else { stmt = c . stmt ( profileNames ) args = [ ] interface { } { } } code := cluster . EntityTypes [ " " ] formatter := cluster . EntityFormatURIs [ code ] return query . SelectURIs ( stmt , formatter , args ... ) } 
func ( c * ClusterTx ) ProfileList ( filter ProfileFilter ) ( [ ] Profile , error ) { if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( profileObjectsByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil { stmt = c . stmt ( profileObjectsByProject ) args = [ ] interface { } { filter . Project , } } else { stmt = c . stmt ( profileObjects ) args = [ ] interface { } { } } return [ ] interface { } { & objects [ i ] . ID , & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Description , } } if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { _ , ok := configObjects [ objects [ i ] . Project ] if ! ok { subIndex := map [ string ] map [ string ] string { } configObjects [ objects [ i ] . Project ] = subIndex } value := configObjects [ objects [ i ] . Project ] [ objects [ i ] . Name ] if value == nil { value = map [ string ] string { } } objects [ i ] . Config = value } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { _ , ok := devicesObjects [ objects [ i ] . Project ] if ! ok { subIndex := map [ string ] map [ string ] map [ string ] string { } devicesObjects [ objects [ i ] . Project ] = subIndex } value := devicesObjects [ objects [ i ] . Project ] [ objects [ i ] . Name ] if value == nil { value = map [ string ] map [ string ] string { } } objects [ i ] . Devices = value } if err != nil { return nil , errors . Wrap ( err , " " ) } for i := range objects { _ , ok := usedByObjects [ objects [ i ] . Project ] if ! ok { subIndex := map [ string ] [ ] string { } usedByObjects [ objects [ i ] . Project ] = subIndex } value := usedByObjects [ objects [ i ] . Project ] [ objects [ i ] . Name ] if value == nil { value = [ ] string { } } objects [ i ] . UsedBy = value } return objects , nil } 
func ( c * ClusterTx ) ProfileGet ( project string , name string ) ( * Profile , error ) { filter := ProfileFilter { } filter . Project = project filter . Name = name objects , err := c . ProfileList ( filter ) if err != nil { return nil , errors . Wrap ( err , " " ) } switch len ( objects ) { case 0 : return nil , ErrNoSuchObject case 1 : return & objects [ 0 ] , nil default : return nil , fmt . Errorf ( " " ) } } 
func ( c * ClusterTx ) ProfileExists ( project string , name string ) ( bool , error ) { _ , err := c . ProfileID ( project , name ) if err != nil { if err == ErrNoSuchObject { return false , nil } return false , err } return true , nil } 
func ( c * ClusterTx ) ProfileConfigRef ( filter ProfileFilter ) ( map [ string ] map [ string ] map [ string ] string , error ) { Name string Key string Value string } , 0 ) if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( profileConfigRefByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil { stmt = c . stmt ( profileConfigRefByProject ) args = [ ] interface { } { filter . Project , } } else { stmt = c . stmt ( profileConfigRef ) args = [ ] interface { } { } } Name string Key string Value string } { } ) return [ ] interface { } { & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Key , & objects [ i ] . Value , } } if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , object := range objects { _ , ok := index [ object . Project ] if ! ok { subIndex := map [ string ] map [ string ] string { } index [ object . Project ] = subIndex } item , ok := index [ object . Project ] [ object . Name ] if ! ok { item = map [ string ] string { } } index [ object . Project ] [ object . Name ] = item item [ object . Key ] = object . Value } return index , nil } 
func ( c * ClusterTx ) ProfileDevicesRef ( filter ProfileFilter ) ( map [ string ] map [ string ] map [ string ] map [ string ] string , error ) { Name string Device string Type int Key string Value string } , 0 ) if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( profileDevicesRefByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil { stmt = c . stmt ( profileDevicesRefByProject ) args = [ ] interface { } { filter . Project , } } else { stmt = c . stmt ( profileDevicesRef ) args = [ ] interface { } { } } Name string Device string Type int Key string Value string } { } ) return [ ] interface { } { & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Device , & objects [ i ] . Type , & objects [ i ] . Key , & objects [ i ] . Value , } } if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , object := range objects { _ , ok := index [ object . Project ] if ! ok { subIndex := map [ string ] map [ string ] map [ string ] string { } index [ object . Project ] = subIndex } item , ok := index [ object . Project ] [ object . Name ] if ! ok { item = map [ string ] map [ string ] string { } } index [ object . Project ] [ object . Name ] = item config , ok := item [ object . Device ] if ! ok { if err != nil { return nil , errors . Wrapf ( err , " " , object . Type ) } config = map [ string ] string { } config [ " " ] = deviceType item [ object . Device ] = config } if object . Key != " " { config [ object . Key ] = object . Value } } return index , nil } 
func ( c * ClusterTx ) ProfileUsedByRef ( filter ProfileFilter ) ( map [ string ] map [ string ] [ ] string , error ) { Name string Value string } , 0 ) if filter . Project != " " { criteria [ " " ] = filter . Project } if filter . Name != " " { criteria [ " " ] = filter . Name } var args [ ] interface { } if criteria [ " " ] != nil && criteria [ " " ] != nil { stmt = c . stmt ( profileUsedByRefByProjectAndName ) args = [ ] interface { } { filter . Project , filter . Name , } } else if criteria [ " " ] != nil { stmt = c . stmt ( profileUsedByRefByProject ) args = [ ] interface { } { filter . Project , } } else { stmt = c . stmt ( profileUsedByRef ) args = [ ] interface { } { } } Name string Value string } { } ) return [ ] interface { } { & objects [ i ] . Project , & objects [ i ] . Name , & objects [ i ] . Value , } } if err != nil { return nil , errors . Wrap ( err , " " ) } for _ , object := range objects { _ , ok := index [ object . Project ] if ! ok { subIndex := map [ string ] [ ] string { } index [ object . Project ] = subIndex } item , ok := index [ object . Project ] [ object . Name ] if ! ok { item = [ ] string { } } index [ object . Project ] [ object . Name ] = append ( item , object . Value ) } return index , nil } 
func ( c * ClusterTx ) ProfileCreate ( object Profile ) ( int64 , error ) { if err != nil { return - 1 , errors . Wrap ( err , " " ) } if exists { return - 1 , fmt . Errorf ( " " ) } args := make ( [ ] interface { } , 3 ) args [ 1 ] = object . Name args [ 2 ] = object . Description if err != nil { return - 1 , errors . Wrap ( err , " " ) } id , err := result . LastInsertId ( ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } for key , value := range object . Config { _ , err := stmt . Exec ( id , key , value ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } } if ! ok { return - 1 , fmt . Errorf ( " " , name ) } typCode , err := dbDeviceTypeToInt ( typ ) if err != nil { return - 1 , errors . Wrapf ( err , " " , typ ) } stmt = c . stmt ( profileCreateDevicesRef ) result , err := stmt . Exec ( id , name , typCode ) if err != nil { return - 1 , errors . Wrapf ( err , " " , name ) } deviceID , err := result . LastInsertId ( ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } stmt = c . stmt ( profileCreateDevicesConfigRef ) for key , value := range config { _ , err := stmt . Exec ( deviceID , key , value ) if err != nil { return - 1 , errors . Wrap ( err , " " ) } } } return id , nil } 
func ( c * ClusterTx ) ProfileRename ( project string , name string , to string ) error { stmt := c . stmt ( profileRename ) result , err := stmt . Exec ( to , project , name ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func ( c * ClusterTx ) ProfileDelete ( project string , name string ) error { stmt := c . stmt ( profileDelete ) result , err := stmt . Exec ( project , name ) if err != nil { return errors . Wrap ( err , " " ) } n , err := result . RowsAffected ( ) if err != nil { return errors . Wrap ( err , " " ) } if n != 1 { return fmt . Errorf ( " " , n ) } return nil } 
func InMemoryNetwork ( ) ( net . Listener , func ( ) net . Conn ) { listener := & inMemoryListener { conns : make ( chan net . Conn , 16 ) , closed : make ( chan struct { } ) , } dialer := func ( ) net . Conn { server , client := net . Pipe ( ) listener . conns <- server return client } return listener , dialer } 
func ( l * inMemoryListener ) Accept ( ) ( net . Conn , error ) { select { case conn := <- l . conns : return conn , nil case <- l . closed : return nil , fmt . Errorf ( " " ) } } 
func CanonicalNetworkAddress ( address string ) string { _ , _ , err := net . SplitHostPort ( address ) if err != nil { ip := net . ParseIP ( address ) if ip != nil && ip . To4 ( ) == nil { address = fmt . Sprintf ( " " , address , shared . DefaultPort ) } else { address = fmt . Sprintf ( " " , address , shared . DefaultPort ) } } return address } 
func ServerTLSConfig ( cert * shared . CertInfo ) * tls . Config { config := shared . InitTLSConfig ( ) config . ClientAuth = tls . RequestClientCert config . Certificates = [ ] tls . Certificate { cert . KeyPair ( ) } config . NextProtos = [ ] string { " " } if cert . CA ( ) != nil { pool := x509 . NewCertPool ( ) pool . AddCert ( cert . CA ( ) ) config . RootCAs = pool config . ClientCAs = pool logger . Infof ( " " ) } config . BuildNameToCertificate ( ) return config } 
func NetworkInterfaceAddress ( ) string { ifaces , err := net . Interfaces ( ) if err != nil { return " " } for _ , iface := range ifaces { if shared . IsLoopback ( & iface ) { continue } addrs , err := iface . Addrs ( ) if err != nil { continue } if len ( addrs ) == 0 { continue } addr , ok := addrs [ 0 ] . ( * net . IPNet ) if ! ok { continue } return addr . IP . String ( ) } return " " } 
func IsAddressCovered ( address1 , address2 string ) bool { if address1 == address2 { return true } host1 , port1 , err := net . SplitHostPort ( address1 ) if err != nil { return false } host2 , port2 , err := net . SplitHostPort ( address2 ) if err != nil { return false } } if ip != nil && ip . To4 ( ) != nil { return true } return false } } return false } 
func SelectObjects ( stmt * sql . Stmt , dest Dest , args ... interface { } ) error { rows , err := stmt . Query ( args ... ) if err != nil { return err } defer rows . Close ( ) for i := 0 ; rows . Next ( ) ; i ++ { err := rows . Scan ( dest ( i ) ... ) if err != nil { return err } } err = rows . Err ( ) if err != nil { return err } return nil } 
func UpsertObject ( tx * sql . Tx , table string , columns [ ] string , values [ ] interface { } ) ( int64 , error ) { n := len ( columns ) if n == 0 { return - 1 , fmt . Errorf ( " " ) } if n != len ( values ) { return - 1 , fmt . Errorf ( " " ) } stmt := fmt . Sprintf ( " " , table , strings . Join ( columns , " " ) , Params ( n ) ) result , err := tx . Exec ( stmt , values ... ) if err != nil { return - 1 , err } id , err := result . LastInsertId ( ) if err != nil { return - 1 , err } return id , nil } 
func DeleteObject ( tx * sql . Tx , table string , id int64 ) ( bool , error ) { stmt := fmt . Sprintf ( " " , table ) result , err := tx . Exec ( stmt , id ) if err != nil { return false , err } n , err := result . RowsAffected ( ) if err != nil { return false , err } if n > 1 { return true , fmt . Errorf ( " " ) } return n == 1 , nil } 
func ( t * Task ) loop ( ctx context . Context ) { for { var timer <- chan time . Time schedule , err := t . schedule ( ) switch err { case ErrSkip : fallthrough case nil : } else { timer = make ( chan time . Time ) } default : } timer = time . After ( schedule ) } select { case <- timer : if err == nil { delay = schedule } else { } case <- ctx . Done ( ) : return case <- t . reset : delay = immediately } } } 
func IsTerminal ( fd int ) bool { _ , err := GetState ( fd ) return err == nil } 
func GetState ( fd int ) ( * State , error ) { termios := syscall . Termios { } ret , err := C . tcgetattr ( C . int ( fd ) , ( * C . struct_termios ) ( unsafe . Pointer ( & termios ) ) ) if ret != 0 { return nil , err . ( syscall . Errno ) } state := State { } state . Termios = termios return & state , nil } 
func MakeRaw ( fd int ) ( * State , error ) { var err error var oldState , newState * State oldState , err = GetState ( fd ) if err != nil { return nil , err } err = shared . DeepCopy ( & oldState , & newState ) if err != nil { return nil , err } C . cfmakeraw ( ( * C . struct_termios ) ( unsafe . Pointer ( & newState . Termios ) ) ) err = Restore ( fd , newState ) if err != nil { return nil , err } return oldState , nil } 
func Restore ( fd int , state * State ) error { ret , err := C . tcsetattr ( C . int ( fd ) , C . TCSANOW , ( * C . struct_termios ) ( unsafe . Pointer ( & state . Termios ) ) ) if ret != 0 { return err . ( syscall . Errno ) } return nil } 
func socketUnixListen ( path string ) ( net . Listener , error ) { addr , err := net . ResolveUnixAddr ( " " , path ) if err != nil { return nil , fmt . Errorf ( " " , err ) } listener , err := net . ListenUnix ( " " , addr ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return listener , err } 
func CheckAlreadyRunning ( path string ) error { if err == nil { if pid == os . Getpid ( ) { return nil } } } _ , err = lxd . ConnectLXDUnix ( path , nil ) } return nil } 
func socketUnixRemoveStale ( path string ) error { } logger . Debugf ( " " ) err := os . Remove ( path ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func socketUnixSetPermissions ( path string , mode os . FileMode ) error { err := os . Chmod ( path , mode ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func socketUnixSetOwnership ( path string , group string ) error { var gid int var err error if group != " " { gid , err = shared . GroupId ( group ) if err != nil { return fmt . Errorf ( " " , group , err ) } } else { gid = os . Getgid ( ) } err = os . Chown ( path , os . Getuid ( ) , gid ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func cephOSDPoolExists ( ClusterName string , poolName string , userName string ) bool { _ , err := shared . RunCommand ( " " , " " , fmt . Sprintf ( " " , userName ) , " " , ClusterName , " " , " " , " " , poolName , " " ) if err != nil { return false } return true } 
func cephOSDPoolDestroy ( clusterName string , poolName string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , fmt . Sprintf ( " " , userName ) , " " , clusterName , " " , " " , " " , poolName , poolName , " " ) if err != nil { return err } return nil } 
func cephRBDVolumeCreate ( clusterName string , poolName string , volumeName string , volumeType string , size string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , userName , " " , " " , " " , clusterName , " " , poolName , " " , size , " " , fmt . Sprintf ( " " , volumeType , volumeName ) ) return err } 
func cephRBDVolumeExists ( clusterName string , poolName string , volumeName string , volumeType string , userName string ) bool { _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , poolName , " " , " " , fmt . Sprintf ( " " , volumeType , volumeName ) ) if err != nil { return false } return true } 
func cephRBDVolumeMap ( clusterName string , poolName string , volumeName string , volumeType string , userName string ) ( string , error ) { devPath , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , poolName , " " , fmt . Sprintf ( " " , volumeType , volumeName ) ) if err != nil { return " " , err } idx := strings . Index ( devPath , " " ) if idx < 0 { return " " , fmt . Errorf ( " " ) } devPath = devPath [ idx : ] return strings . TrimSpace ( devPath ) , nil } 
func cephRBDSnapshotProtect ( clusterName string , poolName string , volumeName string , volumeType string , snapshotName string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , poolName , " " , " " , " " , snapshotName , fmt . Sprintf ( " " , volumeType , volumeName ) ) if err != nil { runError , ok := err . ( shared . RunError ) if ok { exitError , ok := runError . Err . ( * exec . ExitError ) if ok { waitStatus := exitError . Sys ( ) . ( syscall . WaitStatus ) if waitStatus . ExitStatus ( ) == 16 { } } } return err } return nil } 
func cephRBDCloneCreate ( sourceClusterName string , sourcePoolName string , sourceVolumeName string , sourceVolumeType string , sourceSnapshotName string , targetPoolName string , targetVolumeName string , targetVolumeType string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , userName , " " , sourceClusterName , " " , " " , " " , fmt . Sprintf ( " " , sourcePoolName , sourceVolumeType , sourceVolumeName , sourceSnapshotName ) , fmt . Sprintf ( " " , targetPoolName , targetVolumeType , targetVolumeName ) ) if err != nil { return err } return nil } 
func cephRBDSnapshotListClones ( clusterName string , poolName string , volumeName string , volumeType string , snapshotName string , userName string ) ( [ ] string , error ) { msg , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , poolName , " " , " " , fmt . Sprintf ( " " , volumeType , volumeName ) , " " , snapshotName ) if err != nil { return nil , err } msg = strings . TrimSpace ( msg ) clones := strings . Fields ( msg ) if len ( clones ) == 0 { return nil , db . ErrNoSuchObject } return clones , nil } 
func cephRBDVolumeMarkDeleted ( clusterName string , poolName string , volumeType string , oldVolumeName string , newVolumeName string , userName string , suffix string ) error { deletedName := fmt . Sprintf ( " " , poolName , volumeType , newVolumeName ) if suffix != " " { deletedName = fmt . Sprintf ( " " , deletedName , suffix ) } _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , fmt . Sprintf ( " " , poolName , volumeType , oldVolumeName ) , deletedName ) if err != nil { return err } return nil } 
func cephRBDVolumeUnmarkDeleted ( clusterName string , poolName string , volumeName string , volumeType string , userName string , oldSuffix string , newSuffix string ) error { oldName := fmt . Sprintf ( " " , poolName , volumeType , volumeName ) if oldSuffix != " " { oldName = fmt . Sprintf ( " " , oldName , oldSuffix ) } newName := fmt . Sprintf ( " " , poolName , volumeType , volumeName ) if newSuffix != " " { newName = fmt . Sprintf ( " " , newName , newSuffix ) } _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , oldName , newName ) if err != nil { return err } return nil } 
func cephRBDVolumeRename ( clusterName string , poolName string , volumeType string , oldVolumeName string , newVolumeName string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , fmt . Sprintf ( " " , poolName , volumeType , oldVolumeName ) , fmt . Sprintf ( " " , poolName , volumeType , newVolumeName ) ) if err != nil { return err } return nil } 
func cephRBDVolumeSnapshotRename ( clusterName string , poolName string , volumeName string , volumeType string , oldSnapshotName string , newSnapshotName string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , " " , fmt . Sprintf ( " " , poolName , volumeType , volumeName , oldSnapshotName ) , fmt . Sprintf ( " " , poolName , volumeType , volumeName , newSnapshotName ) ) if err != nil { return err } return nil } 
func cephRBDVolumeGetParent ( clusterName string , poolName string , volumeName string , volumeType string , userName string ) ( string , error ) { msg , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , poolName , " " , fmt . Sprintf ( " " , volumeType , volumeName ) ) if err != nil { return " " , err } idx := strings . Index ( msg , " " ) if idx == - 1 { return " " , db . ErrNoSuchObject } msg = msg [ ( idx + len ( " " ) ) : ] msg = strings . TrimSpace ( msg ) idx = strings . Index ( msg , " \n " ) if idx == - 1 { return " " , fmt . Errorf ( " " ) } msg = msg [ : idx ] msg = strings . TrimSpace ( msg ) return msg , nil } 
func cephRBDSnapshotDelete ( clusterName string , poolName string , volumeName string , volumeType string , snapshotName string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , poolName , " " , " " , fmt . Sprintf ( " " , volumeType , volumeName , snapshotName ) ) if err != nil { return err } return nil } 
func cephRBDVolumeCopy ( clusterName string , oldVolumeName string , newVolumeName string , userName string ) error { _ , err := shared . RunCommand ( " " , " " , userName , " " , clusterName , " " , oldVolumeName , newVolumeName ) if err != nil { return err } return nil } 
func cephRBDVolumeListSnapshots ( clusterName string , poolName string , volumeName string , volumeType string , userName string ) ( [ ] string , error ) { msg , err := shared . RunCommand ( " " , " " , userName , " " , " " , " " , clusterName , " " , poolName , " " , " " , fmt . Sprintf ( " " , volumeType , volumeName ) ) if err != nil { return [ ] string { } , err } var data [ ] map [ string ] interface { } err = json . Unmarshal ( [ ] byte ( msg ) , & data ) if err != nil { return [ ] string { } , err } snapshots := [ ] string { } for _ , v := range data { _ , ok := v [ " " ] if ! ok { return [ ] string { } , fmt . Errorf ( " \" \" " ) } name , ok := v [ " " ] . ( string ) if ! ok { return [ ] string { } , fmt . Errorf ( " \" \" " ) } name = strings . TrimSpace ( name ) snapshots = append ( snapshots , name ) } if len ( snapshots ) == 0 { return [ ] string { } , db . ErrNoSuchObject } return snapshots , nil } 
func ( s * storageCeph ) getRBDSize ( ) ( string , error ) { sz , err := shared . ParseByteSizeString ( s . volume . Config [ " " ] ) if err != nil { return " " , err } } return fmt . Sprintf ( " " , sz ) , nil } 
func ( s * storageCeph ) getRBDFilesystem ( ) string { if s . volume . Config [ " " ] != " " { return s . volume . Config [ " " ] } if s . pool . Config [ " " ] != " " { return s . pool . Config [ " " ] } return " " } 
func ( s * storageCeph ) copyWithoutSnapshotsFull ( target container , source container ) error { logger . Debugf ( `Creating non-sparse copy of RBD storage volume for container "%s" to "%s" without snapshots` , source . Name ( ) , target . Name ( ) ) sourceIsSnapshot := source . IsSnapshot ( ) sourceContainerName := projectPrefix ( source . Project ( ) , source . Name ( ) ) targetContainerName := projectPrefix ( target . Project ( ) , target . Name ( ) ) oldVolumeName := fmt . Sprintf ( " " , s . OSDPoolName , sourceContainerName ) newVolumeName := fmt . Sprintf ( " " , s . OSDPoolName , targetContainerName ) if sourceIsSnapshot { sourceContainerOnlyName , sourceSnapshotOnlyName , _ := containerGetParentAndSnapshotName ( sourceContainerName ) oldVolumeName = fmt . Sprintf ( " " , s . OSDPoolName , sourceContainerOnlyName , sourceSnapshotOnlyName ) } err := cephRBDVolumeCopy ( s . ClusterName , oldVolumeName , newVolumeName , s . UserName ) if err != nil { logger . Debugf ( `Failed to create full RBD copy "%s" to "%s": %s` , source . Name ( ) , target . Name ( ) , err ) return err } _ , err = cephRBDVolumeMap ( s . ClusterName , s . OSDPoolName , targetContainerName , storagePoolVolumeTypeNameContainer , s . UserName ) if err != nil { logger . Errorf ( `Failed to map RBD storage volume for image "%s" on storage pool "%s": %s` , targetContainerName , s . pool . Name , err ) return err } targetContainerMountPoint := getContainerMountPoint ( target . Project ( ) , s . pool . Name , target . Name ( ) ) err = createContainerMountpoint ( targetContainerMountPoint , target . Path ( ) , target . IsPrivileged ( ) ) if err != nil { return err } ourMount , err := target . StorageStart ( ) if err != nil { return err } if ourMount { defer target . StorageStop ( ) } err = target . TemplateApply ( " " ) if err != nil { logger . Errorf ( `Failed to apply copy template for container "%s": %s` , target . Name ( ) , err ) return err } logger . Debugf ( `Applied copy template for container "%s"` , target . Name ( ) ) logger . Debugf ( `Created non-sparse copy of RBD storage volume for container "%s" to "%s" without snapshots` , source . Name ( ) , target . Name ( ) ) return nil } 
func ( s * storageCeph ) copyWithoutSnapshotsSparse ( target container , source container ) error { logger . Debugf ( `Creating sparse copy of RBD storage volume for container "%s" to "%s" without snapshots` , source . Name ( ) , target . Name ( ) ) sourceIsSnapshot := source . IsSnapshot ( ) sourceContainerName := projectPrefix ( source . Project ( ) , source . Name ( ) ) targetContainerName := projectPrefix ( target . Project ( ) , target . Name ( ) ) sourceContainerOnlyName := sourceContainerName sourceSnapshotOnlyName := " " snapshotName := fmt . Sprintf ( " " , uuid . NewRandom ( ) . String ( ) ) if sourceIsSnapshot { sourceContainerOnlyName , sourceSnapshotOnlyName , _ = containerGetParentAndSnapshotName ( sourceContainerName ) snapshotName = fmt . Sprintf ( " " , sourceSnapshotOnlyName ) } else { if err != nil { logger . Errorf ( `Failed to create snapshot for RBD storage volume for image "%s" on storage pool "%s": %s` , targetContainerName , s . pool . Name , err ) return err } } if err != nil { logger . Errorf ( `Failed to protect snapshot for RBD storage volume for image "%s" on storage pool "%s": %s` , snapshotName , s . pool . Name , err ) return err } err = cephRBDCloneCreate ( s . ClusterName , s . OSDPoolName , sourceContainerOnlyName , storagePoolVolumeTypeNameContainer , snapshotName , s . OSDPoolName , targetContainerName , storagePoolVolumeTypeNameContainer , s . UserName ) if err != nil { logger . Errorf ( `Failed to clone new RBD storage volume for container "%s": %s` , targetContainerName , err ) return err } if err != nil { return err } err = createContainerMountpoint ( targetContainerMountPoint , target . Path ( ) , target . IsPrivileged ( ) ) if err != nil { return err } ourMount , err := target . StorageStart ( ) if err != nil { return err } if ourMount { defer target . StorageStop ( ) } err = target . TemplateApply ( " " ) if err != nil { logger . Errorf ( `Failed to apply copy template for container "%s": %s` , target . Name ( ) , err ) return err } logger . Debugf ( `Applied copy template for container "%s"` , target . Name ( ) ) logger . Debugf ( `Created sparse copy of RBD storage volume for container "%s" to "%s" without snapshots` , source . Name ( ) , target . Name ( ) ) return nil } 
func ( s * storageCeph ) copyWithSnapshots ( sourceVolumeName string , targetVolumeName string , sourceParentSnapshot string ) error { logger . Debugf ( `Creating non-sparse copy of RBD storage volume "%s to "%s"` , sourceVolumeName , targetVolumeName ) args := [ ] string { " " , " " , s . UserName , " " , s . ClusterName , sourceVolumeName , } if sourceParentSnapshot != " " { args = append ( args , " " , sourceParentSnapshot ) } // redirect output to stdout args = append ( args , " " ) rbdSendCmd := exec . Command ( " " , args ... ) rbdRecvCmd := exec . Command ( " " , " " , s . UserName , " " , " " , s . ClusterName , " " , targetVolumeName ) rbdRecvCmd . Stdin , _ = rbdSendCmd . StdoutPipe ( ) rbdRecvCmd . Stdout = os . Stdout rbdRecvCmd . Stderr = os . Stderr err := rbdRecvCmd . Start ( ) if err != nil { return err } err = rbdSendCmd . Run ( ) if err != nil { return err } err = rbdRecvCmd . Wait ( ) if err != nil { return err } logger . Debugf ( `Created non-sparse copy of RBD storage volume "%s" to "%s"` , sourceVolumeName , targetVolumeName ) return nil } 
func cephContainerDelete ( clusterName string , poolName string , volumeName string , volumeType string , userName string ) int { logEntry := fmt . Sprintf ( " " , poolName , volumeType , volumeName ) snaps , err := cephRBDVolumeListSnapshots ( clusterName , poolName , volumeName , volumeType , userName ) if err == nil { var zombies int for _ , snap := range snaps { logEntry := fmt . Sprintf ( " " , poolName , volumeType , volumeName , snap ) ret := cephContainerSnapshotDelete ( clusterName , poolName , volumeName , volumeType , snap , userName ) if ret < 0 { logger . Errorf ( `Failed to delete RBD storage volume "%s"` , logEntry ) return - 1 } else if ret == 1 { logger . Debugf ( `Marked RBD storage volume "%s" as zombie` , logEntry ) zombies ++ } else { logger . Debugf ( `Deleted RBD storage volume "%s"` , logEntry ) } } if zombies > 0 { if err != nil { logger . Errorf ( `Failed to unmap RBD storage volume "%s": %s` , logEntry , err ) return - 1 } logger . Debugf ( `Unmapped RBD storage volume "%s"` , logEntry ) if strings . HasPrefix ( volumeType , " " ) { logger . Debugf ( `RBD storage volume "%s" already marked as zombie` , logEntry ) return 1 } newVolumeName := fmt . Sprintf ( " " , volumeName , uuid . NewRandom ( ) . String ( ) ) err := cephRBDVolumeMarkDeleted ( clusterName , poolName , volumeType , volumeName , newVolumeName , userName , " " ) if err != nil { logger . Errorf ( `Failed to mark RBD storage volume "%s" as zombie: %s` , logEntry , err ) return - 1 } logger . Debugf ( `Marked RBD storage volume "%s" as zombie` , logEntry ) return 1 } } else { if err != db . ErrNoSuchObject { logger . Errorf ( `Failed to retrieve snapshots of RBD storage volume: %s` , err ) return - 1 } parent , err := cephRBDVolumeGetParent ( clusterName , poolName , volumeName , volumeType , userName ) if err == nil { logger . Debugf ( `Detected "%s" as parent of RBD storage volume "%s"` , parent , logEntry ) _ , parentVolumeType , parentVolumeName , parentSnapshotName , err := parseParent ( parent ) if err != nil { logger . Errorf ( `Failed to parse parent "%s" of RBD storage volume "%s"` , parent , logEntry ) return - 1 } logger . Debugf ( `Split parent "%s" of RBD storage volume "%s" into volume type "%s", volume name "%s", and snapshot name "%s"` , parent , logEntry , parentVolumeType , parentVolumeName , parentSnapshotName ) if err != nil { logger . Errorf ( `Failed to unmap RBD storage volume "%s": %s` , logEntry , err ) return - 1 } logger . Debugf ( `Unmapped RBD storage volume "%s"` , logEntry ) if err != nil { logger . Errorf ( `Failed to delete RBD storage volume "%s": %s` , logEntry , err ) return - 1 } logger . Debugf ( `Deleted RBD storage volume "%s"` , logEntry ) if ret < 0 { logger . Errorf ( `Failed to delete snapshot "%s" of RBD storage volume "%s"` , parentSnapshotName , logEntry ) return - 1 } logger . Debugf ( `Deleteed snapshot "%s" of RBD storage volume "%s"` , parentSnapshotName , logEntry ) } return 0 } else { if err != db . ErrNoSuchObject { logger . Errorf ( `Failed to retrieve parent of RBD storage volume "%s"` , logEntry ) return - 1 } logger . Debugf ( `RBD storage volume "%s" does not have parent` , logEntry ) if err != nil { logger . Errorf ( `Failed to unmap RBD storage volume "%s": %s` , logEntry , err ) return - 1 } logger . Debugf ( `Unmapped RBD storage volume "%s"` , logEntry ) if err != nil { logger . Errorf ( `Failed to delete RBD storage volume "%s": %s` , logEntry , err ) return - 1 } logger . Debugf ( `Deleted RBD storage volume "%s"` , logEntry ) } } return 0 } 
func cephContainerSnapshotDelete ( clusterName string , poolName string , volumeName string , volumeType string , snapshotName string , userName string ) int { logImageEntry := fmt . Sprintf ( " " , poolName , volumeType , volumeName ) logSnapshotEntry := fmt . Sprintf ( " " , poolName , volumeType , volumeName , snapshotName ) clones , err := cephRBDSnapshotListClones ( clusterName , poolName , volumeName , volumeType , snapshotName , userName ) if err != nil { if err != db . ErrNoSuchObject { logger . Errorf ( `Failed to list clones of RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debugf ( `RBD snapshot "%s" of RBD storage volume "%s" does not have any clones` , logSnapshotEntry , logImageEntry ) if err != nil { logger . Errorf ( `Failed to unprotect RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debugf ( `Unprotected RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if err != nil { logger . Errorf ( `Failed to unmap RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debugf ( `Unmapped RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if err != nil { logger . Errorf ( `Failed to delete RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debugf ( `Deleted RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if ret < 0 { logger . Errorf ( `Failed to delete RBD storage volume "%s"` , logImageEntry ) return - 1 } logger . Debugf ( `Deleted RBD storage volume "%s"` , logImageEntry ) } return 0 } else { logger . Debugf ( `Detected "%v" as clones of RBD snapshot "%s" of RBD storage volume "%s"` , clones , logSnapshotEntry , logImageEntry ) canDelete := true for _ , clone := range clones { clonePool , cloneType , cloneName , err := parseClone ( clone ) if err != nil { logger . Errorf ( `Failed to parse clone "%s" of RBD snapshot "%s" of RBD storage volume "%s"` , clone , logSnapshotEntry , logImageEntry ) return - 1 } logger . Debugf ( `Split clone "%s" of RBD snapshot "%s" of RBD storage volume "%s" into pool name "%s", volume type "%s", and volume name "%s"` , clone , logSnapshotEntry , logImageEntry , clonePool , cloneType , cloneName ) if ! strings . HasPrefix ( cloneType , " " ) { canDelete = false continue } ret := cephContainerDelete ( clusterName , clonePool , cloneName , cloneType , userName ) if ret < 0 { logger . Errorf ( `Failed to delete clone "%s" of RBD snapshot "%s" of RBD storage volume "%s"` , clone , logSnapshotEntry , logImageEntry ) return - 1 } else if ret == 1 { } } if canDelete { logger . Debugf ( `Deleted all clones of RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if err != nil { logger . Errorf ( `Failed to unprotect RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debugf ( `Unprotected RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if err != nil { logger . Errorf ( `Failed to unmap RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debugf ( `Unmapped RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if err != nil { logger . Errorf ( `Failed to delete RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debugf ( `Deleted RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if ret < 0 { logger . Errorf ( `Failed to delete RBD storage volume "%s"` , logImageEntry ) return - 1 } logger . Debugf ( `Deleted RBD storage volume "%s"` , logImageEntry ) } } else { logger . Debugf ( `Could not delete all clones of RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) if strings . HasPrefix ( snapshotName , " " ) { return 1 } err := cephRBDVolumeSnapshotUnmap ( clusterName , poolName , volumeName , volumeType , snapshotName , userName , true ) if err != nil { logger . Errorf ( `Failed to unmap RBD snapshot "%s" of RBD storage volume "%s": %s` , logSnapshotEntry , logImageEntry , err ) return - 1 } logger . Debug ( `Unmapped RBD snapshot "%s" of RBD storage volume "%s"` , logSnapshotEntry , logImageEntry ) newSnapshotName := fmt . Sprintf ( " " , snapshotName ) logSnapshotNewEntry := fmt . Sprintf ( " " , poolName , volumeName , volumeType , newSnapshotName ) err = cephRBDVolumeSnapshotRename ( clusterName , poolName , volumeName , volumeType , snapshotName , newSnapshotName , userName ) if err != nil { logger . Errorf ( `Failed to rename RBD snapshot "%s" of RBD storage volume "%s" to %s` , logSnapshotEntry , logImageEntry , logSnapshotNewEntry ) return - 1 } logger . Debugf ( `Renamed RBD snapshot "%s" of RBD storage volume "%s" to %s` , logSnapshotEntry , logImageEntry , logSnapshotNewEntry ) } } return 1 } 
func parseParent ( parent string ) ( string , string , string , string , error ) { idx := strings . Index ( parent , " " ) if idx == - 1 { return " " , " " , " " , " " , fmt . Errorf ( " " ) } slider := parent [ ( idx + 1 ) : ] poolName := parent [ : idx ] volumeType := slider idx = strings . Index ( slider , " " ) if idx == 0 { idx += len ( " " ) volumeType = slider slider = slider [ idx : ] } idxType := strings . Index ( slider , " " ) if idxType == - 1 { return " " , " " , " " , " " , fmt . Errorf ( " " ) } if idx == len ( " " ) { idxType += idx } volumeType = volumeType [ : idxType ] idx = strings . Index ( slider , " " ) if idx == - 1 { return " " , " " , " " , " " , fmt . Errorf ( " " ) } volumeName := slider idx = strings . Index ( volumeName , " " ) if idx == - 1 { return " " , " " , " " , " " , fmt . Errorf ( " " ) } volumeName = volumeName [ ( idx + 1 ) : ] idx = strings . Index ( volumeName , " " ) if idx == - 1 { return " " , " " , " " , " " , fmt . Errorf ( " " ) } snapshotName := volumeName [ ( idx + 1 ) : ] volumeName = volumeName [ : idx ] return poolName , volumeType , volumeName , snapshotName , nil } 
func parseClone ( clone string ) ( string , string , string , error ) { idx := strings . Index ( clone , " " ) if idx == - 1 { return " " , " " , " " , fmt . Errorf ( " " ) } slider := clone [ ( idx + 1 ) : ] poolName := clone [ : idx ] volumeType := slider idx = strings . Index ( slider , " " ) if idx == 0 { idx += len ( " " ) volumeType = slider slider = slider [ idx : ] } idxType := strings . Index ( slider , " " ) if idxType == - 1 { return " " , " " , " " , fmt . Errorf ( " " ) } if idx == len ( " " ) { idxType += idx } volumeType = volumeType [ : idxType ] idx = strings . Index ( slider , " " ) if idx == - 1 { return " " , " " , " " , fmt . Errorf ( " " ) } volumeName := slider idx = strings . Index ( volumeName , " " ) if idx == - 1 { return " " , " " , " " , fmt . Errorf ( " " ) } volumeName = volumeName [ ( idx + 1 ) : ] return poolName , volumeType , volumeName , nil } 
func getRBDMappedDevPath ( clusterName string , poolName string , volumeType string , volumeName string , doMap bool , userName string ) ( string , int ) { files , err := ioutil . ReadDir ( " " ) if err != nil { if os . IsNotExist ( err ) { if doMap { goto mapImage } return " " , 0 } return " " , - 1 } for _ , f := range files { if ! f . IsDir ( ) { continue } fName := f . Name ( ) idx , err := strconv . ParseUint ( fName , 10 , 64 ) if err != nil { continue } tmp := fmt . Sprintf ( " " , fName ) contents , err := ioutil . ReadFile ( tmp ) if err != nil { if os . IsNotExist ( err ) { continue } return " " , - 1 } detectedPoolName := strings . TrimSpace ( string ( contents ) ) if detectedPoolName != poolName { continue } tmp = fmt . Sprintf ( " " , fName ) contents , err = ioutil . ReadFile ( tmp ) if err != nil { if os . IsNotExist ( err ) { continue } return " " , - 1 } typedVolumeName := fmt . Sprintf ( " " , volumeType , volumeName ) detectedVolumeName := strings . TrimSpace ( string ( contents ) ) if detectedVolumeName != typedVolumeName { continue } tmp = fmt . Sprintf ( " " , fName ) contents , err = ioutil . ReadFile ( tmp ) if err != nil { if os . IsNotExist ( err ) { return fmt . Sprintf ( " " , idx ) , 1 } return " " , - 1 } detectedSnapName := strings . TrimSpace ( string ( contents ) ) if detectedSnapName != " " { continue } return fmt . Sprintf ( " " , idx ) , 1 } if ! doMap { return " " , 0 } mapImage : devPath , err := cephRBDVolumeMap ( clusterName , poolName , volumeName , volumeType , userName ) if err != nil { return " " , - 1 } return strings . TrimSpace ( devPath ) , 2 } 
func ( s * storageCeph ) cephRBDVolumeDumpToFile ( sourceVolumeName string , file string ) error { logger . Debugf ( `Dumping RBD storage volume "%s" to "%s"` , sourceVolumeName , file ) args := [ ] string { " " , " " , s . UserName , " " , s . ClusterName , sourceVolumeName , file , } rbdSendCmd := exec . Command ( " " , args ... ) err := rbdSendCmd . Run ( ) if err != nil { return err } logger . Debugf ( `Dumped RBD storage volume "%s" to "%s"` , sourceVolumeName , file ) return nil } 
func ( s * storageCeph ) cephRBDVolumeBackupCreate ( tmpPath string , backup backup , source container ) error { sourceIsSnapshot := source . IsSnapshot ( ) sourceContainerName := source . Name ( ) sourceContainerOnlyName := projectPrefix ( source . Project ( ) , sourceContainerName ) sourceSnapshotOnlyName := " " if err != nil { return fmt . Errorf ( " " , string ( output ) , err ) } return nil } bwlimit := s . pool . Config [ " " ] if sourceIsSnapshot { sourceContainerOnlyName , sourceSnapshotOnlyName , _ = containerGetParentAndSnapshotName ( sourceContainerName ) sourceContainerOnlyName = projectPrefix ( source . Project ( ) , sourceContainerOnlyName ) snapshotName = fmt . Sprintf ( " " , projectPrefix ( source . Project ( ) , sourceSnapshotOnlyName ) ) } else { if err != nil { return err } defer cephRBDSnapshotDelete ( s . ClusterName , s . OSDPoolName , sourceContainerOnlyName , storagePoolVolumeTypeNameContainer , snapshotName , s . UserName ) } if err != nil { return err } defer cephRBDSnapshotUnprotect ( s . ClusterName , s . OSDPoolName , sourceContainerOnlyName , storagePoolVolumeTypeNameContainer , snapshotName , s . UserName ) err = cephRBDCloneCreate ( s . ClusterName , s . OSDPoolName , sourceContainerOnlyName , storagePoolVolumeTypeNameContainer , snapshotName , s . OSDPoolName , cloneName , " " , s . UserName ) if err != nil { return err } defer cephRBDVolumeDelete ( s . ClusterName , s . OSDPoolName , cloneName , " " , s . UserName ) if err != nil { return err } defer cephRBDVolumeUnmap ( s . ClusterName , s . OSDPoolName , cloneName , " " , s . UserName , true ) msg , err := fsGenerateNewUUID ( RBDFilesystem , RBDDevPath ) if err != nil { logger . Errorf ( " \" \" " , RBDFilesystem , msg , err ) return err } if err != nil { return err } defer os . RemoveAll ( tmpContainerMntPoint ) err = os . Chmod ( tmpContainerMntPoint , 0700 ) if err != nil { return err } err = tryMount ( RBDDevPath , tmpContainerMntPoint , RBDFilesystem , mountFlags , mountOptions ) if err != nil { logger . Errorf ( " " , RBDDevPath , tmpContainerMntPoint , err ) return err } logger . Debugf ( " " , RBDDevPath , tmpContainerMntPoint ) defer tryUnmount ( tmpContainerMntPoint , syscall . MNT_DETACH ) if sourceIsSnapshot { _ , targetName , _ = containerGetParentAndSnapshotName ( sourceContainerName ) } if sourceIsSnapshot { targetBackupMntPoint = fmt . Sprintf ( " " , tmpPath , targetName ) } err = os . MkdirAll ( targetBackupMntPoint , 0711 ) if err != nil { return err } err = rsync ( tmpContainerMntPoint , targetBackupMntPoint , bwlimit ) if err != nil { return err } return nil } 
func ( s * storageCeph ) cephRBDGenerateUUID ( volumeName string , volumeType string ) error { if err != nil { return err } defer cephRBDVolumeUnmap ( s . ClusterName , s . OSDPoolName , volumeName , volumeType , s . UserName , true ) if err != nil { return fmt . Errorf ( " " , volumeName , err , msg ) } return nil } 
func GetConfigCmd ( noPortForwarding * bool ) * cobra . Command { var format string getConfig := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( true , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) resp , err := c . GetConfiguration ( c . Ctx ( ) , & auth . GetConfigurationRequest { } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } if resp . Configuration == nil { fmt . Println ( " " ) return nil } output , err := json . MarshalIndent ( resp . Configuration , " " , " " ) if err != nil { return fmt . Errorf ( " \n \n " , resp . Configuration , err ) } switch format { case " " : if err != nil { return fmt . Errorf ( " " , err ) } default : return fmt . Errorf ( " " , format ) } fmt . Println ( string ( output ) ) return nil } ) , } getConfig . Flags ( ) . StringVarP ( & format , " " , " " , " " , " " + " \" \" \" \" " ) return cmdutil . CreateAlias ( getConfig , " " ) } 
func SetConfigCmd ( noPortForwarding * bool ) * cobra . Command { var file string setConfig := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( true , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) var configBytes [ ] byte if file == " " { var err error configBytes , err = ioutil . ReadAll ( os . Stdin ) if err != nil { return fmt . Errorf ( " " , err ) } } else if file != " " { var err error configBytes , err = ioutil . ReadFile ( file ) if err != nil { return fmt . Errorf ( " " , file , err ) } } else { return errors . New ( " \" \" " ) } if err := yaml . Unmarshal ( configBytes , & config ) ; err != nil { return fmt . Errorf ( " " , err ) } return grpcutil . ScrubGRPC ( err ) } ) , } setConfig . Flags ( ) . StringVarP ( & file , " " , " " , " " , " " + " " ) return cmdutil . CreateAlias ( setConfig , " " ) } 
func NewSharder ( discoveryClient discovery . Client , numShards uint64 , namespace string ) Sharder { return newSharder ( discoveryClient , numShards , namespace ) } 
func NewRouter ( sharder Sharder , dialer grpcutil . Dialer , localAddress string , ) Router { return newRouter ( sharder , dialer , localAddress , ) } 
func PachctlCmd ( ) * cobra . Command { var verbose bool var noMetrics bool var noPortForwarding bool raw := false rawFlags := pflag . NewFlagSet ( " " , pflag . ContinueOnError ) rawFlags . BoolVar ( & raw , " " , false , " " ) marshaller := & jsonpb . Marshaler { Indent : " " } rootCmd := & cobra . Command { Use : os . Args [ 0 ] , Long : `Access the Pachyderm API. Environment variables: PACHD_ADDRESS=<host>:<port>, the pachd server to connect to (e.g. 127.0.0.1:30650). PACH_CONFIG=<path>, the path where pachctl will attempt to load your pach config. JAEGER_ENDPOINT=<host>:<port>, the Jaeger server to connect to, if PACH_ENABLE_TRACING is set PACH_ENABLE_TRACING={true,false}, If true, and JAEGER_ENDPOINT is set, attach a Jaeger trace to all outgoing RPCs ` , PersistentPreRun : func ( cmd * cobra . Command , args [ ] string ) { log . SetFormatter ( new ( prefixed . TextFormatter ) ) if ! verbose { log . SetLevel ( log . ErrorLevel ) } else { log . SetLevel ( log . DebugLevel ) etcd . SetLogger ( grpclog . NewLoggerV2 ( logutil . NewGRPCLogWriter ( logger , " " ) , ioutil . Discard , ioutil . Discard , ) ) } } , BashCompletionFunction : bashCompletionFunc , } rootCmd . PersistentFlags ( ) . BoolVarP ( & verbose , " " , " " , false , " " ) rootCmd . PersistentFlags ( ) . BoolVarP ( & noMetrics , " " , " " , false , " " ) rootCmd . PersistentFlags ( ) . BoolVarP ( & noPortForwarding , " " , " " , false , " " ) var subcommands [ ] * cobra . Command var clientOnly bool var timeoutFlag string versionCmd := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) ( retErr error ) { if clientOnly { if raw { if err := marshaller . Marshal ( os . Stdout , version . Version ) ; err != nil { return err } } else { fmt . Println ( version . PrettyPrintVersion ( version . Version ) ) } return nil } if ! noMetrics { start := time . Now ( ) startMetricsWait := metrics . StartReportAndFlushUserAction ( " " , start ) defer startMetricsWait ( ) defer func ( ) { finishMetricsWait := metrics . FinishReportAndFlushUserAction ( " " , retErr , start ) finishMetricsWait ( ) } ( ) } if raw { if err := marshaller . Marshal ( os . Stdout , version . Version ) ; err != nil { return err } } else { printVersionHeader ( writer ) printVersion ( writer , " " , version . Version ) if err := writer . Flush ( ) ; err != nil { return err } } var err error if timeoutFlag != " " { var timeout time . Duration timeout , err = time . ParseDuration ( timeoutFlag ) if err != nil { return fmt . Errorf ( " " , timeout , err ) } pachClient , err = client . NewOnUserMachine ( false , ! noPortForwarding , " " , client . WithDialTimeout ( timeout ) ) } else { pachClient , err = client . NewOnUserMachine ( false , ! noPortForwarding , " " ) } if err != nil { return err } defer pachClient . Close ( ) ctx , cancel := context . WithTimeout ( context . Background ( ) , time . Second ) defer cancel ( ) version , err := pachClient . GetVersion ( ctx , & types . Empty { } ) if err != nil { buf := bytes . NewBufferString ( " " ) errWriter := ansiterm . NewTabWriter ( buf , 20 , 1 , 3 , ' ' , 0 ) fmt . Fprintf ( errWriter , " \t \n \n \n " , pachClient . GetAddress ( ) , grpc . ErrorDesc ( err ) ) errWriter . Flush ( ) return errors . New ( buf . String ( ) ) } } } else { printVersion ( writer , " " , version ) if err := writer . Flush ( ) ; err != nil { return err } } return nil } ) , } versionCmd . Flags ( ) . BoolVar ( & clientOnly , " " , false , " " + " " + " " ) versionCmd . Flags ( ) . StringVar ( & timeoutFlag , " " , " " , " " + " " + " " + " " + " " ) versionCmd . Flags ( ) . AddFlagSet ( rawFlags ) subcommands = append ( subcommands , cmdutil . CreateAlias ( versionCmd , " " ) ) deleteAll := & cobra . Command { Short : " " , Long : `Delete all repos, commits, files, pipelines and jobs. This resets the cluster to its initial state.` , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! noMetrics , ! noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) red := color . New ( color . FgRed ) . SprintFunc ( ) var repos , pipelines [ ] string repoInfos , err := client . ListRepo ( ) if err != nil { return err } for _ , ri := range repoInfos { repos = append ( repos , red ( ri . Repo . Name ) ) } pipelineInfos , err := client . ListPipeline ( ) if err != nil { return err } for _ , pi := range pipelineInfos { pipelines = append ( pipelines , red ( pi . Pipeline . Name ) ) } fmt . Println ( " " ) if len ( repos ) > 0 { fmt . Printf ( " \n " , strings . Join ( repos , " " ) ) } if len ( pipelines ) > 0 { fmt . Printf ( " \n " , strings . Join ( pipelines , " " ) ) } fmt . Println ( " " ) r := bufio . NewReader ( os . Stdin ) bytes , err := r . ReadBytes ( '\n' ) if err != nil { return err } if bytes [ 0 ] == 'y' || bytes [ 0 ] == 'Y' { return client . DeleteAll ( ) } return nil } ) , } subcommands = append ( subcommands , cmdutil . CreateAlias ( deleteAll , " " ) ) var port uint16 var remotePort uint16 var samlPort uint16 var uiPort uint16 var uiWebsocketPort uint16 var pfsPort uint16 var s3gatewayPort uint16 var namespace string portForward := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { fw , err := client . NewPortForwarder ( namespace ) if err != nil { return err } if err = fw . Lock ( ) ; err != nil { return err } defer fw . Close ( ) failCount := 0 fmt . Println ( " " ) if err = fw . RunForDaemon ( port , remotePort ) ; err != nil { fmt . Printf ( " \n " , err ) failCount ++ } fmt . Println ( " " ) if err = fw . RunForSAMLACS ( samlPort ) ; err != nil { fmt . Printf ( " \n " , err ) failCount ++ } fmt . Printf ( " \n " , uiPort ) if err = fw . RunForDashUI ( uiPort ) ; err != nil { fmt . Printf ( " \n " , err ) failCount ++ } fmt . Println ( " " ) if err = fw . RunForDashWebSocket ( uiWebsocketPort ) ; err != nil { fmt . Printf ( " \n " , err ) failCount ++ } fmt . Println ( " " ) if err = fw . RunForPFS ( pfsPort ) ; err != nil { fmt . Printf ( " \n " , err ) failCount ++ } fmt . Println ( " " ) if err = fw . RunForS3Gateway ( s3gatewayPort ) ; err != nil { fmt . Printf ( " \n " , err ) failCount ++ } if failCount < 6 { fmt . Println ( " " ) ch := make ( chan os . Signal , 1 ) signal . Notify ( ch , os . Interrupt ) <- ch } return nil } ) , } portForward . Flags ( ) . Uint16VarP ( & port , " " , " " , 30650 , " " ) portForward . Flags ( ) . Uint16Var ( & remotePort , " " , 650 , " " ) portForward . Flags ( ) . Uint16Var ( & samlPort , " " , 30654 , " " ) portForward . Flags ( ) . Uint16VarP ( & uiPort , " " , " " , 30080 , " " ) portForward . Flags ( ) . Uint16VarP ( & uiWebsocketPort , " " , " " , 30081 , " " ) portForward . Flags ( ) . Uint16VarP ( & pfsPort , " " , " " , 30652 , " " ) portForward . Flags ( ) . Uint16VarP ( & s3gatewayPort , " " , " " , 30600 , " " ) portForward . Flags ( ) . StringVar ( & namespace , " " , " " , " " ) subcommands = append ( subcommands , cmdutil . CreateAlias ( portForward , " " ) ) var install bool var path string completion := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) ( retErr error ) { var dest io . Writer if install { f , err := os . Create ( path ) if err != nil { if os . IsPermission ( err ) { fmt . Fprintf ( os . Stderr , " \n " ) } return err } defer func ( ) { if err := f . Close ( ) ; err != nil && retErr == nil { retErr = err } fmt . Printf ( " \n " , path ) } ( ) dest = f } else { dest = os . Stdout } unhide = func ( cmd * cobra . Command ) { cmd . Hidden = false for _ , subcmd := range cmd . Commands ( ) { unhide ( subcmd ) } } unhide ( rootCmd ) return rootCmd . GenBashCompletion ( dest ) } ) , } completion . Flags ( ) . BoolVar ( & install , " " , false , " " ) completion . Flags ( ) . StringVar ( & path , " " , " " , " " ) subcommands = append ( subcommands , cmdutil . CreateAlias ( completion , " " ) ) subcommands = append ( subcommands , cmdutil . CreateAlias ( deleteDocs , " " ) ) createDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( createDocs , " " ) ) updateDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( updateDocs , " " ) ) inspectDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( inspectDocs , " " ) ) listDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( listDocs , " " ) ) startDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( startDocs , " " ) ) finishDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( finishDocs , " " ) ) flushDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( flushDocs , " " ) ) subscribeDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( subscribeDocs , " " ) ) putDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( putDocs , " " ) ) copyDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( copyDocs , " " ) ) getDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( getDocs , " " ) ) globDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( globDocs , " " ) ) diffDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( diffDocs , " " ) ) stopDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( stopDocs , " " ) ) restartDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( restartDocs , " " ) ) editDocs := & cobra . Command { Short : " " , Long : " " , } subcommands = append ( subcommands , cmdutil . CreateAlias ( editDocs , " " ) ) subcommands = append ( subcommands , pfscmds . Cmds ( & noMetrics , & noPortForwarding ) ... ) subcommands = append ( subcommands , ppscmds . Cmds ( & noMetrics , & noPortForwarding ) ... ) subcommands = append ( subcommands , deploycmds . Cmds ( & noMetrics , & noPortForwarding ) ... ) subcommands = append ( subcommands , authcmds . Cmds ( & noMetrics , & noPortForwarding ) ... ) subcommands = append ( subcommands , enterprisecmds . Cmds ( & noMetrics , & noPortForwarding ) ... ) subcommands = append ( subcommands , admincmds . Cmds ( & noMetrics , & noPortForwarding ) ... ) subcommands = append ( subcommands , debugcmds . Cmds ( & noMetrics , & noPortForwarding ) ... ) cmdutil . MergeCommands ( rootCmd , subcommands ) applyRootUsageFunc ( rootCmd ) applyCommandCompat1_8 ( rootCmd , & noMetrics , & noPortForwarding ) return rootCmd } 
func ( b * backend ) Renew ( ctx context . Context , req * logical . Request , d * framework . FieldData ) ( resp * logical . Response , retErr error ) { defer func ( ) { b . Logger ( ) . Debug ( fmt . Sprintf ( " " , req . Operation , req . Path , retErr == nil && ! resp . IsError ( ) ) ) } ( ) if ! ok { return nil , fmt . Errorf ( " " ) } userToken , ok := tokenIface . ( string ) if ! ok { return nil , fmt . Errorf ( " " , tokenIface ) } if err != nil { return nil , err } if len ( config . AdminToken ) == 0 { return nil , errors . New ( " " ) } if len ( config . PachdAddress ) == 0 { return nil , errors . New ( " " ) } if ttl == 0 { ttl , maxTTL , err = b . SanitizeTTLStr ( config . TTL , maxTTL . String ( ) ) if err != nil { return nil , fmt . Errorf ( " " , err ) } } if err != nil { return nil , err } } 
func renewUserCredentials ( ctx context . Context , pachdAddress string , adminToken string , userToken string , ttl time . Duration ) error { if err != nil { return err } defer client . Close ( ) client = client . WithCtx ( ctx ) client . SetAuthToken ( adminToken ) _ , err = client . AuthAPIClient . ExtendAuthToken ( client . Ctx ( ) , & auth . ExtendAuthTokenRequest { Token : userToken , TTL : int64 ( ttl . Seconds ( ) ) , } ) if err != nil { return err } return nil } 
func NewLocalClient ( root string ) ( Client , error ) { if err := os . MkdirAll ( root , 0755 ) ; err != nil { return nil , err } return & localClient { root } , nil } 
func AddSpanToAnyExisting ( ctx context . Context , operation string , kvs ... interface { } ) ( opentracing . Span , context . Context ) { if parentSpan := opentracing . SpanFromContext ( ctx ) ; parentSpan != nil { span := opentracing . StartSpan ( operation , opentracing . ChildOf ( parentSpan . Context ( ) ) ) tagSpan ( span , kvs ) return span , opentracing . ContextWithSpan ( ctx , span ) } return nil , ctx } 
func InstallJaegerTracerFromEnv ( ) { jaegerOnce . Do ( func ( ) { jaegerEndpoint , onUserMachine := os . LookupEnv ( jaegerEndpointEnvVar ) if ! onUserMachine { if host , ok := os . LookupEnv ( " " ) ; ok { port := os . Getenv ( " " ) jaegerEndpoint = fmt . Sprintf ( " " , host , port ) } } if jaegerEndpoint == " " { return } jaegerEndpoint = strings . TrimSuffix ( jaegerEndpoint , " " ) jaegerEndpoint = fmt . Sprintf ( " " , jaegerEndpoint ) cfg := jaegercfg . Configuration { if ! onUserMachine { logger = jaeger . StdLogger } if err != nil { panic ( fmt . Sprintf ( " " , err ) ) } opentracing . SetGlobalTracer ( tracer ) } ) } 
func UnaryClientInterceptor ( ) grpc . UnaryClientInterceptor { return otgrpc . OpenTracingClientInterceptor ( opentracing . GlobalTracer ( ) , otgrpc . IncludingSpans ( addTraceIfTracingEnabled ) ) } 
func StreamClientInterceptor ( ) grpc . StreamClientInterceptor { return otgrpc . OpenTracingStreamClientInterceptor ( opentracing . GlobalTracer ( ) , otgrpc . IncludingSpans ( addTraceIfTracingEnabled ) ) } 
func UnaryServerInterceptor ( ) grpc . UnaryServerInterceptor { return otgrpc . OpenTracingServerInterceptor ( opentracing . GlobalTracer ( ) , otgrpc . IncludingSpans ( addTraceIfTracingEnabled ) ) } 
func StreamServerInterceptor ( ) grpc . StreamServerInterceptor { return otgrpc . OpenTracingStreamServerInterceptor ( opentracing . GlobalTracer ( ) , otgrpc . IncludingSpans ( addTraceIfTracingEnabled ) ) } 
func CloseAndReportTraces ( ) { if c , ok := opentracing . GlobalTracer ( ) . ( io . Closer ) ; ok { c . Close ( ) } } 
func newWriter ( ctx context . Context , objC obj . Client , prefix string ) * Writer { hash . Write ( make ( [ ] byte , WindowSize ) ) return & Writer { ctx : ctx , objC : objC , prefix : prefix , cbs : [ ] func ( [ ] * DataRef ) error { } , buf : & bytes . Buffer { } , hash : hash , splitMask : ( 1 << uint64 ( AverageBits ) ) - 1 , } } 
func ( w * Writer ) RangeStart ( cb func ( [ ] * DataRef ) error ) { } w . dataRefs = [ ] * DataRef { & DataRef { OffsetBytes : int64 ( w . buf . Len ( ) ) } } w . rangeSize = 0 w . rangeCount ++ } 
func ( w * Writer ) Write ( data [ ] byte ) ( int , error ) { offset := 0 size := w . buf . Len ( ) for i , b := range data { size ++ w . hash . Roll ( b ) if w . hash . Sum64 ( ) & w . splitMask == 0 { w . buf . Write ( data [ offset : i + 1 ] ) if err := w . put ( ) ; err != nil { return 0 , err } w . buf . Reset ( ) offset = i + 1 size = 0 } } w . buf . Write ( data [ offset : ] ) w . rangeSize += int64 ( len ( data ) ) return len ( data ) , nil } 
func identifyUser ( client * analytics . Client , userID string ) { err := client . Identify ( & analytics . Identify { UserId : userID , } ) if err != nil { log . Errorf ( " " , err . Error ( ) ) } } 
func ( b * ConstantBackOff ) GetElapsedTime ( ) time . Duration { return time . Now ( ) . Sub ( b . startTime ) } 
func ( b * ConstantBackOff ) NextBackOff ( ) time . Duration { if b . MaxElapsedTime != 0 && b . GetElapsedTime ( ) > b . MaxElapsedTime { return Stop } return b . Interval } 
func ( b * ConstantBackOff ) For ( maxElapsed time . Duration ) * ConstantBackOff { b . MaxElapsedTime = maxElapsed return b } 
func ( l * logger ) Log ( request interface { } , response interface { } , err error , duration time . Duration ) { if err != nil { l . LogAtLevelFromDepth ( request , response , err , duration , logrus . ErrorLevel , 4 ) } else { l . LogAtLevelFromDepth ( request , response , err , duration , logrus . InfoLevel , 4 ) } } 
func ( f FormatterFunc ) Format ( entry * logrus . Entry ) ( [ ] byte , error ) { return f ( entry ) } 
func Pretty ( entry * logrus . Entry ) ( [ ] byte , error ) { serialized := [ ] byte ( fmt . Sprintf ( " " , entry . Time . Format ( logrus . DefaultTimestampFormat ) , strings . ToUpper ( entry . Level . String ( ) ) , ) , ) if entry . Data [ " " ] != nil { serialized = append ( serialized , [ ] byte ( fmt . Sprintf ( " " , entry . Data [ " " ] , entry . Data [ " " ] ) ) ... ) } if len ( entry . Data ) > 2 { delete ( entry . Data , " " ) delete ( entry . Data , " " ) if entry . Data [ " " ] != nil { entry . Data [ " " ] = entry . Data [ " " ] . ( time . Duration ) . Seconds ( ) } data , err := json . Marshal ( entry . Data ) if err != nil { return nil , fmt . Errorf ( " " , err ) } serialized = append ( serialized , [ ] byte ( string ( data ) ) ... ) serialized = append ( serialized , ' ' ) } serialized = append ( serialized , [ ] byte ( entry . Message ) ... ) serialized = append ( serialized , '\n' ) return serialized , nil } 
func NewGRPCLogWriter ( logger * logrus . Logger , source string ) * GRPCLogWriter { return & GRPCLogWriter { logger : logger , source : source , } } 
func ( l * GRPCLogWriter ) Write ( p [ ] byte ) ( int , error ) { parts := strings . SplitN ( string ( p ) , " " , 4 ) entry := l . logger . WithField ( " " , l . source ) if len ( parts ) == 4 { message := strings . TrimSpace ( parts [ 3 ] ) if level == " " { entry . Info ( message ) } else if level == " " { entry . Error ( message ) } else if level == " " { entry . Warning ( message ) } else if level == " " { } else { entry . Error ( message ) entry . Error ( " " , level ) } } else { entry . Error ( p ) entry . Error ( " " ) } return len ( p ) , nil } 
func Read ( ) ( * Config , error ) { var c * Config if raw , err := ioutil . ReadFile ( p ) ; err == nil { err = json . Unmarshal ( raw , & c ) if err != nil { return nil , err } } else if os . IsNotExist ( err ) { c = & Config { } } else { return nil , fmt . Errorf ( " " , p , err ) } if c . UserID == " " { fmt . Printf ( " " + " \n " , p ) uuid , err := uuid . NewV4 ( ) if err != nil { return nil , err } c . UserID = uuid . String ( ) if err := c . Write ( ) ; err != nil { return nil , err } } return c , nil } 
func ( c * Config ) Write ( ) error { rawConfig , err := json . MarshalIndent ( c , " " , " " ) if err != nil { return err } if _ , ok := os . LookupEnv ( configEnvVar ) ; ok { if _ , err := os . Stat ( d ) ; err != nil { return fmt . Errorf ( " " , p , err ) } } else { if err != nil { return err } } return ioutil . WriteFile ( p , rawConfig , 0644 ) } 
func ( r * readWriter ) Read ( val proto . Message ) error { buf , err := r . ReadBytes ( ) if err != nil { return err } return proto . Unmarshal ( buf , val ) } 
func ( r * readWriter ) Write ( val proto . Message ) ( int64 , error ) { bytes , err := proto . Marshal ( val ) if err != nil { return 0 , err } return r . WriteBytes ( bytes ) } 
func NewReadWriter ( rw io . ReadWriter ) ReadWriter { return & readWriter { r : rw , w : rw } } 
func Cmds ( noMetrics * bool , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command var noObjects bool var url string extract := & cobra . Command { Short : " " , Long : " " , Example : ` # Extract into a local file: $ {{alias}} > backup # Extract to s3: $ {{alias}} -u s3: if err != nil { return err } defer c . Close ( ) if url != " " { return c . ExtractURL ( url ) } w := snappy . NewBufferedWriter ( os . Stdout ) defer func ( ) { if err := w . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return c . ExtractWriter ( ! noObjects , w ) } ) , } extract . Flags ( ) . BoolVar ( & noObjects , " " , false , " " ) extract . Flags ( ) . StringVarP ( & url , " " , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( extract , " " ) ) restore := & cobra . Command { Short : " " , Long : " " , Example : ` # Restore from a local file: $ {{alias}} < backup # Restore from s3: $ {{alias}} -u s3: if err != nil { return err } defer c . Close ( ) if url != " " { err = c . RestoreURL ( url ) } else { err = c . RestoreReader ( snappy . NewReader ( os . Stdin ) ) } if err != nil { return fmt . Errorf ( " \n " + " " , err ) } return nil } ) , } restore . Flags ( ) . StringVarP ( & url , " " , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( restore , " " ) ) inspectCluster := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) ci , err := c . InspectCluster ( ) if err != nil { return err } fmt . Println ( ci . ID ) return nil } ) , } commands = append ( commands , cmdutil . CreateAlias ( inspectCluster , " " ) ) return commands } 
func RunGitHookServer ( address string , etcdAddress string , etcdPrefix string ) error { c , err := client . NewFromAddress ( address ) if err != nil { return err } etcdClient , err := etcd . New ( etcd . Config { Endpoints : [ ] string { etcdAddress } , DialOptions : client . DefaultDialOptions ( ) , } ) if err != nil { return err } hook , err := github . New ( ) if err != nil { return err } s := & gitHookServer { hook , c , etcdClient , ppsdb . Pipelines ( etcdClient , etcdPrefix ) , } return http . ListenAndServe ( fmt . Sprintf ( " " , GitHookPort ) , s ) } 
func newLoggingPipe ( ) * loggingPipe { p := & loggingPipe { } p . clientReader , p . clientWriter = io . Pipe ( ) p . clientReader = io . TeeReader ( p . clientReader , & p . ServerToClientBuf ) p . serverReader , p . serverWriter = io . Pipe ( ) p . serverReader = io . TeeReader ( p . serverReader , & p . ClientToServerBuf ) return p } 
func ( p * loggingPipe ) Close ( ) error { p . clientWriter . Close ( ) p . serverWriter . Close ( ) return nil } 
func ( p * loggingPipe ) clientConn ( ) * loggingConn { return & loggingConn { pipe : p , r : p . clientReader , w : p . serverWriter , } } 
func ( p * loggingPipe ) serverConn ( ) * loggingConn { return & loggingConn { pipe : p , r : p . serverReader , w : p . clientWriter , } } 
func ( l * loggingConn ) Read ( b [ ] byte ) ( n int , err error ) { return l . r . Read ( b ) } 
func ( l * loggingConn ) Write ( b [ ] byte ) ( n int , err error ) { return l . w . Write ( b ) } 
func ( l * TestListener ) Dial ( context . Context , string , string ) ( net . Conn , error ) { l . connMu . Lock ( ) defer l . connMu . Unlock ( ) if l . conn != nil { return nil , errors . New ( " " ) } l . conn = p . serverConn ( ) close ( l . connCh ) return p . clientConn ( ) , nil } 
func ( l * TestListener ) Accept ( ) ( net . Conn , error ) { conn := <- l . connCh if conn == nil { return nil , errors . New ( " " ) } return conn , nil } 
func ( l * TestListener ) Close ( ) error { l . connMu . Lock ( ) defer l . connMu . Unlock ( ) c := <- l . connCh if c != nil { close ( l . connCh ) } return nil } 
func Server ( pc * client . APIClient , port uint16 ) * http . Server { router := mux . NewRouter ( ) router . Handle ( `/` , newRootHandler ( pc ) ) . Methods ( " " , " " ) trailingSlashBucketRouter := router . Path ( `/{branch:[a-zA-Z0-9\-_]{1,255}}.{repo:[a-zA-Z0-9\-_]{1,255}}/` ) . Subrouter ( ) attachBucketRoutes ( trailingSlashBucketRouter , bucketHandler ) bucketRouter := router . Path ( `/{branch:[a-zA-Z0-9\-_]{1,255}}.{repo:[a-zA-Z0-9\-_]{1,255}}` ) . Subrouter ( ) attachBucketRoutes ( bucketRouter , bucketHandler ) objectRouter . Methods ( " " , " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " , " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " , " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " , " " , " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Headers ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " , " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectRouter . Methods ( " " ) . Queries ( " " , " " ) . HandlerFunc ( notImplementedError ) objectHandler := newObjectHandler ( pc ) objectRouter . Methods ( " " , " " ) . HandlerFunc ( objectHandler . get ) objectRouter . Methods ( " " ) . HandlerFunc ( objectHandler . put ) objectRouter . Methods ( " " ) . HandlerFunc ( objectHandler . del ) router . MethodNotAllowedHandler = http . HandlerFunc ( methodNotAllowedError ) router . NotFoundHandler = http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { requestLogger ( r ) . Infof ( " " , r . URL . Path ) if bucketNameValidator . MatchString ( r . URL . Path ) { noSuchKeyError ( w , r ) } else { invalidBucketNameError ( w , r ) } } ) var lastEnterpriseCheck time . Time isEnterprise := false return & http . Server { Addr : fmt . Sprintf ( " " , port ) , Handler : http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { if requestID == " " { requestID = uuid . NewWithoutDashes ( ) r . Header . Set ( " " , requestID ) } w . Header ( ) . Set ( " " , requestID ) if ! isEnterprise || now . Sub ( lastEnterpriseCheck ) > enterpriseTimeout { resp , err := pc . Enterprise . GetState ( context . Background ( ) , & enterpriseclient . GetStateRequest { } ) if err != nil { err = fmt . Errorf ( " " , grpcutil . ScrubGRPC ( err ) ) internalError ( w , r , err ) return } isEnterprise = resp . State == enterpriseclient . State_ACTIVE } if ! isEnterprise { enterpriseDisabledError ( w , r ) return } router . ServeHTTP ( w , r ) } ) , ErrorLog : stdlog . New ( serverErrorLog , " " , 0 ) , } } 
func Code ( err error ) ErrCode { if err == nil { return OK } hte , ok := err . ( * hashTreeError ) if ! ok { return Unknown } return hte . code } 
func errorf ( c ErrCode , fmtStr string , args ... interface { } ) error { return & hashTreeError { code : c , s : fmt . Sprintf ( fmtStr , args ... ) , } } 
func InitPachOnlyEnv ( config * Configuration ) * ServiceEnv { env := & ServiceEnv { Configuration : config } env . pachAddress = net . JoinHostPort ( " " , fmt . Sprintf ( " " , env . PeerPort ) ) env . pachEg . Go ( env . initPachClient ) return env } 
func InitServiceEnv ( config * Configuration ) * ServiceEnv { env := InitPachOnlyEnv ( config ) env . etcdAddress = fmt . Sprintf ( " " , net . JoinHostPort ( env . EtcdHost , env . EtcdPort ) ) env . etcdEg . Go ( env . initEtcdClient ) return env } 
func InitWithKube ( config * Configuration ) * ServiceEnv { env := InitServiceEnv ( config ) env . kubeEg . Go ( env . initKubeClient ) return env } 
func ( env * ServiceEnv ) GetPachClient ( ctx context . Context ) * client . APIClient { if err := env . pachEg . Wait ( ) ; err != nil { panic ( err ) } return env . pachClient . WithCtx ( ctx ) } 
func ( env * ServiceEnv ) GetEtcdClient ( ) * etcd . Client { if err := env . etcdEg . Wait ( ) ; err != nil { panic ( err ) } if env . etcdClient == nil { panic ( " " ) } return env . etcdClient } 
func ( env * ServiceEnv ) GetKubeClient ( ) * kube . Clientset { if err := env . kubeEg . Wait ( ) ; err != nil { panic ( err ) } if env . kubeClient == nil { panic ( " " ) } return env . kubeClient } 
func NewHasher ( jobModulus uint64 , pipelineModulus uint64 ) * Hasher { return & Hasher { JobModulus : jobModulus , PipelineModulus : pipelineModulus , } } 
func ( s * Hasher ) HashJob ( jobID string ) uint64 { return uint64 ( adler32 . Checksum ( [ ] byte ( jobID ) ) ) % s . JobModulus } 
func ( s * Hasher ) HashPipeline ( pipelineName string ) uint64 { return uint64 ( adler32 . Checksum ( [ ] byte ( pipelineName ) ) ) % s . PipelineModulus } 
func Status ( ctx context . Context , pipelineRcName string , etcdClient * etcd . Client , etcdPrefix string , workerGrpcPort uint16 ) ( [ ] * pps . WorkerStatus , error ) { workerClients , err := Clients ( ctx , pipelineRcName , etcdClient , etcdPrefix , workerGrpcPort ) if err != nil { return nil , err } var result [ ] * pps . WorkerStatus for _ , workerClient := range workerClients { status , err := workerClient . Status ( ctx , & types . Empty { } ) if err != nil { return nil , err } result = append ( result , status ) } return result , nil } 
func Cancel ( ctx context . Context , pipelineRcName string , etcdClient * etcd . Client , etcdPrefix string , workerGrpcPort uint16 , jobID string , dataFilter [ ] string ) error { workerClients , err := Clients ( ctx , pipelineRcName , etcdClient , etcdPrefix , workerGrpcPort ) if err != nil { return err } success := false for _ , workerClient := range workerClients { resp , err := workerClient . Cancel ( ctx , & CancelRequest { JobID : jobID , DataFilters : dataFilter , } ) if err != nil { return err } if resp . Success { success = true } } if ! success { return fmt . Errorf ( " " , dataFilter , jobID ) } return nil } 
func Conns ( ctx context . Context , pipelineRcName string , etcdClient * etcd . Client , etcdPrefix string , workerGrpcPort uint16 ) ( [ ] * grpc . ClientConn , error ) { resp , err := etcdClient . Get ( ctx , path . Join ( etcdPrefix , WorkerEtcdPrefix , pipelineRcName ) , etcd . WithPrefix ( ) ) if err != nil { return nil , err } var result [ ] * grpc . ClientConn for _ , kv := range resp . Kvs { conn , err := grpc . Dial ( fmt . Sprintf ( " " , path . Base ( string ( kv . Key ) ) , workerGrpcPort ) , append ( client . DefaultDialOptions ( ) , grpc . WithInsecure ( ) ) ... ) if err != nil { return nil , err } result = append ( result , conn ) } return result , nil } 
func Clients ( ctx context . Context , pipelineRcName string , etcdClient * etcd . Client , etcdPrefix string , workerGrpcPort uint16 ) ( [ ] Client , error ) { conns , err := Conns ( ctx , pipelineRcName , etcdClient , etcdPrefix , workerGrpcPort ) if err != nil { return nil , err } var result [ ] Client for _ , conn := range conns { result = append ( result , newClient ( conn ) ) } return result , nil } 
func NewClient ( address string ) ( Client , error ) { port , err := strconv . Atoi ( os . Getenv ( client . PPSWorkerPortEnv ) ) if err != nil { return Client { } , err } conn , err := grpc . Dial ( fmt . Sprintf ( " " , address , port ) , append ( client . DefaultDialOptions ( ) , grpc . WithInsecure ( ) ) ... ) if err != nil { return Client { } , err } return newClient ( conn ) , nil } 
func ScrubGRPC ( err error ) error { if err == nil { return nil } if s , ok := status . FromError ( err ) ; ok { return errors . New ( s . Message ( ) ) } return err } 
func RunFixedArgs ( numArgs int , run func ( [ ] string ) error ) func ( * cobra . Command , [ ] string ) { return func ( cmd * cobra . Command , args [ ] string ) { if len ( args ) != numArgs { fmt . Printf ( " \n \n " , numArgs , len ( args ) ) cmd . Usage ( ) } else { if err := run ( args ) ; err != nil { ErrorAndExit ( " " , err ) } } } } 
func RunBoundedArgs ( min int , max int , run func ( [ ] string ) error ) func ( * cobra . Command , [ ] string ) { return func ( cmd * cobra . Command , args [ ] string ) { if len ( args ) < min || len ( args ) > max { fmt . Printf ( " \n \n " , min , max , len ( args ) ) cmd . Usage ( ) } else { if err := run ( args ) ; err != nil { ErrorAndExit ( " " , err ) } } } } 
func Run ( run func ( args [ ] string ) error ) func ( * cobra . Command , [ ] string ) { return func ( _ * cobra . Command , args [ ] string ) { if err := run ( args ) ; err != nil { ErrorAndExit ( err . Error ( ) ) } } } 
func ErrorAndExit ( format string , args ... interface { } ) { if errString := strings . TrimSpace ( fmt . Sprintf ( format , args ... ) ) ; errString != " " { fmt . Fprintf ( os . Stderr , " \n " , errString ) } os . Exit ( 1 ) } 
func ParseCommit ( arg string ) ( * pfs . Commit , error ) { parts := strings . SplitN ( arg , " " , 2 ) if parts [ 0 ] == " " { return nil , fmt . Errorf ( " \" \" " , arg ) } commit := & pfs . Commit { Repo : & pfs . Repo { Name : parts [ 0 ] , } , ID : " " , } if len ( parts ) == 2 { commit . ID = parts [ 1 ] } return commit , nil } 
func ParseCommits ( args [ ] string ) ( [ ] * pfs . Commit , error ) { var results [ ] * pfs . Commit for _ , arg := range args { commit , err := ParseCommit ( arg ) if err != nil { return nil , err } results = append ( results , commit ) } return results , nil } 
func ParseBranch ( arg string ) ( * pfs . Branch , error ) { commit , err := ParseCommit ( arg ) if err != nil { return nil , err } return & pfs . Branch { Repo : commit . Repo , Name : commit . ID } , nil } 
func ParseBranches ( args [ ] string ) ( [ ] * pfs . Branch , error ) { var results [ ] * pfs . Branch for _ , arg := range args { branch , err := ParseBranch ( arg ) if err != nil { return nil , err } results = append ( results , branch ) } return results , nil } 
func ParseFile ( arg string ) ( * pfs . File , error ) { repoAndRest := strings . SplitN ( arg , " " , 2 ) if repoAndRest [ 0 ] == " " { return nil , fmt . Errorf ( " \" \" " , arg ) } file := & pfs . File { Commit : & pfs . Commit { Repo : & pfs . Repo { Name : repoAndRest [ 0 ] , } , ID : " " , } , Path : " " , } if len ( repoAndRest ) > 1 { commitAndPath := strings . SplitN ( repoAndRest [ 1 ] , " " , 2 ) if commitAndPath [ 0 ] == " " { return nil , fmt . Errorf ( " \" \" " , arg ) } file . Commit . ID = commitAndPath [ 0 ] if len ( commitAndPath ) > 1 { file . Path = commitAndPath [ 1 ] } } return file , nil } 
func ParseFiles ( args [ ] string ) ( [ ] * pfs . File , error ) { var results [ ] * pfs . File for _ , arg := range args { commit , err := ParseFile ( arg ) if err != nil { return nil , err } results = append ( results , commit ) } return results , nil } 
func ( r * RepeatedStringArg ) Set ( s string ) error { * r = append ( * r , s ) return nil } 
func CreateAlias ( cmd * cobra . Command , invocation string ) * cobra . Command { args := strings . Split ( invocation , " " ) for i , arg := range args { cur := & cobra . Command { } if cmd . Use == " " { cur . Use = arg } else { cur . Use = strings . Replace ( cmd . Use , " " , arg , - 1 ) } cur . Example = strings . Replace ( cmd . Example , " " , fmt . Sprintf ( " " , os . Args [ 0 ] , invocation ) , - 1 ) } else { cur . Use = arg } if root == nil { root = cur } else if prev != nil { prev . AddCommand ( cur ) } prev = cur } return root } 
func MergeCommands ( root * cobra . Command , children [ ] * cobra . Command ) { } } return nil } depth = func ( cmd * cobra . Command ) int { maxDepth := 0 for _ , subcmd := range cmd . Commands ( ) { subcmdDepth := depth ( subcmd ) if subcmdDepth > maxDepth { maxDepth = subcmdDepth } } return maxDepth + 1 } sort . Slice ( children , func ( i , j int ) bool { return depth ( children [ i ] ) < depth ( children [ j ] ) } ) if parent == nil { root . AddCommand ( cmd ) } else { MergeCommands ( parent , cmd . Commands ( ) ) } } } 
func SetDocsUsage ( command * cobra . Command ) { command . SetHelpTemplate ( `{{or .Long .Short}} {{.UsageString}} ` ) command . SetUsageFunc ( func ( cmd * cobra . Command ) error { rootCmd := cmd . Root ( ) var walk func ( * cobra . Command ) walk = func ( cursor * cobra . Command ) { if cursor . Name ( ) == cmd . Name ( ) && cursor . CommandPath ( ) != cmd . CommandPath ( ) { associated = append ( associated , cursor ) } for _ , subcmd := range cursor . Commands ( ) { walk ( subcmd ) } } walk ( rootCmd ) var maxCommandPath int for _ , x := range associated { commandPathLen := len ( x . CommandPath ( ) ) if commandPathLen > maxCommandPath { maxCommandPath = commandPathLen } } templateFuncs := template . FuncMap { " " : func ( s string ) string { format := fmt . Sprintf ( " " , maxCommandPath + 1 ) return fmt . Sprintf ( format , s ) } , " " : func ( ) [ ] * cobra . Command { return associated } , } text := `Associated Commands:{{range associated}}{{if .IsAvailableCommand}} {{pad .CommandPath}} {{.Short}}{{end}}{{end}}` t := template . New ( " " ) t . Funcs ( templateFuncs ) template . Must ( t . Parse ( text ) ) return t . Execute ( cmd . Out ( ) , cmd ) } ) } 
func ( a * apiServer ) master ( ) { masterLock := dlock . NewDLock ( a . env . GetEtcdClient ( ) , path . Join ( a . etcdPrefix , masterLockPath ) ) backoff . RetryNotify ( func ( ) error { ctx , cancel := context . WithCancel ( context . Background ( ) ) defer cancel ( ) ctx , err := masterLock . Lock ( ctx ) if err != nil { return err } defer masterLock . Unlock ( ctx ) kubeClient := a . env . GetKubeClient ( ) log . Infof ( " " ) pipelineWatcher , err := a . pipelines . ReadOnly ( ctx ) . Watch ( watch . WithPrevKV ( ) ) if err != nil { return fmt . Errorf ( " " , err ) } defer pipelineWatcher . Close ( ) kubePipelineWatch , err := kubeClient . CoreV1 ( ) . Pods ( a . namespace ) . Watch ( metav1 . ListOptions { LabelSelector : metav1 . FormatLabelSelector ( metav1 . SetAsLabelSelector ( map [ string ] string { " " : " " , } ) ) , Watch : true , } ) if err != nil { log . Errorf ( " " , err ) } else { watchChan = kubePipelineWatch . ResultChan ( ) defer kubePipelineWatch . Stop ( ) } for { select { case event := <- pipelineWatcher . Watch ( ) : if event . Err != nil { return fmt . Errorf ( " " , event . Err ) } switch event . Type { case watch . EventPut : var pipelineName string var pipelinePtr pps . EtcdPipelineInfo if err := event . Unmarshal ( & pipelineName , & pipelinePtr ) ; err != nil { return err } var pipelineInfo , prevPipelineInfo * pps . PipelineInfo if err := a . sudo ( pachClient , func ( superUserClient * client . APIClient ) error { var err error pipelineInfo , err = ppsutil . GetPipelineInfo ( superUserClient , & pipelinePtr , true ) if err != nil { return err } if event . PrevKey != nil { if err := event . UnmarshalPrev ( & pipelineName , & prevPipelinePtr ) ; err != nil { return err } prevPipelineInfo , err = ppsutil . GetPipelineInfo ( superUserClient , & prevPipelinePtr , true ) if err != nil { return err } } return nil } ) ; err != nil { return fmt . Errorf ( " " , err ) } if err := a . deleteWorkersForPipeline ( pipelineName ) ; err != nil { return err } if err := a . setPipelineState ( pachClient , pipelineInfo , pps . PipelineState_PIPELINE_PAUSED , " " ) ; err != nil { return err } } var hasGitInput bool pps . VisitInput ( pipelineInfo . Input , func ( input * pps . Input ) { if input . Git != nil { hasGitInput = true } } ) if prevPipelinePtr . SpecCommit != nil { prevSpecCommit = prevPipelinePtr . SpecCommit . ID } return pipelinePtr . SpecCommit . ID != prevSpecCommit && ! pipelineInfo . Stopped } ( ) if pipelineRestarted || authActivationChanged || pipelineUpserted { if ( pipelineUpserted || authActivationChanged ) && event . PrevKey != nil { if err := a . deleteWorkersForPipeline ( prevPipelineInfo . Pipeline . Name ) ; err != nil { return err } } if ( pipelineUpserted || pipelineRestarted ) && hasGitInput { if err := a . checkOrDeployGithookService ( ) ; err != nil { return err } } log . Infof ( " " , pipelineName ) if err := a . upsertWorkersForPipeline ( pipelineInfo ) ; err != nil { if err := a . setPipelineState ( pachClient , pipelineInfo , pps . PipelineState_PIPELINE_STARTING , fmt . Sprintf ( " " , err . Error ( ) ) ) ; err != nil { return err } } } if pipelineInfo . State == pps . PipelineState_PIPELINE_RUNNING { if err := a . scaleUpWorkersForPipeline ( pipelineInfo ) ; err != nil { return err } } if pipelineInfo . State == pps . PipelineState_PIPELINE_STANDBY { if err := a . scaleDownWorkersForPipeline ( pipelineInfo ) ; err != nil { return err } } } case event := <- watchChan : } kubePipelineWatch , err = kubeClient . CoreV1 ( ) . Pods ( a . namespace ) . Watch ( metav1 . ListOptions { LabelSelector : metav1 . FormatLabelSelector ( metav1 . SetAsLabelSelector ( map [ string ] string { " " : " " , } ) ) , Watch : true , } ) if err != nil { log . Errorf ( " " , err ) watchChan = nil } else { watchChan = kubePipelineWatch . ResultChan ( ) defer kubePipelineWatch . Stop ( ) } } pod , ok := event . Object . ( * v1 . Pod ) if ! ok { continue } if pod . Status . Phase == v1 . PodFailed { log . Errorf ( " " , pod . Status . Message ) } for _ , status := range pod . Status . ContainerStatuses { if status . Name == " " && status . State . Waiting != nil && failures [ status . State . Waiting . Reason ] { if err := a . setPipelineFailure ( ctx , pod . ObjectMeta . Annotations [ " " ] , status . State . Waiting . Message ) ; err != nil { return err } } } } } } , backoff . NewInfiniteBackOff ( ) , func ( err error , d time . Duration ) error { for _ , c := range a . monitorCancels { c ( ) } a . monitorCancels = make ( map [ string ] func ( ) ) log . Errorf ( " " , err , d ) return nil } ) } 
func ( a * apiServer ) makeCronCommits ( pachClient * client . APIClient , in * pps . Input ) error { schedule , err := cron . ParseStandard ( in . Cron . Spec ) if err != nil { return err } if err != nil && ! isNilBranchErr ( err ) { return err } else if commitInfo != nil && commitInfo . Finished == nil { } } var latestTime time . Time files , err := pachClient . ListFile ( in . Cron . Repo , " " , " " ) if err != nil && ! isNilBranchErr ( err ) { return err } else if err != nil || len ( files ) == 0 { if err != nil { return err } } else { if err != nil { return err } } for { if err != nil { return err } if err != nil { return err } if in . Cron . Overwrite { if err != nil && ! isNotFoundErr ( err ) && ! isNilBranchErr ( err ) { return fmt . Errorf ( " " , err ) } } if err != nil { return fmt . Errorf ( " " , err ) } err = pachClient . FinishCommit ( in . Cron . Repo , " " ) if err != nil { return err } } } 
func ( o * tracingObjClient ) Writer ( ctx context . Context , name string ) ( io . WriteCloser , error ) { span , ctx := tracing . AddSpanToAnyExisting ( ctx , o . provider + " " , " " , name ) if span != nil { defer span . Finish ( ) } return o . Client . Writer ( ctx , name ) } 
func ( o * tracingObjClient ) Reader ( ctx context . Context , name string , offset uint64 , size uint64 ) ( io . ReadCloser , error ) { span , ctx := tracing . AddSpanToAnyExisting ( ctx , o . provider + " " , " " , name , " " , fmt . Sprintf ( " " , offset ) , " " , fmt . Sprintf ( " " , size ) ) defer tracing . FinishAnySpan ( span ) return o . Client . Reader ( ctx , name , offset , size ) } 
func ( o * tracingObjClient ) Delete ( ctx context . Context , name string ) error { span , ctx := tracing . AddSpanToAnyExisting ( ctx , o . provider + " " , " " , name ) defer tracing . FinishAnySpan ( span ) return o . Client . Delete ( ctx , name ) } 
func ( o * tracingObjClient ) Walk ( ctx context . Context , prefix string , fn func ( name string ) error ) error { span , ctx := tracing . AddSpanToAnyExisting ( ctx , o . provider + " " , " " , prefix ) defer tracing . FinishAnySpan ( span ) return o . Client . Walk ( ctx , prefix , fn ) } 
func ( o * tracingObjClient ) Exists ( ctx context . Context , name string ) bool { span , ctx := tracing . AddSpanToAnyExisting ( ctx , o . provider + " " , " " , name ) defer tracing . FinishAnySpan ( span ) return o . Client . Exists ( ctx , name ) } 
func ( c * Commit ) FullID ( ) string { return fmt . Sprintf ( " " , c . Repo . Name , c . ID ) } 
func GetBlock ( hash hash . Hash ) * Block { return & Block { Hash : base64 . URLEncoding . EncodeToString ( hash . Sum ( nil ) ) , } } 
func ( h * healthServer ) Health ( context . Context , * types . Empty ) ( * types . Empty , error ) { if ! h . ready { return nil , fmt . Errorf ( " " ) } return & types . Empty { } , nil } 
func clean ( p string ) string { if ! strings . HasPrefix ( p , " " ) { p = " " + p } return internalDefault ( path . Clean ( p ) ) } 
func split ( p string ) ( string , string ) { return clean ( path . Dir ( p ) ) , base ( p ) } 
func ValidatePath ( path string ) error { path = clean ( path ) match , _ := regexp . MatchString ( " " , path ) if ! match { return fmt . Errorf ( " " , path ) } if IsGlob ( path ) { return fmt . Errorf ( " " , path , globRegex . FindString ( path ) ) } return nil } 
func MatchDatum ( filter [ ] string , data [ ] * pps . InputFile ) bool { dataFilters : for _ , dataFilter := range filter { for _ , datum := range data { if dataFilter == datum . Path || dataFilter == base64 . StdEncoding . EncodeToString ( datum . Hash ) || dataFilter == hex . EncodeToString ( datum . Hash ) { continue dataFilters } } matchesData = false break } return matchesData } 
func NewCacheServer ( router shard . Router , shards uint64 ) CacheServer { server := & groupCacheServer { Logger : log . NewLogger ( " " ) , router : router , localShards : make ( map [ uint64 ] bool ) , shards : shards , } groupcache . RegisterPeerPicker ( func ( ) groupcache . PeerPicker { return server } ) return server } 
func ( a * apiServer ) authorizePipelineOp ( pachClient * client . APIClient , operation pipelineOperation , input * pps . Input , output string ) error { ctx := pachClient . Ctx ( ) me , err := pachClient . WhoAmI ( ctx , & auth . WhoAmIRequest { } ) if auth . IsErrNotActivated ( err ) { return nil } else if err != nil { return err } if input != nil { done := make ( map [ string ] struct { } ) pps . VisitInput ( input , func ( in * pps . Input ) { var repo string if in . Pfs != nil { repo = in . Pfs . Repo } else { return } if _ , ok := done [ repo ] ; ok { return } done [ repo ] = struct { } { } eg . Go ( func ( ) error { resp , err := pachClient . Authorize ( ctx , & auth . AuthorizeRequest { Repo : repo , Scope : auth . Scope_READER , } ) if err != nil { return err } if ! resp . Authorized { return & auth . ErrNotAuthorized { Subject : me . Username , Repo : repo , Required : auth . Scope_READER , } } return nil } ) } ) if err := eg . Wait ( ) ; err != nil { return err } } switch operation { case pipelineOpCreate : if _ , err := pachClient . InspectRepo ( output ) ; err == nil { return fmt . Errorf ( " \" \" " , output ) } else if ! isNotFoundErr ( err ) { return err } case pipelineOpListDatum , pipelineOpGetLogs : required = auth . Scope_READER case pipelineOpUpdate : required = auth . Scope_WRITER case pipelineOpDelete : required = auth . Scope_OWNER default : return fmt . Errorf ( " " , operation ) } if required != auth . Scope_NONE { resp , err := pachClient . Authorize ( ctx , & auth . AuthorizeRequest { Repo : output , Scope : required , } ) if err != nil { return err } if ! resp . Authorized { return & auth . ErrNotAuthorized { Subject : me . Username , Repo : output , Required : required , } } } return nil } 
func ( a * apiServer ) listJob ( pachClient * client . APIClient , pipeline * pps . Pipeline , outputCommit * pfs . Commit , inputCommits [ ] * pfs . Commit , f func ( * pps . JobInfo ) error ) error { authIsActive := true me , err := pachClient . WhoAmI ( pachClient . Ctx ( ) , & auth . WhoAmIRequest { } ) if auth . IsErrNotActivated ( err ) { authIsActive = false } else if err != nil { return err } if authIsActive && pipeline != nil { if err != nil { return err } if ! resp . Authorized { return & auth . ErrNotAuthorized { Subject : me . Username , Repo : pipeline . Name , Required : auth . Scope_READER , } } } if outputCommit != nil { outputCommit , err = a . resolveCommit ( pachClient , outputCommit ) if err != nil { return err } } for i , inputCommit := range inputCommits { inputCommits [ i ] , err = a . resolveCommit ( pachClient , inputCommit ) if err != nil { return err } } jobs := a . jobs . ReadOnly ( pachClient . Ctx ( ) ) jobPtr := & pps . EtcdJobInfo { } _f := func ( key string ) error { jobInfo , err := a . jobInfoFromPtr ( pachClient , jobPtr , len ( inputCommits ) > 0 ) if err != nil { if isNotFoundErr ( err ) { } else if auth . IsErrNotAuthorized ( err ) { return nil } return err } if len ( inputCommits ) > 0 { found := make ( [ ] bool , len ( inputCommits ) ) pps . VisitInput ( jobInfo . Input , func ( in * pps . Input ) { if in . Pfs != nil { for i , inputCommit := range inputCommits { if in . Pfs . Commit == inputCommit . ID { found [ i ] = true } } } } ) for _ , found := range found { if ! found { return nil } } } return f ( jobInfo ) } if pipeline != nil { return jobs . GetByIndex ( ppsdb . JobsPipelineIndex , pipeline , jobPtr , col . DefaultOptions , _f ) } else if outputCommit != nil { return jobs . GetByIndex ( ppsdb . JobsOutputIndex , outputCommit , jobPtr , col . DefaultOptions , _f ) } else { return jobs . List ( jobPtr , col . DefaultOptions , _f ) } } 
func ( a * apiServer ) listDatum ( pachClient * client . APIClient , job * pps . Job , page , pageSize int64 ) ( response * pps . ListDatumResponse , retErr error ) { if err := checkLoggedIn ( pachClient ) ; err != nil { return nil , err } response = & pps . ListDatumResponse { } ctx := pachClient . Ctx ( ) pfsClient := pachClient . PfsAPIClient if err != nil { return nil , err } } } getPageBounds := func ( totalSize int ) ( int , int , error ) { start := int ( page * pageSize ) end := int ( ( page + 1 ) * pageSize ) switch { case totalSize <= start : return 0 , 0 , io . EOF case totalSize <= end : return start , totalSize , nil case end < totalSize : return start , end , nil } return 0 , 0 , goerr . New ( " " ) } df , err := workerpkg . NewDatumFactory ( pachClient , jobInfo . Input ) if err != nil { return nil , err } end := df . Len ( ) if pageSize > 0 { var err error start , end , err = getPageBounds ( df . Len ( ) ) if err != nil { return nil , err } response . Page = page response . TotalPages = getTotalPages ( df . Len ( ) ) } var datumInfos [ ] * pps . DatumInfo for i := start ; i < end ; i ++ { datum := df . Datum ( i ) id := workerpkg . HashDatum ( jobInfo . Pipeline . Name , jobInfo . Salt , datum ) datumInfo := & pps . DatumInfo { Datum : & pps . Datum { ID : id , Job : jobInfo . Job , } , State : pps . DatumState_STARTING , } for _ , input := range datum { datumInfo . Data = append ( datumInfo . Data , input . FileInfo ) } datumInfos = append ( datumInfos , datumInfo ) } response . DatumInfos = datumInfos return response , nil } var datumFileInfos [ ] * pfs . FileInfo fs , err := pfsClient . ListFileStream ( ctx , & pfs . ListFileRequest { File : file , Full : true } ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } pathToDatumHash := func ( path string ) ( string , error ) { _ , datumHash := filepath . Split ( path ) if _ , ok := blacklist [ datumHash ] ; ok { return " " , fmt . Errorf ( " " , datumHash ) } return datumHash , nil } for { f , err := fs . Recv ( ) if err == io . EOF { break } else if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } if _ , err := pathToDatumHash ( f . File . Path ) ; err != nil { } datumFileInfos = append ( datumFileInfos , f ) } var egGetDatums errgroup . Group limiter := limit . New ( 200 ) datumInfos := make ( [ ] * pps . DatumInfo , len ( datumFileInfos ) ) for index , fileInfo := range datumFileInfos { fileInfo := fileInfo index := index egGetDatums . Go ( func ( ) error { limiter . Acquire ( ) defer limiter . Release ( ) datumHash , err := pathToDatumHash ( fileInfo . File . Path ) if err != nil { } datum , err := a . getDatum ( pachClient , jobInfo . StatsCommit . Repo . Name , jobInfo . StatsCommit , job . ID , datumHash , df ) if err != nil { return err } datumInfos [ index ] = datum return nil } ) } if err = egGetDatums . Wait ( ) ; err != nil { return nil , err } } ) if pageSize > 0 { response . Page = page response . TotalPages = getTotalPages ( len ( datumInfos ) ) start , end , err := getPageBounds ( len ( datumInfos ) ) if err != nil { return nil , err } datumInfos = datumInfos [ start : end ] } response . DatumInfos = datumInfos return response , nil } 
func ( a * apiServer ) hardStopPipeline ( pachClient * client . APIClient , pipelineInfo * pps . PipelineInfo ) error { } if err != nil { return fmt . Errorf ( " " , pipelineInfo . OutputBranch , err ) } if err == io . EOF { break } else if err != nil { return err } if ci . Finished == nil { } } return nil } 
func ( a * apiServer ) sudo ( pachClient * client . APIClient , f func ( * client . APIClient ) error ) error { b . MaxElapsedTime = 60 * time . Second b . MaxInterval = 5 * time . Second if err := backoff . Retry ( func ( ) error { superUserTokenCol := col . NewCollection ( a . env . GetEtcdClient ( ) , ppsconsts . PPSTokenKey , nil , & types . StringValue { } , nil , nil ) . ReadOnly ( pachClient . Ctx ( ) ) var result types . StringValue if err := superUserTokenCol . Get ( " " , & result ) ; err != nil { return err } superUserToken = result . Value return nil } , b ) ; err != nil { panic ( fmt . Sprintf ( " " , err ) ) } } ) superUserClient . SetAuthToken ( superUserToken ) return f ( superUserClient ) } 
func ( a * apiServer ) makePipelineInfoCommit ( pachClient * client . APIClient , pipelineInfo * pps . PipelineInfo ) ( result * pfs . Commit , retErr error ) { pipelineName := pipelineInfo . Pipeline . Name var commit * pfs . Commit if err := a . sudo ( pachClient , func ( superUserClient * client . APIClient ) error { data , err := pipelineInfo . Marshal ( ) if err != nil { return fmt . Errorf ( " " , err ) } if _ , err = superUserClient . PutFileOverwrite ( ppsconsts . SpecRepo , pipelineName , ppsconsts . SpecFile , bytes . NewReader ( data ) , 0 ) ; err != nil { return err } branchInfo , err := superUserClient . InspectBranch ( ppsconsts . SpecRepo , pipelineName ) if err != nil { return err } commit = branchInfo . Head return nil } ) ; err != nil { return nil , err } return commit , nil } 
func setPipelineDefaults ( pipelineInfo * pps . PipelineInfo ) { now := time . Now ( ) if pipelineInfo . Transform . Image == " " { pipelineInfo . Transform . Image = DefaultUserImage } pps . VisitInput ( pipelineInfo . Input , func ( input * pps . Input ) { if input . Pfs != nil { if input . Pfs . Branch == " " { input . Pfs . Branch = " " } if input . Pfs . Name == " " { input . Pfs . Name = input . Pfs . Repo } } if input . Cron != nil { if input . Cron . Start == nil { start , _ := types . TimestampProto ( now ) input . Cron . Start = start } if input . Cron . Repo == " " { input . Cron . Repo = fmt . Sprintf ( " " , pipelineInfo . Pipeline . Name , input . Cron . Name ) } } if input . Git != nil { if input . Git . Branch == " " { input . Git . Branch = " " } if input . Git . Name == " " { input . Git . Name = tokens [ 0 ] } } } ) if pipelineInfo . OutputBranch == " " { } if pipelineInfo . CacheSize == " " { pipelineInfo . CacheSize = " " } if pipelineInfo . ResourceRequests == nil && pipelineInfo . CacheSize != " " { pipelineInfo . ResourceRequests = & pps . ResourceSpec { Memory : pipelineInfo . CacheSize , } } if pipelineInfo . MaxQueueSize < 1 { pipelineInfo . MaxQueueSize = 1 } if pipelineInfo . DatumTries == 0 { pipelineInfo . DatumTries = DefaultDatumTries } } 
func ( a * apiServer ) inspectPipeline ( pachClient * client . APIClient , name string ) ( * pps . PipelineInfo , error ) { if err := checkLoggedIn ( pachClient ) ; err != nil { return nil , err } kubeClient := a . env . GetKubeClient ( ) name , ancestors := ancestry . Parse ( name ) pipelinePtr := pps . EtcdPipelineInfo { } if err := a . pipelines . ReadOnly ( pachClient . Ctx ( ) ) . Get ( name , & pipelinePtr ) ; err != nil { if col . IsErrNotFound ( err ) { return nil , fmt . Errorf ( " \" \" " , name ) } return nil , err } pipelinePtr . SpecCommit . ID = ancestry . Add ( pipelinePtr . SpecCommit . ID , ancestors ) pipelineInfo , err := ppsutil . GetPipelineInfo ( pachClient , & pipelinePtr , true ) if err != nil { return nil , err } if pipelineInfo . Service != nil { rcName := ppsutil . PipelineRcName ( pipelineInfo . Pipeline . Name , pipelineInfo . Version ) if err != nil { return nil , err } service , err := kubeClient . CoreV1 ( ) . Services ( a . namespace ) . Get ( fmt . Sprintf ( " " , rcName ) , metav1 . GetOptions { } ) if err != nil { if ! isNotFoundErr ( err ) { return nil , err } } else { pipelineInfo . Service . IP = service . Spec . ClusterIP } } var hasGitInput bool pps . VisitInput ( pipelineInfo . Input , func ( input * pps . Input ) { if input . Git != nil { hasGitInput = true } } ) if hasGitInput { pipelineInfo . GithookURL = " " svc , err := getGithookService ( kubeClient , a . namespace ) if err != nil { return pipelineInfo , nil } numIPs := len ( svc . Status . LoadBalancer . Ingress ) if numIPs == 0 { } if numIPs != 1 { return nil , fmt . Errorf ( " " ) } ingress := svc . Status . LoadBalancer . Ingress [ 0 ] if ingress . IP != " " { } else if ingress . Hostname != " " { } } return pipelineInfo , nil } 
func CollectActiveObjectsAndTags ( ctx context . Context , pachClient * client . APIClient , repoInfos [ ] * pfs . RepoInfo , pipelineInfos [ ] * pps . PipelineInfo , memoryAllowance int , storageRoot string ) ( * ActiveStat , error ) { if memoryAllowance == 0 { memoryAllowance = defaultGCMemory } result := & ActiveStat { var activeObjectsMu sync . Mutex defer activeObjectsMu . Unlock ( ) for _ , object := range objects { if object != nil { result . NObjects ++ result . Objects . AddString ( object . Hash ) } } } } addActiveObjects ( object ) tree , err := hashtree . GetHashTreeObject ( pachClient , storageRoot , object ) if err != nil { return err } return tree . Walk ( " " , func ( path string , node * hashtree . NodeProto ) error { if node . FileNode != nil { addActiveObjects ( node . FileNode . Objects ... ) } return nil } ) } var eg errgroup . Group for _ , repo := range repoInfos { repo := repo client , err := pachClient . ListCommitStream ( ctx , & pfs . ListCommitRequest { Repo : repo . Repo , } ) if err != nil { return nil , err } for { ci , err := client . Recv ( ) if err == io . EOF { break } else if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } limiter . Acquire ( ) eg . Go ( func ( ) error { defer limiter . Release ( ) addActiveObjects ( ci . Datums ) return addActiveTree ( ci . Tree ) } ) } } if err := eg . Wait ( ) ; err != nil { return nil , err } eg = errgroup . Group { } for _ , pipelineInfo := range pipelineInfos { tags , err := pachClient . ObjectAPIClient . ListTags ( pachClient . Ctx ( ) , & pfs . ListTagsRequest { Prefix : client . DatumTagPrefix ( pipelineInfo . Salt ) , IncludeObject : true , } ) if err != nil { return nil , fmt . Errorf ( " " , err ) } for resp , err := tags . Recv ( ) ; err != io . EOF ; resp , err = tags . Recv ( ) { resp := resp if err != nil { return nil , err } result . Tags . AddString ( resp . Tag . Name ) result . NTags ++ limiter . Acquire ( ) eg . Go ( func ( ) error { defer limiter . Release ( ) return nil } ) } } if err := eg . Wait ( ) ; err != nil { return nil , err } return result , nil } 
func ( a * apiServer ) incrementGCGeneration ( ctx context . Context ) error { resp , err := a . env . GetEtcdClient ( ) . Get ( ctx , client . GCGenerationKey ) if err != nil { return err } if resp . Count == 0 { } } else { oldGen , err := strconv . Atoi ( string ( resp . Kvs [ 0 ] . Value ) ) if err != nil { return err } newGen := oldGen + 1 if _ , err := a . env . GetEtcdClient ( ) . Put ( ctx , client . GCGenerationKey , strconv . Itoa ( newGen ) ) ; err != nil { return err } } return nil } 
func NewDebugServer ( name string , etcdClient * etcd . Client , etcdPrefix string , workerGrpcPort uint16 ) debug . DebugServer { return & debugServer { name : name , etcdClient : etcdClient , etcdPrefix : etcdPrefix , workerGrpcPort : workerGrpcPort , } } 
func ( c APIClient ) Health ( ) error { _ , err := c . healthClient . Health ( c . Ctx ( ) , & types . Empty { } ) return grpcutil . ScrubGRPC ( err ) } 
func newObjBlockAPIServer ( dir string , cacheBytes int64 , etcdAddress string , objClient obj . Client , test bool ) ( * objBlockAPIServer , error ) { } oneCacheShare := cacheBytes / ( objectCacheShares + tagCacheShares + objectInfoCacheShares + blockCacheShares ) s := & objBlockAPIServer { Logger : log . NewLogger ( " " ) , dir : dir , objClient : objClient , objectIndexes : make ( map [ string ] * pfsclient . ObjectIndex ) , objectCacheBytes : oneCacheShare * objectCacheShares , } objectGroupName := " " tagGroupName := " " objectInfoGroupName := " " blockGroupName := " " if test { uuid := uuid . New ( ) objectGroupName += uuid tagGroupName += uuid objectInfoGroupName += uuid blockGroupName += uuid } s . objectCache = groupcache . NewGroup ( objectGroupName , oneCacheShare * objectCacheShares , groupcache . GetterFunc ( s . objectGetter ) ) s . tagCache = groupcache . NewGroup ( tagGroupName , oneCacheShare * tagCacheShares , groupcache . GetterFunc ( s . tagGetter ) ) s . objectInfoCache = groupcache . NewGroup ( objectInfoGroupName , oneCacheShare * objectInfoCacheShares , groupcache . GetterFunc ( s . objectInfoGetter ) ) s . blockCache = groupcache . NewGroup ( blockGroupName , oneCacheShare * blockCacheShares , groupcache . GetterFunc ( s . blockGetter ) ) if ! test { RegisterCacheStats ( " " , & s . tagCache . Stats ) RegisterCacheStats ( " " , & s . objectCache . Stats ) RegisterCacheStats ( " " , & s . objectInfoCache . Stats ) } go s . watchGC ( etcdAddress ) return s , nil } 
func ( s * objBlockAPIServer ) watchGC ( etcdAddress string ) { b := backoff . NewInfiniteBackOff ( ) backoff . RetryNotify ( func ( ) error { etcdClient , err := etcd . New ( etcd . Config { Endpoints : [ ] string { etcdAddress } , DialOptions : client . DefaultDialOptions ( ) , } ) if err != nil { return fmt . Errorf ( " " , err ) } watcher , err := watch . NewWatcher ( context . Background ( ) , etcdClient , " " , client . GCGenerationKey , nil ) if err != nil { return fmt . Errorf ( " " , err ) } defer watcher . Close ( ) for { ev , ok := <- watcher . Watch ( ) if ev . Err != nil { return fmt . Errorf ( " " , ev . Err ) } if ! ok { return fmt . Errorf ( " " ) } newGen , err := strconv . Atoi ( string ( ev . Value ) ) if err != nil { return fmt . Errorf ( " " , err ) } s . setGeneration ( newGen ) } } , b , func ( err error , d time . Duration ) error { logrus . Errorf ( " " , err , d ) return nil } ) } 
func ( s * objBlockAPIServer ) writeInternal ( ctx context . Context , path string , data [ ] byte ) ( retErr error ) { defer func ( ) { if retErr != nil { return } retErr = func ( ) ( retErr error ) { if ! s . objClient . Exists ( ctx , path ) { logrus . Errorf ( " " , path ) return fmt . Errorf ( " " , path ) } return nil } ( ) } ( ) w , err := s . objClient . Writer ( ctx , path ) if err != nil { return err } defer func ( ) { if err := w . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) _ , err = w . Write ( data ) return err } 
func ( s * objBlockAPIServer ) splitKey ( key string ) string { gen := s . getGeneration ( ) if len ( key ) < prefixLength { return fmt . Sprintf ( " " , key , gen ) } return fmt . Sprintf ( " " , key [ : prefixLength ] , key [ prefixLength : ] , gen ) } 
func NewWriter ( w io . Writer , header string ) * Writer { if header [ len ( header ) - 1 ] != '\n' { panic ( " " ) } tabwriter := ansiterm . NewTabWriter ( w , 0 , 1 , 1 , ' ' , 0 ) tabwriter . Write ( [ ] byte ( header ) ) return & Writer { w : tabwriter , lines : 1 , } 
func ( w * Writer ) Write ( buf [ ] byte ) ( int , error ) { if w . lines >= termHeight { if err := w . Flush ( ) ; err != nil { return 0 , err } if _ , err := w . w . Write ( w . header ) ; err != nil { return 0 , err } w . lines ++ } w . lines += bytes . Count ( buf , [ ] byte { '\n' } ) return w . w . Write ( buf ) } 
func PrintRepoHeader ( w io . Writer , printAuth bool ) { if printAuth { fmt . Fprint ( w , RepoAuthHeader ) return } fmt . Fprint ( w , RepoHeader ) } 
func PrintRepoInfo ( w io . Writer , repoInfo * pfs . RepoInfo , fullTimestamps bool ) { fmt . Fprintf ( w , " \t " , repoInfo . Repo . Name ) if fullTimestamps { fmt . Fprintf ( w , " \t " , repoInfo . Created . String ( ) ) } else { fmt . Fprintf ( w , " \t " , pretty . Ago ( repoInfo . Created ) ) } fmt . Fprintf ( w , " \t " , units . BytesSize ( float64 ( repoInfo . SizeBytes ) ) ) if repoInfo . AuthInfo != nil { fmt . Fprintf ( w , " \t " , repoInfo . AuthInfo . AccessLevel . String ( ) ) } fmt . Fprintln ( w ) } 
func PrintDetailedRepoInfo ( repoInfo * PrintableRepoInfo ) error { template , err := template . New ( " " ) . Funcs ( funcMap ) . Parse ( `Name: {{.Repo.Name}}{{if .Description}} Description: {{.Description}}{{end}}{{if .FullTimestamps}} Created: {{.Created}}{{else}} Created: {{prettyAgo .Created}}{{end}} Size of HEAD on master: {{prettySize .SizeBytes}}{{if .AuthInfo}} Access level: {{ .AuthInfo.AccessLevel.String }}{{end}} ` ) if err != nil { return err } err = template . Execute ( os . Stdout , repoInfo ) if err != nil { return err } return nil } 
func PrintBranch ( w io . Writer , branchInfo * pfs . BranchInfo ) { fmt . Fprintf ( w , " \t " , branchInfo . Branch . Name ) if branchInfo . Head != nil { fmt . Fprintf ( w , " \t \n " , branchInfo . Head . ID ) } else { fmt . Fprintf ( w , " \t \n " ) } } 
func PrintCommitInfo ( w io . Writer , commitInfo * pfs . CommitInfo , fullTimestamps bool ) { fmt . Fprintf ( w , " \t " , commitInfo . Commit . Repo . Name ) fmt . Fprintf ( w , " \t " , commitInfo . Branch . Name ) fmt . Fprintf ( w , " \t " , commitInfo . Commit . ID ) if commitInfo . ParentCommit != nil { fmt . Fprintf ( w , " \t " , commitInfo . ParentCommit . ID ) } else { fmt . Fprint ( w , " \t " ) } if fullTimestamps { fmt . Fprintf ( w , " \t " , commitInfo . Started . String ( ) ) } else { fmt . Fprintf ( w , " \t " , pretty . Ago ( commitInfo . Started ) ) } if commitInfo . Finished != nil { fmt . Fprintf ( w , fmt . Sprintf ( " \t " , pretty . TimeDifference ( commitInfo . Started , commitInfo . Finished ) ) ) fmt . Fprintf ( w , " \t \n " , units . BytesSize ( float64 ( commitInfo . SizeBytes ) ) ) } else { fmt . Fprintf ( w , " \t " ) } } 
func PrintDetailedCommitInfo ( commitInfo * PrintableCommitInfo ) error { template , err := template . New ( " " ) . Funcs ( funcMap ) . Parse ( `Commit: {{.Commit.Repo.Name}}@{{.Commit.ID}}{{if .Branch}} Original Branch: {{.Branch.Name}}{{end}}{{if .Description}} Description: {{.Description}}{{end}}{{if .ParentCommit}} Parent: {{.ParentCommit.ID}}{{end}}{{if .FullTimestamps}} Started: {{.Started}}{{else}} Started: {{prettyAgo .Started}}{{end}}{{if .Finished}}{{if .FullTimestamps}} Finished: {{.Finished}}{{else}} Finished: {{prettyAgo .Finished}}{{end}}{{end}} Size: {{prettySize .SizeBytes}}{{if .Provenance}} Provenance: {{range .Provenance}} {{.Commit.Repo.Name}}@{{.Commit.ID}} ({{.Branch.Name}}) {{end}} {{end}} ` ) if err != nil { return err } err = template . Execute ( os . Stdout , commitInfo ) if err != nil { return err } return nil } 
func PrintFileInfo ( w io . Writer , fileInfo * pfs . FileInfo , fullTimestamps bool ) { fmt . Fprintf ( w , " \t " , fileInfo . File . Commit . ID ) fmt . Fprintf ( w , " \t " , fileInfo . File . Path ) if fileInfo . FileType == pfs . FileType_FILE { fmt . Fprint ( w , " \t " ) } else { fmt . Fprint ( w , " \t " ) } if fileInfo . Committed == nil { fmt . Fprintf ( w , " \t " ) } else if fullTimestamps { fmt . Fprintf ( w , " \t " , fileInfo . Committed . String ( ) ) } else { fmt . Fprintf ( w , " \t " , pretty . Ago ( fileInfo . Committed ) ) } fmt . Fprintf ( w , " \t \n " , units . BytesSize ( float64 ( fileInfo . SizeBytes ) ) ) } 
func PrintDetailedFileInfo ( fileInfo * pfs . FileInfo ) error { template , err := template . New ( " " ) . Funcs ( funcMap ) . Parse ( `Path: {{.File.Path}} Type: {{fileType .FileType}} Size: {{prettySize .SizeBytes}} Children: {{range .Children}} {{.}} {{end}} ` ) if err != nil { return err } return template . Execute ( os . Stdout , fileInfo ) } 
func CompactPrintBranch ( b * pfs . Branch ) string { return fmt . Sprintf ( " " , b . Repo . Name , b . Name ) } 
func CompactPrintCommit ( c * pfs . Commit ) string { return fmt . Sprintf ( " " , c . Repo . Name , c . ID ) } 
func CompactPrintFile ( f * pfs . File ) string { return fmt . Sprintf ( " " , f . Commit . Repo . Name , f . Commit . ID , f . Path ) } 
func Parse ( s string ) ( string , int ) { sepIndex := strings . IndexAny ( s , " " ) if sepIndex == - 1 { return s , 0 } strAfterSep := s [ sepIndex + 1 : ] } } } } 
func Add ( s string , ancestors int ) string { return fmt . Sprintf ( " " , s , ancestors ) } 
func RetryNotify ( operation Operation , b BackOff , notify Notify ) error { var err error var next time . Duration b . Reset ( ) for { if err = operation ( ) ; err == nil { return nil } if next = b . NextBackOff ( ) ; next == Stop { return err } if notify != nil { if err := notify ( err , next ) ; err != nil { return err } } time . Sleep ( next ) } } 
func NewCache ( size int ) ( * Cache , error ) { c , err := lru . NewWithEvict ( size , func ( key interface { } , value interface { } ) { go func ( ) { tree , ok := value . ( * dbHashTree ) if ! ok { logrus . Infof ( " " , reflect . TypeOf ( value ) ) return } if err := tree . Destroy ( ) ; err != nil { logrus . Infof ( " " , err ) } } ( ) } ) if err != nil { return nil , err } return & Cache { c } , nil } 
func ( c * MergeCache ) Put ( id int64 , tree io . Reader ) ( retErr error ) { return c . Cache . Put ( fmt . Sprint ( id ) , tree ) } 
func ( c * MergeCache ) Get ( id int64 , w io . Writer , filter Filter ) ( retErr error ) { r , err := c . Cache . Get ( fmt . Sprint ( id ) ) if err != nil { return err } defer func ( ) { if err := r . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return NewWriter ( w ) . Copy ( NewReader ( r , filter ) ) } 
func ( c * MergeCache ) Delete ( id int64 ) error { return c . Cache . Delete ( fmt . Sprint ( id ) ) } 
func ( c * MergeCache ) Merge ( w * Writer , base io . Reader , filter Filter ) ( retErr error ) { var trees [ ] * Reader if base != nil { trees = append ( trees , NewReader ( base , filter ) ) } for _ , key := range c . Keys ( ) { r , err := c . Cache . Get ( key ) if err != nil { return err } defer func ( ) { if err := r . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) trees = append ( trees , NewReader ( r , filter ) ) } return Merge ( w , trees ) } 
func PrintJobInfo ( w io . Writer , jobInfo * ppsclient . JobInfo , fullTimestamps bool ) { fmt . Fprintf ( w , " \t " , jobInfo . Job . ID ) fmt . Fprintf ( w , " \t " , jobInfo . Pipeline . Name ) if fullTimestamps { fmt . Fprintf ( w , " \t " , jobInfo . Started . String ( ) ) } else { fmt . Fprintf ( w , " \t " , pretty . Ago ( jobInfo . Started ) ) } if jobInfo . Finished != nil { fmt . Fprintf ( w , " \t " , pretty . TimeDifference ( jobInfo . Started , jobInfo . Finished ) ) } else { fmt . Fprintf ( w , " \t " ) } fmt . Fprintf ( w , " \t " , jobInfo . Restart ) if jobInfo . DataRecovered != 0 { fmt . Fprintf ( w , " \t " , jobInfo . DataProcessed , jobInfo . DataSkipped , jobInfo . DataRecovered , jobInfo . DataTotal ) } else { fmt . Fprintf ( w , " \t " , jobInfo . DataProcessed , jobInfo . DataSkipped , jobInfo . DataTotal ) } fmt . Fprintf ( w , " \t " , pretty . Size ( jobInfo . Stats . DownloadBytes ) ) fmt . Fprintf ( w , " \t " , pretty . Size ( jobInfo . Stats . UploadBytes ) ) if jobInfo . State == ppsclient . JobState_JOB_FAILURE { fmt . Fprintf ( w , " \t \n " , jobState ( jobInfo . State ) , safeTrim ( jobInfo . Reason , jobReasonLen ) ) } else { fmt . Fprintf ( w , " \t \n " , jobState ( jobInfo . State ) ) } } 
func PrintPipelineInfo ( w io . Writer , pipelineInfo * ppsclient . PipelineInfo , fullTimestamps bool ) { fmt . Fprintf ( w , " \t " , pipelineInfo . Pipeline . Name ) fmt . Fprintf ( w , " \t " , ShorthandInput ( pipelineInfo . Input ) ) if fullTimestamps { fmt . Fprintf ( w , " \t " , pipelineInfo . CreatedAt . String ( ) ) } else { fmt . Fprintf ( w , " \t " , pretty . Ago ( pipelineInfo . CreatedAt ) ) } fmt . Fprintf ( w , " \t \n " , pipelineState ( pipelineInfo . State ) , jobState ( pipelineInfo . LastJobState ) ) } 
func PrintWorkerStatus ( w io . Writer , workerStatus * ppsclient . WorkerStatus , fullTimestamps bool ) { fmt . Fprintf ( w , " \t " , workerStatus . WorkerID ) fmt . Fprintf ( w , " \t " , workerStatus . JobID ) for _ , datum := range workerStatus . Data { fmt . Fprintf ( w , datum . Path ) } fmt . Fprintf ( w , " \t " ) if fullTimestamps { fmt . Fprintf ( w , " \t " , workerStatus . Started . String ( ) ) } else { fmt . Fprintf ( w , " \t " , pretty . Ago ( workerStatus . Started ) ) } fmt . Fprintf ( w , " \t \n " , workerStatus . QueueSize ) } 
func PrintDetailedJobInfo ( jobInfo * PrintableJobInfo ) error { template , err := template . New ( " " ) . Funcs ( funcMap ) . Parse ( `ID: {{.Job.ID}} {{if .Pipeline}} Pipeline: {{.Pipeline.Name}} {{end}} {{if .ParentJob}} Parent: {{.ParentJob.ID}} {{end}}{{if .FullTimestamps}} Started: {{.Started}}{{else}} Started: {{prettyAgo .Started}} {{end}}{{if .Finished}} Duration: {{prettyTimeDifference .Started .Finished}} {{end}} State: {{jobState .State}} Reason: {{.Reason}} Processed: {{.DataProcessed}} Failed: {{.DataFailed}} Skipped: {{.DataSkipped}} Recovered: {{.DataRecovered}} Total: {{.DataTotal}} Data Downloaded: {{prettySize .Stats.DownloadBytes}} Data Uploaded: {{prettySize .Stats.UploadBytes}} Download Time: {{prettyDuration .Stats.DownloadTime}} Process Time: {{prettyDuration .Stats.ProcessTime}} Upload Time: {{prettyDuration .Stats.UploadTime}} Datum Timeout: {{.DatumTimeout}} Job Timeout: {{.JobTimeout}} Worker Status: {{workerStatus .}}Restarts: {{.Restart}} ParallelismSpec: {{.ParallelismSpec}} {{ if .ResourceRequests }}ResourceRequests: CPU: {{ .ResourceRequests.Cpu }} Memory: {{ .ResourceRequests.Memory }} {{end}} {{ if .ResourceLimits }}ResourceLimits: CPU: {{ .ResourceLimits.Cpu }} Memory: {{ .ResourceLimits.Memory }} {{ if .ResourceLimits.Gpu }}GPU: Type: {{ .ResourceLimits.Gpu.Type }} Number: {{ .ResourceLimits.Gpu.Number }} {{end}} {{end}} {{ if .Service }}Service: {{ if .Service.InternalPort }}InternalPort: {{ .Service.InternalPort }} {{end}} {{ if .Service.ExternalPort }}ExternalPort: {{ .Service.ExternalPort }} {{end}} {{end}}Input: {{jobInput .}} Transform: {{prettyTransform .Transform}} {{if .OutputCommit}} Output Commit: {{.OutputCommit.ID}} {{end}} {{ if .StatsCommit }} Stats Commit: {{.StatsCommit.ID}} {{end}} {{ if .Egress }} Egress: {{.Egress.URL}} {{end}} ` ) if err != nil { return err } err = template . Execute ( os . Stdout , jobInfo ) if err != nil { return err } return nil } 
func PrintDetailedPipelineInfo ( pipelineInfo * PrintablePipelineInfo ) error { template , err := template . New ( " " ) . Funcs ( funcMap ) . Parse ( `Name: {{.Pipeline.Name}}{{if .Description}} Description: {{.Description}}{{end}}{{if .FullTimestamps }} Created: {{.CreatedAt}}{{ else }} Created: {{prettyAgo .CreatedAt}} {{end}} State: {{pipelineState .State}} Stopped: {{ .Stopped }} Reason: {{.Reason}} Parallelism Spec: {{.ParallelismSpec}} {{ if .ResourceRequests }}ResourceRequests: CPU: {{ .ResourceRequests.Cpu }} Memory: {{ .ResourceRequests.Memory }} {{end}} {{ if .ResourceLimits }}ResourceLimits: CPU: {{ .ResourceLimits.Cpu }} Memory: {{ .ResourceLimits.Memory }} {{ if .ResourceLimits.Gpu }}GPU: Type: {{ .ResourceLimits.Gpu.Type }} Number: {{ .ResourceLimits.Gpu.Number }} {{end}} {{end}} Datum Timeout: {{.DatumTimeout}} Job Timeout: {{.JobTimeout}} Input: {{pipelineInput .PipelineInfo}} {{ if .GithookURL }}Githook URL: {{.GithookURL}} {{end}} Output Branch: {{.OutputBranch}} Transform: {{prettyTransform .Transform}} {{ if .Egress }}Egress: {{.Egress.URL}} {{end}} {{if .RecentError}} Recent Error: {{.RecentError}} {{end}} Job Counts: {{jobCounts .JobCounts}} ` ) if err != nil { return err } err = template . Execute ( os . Stdout , pipelineInfo ) if err != nil { return err } return nil } 
func PrintDatumInfo ( w io . Writer , datumInfo * ppsclient . DatumInfo ) { totalTime := " " if datumInfo . Stats != nil { totalTime = units . HumanDuration ( client . GetDatumTotalTime ( datumInfo . Stats ) ) } fmt . Fprintf ( w , " \t \t \n " , datumInfo . Datum . ID , datumState ( datumInfo . State ) , totalTime ) } 
func PrintDetailedDatumInfo ( w io . Writer , datumInfo * ppsclient . DatumInfo ) { fmt . Fprintf ( w , " \t \n " , datumInfo . Datum . ID ) fmt . Fprintf ( w , " \t \n " , datumInfo . Datum . Job . ID ) fmt . Fprintf ( w , " \t \n " , datumInfo . State ) fmt . Fprintf ( w , " \t \n " , pretty . Size ( datumInfo . Stats . DownloadBytes ) ) fmt . Fprintf ( w , " \t \n " , pretty . Size ( datumInfo . Stats . UploadBytes ) ) totalTime := client . GetDatumTotalTime ( datumInfo . Stats ) . String ( ) fmt . Fprintf ( w , " \t \n " , totalTime ) var downloadTime string dl , err := types . DurationFromProto ( datumInfo . Stats . DownloadTime ) if err != nil { downloadTime = err . Error ( ) } downloadTime = dl . String ( ) fmt . Fprintf ( w , " \t \n " , downloadTime ) var procTime string proc , err := types . DurationFromProto ( datumInfo . Stats . ProcessTime ) if err != nil { procTime = err . Error ( ) } procTime = proc . String ( ) fmt . Fprintf ( w , " \t \n " , procTime ) var uploadTime string ul , err := types . DurationFromProto ( datumInfo . Stats . UploadTime ) if err != nil { uploadTime = err . Error ( ) } uploadTime = ul . String ( ) fmt . Fprintf ( w , " \t \n " , uploadTime ) fmt . Fprintf ( w , " \n " ) tw := ansiterm . NewTabWriter ( w , 10 , 1 , 3 , ' ' , 0 ) PrintFileHeader ( tw ) PrintFile ( tw , datumInfo . PfsState ) tw . Flush ( ) fmt . Fprintf ( w , " \n " ) tw = ansiterm . NewTabWriter ( w , 10 , 1 , 3 , ' ' , 0 ) PrintFileHeader ( tw ) for _ , d := range datumInfo . Data { PrintFile ( tw , d . File ) } tw . Flush ( ) } 
func PrintFile ( w io . Writer , file * pfsclient . File ) { fmt . Fprintf ( w , " \t \t \t \n " , file . Commit . Repo . Name , file . Commit . ID , file . Path ) } 
func ShorthandInput ( input * ppsclient . Input ) string { switch { case input == nil : return " " case input . Pfs != nil : return fmt . Sprintf ( " " , input . Pfs . Repo , input . Pfs . Glob ) case input . Cross != nil : var subInput [ ] string for _ , input := range input . Cross { subInput = append ( subInput , ShorthandInput ( input ) ) } return " " + strings . Join ( subInput , " + " " case input . Union != nil : var subInput [ ] string for _ , input := range input . Union { subInput = append ( subInput , ShorthandInput ( input ) ) } return " " + strings . Join ( subInput , " + " " case input . Cron != nil : return fmt . Sprintf ( " " , input . Cron . Name , input . Cron . Spec ) } return " " } 
func ( v * vaultCredentialsProvider ) updateLease ( secret * vault . Secret ) { v . leaseMu . Lock ( ) defer v . leaseMu . Unlock ( ) v . leaseID = secret . LeaseID v . leaseLastRenew = time . Now ( ) v . leaseDuration = time . Duration ( secret . LeaseDuration ) * time . Second } 
func ( v * vaultCredentialsProvider ) Retrieve ( ) ( credentials . Value , error ) { var emptyCreds , result credentials . Value if err != nil { return emptyCreds , fmt . Errorf ( " " , err ) } accessKeyIface , accessKeyOk := vaultSecret . Data [ " " ] awsSecretIface , awsSecretOk := vaultSecret . Data [ " " ] if ! accessKeyOk || ! awsSecretOk { return emptyCreds , fmt . Errorf ( " " ) } result . SecretAccessKey , awsSecretOk = awsSecretIface . ( string ) if ! accessKeyOk || ! awsSecretOk { return emptyCreds , fmt . Errorf ( " " , accessKeyIface , awsSecretIface ) } go func ( ) { for { if renewInterval . Seconds ( ) < oneDayInSeconds { renewInterval = oneDayInSeconds * time . Second } backoff . RetryNotify ( func ( ) error { if err != nil { return err } v . updateLease ( vaultSecret ) return nil } , backoff . NewExponentialBackOff ( ) , func ( err error , _ time . Duration ) error { log . Errorf ( " " , err ) return nil } ) } } ( ) return result , nil } 
func ( v * vaultCredentialsProvider ) IsExpired ( ) bool { v . leaseMu . Lock ( ) defer v . leaseMu . Unlock ( ) return time . Now ( ) . After ( v . leaseLastRenew . Add ( v . leaseDuration ) ) } 
func ( a * sharder ) unsafeAssignRoles ( cancel chan bool ) ( retErr error ) { var version int64 oldServers := make ( map [ string ] bool ) oldRoles := make ( map [ string ] * ServerRole ) oldShards := make ( map [ uint64 ] string ) var oldMinVersion int64 if err != nil { return err } for _ , encodedServerRole := range serverRoles { serverRole , err := decodeServerRole ( encodedServerRole ) if err != nil { return err } if oldServerRole , ok := oldRoles [ serverRole . Address ] ; ! ok || oldServerRole . Version < serverRole . Version { oldRoles [ serverRole . Address ] = serverRole oldServers [ serverRole . Address ] = true } if version < serverRole . Version + 1 { version = serverRole . Version + 1 } } for _ , oldServerRole := range oldRoles { for shard := range oldServerRole . Shards { oldShards [ shard ] = oldServerRole . Address } } err = a . discoveryClient . WatchAll ( a . serverStateDir ( ) , cancel , func ( encodedServerStates map [ string ] string ) error { if len ( encodedServerStates ) == 0 { return nil } newServerStates := make ( map [ string ] * ServerState ) newRoles := make ( map [ string ] * ServerRole ) newShards := make ( map [ uint64 ] string ) shardsPerServer := a . numShards / uint64 ( len ( encodedServerStates ) ) shardsRemainder := a . numShards % uint64 ( len ( encodedServerStates ) ) for _ , encodedServerState := range encodedServerStates { serverState , err := decodeServerState ( encodedServerState ) if err != nil { return err } newServerStates [ serverState . Address ] = serverState newRoles [ serverState . Address ] = & ServerRole { Address : serverState . Address , Version : version , Shards : make ( map [ uint64 ] bool ) , } } for _ , serverState := range newServerStates { if serverState . Version < minVersion { minVersion = serverState . Version } } if err := a . discoveryClient . WatchAll ( a . frontendStateDir ( ) , cancel , func ( encodedFrontendStates map [ string ] string ) error { for _ , encodedFrontendState := range encodedFrontendStates { frontendState , err := decodeFrontendState ( encodedFrontendState ) if err != nil { return err } if frontendState . Version < minVersion { return nil } } return errComplete } ) ; err != nil && err != errComplete { return err } serverRoles , err := a . discoveryClient . GetAll ( a . serverRoleDir ( ) ) if err != nil { return err } for key , encodedServerRole := range serverRoles { serverRole , err := decodeServerRole ( encodedServerRole ) if err != nil { return err } if serverRole . Version < minVersion { if err := a . discoveryClient . Delete ( key ) ; err != nil { return err } } } } } Shard : for shard := uint64 ( 0 ) ; shard < a . numShards ; shard ++ { if address , ok := oldShards [ shard ] ; ok { if assignShard ( newRoles , newShards , address , shard , shardsPerServer , & shardsRemainder ) { continue Shard } } for address := range newServerStates { if assignShard ( newRoles , newShards , address , shard , shardsPerServer , & shardsRemainder ) { continue Shard } } log . Error ( & FailedToAssignRoles { ServerStates : newServerStates , NumShards : a . numShards , } ) return nil } addresses := Addresses { Version : version , Addresses : make ( map [ uint64 ] string ) , } for address , serverRole := range newRoles { encodedServerRole , err := marshaler . MarshalToString ( serverRole ) if err != nil { return err } if err := a . discoveryClient . Set ( a . serverRoleKeyVersion ( address , version ) , encodedServerRole , 0 ) ; err != nil { return err } address := newServerStates [ address ] . Address for shard := range serverRole . Shards { addresses . Addresses [ shard ] = address } } encodedAddresses , err := marshaler . MarshalToString ( & addresses ) if err != nil { return err } if err := a . discoveryClient . Set ( a . addressesKey ( version ) , encodedAddresses , 0 ) ; err != nil { return err } version ++ oldServers = make ( map [ string ] bool ) for address := range newServerStates { oldServers [ address ] = true } oldRoles = newRoles oldShards = newShards return nil } ) if err == discovery . ErrCancelled { return ErrCancelled } return err } 
func NewBranch ( repoName string , branchName string ) * pfs . Branch { return & pfs . Branch { Repo : NewRepo ( repoName ) , Name : branchName , } } 
func NewCommit ( repoName string , commitID string ) * pfs . Commit { return & pfs . Commit { Repo : NewRepo ( repoName ) , ID : commitID , } } 
func NewCommitProvenance ( repoName string , branchName string , commitID string ) * pfs . CommitProvenance { return & pfs . CommitProvenance { Commit : NewCommit ( repoName , commitID ) , Branch : NewBranch ( repoName , branchName ) , } } 
func NewFile ( repoName string , commitID string , path string ) * pfs . File { return & pfs . File { Commit : NewCommit ( repoName , commitID ) , Path : path , } } 
func ( c APIClient ) CreateRepo ( repoName string ) error { _ , err := c . PfsAPIClient . CreateRepo ( c . Ctx ( ) , & pfs . CreateRepoRequest { Repo : NewRepo ( repoName ) , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) InspectRepo ( repoName string ) ( * pfs . RepoInfo , error ) { resp , err := c . PfsAPIClient . InspectRepo ( c . Ctx ( ) , & pfs . InspectRepoRequest { Repo : NewRepo ( repoName ) , } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return resp , nil } 
func ( c APIClient ) ListRepo ( ) ( [ ] * pfs . RepoInfo , error ) { request := & pfs . ListRepoRequest { } repoInfos , err := c . PfsAPIClient . ListRepo ( c . Ctx ( ) , request , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return repoInfos . RepoInfo , nil } 
func ( c APIClient ) DeleteRepo ( repoName string , force bool ) error { _ , err := c . PfsAPIClient . DeleteRepo ( c . Ctx ( ) , & pfs . DeleteRepoRequest { Repo : NewRepo ( repoName ) , Force : force , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) BuildCommit ( repoName string , branch string , parent string , treeObject string ) ( * pfs . Commit , error ) { commit , err := c . PfsAPIClient . BuildCommit ( c . Ctx ( ) , & pfs . BuildCommitRequest { Parent : NewCommit ( repoName , parent ) , Branch : branch , Tree : & pfs . Object { Hash : treeObject } , } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return commit , nil } 
func ( c APIClient ) StartCommitParent ( repoName string , branch string , parentCommit string ) ( * pfs . Commit , error ) { commit , err := c . PfsAPIClient . StartCommit ( c . Ctx ( ) , & pfs . StartCommitRequest { Parent : & pfs . Commit { Repo : & pfs . Repo { Name : repoName , } , ID : parentCommit , } , Branch : branch , } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return commit , nil } 
func ( c APIClient ) FinishCommit ( repoName string , commitID string ) error { _ , err := c . PfsAPIClient . FinishCommit ( c . Ctx ( ) , & pfs . FinishCommitRequest { Commit : NewCommit ( repoName , commitID ) , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) InspectCommit ( repoName string , commitID string ) ( * pfs . CommitInfo , error ) { return c . inspectCommit ( repoName , commitID , pfs . CommitState_STARTED ) } 
func ( c APIClient ) BlockCommit ( repoName string , commitID string ) ( * pfs . CommitInfo , error ) { return c . inspectCommit ( repoName , commitID , pfs . CommitState_FINISHED ) } 
func ( c APIClient ) ListCommit ( repoName string , to string , from string , number uint64 ) ( [ ] * pfs . CommitInfo , error ) { var result [ ] * pfs . CommitInfo if err := c . ListCommitF ( repoName , to , from , number , func ( ci * pfs . CommitInfo ) error { result = append ( result , ci ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func ( c APIClient ) ListCommitF ( repoName string , to string , from string , number uint64 , f func ( * pfs . CommitInfo ) error ) error { req := & pfs . ListCommitRequest { Repo : NewRepo ( repoName ) , Number : number , } if from != " " { req . From = NewCommit ( repoName , from ) } if to != " " { req . To = NewCommit ( repoName , to ) } stream , err := c . PfsAPIClient . ListCommitStream ( c . Ctx ( ) , req ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { ci , err := stream . Recv ( ) if err == io . EOF { break } else if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( ci ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } return nil } 
func ( c APIClient ) ListCommitByRepo ( repoName string ) ( [ ] * pfs . CommitInfo , error ) { return c . ListCommit ( repoName , " " , " " , 0 ) } 
func ( c APIClient ) CreateBranch ( repoName string , branch string , commit string , provenance [ ] * pfs . Branch ) error { var head * pfs . Commit if commit != " " { head = NewCommit ( repoName , commit ) } _ , err := c . PfsAPIClient . CreateBranch ( c . Ctx ( ) , & pfs . CreateBranchRequest { Branch : NewBranch ( repoName , branch ) , Head : head , Provenance : provenance , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) InspectBranch ( repoName string , branch string ) ( * pfs . BranchInfo , error ) { branchInfo , err := c . PfsAPIClient . InspectBranch ( c . Ctx ( ) , & pfs . InspectBranchRequest { Branch : NewBranch ( repoName , branch ) , } , ) return branchInfo , grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) ListBranch ( repoName string ) ( [ ] * pfs . BranchInfo , error ) { branchInfos , err := c . PfsAPIClient . ListBranch ( c . Ctx ( ) , & pfs . ListBranchRequest { Repo : NewRepo ( repoName ) , } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return branchInfos . BranchInfo , nil } 
func ( c APIClient ) SetBranch ( repoName string , commit string , branch string ) error { return c . CreateBranch ( repoName , branch , commit , nil ) } 
func ( c APIClient ) DeleteBranch ( repoName string , branch string , force bool ) error { _ , err := c . PfsAPIClient . DeleteBranch ( c . Ctx ( ) , & pfs . DeleteBranchRequest { Branch : NewBranch ( repoName , branch ) , Force : force , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) DeleteCommit ( repoName string , commitID string ) error { _ , err := c . PfsAPIClient . DeleteCommit ( c . Ctx ( ) , & pfs . DeleteCommitRequest { Commit : NewCommit ( repoName , commitID ) , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) FlushCommit ( commits [ ] * pfs . Commit , toRepos [ ] * pfs . Repo ) ( CommitInfoIterator , error ) { ctx , cancel := context . WithCancel ( c . Ctx ( ) ) stream , err := c . PfsAPIClient . FlushCommit ( ctx , & pfs . FlushCommitRequest { Commits : commits , ToRepos : toRepos , } , ) if err != nil { cancel ( ) return nil , grpcutil . ScrubGRPC ( err ) } return & commitInfoIterator { stream , cancel } , nil } 
func ( c APIClient ) FlushCommitF ( commits [ ] * pfs . Commit , toRepos [ ] * pfs . Repo , f func ( * pfs . CommitInfo ) error ) error { stream , err := c . PfsAPIClient . FlushCommit ( c . Ctx ( ) , & pfs . FlushCommitRequest { Commits : commits , ToRepos : toRepos , } , ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { ci , err := stream . Recv ( ) if err != nil { if err == io . EOF { return nil } return grpcutil . ScrubGRPC ( err ) } if err := f ( ci ) ; err != nil { return err } } } 
func ( c APIClient ) FlushCommitAll ( commits [ ] * pfs . Commit , toRepos [ ] * pfs . Repo ) ( [ ] * pfs . CommitInfo , error ) { var result [ ] * pfs . CommitInfo if err := c . FlushCommitF ( commits , toRepos , func ( ci * pfs . CommitInfo ) error { result = append ( result , ci ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func ( c APIClient ) SubscribeCommit ( repo string , branch string , from string , state pfs . CommitState ) ( CommitInfoIterator , error ) { ctx , cancel := context . WithCancel ( c . Ctx ( ) ) req := & pfs . SubscribeCommitRequest { Repo : NewRepo ( repo ) , Branch : branch , State : state , } if from != " " { req . From = NewCommit ( repo , from ) } stream , err := c . PfsAPIClient . SubscribeCommit ( ctx , req ) if err != nil { cancel ( ) return nil , grpcutil . ScrubGRPC ( err ) } return & commitInfoIterator { stream , cancel } , nil } 
func ( c APIClient ) SubscribeCommitF ( repo , branch , from string , state pfs . CommitState , f func ( * pfs . CommitInfo ) error ) error { req := & pfs . SubscribeCommitRequest { Repo : NewRepo ( repo ) , Branch : branch , State : state , } if from != " " { req . From = NewCommit ( repo , from ) } stream , err := c . PfsAPIClient . SubscribeCommit ( c . Ctx ( ) , req ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { ci , err := stream . Recv ( ) if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( ci ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } } } 
func ( c APIClient ) PutObjectAsync ( tags [ ] * pfs . Tag ) ( * PutObjectWriteCloserAsync , error ) { w , err := c . newPutObjectWriteCloserAsync ( tags ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return w , nil } 
func ( c APIClient ) PutObject ( _r io . Reader , tags ... string ) ( object * pfs . Object , _ int64 , retErr error ) { r := grpcutil . ReaderWrapper { _r } w , err := c . newPutObjectWriteCloser ( tags ... ) if err != nil { return nil , 0 , grpcutil . ScrubGRPC ( err ) } defer func ( ) { if err := w . Close ( ) ; err != nil && retErr == nil { retErr = grpcutil . ScrubGRPC ( err ) } if retErr == nil { object = w . object } } ( ) buf := grpcutil . GetBuffer ( ) defer grpcutil . PutBuffer ( buf ) written , err := io . CopyBuffer ( w , r , buf ) if err != nil { return nil , 0 , grpcutil . ScrubGRPC ( err ) } } 
func ( c APIClient ) PutObjectSplit ( _r io . Reader ) ( objects [ ] * pfs . Object , _ int64 , retErr error ) { r := grpcutil . ReaderWrapper { _r } w , err := c . newPutObjectSplitWriteCloser ( ) if err != nil { return nil , 0 , grpcutil . ScrubGRPC ( err ) } defer func ( ) { if err := w . Close ( ) ; err != nil && retErr == nil { retErr = grpcutil . ScrubGRPC ( err ) } if retErr == nil { objects = w . objects } } ( ) buf := grpcutil . GetBuffer ( ) defer grpcutil . PutBuffer ( buf ) written , err := io . CopyBuffer ( w , r , buf ) if err != nil { return nil , 0 , grpcutil . ScrubGRPC ( err ) } } 
func ( c APIClient ) GetObject ( hash string , writer io . Writer ) error { getObjectClient , err := c . ObjectAPIClient . GetObject ( c . Ctx ( ) , & pfs . Object { Hash : hash } , ) if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := grpcutil . WriteFromStreamingBytesClient ( getObjectClient , writer ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c APIClient ) GetObjectReader ( hash string ) ( io . ReadCloser , error ) { ctx , cancel := context . WithCancel ( c . Ctx ( ) ) getObjectClient , err := c . ObjectAPIClient . GetObject ( ctx , & pfs . Object { Hash : hash } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return grpcutil . NewStreamingBytesReader ( getObjectClient , cancel ) , nil } 
func ( c APIClient ) ReadObject ( hash string ) ( [ ] byte , error ) { var buffer bytes . Buffer if err := c . GetObject ( hash , & buffer ) ; err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return buffer . Bytes ( ) , nil } 
func ( c APIClient ) GetObjects ( hashes [ ] string , offset uint64 , size uint64 , totalSize uint64 , writer io . Writer ) error { var objects [ ] * pfs . Object for _ , hash := range hashes { objects = append ( objects , & pfs . Object { Hash : hash } ) } getObjectsClient , err := c . ObjectAPIClient . GetObjects ( c . Ctx ( ) , & pfs . GetObjectsRequest { Objects : objects , OffsetBytes : offset , SizeBytes : size , TotalSize : totalSize , } , ) if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := grpcutil . WriteFromStreamingBytesClient ( getObjectsClient , writer ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c APIClient ) ReadObjects ( hashes [ ] string , offset uint64 , size uint64 ) ( [ ] byte , error ) { var buffer bytes . Buffer if err := c . GetObjects ( hashes , offset , size , 0 , & buffer ) ; err != nil { return nil , err } return buffer . Bytes ( ) , nil } 
func ( c APIClient ) TagObject ( hash string , tags ... string ) error { var _tags [ ] * pfs . Tag for _ , tag := range tags { _tags = append ( _tags , & pfs . Tag { Name : tag } ) } if _ , err := c . ObjectAPIClient . TagObject ( c . Ctx ( ) , & pfs . TagObjectRequest { Object : & pfs . Object { Hash : hash } , Tags : _tags , } , ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c APIClient ) ListObject ( f func ( * pfs . Object ) error ) error { listObjectClient , err := c . ObjectAPIClient . ListObjects ( c . Ctx ( ) , & pfs . ListObjectsRequest { } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { object , err := listObjectClient . Recv ( ) if err != nil { if err == io . EOF { return nil } return grpcutil . ScrubGRPC ( err ) } if err := f ( object ) ; err != nil { return err } } } 
func ( c APIClient ) InspectObject ( hash string ) ( * pfs . ObjectInfo , error ) { value , err := c . ObjectAPIClient . InspectObject ( c . Ctx ( ) , & pfs . Object { Hash : hash } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return value , nil } 
func ( c APIClient ) GetTag ( tag string , writer io . Writer ) error { getTagClient , err := c . ObjectAPIClient . GetTag ( c . Ctx ( ) , & pfs . Tag { Name : tag } , ) if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := grpcutil . WriteFromStreamingBytesClient ( getTagClient , writer ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c APIClient ) GetTagReader ( tag string ) ( io . ReadCloser , error ) { ctx , cancel := context . WithCancel ( c . Ctx ( ) ) getTagClient , err := c . ObjectAPIClient . GetTag ( ctx , & pfs . Tag { Name : tag } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return grpcutil . NewStreamingBytesReader ( getTagClient , cancel ) , nil } 
func ( c APIClient ) ReadTag ( tag string ) ( [ ] byte , error ) { var buffer bytes . Buffer if err := c . GetTag ( tag , & buffer ) ; err != nil { return nil , err } return buffer . Bytes ( ) , nil } 
func ( c APIClient ) ListTag ( f func ( * pfs . ListTagsResponse ) error ) error { listTagClient , err := c . ObjectAPIClient . ListTags ( c . Ctx ( ) , & pfs . ListTagsRequest { IncludeObject : true } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { listTagResponse , err := listTagClient . Recv ( ) if err != nil { if err == io . EOF { return nil } return grpcutil . ScrubGRPC ( err ) } if err := f ( listTagResponse ) ; err != nil { return err } } } 
func ( c APIClient ) Compact ( ) error { _ , err := c . ObjectAPIClient . Compact ( c . Ctx ( ) , & types . Empty { } , ) return err } 
func ( c APIClient ) NewPutFileClient ( ) ( PutFileClient , error ) { pfc , err := c . PfsAPIClient . PutFile ( c . Ctx ( ) ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return & putFileClient { c : pfc } , nil } 
func ( c * putFileClient ) PutFileWriter ( repoName , commitID , path string ) ( io . WriteCloser , error ) { return c . newPutFileWriteCloser ( repoName , commitID , path , pfs . Delimiter_NONE , 0 , 0 , 0 , nil ) } 
func ( c * putFileClient ) PutFileSplitWriter ( repoName string , commitID string , path string , delimiter pfs . Delimiter , targetFileDatums int64 , targetFileBytes int64 , headerRecords int64 , overwrite bool ) ( io . WriteCloser , error ) { if overwrite { overwriteIndex = & pfs . OverwriteIndex { } } return c . newPutFileWriteCloser ( repoName , commitID , path , delimiter , targetFileDatums , targetFileBytes , headerRecords , overwriteIndex ) } 
func ( c * putFileClient ) PutFile ( repoName string , commitID string , path string , reader io . Reader ) ( _ int , retErr error ) { return c . PutFileSplit ( repoName , commitID , path , pfs . Delimiter_NONE , 0 , 0 , 0 , false , reader ) } 
func ( c * putFileClient ) PutFileOverwrite ( repoName string , commitID string , path string , reader io . Reader , overwriteIndex int64 ) ( _ int , retErr error ) { writer , err := c . newPutFileWriteCloser ( repoName , commitID , path , pfs . Delimiter_NONE , 0 , 0 , 0 , & pfs . OverwriteIndex { Index : overwriteIndex } ) if err != nil { return 0 , grpcutil . ScrubGRPC ( err ) } defer func ( ) { if err := writer . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) written , err := io . Copy ( writer , reader ) return int ( written ) , grpcutil . ScrubGRPC ( err ) } 
func ( c * putFileClient ) PutFileSplit ( repoName string , commitID string , path string , delimiter pfs . Delimiter , targetFileDatums int64 , targetFileBytes int64 , headerRecords int64 , overwrite bool , reader io . Reader ) ( _ int , retErr error ) { writer , err := c . PutFileSplitWriter ( repoName , commitID , path , delimiter , targetFileDatums , targetFileBytes , headerRecords , overwrite ) if err != nil { return 0 , grpcutil . ScrubGRPC ( err ) } defer func ( ) { if err := writer . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) buf := grpcutil . GetBuffer ( ) defer grpcutil . PutBuffer ( buf ) written , err := io . CopyBuffer ( writer , reader , buf ) return int ( written ) , grpcutil . ScrubGRPC ( err ) } 
func ( c * putFileClient ) PutFileURL ( repoName string , commitID string , path string , url string , recursive bool , overwrite bool ) ( retErr error ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) var overwriteIndex * pfs . OverwriteIndex if overwrite { overwriteIndex = & pfs . OverwriteIndex { } } if c . oneoff { defer func ( ) { if err := grpcutil . ScrubGRPC ( c . Close ( ) ) ; err != nil && retErr == nil { retErr = err } } ( ) } if err := c . c . Send ( & pfs . PutFileRequest { File : NewFile ( repoName , commitID , path ) , Url : url , Recursive : recursive , OverwriteIndex : overwriteIndex , } ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c * putFileClient ) Close ( ) error { _ , err := c . c . CloseAndRecv ( ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) PutFileWriter ( repoName string , commitID string , path string ) ( io . WriteCloser , error ) { pfc , err := c . newOneoffPutFileClient ( ) if err != nil { return nil , err } return pfc . PutFileWriter ( repoName , commitID , path ) } 
func ( c APIClient ) PutFileSplitWriter ( repoName string , commitID string , path string , delimiter pfs . Delimiter , targetFileDatums int64 , targetFileBytes int64 , headerRecords int64 , overwrite bool ) ( io . WriteCloser , error ) { pfc , err := c . newOneoffPutFileClient ( ) if err != nil { return nil , err } return pfc . PutFileSplitWriter ( repoName , commitID , path , delimiter , targetFileDatums , targetFileBytes , headerRecords , overwrite ) } 
func ( c APIClient ) PutFile ( repoName string , commitID string , path string , reader io . Reader ) ( _ int , retErr error ) { pfc , err := c . newOneoffPutFileClient ( ) if err != nil { return 0 , err } return pfc . PutFile ( repoName , commitID , path , reader ) } 
func ( c APIClient ) PutFileSplit ( repoName string , commitID string , path string , delimiter pfs . Delimiter , targetFileDatums int64 , targetFileBytes int64 , headerRecords int64 , overwrite bool , reader io . Reader ) ( _ int , retErr error ) { if err != nil { return 0 , err } return pfc . PutFileSplit ( repoName , commitID , path , delimiter , targetFileDatums , targetFileBytes , headerRecords , overwrite , reader ) } 
func ( c APIClient ) PutFileURL ( repoName string , commitID string , path string , url string , recursive bool , overwrite bool ) ( retErr error ) { pfc , err := c . newOneoffPutFileClient ( ) if err != nil { return err } return pfc . PutFileURL ( repoName , commitID , path , url , recursive , overwrite ) } 
func ( c APIClient ) CopyFile ( srcRepo , srcCommit , srcPath , dstRepo , dstCommit , dstPath string , overwrite bool ) error { if _ , err := c . PfsAPIClient . CopyFile ( c . Ctx ( ) , & pfs . CopyFileRequest { Src : NewFile ( srcRepo , srcCommit , srcPath ) , Dst : NewFile ( dstRepo , dstCommit , dstPath ) , Overwrite : overwrite , } ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c APIClient ) GetFile ( repoName string , commitID string , path string , offset int64 , size int64 , writer io . Writer ) error { if c . limiter != nil { c . limiter . Acquire ( ) defer c . limiter . Release ( ) } apiGetFileClient , err := c . getFile ( repoName , commitID , path , offset , size ) if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := grpcutil . WriteFromStreamingBytesClient ( apiGetFileClient , writer ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c APIClient ) GetFileReader ( repoName string , commitID string , path string , offset int64 , size int64 ) ( io . Reader , error ) { apiGetFileClient , err := c . getFile ( repoName , commitID , path , offset , size ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return grpcutil . NewStreamingBytesReader ( apiGetFileClient , nil ) , nil } 
func ( c APIClient ) GetFileReadSeeker ( repoName string , commitID string , path string ) ( io . ReadSeeker , error ) { fileInfo , err := c . InspectFile ( repoName , commitID , path ) if err != nil { return nil , err } reader , err := c . GetFileReader ( repoName , commitID , path , 0 , 0 ) if err != nil { return nil , err } return & getFileReadSeeker { Reader : reader , file : NewFile ( repoName , commitID , path ) , offset : 0 , size : int64 ( fileInfo . SizeBytes ) , c : c , } , nil } 
func ( c APIClient ) InspectFile ( repoName string , commitID string , path string ) ( * pfs . FileInfo , error ) { return c . inspectFile ( repoName , commitID , path ) } 
func ( c APIClient ) ListFile ( repoName string , commitID string , path string ) ( [ ] * pfs . FileInfo , error ) { var result [ ] * pfs . FileInfo if err := c . ListFileF ( repoName , commitID , path , 0 , func ( fi * pfs . FileInfo ) error { result = append ( result , fi ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func ( c APIClient ) ListFileHistory ( repoName string , commitID string , path string , history int64 ) ( [ ] * pfs . FileInfo , error ) { var result [ ] * pfs . FileInfo if err := c . ListFileF ( repoName , commitID , path , history , func ( fi * pfs . FileInfo ) error { result = append ( result , fi ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func ( c APIClient ) ListFileF ( repoName string , commitID string , path string , history int64 , f func ( fi * pfs . FileInfo ) error ) error { fs , err := c . PfsAPIClient . ListFileStream ( c . Ctx ( ) , & pfs . ListFileRequest { File : NewFile ( repoName , commitID , path ) , History : history , } , ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { fi , err := fs . Recv ( ) if err == io . EOF { return nil } else if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( fi ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } } 
func ( c APIClient ) GlobFile ( repoName string , commitID string , pattern string ) ( [ ] * pfs . FileInfo , error ) { fs , err := c . PfsAPIClient . GlobFileStream ( c . Ctx ( ) , & pfs . GlobFileRequest { Commit : NewCommit ( repoName , commitID ) , Pattern : pattern , } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } var result [ ] * pfs . FileInfo for { f , err := fs . Recv ( ) if err == io . EOF { break } else if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } result = append ( result , f ) } return result , nil } 
func ( c APIClient ) GlobFileF ( repoName string , commitID string , pattern string , f func ( fi * pfs . FileInfo ) error ) error { fs , err := c . PfsAPIClient . GlobFileStream ( c . Ctx ( ) , & pfs . GlobFileRequest { Commit : NewCommit ( repoName , commitID ) , Pattern : pattern , } , ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { fi , err := fs . Recv ( ) if err == io . EOF { return nil } else if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( fi ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } } 
func ( c APIClient ) DiffFile ( newRepoName , newCommitID , newPath , oldRepoName , oldCommitID , oldPath string , shallow bool ) ( [ ] * pfs . FileInfo , [ ] * pfs . FileInfo , error ) { var oldFile * pfs . File if oldRepoName != " " { oldFile = NewFile ( oldRepoName , oldCommitID , oldPath ) } resp , err := c . PfsAPIClient . DiffFile ( c . Ctx ( ) , & pfs . DiffFileRequest { NewFile : NewFile ( newRepoName , newCommitID , newPath ) , OldFile : oldFile , Shallow : shallow , } , ) if err != nil { return nil , nil , grpcutil . ScrubGRPC ( err ) } return resp . NewFiles , resp . OldFiles , nil } 
func ( c APIClient ) Walk ( repoName string , commitID string , path string , f WalkFn ) error { fs , err := c . PfsAPIClient . WalkFile ( c . Ctx ( ) , & pfs . WalkFileRequest { File : NewFile ( repoName , commitID , path ) } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { fi , err := fs . Recv ( ) if err == io . EOF { return nil } else if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( fi ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } } 
func ( c APIClient ) DeleteFile ( repoName string , commitID string , path string ) error { _ , err := c . PfsAPIClient . DeleteFile ( c . Ctx ( ) , & pfs . DeleteFileRequest { File : NewFile ( repoName , commitID , path ) , } , ) return err } 
func ( w * PutObjectWriteCloserAsync ) Write ( p [ ] byte ) ( int , error ) { select { case err := <- w . errChan : if err != nil { return 0 , grpcutil . ScrubGRPC ( err ) } default : for len ( w . buf ) + len ( p ) > cap ( w . buf ) { w . buf = append ( w . buf , p [ : i ] ... ) p = p [ i : ] w . writeChan <- w . buf w . buf = grpcutil . GetBuffer ( ) [ : 0 ] } w . buf = append ( w . buf , p ... ) } return len ( p ) , nil } 
func ( w * PutObjectWriteCloserAsync ) Close ( ) error { w . writeChan <- w . buf close ( w . writeChan ) err := <- w . errChan if err != nil { return grpcutil . ScrubGRPC ( err ) } w . object , err = w . client . CloseAndRecv ( ) return grpcutil . ScrubGRPC ( err ) } 
func ( w * PutObjectWriteCloserAsync ) Object ( ) ( * pfs . Object , error ) { select { case err := <- w . errChan : if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return w . object , nil default : return nil , fmt . Errorf ( " " ) } } 
func PrettyPrintVersion ( version * pb . Version ) string { result := PrettyPrintVersionNoAdditional ( version ) if version . Additional != " " { result += fmt . Sprintf ( " " , version . Additional ) } return result } 
func PrettyPrintVersionNoAdditional ( version * pb . Version ) string { return fmt . Sprintf ( " " , version . Major , version . Minor , version . Micro ) } 
func recursiveBlockQuoteExamples ( parent * cobra . Command ) { if parent . Example != " " { parent . Example = fmt . Sprintf ( " \n \n " , parent . Example ) } for _ , cmd := range parent . Commands ( ) { recursiveBlockQuoteExamples ( cmd ) } } 
func errMissingField ( field string ) * logical . Response { return logical . ErrorResponse ( fmt . Sprintf ( " " , field ) ) } 
func validateFields ( req * logical . Request , data * framework . FieldData ) error { var unknownFields [ ] string for k := range req . Data { if _ , ok := data . Schema [ k ] ; ! ok { unknownFields = append ( unknownFields , k ) } } if len ( unknownFields ) > 0 { return fmt . Errorf ( " " , unknownFields ) } return nil } 
func putConfig ( ctx context . Context , s logical . Storage , cfg * config ) error { entry , err := logical . StorageEntryJSON ( " " , cfg ) if err != nil { return fmt . Errorf ( " " , err ) } if err := s . Put ( ctx , entry ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func getConfig ( ctx context . Context , s logical . Storage ) ( * config , error ) { entry , err := s . Get ( ctx , " " ) if err != nil { return nil , fmt . Errorf ( " " , err ) } if entry == nil || len ( entry . Value ) == 0 { return nil , errors . New ( " " ) } var result config if err := entry . DecodeJSON ( & result ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } return & result , nil } 
func getStringField ( data * framework . FieldData , key string ) ( string , * logical . Response ) { valueIface , ok , err := data . GetOkErr ( key ) if err != nil { return " " , logical . ErrorResponse ( fmt . Sprintf ( " " , err , key ) ) } } value , ok := valueIface . ( string ) if ! ok { return " " , logical . ErrorResponse ( fmt . Sprintf ( " " , key , valueIface ) ) } return value , nil } 
func Serve ( servers ... ServerOptions , ) ( retErr error ) { for _ , server := range servers { if server . RegisterFunc == nil { return ErrMustSpecifyRegisterFunc } if server . Port == 0 { return ErrMustSpecifyPort } opts := [ ] grpc . ServerOption { grpc . MaxConcurrentStreams ( math . MaxUint32 ) , grpc . MaxRecvMsgSize ( server . MaxMsgSize ) , grpc . MaxSendMsgSize ( server . MaxMsgSize ) , grpc . KeepaliveEnforcementPolicy ( keepalive . EnforcementPolicy { MinTime : 5 * time . Second , PermitWithoutStream : true , } ) , grpc . UnaryInterceptor ( tracing . UnaryServerInterceptor ( ) ) , grpc . StreamInterceptor ( tracing . StreamServerInterceptor ( ) ) , } if server . PublicPortTLSAllowed { keyPath := path . Join ( TLSVolumePath , TLSKeyFile ) _ , certPathStatErr := os . Stat ( certPath ) _ , keyPathStatErr := os . Stat ( keyPath ) if certPathStatErr != nil { log . Warnf ( " " , certPath , certPathStatErr ) } if keyPathStatErr != nil { log . Warnf ( " " , keyPath , keyPathStatErr ) } if certPathStatErr == nil && keyPathStatErr == nil { if err != nil { return fmt . Errorf ( " " , err ) } opts = append ( opts , grpc . Creds ( transportCreds ) ) } } grpcServer := grpc . NewServer ( opts ... ) if err := server . RegisterFunc ( grpcServer ) ; err != nil { return err } listener , err := net . Listen ( " " , fmt . Sprintf ( " " , server . Port ) ) if err != nil { return err } if server . Cancel != nil { go func ( ) { <- server . Cancel if err := listener . Close ( ) ; err != nil { fmt . Printf ( " \n " , err ) } } ( ) } if err := grpcServer . Serve ( listener ) ; err != nil { return err } } return nil } 
func NewPuller ( ) * Puller { return & Puller { errCh : make ( chan error , 1 ) , pipes : make ( map [ string ] bool ) , } } 
func ( p * Puller ) Pull ( client * pachclient . APIClient , root string , repo , commit , file string , pipes bool , emptyFiles bool , concurrency int , statsTree * hashtree . Ordered , statsRoot string ) error { limiter := limit . New ( concurrency ) var eg errgroup . Group if err := client . Walk ( repo , commit , file , func ( fileInfo * pfs . FileInfo ) error { basepath , err := filepath . Rel ( file , fileInfo . File . Path ) if err != nil { return err } if statsTree != nil { statsPath := filepath . Join ( statsRoot , basepath ) if fileInfo . FileType == pfs . FileType_DIR { statsTree . PutDir ( statsPath ) } else { var blockRefs [ ] * pfs . BlockRef for _ , object := range fileInfo . Objects { objectInfo , err := client . InspectObject ( object . Hash ) if err != nil { return err } blockRefs = append ( blockRefs , objectInfo . BlockRef ) } blockRefs = append ( blockRefs , fileInfo . BlockRefs ... ) statsTree . PutFile ( statsPath , fileInfo . Hash , int64 ( fileInfo . SizeBytes ) , & hashtree . FileNodeProto { BlockRefs : blockRefs } ) } } path := filepath . Join ( root , basepath ) if fileInfo . FileType == pfs . FileType_DIR { return os . MkdirAll ( path , 0700 ) } if pipes { return p . makePipe ( path , func ( w io . Writer ) error { return client . GetFile ( repo , commit , fileInfo . File . Path , 0 , 0 , w ) } ) } if emptyFiles { return p . makeFile ( path , func ( w io . Writer ) error { return nil } ) } eg . Go ( func ( ) ( retErr error ) { limiter . Acquire ( ) defer limiter . Release ( ) return p . makeFile ( path , func ( w io . Writer ) error { return client . GetFile ( repo , commit , fileInfo . File . Path , 0 , 0 , w ) } ) } ) return nil } ) ; err != nil { return err } return eg . Wait ( ) } 
func ( p * Puller ) PullDiff ( client * pachclient . APIClient , root string , newRepo , newCommit , newPath , oldRepo , oldCommit , oldPath string , newOnly bool , pipes bool , emptyFiles bool , concurrency int , tree hashtree . HashTree , treeRoot string ) error { limiter := limit . New ( concurrency ) var eg errgroup . Group newFiles , oldFiles , err := client . DiffFile ( newRepo , newCommit , newPath , oldRepo , oldCommit , oldPath , false ) if err != nil { return err } for _ , newFile := range newFiles { basepath , err := filepath . Rel ( newPath , newFile . File . Path ) if err != nil { return err } if tree != nil { treePath := path . Join ( treeRoot , " " , basepath ) if newOnly { treePath = path . Join ( treeRoot , basepath ) } if err := tree . PutFile ( treePath , newFile . Objects , int64 ( newFile . SizeBytes ) ) ; err != nil { return err } } path := filepath . Join ( root , " " , basepath ) if newOnly { path = filepath . Join ( root , basepath ) } if pipes { if err := p . makePipe ( path , func ( w io . Writer ) error { return client . GetFile ( newFile . File . Commit . Repo . Name , newFile . File . Commit . ID , newFile . File . Path , 0 , 0 , w ) } ) ; err != nil { return err } } else if emptyFiles { if err := p . makeFile ( path , func ( w io . Writer ) error { return nil } ) ; err != nil { return err } } else { newFile := newFile limiter . Acquire ( ) eg . Go ( func ( ) error { defer limiter . Release ( ) return p . makeFile ( path , func ( w io . Writer ) error { return client . GetFile ( newFile . File . Commit . Repo . Name , newFile . File . Commit . ID , newFile . File . Path , 0 , 0 , w ) } ) } ) } } if ! newOnly { for _ , oldFile := range oldFiles { basepath , err := filepath . Rel ( oldPath , oldFile . File . Path ) if err != nil { return err } if tree != nil { treePath := path . Join ( treeRoot , " " , basepath ) if err := tree . PutFile ( treePath , oldFile . Objects , int64 ( oldFile . SizeBytes ) ) ; err != nil { return err } } path := filepath . Join ( root , " " , basepath ) if pipes { if err := p . makePipe ( path , func ( w io . Writer ) error { return client . GetFile ( oldFile . File . Commit . Repo . Name , oldFile . File . Commit . ID , oldFile . File . Path , 0 , 0 , w ) } ) ; err != nil { return err } } else { oldFile := oldFile limiter . Acquire ( ) eg . Go ( func ( ) error { defer limiter . Release ( ) return p . makeFile ( path , func ( w io . Writer ) error { return client . GetFile ( oldFile . File . Commit . Repo . Name , oldFile . File . Commit . ID , oldFile . File . Path , 0 , 0 , w ) } ) } ) } } } return eg . Wait ( ) } 
func ( p * Puller ) PullTree ( client * pachclient . APIClient , root string , tree hashtree . HashTree , pipes bool , concurrency int ) error { limiter := limit . New ( concurrency ) var eg errgroup . Group if err := tree . Walk ( " " , func ( path string , node * hashtree . NodeProto ) error { if node . FileNode != nil { path := filepath . Join ( root , path ) var hashes [ ] string for _ , object := range node . FileNode . Objects { hashes = append ( hashes , object . Hash ) } if pipes { return p . makePipe ( path , func ( w io . Writer ) error { return client . GetObjects ( hashes , 0 , 0 , uint64 ( node . SubtreeSize ) , w ) } ) } limiter . Acquire ( ) eg . Go ( func ( ) ( retErr error ) { defer limiter . Release ( ) return p . makeFile ( path , func ( w io . Writer ) error { return client . GetObjects ( hashes , 0 , 0 , uint64 ( node . SubtreeSize ) , w ) } ) } ) } return nil } ) ; err != nil { return err } return eg . Wait ( ) } 
func ( p * Puller ) CleanUp ( ) ( int64 , error ) { var result error select { case result = <- p . errCh : default : } func ( ) { p . Lock ( ) defer p . Unlock ( ) p . cleaned = true for path := range p . pipes { f , err := os . OpenFile ( path , syscall . O_NONBLOCK + os . O_RDONLY , os . ModeNamedPipe ) if err != nil && result == nil { result = err } pipes = append ( pipes , f ) } p . pipes = make ( map [ string ] bool ) } ( ) } } size := p . size p . size = 0 return size , result } 
func Push ( client * pachclient . APIClient , root string , commit * pfs . Commit , overwrite bool ) error { var g errgroup . Group if err := filepath . Walk ( root , func ( path string , info os . FileInfo , err error ) error { g . Go ( func ( ) ( retErr error ) { if path == root || info . IsDir ( ) { return nil } f , err := os . Open ( path ) if err != nil { return err } defer func ( ) { if err := f . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) relPath , err := filepath . Rel ( root , path ) if err != nil { return err } if overwrite { if err := client . DeleteFile ( commit . Repo . Name , commit . ID , relPath ) ; err != nil { return err } } _ , err = client . PutFile ( commit . Repo . Name , commit . ID , relPath , f ) return err } ) return nil } ) ; err != nil { return err } return g . Wait ( ) } 
func PushObj ( pachClient * pachclient . APIClient , commit * pfs . Commit , objClient obj . Client , root string ) error { var eg errgroup . Group sem := make ( chan struct { } , 200 ) if err := pachClient . Walk ( commit . Repo . Name , commit . ID , " " , func ( fileInfo * pfs . FileInfo ) error { if fileInfo . FileType != pfs . FileType_FILE { return nil } eg . Go ( func ( ) ( retErr error ) { sem <- struct { } { } defer func ( ) { <- sem } ( ) w , err := objClient . Writer ( pachClient . Ctx ( ) , filepath . Join ( root , fileInfo . File . Path ) ) if err != nil { return err } defer func ( ) { if err := w . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return pachClient . GetFile ( commit . Repo . Name , commit . ID , fileInfo . File . Path , 0 , 0 , w ) } ) return nil } ) ; err != nil { return err } return eg . Wait ( ) } 
func PushFile ( c * pachclient . APIClient , pfc pachclient . PutFileClient , pfsFile * pfs . File , osFile io . ReadSeeker ) error { fileInfo , err := c . InspectFile ( pfsFile . Commit . Repo . Name , pfsFile . Commit . ID , pfsFile . Path ) if err != nil && ! isNotExist ( err ) { return err } var i int var object * pfs . Object if fileInfo != nil { for i , object = range fileInfo . Objects { hash := pfs . NewHash ( ) if _ , err := io . CopyN ( hash , osFile , pfs . ChunkSize ) ; err != nil { if err == io . EOF { break } return err } if object . Hash != pfs . EncodeHash ( hash . Sum ( nil ) ) { break } } } if _ , err := osFile . Seek ( int64 ( i ) * pfs . ChunkSize , 0 ) ; err != nil { return err } _ , err = pfc . PutFileOverwrite ( pfsFile . Commit . Repo . Name , pfsFile . Commit . ID , pfsFile . Path , osFile , int64 ( i ) ) return err } 
func ( c APIClient ) Dump ( w io . Writer ) error { goroClient , err := c . DebugClient . Dump ( c . Ctx ( ) , & debug . DumpRequest { } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } return grpcutil . ScrubGRPC ( grpcutil . WriteFromStreamingBytesClient ( goroClient , w ) ) } 
func ( c APIClient ) Profile ( profile string , duration time . Duration , w io . Writer ) error { var d * types . Duration if duration != 0 { d = types . DurationProto ( duration ) } profileClient , err := c . DebugClient . Profile ( c . Ctx ( ) , & debug . ProfileRequest { Profile : profile , Duration : d , } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } return grpcutil . ScrubGRPC ( grpcutil . WriteFromStreamingBytesClient ( profileClient , w ) ) } 
func ( c APIClient ) Binary ( w io . Writer ) error { binaryClient , err := c . DebugClient . Binary ( c . Ctx ( ) , & debug . BinaryRequest { } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } return grpcutil . ScrubGRPC ( grpcutil . WriteFromStreamingBytesClient ( binaryClient , w ) ) } 
func RegisterCacheStats ( cacheName string , groupCacheStats * groupcache . Stats ) { c := & cacheStats { cacheName : cacheName , descriptions : make ( map [ string ] * prometheus . Desc ) , stats : groupCacheStats , } if err := prometheus . Register ( c ) ; err != nil { } } } 
func ( c * counter ) wait ( n int64 ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) for c . n < n { c . cond . Wait ( ) } } 
func ( c * counter ) cancel ( ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) c . n = math . MaxInt64 } 
func RunWorkload ( client * client . APIClient , rand * rand . Rand , size int , ) error { worker := newWorker ( rand ) for i := 0 ; i < size ; i ++ { if err := worker . work ( client ) ; err != nil { return err } } for _ , job := range worker . startedJobs { jobInfo , err := client . InspectJob ( job . ID , true ) if err != nil { return err } if jobInfo . State != pps . JobState_JOB_SUCCESS { return fmt . Errorf ( " " , job . ID ) } } return nil } 
func ( w * worker ) createRepo ( c * client . APIClient ) error { repoName := w . randString ( 10 ) if err := c . CreateRepo ( repoName ) ; err != nil { return err } w . repos = append ( w . repos , & pfs . Repo { Name : repoName } ) if err != nil { return err } w . started = append ( w . started , commit ) return nil } 
func ( w * worker ) advanceCommit ( c * client . APIClient ) error { if len ( w . started ) >= maxStartedCommits || len ( w . finished ) == 0 { } i := w . rand . Intn ( len ( w . started ) ) commit := w . started [ i ] } if err := c . FinishCommit ( commit . Repo . Name , commit . ID ) ; err != nil { return err } w . finished = append ( w . finished , commit ) } else { commit , err := c . StartCommitParent ( commit . Repo . Name , " " , commit . ID ) if err != nil { return err } w . started = append ( w . started , commit ) } return nil } 
func ( w * worker ) putFile ( c * client . APIClient ) error { if len ( w . started ) == 0 { return nil } commit := w . started [ w . rand . Intn ( len ( w . started ) ) ] if _ , err := c . PutFile ( commit . Repo . Name , commit . ID , w . randString ( 10 ) , w . reader ( ) ) ; err != nil { return err } return nil } 
func RandString ( r * rand . Rand , n int ) string { b := make ( [ ] byte , n ) for i := range b { b [ i ] = letters [ r . Intn ( len ( letters ) ) ] } return string ( b ) } 
func NewReader ( rand * rand . Rand , bytes int64 ) io . Reader { return & reader { rand : rand , bytes : bytes , } } 
func NewDBHashTree ( storageRoot string ) ( HashTree , error ) { file := dbFile ( storageRoot ) if err := os . MkdirAll ( pathlib . Dir ( file ) , 0777 ) ; err != nil { return nil , err } result , err := newDBHashTree ( file ) if err != nil { return nil , err } if err := result . PutDir ( " " ) ; err != nil { return nil , err } return result , err } 
func DeserializeDBHashTree ( storageRoot string , r io . Reader ) ( _ HashTree , retErr error ) { result , err := NewDBHashTree ( storageRoot ) if err != nil { return nil , err } if err := result . Deserialize ( r ) ; err != nil { return nil , err } return result , nil } 
func ( h * dbHashTree ) Get ( path string ) ( * NodeProto , error ) { path = clean ( path ) var node * NodeProto if err := h . View ( func ( tx * bolt . Tx ) error { var err error node , err = get ( tx , path ) return err } ) ; err != nil { return nil , err } return node , nil } 
func Get ( rs [ ] io . ReadCloser , filePath string ) ( * NodeProto , error ) { filePath = clean ( filePath ) var fileNode * NodeProto if err := nodes ( rs , func ( path string , node * NodeProto ) error { if path == filePath { fileNode = node } return nil } ) ; err != nil { return nil , err } if fileNode == nil { return nil , errorf ( PathNotFound , " \" \" " , filePath ) } return fileNode , nil } 
func iterDir ( tx * bolt . Tx , path string , f func ( k , v [ ] byte , c * bolt . Cursor ) error ) error { node , err := get ( tx , path ) if err != nil { return err } if node . DirNode == nil { return errorf ( PathConflict , " \" \" " , path ) } c := NewChildCursor ( tx , path ) for k , v := c . K ( ) , c . V ( ) ; k != nil ; k , v = c . Next ( ) { if err := f ( k , v , c . c ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } return nil } 
func ( h * dbHashTree ) List ( path string , f func ( * NodeProto ) error ) error { path = clean ( path ) return h . View ( func ( tx * bolt . Tx ) error { return list ( tx , path , f ) } ) } 
func ( h * dbHashTree ) ListAll ( path string ) ( [ ] * NodeProto , error ) { var result [ ] * NodeProto if err := h . List ( path , func ( node * NodeProto ) error { result = append ( result , node ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func List ( rs [ ] io . ReadCloser , pattern string , f func ( string , * NodeProto ) error ) ( retErr error ) { pattern = clean ( pattern ) if pattern == " " { pattern = " " } g , err := globlib . Compile ( pattern , '/' ) if err != nil { return errorf ( MalformedGlob , err . Error ( ) ) } return nodes ( rs , func ( path string , node * NodeProto ) error { if ( g . Match ( path ) && node . DirNode == nil ) || ( g . Match ( pathlib . Dir ( path ) ) ) { return f ( path , node ) } return nil } ) } 
func ( h * dbHashTree ) Glob ( pattern string , f func ( string , * NodeProto ) error ) error { pattern = clean ( pattern ) return h . View ( func ( tx * bolt . Tx ) error { return glob ( tx , pattern , f ) } ) } 
func Glob ( rs [ ] io . ReadCloser , pattern string , f func ( string , * NodeProto ) error ) ( retErr error ) { pattern = clean ( pattern ) g , err := globlib . Compile ( pattern , '/' ) if err != nil { return errorf ( MalformedGlob , err . Error ( ) ) } return nodes ( rs , func ( path string , node * NodeProto ) error { if g . Match ( path ) { return f ( externalDefault ( path ) , node ) } return nil } ) } 
func ( h * dbHashTree ) FSSize ( ) int64 { rootNode , err := h . Get ( " " ) if err != nil { return 0 } return rootNode . SubtreeSize } 
func ( h * dbHashTree ) Walk ( path string , f func ( path string , node * NodeProto ) error ) error { path = clean ( path ) return h . View ( func ( tx * bolt . Tx ) error { c := fs ( tx ) . Cursor ( ) for k , v := c . Seek ( b ( path ) ) ; k != nil && strings . HasPrefix ( s ( k ) , path ) ; k , v = c . Next ( ) { node := & NodeProto { } if err := node . Unmarshal ( v ) ; err != nil { return err } nodePath := s ( k ) if nodePath == " " { nodePath = " " } if nodePath != path && ! strings . HasPrefix ( nodePath , path + " " ) { } if err := f ( nodePath , node ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } return nil } ) } 
func Walk ( rs [ ] io . ReadCloser , walkPath string , f func ( path string , node * NodeProto ) error ) error { walkPath = clean ( walkPath ) return nodes ( rs , func ( path string , node * NodeProto ) error { if path == " " { path = " " } if path != walkPath && ! strings . HasPrefix ( path , walkPath + " " ) { return nil } if err := f ( path , node ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } return nil } ) } 
func ( h * dbHashTree ) Diff ( oldHashTree HashTree , newPath string , oldPath string , recursiveDepth int64 , f func ( path string , node * NodeProto , new bool ) error ) ( retErr error ) { if old == nil { return fmt . Errorf ( " " ) } rollback := func ( tx * bolt . Tx ) { if err := tx . Rollback ( ) ; err != nil && retErr == nil { retErr = err } } var newTx * bolt . Tx var oldTx * bolt . Tx if h == oldHashTree { tx , err := h . Begin ( false ) if err != nil { return err } newTx = tx oldTx = tx defer rollback ( tx ) } else { var err error newTx , err = h . Begin ( false ) if err != nil { return err } defer rollback ( newTx ) oldTx , err = old . Begin ( false ) if err != nil { return err } defer rollback ( oldTx ) } return diff ( newTx , oldTx , newPath , oldPath , recursiveDepth , f ) } 
func ( h * dbHashTree ) Serialize ( _w io . Writer ) error { w := pbutil . NewWriter ( _w ) return h . View ( func ( tx * bolt . Tx ) error { for _ , bucket := range buckets { b := tx . Bucket ( b ( bucket ) ) if _ , err := w . Write ( & BucketHeader { Bucket : bucket , } ) ; err != nil { return err } if err := b . ForEach ( func ( k , v [ ] byte ) error { if _ , err := w . WriteBytes ( k ) ; err != nil { return err } _ , err := w . WriteBytes ( v ) return err } ) ; err != nil { return err } if _ , err := w . WriteBytes ( SentinelByte ) ; err != nil { return err } } return nil } ) } 
func ( h * dbHashTree ) Deserialize ( _r io . Reader ) error { r := pbutil . NewReader ( _r ) hdr := & BucketHeader { } batchSize := 10000 kvs := make ( chan * keyValue , batchSize / 10 ) eg . Go ( func ( ) error { var bucket [ ] byte for { count := 0 if err := h . Update ( func ( tx * bolt . Tx ) error { if bucket != nil { tx . Bucket ( bucket ) . FillPercent = 1 } for kv := range kvs { if kv . k == nil { bucket = kv . v continue } if err := tx . Bucket ( bucket ) . Put ( kv . k , kv . v ) ; err != nil { return err } count ++ if count >= batchSize { return nil } } return nil } ) ; err != nil || copyCtx . Err ( ) != nil { return err } if count <= 0 { return nil } } } ) eg . Go ( func ( ) error { defer close ( kvs ) for { hdr . Reset ( ) } return err } bucket := b ( hdr . Bucket ) select { case kvs <- & keyValue { nil , bucket } : case <- copyCtx . Done ( ) : return nil } for { _k , err := r . ReadBytes ( ) if err != nil { return err } if bytes . Equal ( _k , SentinelByte ) { break } copy ( k , _k ) _v , err := r . ReadBytes ( ) if err != nil { return err } v := make ( [ ] byte , len ( _v ) ) copy ( v , _v ) select { case kvs <- & keyValue { k , v } : case <- copyCtx . Done ( ) : return nil } } } return nil } ) return eg . Wait ( ) } 
func ( h * dbHashTree ) Copy ( ) ( HashTree , error ) { if err := h . Hash ( ) ; err != nil { return nil , err } r , w := io . Pipe ( ) var eg errgroup . Group eg . Go ( func ( ) ( retErr error ) { defer func ( ) { if err := w . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return h . Serialize ( w ) } ) var result HashTree eg . Go ( func ( ) error { var err error result , err = DeserializeDBHashTree ( pathlib . Dir ( h . Path ( ) ) , r ) return err } ) if err := eg . Wait ( ) ; err != nil { return nil , err } return result , nil } 
func ( h * dbHashTree ) Destroy ( ) error { path := h . Path ( ) if err := h . Close ( ) ; err != nil { return err } return os . Remove ( path ) } 
func visit ( tx * bolt . Tx , path string , update updateFn ) error { for path != " " { parent , child := split ( path ) pnode , err := get ( tx , parent ) if err != nil && Code ( err ) != PathNotFound { return err } if pnode != nil && pnode . nodetype ( ) != directory { return errorf ( PathConflict , " \" \" " + " " , path ) } if pnode == nil { pnode = & NodeProto { } } if err := update ( pnode , parent , child ) ; err != nil { return err } if err := put ( tx , parent , pnode ) ; err != nil { return err } path = parent } return nil } 
func ( h * dbHashTree ) PutFile ( path string , objects [ ] * pfs . Object , size int64 ) error { return h . putFile ( path , objects , nil , size , false ) } 
func ( h * dbHashTree ) PutFileOverwrite ( path string , objects [ ] * pfs . Object , overwriteIndex * pfs . OverwriteIndex , sizeDelta int64 ) error { return h . putFile ( path , objects , overwriteIndex , sizeDelta , false ) } 
func ( h * dbHashTree ) PutDirHeaderFooter ( path string , header , footer * pfs . Object , headerSize , footerSize int64 ) error { path = clean ( path ) return h . Batch ( func ( tx * bolt . Tx ) error { if err != nil && Code ( err ) != PathNotFound { return errorf ( Internal , " " , path , err ) } if node != nil && node . nodetype ( ) != directory { return errorf ( PathConflict , " " + " " , path , node . nodetype ( ) ) } if node == nil { newNode = true node = & NodeProto { Name : base ( path ) , DirNode : & DirectoryNodeProto { Shared : & Shared { } , } , } footerSame := ( node . DirNode . Shared . Footer == nil && footer == nil ) || ( node . DirNode . Shared . Footer != nil && node . DirNode . Shared . Footer . Hash == footer . Hash ) if newNode || ! headerSame || ! footerSame { node . DirNode . Shared = & Shared { Header : header , Footer : footer , HeaderSize : headerSize , FooterSize : footerSize , } return put ( tx , path , node ) } return nil } ) } 
func ( h * dbHashTree ) PutFileHeaderFooter ( path string , objects [ ] * pfs . Object , size int64 ) error { return h . putFile ( path , objects , nil , size , true ) } 
func ( h * dbHashTree ) PutDir ( path string ) error { path = clean ( path ) return h . Batch ( func ( tx * bolt . Tx ) error { node , err := get ( tx , path ) if err != nil && Code ( err ) != PathNotFound { return err } if node != nil { if node . nodetype ( ) == directory { return nil } else if node . nodetype ( ) != none { return errorf ( PathConflict , " \" \" " + " " , path , node . nodetype ( ) ) } } node = & NodeProto { Name : base ( path ) , DirNode : & DirectoryNodeProto { } , } if err := put ( tx , path , node ) ; err != nil { return err } return visit ( tx , path , func ( node * NodeProto , parent , child string ) error { if node . DirNode == nil { node . DirNode = & DirectoryNodeProto { } } return nil } ) } ) } 
func deleteDir ( tx * bolt . Tx , path string ) error { c := fs ( tx ) . Cursor ( ) prefix := append ( b ( path ) , nullByte [ 0 ] ) for k , _ := c . Seek ( prefix ) ; bytes . HasPrefix ( k , prefix ) ; k , _ = c . Next ( ) { if err := c . Delete ( ) ; err != nil { return err } } return fs ( tx ) . Delete ( b ( path ) ) } 
func ( h * dbHashTree ) DeleteFile ( path string ) error { path = clean ( path ) } return h . Batch ( func ( tx * bolt . Tx ) error { if err := glob ( tx , path , func ( path string , node * NodeProto ) error { } } size := node . SubtreeSize pnode , err := get ( tx , parent ) if err != nil { if Code ( err ) == PathNotFound { return errorf ( Internal , " \" \" " , path ) } return err } if pnode . DirNode == nil { return errorf ( Internal , " \" \" \" \" " + " " , path , pnode . DirNode ) } put ( tx , parent , pnode ) } node . SubtreeSize -= size return nil } ) ; err != nil { return err } return nil } ) ; err != nil && Code ( err ) != PathNotFound { } return nil } ) } 
func NewReader ( r io . Reader , filter Filter ) * Reader { return & Reader { pbr : pbutil . NewReader ( r ) , filter : filter , } } 
func ( r * Reader ) Read ( ) ( * MergeNode , error ) { _k , err := r . pbr . ReadBytes ( ) if err != nil { return nil , err } if r . filter != nil { for { if r . filter ( _k ) { break } _ , err = r . pbr . ReadBytes ( ) if err != nil { return nil , err } _k , err = r . pbr . ReadBytes ( ) if err != nil { return nil , err } } } k := make ( [ ] byte , len ( _k ) ) copy ( k , _k ) _v , err := r . pbr . ReadBytes ( ) if err != nil { return nil , err } v := make ( [ ] byte , len ( _v ) ) copy ( v , _v ) return & MergeNode { k : k , v : v , } , nil } 
func NewWriter ( w io . Writer ) * Writer { return & Writer { pbw : pbutil . NewWriter ( w ) , } } 
func ( w * Writer ) Write ( n * MergeNode ) error { n . v , err = n . nodeProto . Marshal ( ) if err != nil { return err } } if err := n . nodeProto . Unmarshal ( n . v ) ; err != nil { return err } } w . size = uint64 ( n . nodeProto . SubtreeSize ) } } b , err := w . pbw . WriteBytes ( n . k ) if err != nil { return err } w . offset += uint64 ( b ) b , err = w . pbw . WriteBytes ( n . v ) if err != nil { return err } w . offset += uint64 ( b ) return nil } 
func ( w * Writer ) Copy ( r * Reader ) error { for { n , err := r . Read ( ) if err != nil { if err == io . EOF { return nil } return err } if err := w . Write ( n ) ; err != nil { return err } } } 
func ( w * Writer ) Index ( ) ( [ ] byte , error ) { buf := & bytes . Buffer { } pbw := pbutil . NewWriter ( buf ) for _ , idx := range w . idxs { if _ , err := pbw . Write ( idx ) ; err != nil { return nil , err } } return buf . Bytes ( ) , nil } 
func GetRangeFromIndex ( r io . Reader , prefix string ) ( uint64 , uint64 , error ) { prefix = clean ( prefix ) pbr := pbutil . NewReader ( r ) idx := & Index { } k := b ( prefix ) var lower , upper uint64 iter := func ( f func ( int ) bool ) error { for { if err := pbr . Read ( idx ) ; err != nil { if err == io . EOF { break } return err } var cmp int if len ( k ) < len ( idx . K ) { cmp = bytes . Compare ( k , idx . K [ : len ( k ) ] ) } else { cmp = bytes . Compare ( k [ : len ( idx . K ) ] , idx . K ) } if f ( cmp ) { break } } return nil } low := func ( cmp int ) bool { if cmp > 0 { lower = idx . Offset return false } else if cmp < 0 { } return true } up := func ( cmp int ) bool { if cmp < 0 { upper = idx . Offset return true } return false } } } } 
func NewFilter ( numTrees int64 , tree int64 ) Filter { return func ( k [ ] byte ) bool { if pathToTree ( k , numTrees ) == uint64 ( tree ) { return true } return false } } 
func PathToTree ( path string , numTrees int64 ) uint64 { path = clean ( path ) return pathToTree ( b ( path ) , numTrees ) } 
func Merge ( w * Writer , rs [ ] * Reader ) error { if len ( rs ) == 0 { return nil } mq := & mergePQ { q : make ( [ ] * nodeStream , len ( rs ) + 1 ) } } } for mq . q [ 1 ] != nil { if err != nil { return err } if err != nil { return err } } } return nil } 
func HashFileNode ( n * FileNodeProto ) [ ] byte { hash := sha256 . New ( ) } return hash . Sum ( nil ) } 
func ( h * dbHashTree ) Hash ( ) error { return h . Batch ( func ( tx * bolt . Tx ) error { return canonicalize ( tx , " " ) } ) } 
func IsGlob ( pattern string ) bool { pattern = clean ( pattern ) return globRegex . Match ( [ ] byte ( pattern ) ) } 
func GlobLiteralPrefix ( pattern string ) string { pattern = clean ( pattern ) idx := globRegex . FindStringIndex ( pattern ) if idx == nil { return pattern } return pattern [ : idx [ 0 ] ] } 
func GetHashTreeObject ( pachClient * client . APIClient , storageRoot string , treeRef * pfs . Object ) ( HashTree , error ) { return getHashTree ( storageRoot , func ( w io . Writer ) error { return pachClient . GetObject ( treeRef . Hash , w ) } ) } 
func GetHashTreeTag ( pachClient * client . APIClient , storageRoot string , treeRef * pfs . Tag ) ( HashTree , error ) { return getHashTree ( storageRoot , func ( w io . Writer ) error { return pachClient . GetTag ( treeRef . Name , w ) } ) } 
func PutHashTree ( pachClient * client . APIClient , tree HashTree , tags ... string ) ( * pfs . Object , error ) { r , w := io . Pipe ( ) var eg errgroup . Group eg . Go ( func ( ) ( retErr error ) { defer func ( ) { if err := w . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return tree . Serialize ( w ) } ) var treeRef * pfs . Object eg . Go ( func ( ) error { var err error treeRef , _ , err = pachClient . PutObject ( r , tags ... ) return err } ) if err := eg . Wait ( ) ; err != nil { return nil , err } return treeRef , nil } 
func NewChildCursor ( tx * bolt . Tx , path string ) * ChildCursor { path = clean ( path ) c := fs ( tx ) . Cursor ( ) dir := b ( path ) k , v := c . Seek ( append ( dir , nullByte [ 0 ] ) ) if ! bytes . Equal ( dir , nullByte ) { dir = append ( dir , nullByte [ 0 ] ) } if ! bytes . HasPrefix ( k , dir ) { k , v = nil , nil } return & ChildCursor { c : c , dir : dir , k : k , v : v , } } 
func ( d * ChildCursor ) Next ( ) ( [ ] byte , [ ] byte ) { if d . k == nil { return nil , nil } k , v := d . c . Seek ( append ( d . k , 1 ) ) if ! bytes . HasPrefix ( k , d . dir ) { k , v = nil , nil } d . k , d . v = k , v return k , v } 
func NewOrdered ( root string ) * Ordered { root = clean ( root ) o := & Ordered { } n := & node { path : " " , nodeProto : & NodeProto { Name : " " , DirNode : & DirectoryNodeProto { } , } , hash : sha256 . New ( ) , } o . fs = append ( o . fs , n ) o . dirStack = append ( o . dirStack , n ) o . MkdirAll ( root ) o . root = root return o } 
func ( o * Ordered ) MkdirAll ( path string ) { var paths [ ] string for path != " " { paths = append ( paths , path ) path , _ = split ( path ) } for i := len ( paths ) - 1 ; i >= 0 ; i -- { o . PutDir ( paths [ i ] ) } } 
func ( o * Ordered ) PutDir ( path string ) { path = clean ( path ) if path == " " { return } nodeProto := & NodeProto { Name : base ( path ) , DirNode : & DirectoryNodeProto { } , } o . putDir ( path , nodeProto ) } 
func ( o * Ordered ) PutFile ( path string , hash [ ] byte , size int64 , fileNodeProto * FileNodeProto ) { path = clean ( path ) nodeProto := & NodeProto { Name : base ( path ) , Hash : hash , SubtreeSize : size , FileNode : fileNodeProto , } o . putFile ( path , nodeProto ) } 
func ( o * Ordered ) Serialize ( _w io . Writer ) error { w := NewWriter ( _w ) child . nodeProto . Hash = child . hash . Sum ( nil ) o . dirStack = o . dirStack [ : len ( o . dirStack ) - 1 ] parent := o . dirStack [ len ( o . dirStack ) - 1 ] parent . hash . Write ( [ ] byte ( fmt . Sprintf ( " " , child . nodeProto . Name , child . nodeProto . Hash ) ) ) parent . nodeProto . SubtreeSize += child . nodeProto . SubtreeSize } o . fs [ 0 ] . nodeProto . Hash = o . fs [ 0 ] . hash . Sum ( nil ) for _ , n := range o . fs { if err := w . Write ( & MergeNode { k : b ( n . path ) , nodeProto : n . nodeProto , } ) ; err != nil { return err } } return nil } 
func NewUnordered ( root string ) * Unordered { return & Unordered { fs : make ( map [ string ] * NodeProto ) , root : clean ( root ) , } } 
func ( u * Unordered ) PutFile ( path string , hash [ ] byte , size int64 , blockRefs ... * pfs . BlockRef ) { path = join ( u . root , path ) nodeProto := & NodeProto { Name : base ( path ) , Hash : hash , SubtreeSize : size , FileNode : & FileNodeProto { BlockRefs : blockRefs , } , } u . fs [ path ] = nodeProto u . createParents ( path ) } 
func ( u * Unordered ) Ordered ( ) * Ordered { paths := make ( [ ] string , len ( u . fs ) ) i := 0 for path := range u . fs { paths [ i ] = path i ++ } sort . Strings ( paths ) o := NewOrdered ( " " ) for i := 1 ; i < len ( paths ) ; i ++ { path := paths [ i ] n := u . fs [ path ] if n . DirNode != nil { o . putDir ( path , n ) } else { o . putFile ( path , n ) } } return o } 
func ( b * backend ) Revoke ( ctx context . Context , req * logical . Request , data * framework . FieldData ) ( resp * logical . Response , retErr error ) { b . Logger ( ) . Debug ( fmt . Sprintf ( " " , req . ID , req . Operation , req . Path ) ) defer func ( ) { b . Logger ( ) . Debug ( fmt . Sprintf ( " " , req . ID , req . Operation , req . Path , retErr == nil && ! resp . IsError ( ) ) ) } ( ) if ! ok { return nil , fmt . Errorf ( " " ) } userToken , ok := tokenIface . ( string ) if ! ok { return nil , fmt . Errorf ( " " , tokenIface ) } if err != nil { return nil , err } if len ( config . AdminToken ) == 0 { return nil , errors . New ( " " ) } if len ( config . PachdAddress ) == 0 { return nil , errors . New ( " " ) } if err != nil { return nil , err } return & logical . Response { } , nil } 
func revokeUserCredentials ( ctx context . Context , pachdAddress string , userToken string , adminToken string ) error { if err != nil { return err } defer client . Close ( ) client = client . WithCtx ( ctx ) client . SetAuthToken ( adminToken ) _ , err = client . AuthAPIClient . RevokeAuthToken ( client . Ctx ( ) , & auth . RevokeAuthTokenRequest { Token : userToken , } ) return err } 
func NewAPIServer ( version * pb . Version , options APIServerOptions ) pb . APIServer { return newAPIServer ( version , options ) } 
func GetServerVersion ( clientConn * grpc . ClientConn ) ( * pb . Version , error ) { return pb . NewAPIClient ( clientConn ) . GetVersion ( context . Background ( ) , & types . Empty { } , ) } 
func String ( v * pb . Version ) string { return fmt . Sprintf ( " " , v . Major , v . Minor , v . Micro , v . Additional ) } 
func getPipelineInfo ( pachClient * client . APIClient , env * serviceenv . ServiceEnv ) ( * pps . PipelineInfo , error ) { ctx , cancel := context . WithTimeout ( context . Background ( ) , 30 * time . Second ) defer cancel ( ) resp , err := env . GetEtcdClient ( ) . Get ( ctx , path . Join ( env . PPSEtcdPrefix , " " , env . PPSPipelineName ) ) if err != nil { return nil , err } if len ( resp . Kvs ) != 1 { return nil , fmt . Errorf ( " " , env . PPSPipelineName , len ( resp . Kvs ) , resp ) } var pipelinePtr pps . EtcdPipelineInfo if err := pipelinePtr . Unmarshal ( resp . Kvs [ 0 ] . Value ) ; err != nil { return nil , err } pachClient . SetAuthToken ( pipelinePtr . AuthToken ) return ppsutil . GetPipelineInfo ( pachClient , & pipelinePtr , true ) } 
func insertStr ( ss * [ ] string , newS string ) bool { sz := cap ( * ss ) idx := sort . SearchStrings ( * ss , newS ) if idx >= len ( * ss ) || ( * ss ) [ idx ] != newS { copy ( ( * ss ) [ idx + 1 : ] , ( * ss ) [ idx : ] ) ( * ss ) [ idx ] = newS } else { newSs := make ( [ ] string , len ( * ss ) + 1 , max ( cap1 , cap2 ) ) copy ( newSs , ( * ss ) [ : idx ] ) copy ( newSs [ idx + 1 : ] , ( * ss ) [ idx : ] ) newSs [ idx ] = newS * ss = newSs } return true } return false } 
func removeStr ( ss * [ ] string , s string ) bool { idx := sort . SearchStrings ( * ss , s ) if idx == len ( * ss ) { return false } copy ( ( * ss ) [ idx : ] , ( * ss ) [ idx + 1 : ] ) * ss = ( * ss ) [ : len ( * ss ) - 1 ] return true } 
func PublicCertToPEM ( cert * tls . Certificate ) [ ] byte { return pem . EncodeToMemory ( & pem . Block { Type : " " , Bytes : cert . Certificate [ 0 ] , } ) } 
func KeyToPEM ( cert * tls . Certificate ) [ ] byte { switch k := cert . PrivateKey . ( type ) { case * rsa . PrivateKey : return pem . EncodeToMemory ( & pem . Block { Type : " " , Bytes : x509 . MarshalPKCS1PrivateKey ( k ) , } ) default : return nil } } 
func GenerateSelfSignedCert ( address string , name * pkix . Name , ipAddresses ... string ) ( * tls . Certificate , error ) { } switch { case address == " " && name . CommonName == " " : return nil , errors . New ( " \" \" \" \" " ) case address != " " && name . CommonName == " " : name . CommonName = address case address != " " && name . CommonName != " " && name . CommonName != address : return nil , fmt . Errorf ( " \" \" \" \" " , address , name . CommonName ) default : for _ , strIP := range ipAddresses { nextParsedIP := net . ParseIP ( strIP ) if nextParsedIP == nil { return nil , fmt . Errorf ( " " , strIP ) } parsedIPs = append ( parsedIPs , nextParsedIP ) } if err != nil { return nil , fmt . Errorf ( " " , err ) } if err != nil { return nil , fmt . Errorf ( " " , err ) } signedCert , err := x509 . ParseCertificate ( signedCertDER ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return & tls . Certificate { Certificate : [ ] [ ] byte { signedCertDER } , Leaf : signedCert , PrivateKey : key , } , nil } 
func ActivateCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { var initialAdmin string activate := & cobra . Command { Short : " " , Long : ` Activate Pachyderm's auth system, and restrict access to existing data to the user running the command (or the argument to --initial-admin), who will be the first cluster admin` [ 1 : ] , Run : cmdutil . Run ( func ( args [ ] string ) error { var token string var err error if ! strings . HasPrefix ( initialAdmin , auth . RobotPrefix ) { token , err = githubLogin ( ) if err != nil { return err } } fmt . Println ( " " ) // Exchange GitHub token for Pachyderm token c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) resp , err := c . Activate ( c . Ctx ( ) , & auth . ActivateRequest { GitHubToken : token , Subject : initialAdmin , } ) if err != nil { return fmt . Errorf ( " " , grpcutil . ScrubGRPC ( err ) ) } if err := writePachTokenToCfg ( resp . PachToken ) ; err != nil { return err } if strings . HasPrefix ( initialAdmin , auth . RobotPrefix ) { fmt . Println ( " " + " \n " + " " ) fmt . Printf ( " \" \" \n \n " , initialAdmin , resp . PachToken ) } return nil } ) , } activate . PersistentFlags ( ) . StringVar ( & initialAdmin , " " , " " , ` The subject (robot user or github user) who will be the first cluster admin; the user running 'activate' will identify as this user once auth is active. If you set 'initial-admin' to a robot user, pachctl will print that robot user's Pachyderm token; this token is effectively a root token, and if it's lost you will be locked out of your cluster` [ 1 : ] ) return cmdutil . CreateAlias ( activate , " " ) } 
func DeactivateCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { deactivate := & cobra . Command { Short : " " , Long : " " + " " + " " , Run : cmdutil . Run ( func ( args [ ] string ) error { fmt . Println ( " " + " " ) confirm , err := bufio . NewReader ( os . Stdin ) . ReadString ( '\n' ) if ! strings . Contains ( " " , confirm [ : 1 ] ) { return fmt . Errorf ( " " ) } c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) _ , err = c . Deactivate ( c . Ctx ( ) , & auth . DeactivateRequest { } ) return grpcutil . ScrubGRPC ( err ) } ) , } return cmdutil . CreateAlias ( deactivate , " " ) } 
func LoginCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { var useOTP bool login := & cobra . Command { Short : " " , Long : " " + " " + " " , Run : cmdutil . Run ( func ( [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) var authErr error if useOTP { code , err := bufio . NewReader ( os . Stdin ) . ReadString ( '\n' ) if err != nil { return fmt . Errorf ( " " , err ) } code = strings . TrimSpace ( code ) resp , authErr = c . Authenticate ( c . Ctx ( ) , & auth . AuthenticateRequest { OneTimePassword : code } ) } else { if err != nil { return err } fmt . Println ( " " ) resp , authErr = c . Authenticate ( c . Ctx ( ) , & auth . AuthenticateRequest { GitHubToken : token } ) } } return fmt . Errorf ( " " , grpcutil . ScrubGRPC ( authErr ) ) } return writePachTokenToCfg ( resp . PachToken ) } ) , } login . PersistentFlags ( ) . BoolVarP ( & useOTP , " " , " " , false , " " + " " ) return cmdutil . CreateAlias ( login , " " ) } 
func LogoutCmd ( ) * cobra . Command { logout := & cobra . Command { Short : " " , Long : " " + " " + " " + " " , Run : cmdutil . Run ( func ( [ ] string ) error { cfg , err := config . Read ( ) if err != nil { return fmt . Errorf ( " " + " " , err ) } if cfg . V1 == nil { return nil } cfg . V1 . SessionToken = " " return cfg . Write ( ) } ) , } return cmdutil . CreateAlias ( logout , " " ) } 
func WhoamiCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { whoami := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . Run ( func ( [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) resp , err := c . WhoAmI ( c . Ctx ( ) , & auth . WhoAmIRequest { } ) if err != nil { return fmt . Errorf ( " " , grpcutil . ScrubGRPC ( err ) ) } fmt . Printf ( " \" \" \n " , resp . Username ) if resp . TTL > 0 { fmt . Printf ( " \n " , time . Now ( ) . Add ( time . Duration ( resp . TTL ) * time . Second ) . Format ( time . RFC822 ) ) } if resp . IsAdmin { fmt . Println ( " " ) } return nil } ) , } return cmdutil . CreateAlias ( whoami , " " ) } 
func CheckCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { check := & cobra . Command { Use : " " , Short : " " , Long : " " + " \" \" " + " \" \" " + " \" \" " + " " + " " , Run : cmdutil . RunFixedArgs ( 2 , func ( args [ ] string ) error { scope , err := auth . ParseScope ( args [ 0 ] ) if err != nil { return err } repo := args [ 1 ] c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) resp , err := c . Authorize ( c . Ctx ( ) , & auth . AuthorizeRequest { Repo : repo , Scope : scope , } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } fmt . Printf ( " \n " , resp . Authorized ) return nil } ) , } return cmdutil . CreateAlias ( check , " " ) } 
func GetCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { get := & cobra . Command { Use : " " , Short : " " , Long : " " + " " + " \" \" \" \" \" \" \" \" " + " \" \" \" \" " + " " + " " , Run : cmdutil . RunBoundedArgs ( 1 , 2 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) if len ( args ) == 1 { resp , err := c . GetACL ( c . Ctx ( ) , & auth . GetACLRequest { Repo : repo , } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } t := template . Must ( template . New ( " " ) . Parse ( " \n " ) ) return t . Execute ( os . Stdout , resp . Entries ) } resp , err := c . GetScope ( c . Ctx ( ) , & auth . GetScopeRequest { Repos : [ ] string { repo } , Username : username , } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } fmt . Println ( resp . Scopes [ 0 ] . String ( ) ) return nil } ) , } return cmdutil . CreateAlias ( get , " " ) } 
func SetScopeCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { setScope := & cobra . Command { Use : " " , Short : " " , Long : " " + " " + " \" \" \" \" " + " " + " \" \" \" \" " + " " + " " + " " , Run : cmdutil . RunFixedArgs ( 3 , func ( args [ ] string ) error { scope , err := auth . ParseScope ( args [ 1 ] ) if err != nil { return err } username , repo := args [ 0 ] , args [ 2 ] c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) _ , err = c . SetScope ( c . Ctx ( ) , & auth . SetScopeRequest { Repo : repo , Scope : scope , Username : username , } ) return grpcutil . ScrubGRPC ( err ) } ) , } return cmdutil . CreateAlias ( setScope , " " ) } 
func ListAdminsCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { listAdmins := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . Run ( func ( [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) resp , err := c . GetAdmins ( c . Ctx ( ) , & auth . GetAdminsRequest { } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for _ , user := range resp . Admins { fmt . Println ( user ) } return nil } ) , } return cmdutil . CreateAlias ( listAdmins , " " ) } 
func ModifyAdminsCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { var add [ ] string var remove [ ] string modifyAdmins := & cobra . Command { Short : " " , Long : " " + " " + " " , Run : cmdutil . Run ( func ( [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) _ , err = c . ModifyAdmins ( c . Ctx ( ) , & auth . ModifyAdminsRequest { Add : add , Remove : remove , } ) if auth . IsErrPartiallyActivated ( err ) { return fmt . Errorf ( " " + " " + " " , err ) } return grpcutil . ScrubGRPC ( err ) } ) , } modifyAdmins . PersistentFlags ( ) . StringSliceVar ( & add , " " , [ ] string { } , " " ) modifyAdmins . PersistentFlags ( ) . StringSliceVar ( & remove , " " , [ ] string { } , " " ) return cmdutil . CreateAlias ( modifyAdmins , " " ) } 
func GetAuthTokenCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { var quiet bool getAuthToken := & cobra . Command { Use : " " , Short : " \" \" " , Long : " \" \" " + " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { subject := args [ 0 ] c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) resp , err := c . GetAuthToken ( c . Ctx ( ) , & auth . GetAuthTokenRequest { Subject : subject , } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } if quiet { fmt . Println ( resp . Token ) } else { fmt . Printf ( " \n \n \n " , resp . Subject , resp . Token ) } return nil } ) , } getAuthToken . PersistentFlags ( ) . BoolVarP ( & quiet , " " , " " , false , " " + " " + " " ) return cmdutil . CreateAlias ( getAuthToken , " " ) } 
func UseAuthTokenCmd ( ) * cobra . Command { useAuthToken := & cobra . Command { Short : " " + " " , Long : " " + " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { fmt . Println ( " " ) token , err := bufio . NewReader ( os . Stdin ) . ReadString ( '\n' ) if err != nil { return fmt . Errorf ( " " , err ) } writePachTokenToCfg ( strings . TrimSpace ( token ) ) return nil } ) , } return cmdutil . CreateAlias ( useAuthToken , " " ) } 
func Cmds ( noMetrics , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command auth := & cobra . Command { Short : " " , Long : " " , } commands = append ( commands , cmdutil . CreateAlias ( auth , " " ) ) commands = append ( commands , ActivateCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , DeactivateCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , LoginCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , LogoutCmd ( ) ) commands = append ( commands , WhoamiCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , CheckCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , SetScopeCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , GetCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , ListAdminsCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , ModifyAdminsCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , GetAuthTokenCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , UseAuthTokenCmd ( ) ) commands = append ( commands , GetConfigCmd ( noPortForwarding ) ) commands = append ( commands , SetConfigCmd ( noPortForwarding ) ) return commands } 
func ParseScope ( s string ) ( Scope , error ) { for name , value := range Scope_value { if strings . EqualFold ( s , name ) { return Scope ( value ) , nil } } return Scope_NONE , fmt . Errorf ( " " , s ) } 
func IsErrNotActivated ( err error ) bool { if err == nil { return false } } 
func IsErrPartiallyActivated ( err error ) bool { if err == nil { return false } } 
func IsErrNotSignedIn ( err error ) bool { if err == nil { return false } } 
func IsErrNoMetadata ( err error ) bool { if err == nil { return false } return strings . Contains ( err . Error ( ) , status . Convert ( ErrNoMetadata ) . Message ( ) ) } 
func IsErrBadToken ( err error ) bool { if err == nil { return false } return strings . Contains ( err . Error ( ) , status . Convert ( ErrBadToken ) . Message ( ) ) } 
func IsErrNotAuthorized ( err error ) bool { if err == nil { return false } } 
func IsErrInvalidPrincipal ( err error ) bool { if err == nil { return false } return strings . Contains ( err . Error ( ) , " \" " ) && strings . Contains ( err . Error ( ) , " \" \" \" \" \" \" \" \" \" " ) } 
func IsErrTooShortTTL ( err error ) bool { if err == nil { return false } errMsg := err . Error ( ) return strings . Contains ( errMsg , " " ) && strings . Contains ( errMsg , " " ) && strings . Contains ( errMsg , " " ) } 
func NewDatumFactory ( pachClient * client . APIClient , input * pps . Input ) ( DatumFactory , error ) { switch { case input . Pfs != nil : return newPFSDatumFactory ( pachClient , input . Pfs ) case input . Union != nil : return newUnionDatumFactory ( pachClient , input . Union ) case input . Cross != nil : return newCrossDatumFactory ( pachClient , input . Cross ) case input . Cron != nil : return newCronDatumFactory ( pachClient , input . Cron ) case input . Git != nil : return newGitDatumFactory ( pachClient , input . Git ) } return nil , fmt . Errorf ( " " ) } 
func NewCollection ( etcdClient * etcd . Client , prefix string , indexes [ ] * Index , template proto . Message , keyCheck func ( string ) error , valCheck func ( proto . Message ) error ) Collection { } return & collection { prefix : prefix , etcdClient : etcdClient , indexes : indexes , limit : defaultLimit , template : template , keyCheck : keyCheck , valCheck : valCheck , } } 
func ( c * collection ) Path ( key string ) string { return path . Join ( c . prefix , key ) } 
func ( c * collection ) indexDir ( index * Index , indexVal interface { } ) string { var indexValStr string if marshaller , ok := indexVal . ( proto . Marshaler ) ; ok { if indexValBytes , err := marshaller . Marshal ( ) ; err == nil { } else { indexValStr = fmt . Sprintf ( " " , indexVal ) } } else { indexValStr = fmt . Sprintf ( " " , indexVal ) } return path . Join ( c . indexRoot ( index ) , indexValStr ) } 
func ( c * collection ) indexPath ( index * Index , indexVal interface { } , key string ) string { return path . Join ( c . indexDir ( index , indexVal ) , key ) } 
func ( c * readWriteCollection ) getIndexPath ( val interface { } , index * Index , key string ) string { reflVal := reflect . ValueOf ( val ) field := reflect . Indirect ( reflVal ) . FieldByName ( index . Field ) . Interface ( ) return c . indexPath ( index , field , key ) } 
func ( c * readWriteCollection ) getMultiIndexPaths ( val interface { } , index * Index , key string ) [ ] string { var indexPaths [ ] string field := reflect . Indirect ( reflect . ValueOf ( val ) ) . FieldByName ( index . Field ) for i := 0 ; i < field . Len ( ) ; i ++ { indexPaths = append ( indexPaths , c . indexPath ( index , field . Index ( i ) . Interface ( ) , key ) ) } return indexPaths } 
func ( c * readWriteCollection ) Upsert ( key string , val proto . Message , f func ( ) error ) error { if err := watch . CheckType ( c . template , val ) ; err != nil { return err } if err := c . Get ( key , val ) ; err != nil && ! IsErrNotFound ( err ) { return err } if err := f ( ) ; err != nil { return err } return c . Put ( key , val ) } 
func ( c * readonlyCollection ) get ( key string , opts ... etcd . OpOption ) ( * etcd . GetResponse , error ) { span , ctx := tracing . AddSpanToAnyExisting ( c . ctx , " " ) defer tracing . FinishAnySpan ( span ) resp , err := c . etcdClient . Get ( ctx , key , opts ... ) return resp , err } 
func ( c * readonlyCollection ) ListPrefix ( prefix string , val proto . Message , opts * Options , f func ( string ) error ) error { queryPrefix := c . prefix if prefix != " " { } return c . list ( queryPrefix , & c . limit , opts , func ( kv * mvccpb . KeyValue ) error { if err := proto . Unmarshal ( kv . Value , val ) ; err != nil { return err } return f ( strings . TrimPrefix ( string ( kv . Key ) , queryPrefix ) ) } ) } 
func ( c * readonlyCollection ) List ( val proto . Message , opts * Options , f func ( string ) error ) error { if err := watch . CheckType ( c . template , val ) ; err != nil { return err } return c . list ( c . prefix , & c . limit , opts , func ( kv * mvccpb . KeyValue ) error { if err := proto . Unmarshal ( kv . Value , val ) ; err != nil { return err } return f ( strings . TrimPrefix ( string ( kv . Key ) , c . prefix ) ) } ) } 
func ( c * readonlyCollection ) Watch ( opts ... watch . OpOption ) ( watch . Watcher , error ) { return watch . NewWatcher ( c . ctx , c . etcdClient , c . prefix , c . prefix , c . template , opts ... ) } 
func ( c * readonlyCollection ) WatchByIndex ( index * Index , val interface { } ) ( watch . Watcher , error ) { eventCh := make ( chan * watch . Event ) done := make ( chan struct { } ) watcher , err := watch . NewWatcher ( c . ctx , c . etcdClient , c . prefix , c . indexDir ( index , val ) , c . template ) if err != nil { return nil , err } go func ( ) ( retErr error ) { defer func ( ) { if retErr != nil { eventCh <- & watch . Event { Type : watch . EventError , Err : retErr , } watcher . Close ( ) } close ( eventCh ) } ( ) for { var ev * watch . Event var ok bool select { case ev , ok = <- watcher . Watch ( ) : case <- done : watcher . Close ( ) return nil } if ! ok { watcher . Close ( ) return nil } var directEv * watch . Event switch ev . Type { case watch . EventError : case watch . EventPut : resp , err := c . get ( c . Path ( path . Base ( string ( ev . Key ) ) ) ) if err != nil { return err } if len ( resp . Kvs ) == 0 { } directEv = & watch . Event { Key : [ ] byte ( path . Base ( string ( ev . Key ) ) ) , Value : resp . Kvs [ 0 ] . Value , Type : ev . Type , Template : c . template , } case watch . EventDelete : directEv = & watch . Event { Key : [ ] byte ( path . Base ( string ( ev . Key ) ) ) , Type : ev . Type , Template : c . template , } } eventCh <- directEv } } ( ) return watch . MakeWatcher ( eventCh , done ) , nil } 
func ( c * readonlyCollection ) WatchOne ( key string ) ( watch . Watcher , error ) { return watch . NewWatcher ( c . ctx , c . etcdClient , c . prefix , c . Path ( key ) , c . template ) } 
func ( c * readonlyCollection ) WatchOneF ( key string , f func ( e * watch . Event ) error ) error { watcher , err := watch . NewWatcher ( c . ctx , c . etcdClient , c . prefix , c . Path ( key ) , c . template ) if err != nil { return err } defer watcher . Close ( ) for { select { case e := <- watcher . Watch ( ) : if err := f ( e ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } case <- c . ctx . Done ( ) : return c . ctx . Err ( ) } } } 
func generateUserCredentials ( ctx context . Context , pachdAddress string , adminToken string , username string , ttl time . Duration ) ( string , error ) { if err != nil { return " " , err } defer client . Close ( ) client = client . WithCtx ( ctx ) client . SetAuthToken ( adminToken ) resp , err := client . AuthAPIClient . GetAuthToken ( client . Ctx ( ) , & auth . GetAuthTokenRequest { Subject : username , TTL : int64 ( ttl . Seconds ( ) ) , } ) if err != nil { return " " , err } return resp . Token , nil } 
func NewCache ( root string ) * Cache { return & Cache { root : root , keys : make ( map [ string ] bool ) , } } 
func ( c * Cache ) Put ( key string , value io . Reader ) ( retErr error ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) f , err := os . Create ( filepath . Join ( c . root , key ) ) if err != nil { return err } defer func ( ) { if err := f . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) buf := grpcutil . GetBuffer ( ) defer grpcutil . PutBuffer ( buf ) if _ , err := io . CopyBuffer ( f , value , buf ) ; err != nil { return err } c . keys [ key ] = true return nil } 
func ( c * Cache ) Get ( key string ) ( io . ReadCloser , error ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) if ! c . keys [ key ] { return nil , fmt . Errorf ( " " , key ) } f , err := os . Open ( filepath . Join ( c . root , key ) ) if err != nil { return nil , err } return f , nil } 
func ( c * Cache ) Keys ( ) [ ] string { c . mu . Lock ( ) defer c . mu . Unlock ( ) var keys [ ] string for key := range c . keys { keys = append ( keys , key ) } sort . Strings ( keys ) return keys } 
func ( c * Cache ) Delete ( key string ) error { c . mu . Lock ( ) defer c . mu . Unlock ( ) if ! c . keys [ key ] { return nil } delete ( c . keys , key ) return os . Remove ( filepath . Join ( c . root , key ) ) } 
func ( c * Cache ) Clear ( ) error { c . mu . Lock ( ) defer c . mu . Unlock ( ) defer func ( ) { c . keys = make ( map [ string ] bool ) } ( ) for key := range c . keys { if err := os . Remove ( filepath . Join ( c . root , key ) ) ; err != nil { return err } } return nil } 
func NewHTTPServer ( address string ) ( http . Handler , error ) { router := httprouter . New ( ) s := & server { router : router , address : address , httpClient : & http . Client { } , } router . GET ( getFilePath , s . getFileHandler ) router . GET ( servicePath , s . serviceHandler ) router . POST ( loginPath , s . authLoginHandler ) router . POST ( logoutPath , s . authLogoutHandler ) router . POST ( servicePath , s . serviceHandler ) router . NotFound = http . HandlerFunc ( notFound ) return s , nil } 
func NewDeployServer ( kubeClient * kube . Clientset , kubeNamespace string ) deploy . APIServer { return & apiServer { kubeClient : kubeClient , kubeNamespace : kubeNamespace , } } 
func invalidDelimiterError ( w http . ResponseWriter , r * http . Request ) { writeError ( w , r , http . StatusBadRequest , " " , " " ) } 
func invalidFilePathError ( w http . ResponseWriter , r * http . Request ) { writeError ( w , r , http . StatusBadRequest , " " , " " ) } 
func Cmds ( noMetrics * bool , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command dump := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . Dump ( os . Stdout ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( dump , " " ) ) var duration time . Duration profile := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . Profile ( args [ 0 ] , duration , os . Stdout ) } ) , } profile . Flags ( ) . DurationVarP ( & duration , " " , " " , time . Minute , " " ) commands = append ( commands , cmdutil . CreateAlias ( profile , " " ) ) binary := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . Binary ( os . Stdout ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( binary , " " ) ) var profileFile string var binaryFile string pprof := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) var eg errgroup . Group } f , err := os . Create ( profileFile ) if err != nil { return err } defer func ( ) { if err := f . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return client . Profile ( args [ 0 ] , duration , f ) } ) if err != nil { return err } defer func ( ) { if err := f . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return client . Binary ( f ) } ) if err := eg . Wait ( ) ; err != nil { return err } cmd := exec . Command ( " " , " " , " " , binaryFile , profileFile ) cmd . Stdin = os . Stdin cmd . Stdout = os . Stdout cmd . Stderr = os . Stderr return cmd . Run ( ) } ) , } pprof . Flags ( ) . StringVar ( & profileFile , " " , " " , " " ) pprof . Flags ( ) . StringVar ( & binaryFile , " " , " " , " " ) pprof . Flags ( ) . DurationVarP ( & duration , " " , " " , time . Minute , " " ) commands = append ( commands , cmdutil . CreateAlias ( pprof , " " ) ) debug := & cobra . Command { Short : " " , Long : " " , } commands = append ( commands , cmdutil . CreateAlias ( debug , " " ) ) return commands } 
func Export ( opts * assets . AssetOpts , out io . Writer ) error { client , err := docker . NewClientFromEnv ( ) if err != nil { return err } authConfigs , err := docker . NewAuthConfigurationsFromDockerCfg ( ) if err != nil { return fmt . Errorf ( " " , err . Error ( ) ) } if len ( authConfigs . Configs ) == 0 { return fmt . Errorf ( " " ) } images := assets . Images ( opts ) for _ , image := range images { repository , tag := docker . ParseRepositoryTag ( image ) pulled := false var loopErr [ ] error for registry , authConfig := range authConfigs . Configs { if err := client . PullImage ( docker . PullImageOptions { Repository : repository , Tag : tag , InactivityTimeout : 5 * time . Second , } , authConfig , ) ; err != nil { loopErr = append ( loopErr , fmt . Errorf ( " " , registry , err ) ) continue } pulled = true break } if ! pulled { errStr := " " for _ , err := range loopErr { errStr += err . Error ( ) + " \n " } return fmt . Errorf ( " \n " , repository , tag , errStr ) } } return client . ExportImages ( docker . ExportImagesOptions { Names : images , OutputStream : out , } ) } 
func Import ( opts * assets . AssetOpts , in io . Reader ) error { client , err := docker . NewClientFromEnv ( ) if err != nil { return err } authConfigs , err := docker . NewAuthConfigurationsFromDockerCfg ( ) if err != nil { return fmt . Errorf ( " " , err . Error ( ) ) } if len ( authConfigs . Configs ) == 0 { return fmt . Errorf ( " " ) } if err := client . LoadImage ( docker . LoadImageOptions { InputStream : in , } ) ; err != nil { return err } registry := opts . Registry opts . Registry = " " images := assets . Images ( opts ) opts . Registry = registry for _ , image := range images { repository , tag := docker . ParseRepositoryTag ( image ) registryRepo := assets . AddRegistry ( opts . Registry , repository ) if err := client . TagImage ( image , docker . TagImageOptions { Repo : registryRepo , Tag : tag , } , ) ; err != nil { return fmt . Errorf ( " " , err ) } pushed := false var loopErr [ ] error for registry , authConfig := range authConfigs . Configs { if err := client . PushImage ( docker . PushImageOptions { Name : registryRepo , Tag : tag , Registry : opts . Registry , InactivityTimeout : 5 * time . Second , } , authConfig , ) ; err != nil { loopErr = append ( loopErr , fmt . Errorf ( " " , registry , err ) ) continue } pushed = true break } if ! pushed { errStr := " " for _ , err := range loopErr { errStr += err . Error ( ) + " \n " } return fmt . Errorf ( " \n " , registryRepo , tag , errStr ) } } return nil } 
func DatumTagPrefix ( salt string ) string { h . Write ( [ ] byte ( salt ) ) return hex . EncodeToString ( h . Sum ( nil ) ) [ : 4 ] } 
func NewPFSInput ( repo string , glob string ) * pps . Input { return & pps . Input { Pfs : & pps . PFSInput { Repo : repo , Glob : glob , } , } } 
func NewPFSInputOpts ( name string , repo string , branch string , glob string , lazy bool ) * pps . Input { return & pps . Input { Pfs : & pps . PFSInput { Name : name , Repo : repo , Branch : branch , Glob : glob , Lazy : lazy , } , } } 
func NewCrossInput ( input ... * pps . Input ) * pps . Input { return & pps . Input { Cross : input , } } 
func NewUnionInput ( input ... * pps . Input ) * pps . Input { return & pps . Input { Union : input , } } 
func NewCronInput ( name string , spec string ) * pps . Input { return & pps . Input { Cron : & pps . CronInput { Name : name , Spec : spec , } , } } 
func NewJobInput ( repoName string , commitID string , glob string ) * pps . JobInput { return & pps . JobInput { Commit : NewCommit ( repoName , commitID ) , Glob : glob , } } 
func NewPipelineInput ( repoName string , glob string ) * pps . PipelineInput { return & pps . PipelineInput { Repo : NewRepo ( repoName ) , Glob : glob , } } 
func ( c APIClient ) CreateJob ( pipeline string , outputCommit * pfs . Commit ) ( * pps . Job , error ) { job , err := c . PpsAPIClient . CreateJob ( c . Ctx ( ) , & pps . CreateJobRequest { Pipeline : NewPipeline ( pipeline ) , OutputCommit : outputCommit , } , ) return job , grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) InspectJob ( jobID string , blockState bool ) ( * pps . JobInfo , error ) { jobInfo , err := c . PpsAPIClient . InspectJob ( c . Ctx ( ) , & pps . InspectJobRequest { Job : NewJob ( jobID ) , BlockState : blockState , } ) return jobInfo , grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) InspectJobOutputCommit ( repoName , commitID string , blockState bool ) ( * pps . JobInfo , error ) { jobInfo , err := c . PpsAPIClient . InspectJob ( c . Ctx ( ) , & pps . InspectJobRequest { OutputCommit : NewCommit ( repoName , commitID ) , BlockState : blockState , } ) return jobInfo , grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) ListJob ( pipelineName string , inputCommit [ ] * pfs . Commit , outputCommit * pfs . Commit ) ( [ ] * pps . JobInfo , error ) { var result [ ] * pps . JobInfo if err := c . ListJobF ( pipelineName , inputCommit , outputCommit , func ( ji * pps . JobInfo ) error { result = append ( result , ji ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func ( c APIClient ) ListJobF ( pipelineName string , inputCommit [ ] * pfs . Commit , outputCommit * pfs . Commit , f func ( * pps . JobInfo ) error ) error { var pipeline * pps . Pipeline if pipelineName != " " { pipeline = NewPipeline ( pipelineName ) } client , err := c . PpsAPIClient . ListJobStream ( c . Ctx ( ) , & pps . ListJobRequest { Pipeline : pipeline , InputCommit : inputCommit , OutputCommit : outputCommit , } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { ji , err := client . Recv ( ) if err == io . EOF { return nil } else if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( ji ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } } 
func ( c APIClient ) FlushJob ( commits [ ] * pfs . Commit , toPipelines [ ] string , f func ( * pps . JobInfo ) error ) error { req := & pps . FlushJobRequest { Commits : commits , } for _ , pipeline := range toPipelines { req . ToPipelines = append ( req . ToPipelines , NewPipeline ( pipeline ) ) } client , err := c . PpsAPIClient . FlushJob ( c . Ctx ( ) , req ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { jobInfo , err := client . Recv ( ) if err != nil { if err == io . EOF { return nil } return grpcutil . ScrubGRPC ( err ) } if err := f ( jobInfo ) ; err != nil { return err } } } 
func ( c APIClient ) FlushJobAll ( commits [ ] * pfs . Commit , toPipelines [ ] string ) ( [ ] * pps . JobInfo , error ) { var result [ ] * pps . JobInfo if err := c . FlushJob ( commits , toPipelines , func ( ji * pps . JobInfo ) error { result = append ( result , ji ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func ( c APIClient ) DeleteJob ( jobID string ) error { _ , err := c . PpsAPIClient . DeleteJob ( c . Ctx ( ) , & pps . DeleteJobRequest { Job : NewJob ( jobID ) , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) StopJob ( jobID string ) error { _ , err := c . PpsAPIClient . StopJob ( c . Ctx ( ) , & pps . StopJobRequest { Job : NewJob ( jobID ) , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) RestartDatum ( jobID string , datumFilter [ ] string ) error { _ , err := c . PpsAPIClient . RestartDatum ( c . Ctx ( ) , & pps . RestartDatumRequest { Job : NewJob ( jobID ) , DataFilters : datumFilter , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) ListDatum ( jobID string , pageSize int64 , page int64 ) ( * pps . ListDatumResponse , error ) { client , err := c . PpsAPIClient . ListDatumStream ( c . Ctx ( ) , & pps . ListDatumRequest { Job : NewJob ( jobID ) , PageSize : pageSize , Page : page , } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } resp := & pps . ListDatumResponse { } first := true for { r , err := client . Recv ( ) if err == io . EOF { break } else if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } if first { resp . TotalPages = r . TotalPages resp . Page = r . Page first = false } resp . DatumInfos = append ( resp . DatumInfos , r . DatumInfo ) } return resp , nil } 
func ( c APIClient ) ListDatumF ( jobID string , pageSize int64 , page int64 , f func ( di * pps . DatumInfo ) error ) error { client , err := c . PpsAPIClient . ListDatumStream ( c . Ctx ( ) , & pps . ListDatumRequest { Job : NewJob ( jobID ) , PageSize : pageSize , Page : page , } , ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { resp , err := client . Recv ( ) if err == io . EOF { return nil } else if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( resp . DatumInfo ) ; err != nil { if err == errutil . ErrBreak { return nil } return err } } } 
func ( c APIClient ) InspectDatum ( jobID string , datumID string ) ( * pps . DatumInfo , error ) { datumInfo , err := c . PpsAPIClient . InspectDatum ( c . Ctx ( ) , & pps . InspectDatumRequest { Datum : & pps . Datum { ID : datumID , Job : NewJob ( jobID ) , } , } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return datumInfo , nil } 
func ( l * LogsIter ) Next ( ) bool { if l . err != nil { l . msg = nil return false } l . msg , l . err = l . logsClient . Recv ( ) if l . err != nil { return false } return true } 
func ( l * LogsIter ) Err ( ) error { if l . err == io . EOF { return nil } return grpcutil . ScrubGRPC ( l . err ) } 
func ( c APIClient ) GetLogs ( pipelineName string , jobID string , data [ ] string , datumID string , master bool , follow bool , tail int64 , ) * LogsIter { request := pps . GetLogsRequest { Master : master , Follow : follow , Tail : tail , } resp := & LogsIter { } if pipelineName != " " { request . Pipeline = NewPipeline ( pipelineName ) } if jobID != " " { request . Job = NewJob ( jobID ) } request . DataFilters = data if datumID != " " { request . Datum = & pps . Datum { Job : NewJob ( jobID ) , ID : datumID , } } resp . logsClient , resp . err = c . PpsAPIClient . GetLogs ( c . Ctx ( ) , & request ) resp . err = grpcutil . ScrubGRPC ( resp . err ) return resp } 
func ( c APIClient ) CreatePipeline ( name string , image string , cmd [ ] string , stdin [ ] string , parallelismSpec * pps . ParallelismSpec , input * pps . Input , outputBranch string , update bool , ) error { _ , err := c . PpsAPIClient . CreatePipeline ( c . Ctx ( ) , & pps . CreatePipelineRequest { Pipeline : NewPipeline ( name ) , Transform : & pps . Transform { Image : image , Cmd : cmd , Stdin : stdin , } , ParallelismSpec : parallelismSpec , Input : input , OutputBranch : outputBranch , Update : update , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) InspectPipeline ( pipelineName string ) ( * pps . PipelineInfo , error ) { pipelineInfo , err := c . PpsAPIClient . InspectPipeline ( c . Ctx ( ) , & pps . InspectPipelineRequest { Pipeline : NewPipeline ( pipelineName ) , } , ) return pipelineInfo , grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) ListPipeline ( ) ( [ ] * pps . PipelineInfo , error ) { pipelineInfos , err := c . PpsAPIClient . ListPipeline ( c . Ctx ( ) , & pps . ListPipelineRequest { } , ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return pipelineInfos . PipelineInfo , nil } 
func ( c APIClient ) DeletePipeline ( name string , force bool ) error { _ , err := c . PpsAPIClient . DeletePipeline ( c . Ctx ( ) , & pps . DeletePipelineRequest { Pipeline : NewPipeline ( name ) , Force : force , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) StartPipeline ( name string ) error { _ , err := c . PpsAPIClient . StartPipeline ( c . Ctx ( ) , & pps . StartPipelineRequest { Pipeline : NewPipeline ( name ) , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) StopPipeline ( name string ) error { _ , err := c . PpsAPIClient . StopPipeline ( c . Ctx ( ) , & pps . StopPipelineRequest { Pipeline : NewPipeline ( name ) , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) RerunPipeline ( name string , include [ ] * pfs . Commit , exclude [ ] * pfs . Commit ) error { _ , err := c . PpsAPIClient . RerunPipeline ( c . Ctx ( ) , & pps . RerunPipelineRequest { Pipeline : NewPipeline ( name ) , Include : include , Exclude : exclude , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) CreatePipelineService ( name string , image string , cmd [ ] string , stdin [ ] string , parallelismSpec * pps . ParallelismSpec , input * pps . Input , update bool , internalPort int32 , externalPort int32 , ) error { _ , err := c . PpsAPIClient . CreatePipeline ( c . Ctx ( ) , & pps . CreatePipelineRequest { Pipeline : NewPipeline ( name ) , Transform : & pps . Transform { Image : image , Cmd : cmd , Stdin : stdin , } , ParallelismSpec : parallelismSpec , Input : input , Update : update , Service : & pps . Service { InternalPort : internalPort , ExternalPort : externalPort , } , } , ) return grpcutil . ScrubGRPC ( err ) } 
func ( c APIClient ) GarbageCollect ( memoryBytes int64 ) error { _ , err := c . PpsAPIClient . GarbageCollect ( c . Ctx ( ) , & pps . GarbageCollectRequest { MemoryBytes : memoryBytes } , ) return grpcutil . ScrubGRPC ( err ) } 
func GetDatumTotalTime ( s * pps . ProcessStats ) time . Duration { totalDuration := time . Duration ( 0 ) duration , _ := types . DurationFromProto ( s . DownloadTime ) totalDuration += duration duration , _ = types . DurationFromProto ( s . ProcessTime ) totalDuration += duration duration , _ = types . DurationFromProto ( s . UploadTime ) totalDuration += duration return totalDuration } 
func Mount ( c * client . APIClient , mountPoint string , opts * Options ) error { nfs := pathfs . NewPathNodeFs ( newFileSystem ( c , opts . getCommits ( ) ) , nil ) server , _ , err := nodefs . MountRoot ( mountPoint , nfs . Root ( ) , opts . getFuse ( ) ) if err != nil { return fmt . Errorf ( " " , err ) } sigChan := make ( chan os . Signal , 1 ) signal . Notify ( sigChan , os . Interrupt ) go func ( ) { select { case <- sigChan : case <- opts . getUnmount ( ) : } server . Unmount ( ) } ( ) server . Serve ( ) return nil } 
func NewBufPool ( size int ) * BufPool { return & BufPool { sync . Pool { New : func ( ) interface { } { return make ( [ ] byte , size ) } , } } } 
func StorageRootFromEnv ( ) ( string , error ) { storageRoot , ok := os . LookupEnv ( PachRootEnvVar ) if ! ok { return " " , fmt . Errorf ( " " , PachRootEnvVar ) } storageBackend , ok := os . LookupEnv ( StorageBackendEnvVar ) if ! ok { return " " , fmt . Errorf ( " " , StorageBackendEnvVar ) } case Minio : if len ( storageRoot ) > 0 && storageRoot [ 0 ] == '/' { storageRoot = storageRoot [ 1 : ] } } return storageRoot , nil } 
func BlockPathFromEnv ( block * pfs . Block ) ( string , error ) { storageRoot , err := StorageRootFromEnv ( ) if err != nil { return " " , err } return filepath . Join ( storageRoot , " " , block . Hash ) , nil } 
func NewGoogleClient ( bucket string , opts [ ] option . ClientOption ) ( Client , error ) { return newGoogleClient ( bucket , opts ) } 
func NewGoogleClientFromSecret ( bucket string ) ( Client , error ) { var err error if bucket == " " { bucket , err = readSecretFile ( " " ) if err != nil { return nil , fmt . Errorf ( " " ) } } cred , err := readSecretFile ( " " ) if err != nil { return nil , fmt . Errorf ( " " ) } var opts [ ] option . ClientOption if cred != " " { opts = append ( opts , option . WithCredentialsFile ( secretFile ( " " ) ) ) } else { opts = append ( opts , option . WithTokenSource ( google . ComputeTokenSource ( " " ) ) ) } return NewGoogleClient ( bucket , opts ) } 
func NewGoogleClientFromEnv ( ) ( Client , error ) { bucket , ok := os . LookupEnv ( GoogleBucketEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , GoogleBucketEnvVar ) } creds , ok := os . LookupEnv ( GoogleCredEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , GoogleCredEnvVar ) } opts := [ ] option . ClientOption { option . WithCredentialsJSON ( [ ] byte ( creds ) ) } return NewGoogleClient ( bucket , opts ) } 
func NewMicrosoftClient ( container string , accountName string , accountKey string ) ( Client , error ) { return newMicrosoftClient ( container , accountName , accountKey ) } 
func NewMicrosoftClientFromSecret ( container string ) ( Client , error ) { var err error if container == " " { container , err = readSecretFile ( " " ) if err != nil { return nil , fmt . Errorf ( " " ) } } id , err := readSecretFile ( " " ) if err != nil { return nil , fmt . Errorf ( " " ) } secret , err := readSecretFile ( " " ) if err != nil { return nil , fmt . Errorf ( " " ) } return NewMicrosoftClient ( container , id , secret ) } 
func NewMicrosoftClientFromEnv ( ) ( Client , error ) { container , ok := os . LookupEnv ( MicrosoftContainerEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MicrosoftContainerEnvVar ) } id , ok := os . LookupEnv ( MicrosoftIDEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MicrosoftIDEnvVar ) } secret , ok := os . LookupEnv ( MicrosoftSecretEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MicrosoftSecretEnvVar ) } return NewMicrosoftClient ( container , id , secret ) } 
func NewMinioClient ( endpoint , bucket , id , secret string , secure , isS3V2 bool ) ( Client , error ) { if isS3V2 { return newMinioClientV2 ( endpoint , bucket , id , secret , secure ) } return newMinioClient ( endpoint , bucket , id , secret , secure ) } 
func NewAmazonClient ( region , bucket string , creds * AmazonCreds , distribution string , reversed ... bool ) ( Client , error ) { return newAmazonClient ( region , bucket , creds , distribution , reversed ... ) } 
func NewMinioClientFromSecret ( bucket string ) ( Client , error ) { var err error if bucket == " " { bucket , err = readSecretFile ( " " ) if err != nil { return nil , err } } endpoint , err := readSecretFile ( " " ) if err != nil { return nil , err } id , err := readSecretFile ( " " ) if err != nil { return nil , err } secret , err := readSecretFile ( " " ) if err != nil { return nil , err } secure , err := readSecretFile ( " " ) if err != nil { return nil , err } isS3V2 , err := readSecretFile ( " " ) if err != nil { return nil , err } return NewMinioClient ( endpoint , bucket , id , secret , secure == " " , isS3V2 == " " ) } 
func NewMinioClientFromEnv ( ) ( Client , error ) { bucket , ok := os . LookupEnv ( MinioBucketEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MinioBucketEnvVar ) } endpoint , ok := os . LookupEnv ( MinioEndpointEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MinioEndpointEnvVar ) } id , ok := os . LookupEnv ( MinioIDEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MinioIDEnvVar ) } secret , ok := os . LookupEnv ( MinioSecretEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MinioSecretEnvVar ) } secure , ok := os . LookupEnv ( MinioSecureEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MinioSecureEnvVar ) } isS3V2 , ok := os . LookupEnv ( MinioSignatureEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , MinioSignatureEnvVar ) } return NewMinioClient ( endpoint , bucket , id , secret , secure == " " , isS3V2 == " " ) } 
func NewAmazonClientFromSecret ( bucket string , reversed ... bool ) ( Client , error ) { if err != nil { return nil , fmt . Errorf ( " " ) } if err != nil { return nil , err } } creds . ID , err = readSecretFile ( " " ) if err != nil && ! os . IsNotExist ( err ) { return nil , err } creds . Secret , err = readSecretFile ( " " ) if err != nil && ! os . IsNotExist ( err ) { return nil , err } creds . Token , err = readSecretFile ( " " ) if err != nil && ! os . IsNotExist ( err ) { return nil , err } creds . VaultAddress , err = readSecretFile ( " " ) if err != nil && ! os . IsNotExist ( err ) { return nil , err } creds . VaultRole , err = readSecretFile ( " " ) if err != nil && ! os . IsNotExist ( err ) { return nil , err } creds . VaultToken , err = readSecretFile ( " " ) if err != nil && ! os . IsNotExist ( err ) { return nil , err } return NewAmazonClient ( region , bucket , & creds , distribution , reversed ... ) } 
func NewAmazonClientFromEnv ( ) ( Client , error ) { region , ok := os . LookupEnv ( AmazonRegionEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , AmazonRegionEnvVar ) } bucket , ok := os . LookupEnv ( AmazonBucketEnvVar ) if ! ok { return nil , fmt . Errorf ( " " , AmazonBucketEnvVar ) } var creds AmazonCreds creds . ID , _ = os . LookupEnv ( AmazonIDEnvVar ) creds . Secret , _ = os . LookupEnv ( AmazonSecretEnvVar ) creds . Token , _ = os . LookupEnv ( AmazonTokenEnvVar ) creds . VaultAddress , _ = os . LookupEnv ( AmazonVaultAddrEnvVar ) creds . VaultRole , _ = os . LookupEnv ( AmazonVaultRoleEnvVar ) creds . VaultToken , _ = os . LookupEnv ( AmazonVaultTokenEnvVar ) distribution , _ := os . LookupEnv ( AmazonDistributionEnvVar ) return NewAmazonClient ( region , bucket , & creds , distribution ) } 
func NewClientFromURLAndSecret ( url * ObjectStoreURL , reversed ... bool ) ( c Client , err error ) { switch url . Store { case " " : c , err = NewAmazonClientFromSecret ( url . Bucket , reversed ... ) case " " : fallthrough case " " : c , err = NewGoogleClientFromSecret ( url . Bucket ) case " " : fallthrough case " " : case " " : c , err = NewLocalClient ( " " + url . Bucket ) } switch { case err != nil : return nil , err case c != nil : return TracingObjClient ( url . Store , c ) , nil default : return nil , fmt . Errorf ( " " , url . Bucket ) } } 
func ParseURL ( urlStr string ) ( * ObjectStoreURL , error ) { url , err := url . Parse ( urlStr ) if err != nil { return nil , fmt . Errorf ( " " , urlStr , err ) } switch url . Scheme { case " " , " " , " " , " " : return & ObjectStoreURL { Store : url . Scheme , Bucket : url . Host , Object : strings . Trim ( url . Path , " " ) , } , nil case " " , " " : if len ( parts ) < 1 { return nil , fmt . Errorf ( " " , urlStr ) } return & ObjectStoreURL { Store : url . Scheme , Bucket : parts [ 0 ] , Object : strings . Trim ( path . Join ( parts [ 1 : ] ... ) , " " ) , } , nil } return nil , fmt . Errorf ( " " , url . Scheme ) } 
func NewClientFromEnv ( storageRoot string ) ( c Client , err error ) { storageBackend , ok := os . LookupEnv ( StorageBackendEnvVar ) if ! ok { return nil , fmt . Errorf ( " " ) } switch storageBackend { case Amazon : c , err = NewAmazonClientFromEnv ( ) case Google : c , err = NewGoogleClientFromEnv ( ) case Microsoft : c , err = NewMicrosoftClientFromEnv ( ) case Minio : c , err = NewMinioClientFromEnv ( ) case Local : c , err = NewLocalClient ( storageRoot ) } switch { case err != nil : return nil , err case c != nil : return TracingObjClient ( storageBackend , c ) , nil default : return nil , fmt . Errorf ( " " , storageBackend ) } } 
func NewExponentialBackOffConfig ( ) * backoff . ExponentialBackOff { config := backoff . NewExponentialBackOff ( ) config . Multiplier = 2 config . MaxInterval = 15 * time . Minute return config } 
func ( b * BackoffReadCloser ) Close ( ) error { span , _ := tracing . AddSpanToAnyExisting ( b . ctx , " " ) defer tracing . FinishAnySpan ( span ) return b . reader . Close ( ) } 
func ( b * BackoffWriteCloser ) Close ( ) error { span , _ := tracing . AddSpanToAnyExisting ( b . ctx , " " ) defer tracing . FinishAnySpan ( span ) err := b . writer . Close ( ) if b . client . IsIgnorable ( err ) { return nil } return err } 
func IsRetryable ( client Client , err error ) bool { return isNetRetryable ( err ) || client . IsRetryable ( err ) } 
func RunStdin ( stdin io . Reader , args ... string ) error { return RunIO ( IO { Stdin : stdin } , args ... ) } 
func RunIODirPath ( ioObj IO , dirPath string , args ... string ) error { var debugStderr io . ReadWriter = bytes . NewBuffer ( nil ) var stderr io . Writer = debugStderr if ioObj . Stderr != nil { stderr = io . MultiWriter ( debugStderr , ioObj . Stderr ) } cmd := exec . Command ( args [ 0 ] , args [ 1 : ] ... ) cmd . Stdin = ioObj . Stdin cmd . Stdout = ioObj . Stdout cmd . Stderr = stderr cmd . Dir = dirPath if err := cmd . Run ( ) ; err != nil { data , _ := ioutil . ReadAll ( debugStderr ) if data != nil && len ( data ) > 0 { return fmt . Errorf ( " \n " , strings . Join ( args , " " ) , err . Error ( ) , string ( data ) ) } return fmt . Errorf ( " " , strings . Join ( args , " " ) , err . Error ( ) ) } return nil } 
func ( a * apiServer ) LogReq ( request interface { } ) { a . pachLogger . Log ( request , nil , nil , 0 ) } 
func ( a * apiServer ) LogResp ( request interface { } , response interface { } , err error , duration time . Duration ) { if err == nil { a . pachLogger . LogAtLevelFromDepth ( request , response , err , duration , logrus . InfoLevel , 4 ) } else if authclient . IsErrNotActivated ( err ) { a . pachLogger . LogAtLevelFromDepth ( request , response , err , duration , logrus . DebugLevel , 4 ) } else { a . pachLogger . LogAtLevelFromDepth ( request , response , err , duration , logrus . ErrorLevel , 4 ) } } 
func NewAuthServer ( env * serviceenv . ServiceEnv , etcdPrefix string , public bool ) ( authclient . APIServer , error ) { s := & apiServer { env : env , pachLogger : log . NewLogger ( " " ) , adminCache : make ( map [ string ] struct { } ) , tokens : col . NewCollection ( env . GetEtcdClient ( ) , path . Join ( etcdPrefix , tokensPrefix ) , nil , & authclient . TokenInfo { } , nil , nil , ) , authenticationCodes : col . NewCollection ( env . GetEtcdClient ( ) , path . Join ( etcdPrefix , authenticationCodesPrefix ) , nil , & authclient . OTPInfo { } , nil , nil , ) , acls : col . NewCollection ( env . GetEtcdClient ( ) , path . Join ( etcdPrefix , aclsPrefix ) , nil , & authclient . ACL { } , nil , nil , ) , admins : col . NewCollection ( env . GetEtcdClient ( ) , path . Join ( etcdPrefix , adminsPrefix ) , nil , & types . BoolValue { } , go s . retrieveOrGeneratePPSToken ( ) go s . watchAdmins ( path . Join ( etcdPrefix , adminsPrefix ) ) if public { } return s , nil } 
func ( a * apiServer ) activationState ( ) activationState { a . adminMu . Lock ( ) defer a . adminMu . Unlock ( ) if len ( a . adminCache ) == 0 { return none } if _ , magicUserIsAdmin := a . adminCache [ magicUser ] ; magicUserIsAdmin { return partial } return full } 
func ( a * apiServer ) retrieveOrGeneratePPSToken ( ) { var tokenProto types . StringValue ctx , cancel := context . WithTimeout ( context . Background ( ) , 2 * time . Minute ) defer cancel ( ) b := backoff . NewExponentialBackOff ( ) b . MaxElapsedTime = 60 * time . Second b . MaxInterval = 5 * time . Second if err := backoff . Retry ( func ( ) error { if _ , err := col . NewSTM ( ctx , a . env . GetEtcdClient ( ) , func ( stm col . STM ) error { superUserTokenCol := col . NewCollection ( a . env . GetEtcdClient ( ) , ppsconsts . PPSTokenKey , nil , & types . StringValue { } , nil , nil ) . ReadWrite ( stm ) if err == nil { return nil } if col . IsErrNotFound ( err ) { tokenProto . Value = token if err := superUserTokenCol . Create ( " " , & tokenProto ) ; err != nil { return err } } return nil } ) ; err != nil { return err } a . ppsToken = tokenProto . Value return nil } , b ) ; err != nil { panic ( fmt . Sprintf ( " " , err ) ) } } 
func GitHubTokenToUsername ( ctx context . Context , oauthToken string ) ( string , error ) { if ! githubTokenRegex . MatchString ( oauthToken ) && os . Getenv ( DisableAuthenticationEnvVar ) == " " { logrus . Warnf ( " " + " " + " \" \" " , oauthToken ) return authclient . GitHubPrefix + oauthToken , nil } tc := oauth2 . NewClient ( ctx , ts ) gclient := github . NewClient ( tc ) if err != nil { return " " , fmt . Errorf ( " " , err ) } verifiedUsername := user . GetLogin ( ) return authclient . GitHubPrefix + verifiedUsername , nil } 
func ( a * apiServer ) expiredClusterAdminCheck ( ctx context . Context , username string ) error { state , err := a . getEnterpriseTokenState ( ) if err != nil { return fmt . Errorf ( " " , err ) } isAdmin , err := a . isAdmin ( ctx , username ) if err != nil { return err } if state != enterpriseclient . State_ACTIVE && ! isAdmin { return errors . New ( " " + " " + " " ) } return nil } 
func ( a * apiServer ) getOneTimePassword ( ctx context . Context , username string , expiration time . Time ) ( code string , err error ) { if ! expiration . IsZero ( ) { expirationProto , err := types . TimestampProto ( expiration ) if err != nil { return " " , fmt . Errorf ( " " , expiration . String ( ) , err ) } otpInfo . SessionExpiration = expirationProto } if _ , err = col . NewSTM ( ctx , a . env . GetEtcdClient ( ) , func ( stm col . STM ) error { return a . authenticationCodes . ReadWrite ( stm ) . PutTTL ( hashToken ( code ) , otpInfo , defaultAuthCodeTTLSecs ) } ) ; err != nil { return " " , err } return code , nil } 
func ( a * apiServer ) getScope ( ctx context . Context , subject string , acl * authclient . ACL ) ( authclient . Scope , error ) { if err != nil { return authclient . Scope_NONE , fmt . Errorf ( " " + " " , err ) } for _ , g := range groups { groupScope := acl . Entries [ g ] if scope < groupScope { scope = groupScope } } return scope , nil } 
func ( a * apiServer ) setGroupsForUserInternal ( ctx context . Context , subject string , groups [ ] string ) error { _ , err := col . NewSTM ( ctx , a . env . GetEtcdClient ( ) , func ( stm col . STM ) error { members := a . members . ReadWrite ( stm ) addGroups := addToSet ( nil , groups ... ) if err := members . Get ( subject , & removeGroups ) ; err == nil { for _ , group := range groups { if removeGroups . Groups [ group ] { removeGroups . Groups = removeFromSet ( removeGroups . Groups , group ) addGroups = removeFromSet ( addGroups , group ) } } } } var membersProto authclient . Users for group := range removeGroups . Groups { if err := groups . Upsert ( group , & membersProto , func ( ) error { membersProto . Usernames = removeFromSet ( membersProto . Usernames , subject ) return nil } ) ; err != nil { return err } } return nil } ) ; err != nil { return err } } return nil } ) return err } 
func ( a * apiServer ) getGroups ( ctx context . Context , subject string ) ( [ ] string , error ) { members := a . members . ReadOnly ( ctx ) var groupsProto authclient . Groups if err := members . Get ( subject , & groupsProto ) ; err != nil { if col . IsErrNotFound ( err ) { return [ ] string { } , nil } return nil , err } return setToList ( groupsProto . Groups ) , nil } 
func hashToken ( token string ) string { sum := sha256 . Sum256 ( [ ] byte ( token ) ) return fmt . Sprintf ( " " , sum ) } 
func getAuthToken ( ctx context . Context ) ( string , error ) { md , ok := metadata . FromIncomingContext ( ctx ) if ! ok { return " " , authclient . ErrNoMetadata } if len ( md [ authclient . ContextTokenKey ] ) > 1 { return " " , fmt . Errorf ( " " ) } else if len ( md [ authclient . ContextTokenKey ] ) == 0 { return " " , authclient . ErrNotSignedIn } return md [ authclient . ContextTokenKey ] [ 0 ] , nil } 
func ( a * apiServer ) canonicalizeSubjects ( ctx context . Context , subjects [ ] string ) ( [ ] string , error ) { if subjects == nil { return [ ] string { } , nil } eg := & errgroup . Group { } canonicalizedSubjects := make ( [ ] string , len ( subjects ) ) for i , subject := range subjects { i , subject := i , subject eg . Go ( func ( ) error { subject , err := a . canonicalizeSubject ( ctx , subject ) if err != nil { return err } canonicalizedSubjects [ i ] = subject return nil } ) } if err := eg . Wait ( ) ; err != nil { return nil , err } return canonicalizedSubjects , nil } 
func ( a * apiServer ) canonicalizeSubject ( ctx context . Context , subject string ) ( string , error ) { colonIdx := strings . Index ( subject , " " ) if colonIdx < 0 { subject = authclient . GitHubPrefix + subject colonIdx = len ( authclient . GitHubPrefix ) - 1 } prefix := subject [ : colonIdx ] a . configMu . Lock ( ) defer a . configMu . Unlock ( ) } if prefix == path . Join ( " " , a . configCache . IDP . Name ) { return subject , nil } } switch prefix { case authclient . GitHubPrefix : var err error subject , err = canonicalizeGitHubUsername ( ctx , subject [ len ( authclient . GitHubPrefix ) : ] ) if err != nil { return " " , err } case authclient . PipelinePrefix , authclient . RobotPrefix : break default : return " " , fmt . Errorf ( " " , subject [ : colonIdx + 1 ] ) } return subject , nil } 
func canonicalizeGitHubUsername ( ctx context . Context , user string ) ( string , error ) { if strings . Index ( user , " " ) >= 0 { return " " , fmt . Errorf ( " " , authclient . GitHubPrefix , user ) } if os . Getenv ( DisableAuthenticationEnvVar ) == " " { } gclient := github . NewClient ( http . DefaultClient ) u , _ , err := gclient . Users . Get ( ctx , strings . ToLower ( user ) ) if err != nil { return " " , fmt . Errorf ( " \" \" " , user , err ) } return authclient . GitHubPrefix + u . GetLogin ( ) , nil } 
func Matches ( tb testing . TB , expectedMatch string , actual string , msgAndArgs ... interface { } ) { tb . Helper ( ) r , err := regexp . Compile ( expectedMatch ) if err != nil { fatal ( tb , msgAndArgs , " " , expectedMatch ) } if ! r . MatchString ( actual ) { fatal ( tb , msgAndArgs , " " , actual , expectedMatch ) } } 
func OneOfMatches ( tb testing . TB , expectedMatch string , actuals [ ] string , msgAndArgs ... interface { } ) { tb . Helper ( ) r , err := regexp . Compile ( expectedMatch ) if err != nil { fatal ( tb , msgAndArgs , " " , expectedMatch ) } for _ , actual := range actuals { if r . MatchString ( actual ) { return } } fatal ( tb , msgAndArgs , " " , actuals , expectedMatch ) } 
func Equal ( tb testing . TB , expected interface { } , actual interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) eV , aV := reflect . ValueOf ( expected ) , reflect . ValueOf ( actual ) if eV . Type ( ) != aV . Type ( ) { fatal ( tb , msgAndArgs , " \n " + " " , expected , expected , actual , actual ) } if ! reflect . DeepEqual ( expected , actual ) { fatal ( tb , msgAndArgs , " \n " + " " , expected , actual ) } } 
func NotEqual ( tb testing . TB , expected interface { } , actual interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) if reflect . DeepEqual ( expected , actual ) { fatal ( tb , msgAndArgs , " \n " + " " , expected , actual ) } } 
func ElementsEqualOrErr ( expecteds interface { } , actuals interface { } ) error { es := reflect . ValueOf ( expecteds ) as := reflect . ValueOf ( actuals ) asIsEmpty := actuals == nil || as . IsNil ( ) || ( as . Kind ( ) == reflect . Slice && as . Len ( ) == 0 ) if esIsEmpty && asIsEmpty { return nil } else if esIsEmpty { return fmt . Errorf ( " " , as . Len ( ) , actuals ) } else if asIsEmpty { return fmt . Errorf ( " \n " , es . Len ( ) , expecteds ) } } if as . Kind ( ) != reflect . Slice { return fmt . Errorf ( " \" \" " , as . Type ( ) . String ( ) ) } asArePtrs := as . Type ( ) . Elem ( ) . Kind ( ) == reflect . Ptr esElemType , asElemType := es . Type ( ) . Elem ( ) , as . Type ( ) . Elem ( ) if esArePtrs { esElemType = es . Type ( ) . Elem ( ) . Elem ( ) } if asArePtrs { asElemType = as . Type ( ) . Elem ( ) . Elem ( ) } if esElemType != asElemType { return fmt . Errorf ( " " , es . Type ( ) . Elem ( ) , as . Type ( ) . Elem ( ) ) } expectedCt := reflect . MakeMap ( reflect . MapOf ( esElemType , intType ) ) for i := 0 ; i < es . Len ( ) ; i ++ { v := es . Index ( i ) if esArePtrs { v = v . Elem ( ) } if ! expectedCt . MapIndex ( v ) . IsValid ( ) { expectedCt . SetMapIndex ( v , reflect . ValueOf ( int64 ( 1 ) ) ) } else { newCt := expectedCt . MapIndex ( v ) . Int ( ) + 1 expectedCt . SetMapIndex ( v , reflect . ValueOf ( newCt ) ) } } for i := 0 ; i < as . Len ( ) ; i ++ { v := as . Index ( i ) if asArePtrs { v = v . Elem ( ) } if ! actualCt . MapIndex ( v ) . IsValid ( ) { actualCt . SetMapIndex ( v , reflect . ValueOf ( int64 ( 1 ) ) ) } else { newCt := actualCt . MapIndex ( v ) . Int ( ) + 1 actualCt . SetMapIndex ( v , reflect . ValueOf ( newCt ) ) } } if expectedCt . Len ( ) != actualCt . Len ( ) { } for _ , key := range expectedCt . MapKeys ( ) { ec := expectedCt . MapIndex ( key ) ac := actualCt . MapIndex ( key ) if ! ec . IsValid ( ) || ! ac . IsValid ( ) || ec . Int ( ) != ac . Int ( ) { ecInt , acInt := int64 ( 0 ) , int64 ( 0 ) if ec . IsValid ( ) { ecInt = ec . Int ( ) } if ac . IsValid ( ) { acInt = ac . Int ( ) } } } return nil } 
func ElementsEqualUnderFn ( tb testing . TB , expecteds interface { } , actuals interface { } , f func ( interface { } ) interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) as := reflect . ValueOf ( actuals ) es := reflect . ValueOf ( expecteds ) } else if actuals == nil || as . IsNil ( ) || as . Len ( ) == 0 { } return } } else if expecteds == nil || es . IsNil ( ) || es . Len ( ) == 0 { fatal ( tb , msgAndArgs , fmt . Sprintf ( " \n " , as . Len ( ) , actuals ) ) } for i := 0 ; i < as . Len ( ) ; i ++ { newActuals . Index ( i ) . Set ( reflect . ValueOf ( f ( as . Index ( i ) . Interface ( ) ) ) ) } if err := ElementsEqualOrErr ( expecteds , newActuals . Interface ( ) ) ; err != nil { fatal ( tb , msgAndArgs , err . Error ( ) ) } } 
func ElementsEqual ( tb testing . TB , expecteds interface { } , actuals interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) if err := ElementsEqualOrErr ( expecteds , actuals ) ; err != nil { fatal ( tb , msgAndArgs , err . Error ( ) ) } } 
func oneOfEquals ( sliceName string , slice interface { } , elem interface { } ) ( bool , error ) { e := reflect . ValueOf ( elem ) sl := reflect . ValueOf ( slice ) if slice == nil || sl . IsNil ( ) { sl = reflect . MakeSlice ( reflect . SliceOf ( e . Type ( ) ) , 0 , 0 ) } if sl . Kind ( ) != reflect . Slice { return false , fmt . Errorf ( " \" \" " , sliceName , sl . Type ( ) . String ( ) ) } if e . Type ( ) != sl . Type ( ) . Elem ( ) { return false , nil } arePtrs := e . Kind ( ) == reflect . Ptr for i := 0 ; i < sl . Len ( ) ; i ++ { if ! arePtrs && reflect . DeepEqual ( e . Interface ( ) , sl . Index ( i ) . Interface ( ) ) { return true , nil } else if arePtrs && reflect . DeepEqual ( e . Elem ( ) . Interface ( ) , sl . Index ( i ) . Elem ( ) . Interface ( ) ) { return true , nil } } return false , nil } 
func EqualOneOf ( tb testing . TB , expecteds interface { } , actual interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) equal , err := oneOfEquals ( " " , expecteds , actual ) if err != nil { fatal ( tb , msgAndArgs , err . Error ( ) ) } if ! equal { fatal ( tb , msgAndArgs , " \n " + " " , expecteds , actual ) } } 
func NoneEquals ( tb testing . TB , expected interface { } , actuals interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) equal , err := oneOfEquals ( " " , actuals , expected ) if err != nil { fatal ( tb , msgAndArgs , err . Error ( ) ) } if equal { fatal ( tb , msgAndArgs , " \n " , expected , actuals ) } } 
func NoError ( tb testing . TB , err error , msgAndArgs ... interface { } ) { tb . Helper ( ) if err != nil { fatal ( tb , msgAndArgs , " " , err . Error ( ) ) } } 
func NoErrorWithinT ( tb testing . TB , t time . Duration , f func ( ) error , msgAndArgs ... interface { } ) { tb . Helper ( ) errCh := make ( chan error ) go func ( ) { } ( ) select { case err := <- errCh : if err != nil { fatal ( tb , msgAndArgs , " " , err . Error ( ) ) } case <- time . After ( t ) : fatal ( tb , msgAndArgs , " " , t . String ( ) ) } } 
func NoErrorWithinTRetry ( tb testing . TB , t time . Duration , f func ( ) error , msgAndArgs ... interface { } ) { tb . Helper ( ) doneCh := make ( chan struct { } ) timeout := false var err error go func ( ) { for ! timeout { if err = f ( ) ; err == nil { close ( doneCh ) break } } } ( ) select { case <- doneCh : case <- time . After ( t ) : timeout = true fatal ( tb , msgAndArgs , " " , t . String ( ) , err ) } } 
func YesError ( tb testing . TB , err error , msgAndArgs ... interface { } ) { tb . Helper ( ) if err == nil { fatal ( tb , msgAndArgs , " " , err ) } } 
func NotNil ( tb testing . TB , object interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) success := true if object == nil { success = false } else { value := reflect . ValueOf ( object ) kind := value . Kind ( ) if kind >= reflect . Chan && kind <= reflect . Slice && value . IsNil ( ) { success = false } } if ! success { fatal ( tb , msgAndArgs , " " ) } } 
func Nil ( tb testing . TB , object interface { } , msgAndArgs ... interface { } ) { tb . Helper ( ) if object == nil { return } value := reflect . ValueOf ( object ) kind := value . Kind ( ) if kind >= reflect . Chan && kind <= reflect . Slice && value . IsNil ( ) { return } fatal ( tb , msgAndArgs , " " , object ) } 
func False ( tb testing . TB , value bool , msgAndArgs ... interface { } ) { tb . Helper ( ) if value { fatal ( tb , msgAndArgs , " " ) } } 
func NewSTM ( ctx context . Context , c * v3 . Client , apply func ( STM ) error ) ( * v3 . TxnResponse , error ) { return newSTMSerializable ( ctx , c , apply , false ) } 
func NewDryrunSTM ( ctx context . Context , c * v3 . Client , apply func ( STM ) error ) error { _ , err := newSTMSerializable ( ctx , c , apply , true ) return err } 
func newSTMRepeatable ( ctx context . Context , c * v3 . Client , apply func ( STM ) error ) ( * v3 . TxnResponse , error ) { s := & stm { client : c , ctx : ctx , getOpts : [ ] v3 . OpOption { v3 . WithSerializable ( ) } } return runSTM ( s , apply , false ) } 
func newSTMSerializable ( ctx context . Context , c * v3 . Client , apply func ( STM ) error , dryrun bool ) ( * v3 . TxnResponse , error ) { s := & stmSerializable { stm : stm { client : c , ctx : ctx } , prefetch : make ( map [ string ] * v3 . GetResponse ) , } return runSTM ( s , apply , dryrun ) } 
func newSTMReadCommitted ( ctx context . Context , c * v3 . Client , apply func ( STM ) error ) ( * v3 . TxnResponse , error ) { s := & stmReadCommitted { stm { client : c , ctx : ctx , getOpts : [ ] v3 . OpOption { v3 . WithSerializable ( ) } } } return runSTM ( s , apply , true ) } 
func ( s * stm ) cmps ( ) [ ] v3 . Cmp { cmps := make ( [ ] v3 . Cmp , 0 , len ( s . rset ) ) for k , rk := range s . rset { cmps = append ( cmps , isKeyCurrent ( k , rk ) ) } return cmps } 
func ( s * stm ) puts ( ) [ ] v3 . Op { puts := make ( [ ] v3 . Op , 0 , len ( s . wset ) ) for _ , v := range s . wset { puts = append ( puts , v . op ) } return puts } 
func ( s * stmReadCommitted ) commit ( ) * v3 . TxnResponse { s . rset = nil return s . stm . commit ( ) } 
func ( s * stm ) fetchTTL ( iface STM , key string ) ( int64 , error ) { } } if len ( getResp . Kvs ) == 0 { return 0 , ErrNotFound { Key : key } } leaseID := v3 . LeaseID ( getResp . Kvs [ 0 ] . Lease ) if leaseID == 0 { s . ttlset [ key ] = 0 return 0 , nil } span , ctx := tracing . AddSpanToAnyExisting ( s . ctx , " " ) defer tracing . FinishAnySpan ( span ) leaseResp , err := s . client . TimeToLive ( ctx , leaseID ) if err != nil { panic ( stmError { err } ) } s . ttlset [ key ] = leaseResp . TTL for _ , key := range leaseResp . Keys { s . ttlset [ string ( key ) ] = leaseResp . TTL } return leaseResp . TTL , nil } 
func Pipelines ( etcdClient * etcd . Client , etcdPrefix string ) col . Collection { return col . NewCollection ( etcdClient , path . Join ( etcdPrefix , pipelinesPrefix ) , nil , & pps . EtcdPipelineInfo { } , nil , nil , ) } 
func Jobs ( etcdClient * etcd . Client , etcdPrefix string ) col . Collection { return col . NewCollection ( etcdClient , path . Join ( etcdPrefix , jobsPrefix ) , [ ] * col . Index { JobsPipelineIndex , JobsOutputIndex } , & pps . EtcdJobInfo { } , nil , nil , ) } 
func NewTicker ( b BackOff ) * Ticker { c := make ( chan time . Time ) t := & Ticker { C : c , c : c , b : b , stop : make ( chan struct { } ) , } go t . run ( ) runtime . SetFinalizer ( t , ( * Ticker ) . Stop ) return t } 
func customCheckRetry ( cluster * etcd . Cluster , numReqs int , lastResp http . Response , err error ) error { if 600 > maxRetries { maxRetries = 600 } if numReqs > maxRetries { errStr := fmt . Sprintf ( " " , cluster . Machines , err ) return & etcd . EtcdError { ErrorCode : etcd . ErrCodeEtcdNotReachable , Message : " " , Cause : errStr , Index : 0 , } } if lastResp . StatusCode == 0 { } if lastResp . StatusCode != http . StatusInternalServerError { if lastResp . Body != nil { if b , err := ioutil . ReadAll ( lastResp . Body ) ; err == nil { body = b } } errStr := fmt . Sprintf ( " " , http . StatusText ( lastResp . StatusCode ) , body ) return & etcd . EtcdError { ErrorCode : etcd . ErrCodeUnhandledHTTPStatus , Message : " " , Cause : errStr , Index : 0 , } } fmt . Println ( " " , lastResp . StatusCode ) return nil } 
func nodeToMap ( node * etcd . Node , out map [ string ] string ) bool { key := strings . TrimPrefix ( node . Key , " " ) if ! node . Dir { if node . Value == " " { if _ , ok := out [ key ] ; ok { delete ( out , key ) return true } return false } if value , ok := out [ key ] ; ! ok || value != node . Value { out [ key ] = node . Value return true } return false } changed := false for _ , node := range node . Nodes { changed = nodeToMap ( node , out ) || changed } return changed } 
func fillDefaultResourceRequests ( opts * AssetOpts , persistentDiskBackend backend ) { if persistentDiskBackend == localBackend { } if opts . PachdNonCacheMemRequest == " " { opts . PachdNonCacheMemRequest = " " } if opts . PachdCPURequest == " " { opts . PachdCPURequest = " " } if opts . EtcdMemRequest == " " { opts . EtcdMemRequest = " " } if opts . EtcdCPURequest == " " { opts . EtcdCPURequest = " " } } else { } if opts . PachdNonCacheMemRequest == " " { opts . PachdNonCacheMemRequest = " " } if opts . PachdCPURequest == " " { opts . PachdCPURequest = " " } if opts . EtcdMemRequest == " " { opts . EtcdMemRequest = " " } if opts . EtcdCPURequest == " " { opts . EtcdCPURequest = " " } } } 
func ServiceAccount ( opts * AssetOpts ) * v1 . ServiceAccount { return & v1 . ServiceAccount { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( ServiceAccountName , labels ( " " ) , nil , opts . Namespace ) , } } 
func ClusterRole ( opts * AssetOpts ) * rbacv1 . ClusterRole { return & rbacv1 . ClusterRole { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( roleName , labels ( " " ) , nil , opts . Namespace ) , Rules : rolePolicyRules , } } 
func RoleBinding ( opts * AssetOpts ) * rbacv1 . RoleBinding { return & rbacv1 . RoleBinding { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( roleBindingName , labels ( " " ) , nil , opts . Namespace ) , Subjects : [ ] rbacv1 . Subject { { Kind : " " , Name : ServiceAccountName , Namespace : opts . Namespace , } } , RoleRef : rbacv1 . RoleRef { Kind : " " , Name : roleName , } , } } 
func GetBackendSecretVolumeAndMount ( backend string ) ( v1 . Volume , v1 . VolumeMount ) { return v1 . Volume { Name : client . StorageSecretName , VolumeSource : v1 . VolumeSource { Secret : & v1 . SecretVolumeSource { SecretName : client . StorageSecretName , } , } , } , v1 . VolumeMount { Name : client . StorageSecretName , MountPath : " " + client . StorageSecretName , } } 
func GetSecretEnvVars ( storageBackend string ) [ ] v1 . EnvVar { var envVars [ ] v1 . EnvVar if storageBackend != " " { envVars = append ( envVars , v1 . EnvVar { Name : obj . StorageBackendEnvVar , Value : storageBackend , } ) } trueVal := true for envVar , secretKey := range obj . EnvVarToSecretKey { envVars = append ( envVars , v1 . EnvVar { Name : envVar , ValueFrom : & v1 . EnvVarSource { SecretKeyRef : & v1 . SecretKeySelector { LocalObjectReference : v1 . LocalObjectReference { Name : client . StorageSecretName , } , Key : secretKey , Optional : & trueVal , } , } , } ) } return envVars } 
func PachdDeployment ( opts * AssetOpts , objectStoreBackend backend , hostPath string ) * apps . Deployment { } if opts . TracePort == 0 { opts . TracePort = 651 } if opts . HTTPPort == 0 { opts . HTTPPort = 652 } if opts . PeerPort == 0 { opts . PeerPort = 653 } mem := resource . MustParse ( opts . BlockCacheSize ) mem . Add ( resource . MustParse ( opts . PachdNonCacheMemRequest ) ) cpu := resource . MustParse ( opts . PachdCPURequest ) image := AddRegistry ( opts . Registry , versionedPachdImage ( opts ) ) volumes := [ ] v1 . Volume { { Name : " " , } , } volumeMounts := [ ] v1 . VolumeMount { { Name : " " , MountPath : " " , } , } var storageHostPath string switch objectStoreBackend { case localBackend : storageHostPath = filepath . Join ( hostPath , " " ) volumes [ 0 ] . HostPath = & v1 . HostPathVolumeSource { Path : storageHostPath , } backendEnvVar = pfs . LocalBackendEnvVar case minioBackend : backendEnvVar = pfs . MinioBackendEnvVar case amazonBackend : backendEnvVar = pfs . AmazonBackendEnvVar case googleBackend : backendEnvVar = pfs . GoogleBackendEnvVar case microsoftBackend : backendEnvVar = pfs . MicrosoftBackendEnvVar } volume , mount := GetBackendSecretVolumeAndMount ( backendEnvVar ) volumes = append ( volumes , volume ) volumeMounts = append ( volumeMounts , mount ) if opts . TLS != nil { volumes = append ( volumes , v1 . Volume { Name : tlsVolumeName , VolumeSource : v1 . VolumeSource { Secret : & v1 . SecretVolumeSource { SecretName : tlsSecretName , } , } , } ) volumeMounts = append ( volumeMounts , v1 . VolumeMount { Name : tlsVolumeName , MountPath : grpcutil . TLSVolumePath , } ) } resourceRequirements := v1 . ResourceRequirements { Requests : v1 . ResourceList { v1 . ResourceCPU : cpu , v1 . ResourceMemory : mem , } , } if ! opts . NoGuaranteed { resourceRequirements . Limits = v1 . ResourceList { v1 . ResourceCPU : cpu , v1 . ResourceMemory : mem , } } return & apps . Deployment { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( pachdName , labels ( pachdName ) , nil , opts . Namespace ) , Spec : apps . DeploymentSpec { Replicas : replicas ( 1 ) , Selector : & metav1 . LabelSelector { MatchLabels : labels ( pachdName ) , } , Template : v1 . PodTemplateSpec { ObjectMeta : objectMeta ( pachdName , labels ( pachdName ) , map [ string ] string { IAMAnnotation : opts . IAMRole } , opts . Namespace ) , Spec : v1 . PodSpec { Containers : [ ] v1 . Container { { Name : pachdName , Image : image , Env : append ( [ ] v1 . EnvVar { { Name : " " , Value : " " } , { Name : " " , Value : opts . EtcdPrefix } , { Name : " " , Value : fmt . Sprintf ( " " , opts . PachdShards ) } , { Name : " " , Value : backendEnvVar } , { Name : " " , Value : storageHostPath } , { Name : " " , Value : AddRegistry ( opts . Registry , versionedWorkerImage ( opts ) ) } , { Name : " " , Value : opts . ImagePullSecret } , { Name : " " , Value : image } , { Name : " " , Value : " " } , { Name : " " , Value : opts . Version } , { Name : " " , Value : strconv . FormatBool ( opts . Metrics ) } , { Name : " " , Value : opts . LogLevel } , { Name : " " , Value : opts . BlockCacheSize } , { Name : " " , Value : opts . IAMRole } , { Name : " " , Value : strconv . FormatBool ( opts . NoExposeDockerSocket ) } , { Name : auth . DisableAuthenticationEnvVar , Value : strconv . FormatBool ( opts . DisableAuthentication ) } , { Name : " " , ValueFrom : & v1 . EnvVarSource { FieldRef : & v1 . ObjectFieldSelector { APIVersion : " " , FieldPath : " " , } , } , } , { Name : " " , ValueFrom : & v1 . EnvVarSource { ResourceFieldRef : & v1 . ResourceFieldSelector { ContainerName : " " , Resource : " " , } , } , } , { Name : " " , Value : strconv . FormatBool ( opts . ExposeObjectAPI ) } , } , GetSecretEnvVars ( " " ) ... ) , Ports : [ ] v1 . ContainerPort { { ContainerPort : opts . PachdPort , } 
func PachdService ( opts * AssetOpts ) * v1 . Service { prometheusAnnotations := map [ string ] string { " " : " " , " " : strconv . Itoa ( PrometheusPort ) , } return & v1 . Service { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( pachdName , labels ( pachdName ) , prometheusAnnotations , opts . Namespace ) , Spec : v1 . ServiceSpec { Type : v1 . ServiceTypeNodePort , Selector : map [ string ] string { " " : pachdName , } , Ports : [ ] v1 . ServicePort { { Port : 600 , } 
func GithookService ( namespace string ) * v1 . Service { name := " " return & v1 . Service { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( name , labels ( name ) , nil , namespace ) , Spec : v1 . ServiceSpec { Type : v1 . ServiceTypeLoadBalancer , Selector : map [ string ] string { " " : pachdName , } , Ports : [ ] v1 . ServicePort { { TargetPort : intstr . FromInt ( githook . GitHookPort ) , Name : " " , Port : githook . ExternalPort ( ) , } , } , } , } } 
func EtcdDeployment ( opts * AssetOpts , hostPath string ) * apps . Deployment { cpu := resource . MustParse ( opts . EtcdCPURequest ) mem := resource . MustParse ( opts . EtcdMemRequest ) var volumes [ ] v1 . Volume if hostPath == " " { volumes = [ ] v1 . Volume { { Name : " " , VolumeSource : v1 . VolumeSource { PersistentVolumeClaim : & v1 . PersistentVolumeClaimVolumeSource { ClaimName : etcdVolumeClaimName , } , } , } , } } else { volumes = [ ] v1 . Volume { { Name : " " , VolumeSource : v1 . VolumeSource { HostPath : & v1 . HostPathVolumeSource { Path : filepath . Join ( hostPath , " " ) , } , } , } , } } resourceRequirements := v1 . ResourceRequirements { Requests : v1 . ResourceList { v1 . ResourceCPU : cpu , v1 . ResourceMemory : mem , } , } if ! opts . NoGuaranteed { resourceRequirements . Limits = v1 . ResourceList { v1 . ResourceCPU : cpu , v1 . ResourceMemory : mem , } } if opts . Registry != " " { image = AddRegistry ( opts . Registry , etcdImage ) } return & apps . Deployment { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( etcdName , labels ( etcdName ) , nil , opts . Namespace ) , Spec : apps . DeploymentSpec { Replicas : replicas ( 1 ) , Selector : & metav1 . LabelSelector { MatchLabels : labels ( etcdName ) , } , Template : v1 . PodTemplateSpec { ObjectMeta : objectMeta ( etcdName , labels ( etcdName ) , nil , opts . Namespace ) , Spec : v1 . PodSpec { Containers : [ ] v1 . Container { { Name : etcdName , Image : image , } 
func EtcdStorageClass ( opts * AssetOpts , backend backend ) ( interface { } , error ) { sc := map [ string ] interface { } { " " : " " , " " : " " , " " : map [ string ] interface { } { " " : defaultEtcdStorageClassName , " " : labels ( etcdName ) , " " : opts . Namespace , } , } switch backend { case googleBackend : sc [ " " ] = " " sc [ " " ] = map [ string ] string { " " : " " , } case amazonBackend : sc [ " " ] = " " sc [ " " ] = map [ string ] string { " " : " " , } default : return nil , nil } return sc , nil } 
func EtcdVolume ( persistentDiskBackend backend , opts * AssetOpts , hostPath string , name string , size int ) ( * v1 . PersistentVolume , error ) { spec := & v1 . PersistentVolume { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( etcdVolumeName , labels ( etcdName ) , nil , opts . Namespace ) , Spec : v1 . PersistentVolumeSpec { Capacity : map [ v1 . ResourceName ] resource . Quantity { " " : resource . MustParse ( fmt . Sprintf ( " " , size ) ) , } , AccessModes : [ ] v1 . PersistentVolumeAccessMode { v1 . ReadWriteOnce } , PersistentVolumeReclaimPolicy : v1 . PersistentVolumeReclaimRetain , } , } switch persistentDiskBackend { case amazonBackend : spec . Spec . PersistentVolumeSource = v1 . PersistentVolumeSource { AWSElasticBlockStore : & v1 . AWSElasticBlockStoreVolumeSource { FSType : " " , VolumeID : name , } , } case googleBackend : spec . Spec . PersistentVolumeSource = v1 . PersistentVolumeSource { GCEPersistentDisk : & v1 . GCEPersistentDiskVolumeSource { FSType : " " , PDName : name , } , } case microsoftBackend : dataDiskURI := name split := strings . Split ( name , " " ) diskName := split [ len ( split ) - 1 ] spec . Spec . PersistentVolumeSource = v1 . PersistentVolumeSource { AzureDisk : & v1 . AzureDiskVolumeSource { DiskName : diskName , DataDiskURI : dataDiskURI , } , } case minioBackend : fallthrough case localBackend : spec . Spec . PersistentVolumeSource = v1 . PersistentVolumeSource { HostPath : & v1 . HostPathVolumeSource { Path : filepath . Join ( hostPath , " " ) , } , } default : return nil , fmt . Errorf ( " \" \" " , persistentDiskBackend ) } return spec , nil } 
func EtcdVolumeClaim ( size int , opts * AssetOpts ) * v1 . PersistentVolumeClaim { return & v1 . PersistentVolumeClaim { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( etcdVolumeClaimName , labels ( etcdName ) , nil , opts . Namespace ) , Spec : v1 . PersistentVolumeClaimSpec { Resources : v1 . ResourceRequirements { Requests : map [ v1 . ResourceName ] resource . Quantity { " " : resource . MustParse ( fmt . Sprintf ( " " , size ) ) , } , } , AccessModes : [ ] v1 . PersistentVolumeAccessMode { v1 . ReadWriteOnce } , VolumeName : etcdVolumeName , } , } } 
func EtcdNodePortService ( local bool , opts * AssetOpts ) * v1 . Service { var clientNodePort int32 if local { clientNodePort = 32379 } return & v1 . Service { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( etcdName , labels ( etcdName ) , nil , opts . Namespace ) , Spec : v1 . ServiceSpec { Type : v1 . ServiceTypeNodePort , Selector : map [ string ] string { " " : etcdName , } , Ports : [ ] v1 . ServicePort { { Port : 2379 , Name : " " , NodePort : clientNodePort , } , } , } , } } 
func EtcdHeadlessService ( opts * AssetOpts ) * v1 . Service { return & v1 . Service { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( etcdHeadlessServiceName , labels ( etcdName ) , nil , opts . Namespace ) , Spec : v1 . ServiceSpec { Selector : map [ string ] string { " " : etcdName , } , ClusterIP : " " , Ports : [ ] v1 . ServicePort { { Name : " " , Port : 2380 , } , } , } , } } 
func EtcdStatefulSet ( opts * AssetOpts , backend backend , diskSpace int ) interface { } { mem := resource . MustParse ( opts . EtcdMemRequest ) cpu := resource . MustParse ( opts . EtcdCPURequest ) initialCluster := make ( [ ] string , 0 , opts . EtcdNodes ) for i := 0 ; i < opts . EtcdNodes ; i ++ { url := fmt . Sprintf ( " " , i ) initialCluster = append ( initialCluster , fmt . Sprintf ( " " , i , url ) ) } for i , str := range etcdCmd { etcdCmd [ i ] = fmt . Sprintf ( " \" \" " , str ) } var pvcTemplates [ ] interface { } switch backend { case googleBackend , amazonBackend : storageClassName := opts . EtcdStorageClassName if storageClassName == " " { storageClassName = defaultEtcdStorageClassName } pvcTemplates = [ ] interface { } { map [ string ] interface { } { " " : map [ string ] interface { } { " " : etcdVolumeClaimName , " " : labels ( etcdName ) , " " : map [ string ] string { " " : storageClassName , } , " " : opts . Namespace , } , " " : map [ string ] interface { } { " " : map [ string ] interface { } { " " : map [ string ] interface { } { " " : resource . MustParse ( fmt . Sprintf ( " " , diskSpace ) ) , } , } , " " : [ ] string { " " } , } , } , } default : pvcTemplates = [ ] interface { } { map [ string ] interface { } { " " : map [ string ] interface { } { " " : etcdVolumeClaimName , " " : labels ( etcdName ) , " " : opts . Namespace , } , " " : map [ string ] interface { } { " " : map [ string ] interface { } { " " : map [ string ] interface { } { " " : resource . MustParse ( fmt . Sprintf ( " " , diskSpace ) ) , } , } , " " : [ ] string { " " } , } , } , } } var imagePullSecrets [ ] map [ string ] string if opts . ImagePullSecret != " " { imagePullSecrets = append ( imagePullSecrets , map [ string ] string { " " : opts . ImagePullSecret } ) } if opts . Registry != " " { image = AddRegistry ( opts . Registry , etcdImage ) } return map [ string ] interface { } { " " : " " , " " : " " , " " : map [ string ] interface { } { " " : etcdName , " " : labels ( etcdName ) , " " : opts . Namespace , } , " " : map [ string ] interface { } { } 
func DashDeployment ( opts * AssetOpts ) * apps . Deployment { return & apps . Deployment { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( dashName , labels ( dashName ) , nil , opts . Namespace ) , Spec : apps . DeploymentSpec { Selector : & metav1 . LabelSelector { MatchLabels : labels ( dashName ) , } , Template : v1 . PodTemplateSpec { ObjectMeta : objectMeta ( dashName , labels ( dashName ) , nil , opts . Namespace ) , Spec : v1 . PodSpec { Containers : [ ] v1 . Container { { Name : dashName , Image : AddRegistry ( opts . Registry , opts . DashImage ) , Ports : [ ] v1 . ContainerPort { { ContainerPort : 8080 , Name : " " , } , } , ImagePullPolicy : " " , } , { Name : grpcProxyName , Image : AddRegistry ( opts . Registry , grpcProxyImage ) , Ports : [ ] v1 . ContainerPort { { ContainerPort : 8081 , Name : " " , } , } , ImagePullPolicy : " " , } , } , ImagePullSecrets : imagePullSecrets ( opts ) , } , } , } , } } 
func DashService ( opts * AssetOpts ) * v1 . Service { return & v1 . Service { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( dashName , labels ( dashName ) , nil , opts . Namespace ) , Spec : v1 . ServiceSpec { Type : v1 . ServiceTypeNodePort , Selector : labels ( dashName ) , Ports : [ ] v1 . ServicePort { { Port : 8080 , Name : " " , NodePort : 30080 , } , { Port : 8081 , Name : " " , NodePort : 30081 , } , } , } , } } 
func MinioSecret ( bucket string , id string , secret string , endpoint string , secure , isS3V2 bool ) map [ string ] [ ] byte { secureV := " " if secure { secureV = " " } s3V2 := " " if isS3V2 { s3V2 = " " } return map [ string ] [ ] byte { " " : [ ] byte ( bucket ) , " " : [ ] byte ( id ) , " " : [ ] byte ( secret ) , " " : [ ] byte ( endpoint ) , " " : [ ] byte ( secureV ) , " " : [ ] byte ( s3V2 ) , } } 
func WriteSecret ( encoder Encoder , data map [ string ] [ ] byte , opts * AssetOpts ) error { if opts . DashOnly { return nil } secret := & v1 . Secret { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( client . StorageSecretName , labels ( client . StorageSecretName ) , nil , opts . Namespace ) , Data : data , } return encoder . Encode ( secret ) } 
func AmazonSecret ( region , bucket , id , secret , token , distribution string ) map [ string ] [ ] byte { return map [ string ] [ ] byte { " " : [ ] byte ( region ) , " " : [ ] byte ( bucket ) , " " : [ ] byte ( id ) , " " : [ ] byte ( secret ) , " " : [ ] byte ( token ) , " " : [ ] byte ( distribution ) , } } 
func AmazonVaultSecret ( region , bucket , vaultAddress , vaultRole , vaultToken , distribution string ) map [ string ] [ ] byte { return map [ string ] [ ] byte { " " : [ ] byte ( region ) , " " : [ ] byte ( bucket ) , " " : [ ] byte ( vaultAddress ) , " " : [ ] byte ( vaultRole ) , " " : [ ] byte ( vaultToken ) , " " : [ ] byte ( distribution ) , } } 
func AmazonIAMRoleSecret ( region , bucket , distribution string ) map [ string ] [ ] byte { return map [ string ] [ ] byte { " " : [ ] byte ( region ) , " " : [ ] byte ( bucket ) , " " : [ ] byte ( distribution ) , } } 
func GoogleSecret ( bucket string , cred string ) map [ string ] [ ] byte { return map [ string ] [ ] byte { " " : [ ] byte ( bucket ) , " " : [ ] byte ( cred ) , } } 
func MicrosoftSecret ( container string , id string , secret string ) map [ string ] [ ] byte { return map [ string ] [ ] byte { " " : [ ] byte ( container ) , " " : [ ] byte ( id ) , " " : [ ] byte ( secret ) , } } 
func WriteDashboardAssets ( encoder Encoder , opts * AssetOpts ) error { if err := encoder . Encode ( DashService ( opts ) ) ; err != nil { return err } return encoder . Encode ( DashDeployment ( opts ) ) } 
func WriteAssets ( encoder Encoder , opts * AssetOpts , objectStoreBackend backend , persistentDiskBackend backend , volumeSize int , hostPath string ) error { } fillDefaultResourceRequests ( opts , persistentDiskBackend ) if opts . DashOnly { if dashErr := WriteDashboardAssets ( encoder , opts ) ; dashErr != nil { return dashErr } return nil } if err := encoder . Encode ( ServiceAccount ( opts ) ) ; err != nil { return err } if ! opts . NoRBAC { if opts . LocalRoles { if err := encoder . Encode ( Role ( opts ) ) ; err != nil { return err } if err := encoder . Encode ( RoleBinding ( opts ) ) ; err != nil { return err } } else { if err := encoder . Encode ( ClusterRole ( opts ) ) ; err != nil { return err } if err := encoder . Encode ( ClusterRoleBinding ( opts ) ) ; err != nil { return err } } } if opts . EtcdNodes > 0 && opts . EtcdVolume != " " { return fmt . Errorf ( " " ) } } } else if opts . EtcdNodes > 0 { if err != nil { return err } if sc != nil { if err = encoder . Encode ( sc ) ; err != nil { return err } } } if err := encoder . Encode ( EtcdHeadlessService ( opts ) ) ; err != nil { return err } if err := encoder . Encode ( EtcdStatefulSet ( opts , persistentDiskBackend , volumeSize ) ) ; err != nil { return err } } else if opts . EtcdVolume != " " || persistentDiskBackend == localBackend { volume , err := EtcdVolume ( persistentDiskBackend , opts , hostPath , opts . EtcdVolume , volumeSize ) if err != nil { return err } if err = encoder . Encode ( volume ) ; err != nil { return err } if err = encoder . Encode ( EtcdVolumeClaim ( volumeSize , opts ) ) ; err != nil { return err } if err = encoder . Encode ( EtcdDeployment ( opts , " " ) ) ; err != nil { return err } } else { return fmt . Errorf ( " " ) } if err := encoder . Encode ( EtcdNodePortService ( objectStoreBackend == localBackend , opts ) ) ; err != nil { return err } if err := encoder . Encode ( PachdService ( opts ) ) ; err != nil { return err } if err := encoder . Encode ( PachdDeployment ( opts , objectStoreBackend , hostPath ) ) ; err != nil { return err } if ! opts . NoDash { if err := WriteDashboardAssets ( encoder , opts ) ; err != nil { return err } } if opts . TLS != nil { if err := WriteTLSSecret ( encoder , opts ) ; err != nil { return err } } return nil } 
func WriteTLSSecret ( encoder Encoder , opts * AssetOpts ) error { } if opts . TLS == nil { return fmt . Errorf ( " " ) } if opts . TLS . ServerKey == " " { return fmt . Errorf ( " \" \" " ) } if opts . TLS . ServerCert == " " { return fmt . Errorf ( " \" \" " ) } if err != nil { return fmt . Errorf ( " \" \" " , opts . TLS . ServerCert , err ) } keyBytes , err := ioutil . ReadFile ( opts . TLS . ServerKey ) if err != nil { return fmt . Errorf ( " \" \" " , opts . TLS . ServerKey , err ) } secret := & v1 . Secret { TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , ObjectMeta : objectMeta ( tlsSecretName , labels ( tlsSecretName ) , nil , opts . Namespace ) , Data : map [ string ] [ ] byte { grpcutil . TLSCertFile : certBytes , grpcutil . TLSKeyFile : keyBytes , } , } return encoder . Encode ( secret ) } 
func WriteLocalAssets ( encoder Encoder , opts * AssetOpts , hostPath string ) error { if err := WriteAssets ( encoder , opts , localBackend , localBackend , 1 , hostPath ) ; err != nil { return err } if secretErr := WriteSecret ( encoder , LocalSecret ( ) , opts ) ; secretErr != nil { return secretErr } return nil } 
func WriteCustomAssets ( encoder Encoder , opts * AssetOpts , args [ ] string , objectStoreBackend string , persistentDiskBackend string , secure , isS3V2 bool ) error { switch objectStoreBackend { case " " : if len ( args ) != s3CustomArgs { return fmt . Errorf ( " " , s3CustomArgs ) } volumeSize , err := strconv . Atoi ( args [ 1 ] ) if err != nil { return fmt . Errorf ( " " , args [ 1 ] ) } switch persistentDiskBackend { case " " : if err := WriteAssets ( encoder , opts , minioBackend , amazonBackend , volumeSize , " " ) ; err != nil { return err } case " " : if err := WriteAssets ( encoder , opts , minioBackend , googleBackend , volumeSize , " " ) ; err != nil { return err } case " " : if err := WriteAssets ( encoder , opts , minioBackend , microsoftBackend , volumeSize , " " ) ; err != nil { return err } default : return fmt . Errorf ( " " ) } return WriteSecret ( encoder , MinioSecret ( args [ 2 ] , args [ 3 ] , args [ 4 ] , args [ 5 ] , secure , isS3V2 ) , opts ) default : return fmt . Errorf ( " " ) } } 
func WriteAmazonAssets ( encoder Encoder , opts * AssetOpts , region string , bucket string , volumeSize int , creds * AmazonCreds , cloudfrontDistro string ) error { if err := WriteAssets ( encoder , opts , amazonBackend , amazonBackend , volumeSize , " " ) ; err != nil { return err } var secret map [ string ] [ ] byte if creds == nil { secret = AmazonIAMRoleSecret ( region , bucket , cloudfrontDistro ) } else if creds . ID != " " { secret = AmazonSecret ( region , bucket , creds . ID , creds . Secret , creds . Token , cloudfrontDistro ) } else if creds . VaultAddress != " " { secret = AmazonVaultSecret ( region , bucket , creds . VaultAddress , creds . VaultRole , creds . VaultToken , cloudfrontDistro ) } return WriteSecret ( encoder , secret , opts ) } 
func WriteGoogleAssets ( encoder Encoder , opts * AssetOpts , bucket string , cred string , volumeSize int ) error { if err := WriteAssets ( encoder , opts , googleBackend , googleBackend , volumeSize , " " ) ; err != nil { return err } return WriteSecret ( encoder , GoogleSecret ( bucket , cred ) , opts ) } 
func WriteMicrosoftAssets ( encoder Encoder , opts * AssetOpts , container string , id string , secret string , volumeSize int ) error { if err := WriteAssets ( encoder , opts , microsoftBackend , microsoftBackend , volumeSize , " " ) ; err != nil { return err } return WriteSecret ( encoder , MicrosoftSecret ( container , id , secret ) , opts ) } 
func Images ( opts * AssetOpts ) [ ] string { return [ ] string { versionedWorkerImage ( opts ) , etcdImage , grpcProxyImage , pauseImage , versionedPachdImage ( opts ) , opts . DashImage , } } 
func AddRegistry ( registry string , imageName string ) string { if registry == " " { return imageName } parts := strings . Split ( imageName , " " ) if len ( parts ) == 3 { parts = parts [ 1 : ] } return path . Join ( registry , parts [ 0 ] , parts [ 1 ] ) } 
func ( b * ExponentialBackOff ) withCanonicalRandomizationFactor ( ) * ExponentialBackOff { if b . RandomizationFactor < 0 { b . RandomizationFactor = 0 } else if b . RandomizationFactor > 1 { b . RandomizationFactor = 1 } return b } 
func New10sBackOff ( ) * ExponentialBackOff { b := & ExponentialBackOff { InitialInterval : 100 * time . Millisecond , RandomizationFactor : DefaultRandomizationFactor , Multiplier : DefaultMultiplier , MaxInterval : 2 * time . Second , MaxElapsedTime : 10 * time . Second , Clock : SystemClock , } return b . withCanonicalRandomizationFactor ( ) . withReset ( ) } 
func ( b * ExponentialBackOff ) Reset ( ) { b . currentInterval = b . InitialInterval b . startTime = b . Clock . Now ( ) } 
func ( b * ExponentialBackOff ) NextBackOff ( ) time . Duration { } defer b . incrementCurrentInterval ( ) return getRandomValueFromInterval ( b . RandomizationFactor , rand . Float64 ( ) , b . currentInterval ) } 
func ( b * ExponentialBackOff ) GetElapsedTime ( ) time . Duration { return b . Clock . Now ( ) . Sub ( b . startTime ) } 
func ( b * ExponentialBackOff ) incrementCurrentInterval ( ) { } else { b . currentInterval = time . Duration ( float64 ( b . currentInterval ) * b . Multiplier ) } } 
func getRandomValueFromInterval ( randomizationFactor , random float64 , currentInterval time . Duration ) time . Duration { var delta = randomizationFactor * float64 ( currentInterval ) var minInterval = float64 ( currentInterval ) - delta var maxInterval = float64 ( currentInterval ) + delta } 
func Factory ( ctx context . Context , c * logical . BackendConfig ) ( logical . Backend , error ) { result := & backend { } result . Backend = & framework . Backend { BackendType : logical . TypeLogical , PathsSpecial : & logical . Paths { Unauthenticated : [ ] string { " " } , } , Paths : [ ] * framework . Path { result . configPath ( ) , result . loginPath ( ) , result . versionPath ( ) , } , Secrets : [ ] * framework . Secret { { Type : " " , Fields : map [ string ] * framework . FieldSchema { " " : & framework . FieldSchema { Type : framework . TypeString , Description : " " , } , } , Renew : result . Renew , Revoke : result . Revoke , } } , } if err := result . Setup ( ctx , c ) ; err != nil { return nil , err } return result , nil } 
func NewAPIServer ( env * serviceenv . ServiceEnv , etcdPrefix string , treeCache * hashtree . Cache , storageRoot string , memoryRequest int64 ) ( APIServer , error ) { return newAPIServer ( env , etcdPrefix , treeCache , storageRoot , memoryRequest ) } 
func NewBlockAPIServer ( dir string , cacheBytes int64 , backend string , etcdAddress string ) ( BlockAPIServer , error ) { switch backend { case MinioBackendEnvVar : } blockAPIServer , err := newMinioBlockAPIServer ( dir , cacheBytes , etcdAddress ) if err != nil { return nil , err } return blockAPIServer , nil case AmazonBackendEnvVar : } blockAPIServer , err := newAmazonBlockAPIServer ( dir , cacheBytes , etcdAddress ) if err != nil { return nil , err } return blockAPIServer , nil case GoogleBackendEnvVar : if err != nil { return nil , err } return blockAPIServer , nil case MicrosoftBackendEnvVar : blockAPIServer , err := newMicrosoftBlockAPIServer ( dir , cacheBytes , etcdAddress ) if err != nil { return nil , err } return blockAPIServer , nil case LocalBackendEnvVar : fallthrough default : blockAPIServer , err := newLocalBlockAPIServer ( dir , cacheBytes , etcdAddress ) if err != nil { return nil , err } return blockAPIServer , nil } } 
func LocalStorage ( tb testing . TB ) ( obj . Client , * Storage ) { wd , err := os . Getwd ( ) require . NoError ( tb , err ) objC , err := obj . NewLocalClient ( wd ) require . NoError ( tb , err ) return objC , NewStorage ( objC , Prefix ) } 
func ( a * APIServer ) waitJob ( pachClient * client . APIClient , jobInfo * pps . JobInfo , logger * taggedLogger ) ( retErr error ) { logger . Logf ( " " , jobInfo . Job . ID ) ctx , cancel := context . WithCancel ( pachClient . Ctx ( ) ) pachClient = pachClient . WithCtx ( ctx ) if err != nil { if pfsserver . IsCommitNotFoundErr ( err ) || pfsserver . IsCommitDeletedErr ( err ) { defer cancel ( ) if err := a . jobs . ReadWrite ( stm ) . Get ( jobInfo . Job . ID , jobPtr ) ; err != nil { return err } return a . deleteJob ( stm , jobPtr ) } ) ; err != nil && ! col . IsErrNotFound ( err ) { return err } return nil } return err } if commitInfo . Trees == nil { defer cancel ( ) if _ , err := col . NewSTM ( ctx , a . etcdClient , func ( stm col . STM ) error { if err := a . jobs . ReadWrite ( stm ) . Get ( jobInfo . Job . ID , jobPtr ) ; err != nil { return err } if ! ppsutil . IsTerminal ( jobPtr . State ) { return ppsutil . UpdateJobState ( a . pipelines . ReadWrite ( stm ) , a . jobs . ReadWrite ( stm ) , jobPtr , pps . JobState_JOB_KILLED , " " ) } return nil } ) ; err != nil { return err } } return nil } , backoff . NewInfiniteBackOff ( ) , func ( err error , d time . Duration ) error { if isDone ( ctx ) { return err } return nil } ) } ( ) if jobInfo . JobTimeout != nil { startTime , err := types . TimestampFromProto ( jobInfo . Started ) if err != nil { return err } timeout , err := types . DurationFromProto ( jobInfo . JobTimeout ) if err != nil { return err } afterTime := startTime . Add ( timeout ) . Sub ( time . Now ( ) ) logger . Logf ( " " , afterTime ) timer := time . AfterFunc ( afterTime , func ( ) { if _ , err := pachClient . PfsAPIClient . FinishCommit ( ctx , & pfs . FinishCommitRequest { Commit : jobInfo . OutputCommit , Empty : true , } ) ; err != nil { logger . Logf ( " " , err ) } } ) defer timer . Stop ( ) } backoff . RetryNotify ( func ( ) ( retErr error ) { if err != nil { return err } if len ( failedInputs ) > 0 { reason := fmt . Sprintf ( " " , strings . Join ( failedInputs , " " ) ) if err := a . updateJobState ( ctx , jobInfo , nil , pps . JobState_JOB_FAILURE , reason ) ; err != nil { return err } _ , err := pachClient . PfsAPIClient . FinishCommit ( ctx , & pfs . FinishCommitRequest { Commit : jobInfo . OutputCommit , Empty : true , } ) return err } if err != nil { return err } parallelism , err := ppsutil . GetExpectedNumWorkers ( a . kubeClient , a . pipelineInfo . ParallelismSpec ) if err != nil { return fmt . Errorf ( " " , err ) } numHashtrees , err := ppsutil . GetExpectedNumHashtrees ( a . pipelineInfo . HashtreeSpec ) if err != nil { return fmt . Errorf ( " " , err ) } plan := & Plan { } var statsTrees [ ] * pfs . Object var statsSize uint64 if jobInfo . EnableStats { ci , err := pachClient . InspectCommit ( jobInfo . OutputCommit . Repo . Name , jobInfo . OutputCommit . ID ) if err != nil { return err } for _ , commitRange := range ci . Subvenance { if commitRange . Lower . Repo . Name == jobInfo . OutputRepo . Name && commitRange . Upper . Repo . Name == jobInfo . OutputRepo . Name { statsCommit = commitRange . Lower } } } if _ , err := col . NewSTM ( ctx , a . etcdClient , func ( stm col . STM ) error { jobs := a . jobs . ReadWrite ( stm ) jobPtr := & pps . EtcdJobInfo { } if err := jobs . Get ( jobID , jobPtr ) ; err != nil { return err } if jobPtr . State == pps . JobState_JOB_KILLED { return nil } jobPtr . DataTotal = int64 ( df . Len ( ) ) jobPtr . StatsCommit = statsCommit if err := ppsutil . UpdateJobState ( a . pipelines . ReadWrite ( stm ) , a . jobs . ReadWrite ( stm ) , jobPtr , pps . JobState_JOB_RUNNING , " " ) ; err != nil { return err } plansCol := a . plans . ReadWrite ( stm ) if err := plansCol . Get ( jobID , plan ) ; err == nil { return nil } plan = newPlan ( df , jobInfo . ChunkSpec , parallelism , numHashtrees ) return plansCol . Put ( jobID , plan ) } ) ; err != nil { return err } defer func ( ) { if retErr == nil { if _ , err := col . NewSTM ( ctx , a . etcdClient , func ( stm col . STM ) error { chunksCol := a . chunks ( jobID ) . ReadWrite ( stm ) chunksCol . DeleteAll ( ) plansCol := a . plans . ReadWrite ( stm ) return plansCol . Delete ( jobID ) } ) ; err != nil { retErr = err } } } ( ) } if jobInfo . EnableStats { if _ , err = pachClient . PfsAPIClient . FinishCommit ( ctx , & pfs . FinishCommitRequest { Commit : statsCommit , Trees : statsTrees , SizeBytes : statsSize , } ) ; err != nil { return err } } _ , err := pachClient . PfsAPIClient . FinishCommit ( ctx , & pfs . FinishCommitRequest { Commit : jobInfo . OutputCommit , Empty : true , } ) return err } var failedDatumID string for _ , high := range plan . Chunks { chunkState := & ChunkState { } if err := chunks . WatchOneF ( fmt . Sprint ( high ) , func ( e * watch . Event ) error { var key string if err := e . Unmarshal ( & key , chunkState ) ; err != nil { return err } if key != fmt . Sprint ( high ) { return nil } if chunkState . State != State_RUNNING { if chunkState . State == State_FAILED { failedDatumID = chunkState . DatumID } return errutil . ErrBreak } return nil } ) ; err != nil { return err } } if err := a . updateJobState ( ctx , jobInfo , nil , pps . JobState_JOB_MERGING , " " ) ; err != nil { return err } var trees [ ] * pfs . Object var size uint64 if failedDatumID == " " || jobInfo . EnableStats { for merge := int64 ( 0 ) ; merge < plan . Merges ; merge ++ { mergeState := & MergeState { } if err := merges . WatchOneF ( fmt . Sprint ( merge ) , func ( e * watch . Event ) error { var key string if err := e . Unmarshal ( & key , mergeState ) ; err != nil { return err } if key != fmt . Sprint ( merge ) { return nil } if mergeState . State != State_RUNNING { trees = append ( trees , mergeState . Tree ) size += mergeState . SizeBytes statsTrees = append ( statsTrees , mergeState . StatsTree ) statsSize += mergeState . StatsSizeBytes return errutil . ErrBreak } return nil } ) ; err != nil { return err } } } if jobInfo . EnableStats { if _ , err = pachClient . PfsAPIClient . FinishCommit ( ctx , & pfs . FinishCommitRequest { Commit : statsCommit , Trees : statsTrees , SizeBytes : statsSize , } ) ; err != nil { return err } } if err := a . updateJobState ( ctx , jobInfo , statsCommit , pps . JobState_JOB_FAILURE , reason ) ; err != nil { return err } _ , err = pachClient . PfsAPIClient . FinishCommit ( ctx , & pfs . FinishCommitRequest { Commit : jobInfo . OutputCommit , Empty : true , } ) return err } pbw := pbutil . NewWriter ( buf ) for i := 0 ; i < df . Len ( ) ; i ++ { files := df . Datum ( i ) datumHash := HashDatum ( a . pipelineInfo . Pipeline . Name , a . pipelineInfo . Salt , files ) if _ , err := pbw . WriteBytes ( [ ] byte ( datumHash ) ) ; err != nil { return err } } datums , _ , err := pachClient . PutObject ( buf ) if err != nil { return err } if err != nil && ! pfsserver . IsCommitFinishedErr ( err ) { if pfsserver . IsCommitNotFoundErr ( err ) || pfsserver . IsCommitDeletedErr ( err ) { return nil } return err } return a . updateJobState ( ctx , jobInfo , statsCommit , pps . JobState_JOB_FAILURE , reason ) } return a . updateJobState ( ctx , jobInfo , statsCommit , pps . JobState_JOB_SUCCESS , " " ) } , backoff . NewInfiniteBackOff ( ) , func ( err error , d time . Duration ) error { logger . Logf ( " " , err , d ) select { case <- ctx . Done ( ) : if err := ctx . Err ( ) ; err != nil { if err == context . DeadlineExceeded { reason := fmt . Sprintf ( " " , jobInfo . JobTimeout ) jobID := jobInfo . Job . ID jobPtr := & pps . EtcdJobInfo { } if err := jobs . Get ( jobID , jobPtr ) ; err != nil { return err } err = ppsutil . UpdateJobState ( a . pipelines . ReadWrite ( stm ) , a . jobs . ReadWrite ( stm ) , jobPtr , pps . JobState_JOB_FAILURE , reason ) if err != nil { return nil } return nil } ) if err != nil { return err } } return err } return err default : } jobID := jobInfo . Job . ID jobPtr := & pps . EtcdJobInfo { } if err := jobs . Get ( jobID , jobPtr ) ; err != nil { return err } jobPtr . Restart ++ return jobs . Put ( jobID , jobPtr ) } ) if err != nil { logger . Logf ( " " , jobInfo . Job . ID ) } return nil } ) return nil } 
func ( a * APIServer ) deleteJob ( stm col . STM , jobPtr * pps . EtcdJobInfo ) error { pipelinePtr := & pps . EtcdPipelineInfo { } if err := a . pipelines . ReadWrite ( stm ) . Update ( jobPtr . Pipeline . Name , pipelinePtr , func ( ) error { if pipelinePtr . JobCounts == nil { pipelinePtr . JobCounts = make ( map [ int32 ] int32 ) } if pipelinePtr . JobCounts [ int32 ( jobPtr . State ) ] != 0 { pipelinePtr . JobCounts [ int32 ( jobPtr . State ) ] -- } return nil } ) ; err != nil { return err } return a . jobs . ReadWrite ( stm ) . Delete ( jobPtr . Job . ID ) } 
func writeXML ( w http . ResponseWriter , r * http . Request , code int , v interface { } ) { w . Header ( ) . Set ( " " , " " ) w . WriteHeader ( code ) encoder := xml . NewEncoder ( w ) if err := encoder . Encode ( v ) ; err != nil { } } 
func clean1_7HashtreePath ( p string ) string { if ! strings . HasPrefix ( p , " " ) { p = " " + p } return default1_7HashtreeRoot ( pathlib . Clean ( p ) ) } 
func NewFromAddress ( addr string , options ... Option ) ( * APIClient , error ) { for _ , option := range options { if err := option ( & settings ) ; err != nil { return nil , err } } c := & APIClient { addr : addr , caCerts : settings . caCerts , limiter : limit . New ( settings . maxConcurrentStreams ) , } if err := c . connect ( settings . dialTimeout ) ; err != nil { return nil , err } return c , nil } 
func WithMaxConcurrentStreams ( streams int ) Option { return func ( settings * clientSettings ) error { settings . maxConcurrentStreams = streams return nil } } 
func WithRootCAs ( path string ) Option { return func ( settings * clientSettings ) error { settings . caCerts = x509 . NewCertPool ( ) return addCertFromFile ( settings . caCerts , path ) } } 
func WithAdditionalRootCAs ( pemBytes [ ] byte ) Option { return func ( settings * clientSettings ) error { } if ok := settings . caCerts . AppendCertsFromPEM ( pemBytes ) ; ! ok { return fmt . Errorf ( " " ) } return nil } } 
func WithDialTimeout ( t time . Duration ) Option { return func ( settings * clientSettings ) error { settings . dialTimeout = t return nil } } 
func WithAdditionalPachdCert ( ) Option { return func ( settings * clientSettings ) error { if _ , err := os . Stat ( grpcutil . TLSVolumePath ) ; err == nil { if settings . caCerts == nil { settings . caCerts = x509 . NewCertPool ( ) } return addCertFromFile ( settings . caCerts , path . Join ( grpcutil . TLSVolumePath , grpcutil . TLSCertFile ) ) } return nil } } 
func getUserMachineAddrAndOpts ( cfg * config . Config ) ( string , [ ] Option , error ) { } options , err := getCertOptionsFromEnv ( ) if err != nil { return " " , nil , err } return envAddr , options , nil } if err != nil { return " " , nil , fmt . Errorf ( " " , err ) } return cfg . V1 . PachdAddress , [ ] Option { WithAdditionalRootCAs ( pemBytes ) } , nil } return cfg . V1 . PachdAddress , nil , nil } if err != nil { return " " , nil , err } return " " , options , nil } 
func NewOnUserMachine ( reportMetrics bool , portForward bool , prefix string , options ... Option ) ( * APIClient , error ) { cfg , err := config . Read ( ) if err != nil { } addr , cfgOptions , err := getUserMachineAddrAndOpts ( cfg ) if err != nil { return nil , err } if addr == " " { addr = fmt . Sprintf ( " " , DefaultPachdNodePort ) if portForward { fw = portForwarder ( ) } } client , err := NewFromAddress ( addr , append ( options , cfgOptions ... ) ... ) if err != nil { if strings . Contains ( err . Error ( ) , " " ) { if colonIdx := strings . LastIndexByte ( addr , ':' ) ; colonIdx >= 0 { port = addr [ colonIdx + 1 : ] } } if strings . HasPrefix ( addr , " " ) || strings . HasPrefix ( addr , " " ) || strings . HasPrefix ( addr , " " ) || strings . HasPrefix ( addr , " " ) { return nil , fmt . Errorf ( " " + " " , addr , err ) } if port == " " { return nil , fmt . Errorf ( " " + " " , addr , err ) } } return nil , fmt . Errorf ( " " , addr , err ) } if cfg != nil && cfg . UserID != " " && reportMetrics { client . metricsUserID = cfg . UserID } if cfg != nil && cfg . V1 != nil && cfg . V1 . SessionToken != " " { client . authenticationToken = cfg . V1 . SessionToken } return client , nil } 
func NewInCluster ( options ... Option ) ( * APIClient , error ) { host , ok := os . LookupEnv ( " " ) if ! ok { return nil , fmt . Errorf ( " " ) } port , ok := os . LookupEnv ( " " ) if ! ok { return nil , fmt . Errorf ( " " ) } } 
func ( c * APIClient ) Close ( ) error { if err := c . clientConn . Close ( ) ; err != nil { return err } if c . portForwarder != nil { c . portForwarder . Close ( ) } return nil } 
func ( c APIClient ) DeleteAll ( ) error { if _ , err := c . AuthAPIClient . Deactivate ( c . Ctx ( ) , & auth . DeactivateRequest { } , ) ; err != nil && ! auth . IsErrNotActivated ( err ) { return grpcutil . ScrubGRPC ( err ) } if _ , err := c . PpsAPIClient . DeleteAll ( c . Ctx ( ) , & types . Empty { } , ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } if _ , err := c . PfsAPIClient . DeleteAll ( c . Ctx ( ) , & types . Empty { } , ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } 
func ( c APIClient ) SetMaxConcurrentStreams ( n int ) { c . limiter = limit . New ( n ) } 
func DefaultDialOptions ( ) [ ] grpc . DialOption { return [ ] grpc . DialOption { } 
func ( c * APIClient ) AddMetadata ( ctx context . Context ) context . Context { if c . authenticationToken != " " { clientData [ auth . ContextTokenKey ] = c . authenticationToken } clientData [ " " ] = c . metricsPrefix } outgoingMD , _ := metadata . FromOutgoingContext ( ctx ) clientMD := metadata . New ( clientData ) finalMD := make ( metadata . MD ) for _ , md := range [ ] metadata . MD { incomingMD , outgoingMD , clientMD } { for k , v := range md { finalMD [ k ] = v } } return metadata . NewOutgoingContext ( ctx , finalMD ) } 
func ( c * APIClient ) Ctx ( ) context . Context { if c . ctx == nil { return c . AddMetadata ( context . Background ( ) ) } return c . AddMetadata ( c . ctx ) } 
func ( c * APIClient ) WithCtx ( ctx context . Context ) * APIClient { result := * c result . ctx = ctx return & result } 
func NewDLock ( client * etcd . Client , prefix string ) DLock { return & etcdImpl { client : client , prefix : prefix , } } 
func ( a * APIServer ) DatumID ( data [ ] * Input ) string { hash := sha256 . New ( ) for _ , d := range data { hash . Write ( [ ] byte ( d . FileInfo . File . Path ) ) hash . Write ( d . FileInfo . Hash ) } } 
func ( logger * taggedLogger ) Logf ( formatString string , args ... interface { } ) { logger . template . Message = fmt . Sprintf ( formatString , args ... ) if ts , err := types . TimestampProto ( time . Now ( ) ) ; err == nil { logger . template . Ts = ts } else { logger . stderrLog . Printf ( " \n " , err ) return } msg , err := logger . marshaler . MarshalToString ( & logger . template ) if err != nil { logger . stderrLog . Printf ( " \n " , & logger . template , err ) return } fmt . Println ( msg ) if logger . putObjClient != nil { logger . msgCh <- msg + " \n " } } 
func NewAPIServer ( pachClient * client . APIClient , etcdClient * etcd . Client , etcdPrefix string , pipelineInfo * pps . PipelineInfo , workerName string , namespace string , hashtreeStorage string ) ( * APIServer , error ) { initPrometheus ( ) cfg , err := rest . InClusterConfig ( ) if err != nil { return nil , err } kubeClient , err := kube . NewForConfig ( cfg ) if err != nil { return nil , err } server := & APIServer { pachClient : pachClient , kubeClient : kubeClient , etcdClient : etcdClient , etcdPrefix : etcdPrefix , pipelineInfo : pipelineInfo , logMsgTemplate : pps . LogMessage { PipelineName : pipelineInfo . Pipeline . Name , WorkerID : os . Getenv ( client . PPSPodNameEnv ) , } , workerName : workerName , namespace : namespace , jobs : ppsdb . Jobs ( etcdClient , etcdPrefix ) , pipelines : ppsdb . Pipelines ( etcdClient , etcdPrefix ) , plans : col . NewCollection ( etcdClient , path . Join ( etcdPrefix , planPrefix ) , nil , & Plan { } , nil , nil ) , shards : col . NewCollection ( etcdClient , path . Join ( etcdPrefix , shardPrefix , pipelineInfo . Pipeline . Name ) , nil , & ShardInfo { } , nil , nil ) , hashtreeStorage : hashtreeStorage , claimedShard : make ( chan context . Context , 1 ) , shard : noShard , clients : make ( map [ string ] Client ) , } logger , err := server . getTaggedLogger ( pachClient , " " , nil , false ) if err != nil { return nil , err } resp , err := pachClient . Enterprise . GetState ( context . Background ( ) , & enterprise . GetStateRequest { } ) if err != nil { logger . Logf ( " \n " , err ) } else { server . exportStats = resp . State == enterprise . State_ACTIVE } numWorkers , err := ppsutil . GetExpectedNumWorkers ( kubeClient , pipelineInfo . ParallelismSpec ) if err != nil { logger . Logf ( " " , err ) numWorkers = 1 } server . numWorkers = numWorkers numShards , err := ppsutil . GetExpectedNumHashtrees ( pipelineInfo . HashtreeSpec ) if err != nil { logger . Logf ( " " , err ) numShards = 1 } server . numShards = numShards root := filepath . Join ( hashtreeStorage , uuid . NewWithoutDashes ( ) ) if err := os . MkdirAll ( filepath . Join ( root , " " , " " ) , 0777 ) ; err != nil { return nil , err } if err := os . MkdirAll ( filepath . Join ( root , " " , " " ) , 0777 ) ; err != nil { return nil , err } server . chunkCache = hashtree . NewMergeCache ( filepath . Join ( root , " " ) ) server . chunkStatsCache = hashtree . NewMergeCache ( filepath . Join ( root , " " , " " ) ) server . datumCache = hashtree . NewMergeCache ( filepath . Join ( root , " " ) ) server . datumStatsCache = hashtree . NewMergeCache ( filepath . Join ( root , " " , " " ) ) var noDocker bool if _ , err := os . Stat ( " " ) ; err != nil { noDocker = true } if pipelineInfo . Transform . Image != " " && ! noDocker { docker , err := docker . NewClientFromEnv ( ) if err != nil { return nil , err } image , err := docker . InspectImage ( pipelineInfo . Transform . Image ) if err != nil { return nil , fmt . Errorf ( " " , pipelineInfo . Transform . Image , err ) } if pipelineInfo . Transform . User == " " { pipelineInfo . Transform . User = image . Config . User } if pipelineInfo . Transform . WorkingDir == " " { pipelineInfo . Transform . WorkingDir = image . Config . WorkingDir } if server . pipelineInfo . Transform . Cmd == nil { server . pipelineInfo . Transform . Cmd = image . Config . Entrypoint } } if pipelineInfo . Transform . User != " " { user , err := lookupDockerUser ( pipelineInfo . Transform . User ) if err != nil && ! os . IsNotExist ( err ) { return nil , err } if err != nil { return nil , err } uid32 := uint32 ( uid ) server . uid = & uid32 gid , err := strconv . ParseUint ( user . Gid , 10 , 32 ) if err != nil { return nil , err } gid32 := uint32 ( gid ) server . gid = & gid32 } } switch { case pipelineInfo . Service != nil : go server . master ( " " , server . serviceSpawner ) case pipelineInfo . Spout != nil : go server . master ( " " , server . spoutSpawner ) default : go server . master ( " " , server . jobSpawner ) } go server . worker ( ) return server , nil } 
func ( a * APIServer ) runUserErrorHandlingCode ( ctx context . Context , logger * taggedLogger , environ [ ] string , stats * pps . ProcessStats , rawDatumTimeout * types . Duration ) ( retErr error ) { logger . Logf ( " " ) defer func ( start time . Time ) { if retErr != nil { logger . Logf ( " " , time . Since ( start ) , retErr ) } else { logger . Logf ( " " , time . Since ( start ) ) } } ( time . Now ( ) ) cmd := exec . CommandContext ( ctx , a . pipelineInfo . Transform . ErrCmd [ 0 ] , a . pipelineInfo . Transform . ErrCmd [ 1 : ] ... ) if a . pipelineInfo . Transform . ErrStdin != nil { cmd . Stdin = strings . NewReader ( strings . Join ( a . pipelineInfo . Transform . ErrStdin , " \n " ) + " \n " ) } cmd . Stdout = logger . userLogger ( ) cmd . Stderr = logger . userLogger ( ) cmd . Env = environ if a . uid != nil && a . gid != nil { cmd . SysProcAttr = & syscall . SysProcAttr { Credential : & syscall . Credential { Uid : * a . uid , Gid : * a . gid , } , } } cmd . Dir = a . pipelineInfo . Transform . WorkingDir err := cmd . Start ( ) if err != nil { return fmt . Errorf ( " " , err ) } if err != nil { return fmt . Errorf ( " " , err ) } if isDone ( ctx ) { if err = ctx . Err ( ) ; err != nil { return err } } } } } } return fmt . Errorf ( " " , err ) } return nil } 
func HashDatum ( pipelineName string , pipelineSalt string , data [ ] * Input ) string { hash := sha256 . New ( ) for _ , datum := range data { hash . Write ( [ ] byte ( datum . Name ) ) hash . Write ( [ ] byte ( datum . FileInfo . File . Path ) ) hash . Write ( datum . FileInfo . Hash ) } hash . Write ( [ ] byte ( pipelineName ) ) hash . Write ( [ ] byte ( pipelineSalt ) ) return client . DatumTagPrefix ( pipelineSalt ) + hex . EncodeToString ( hash . Sum ( nil ) ) } 
func HashDatum15 ( pipelineInfo * pps . PipelineInfo , data [ ] * Input ) ( string , error ) { hash := sha256 . New ( ) for _ , datum := range data { hash . Write ( [ ] byte ( datum . Name ) ) hash . Write ( [ ] byte ( datum . FileInfo . File . Path ) ) hash . Write ( datum . FileInfo . Hash ) } pipelineInfo . Transform . Env = nil defer func ( ) { pipelineInfo . Transform . Env = env } ( ) bytes , err := pipelineInfo . Transform . Marshal ( ) if err != nil { return " " , err } hash . Write ( bytes ) hash . Write ( [ ] byte ( pipelineInfo . Pipeline . Name ) ) hash . Write ( [ ] byte ( pipelineInfo . ID ) ) hash . Write ( [ ] byte ( strconv . Itoa ( int ( pipelineInfo . Version ) ) ) ) } 
func ( a * APIServer ) Status ( ctx context . Context , _ * types . Empty ) ( * pps . WorkerStatus , error ) { a . statusMu . Lock ( ) defer a . statusMu . Unlock ( ) started , err := types . TimestampProto ( a . started ) if err != nil { return nil , err } result := & pps . WorkerStatus { JobID : a . jobID , WorkerID : a . workerName , Started : started , Data : a . datum ( ) , QueueSize : atomic . LoadInt64 ( & a . queueSize ) , } return result , nil } 
func ( a * APIServer ) Cancel ( ctx context . Context , request * CancelRequest ) ( * CancelResponse , error ) { a . statusMu . Lock ( ) defer a . statusMu . Unlock ( ) if request . JobID != a . jobID { return & CancelResponse { Success : false } , nil } if ! MatchDatum ( request . DataFilters , a . datum ( ) ) { return & CancelResponse { Success : false } , nil } a . cancel ( ) a . data = nil a . started = time . Time { } a . cancel = nil return & CancelResponse { Success : true } , nil } 
func ( a * APIServer ) GetChunk ( request * GetChunkRequest , server Worker_GetChunkServer ) error { filter := hashtree . NewFilter ( a . numShards , request . Shard ) if request . Stats { return a . chunkStatsCache . Get ( request . Id , grpcutil . NewStreamingBytesWriter ( server ) , filter ) } return a . chunkCache . Get ( request . Id , grpcutil . NewStreamingBytesWriter ( server ) , filter ) } 
func ( a * APIServer ) cancelCtxIfJobFails ( jobCtx context . Context , jobCancel func ( ) , jobID string ) { logger := a . getWorkerLogger ( ) backoff . RetryNotify ( func ( ) error { } if err != nil { if col . IsErrNotFound ( err ) { jobCancel ( ) return nil } return fmt . Errorf ( " " , jobID , err ) } jobPtr := & pps . EtcdJobInfo { } if err := e . Unmarshal ( & jobID , jobPtr ) ; err != nil { return fmt . Errorf ( " " , err ) } if ppsutil . IsTerminal ( jobPtr . State ) { jobCancel ( ) } case watch . EventDelete : jobCancel ( ) case watch . EventError : return fmt . Errorf ( " " , e . Err ) } case <- jobCtx . Done ( ) : break } } } , backoff . NewInfiniteBackOff ( ) , func ( err error , d time . Duration ) error { if jobCtx . Err ( ) == context . Canceled { return err } logger . Logf ( " " , jobID , err , d ) return nil } ) } 
func ( a * APIServer ) worker ( ) { logger := a . getWorkerLogger ( ) defer retryCancel ( ) watcher , err := a . jobs . ReadOnly ( retryCtx ) . WatchByIndex ( ppsdb . JobsPipelineIndex , a . pipelineInfo . Pipeline ) if err != nil { return fmt . Errorf ( " " , err ) } defer watcher . Close ( ) NextJob : for e := range watcher . Watch ( ) { } if err := a . chunkStatsCache . Clear ( ) ; err != nil { logger . Logf ( " " , err ) } if e . Type == watch . EventError { return fmt . Errorf ( " " , e . Err ) } else if e . Type == watch . EventDelete { } jobPtr := & pps . EtcdJobInfo { } if err := e . Unmarshal ( & jobID , jobPtr ) ; err != nil { return fmt . Errorf ( " " , err ) } if ppsutil . IsTerminal ( jobPtr . State ) { continue NextJob } defer jobCancel ( ) pachClient := a . pachClient . WithCtx ( jobCtx ) if err != nil { if col . IsErrNotFound ( err ) { continue NextJob } return fmt . Errorf ( " " , jobID , err ) } if jobInfo . PipelineVersion < a . pipelineInfo . Version { continue } if jobInfo . PipelineVersion > a . pipelineInfo . Version { return fmt . Errorf ( " " + " " + " " , jobID , jobInfo . PipelineVersion , a . pipelineInfo . Version ) } if err := a . plans . ReadOnly ( jobCtx ) . GetBlock ( jobInfo . Job . ID , plan ) ; err != nil { return err } df , err := NewDatumFactory ( pachClient , jobInfo . Input ) if err != nil { return fmt . Errorf ( " " , err ) } var useParentHashTree bool parentCommitInfo , err := a . getParentCommitInfo ( jobCtx , pachClient , jobInfo . OutputCommit ) if err != nil { return err } if parentCommitInfo != nil { var err error skip , err = a . getCommitDatums ( jobCtx , pachClient , parentCommitInfo ) if err != nil { return err } var count int for i := 0 ; i < df . Len ( ) ; i ++ { files := df . Datum ( i ) datumHash := HashDatum ( a . pipelineInfo . Pipeline . Name , a . pipelineInfo . Salt , files ) if _ , ok := skip [ datumHash ] ; ok { count ++ } } if len ( skip ) == count { useParentHashTree = true } } if err != nil { return err } eg , ctx := errgroup . WithContext ( jobCtx ) if err != nil { return nil , err } return processResult , nil } , ) } ) eg . Go ( func ( ) error { return a . mergeDatums ( ctx , pachClient , jobInfo , jobID , plan , logger , df , skip , useParentHashTree ) } ) if err := eg . Wait ( ) ; err != nil { if jobCtx . Err ( ) == context . Canceled { continue NextJob } return fmt . Errorf ( " " , jobID , err ) } } return fmt . Errorf ( " " , a . pipelineInfo . Pipeline . Name ) } , backoff . NewInfiniteBackOff ( ) , func ( err error , d time . Duration ) error { logger . Logf ( " " , err , d ) return nil } ) } 
func ( a * APIServer ) processDatums ( pachClient * client . APIClient , logger * taggedLogger , jobInfo * pps . JobInfo , df DatumFactory , low , high int64 , skip map [ string ] struct { } , useParentHashTree bool ) ( result * processResult , retErr error ) { defer func ( ) { if err := a . datumCache . Clear ( ) ; err != nil && retErr == nil { logger . Logf ( " " , err ) } if err := a . datumStatsCache . Clear ( ) ; err != nil && retErr == nil { logger . Logf ( " " , err ) } } ( ) ctx := pachClient . Ctx ( ) objClient , err := obj . NewClientFromEnv ( a . hashtreeStorage ) if err != nil { return nil , err } stats := & pps . ProcessStats { } var statsMu sync . Mutex result = & processResult { } var eg errgroup . Group limiter := limit . New ( int ( a . pipelineInfo . MaxQueueSize ) ) for i := low ; i < high ; i ++ { datumIdx := i limiter . Acquire ( ) atomic . AddInt64 ( & a . queueSize , 1 ) eg . Go ( func ( ) ( retErr error ) { defer limiter . Release ( ) defer atomic . AddInt64 ( & a . queueSize , - 1 ) data := df . Datum ( int ( datumIdx ) ) logger , err := a . getTaggedLogger ( pachClient , jobInfo . Job . ID , data , a . pipelineInfo . EnableStats ) if err != nil { return err } if _ , ok := skip [ tag ] ; ok { if ! useParentHashTree { if err := a . cacheHashtree ( pachClient , tag , datumIdx ) ; err != nil { return err } } atomic . AddInt64 ( & result . datumsSkipped , 1 ) logger . Logf ( " " ) return nil } if _ , err := pachClient . InspectTag ( ctx , client . NewTag ( tag ) ) ; err == nil { if err := a . cacheHashtree ( pachClient , tag , datumIdx ) ; err != nil { return err } atomic . AddInt64 ( & result . datumsSkipped , 1 ) logger . Logf ( " " ) return nil } subStats := & pps . ProcessStats { } var inputTree , outputTree * hashtree . Ordered var statsTree * hashtree . Unordered if a . pipelineInfo . EnableStats { statsRoot := path . Join ( " " , logger . template . DatumID ) inputTree = hashtree . NewOrdered ( path . Join ( statsRoot , " " ) ) outputTree = hashtree . NewOrdered ( path . Join ( statsRoot , " " , " " ) ) statsTree = hashtree . NewUnordered ( statsRoot ) if err != nil { return err } objectInfo , err := pachClient . InspectObject ( object . Hash ) if err != nil { return err } h , err := pfs . DecodeHash ( object . Hash ) if err != nil { return err } statsTree . PutFile ( " " , h , size , objectInfo . BlockRef ) defer func ( ) { if err := a . writeStats ( pachClient , objClient , tag , subStats , logger , inputTree , outputTree , statsTree , datumIdx ) ; err != nil && retErr == nil { retErr = err } } ( ) } env := a . userCodeEnv ( jobInfo . Job . ID , jobInfo . OutputCommit . ID , data ) var dir string var failures int64 if err := backoff . RetryNotify ( func ( ) error { if isDone ( ctx ) { return ctx . Err ( ) } dir , err = a . downloadData ( pachClient , logger , data , puller , subStats , inputTree ) } } ( ) } } ( ) if err != nil { return fmt . Errorf ( " " , err ) } a . runMu . Lock ( ) defer a . runMu . Unlock ( ) pachClient := pachClient . WithCtx ( ctx ) func ( ) { a . statusMu . Lock ( ) defer a . statusMu . Unlock ( ) a . jobID = jobInfo . Job . ID a . data = data a . started = time . Now ( ) a . cancel = cancel a . stats = stats } ( ) if err := os . MkdirAll ( client . PPSInputPrefix , 0777 ) ; err != nil { return err } if err := a . linkData ( data , dir ) ; err != nil { return fmt . Errorf ( " " , err ) } defer func ( ) { if err := a . unlinkData ( data ) ; err != nil && retErr == nil { retErr = fmt . Errorf ( " " , err ) } } ( ) } return err } ) } if err := a . runUserCode ( ctx , logger , env , subStats , jobInfo . DatumTimeout ) ; err != nil { if a . pipelineInfo . Transform . ErrCmd != nil && failures == jobInfo . DatumTries - 1 { if err = a . runUserErrorHandlingCode ( ctx , logger , env , subStats , jobInfo . DatumTimeout ) ; err != nil { return fmt . Errorf ( " " , err ) } return errDatumRecovered } return fmt . Errorf ( " " , err ) } if err != nil { logger . Logf ( " " , err ) return err } atomic . AddUint64 ( & subStats . DownloadBytes , uint64 ( downSize ) ) a . reportDownloadSizeStats ( float64 ( downSize ) , logger ) return a . uploadOutput ( pachClient , dir , tag , logger , data , subStats , outputTree , datumIdx ) } , & backoff . ZeroBackOff { } , func ( err error , d time . Duration ) error { if isDone ( ctx ) { return ctx . Err ( ) } failures ++ if failures >= jobInfo . DatumTries { logger . Logf ( " " , err ) if statsTree != nil { object , size , err := pachClient . PutObject ( strings . NewReader ( err . Error ( ) ) ) if err != nil { logger . stderrLog . Printf ( " \n " , err ) } else { objectInfo , err := pachClient . InspectObject ( object . Hash ) if err != nil { return err } h , err := pfs . DecodeHash ( object . Hash ) if err != nil { return err } statsTree . PutFile ( " " , h , size , objectInfo . BlockRef ) } } return err } logger . Logf ( " " , err , d ) return nil } ) ; err == errDatumRecovered { atomic . AddInt64 ( & result . datumsRecovered , 1 ) return nil } else if err != nil { result . failedDatumID = a . DatumID ( data ) atomic . AddInt64 ( & result . datumsFailed , 1 ) return nil } statsMu . Lock ( ) defer statsMu . Unlock ( ) if err := mergeStats ( stats , subStats ) ; err != nil { logger . Logf ( " " , err ) } return nil } ) } if err := eg . Wait ( ) ; err != nil { return nil , err } if _ , err := col . NewSTM ( ctx , a . etcdClient , func ( stm col . STM ) error { jobs := a . jobs . ReadWrite ( stm ) jobID := jobInfo . Job . ID jobPtr := & pps . EtcdJobInfo { } if err := jobs . Get ( jobID , jobPtr ) ; err != nil { return err } if jobPtr . Stats == nil { jobPtr . Stats = & pps . ProcessStats { } } if err := mergeStats ( jobPtr . Stats , stats ) ; err != nil { logger . Logf ( " " , err ) } return jobs . Put ( jobID , jobPtr ) } ) ; err != nil { return nil , err } result . datumsProcessed = high - low - result . datumsSkipped - result . datumsFailed - result . datumsRecovered } return result , nil } 
func mergeStats ( x , y * pps . ProcessStats ) error { var err error if x . DownloadTime , err = plusDuration ( x . DownloadTime , y . DownloadTime ) ; err != nil { return err } if x . ProcessTime , err = plusDuration ( x . ProcessTime , y . ProcessTime ) ; err != nil { return err } if x . UploadTime , err = plusDuration ( x . UploadTime , y . UploadTime ) ; err != nil { return err } x . DownloadBytes += y . DownloadBytes x . UploadBytes += y . UploadBytes return nil } 
func ( a * APIServer ) mergeChunk ( logger * taggedLogger , high int64 , result * processResult ) ( retErr error ) { logger . Logf ( " " ) defer func ( start time . Time ) { if retErr != nil { logger . Logf ( " " , time . Since ( start ) , retErr ) } else { logger . Logf ( " " , time . Since ( start ) ) } } ( time . Now ( ) ) buf := & bytes . Buffer { } if result . datumsFailed <= 0 { if err := a . datumCache . Merge ( hashtree . NewWriter ( buf ) , nil , nil ) ; err != nil { return err } } if err := a . chunkCache . Put ( high , buf ) ; err != nil { return err } if a . pipelineInfo . EnableStats { buf . Reset ( ) if err := a . datumStatsCache . Merge ( hashtree . NewWriter ( buf ) , nil , nil ) ; err != nil { return err } return a . chunkStatsCache . Put ( high , buf ) } return nil } 
func lookupDockerUser ( userArg string ) ( _ * user . User , retErr error ) { userParts := strings . Split ( userArg , " " ) userOrUID := userParts [ 0 ] groupOrGID := " " if len ( userParts ) > 1 { groupOrGID = userParts [ 1 ] } passwd , err := os . Open ( " " ) if err != nil { return nil , err } defer func ( ) { if err := passwd . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) scanner := bufio . NewScanner ( passwd ) for scanner . Scan ( ) { parts := strings . Split ( scanner . Text ( ) , " " ) if parts [ 0 ] == userOrUID || parts [ 2 ] == userOrUID { result := & user . User { Username : parts [ 0 ] , Uid : parts [ 2 ] , Gid : parts [ 3 ] , Name : parts [ 4 ] , HomeDir : parts [ 5 ] , } if groupOrGID != " " { if parts [ 0 ] == userOrUID { if err != nil { return nil , err } result . Gid = group . Gid } else { } } return result , nil } } if err := scanner . Err ( ) ; err != nil { log . Fatal ( err ) } return nil , fmt . Errorf ( " " , userArg ) } 
func Cmds ( noMetrics * bool , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command raw := false rawFlags := pflag . NewFlagSet ( " " , pflag . ContinueOnError ) rawFlags . BoolVar ( & raw , " " , false , " " ) fullTimestamps := false fullTimestampsFlags := pflag . NewFlagSet ( " " , pflag . ContinueOnError ) fullTimestampsFlags . BoolVar ( & fullTimestamps , " " , false , " " ) marshaller := & jsonpb . Marshaler { Indent : " " } repoDocs := & cobra . Command { Short : " " , Long : `Repos, short for repository, are the top level data objects in Pachyderm. Repos contain version-controlled directories and files. Files can be of any size or type (e.g. csv, binary, images, etc).` , } cmdutil . SetDocsUsage ( repoDocs ) commands = append ( commands , cmdutil . CreateAlias ( repoDocs , " " ) ) var description string createRepo := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) _ , err = c . PfsAPIClient . CreateRepo ( c . Ctx ( ) , & pfsclient . CreateRepoRequest { Repo : client . NewRepo ( args [ 0 ] ) , Description : description , } , ) return grpcutil . ScrubGRPC ( err ) } ) , } createRepo . Flags ( ) . StringVarP ( & description , " " , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( createRepo , " " ) ) updateRepo := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) _ , err = c . PfsAPIClient . CreateRepo ( c . Ctx ( ) , & pfsclient . CreateRepoRequest { Repo : client . NewRepo ( args [ 0 ] ) , Description : description , Update : true , } , ) return grpcutil . ScrubGRPC ( err ) } ) , } updateRepo . Flags ( ) . StringVarP ( & description , " " , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( updateRepo , " " ) ) inspectRepo := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) repoInfo , err := c . InspectRepo ( args [ 0 ] ) if err != nil { return err } if repoInfo == nil { return fmt . Errorf ( " " , args [ 0 ] ) } if raw { return marshaller . Marshal ( os . Stdout , repoInfo ) } ri := & pretty . PrintableRepoInfo { RepoInfo : repoInfo , FullTimestamps : fullTimestamps , } return pretty . PrintDetailedRepoInfo ( ri ) } ) , } inspectRepo . Flags ( ) . AddFlagSet ( rawFlags ) inspectRepo . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( inspectRepo , " " ) ) listRepo := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) repoInfos , err := c . ListRepo ( ) if err != nil { return err } if raw { for _ , repoInfo := range repoInfos { if err := marshaller . Marshal ( os . Stdout , repoInfo ) ; err != nil { return err } } return nil } header := pretty . RepoHeader if ( len ( repoInfos ) > 0 ) && ( repoInfos [ 0 ] . AuthInfo != nil ) { header = pretty . RepoAuthHeader } writer := tabwriter . NewWriter ( os . Stdout , header ) for _ , repoInfo := range repoInfos { pretty . PrintRepoInfo ( writer , repoInfo , fullTimestamps ) } return writer . Flush ( ) } ) , } listRepo . Flags ( ) . AddFlagSet ( rawFlags ) listRepo . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( listRepo , " " ) ) var force bool var all bool deleteRepo := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunBoundedArgs ( 0 , 1 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if len ( args ) > 0 && all { return fmt . Errorf ( " " ) } if len ( args ) == 0 && ! all { return fmt . Errorf ( " " ) } if all { _ , err = client . PfsAPIClient . DeleteRepo ( client . Ctx ( ) , & pfsclient . DeleteRepoRequest { Force : force , All : all , } ) } else { err = client . DeleteRepo ( args [ 0 ] , force ) } if err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } ) , } deleteRepo . Flags ( ) . BoolVarP ( & force , " " , " " , false , " " ) deleteRepo . Flags ( ) . BoolVar ( & all , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( deleteRepo , " " ) ) commitDocs := & cobra . Command { Short : " " , Long : `Commits are atomic transactions on the content of a repo. Creating a commit is a multistep process: - start a new commit with 'start commit' - write files to the commit via 'put file' - finish the new commit with 'finish commit' Commits that have been started but not finished are NOT durable storage. Commits become reliable (and immutable) when they are finished. Commits can be created with another commit as a parent.` , } cmdutil . SetDocsUsage ( commitDocs ) commands = append ( commands , cmdutil . CreateAlias ( commitDocs , " " ) ) var parent string startCommit := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : `# Start a new commit in repo "test" that's not on any branch $ {{alias}} test # Start a commit in repo "test" on branch "master" $ {{alias}} test@master # Start a commit with "master" as the parent in repo "test", on a new branch "patch"; essentially a fork. $ {{alias}} test@patch -p master # Start a commit with XXX as the parent in repo "test", not on any branch $ {{alias}} test -p XXX` , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { branch , err := cmdutil . ParseBranch ( args [ 0 ] ) if err != nil { return err } cli , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer cli . Close ( ) commit , err := cli . PfsAPIClient . StartCommit ( cli . Ctx ( ) , & pfsclient . StartCommitRequest { Branch : branch . Name , Parent : client . NewCommit ( branch . Repo . Name , parent ) , Description : description , } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } fmt . Println ( commit . ID ) return nil } ) , } startCommit . Flags ( ) . StringVarP ( & parent , " " , " " , " " , " " ) startCommit . MarkFlagCustom ( " " , " " ) startCommit . Flags ( ) . StringVarP ( & description , " " , " " , " " , " " ) startCommit . Flags ( ) . StringVar ( & description , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( startCommit , " " ) ) finishCommit := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { commit , err := cmdutil . ParseCommit ( args [ 0 ] ) if err != nil { return err } cli , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer cli . Close ( ) if description != " " { _ , err := cli . PfsAPIClient . FinishCommit ( cli . Ctx ( ) , & pfsclient . FinishCommitRequest { Commit : commit , Description : description , } ) return grpcutil . ScrubGRPC ( err ) } return cli . FinishCommit ( commit . Repo . Name , commit . ID ) } ) , } finishCommit . Flags ( ) . StringVarP ( & description , " " , " " , " " , " " ) finishCommit . Flags ( ) . StringVar ( & description , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( finishCommit , " " ) ) inspectCommit := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { commit , err := cmdutil . ParseCommit ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) commitInfo , err := client . InspectCommit ( commit . Repo . Name , commit . ID ) if err != nil { return err } if commitInfo == nil { return fmt . Errorf ( " " , commit . ID ) } if raw { return marshaller . Marshal ( os . Stdout , commitInfo ) } ci := & pretty . PrintableCommitInfo { CommitInfo : commitInfo , FullTimestamps : fullTimestamps , } return pretty . PrintDetailedCommitInfo ( ci ) } ) , } inspectCommit . Flags ( ) . AddFlagSet ( rawFlags ) inspectCommit . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( inspectCommit , " " ) ) var from string var number int listCommit := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # return commits in repo "foo" $ {{alias}} foo # return commits in repo "foo" on branch "master" $ {{alias}} foo@master # return the last 20 commits in repo "foo" on branch "master" $ {{alias}} foo@master -n 20 # return commits in repo "foo" since commit XXX $ {{alias}} foo@master --from XXX` , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) ( retErr error ) { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) branch , err := cmdutil . ParseBranch ( args [ 0 ] ) if err != nil { return err } if raw { return c . ListCommitF ( branch . Repo . Name , branch . Name , from , uint64 ( number ) , func ( ci * pfsclient . CommitInfo ) error { return marshaller . Marshal ( os . Stdout , ci ) } ) } writer := tabwriter . NewWriter ( os . Stdout , pretty . CommitHeader ) if err := c . ListCommitF ( branch . Repo . Name , branch . Name , from , uint64 ( number ) , func ( ci * pfsclient . CommitInfo ) error { pretty . PrintCommitInfo ( writer , ci , fullTimestamps ) return nil } ) ; err != nil { return err } return writer . Flush ( ) } ) , } listCommit . Flags ( ) . StringVarP ( & from , " " , " " , " " , " " ) listCommit . Flags ( ) . IntVarP ( & number , " " , " " , 0 , " " ) listCommit . MarkFlagCustom ( " " , " " ) listCommit . Flags ( ) . AddFlagSet ( rawFlags ) listCommit . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( listCommit , " " ) ) printCommitIter := func ( commitIter client . CommitInfoIterator ) error { if raw { for { commitInfo , err := commitIter . Next ( ) if err == io . EOF { return nil } if err != nil { return err } if err := marshaller . Marshal ( os . Stdout , commitInfo ) ; err != nil { return err } } } writer := tabwriter . NewWriter ( os . Stdout , pretty . CommitHeader ) for { commitInfo , err := commitIter . Next ( ) if err == io . EOF { break } if err != nil { return err } pretty . PrintCommitInfo ( writer , commitInfo , fullTimestamps ) } return writer . Flush ( ) } var repos cmdutil . RepeatedStringArg flushCommit := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # return commits caused by foo@XXX and bar@YYY $ {{alias}} foo@XXX bar@YYY # return commits caused by foo@XXX leading to repos bar and baz $ {{alias}} foo@XXX -r bar -r baz` , Run : cmdutil . Run ( func ( args [ ] string ) error { commits , err := cmdutil . ParseCommits ( args ) if err != nil { return err } c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) var toRepos [ ] * pfsclient . Repo for _ , repoName := range repos { toRepos = append ( toRepos , client . NewRepo ( repoName ) ) } commitIter , err := c . FlushCommit ( commits , toRepos ) if err != nil { return err } return printCommitIter ( commitIter ) } ) , } flushCommit . Flags ( ) . VarP ( & repos , " " , " " , " " ) flushCommit . MarkFlagCustom ( " " , " " ) flushCommit . Flags ( ) . AddFlagSet ( rawFlags ) flushCommit . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( flushCommit , " " ) ) var newCommits bool subscribeCommit := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # subscribe to commits in repo "test" on branch "master" $ {{alias}} test@master # subscribe to commits in repo "test" on branch "master", but only since commit XXX. $ {{alias}} test@master --from XXX # subscribe to commits in repo "test" on branch "master", but only for new commits created from now on. $ {{alias}} test@master --new` , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { branch , err := cmdutil . ParseBranch ( args [ 0 ] ) if err != nil { return err } c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) if newCommits && from != " " { return fmt . Errorf ( " " ) } if newCommits { from = branch . Name } commitIter , err := c . SubscribeCommit ( branch . Repo . Name , branch . Name , from , pfsclient . CommitState_STARTED ) if err != nil { return err } return printCommitIter ( commitIter ) } ) , } subscribeCommit . Flags ( ) . StringVar ( & from , " " , " " , " " ) subscribeCommit . MarkFlagCustom ( " " , " " ) subscribeCommit . Flags ( ) . BoolVar ( & newCommits , " " , false , " " ) subscribeCommit . Flags ( ) . AddFlagSet ( rawFlags ) subscribeCommit . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( subscribeCommit , " " ) ) deleteCommit := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { commit , err := cmdutil . ParseCommit ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . DeleteCommit ( commit . Repo . Name , commit . ID ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( deleteCommit , " " ) ) branchDocs := & cobra . Command { Short : " " , Long : `A branch in Pachyderm is an alias for a Commit ID. The branch reference will "float" to always refer to the latest commit on the branch, known as the HEAD commit. Not all commits must be on a branch and multiple branches can refer to the same commit. Any pachctl command that can take a Commit ID, can take a branch name instead.` , } cmdutil . SetDocsUsage ( branchDocs ) commands = append ( commands , cmdutil . CreateAlias ( branchDocs , " " ) ) var branchProvenance cmdutil . RepeatedStringArg var head string createBranch := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { branch , err := cmdutil . ParseBranch ( args [ 0 ] ) if err != nil { return err } provenance , err := cmdutil . ParseBranches ( branchProvenance ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . CreateBranch ( branch . Repo . Name , branch . Name , head , provenance ) } ) , } createBranch . Flags ( ) . VarP ( & branchProvenance , " " , " " , " " ) createBranch . MarkFlagCustom ( " " , " " ) createBranch . Flags ( ) . StringVarP ( & head , " " , " " , " " , " " ) createBranch . MarkFlagCustom ( " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( createBranch , " " ) ) listBranch := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) branches , err := client . ListBranch ( args [ 0 ] ) if err != nil { return err } if raw { for _ , branch := range branches { if err := marshaller . Marshal ( os . Stdout , branch ) ; err != nil { return err } } return nil } writer := tabwriter . NewWriter ( os . Stdout , pretty . BranchHeader ) for _ , branch := range branches { pretty . PrintBranch ( writer , branch ) } return writer . Flush ( ) } ) , } listBranch . Flags ( ) . AddFlagSet ( rawFlags ) commands = append ( commands , cmdutil . CreateAlias ( listBranch , " " ) ) deleteBranch := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { branch , err := cmdutil . ParseBranch ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . DeleteBranch ( branch . Repo . Name , branch . Name , force ) } ) , } deleteBranch . Flags ( ) . BoolVarP ( & force , " " , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( deleteBranch , " " ) ) fileDocs := & cobra . Command { Short : " " , Long : `Files are the lowest level data objects in Pachyderm. Files can be of any type (e.g. csv, binary, images, etc) or size and can be written to started (but not finished) commits with 'put file'. Files can be read from commits with 'get file'.` , } cmdutil . SetDocsUsage ( fileDocs ) commands = append ( commands , cmdutil . CreateAlias ( fileDocs , " " ) ) var filePaths [ ] string var recursive bool var inputFile string var parallelism int var split string var targetFileDatums uint var targetFileBytes uint var headerRecords uint var putFileCommit bool var overwrite bool putFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # Put data from stdin as repo/branch/path: $ echo "data" | {{alias}} repo branch path # Put data from stdin as repo/branch/path and start / finish a new commit on the branch. $ echo "data" | {{alias}} -c repo branch path # Put a file from the local filesystem as repo/branch/path: $ {{alias}} repo branch path -f file # Put a file from the local filesystem as repo/branch/file: $ {{alias}} repo branch -f file # Put the contents of a directory as repo/branch/path/dir/file: $ {{alias}} -r repo branch path -f dir # Put the contents of a directory as repo/branch/dir/file: $ {{alias}} -r repo branch -f dir # Put the contents of a directory as repo/branch/file, i.e. put files at the top level: $ {{alias}} -r repo branch / -f dir # Put the data from a URL as repo/branch/path: $ {{alias}} repo branch path -f http://host/path # Put the data from a URL as repo/branch/path: $ {{alias}} repo branch -f http://host/path # Put the data from an S3 bucket as repo/branch/s3_object: $ {{alias}} repo branch -r -f s3://my_bucket # Put several files or URLs that are listed in file. # Files and URLs should be newline delimited. $ {{alias}} repo branch -i file # Put several files or URLs that are listed at URL. # NOTE this URL can reference local files, so it could cause you to put sensitive # files into your Pachyderm cluster. $ {{alias}} repo branch -i http://host/path` , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) ( retErr error ) { file , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " , client . WithMaxConcurrentStreams ( parallelism ) ) if err != nil { return err } defer c . Close ( ) pfc , err := c . NewPutFileClient ( ) if err != nil { return err } defer func ( ) { if err := pfc . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) if putFileCommit { fmt . Fprintf ( os . Stderr , " \n " ) } limiter := limit . New ( int ( parallelism ) ) var sources [ ] string if inputFile != " " { // User has provided a file listing sources, one per line. Read sources var r io . Reader if inputFile == " " { r = os . Stdin } else if url , err := url . Parse ( inputFile ) ; err == nil && url . Scheme != " " { resp , err := http . Get ( url . String ( ) ) if err != nil { return err } defer func ( ) { if err := resp . Body . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) r = resp . Body } else { inputFile , err := os . Open ( inputFile ) if err != nil { return err } defer func ( ) { if err := inputFile . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) r = inputFile } // scan line by line scanner := bufio . NewScanner ( r ) for scanner . Scan ( ) { if filePath := scanner . Text ( ) ; filePath != " " { sources = append ( sources , filePath ) } } } else { // User has provided a single source sources = filePaths } // Arguments parsed; create putFileHelper and begin copying data var eg errgroup . Group filesPut := & gosync . Map { } for _ , source := range sources { source := source if file . Path == " " { // The user has not specified a path so we use source as path. if source == " " { return fmt . Errorf ( " " ) } eg . Go ( func ( ) error { return putFileHelper ( c , pfc , file . Commit . Repo . Name , file . Commit . ID , joinPaths ( " " , source ) , source , recursive , overwrite , limiter , split , targetFileDatums , targetFileBytes , headerRecords , filesPut ) } ) } else if len ( sources ) == 1 { // We have a single source and the user has specified a path, // we use the path and ignore source (in terms of naming the file). eg . Go ( func ( ) error { return putFileHelper ( c , pfc , file . Commit . Repo . Name , file . Commit . ID , file . Path , source , recursive , overwrite , limiter , split , targetFileDatums , targetFileBytes , headerRecords , filesPut ) } ) } else { // We have multiple sources and the user has specified a path, // we use that path as a prefix for the filepaths. eg . Go ( func ( ) error { return putFileHelper ( c , pfc , file . Commit . Repo . Name , file . Commit . ID , joinPaths ( file . Path , source ) , source , recursive , overwrite , limiter , split , targetFileDatums , targetFileBytes , headerRecords , filesPut ) } ) } } return eg . Wait ( ) } ) , } putFile . Flags ( ) . StringSliceVarP ( & filePaths , " " , " " , [ ] string { " " } , " " ) putFile . Flags ( ) . StringVarP ( & inputFile , " " , " " , " " , " " ) putFile . Flags ( ) . BoolVarP ( & recursive , " " , " " , false , " " ) putFile . Flags ( ) . IntVarP ( & parallelism , " " , " " , DefaultParallelism , " " ) putFile . Flags ( ) . StringVar ( & split , " " , " " , " " ) putFile . Flags ( ) . UintVar ( & targetFileDatums , " " , 0 , " " ) putFile . Flags ( ) . UintVar ( & targetFileBytes , " " , 0 , " " ) putFile . Flags ( ) . UintVar ( & headerRecords , " " , 0 , " " ) putFile . Flags ( ) . BoolVarP ( & putFileCommit , " " , " " , false , " " ) putFile . Flags ( ) . BoolVarP ( & overwrite , " " , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( putFile , " " ) ) copyFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 2 , func ( args [ ] string ) ( retErr error ) { srcFile , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } destFile , err := cmdutil . ParseFile ( args [ 1 ] ) if err != nil { return err } c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " , client . WithMaxConcurrentStreams ( parallelism ) ) if err != nil { return err } defer c . Close ( ) return c . CopyFile ( srcFile . Commit . Repo . Name , srcFile . Commit . ID , srcFile . Path , destFile . Commit . Repo . Name , destFile . Commit . ID , destFile . Path , overwrite , ) } ) , } copyFile . Flags ( ) . BoolVarP ( & overwrite , " " , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( copyFile , " " ) ) var outputPath string getFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # get file "XXX" on branch "master" in repo "foo" $ {{alias}} foo@master:XXX # get file "XXX" in the parent of the current head of branch "master" # in repo "foo" $ {{alias}} foo@master^:XXX # get file "XXX" in the grandparent of the current head of branch "master" # in repo "foo" $ {{alias}} foo@master^2:XXX` , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { file , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if recursive { if outputPath == " " { return fmt . Errorf ( " " ) } puller := sync . NewPuller ( ) return puller . Pull ( client , outputPath , file . Commit . Repo . Name , file . Commit . ID , file . Path , false , false , parallelism , nil , " " ) } var w io . Writer // If an output path is given, print the output to stdout if outputPath == " " { w = os . Stdout } else { f , err := os . Create ( outputPath ) if err != nil { return err } defer f . Close ( ) w = f } return client . GetFile ( file . Commit . Repo . Name , file . Commit . ID , file . Path , 0 , 0 , w ) } ) , } getFile . Flags ( ) . BoolVarP ( & recursive , " " , " " , false , " " ) getFile . Flags ( ) . StringVarP ( & outputPath , " " , " " , " " , " " ) getFile . Flags ( ) . IntVarP ( & parallelism , " " , " " , DefaultParallelism , " " ) commands = append ( commands , cmdutil . CreateAlias ( getFile , " " ) ) inspectFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { file , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) fileInfo , err := client . InspectFile ( file . Commit . Repo . Name , file . Commit . ID , file . Path ) if err != nil { return err } if fileInfo == nil { return fmt . Errorf ( " " , file . Path ) } if raw { return marshaller . Marshal ( os . Stdout , fileInfo ) } return pretty . PrintDetailedFileInfo ( fileInfo ) } ) , } inspectFile . Flags ( ) . AddFlagSet ( rawFlags ) commands = append ( commands , cmdutil . CreateAlias ( inspectFile , " " ) ) var history int64 listFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # list top-level files on branch "master" in repo "foo" $ {{alias}} foo@master # list files under directory "dir" on branch "master" in repo "foo" $ {{alias}} foo@master:dir # list top-level files in the parent commit of the current head of "master" # in repo "foo" $ {{alias}} foo@master^ # list top-level files in the grandparent of the current head of "master" # in repo "foo" $ {{alias}} foo@master^2 # list the last n versions of top-level files on branch "master" in repo "foo" $ {{alias}} foo@master --history n # list all versions of top-level files on branch "master" in repo "foo" $ {{alias}} foo@master --history -1` , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { file , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if raw { return client . ListFileF ( file . Commit . Repo . Name , file . Commit . ID , file . Path , history , func ( fi * pfsclient . FileInfo ) error { return marshaller . Marshal ( os . Stdout , fi ) } ) } writer := tabwriter . NewWriter ( os . Stdout , pretty . FileHeader ) if err := client . ListFileF ( file . Commit . Repo . Name , file . Commit . ID , file . Path , history , func ( fi * pfsclient . FileInfo ) error { pretty . PrintFileInfo ( writer , fi , fullTimestamps ) return nil } ) ; err != nil { return err } return writer . Flush ( ) } ) , } listFile . Flags ( ) . AddFlagSet ( rawFlags ) listFile . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) listFile . Flags ( ) . Int64Var ( & history , " " , 0 , " " ) commands = append ( commands , cmdutil . CreateAlias ( listFile , " " ) ) globFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # Return files in repo "foo" on branch "master" that start # with the character "A". Note how the double quotation marks around the # parameter are necessary because otherwise your shell might interpret the "*". $ {{alias}} "foo@master:A*" # Return files in repo "foo" on branch "master" under directory "data". $ {{alias}} "foo@master:data/*"` , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { file , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) fileInfos , err := client . GlobFile ( file . Commit . Repo . Name , file . Commit . ID , file . Path ) if err != nil { return err } if raw { for _ , fileInfo := range fileInfos { if err := marshaller . Marshal ( os . Stdout , fileInfo ) ; err != nil { return err } } return nil } writer := tabwriter . NewWriter ( os . Stdout , pretty . FileHeader ) for _ , fileInfo := range fileInfos { pretty . PrintFileInfo ( writer , fileInfo , fullTimestamps ) } return writer . Flush ( ) } ) , } globFile . Flags ( ) . AddFlagSet ( rawFlags ) globFile . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( globFile , " " ) ) var shallow bool diffFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # Return the diff of the file "path" of the repo "foo" between the head of the # "master" branch and its parent. $ {{alias}} foo@master:path # Return the diff between the master branches of repos foo and bar at paths # path1 and path2, respectively. $ {{alias}} foo@master:path1 bar@master:path2` , Run : cmdutil . RunBoundedArgs ( 1 , 2 , func ( args [ ] string ) error { newFile , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } oldFile := client . NewFile ( " " , " " , " " ) if len ( args ) == 2 { oldFile , err = cmdutil . ParseFile ( args [ 1 ] ) if err != nil { return err } } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) newFiles , oldFiles , err := client . DiffFile ( newFile . Commit . Repo . Name , newFile . Commit . ID , newFile . Path , oldFile . Commit . Repo . Name , oldFile . Commit . ID , oldFile . Path , shallow , ) if err != nil { return err } if len ( newFiles ) > 0 { fmt . Println ( " " ) writer := tabwriter . NewWriter ( os . Stdout , pretty . FileHeader ) for _ , fileInfo := range newFiles { pretty . PrintFileInfo ( writer , fileInfo , fullTimestamps ) } if err := writer . Flush ( ) ; err != nil { return err } } if len ( oldFiles ) > 0 { fmt . Println ( " " ) writer := tabwriter . NewWriter ( os . Stdout , pretty . FileHeader ) for _ , fileInfo := range oldFiles { pretty . PrintFileInfo ( writer , fileInfo , fullTimestamps ) } if err := writer . Flush ( ) ; err != nil { return err } } return nil } ) , } diffFile . Flags ( ) . BoolVarP ( & shallow , " " , " " , false , " " ) diffFile . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( diffFile , " " ) ) deleteFile := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { file , err := cmdutil . ParseFile ( args [ 0 ] ) if err != nil { return err } client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . DeleteFile ( file . Commit . Repo . Name , file . Commit . ID , file . Path ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( deleteFile , " " ) ) objectDocs := & cobra . Command { Short : " " , Long : `Objects are content-addressed blobs of data that are directly stored in the backend object store. Objects are a low-level resource and should not be accessed directly by most users.` , } cmdutil . SetDocsUsage ( objectDocs ) commands = append ( commands , cmdutil . CreateAlias ( objectDocs , " " ) ) getObject := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . GetObject ( args [ 0 ] , os . Stdout ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( getObject , " " ) ) tagDocs := & cobra . Command { Short : " " , Long : `Tags are aliases for objects. Many tags can refer to the same object. Tags are a low-level resource and should not be accessed directly by most users.` , } cmdutil . SetDocsUsage ( tagDocs ) commands = append ( commands , cmdutil . CreateAlias ( tagDocs , " " ) ) getTag := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) return client . GetTag ( args [ 0 ] , os . Stdout ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( getTag , " " ) ) var debug bool var commits cmdutil . RepeatedStringArg mount := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) mountPoint := args [ 0 ] commits , err := parseCommits ( commits ) if err != nil { return err } opts := & fuse . Options { Fuse : & nodefs . Options { Debug : debug , } , Commits : commits , } return fuse . Mount ( client , mountPoint , opts ) } ) , } mount . Flags ( ) . BoolVarP ( & debug , " " , " " , false , " " ) mount . Flags ( ) . VarP ( & commits , " " , " " , " \" \" " ) mount . MarkFlagCustom ( " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( mount , " " ) ) unmount := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunBoundedArgs ( 0 , 1 , func ( args [ ] string ) error { if len ( args ) == 1 { return syscall . Unmount ( args [ 0 ] , 0 ) } if all { stdin := strings . NewReader ( ` mount | grep pfs:// | cut -f 3 -d " " ` ) var stdout bytes . Buffer if err := cmdutil . RunIO ( cmdutil . IO { Stdin : stdin , Stdout : & stdout , Stderr : os . Stderr , } , " " ) ; err != nil { return err } scanner := bufio . NewScanner ( & stdout ) var mounts [ ] string for scanner . Scan ( ) { mounts = append ( mounts , scanner . Text ( ) ) } if len ( mounts ) == 0 { fmt . Println ( " " ) return nil } fmt . Printf ( " \n " ) for _ , mount := range mounts { fmt . Printf ( " \n " , mount ) } r := bufio . NewReader ( os . Stdin ) bytes , err := r . ReadBytes ( '\n' ) if err != nil { return err } if bytes [ 0 ] == 'y' || bytes [ 0 ] == 'Y' { for _ , mount := range mounts { if err := syscall . Unmount ( mount , 0 ) ; err != nil { return err } } } } return nil } ) , } unmount . Flags ( ) . BoolVarP ( & all , " " , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( unmount , " " ) ) return commands } 
func IsCommitNotFoundErr ( err error ) bool { if err == nil { return false } return commitNotFoundRe . MatchString ( grpcutil . ScrubGRPC ( err ) . Error ( ) ) } 
func IsCommitDeletedErr ( err error ) bool { if err == nil { return false } return commitDeletedRe . MatchString ( grpcutil . ScrubGRPC ( err ) . Error ( ) ) } 
func IsCommitFinishedErr ( err error ) bool { if err == nil { return false } return commitFinishedRe . MatchString ( grpcutil . ScrubGRPC ( err ) . Error ( ) ) } 
func IsRepoNotFoundErr ( err error ) bool { if err == nil { return false } return repoNotFoundRe . MatchString ( err . Error ( ) ) } 
func IsBranchNotFoundErr ( err error ) bool { if err == nil { return false } return branchNotFoundRe . MatchString ( err . Error ( ) ) } 
func IsFileNotFoundErr ( err error ) bool { if err == nil { return false } return fileNotFoundRe . MatchString ( err . Error ( ) ) } 
func ( c APIClient ) Version ( ) ( string , error ) { v , err := c . VersionAPIClient . GetVersion ( c . Ctx ( ) , & types . Empty { } ) if err != nil { return " " , grpcutil . ScrubGRPC ( err ) } return version . PrettyPrintVersion ( v ) , nil } 
func validateRepoName ( name string ) error { match , _ := regexp . MatchString ( " " , name ) if ! match { return fmt . Errorf ( " " , name ) } return nil } 
func newDriver ( env * serviceenv . ServiceEnv , etcdPrefix string , treeCache * hashtree . Cache , storageRoot string , memoryRequest int64 ) ( * driver , error ) { } d := & driver { etcdClient : etcdClient , prefix : etcdPrefix , repos : pfsdb . Repos ( etcdClient , etcdPrefix ) , putFileRecords : pfsdb . PutFileRecords ( etcdClient , etcdPrefix ) , commits : func ( repo string ) col . Collection { return pfsdb . Commits ( etcdClient , etcdPrefix , repo ) } , branches : func ( repo string ) col . Collection { return pfsdb . Branches ( etcdClient , etcdPrefix , repo ) } , openCommits : pfsdb . OpenCommits ( etcdClient , etcdPrefix ) , treeCache : treeCache , storageRoot : storageRoot , repoInfo := & pfs . RepoInfo { Repo : repo , Created : now ( ) , } if _ , err := col . NewSTM ( context . Background ( ) , etcdClient , func ( stm col . STM ) error { repos := d . repos . ReadWrite ( stm ) return repos . Create ( repo . Name , repoInfo ) } ) ; err != nil && ! col . IsErrExists ( err ) { return nil , err } return d , nil } 
func ( d * driver ) checkIsAuthorized ( pachClient * client . APIClient , r * pfs . Repo , s auth . Scope ) error { ctx := pachClient . Ctx ( ) me , err := pachClient . WhoAmI ( ctx , & auth . WhoAmIRequest { } ) if auth . IsErrNotActivated ( err ) { return nil } resp , err := pachClient . AuthAPIClient . Authorize ( ctx , & auth . AuthorizeRequest { Repo : r . Name , Scope : s , } ) if err != nil { return fmt . Errorf ( " \" \" " , r . Name , grpcutil . ScrubGRPC ( err ) ) } if ! resp . Authorized { return & auth . ErrNotAuthorized { Subject : me . Username , Repo : r . Name , Required : s } } return nil } 
func ( d * driver ) makeCommit ( pachClient * client . APIClient , ID string , parent * pfs . Commit , branch string , provenance [ ] * pfs . CommitProvenance , treeRef * pfs . Object , recordFiles [ ] string , records [ ] * pfs . PutFileRecords , description string ) ( * pfs . Commit , error ) { } } if newCommit . ID == " " { newCommit . ID = uuid . NewWithoutDashes ( ) } newCommitInfo := & pfs . CommitInfo { Commit : newCommit , Started : now ( ) , Description : description , } if treeRef != nil { var err error tree , err = hashtree . GetHashTreeObject ( pachClient , d . storageRoot , treeRef ) if err != nil { return nil , err } } repos := d . repos . ReadWrite ( stm ) commits := d . commits ( parent . Repo . Name ) . ReadWrite ( stm ) branches := d . branches ( parent . Repo . Name ) . ReadWrite ( stm ) if err := repos . Get ( parent . Repo . Name , repoInfo ) ; err != nil { return err } if err := branches . Upsert ( branch , branchInfo , func ( ) error { } for _ , p := range branchInfo . Provenance { if p . Repo . Name == ppsconsts . SpecRepo { provenanceCount -- break } } if provenanceCount > 0 && treeRef == nil { return fmt . Errorf ( " " ) } branchInfo . Head = newCommit branchInfo . Branch = client . NewBranch ( newCommit . Repo . Name , branch ) return nil } ) ; err != nil { return err } } if err != nil { return fmt . Errorf ( " " , err ) } } if err := commits . Update ( parent . ID , parentCommitInfo , func ( ) error { newCommitInfo . ParentCommit = parent } parentCommitInfo . ChildCommits = append ( parentCommitInfo . ChildCommits , newCommit ) return nil } ) ; err != nil { } } if err != nil { return err } tree , err = parentTree . Copy ( ) if err != nil { return err } for i , record := range records { if err := d . applyWrite ( recordFiles [ i ] , record , tree ) ; err != nil { return err } } if err := tree . Hash ( ) ; err != nil { return err } treeRef , err = hashtree . PutHashTree ( pachClient , tree ) if err != nil { return err } } newCommitInfo . SizeBytes = uint64 ( tree . FSSize ( ) ) newCommitInfo . Finished = now ( ) } } else { if err := d . openCommits . ReadWrite ( stm ) . Put ( newCommit . ID , newCommit ) ; err != nil { return err } } } for _ , prov := range provenance { newCommitProv [ prov . Commit . ID ] = prov provCommitInfo := & pfs . CommitInfo { } if err := d . commits ( prov . Commit . Repo . Name ) . ReadWrite ( stm ) . Get ( prov . Commit . ID , provCommitInfo ) ; err != nil { return err } for _ , c := range provCommitInfo . Provenance { newCommitProv [ c . Commit . ID ] = c } } provCommitInfo := & pfs . CommitInfo { } if err := d . commits ( prov . Commit . Repo . Name ) . ReadWrite ( stm ) . Update ( prov . Commit . ID , provCommitInfo , func ( ) error { appendSubvenance ( provCommitInfo , newCommitInfo ) return nil } ) ; err != nil { return err } } } } return nil } ) ; err != nil { return nil , err } return newCommit , nil } 
func ( d * driver ) writeFinishedCommit ( ctx context . Context , commit * pfs . Commit , commitInfo * pfs . CommitInfo ) error { _ , err := col . NewSTM ( ctx , d . etcdClient , func ( stm col . STM ) error { commits := d . commits ( commit . Repo . Name ) . ReadWrite ( stm ) if err := commits . Put ( commit . ID , commitInfo ) ; err != nil { return err } if err := d . openCommits . ReadWrite ( stm ) . Delete ( commit . ID ) ; err != nil { return fmt . Errorf ( " " , commit . ID , err ) } repoInfo := new ( pfs . RepoInfo ) if err := repos . Get ( commit . Repo . Name , repoInfo ) ; err != nil { return err } for _ , branch := range repoInfo . Branches { if branch . Name == " " { branchInfo := & pfs . BranchInfo { } if err := d . branches ( commit . Repo . Name ) . ReadWrite ( stm ) . Get ( branch . Name , branchInfo ) ; err != nil { return err } if err := repos . Put ( commit . Repo . Name , repoInfo ) ; err != nil { return err } } } } return nil } ) return err } 
func ( d * driver ) propagateCommit ( stm col . STM , branch * pfs . Branch ) error { if branch == nil { return fmt . Errorf ( " " ) } branchInfo := & pfs . BranchInfo { } if err := d . branches ( branch . Repo . Name ) . ReadWrite ( stm ) . Get ( branch . Name , branchInfo ) ; err != nil { return err } subvBranchInfos = append ( subvBranchInfos , branchInfo ) for _ , subvBranch := range branchInfo . Subvenance { subvBranchInfo := & pfs . BranchInfo { } if err := d . branches ( subvBranch . Repo . Name ) . ReadWrite ( stm ) . Get ( subvBranch . Name , subvBranchInfo ) ; err != nil { return err } subvBranchInfos = append ( subvBranchInfos , subvBranchInfo ) } var head * pfs . CommitInfo if branchInfo . Head != nil { head = & pfs . CommitInfo { } if err := d . commits ( branch . Repo . Name ) . ReadWrite ( stm ) . Get ( branchInfo . Head . ID , head ) ; err != nil { return err } } repo := branch . Repo commits := d . commits ( repo . Name ) . ReadWrite ( stm ) branches := d . branches ( repo . Name ) . ReadWrite ( stm ) commitProvMap := make ( map [ string ] * pfs . CommitProvenance ) for _ , provBranch := range branchInfo . Provenance { provBranchInfo := & pfs . BranchInfo { } if err := d . branches ( provBranch . Repo . Name ) . ReadWrite ( stm ) . Get ( provBranch . Name , provBranchInfo ) ; err != nil && ! col . IsErrNotFound ( err ) { return fmt . Errorf ( " " , provBranch . Repo . Name , provBranch . Name , err ) } if provBranchInfo . Head == nil { continue } if head != nil { for _ , commitProv := range head . Provenance { commitProvMap [ key ( commitProv . Commit . ID , commitProv . Branch . Name ) ] = commitProv } } if len ( commitProvMap ) == 0 { } if err := commits . Get ( branchInfo . Head . ID , branchHeadInfo ) ; err != nil { return pfsserver . ErrCommitNotFound { branchInfo . Head } } headIsSubset := false for _ , v := range commitProvMap { matched := false for _ , c := range branchHeadInfo . Provenance { if c . Commit . ID == v . Commit . ID { matched = true } } headIsSubset = matched if ! headIsSubset { break } } if len ( branchHeadInfo . Provenance ) >= len ( commitProvMap ) && headIsSubset { } } for _ , p := range commitProvMap { if p . Branch . Repo . Name != ppsconsts . SpecRepo { allSpec = false break } } if allSpec { } newCommitInfo := & pfs . CommitInfo { Commit : newCommit , Started : now ( ) , } if branchInfo . Head != nil { parentCommitInfo := & pfs . CommitInfo { } if err := commits . Update ( newCommitInfo . ParentCommit . ID , parentCommitInfo , func ( ) error { parentCommitInfo . ChildCommits = append ( parentCommitInfo . ChildCommits , newCommit ) return nil } ) ; err != nil { return err } } branchInfo . Head = newCommit branchInfo . Name = branch . Name branchInfo . Branch = branch newCommitInfo . Branch = branch if err := branches . Put ( branch . Name , branchInfo ) ; err != nil { return err } if err := d . commits ( prov . Commit . Repo . Name ) . ReadWrite ( stm ) . Update ( prov . Commit . ID , provCommitInfo , func ( ) error { appendSubvenance ( provCommitInfo , newCommitInfo ) return nil } ) ; err != nil { return err } } } if err := d . openCommits . ReadWrite ( stm ) . Put ( newCommit . ID , newCommit ) ; err != nil { return err } } return nil } 
func ( d * driver ) inspectCommit ( pachClient * client . APIClient , commit * pfs . Commit , blockState pfs . CommitState ) ( * pfs . CommitInfo , error ) { ctx := pachClient . Ctx ( ) if commit == nil { return nil , fmt . Errorf ( " " ) } if err := d . checkIsAuthorized ( pachClient , commit . Repo , auth . Scope_READER ) ; err != nil { return nil , err } if _ , err := col . NewSTM ( ctx , d . etcdClient , func ( stm col . STM ) error { var err error commitInfo , err = d . resolveCommit ( stm , commit ) return err } ) ; err != nil { return nil , err } commits := d . commits ( commit . Repo . Name ) . ReadOnly ( ctx ) if blockState == pfs . CommitState_READY { } } if blockState == pfs . CommitState_FINISHED { if err != nil { return err } defer commitInfoWatcher . Close ( ) for { var commitID string _commitInfo := new ( pfs . CommitInfo ) event := <- commitInfoWatcher . Watch ( ) switch event . Type { case watch . EventError : return event . Err case watch . EventPut : if err := event . Unmarshal ( & commitID , _commitInfo ) ; err != nil { return fmt . Errorf ( " " , err ) } case watch . EventDelete : return pfsserver . ErrCommitDeleted { commit } } if _commitInfo . Finished != nil { commitInfo = _commitInfo break } } return nil } ( ) ; err != nil { return nil , err } } return commitInfo , nil } 
func ( d * driver ) resolveCommit ( stm col . STM , userCommit * pfs . Commit ) ( * pfs . CommitInfo , error ) { if userCommit == nil { return nil , fmt . Errorf ( " " ) } if userCommit . ID == " " { return nil , fmt . Errorf ( " " ) } commit := proto . Clone ( userCommit ) . ( * pfs . Commit ) commit . ID , ancestryLength = ancestry . Parse ( commit . ID ) branchInfo := & pfs . BranchInfo { } } if branchInfo . Head == nil { return nil , pfsserver . ErrNoHead { branchInfo . Branch } } commitBranch = branchInfo . Branch commit . ID = branchInfo . Head . ID } commitInfo := & pfs . CommitInfo { } for i := 0 ; i <= ancestryLength ; i ++ { if commit == nil { return nil , pfsserver . ErrCommitNotFound { userCommit } } childCommit := commit if err := commits . Get ( commit . ID , commitInfo ) ; err != nil { if col . IsErrNotFound ( err ) { if i == 0 { return nil , pfsserver . ErrCommitNotFound { childCommit } } return nil , pfsserver . ErrParentCommitNotFound { childCommit } } return nil , err } commit = commitInfo . ParentCommit } if commitInfo . Branch == nil { commitInfo . Branch = commitBranch } userCommit . ID = commitInfo . Commit . ID return commitInfo , nil } 
func ( d * driver ) createBranch ( pachClient * client . APIClient , branch * pfs . Branch , commit * pfs . Commit , provenance [ ] * pfs . Branch ) error { ctx := pachClient . Ctx ( ) if err := d . checkIsAuthorized ( pachClient , branch . Repo , auth . Scope_WRITER ) ; err != nil { return err } if ! sameTarget && provenance != nil { return fmt . Errorf ( " \" \" \" \" " , branch . Name , commit . Repo . Name , commit . ID ) } } _ , err := col . NewSTM ( ctx , d . etcdClient , func ( stm col . STM ) error { if commit != nil { _ , err = d . resolveCommit ( stm , commit ) if err != nil { } commit = nil } } branchInfo := & pfs . BranchInfo { } if err := branches . Upsert ( branch . Name , branchInfo , func ( ) error { branchInfo . Name = branch . Name branchInfo . Branch = branch branchInfo . Head = commit branchInfo . DirectProvenance = nil for _ , provBranch := range provenance { add ( & branchInfo . DirectProvenance , provBranch ) } return nil } ) ; err != nil { return err } repos := d . repos . ReadWrite ( stm ) repoInfo := & pfs . RepoInfo { } if err := repos . Update ( branch . Repo . Name , repoInfo , func ( ) error { add ( & repoInfo . Branches , branch ) return nil } ) ; err != nil { return err } for _ , subvBranch := range branchInfo . Subvenance { subvBranchInfo := & pfs . BranchInfo { } if err := d . branches ( subvBranch . Repo . Name ) . ReadWrite ( stm ) . Get ( subvBranch . Name , subvBranchInfo ) ; err != nil { return err } toUpdate = append ( toUpdate , subvBranchInfo ) } for _ , branchInfo := range toUpdate { oldProvenance := branchInfo . Provenance branchInfo . Provenance = nil } provBranchInfo := & pfs . BranchInfo { } if err := d . branches ( provBranch . Repo . Name ) . ReadWrite ( stm ) . Get ( provBranch . Name , provBranchInfo ) ; err != nil { return err } for _ , provBranch := range provBranchInfo . Provenance { if err := d . addBranchProvenance ( branchInfo , provBranch , stm ) ; err != nil { return err } } } if err := d . branches ( branchInfo . Branch . Repo . Name ) . ReadWrite ( stm ) . Put ( branchInfo . Branch . Name , branchInfo ) ; err != nil { return err } if err := d . branches ( oldProvBranch . Repo . Name ) . ReadWrite ( stm ) . Update ( oldProvBranch . Name , oldProvBranchInfo , func ( ) error { del ( & oldProvBranchInfo . Subvenance , branchInfo . Branch ) return nil } ) ; err != nil { return err } } } } } ) return err } 
func ( d * driver ) scratchCommitPrefix ( commit * pfs . Commit ) string { } 
func ( d * driver ) scratchFilePrefix ( file * pfs . File ) ( string , error ) { return path . Join ( d . scratchCommitPrefix ( file . Commit ) , file . Path ) , nil } 
func headerDirToPutFileRecords ( tree hashtree . HashTree , path string , node * hashtree . NodeProto ) ( * pfs . PutFileRecords , error ) { if node . DirNode == nil || node . DirNode . Shared == nil { return nil , fmt . Errorf ( " " ) } s := node . DirNode . Shared pfr := & pfs . PutFileRecords { Split : true , } if s . Header != nil { pfr . Header = & pfs . PutFileRecord { SizeBytes : s . HeaderSize , ObjectHash : s . Header . Hash , } } if s . Footer != nil { pfr . Footer = & pfs . PutFileRecord { SizeBytes : s . FooterSize , ObjectHash : s . Footer . Hash , } } if err := tree . List ( path , func ( child * hashtree . NodeProto ) error { if child . FileNode == nil { return fmt . Errorf ( " " + " " ) } for i , o := range child . FileNode . Objects { if i == 0 { size = child . SubtreeSize } pfr . Records = append ( pfr . Records , & pfs . PutFileRecord { SizeBytes : size , ObjectHash : o . Hash , } ) } return nil } ) ; err != nil { return nil , err } return pfr , nil } 
func ( d * driver ) getTreeForFile ( pachClient * client . APIClient , file * pfs . File ) ( hashtree . HashTree , error ) { if file . Commit == nil { t , err := hashtree . NewDBHashTree ( d . storageRoot ) if err != nil { return nil , err } return t , nil } commitInfo , err := d . inspectCommit ( pachClient , file . Commit , pfs . CommitState_STARTED ) if err != nil { return nil , err } if commitInfo . Finished != nil { tree , err := d . getTreeForCommit ( pachClient , file . Commit ) if err != nil { return nil , err } return tree , nil } parentTree , err := d . getTreeForCommit ( pachClient , commitInfo . ParentCommit ) if err != nil { return nil , err } return d . getTreeForOpenCommit ( pachClient , file , parentTree ) } 
func provenantOnInput ( provenance [ ] * pfs . CommitProvenance ) bool { provenanceCount := len ( provenance ) for _ , p := range provenance { break } } return provenanceCount > 0 } 
func nodeToFileInfo ( ci * pfs . CommitInfo , path string , node * hashtree . NodeProto , full bool ) * pfs . FileInfo { fileInfo := & pfs . FileInfo { File : & pfs . File { Commit : ci . Commit , Path : path , } , SizeBytes : uint64 ( node . SubtreeSize ) , Hash : node . Hash , Committed : ci . Finished , } if node . FileNode != nil { fileInfo . FileType = pfs . FileType_FILE if full { fileInfo . Objects = node . FileNode . Objects fileInfo . BlockRefs = node . FileNode . BlockRefs } } else if node . DirNode != nil { fileInfo . FileType = pfs . FileType_DIR if full { fileInfo . Children = node . DirNode . Children } } return fileInfo } 
func nodeToFileInfoHeaderFooter ( ci * pfs . CommitInfo , filePath string , node * hashtree . NodeProto , tree hashtree . HashTree , full bool ) ( * pfs . FileInfo , error ) { if node . FileNode == nil || ! node . FileNode . HasHeaderFooter { return nodeToFileInfo ( ci , filePath , node , full ) , nil } node = proto . Clone ( node ) . ( * hashtree . NodeProto ) } parentNode , err := tree . Get ( parentPath ) if err != nil { return nil , fmt . Errorf ( " " + " " , filePath , parentPath , err ) } if parentNode . DirNode == nil { return nil , fmt . Errorf ( " " + " " , filePath ) } if parentNode . DirNode . Shared == nil { return nil , fmt . Errorf ( " " + " " , filePath ) } s := parentNode . DirNode . Shared var newObjects [ ] * pfs . Object if s . Header != nil { newObjects = make ( [ ] * pfs . Object , newL , newL + 1 ) newObjects [ 0 ] = s . Header copy ( newObjects [ 1 : ] , node . FileNode . Objects ) } else { newObjects = node . FileNode . Objects } if s . Footer != nil { newObjects = append ( newObjects , s . Footer ) } node . FileNode . Objects = newObjects node . SubtreeSize += s . HeaderSize + s . FooterSize node . Hash = hashtree . HashFileNode ( node . FileNode ) return nodeToFileInfo ( ci , filePath , node , full ) , nil } 
func ( d * driver ) fileHistory ( pachClient * client . APIClient , file * pfs . File , history int64 , f func ( * pfs . FileInfo ) error ) error { var fi * pfs . FileInfo for { _fi , err := d . inspectFile ( pachClient , file ) if err != nil { if _ , ok := err . ( pfsserver . ErrFileNotFound ) ; ok { return f ( fi ) } return err } if fi != nil && bytes . Compare ( fi . Hash , _fi . Hash ) != 0 { if err := f ( fi ) ; err != nil { return err } if history > 0 { history -- if history == 0 { return nil } } } fi = _fi ci , err := d . inspectCommit ( pachClient , file . Commit , pfs . CommitState_STARTED ) if err != nil { return err } if ci . ParentCommit == nil { return f ( fi ) } file . Commit = ci . ParentCommit } } 
func ( d * driver ) upsertPutFileRecords ( pachClient * client . APIClient , file * pfs . File , newRecords * pfs . PutFileRecords ) error { prefix , err := d . scratchFilePrefix ( file ) if err != nil { return err } ctx := pachClient . Ctx ( ) _ , err = col . NewSTM ( ctx , d . etcdClient , func ( stm col . STM ) error { commitsCol := d . openCommits . ReadOnly ( ctx ) var commit pfs . Commit err := commitsCol . Get ( file . Commit . ID , & commit ) if err != nil { return err } } recordsCol := d . putFileRecords . ReadWrite ( stm ) var existingRecords pfs . PutFileRecords return recordsCol . Upsert ( prefix , & existingRecords , func ( ) error { if newRecords . Tombstone { existingRecords . Tombstone = true existingRecords . Records = nil } existingRecords . Split = newRecords . Split existingRecords . Records = append ( existingRecords . Records , newRecords . Records ... ) existingRecords . Header = newRecords . Header existingRecords . Footer = newRecords . Footer return nil } ) } ) if err != nil { return err } return err } 
func ( r * PGDumpReader ) ReadRow ( ) ( [ ] byte , error ) { if len ( r . Header ) == 0 { err := r . readHeader ( ) if err != nil { return nil , err } } endLine := " \\ \n " row , err := r . rd . ReadBytes ( '\n' ) if err != nil && err != io . EOF { return nil , fmt . Errorf ( " " , err ) } row = row [ : len ( row ) - 1 ] } if string ( row ) == endLine { r . Footer = append ( r . Footer , row ... ) err = r . readFooter ( ) row = nil } if err == io . EOF && len ( r . Footer ) == 0 { return nil , fmt . Errorf ( " " ) } return row , err } 
func NewReporter ( clusterID string , kubeClient * kube . Clientset ) * Reporter { reporter := & Reporter { segmentClient : newPersistentClient ( ) , clusterID : clusterID , kubeClient : kubeClient , } go reporter . reportClusterMetrics ( ) return reporter } 
func ReportUserAction ( ctx context . Context , r * Reporter , action string ) func ( time . Time , error ) { if r == nil { } return func ( start time . Time , err error ) { if err == nil { r . reportUserAction ( ctx , fmt . Sprintf ( " " , action ) , time . Since ( start ) . Seconds ( ) ) } else { r . reportUserAction ( ctx , fmt . Sprintf ( " " , action ) , err . Error ( ) ) } } } 
func reportAndFlushUserAction ( action string , value interface { } ) func ( ) { metricsDone := make ( chan struct { } ) go func ( ) { client := newSegmentClient ( ) defer client . Close ( ) cfg , err := config . Read ( ) if err != nil || cfg == nil || cfg . UserID == " " { log . Errorf ( " " , err ) } reportUserMetricsToSegment ( client , cfg . UserID , " " , action , value , " " ) close ( metricsDone ) } ( ) return func ( ) { select { case <- metricsDone : return case <- time . After ( time . Second * 5 ) : return } } } 
func FinishReportAndFlushUserAction ( action string , err error , start time . Time ) func ( ) { var wait func ( ) if err != nil { wait = reportAndFlushUserAction ( fmt . Sprintf ( " " , action ) , err ) } else { wait = reportAndFlushUserAction ( fmt . Sprintf ( " " , action ) , time . Since ( start ) . Seconds ( ) ) } return wait } 
func ( r * Reader ) Read ( data [ ] byte ) ( int , error ) { var totalRead int for len ( data ) > 0 { n , err := r . r . Read ( data ) data = data [ n : ] totalRead += n if err != nil { } } } r . curr = r . dataRefs [ 0 ] r . dataRefs = r . dataRefs [ 1 : ] r . r = bytes . NewReader ( r . buf . Bytes ( ) [ r . curr . OffsetBytes : r . curr . OffsetBytes + r . curr . SizeBytes ] ) } } return totalRead , nil } 
func parseISO8601 ( s string ) ( time . Time , error ) { t , err := time . Parse ( time . RFC3339 , s ) if err == nil { return t , nil } t , err = time . Parse ( " " , s ) if err == nil { return t , nil } return time . Time { } , fmt . Errorf ( " \" \" " , s , [ ] string { time . RFC3339 , " " } ) } 
func ActivateCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { var expires string activate := & cobra . Command { Use : " " , Short : " " + " " , Long : " " + " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err . Error ( ) ) } defer c . Close ( ) req := & enterprise . ActivateRequest { } req . ActivationCode = args [ 0 ] if expires != " " { t , err := parseISO8601 ( expires ) if err != nil { return fmt . Errorf ( " \" \" " , expires , err . Error ( ) ) } req . Expires , err = types . TimestampProto ( t ) if err != nil { return fmt . Errorf ( " \" \" " , t . String ( ) , err . Error ( ) ) } } resp , err := c . Enterprise . Activate ( c . Ctx ( ) , req ) if err != nil { return err } ts , err := types . TimestampFromProto ( resp . Info . Expires ) if err != nil { return fmt . Errorf ( " " + " " , err . Error ( ) ) } fmt . Printf ( " " + " \n " , ts . String ( ) ) return nil } ) , } activate . PersistentFlags ( ) . StringVar ( & expires , " " , " " , " " + " " + " " + " " + " " ) return cmdutil . CreateAlias ( activate , " " ) } 
func GetStateCmd ( noMetrics , noPortForwarding * bool ) * cobra . Command { getState := & cobra . Command { Short : " " + " " , Long : " " + " " , Run : cmdutil . Run ( func ( args [ ] string ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err . Error ( ) ) } defer c . Close ( ) resp , err := c . Enterprise . GetState ( c . Ctx ( ) , & enterprise . GetStateRequest { } ) if err != nil { return err } if resp . State == enterprise . State_NONE { fmt . Println ( " " ) return nil } ts , err := types . TimestampFromProto ( resp . Info . Expires ) if err != nil { return fmt . Errorf ( " " + " " , err . Error ( ) ) } fmt . Printf ( " \n \n " , resp . State . String ( ) , ts . String ( ) ) return nil } ) , } return cmdutil . CreateAlias ( getState , " " ) } 
func Cmds ( noMetrics , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command enterprise := & cobra . Command { Short : " " , Long : " " , } commands = append ( commands , cmdutil . CreateAlias ( enterprise , " " ) ) commands = append ( commands , ActivateCmd ( noMetrics , noPortForwarding ) ) commands = append ( commands , GetStateCmd ( noMetrics , noPortForwarding ) ) return commands } 
func NewConfiguration ( config interface { } ) * Configuration { configuration := & Configuration { } switch config . ( type ) { case * GlobalConfiguration : configuration . GlobalConfiguration = config . ( * GlobalConfiguration ) return configuration case * PachdFullConfiguration : configuration . GlobalConfiguration = & config . ( * PachdFullConfiguration ) . GlobalConfiguration configuration . PachdSpecificConfiguration = & config . ( * PachdFullConfiguration ) . PachdSpecificConfiguration return configuration case * WorkerFullConfiguration : configuration . GlobalConfiguration = & config . ( * WorkerFullConfiguration ) . GlobalConfiguration configuration . WorkerSpecificConfiguration = & config . ( * WorkerFullConfiguration ) . WorkerSpecificConfiguration return configuration default : return nil } } 
func Repos ( etcdClient * etcd . Client , etcdPrefix string ) col . Collection { return col . NewCollection ( etcdClient , path . Join ( etcdPrefix , reposPrefix ) , nil , & pfs . RepoInfo { } , nil , nil , ) } 
func PutFileRecords ( etcdClient * etcd . Client , etcdPrefix string ) col . Collection { return col . NewCollection ( etcdClient , path . Join ( etcdPrefix , putFileRecordsPrefix ) , nil , & pfs . PutFileRecords { } , nil , nil , ) } 
func Commits ( etcdClient * etcd . Client , etcdPrefix string , repo string ) col . Collection { return col . NewCollection ( etcdClient , path . Join ( etcdPrefix , commitsPrefix , repo ) , [ ] * col . Index { ProvenanceIndex } , & pfs . CommitInfo { } , nil , nil , ) } 
func Branches ( etcdClient * etcd . Client , etcdPrefix string , repo string ) col . Collection { return col . NewCollection ( etcdClient , path . Join ( etcdPrefix , branchesPrefix , repo ) , nil , & pfs . BranchInfo { } , func ( key string ) error { if uuid . IsUUIDWithoutDashes ( key ) { return fmt . Errorf ( " " ) } return nil } , nil , ) } 
func OpenCommits ( etcdClient * etcd . Client , etcdPrefix string ) col . Collection { return col . NewCollection ( etcdClient , path . Join ( etcdPrefix , openCommitsPrefix ) , nil , & pfs . Commit { } , nil , nil , ) } 
func NewDAG ( nodes map [ string ] [ ] string ) * DAG { result := & DAG { parents : make ( map [ string ] [ ] string ) , children : make ( map [ string ] [ ] string ) , leaves : make ( map [ string ] bool ) , } for id , parents := range nodes { result . NewNode ( id , parents ) } return result } 
func ( d * DAG ) NewNode ( id string , parents [ ] string ) { d . parents [ id ] = parents for _ , parentID := range parents { d . children [ parentID ] = append ( d . children [ parentID ] , id ) d . leaves [ parentID ] = false } if _ , ok := d . leaves [ id ] ; ! ok { d . leaves [ id ] = true } } 
func ( d * DAG ) Sorted ( ) [ ] string { seen := make ( map [ string ] bool ) var result [ ] string for id := range d . parents { result = append ( result , dfs ( id , d . parents , seen ) ... ) } return result } 
func ( d * DAG ) Leaves ( ) [ ] string { var result [ ] string for id , isLeaf := range d . leaves { } } return result } 
func ( d * DAG ) Ancestors ( id string , from [ ] string ) [ ] string { seen := make ( map [ string ] bool ) for _ , fromID := range from { seen [ fromID ] = true } return dfs ( id , d . parents , seen ) } 
func ( d * DAG ) Descendants ( id string , to [ ] string ) [ ] string { seen := make ( map [ string ] bool ) for _ , toID := range to { seen [ toID ] = true } return bfs ( id , d . children , seen ) } 
func ( d * DAG ) Ghosts ( ) [ ] string { var result [ ] string for id := range d . children { if _ , ok := d . parents [ id ] ; ! ok { result = append ( result , id ) } } return result } 
func NewPortForwarder ( namespace string ) ( * PortForwarder , error ) { if namespace == " " { namespace = " " } rules := clientcmd . NewDefaultClientConfigLoadingRules ( ) overrides := & clientcmd . ConfigOverrides { } kubeConfig := clientcmd . NewNonInteractiveDeferredLoadingClientConfig ( rules , overrides ) config , err := kubeConfig . ClientConfig ( ) if err != nil { return nil , err } client , err := kubernetes . NewForConfig ( config ) if err != nil { return nil , err } core := client . CoreV1 ( ) return & PortForwarder { core : core , client : core . RESTClient ( ) , config : config , namespace : namespace , logger : log . StandardLogger ( ) . Writer ( ) , stopChansLock : & sync . Mutex { } , stopChans : [ ] chan struct { } { } , shutdown : false , } , nil } 
func ( f * PortForwarder ) Run ( appName string , localPort , remotePort uint16 ) error { podNameSelector := map [ string ] string { " " : " " , " " : appName , } podList , err := f . core . Pods ( f . namespace ) . List ( metav1 . ListOptions { LabelSelector : metav1 . FormatLabelSelector ( metav1 . SetAsLabelSelector ( podNameSelector ) ) , TypeMeta : metav1 . TypeMeta { Kind : " " , APIVersion : " " , } , } ) if err != nil { return err } if len ( podList . Items ) == 0 { return fmt . Errorf ( " " , appName ) } url := f . client . Post ( ) . Resource ( " " ) . Namespace ( f . namespace ) . Name ( podName ) . SubResource ( " " ) . URL ( ) transport , upgrader , err := spdy . RoundTripperFor ( f . config ) if err != nil { return err } dialer := spdy . NewDialer ( upgrader , & http . Client { Transport : transport } , " " , url ) ports := [ ] string { fmt . Sprintf ( " " , localPort , remotePort ) } readyChan := make ( chan struct { } , 1 ) stopChan := make ( chan struct { } , 1 ) if f . shutdown { f . stopChansLock . Unlock ( ) return fmt . Errorf ( " " ) } f . stopChans = append ( f . stopChans , stopChan ) f . stopChansLock . Unlock ( ) fw , err := portforward . New ( dialer , ports , stopChan , readyChan , ioutil . Discard , f . logger ) if err != nil { return err } errChan := make ( chan error , 1 ) go func ( ) { errChan <- fw . ForwardPorts ( ) } ( ) select { case err = <- errChan : return fmt . Errorf ( " " , err ) case <- fw . Ready : return nil } } 
func ( f * PortForwarder ) RunForDaemon ( localPort , remotePort uint16 ) error { if localPort == 0 { localPort = pachdLocalPort } if remotePort == 0 { remotePort = pachdRemotePort } return f . Run ( " " , localPort , remotePort ) } 
func ( f * PortForwarder ) RunForSAMLACS ( localPort uint16 ) error { if localPort == 0 { localPort = samlAcsLocalPort } return f . Run ( " " , localPort , 654 ) } 
func ( f * PortForwarder ) RunForDashUI ( localPort uint16 ) error { if localPort == 0 { localPort = dashUILocalPort } return f . Run ( " " , localPort , 8080 ) } 
func ( f * PortForwarder ) RunForDashWebSocket ( localPort uint16 ) error { if localPort == 0 { localPort = dashWebSocketLocalPort } return f . Run ( " " , localPort , 8081 ) } 
func ( f * PortForwarder ) RunForPFS ( localPort uint16 ) error { if localPort == 0 { localPort = pfsLocalPort } return f . Run ( " " , localPort , 30652 ) } 
func ( f * PortForwarder ) RunForS3Gateway ( localPort uint16 ) error { if localPort == 0 { localPort = s3gatewayLocalPort } return f . Run ( " " , localPort , 600 ) } 
func ( f * PortForwarder ) Lock ( ) error { pidfile . SetPidfilePath ( path . Join ( os . Getenv ( " " ) , " " ) ) return pidfile . Write ( ) } 
func ( f * PortForwarder ) Close ( ) { defer f . logger . Close ( ) f . stopChansLock . Lock ( ) defer f . stopChansLock . Unlock ( ) if f . shutdown { panic ( " " ) } f . shutdown = true for _ , stopChan := range f . stopChans { close ( stopChan ) } } 
func ( e * Event ) Unmarshal ( key * string , val proto . Message ) error { if err := CheckType ( e . Template , val ) ; err != nil { return err } * key = string ( e . Key ) return proto . Unmarshal ( e . Value , val ) } 
func ( e * Event ) UnmarshalPrev ( key * string , val proto . Message ) error { if err := CheckType ( e . Template , val ) ; err != nil { return err } * key = string ( e . PrevKey ) return proto . Unmarshal ( e . PrevValue , val ) } 
func NewWatcher ( ctx context . Context , client * etcd . Client , trimPrefix , prefix string , template proto . Message , opts ... OpOption ) ( Watcher , error ) { eventCh := make ( chan * Event ) done := make ( chan struct { } ) if err != nil { return nil , err } nextRevision := resp . Header . Revision + 1 etcdWatcher := etcd . NewWatcher ( client ) for _ , opt := range opts { options = append ( options , etcd . OpOption ( opt ) ) } rch := etcdWatcher . Watch ( ctx , prefix , options ... ) go func ( ) ( retErr error ) { defer func ( ) { if retErr != nil { select { case eventCh <- & Event { Err : retErr , Type : EventError , } : case <- done : } } close ( eventCh ) etcdWatcher . Close ( ) } ( ) for _ , etcdKv := range resp . Kvs { eventCh <- & Event { Key : bytes . TrimPrefix ( etcdKv . Key , [ ] byte ( trimPrefix ) ) , Value : etcdKv . Value , Type : EventPut , Rev : etcdKv . ModRevision , Template : template , } } for { var resp etcd . WatchResponse var ok bool select { case resp , ok = <- rch : case <- done : return nil } if ! ok { if err := etcdWatcher . Close ( ) ; err != nil { return err } etcdWatcher = etcd . NewWatcher ( client ) rch = etcdWatcher . Watch ( ctx , prefix , etcd . WithPrefix ( ) , etcd . WithRev ( nextRevision ) ) continue } if err := resp . Err ( ) ; err != nil { return err } for _ , etcdEv := range resp . Events { ev := & Event { Key : bytes . TrimPrefix ( etcdEv . Kv . Key , [ ] byte ( trimPrefix ) ) , Value : etcdEv . Kv . Value , Rev : etcdEv . Kv . ModRevision , Template : template , } if etcdEv . PrevKv != nil { ev . PrevKey = bytes . TrimPrefix ( etcdEv . PrevKv . Key , [ ] byte ( trimPrefix ) ) ev . PrevValue = etcdEv . PrevKv . Value } if etcdEv . Type == etcd . EventTypePut { ev . Type = EventPut } else { ev . Type = EventDelete } select { case eventCh <- ev : case <- done : return nil } } nextRevision = resp . Header . Revision + 1 } } ( ) return & watcher { eventCh : eventCh , done : done , } , nil } 
func MakeWatcher ( eventCh chan * Event , done chan struct { } ) Watcher { return & watcher { eventCh : eventCh , done : done , } } 
func CheckType ( template proto . Message , val interface { } ) error { if template != nil { valType , templateType := reflect . TypeOf ( val ) , reflect . TypeOf ( template ) if valType != templateType { return fmt . Errorf ( " " , valType , templateType ) } } return nil } 
func NewPool ( kubeClient * kube . Clientset , namespace string , serviceName string , port int , queueSize int64 , opts ... grpc . DialOption ) ( * Pool , error ) { endpointsInterface := kubeClient . CoreV1 ( ) . Endpoints ( namespace ) watch , err := endpointsInterface . Watch ( metav1 . ListOptions { LabelSelector : metav1 . FormatLabelSelector ( metav1 . SetAsLabelSelector ( map [ string ] string { " " : serviceName } , ) ) , Watch : true , } ) if err != nil { return nil , err } pool := & Pool { port : port , endpointsWatch : watch , opts : opts , done : make ( chan struct { } ) , queueSize : queueSize , } pool . connsCond = sync . NewCond ( & pool . connsLock ) go pool . watchEndpoints ( ) return pool , nil } 
func ( p * Pool ) Do ( ctx context . Context , f func ( cc * grpc . ClientConn ) error ) error { var conn * connCount if err := func ( ) error { p . connsLock . Lock ( ) defer p . connsLock . Unlock ( ) for { for addr , mapConn := range p . conns { if mapConn . cc == nil { cc , err := grpc . DialContext ( ctx , addr , p . opts ... ) if err != nil { return fmt . Errorf ( " " , addr , err ) } mapConn . cc = cc conn = mapConn } else { mapConnCount := atomic . LoadInt64 ( & mapConn . count ) if mapConnCount < p . queueSize && ( conn == nil || mapConnCount < atomic . LoadInt64 ( & conn . count ) ) { conn = mapConn } } } if conn == nil { p . connsCond . Wait ( ) } else { atomic . AddInt64 ( & conn . count , 1 ) break } } return nil } ( ) ; err != nil { return err } defer p . connsCond . Broadcast ( ) defer atomic . AddInt64 ( & conn . count , - 1 ) return f ( conn . cc ) } 
func ( p * Pool ) Close ( ) error { close ( p . done ) var retErr error for _ , conn := range p . conns { if conn . cc != nil { if err := conn . cc . Close ( ) ; err != nil { retErr = err } } } return retErr } 
func Cmds ( noMetrics * bool , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command raw := false rawFlags := pflag . NewFlagSet ( " " , pflag . ContinueOnError ) rawFlags . BoolVar ( & raw , " " , false , " " ) fullTimestamps := false fullTimestampsFlags := pflag . NewFlagSet ( " " , pflag . ContinueOnError ) fullTimestampsFlags . BoolVar ( & fullTimestamps , " " , false , " " ) marshaller := & jsonpb . Marshaler { Indent : " " , OrigName : true , } jobDocs := & cobra . Command { Short : " " , Long : `Jobs are the basic units of computation in Pachyderm. Jobs run a containerized workload over a set of finished input commits. Jobs are created by pipelines and will write output to a commit in the pipeline's output repo. A job can have multiple datums, each processed independently and the results will be merged together at the end. If the job fails, the output commit will not be populated with data.` , } cmdutil . SetDocsUsage ( jobDocs ) commands = append ( commands , cmdutil . CreateAlias ( jobDocs , " " ) ) var block bool inspectJob := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) jobInfo , err := client . InspectJob ( args [ 0 ] , block ) if err != nil { cmdutil . ErrorAndExit ( " " , err . Error ( ) ) } if jobInfo == nil { cmdutil . ErrorAndExit ( " " , args [ 0 ] ) } if raw { return marshaller . Marshal ( os . Stdout , jobInfo ) } ji := & pretty . PrintableJobInfo { JobInfo : jobInfo , FullTimestamps : fullTimestamps , } return pretty . PrintDetailedJobInfo ( ji ) } ) , } inspectJob . Flags ( ) . BoolVarP ( & block , " " , " " , false , " " ) inspectJob . Flags ( ) . AddFlagSet ( rawFlags ) inspectJob . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( inspectJob , " " ) ) var pipelineName string var outputCommitStr string var inputCommitStrs [ ] string listJob := & cobra . Command { Short : " " , Long : " " , Example : ` # Return all jobs $ {{alias}} # Return all jobs in pipeline foo $ {{alias}} -p foo # Return all jobs whose input commits include foo@XXX and bar@YYY $ {{alias}} -i foo@XXX -i bar@YYY # Return all jobs in pipeline foo and whose input commits include bar@YYY $ {{alias}} -p foo -i bar@YYY` , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { commits , err := cmdutil . ParseCommits ( inputCommitStrs ) if err != nil { return err } var outputCommit * pfs . Commit if outputCommitStr != " " { outputCommit , err = cmdutil . ParseCommit ( outputCommitStr ) if err != nil { return err } } client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if raw { return client . ListJobF ( pipelineName , commits , outputCommit , func ( ji * ppsclient . JobInfo ) error { if err := marshaller . Marshal ( os . Stdout , ji ) ; err != nil { return err } return nil } ) } writer := tabwriter . NewWriter ( os . Stdout , pretty . JobHeader ) if err := client . ListJobF ( pipelineName , commits , outputCommit , func ( ji * ppsclient . JobInfo ) error { pretty . PrintJobInfo ( writer , ji , fullTimestamps ) return nil } ) ; err != nil { return err } return writer . Flush ( ) } ) , } listJob . Flags ( ) . StringVarP ( & pipelineName , " " , " " , " " , " " ) listJob . MarkFlagCustom ( " " , " " ) listJob . Flags ( ) . StringVarP ( & outputCommitStr , " " , " " , " " , " " ) listJob . MarkFlagCustom ( " " , " " ) listJob . Flags ( ) . StringSliceVarP ( & inputCommitStrs , " " , " " , [ ] string { } , " " ) listJob . MarkFlagCustom ( " " , " " ) listJob . Flags ( ) . AddFlagSet ( rawFlags ) listJob . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( listJob , " " ) ) var pipelines cmdutil . RepeatedStringArg flushJob := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # Return jobs caused by foo@XXX and bar@YYY. $ {{alias}} foo@XXX bar@YYY # Return jobs caused by foo@XXX leading to pipelines bar and baz. $ {{alias}} foo@XXX -p bar -p baz` , Run : cmdutil . Run ( func ( args [ ] string ) error { commits , err := cmdutil . ParseCommits ( args ) if err != nil { return err } c , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer c . Close ( ) jobInfos , err := c . FlushJobAll ( commits , pipelines ) if err != nil { return err } if raw { for _ , jobInfo := range jobInfos { if err := marshaller . Marshal ( os . Stdout , jobInfo ) ; err != nil { return err } } return nil } writer := tabwriter . NewWriter ( os . Stdout , pretty . JobHeader ) for _ , jobInfo := range jobInfos { pretty . PrintJobInfo ( writer , jobInfo , fullTimestamps ) } return writer . Flush ( ) } ) , } flushJob . Flags ( ) . VarP ( & pipelines , " " , " " , " " ) flushJob . MarkFlagCustom ( " " , " " ) flushJob . Flags ( ) . AddFlagSet ( rawFlags ) flushJob . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( flushJob , " " ) ) deleteJob := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if err := client . DeleteJob ( args [ 0 ] ) ; err != nil { cmdutil . ErrorAndExit ( " " , err . Error ( ) ) } return nil } ) , } commands = append ( commands , cmdutil . CreateAlias ( deleteJob , " " ) ) stopJob := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if err := client . StopJob ( args [ 0 ] ) ; err != nil { cmdutil . ErrorAndExit ( " " , err . Error ( ) ) } return nil } ) , } commands = append ( commands , cmdutil . CreateAlias ( stopJob , " " ) ) datumDocs := & cobra . Command { Short : " " , Long : `Datums are the small independent units of processing for Pachyderm jobs. A datum is defined by applying a glob pattern (in the pipeline spec) to the file paths in the input repo. A datum can include one or more files or directories. Datums within a job will be processed independently, sometimes distributed across separate workers. A separate execution of user code will be run for each datum.` , } cmdutil . SetDocsUsage ( datumDocs ) commands = append ( commands , cmdutil . CreateAlias ( datumDocs , " " ) ) restartDatum := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 2 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) datumFilter := strings . Split ( args [ 1 ] , " " ) for i := 0 ; i < len ( datumFilter ) ; { if len ( datumFilter [ i ] ) == 0 { if i + 1 < len ( datumFilter ) { copy ( datumFilter [ i : ] , datumFilter [ i + 1 : ] ) } datumFilter = datumFilter [ : len ( datumFilter ) - 1 ] } else { i ++ } } return client . RestartDatum ( args [ 0 ] , datumFilter ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( restartDatum , " " ) ) var pageSize int64 var page int64 listDatum := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if pageSize < 0 { return fmt . Errorf ( " " ) } if page < 0 { return fmt . Errorf ( " " ) } if raw { return client . ListDatumF ( args [ 0 ] , pageSize , page , func ( di * ppsclient . DatumInfo ) error { return marshaller . Marshal ( os . Stdout , di ) } ) } writer := tabwriter . NewWriter ( os . Stdout , pretty . DatumHeader ) if err := client . ListDatumF ( args [ 0 ] , pageSize , page , func ( di * ppsclient . DatumInfo ) error { pretty . PrintDatumInfo ( writer , di ) return nil } ) ; err != nil { return err } return writer . Flush ( ) } ) , } listDatum . Flags ( ) . Int64Var ( & pageSize , " " , 0 , " " ) listDatum . Flags ( ) . Int64Var ( & page , " " , 0 , " " ) listDatum . Flags ( ) . AddFlagSet ( rawFlags ) commands = append ( commands , cmdutil . CreateAlias ( listDatum , " " ) ) inspectDatum := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 2 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) datumInfo , err := client . InspectDatum ( args [ 0 ] , args [ 1 ] ) if err != nil { return err } if raw { return marshaller . Marshal ( os . Stdout , datumInfo ) } pretty . PrintDetailedDatumInfo ( os . Stdout , datumInfo ) return nil } ) , } inspectDatum . Flags ( ) . AddFlagSet ( rawFlags ) commands = append ( commands , cmdutil . CreateAlias ( inspectDatum , " " ) ) var ( jobID string datumID string commaInputs string // comma-separated list of input files of interest master bool follow bool tail int64 ) getLogs := & cobra . Command { Use : " " , Short : " " , Long : " " , Example : ` # Return logs emitted by recent jobs in the "filter" pipeline $ {{alias}} --pipeline=filter # Return logs emitted by the job aedfa12aedf $ {{alias}} --job=aedfa12aedf # Return logs emitted by the pipeline \"filter\" while processing /apple.txt and a file with the hash 123aef $ {{alias}} --pipeline=filter --inputs=/apple.txt,123aef` , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer client . Close ( ) // Break up comma-separated input paths, and filter out empty entries data := strings . Split ( commaInputs , " " ) for i := 0 ; i < len ( data ) ; { if len ( data [ i ] ) == 0 { if i + 1 < len ( data ) { copy ( data [ i : ] , data [ i + 1 : ] ) } data = data [ : len ( data ) - 1 ] } else { i ++ } } // Issue RPC marshaler := & jsonpb . Marshaler { } iter := client . GetLogs ( pipelineName , jobID , data , datumID , master , follow , tail ) for iter . Next ( ) { var messageStr string if raw { var err error messageStr , err = marshaler . MarshalToString ( iter . Message ( ) ) if err != nil { fmt . Fprintf ( os . Stderr , " \" \" \n " , iter . Message ( ) , err ) } fmt . Println ( messageStr ) } else if iter . Message ( ) . User { fmt . Println ( iter . Message ( ) . Message ) } else if iter . Message ( ) . Master && master { fmt . Println ( iter . Message ( ) . Message ) } else if pipelineName == " " && jobID == " " { fmt . Println ( iter . Message ( ) . Message ) } } return iter . Err ( ) } ) , } getLogs . Flags ( ) . StringVarP ( & pipelineName , " " , " " , " " , " " + " " ) getLogs . MarkFlagCustom ( " " , " " ) getLogs . Flags ( ) . StringVar ( & jobID , " " , " " , " " + " " ) getLogs . MarkFlagCustom ( " " , " " ) getLogs . Flags ( ) . StringVar ( & datumID , " " , " " , " " ) getLogs . Flags ( ) . StringVar ( & commaInputs , " " , " " , " " + " " ) getLogs . Flags ( ) . BoolVar ( & master , " " , false , " " ) getLogs . Flags ( ) . BoolVar ( & raw , " " , false , " " ) getLogs . Flags ( ) . BoolVarP ( & follow , " " , " " , false , " " ) getLogs . Flags ( ) . Int64VarP ( & tail , " " , " " , 0 , " " ) commands = append ( commands , cmdutil . CreateAlias ( getLogs , " " ) ) pipelineDocs := & cobra . Command { Short : " " , Long : `Pipelines are a powerful abstraction for automating jobs. Pipelines take a set of repos and branches as inputs and will write to a single output repo of the same name. Pipelines then subscribe to commits on those repos and launch a job to process each incoming commit. All jobs created by a pipeline will create commits in the pipeline's output repo.` , } cmdutil . SetDocsUsage ( pipelineDocs ) commands = append ( commands , cmdutil . CreateAlias ( pipelineDocs , " " ) ) var build bool var pushImages bool var registry string var username string var pipelinePath string createPipeline := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) ( retErr error ) { return pipelineHelper ( ! * noMetrics , ! * noPortForwarding , false , build , pushImages , registry , username , pipelinePath , false ) } ) , } createPipeline . Flags ( ) . StringVarP ( & pipelinePath , " " , " " , " " , " " ) createPipeline . Flags ( ) . BoolVarP ( & build , " " , " " , false , " " ) createPipeline . Flags ( ) . BoolVarP ( & pushImages , " " , " " , false , " " ) createPipeline . Flags ( ) . StringVarP ( & registry , " " , " " , " " , " " ) createPipeline . Flags ( ) . StringVarP ( & username , " " , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( createPipeline , " " ) ) var reprocess bool updatePipeline := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) ( retErr error ) { return pipelineHelper ( ! * noMetrics , ! * noPortForwarding , reprocess , build , pushImages , registry , username , pipelinePath , true ) } ) , } updatePipeline . Flags ( ) . StringVarP ( & pipelinePath , " " , " " , " " , " " ) updatePipeline . Flags ( ) . BoolVarP ( & build , " " , " " , false , " " ) updatePipeline . Flags ( ) . BoolVarP ( & pushImages , " " , " " , false , " " ) updatePipeline . Flags ( ) . StringVarP ( & registry , " " , " " , " " , " " ) updatePipeline . Flags ( ) . StringVarP ( & username , " " , " " , " " , " " ) updatePipeline . Flags ( ) . BoolVar ( & reprocess , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( updatePipeline , " " ) ) inspectPipeline := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) pipelineInfo , err := client . InspectPipeline ( args [ 0 ] ) if err != nil { return err } if pipelineInfo == nil { return fmt . Errorf ( " " , args [ 0 ] ) } if raw { return marshaller . Marshal ( os . Stdout , pipelineInfo ) } pi := & pretty . PrintablePipelineInfo { PipelineInfo : pipelineInfo , FullTimestamps : fullTimestamps , } return pretty . PrintDetailedPipelineInfo ( pi ) } ) , } inspectPipeline . Flags ( ) . AddFlagSet ( rawFlags ) inspectPipeline . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( inspectPipeline , " " ) ) extractPipeline := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) createPipelineRequest , err := client . ExtractPipeline ( args [ 0 ] ) if err != nil { return err } return marshaller . Marshal ( os . Stdout , createPipelineRequest ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( extractPipeline , " " ) ) var editor string editPipeline := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) ( retErr error ) { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) createPipelineRequest , err := client . ExtractPipeline ( args [ 0 ] ) if err != nil { return err } f , err := ioutil . TempFile ( " " , args [ 0 ] ) if err != nil { return err } if err := marshaller . Marshal ( f , createPipelineRequest ) ; err != nil { return err } defer func ( ) { if err := f . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) if editor == " " { editor = os . Getenv ( " " ) } if editor == " " { editor = " " } if err := cmdutil . RunIO ( cmdutil . IO { Stdin : os . Stdin , Stdout : os . Stdout , Stderr : os . Stderr , } , editor , f . Name ( ) ) ; err != nil { return err } cfgReader , err := ppsutil . NewPipelineManifestReader ( f . Name ( ) ) if err != nil { return err } request , err := cfgReader . NextCreatePipelineRequest ( ) if err != nil { return err } if proto . Equal ( createPipelineRequest , request ) { fmt . Println ( " " ) return nil } request . Update = true request . Reprocess = reprocess if _ , err := client . PpsAPIClient . CreatePipeline ( client . Ctx ( ) , request , ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } ) , } editPipeline . Flags ( ) . BoolVar ( & reprocess , " " , false , " " ) editPipeline . Flags ( ) . StringVar ( & editor , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( editPipeline , " " ) ) var spec bool listPipeline := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer client . Close ( ) pipelineInfos , err := client . ListPipeline ( ) if err != nil { return err } if raw { for _ , pipelineInfo := range pipelineInfos { if err := marshaller . Marshal ( os . Stdout , pipelineInfo ) ; err != nil { return err } } return nil } if spec { for _ , pipelineInfo := range pipelineInfos { if err := marshaller . Marshal ( os . Stdout , ppsutil . PipelineReqFromInfo ( pipelineInfo ) ) ; err != nil { return err } } return nil } writer := tabwriter . NewWriter ( os . Stdout , pretty . PipelineHeader ) for _ , pipelineInfo := range pipelineInfos { pretty . PrintPipelineInfo ( writer , pipelineInfo , fullTimestamps ) } return writer . Flush ( ) } ) , } listPipeline . Flags ( ) . BoolVarP ( & spec , " " , " " , false , " " ) listPipeline . Flags ( ) . AddFlagSet ( rawFlags ) listPipeline . Flags ( ) . AddFlagSet ( fullTimestampsFlags ) commands = append ( commands , cmdutil . CreateAlias ( listPipeline , " " ) ) var all bool var force bool deletePipeline := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunBoundedArgs ( 0 , 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if len ( args ) > 0 && all { return fmt . Errorf ( " " ) } if len ( args ) == 0 && ! all { return fmt . Errorf ( " " ) } if all { _ , err = client . PpsAPIClient . DeletePipeline ( client . Ctx ( ) , & ppsclient . DeletePipelineRequest { All : all , Force : force , } ) } else { err = client . DeletePipeline ( args [ 0 ] , force ) } if err != nil { return grpcutil . ScrubGRPC ( err ) } return nil } ) , } deletePipeline . Flags ( ) . BoolVar ( & all , " " , false , " " ) deletePipeline . Flags ( ) . BoolVarP ( & force , " " , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( deletePipeline , " " ) ) startPipeline := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if err := client . StartPipeline ( args [ 0 ] ) ; err != nil { cmdutil . ErrorAndExit ( " " , err . Error ( ) ) } return nil } ) , } commands = append ( commands , cmdutil . CreateAlias ( startPipeline , " " ) ) stopPipeline := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) if err := client . StopPipeline ( args [ 0 ] ) ; err != nil { cmdutil . ErrorAndExit ( " " , err . Error ( ) ) } return nil } ) , } commands = append ( commands , cmdutil . CreateAlias ( stopPipeline , " " ) ) var memory string garbageCollect := & cobra . Command { Short : " " , Long : `Garbage collect unused data. When a file/commit/repo is deleted, the data is not immediately removed from the underlying storage system (e.g. S3) for performance and architectural reasons. This is similar to how when you delete a file on your computer, the file is not necessarily wiped from disk immediately. To actually remove the data, you will need to manually invoke garbage collection with "pachctl garbage-collect". Currently "pachctl garbage-collect" can only be started when there are no pipelines running. You also need to ensure that there's no ongoing "put file". Garbage collection puts the cluster into a readonly mode where no new jobs can be created and no data can be added. Pachyderm's garbage collection uses bloom filters to index live objects. This means that some dead objects may erronously not be deleted during garbage collection. The probability of this happening depends on how many objects you have; at around 10M objects it starts to become likely with the default values. To lower Pachyderm's error rate and make garbage-collection more comprehensive, you can increase the amount of memory used for the bloom filters with the --memory flag. The default value is 10MB. ` , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) ( retErr error ) { client , err := pachdclient . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return err } defer client . Close ( ) memoryBytes , err := units . RAMInBytes ( memory ) if err != nil { return err } return client . GarbageCollect ( memoryBytes ) } ) , } garbageCollect . Flags ( ) . StringVarP ( & memory , " " , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( garbageCollect , " " ) ) return commands } 
func buildImage ( client * docker . Client , repo string , contextDir string , dockerfile string , destTag string ) error { destImage := fmt . Sprintf ( " " , repo , destTag ) fmt . Printf ( " \n " , destImage ) err := client . BuildImage ( docker . BuildImageOptions { Name : destImage , ContextDir : contextDir , Dockerfile : dockerfile , OutputStream : os . Stdout , } ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func pushImage ( client * docker . Client , authConfig docker . AuthConfiguration , repo string , sourceTag string , destTag string ) ( string , error ) { sourceImage := fmt . Sprintf ( " " , repo , sourceTag ) destImage := fmt . Sprintf ( " " , repo , destTag ) fmt . Printf ( " \n " , destImage ) if err := client . TagImage ( sourceImage , docker . TagImageOptions { Repo : repo , Tag : destTag , Context : context . Background ( ) , } ) ; err != nil { err = fmt . Errorf ( " " , err ) return " " , err } if err := client . PushImage ( docker . PushImageOptions { Name : repo , Tag : destTag , } , authConfig , ) ; err != nil { err = fmt . Errorf ( " " , err ) return " " , err } return destImage , nil } 
func isDockerUsingKeychain ( ) bool { user , err := user . Current ( ) if err != nil { return false } contents , err := ioutil . ReadFile ( path . Join ( user . HomeDir , " " ) ) if err != nil { return false } var j map [ string ] interface { } if err = json . Unmarshal ( contents , & j ) ; err != nil { return false } auths , ok := j [ " " ] if ! ok { return false } authsInner , ok := auths . ( map [ string ] interface { } ) if ! ok { return false } index , ok := authsInner [ " " ] if ! ok { return false } indexInner , ok := index . ( map [ string ] interface { } ) if ! ok || len ( indexInner ) > 0 { return false } return j [ " " ] == " " } 
func newMinioClient ( endpoint , bucket , id , secret string , secure bool ) ( * minioClient , error ) { mclient , err := minio . New ( endpoint , id , secret , secure ) if err != nil { return nil , err } return & minioClient { bucket : bucket , Client : mclient , } , nil } 
func newMinioClientV2 ( endpoint , bucket , id , secret string , secure bool ) ( * minioClient , error ) { mclient , err := minio . NewV2 ( endpoint , id , secret , secure ) if err != nil { return nil , err } return & minioClient { bucket : bucket , Client : mclient , } , nil } 
func newMinioWriter ( ctx context . Context , client * minioClient , name string ) * minioWriter { reader , writer := io . Pipe ( ) w := & minioWriter { ctx : ctx , errChan : make ( chan error ) , pipe : writer , } go func ( ) { _ , err := client . PutObject ( client . bucket , name , reader , " " ) if err != nil { reader . CloseWithError ( err ) } w . errChan <- err } ( ) return w } 
func ( w * minioWriter ) Close ( ) error { span , _ := tracing . AddSpanToAnyExisting ( w . ctx , " " ) defer tracing . FinishAnySpan ( span ) if err := w . pipe . Close ( ) ; err != nil { return err } return <- w . errChan } 
func PipelineRepo ( pipeline * ppsclient . Pipeline ) * pfs . Repo { return & pfs . Repo { Name : pipeline . Name } } 
func PipelineRcName ( name string , version uint64 ) string { return fmt . Sprintf ( " " , strings . ToLower ( name ) , version ) } 
func GetRequestsResourceListFromPipeline ( pipelineInfo * pps . PipelineInfo ) ( * v1 . ResourceList , error ) { return getResourceListFromSpec ( pipelineInfo . ResourceRequests , pipelineInfo . CacheSize ) } 
func GetLimitsResourceListFromPipeline ( pipelineInfo * pps . PipelineInfo ) ( * v1 . ResourceList , error ) { return getResourceListFromSpec ( pipelineInfo . ResourceLimits , pipelineInfo . CacheSize ) } 
func getNumNodes ( kubeClient * kube . Clientset ) ( int , error ) { nodeList , err := kubeClient . CoreV1 ( ) . Nodes ( ) . List ( metav1 . ListOptions { } ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } if len ( nodeList . Items ) == 0 { return 0 , fmt . Errorf ( " " ) } return len ( nodeList . Items ) , nil } 
func GetExpectedNumWorkers ( kubeClient * kube . Clientset , spec * ppsclient . ParallelismSpec ) ( int , error ) { if spec == nil || ( spec . Constant == 0 && spec . Coefficient == 0 ) { return 1 , nil } else if spec . Constant > 0 && spec . Coefficient == 0 { return int ( spec . Constant ) , nil } else if spec . Constant == 0 && spec . Coefficient > 0 { if err != nil { return 0 , err } result := math . Floor ( spec . Coefficient * float64 ( numNodes ) ) return int ( math . Max ( result , 1 ) ) , nil } return 0 , fmt . Errorf ( " " , spec ) } 
func GetExpectedNumHashtrees ( spec * ppsclient . HashtreeSpec ) ( int64 , error ) { if spec == nil || spec . Constant == 0 { return 1 , nil } else if spec . Constant > 0 { return int64 ( spec . Constant ) , nil } return 0 , fmt . Errorf ( " " , spec ) } 
func GetPipelineInfo ( pachClient * client . APIClient , ptr * pps . EtcdPipelineInfo , full bool ) ( * pps . PipelineInfo , error ) { result := & pps . PipelineInfo { } if full { buf := bytes . Buffer { } if err := pachClient . GetFile ( ppsconsts . SpecRepo , ptr . SpecCommit . ID , ppsconsts . SpecFile , 0 , 0 , & buf ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } if err := result . Unmarshal ( buf . Bytes ( ) ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } } result . State = ptr . State result . Reason = ptr . Reason result . JobCounts = ptr . JobCounts result . LastJobState = ptr . LastJobState result . SpecCommit = ptr . SpecCommit return result , nil } 
func FailPipeline ( ctx context . Context , etcdClient * etcd . Client , pipelinesCollection col . Collection , pipelineName string , reason string ) error { _ , err := col . NewSTM ( ctx , etcdClient , func ( stm col . STM ) error { pipelines := pipelinesCollection . ReadWrite ( stm ) pipelinePtr := new ( pps . EtcdPipelineInfo ) if err := pipelines . Get ( pipelineName , pipelinePtr ) ; err != nil { return err } pipelinePtr . State = pps . PipelineState_PIPELINE_FAILURE pipelinePtr . Reason = reason pipelines . Put ( pipelineName , pipelinePtr ) return nil } ) return err } 
func JobInput ( pipelineInfo * pps . PipelineInfo , outputCommitInfo * pfs . CommitInfo ) * pps . Input { key := path . Join for _ , prov := range outputCommitInfo . Provenance { branchToCommit [ key ( prov . Commit . Repo . Name , prov . Branch . Name ) ] = prov . Commit } jobInput := proto . Clone ( pipelineInfo . Input ) . ( * pps . Input ) pps . VisitInput ( jobInput , func ( input * pps . Input ) { if input . Pfs != nil { if commit , ok := branchToCommit [ key ( input . Pfs . Repo , input . Pfs . Branch ) ] ; ok { input . Pfs . Commit = commit . ID } } if input . Cron != nil { if commit , ok := branchToCommit [ key ( input . Cron . Repo , " " ) ] ; ok { input . Cron . Commit = commit . ID } } if input . Git != nil { if commit , ok := branchToCommit [ key ( input . Git . Name , input . Git . Branch ) ] ; ok { input . Git . Commit = commit . ID } } } ) return jobInput } 
func PipelineReqFromInfo ( pipelineInfo * ppsclient . PipelineInfo ) * ppsclient . CreatePipelineRequest { return & ppsclient . CreatePipelineRequest { Pipeline : pipelineInfo . Pipeline , Transform : pipelineInfo . Transform , ParallelismSpec : pipelineInfo . ParallelismSpec , HashtreeSpec : pipelineInfo . HashtreeSpec , Egress : pipelineInfo . Egress , OutputBranch : pipelineInfo . OutputBranch , ScaleDownThreshold : pipelineInfo . ScaleDownThreshold , ResourceRequests : pipelineInfo . ResourceRequests , ResourceLimits : pipelineInfo . ResourceLimits , Input : pipelineInfo . Input , Description : pipelineInfo . Description , CacheSize : pipelineInfo . CacheSize , EnableStats : pipelineInfo . EnableStats , Batch : pipelineInfo . Batch , MaxQueueSize : pipelineInfo . MaxQueueSize , Service : pipelineInfo . Service , ChunkSpec : pipelineInfo . ChunkSpec , DatumTimeout : pipelineInfo . DatumTimeout , JobTimeout : pipelineInfo . JobTimeout , Salt : pipelineInfo . Salt , } } 
func NewPipelineManifestReader ( path string ) ( result * PipelineManifestReader , retErr error ) { result = & PipelineManifestReader { } var pipelineReader io . Reader if path == " " { pipelineReader = io . TeeReader ( os . Stdin , & result . buf ) fmt . Print ( " \n " ) } else if url , err := url . Parse ( path ) ; err == nil && url . Scheme != " " { resp , err := http . Get ( url . String ( ) ) if err != nil { return nil , err } defer func ( ) { if err := resp . Body . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) rawBytes , err := ioutil . ReadAll ( resp . Body ) if err != nil { return nil , err } pipelineReader = io . TeeReader ( strings . NewReader ( string ( rawBytes ) ) , & result . buf ) } else { rawBytes , err := ioutil . ReadFile ( path ) if err != nil { return nil , err } pipelineReader = io . TeeReader ( strings . NewReader ( string ( rawBytes ) ) , & result . buf ) } result . decoder = json . NewDecoder ( pipelineReader ) return result , nil } 
func ( r * PipelineManifestReader ) NextCreatePipelineRequest ( ) ( * ppsclient . CreatePipelineRequest , error ) { var result ppsclient . CreatePipelineRequest if err := jsonpb . UnmarshalNext ( r . decoder , & result ) ; err != nil { if err == io . EOF { return nil , err } return nil , fmt . Errorf ( " " , err ) } return & result , nil } 
func DescribeSyntaxError ( originalErr error , parsedBuffer bytes . Buffer ) error { sErr , ok := originalErr . ( * json . SyntaxError ) if ! ok { return originalErr } buffer := make ( [ ] byte , sErr . Offset ) parsedBuffer . Read ( buffer ) lineOffset := strings . LastIndex ( string ( buffer [ : len ( buffer ) - 1 ] ) , " \n " ) if lineOffset == - 1 { lineOffset = 0 } lines := strings . Split ( string ( buffer [ : len ( buffer ) - 1 ] ) , " \n " ) lineNumber := len ( lines ) descriptiveErrorString := fmt . Sprintf ( " \n \n \n \n " , lineNumber , string ( buffer [ lineOffset : ] ) , strings . Repeat ( " " , int ( sErr . Offset ) - 2 - lineOffset ) , originalErr , ) return errors . New ( descriptiveErrorString ) } 
func IsTerminal ( state pps . JobState ) bool { switch state { case pps . JobState_JOB_SUCCESS , pps . JobState_JOB_FAILURE , pps . JobState_JOB_KILLED : return true case pps . JobState_JOB_STARTING , pps . JobState_JOB_RUNNING , pps . JobState_JOB_MERGING : return false default : panic ( fmt . Sprintf ( " " , state ) ) } } 
func UpdateJobState ( pipelines col . ReadWriteCollection , jobs col . ReadWriteCollection , jobPtr * pps . EtcdJobInfo , state pps . JobState , reason string ) error { if err := pipelines . Get ( jobPtr . Pipeline . Name , pipelinePtr ) ; err != nil { return err } if pipelinePtr . JobCounts == nil { pipelinePtr . JobCounts = make ( map [ int32 ] int32 ) } if pipelinePtr . JobCounts [ int32 ( jobPtr . State ) ] != 0 { pipelinePtr . JobCounts [ int32 ( jobPtr . State ) ] -- } pipelinePtr . JobCounts [ int32 ( state ) ] ++ pipelinePtr . LastJobState = state if err := pipelines . Put ( jobPtr . Pipeline . Name , pipelinePtr ) ; err != nil { return err } if state == pps . JobState_JOB_STARTING { jobPtr . Started , err = types . TimestampProto ( time . Now ( ) ) } else if IsTerminal ( state ) { jobPtr . Finished , err = types . TimestampProto ( time . Now ( ) ) } if err != nil { return err } jobPtr . State = state jobPtr . Reason = reason return jobs . Put ( jobPtr . Job . ID , jobPtr ) } 
func fetchRawIDPMetadata ( name string , mdURL * url . URL ) ( [ ] byte , error ) { c := http . DefaultClient req , err := http . NewRequest ( " " , mdURL . String ( ) , nil ) if err != nil { return nil , fmt . Errorf ( " " , name , err ) } req . Header . Set ( " " , " " ) var rawMetadata [ ] byte b := backoff . NewInfiniteBackOff ( ) b . MaxElapsedTime = 30 * time . Second b . MaxInterval = 2 * time . Second if err := backoff . RetryNotify ( func ( ) error { resp , err := c . Do ( req ) if err != nil { return err } if resp . StatusCode != http . StatusOK { return fmt . Errorf ( " " , resp . StatusCode , resp . Status ) } rawMetadata , err = ioutil . ReadAll ( resp . Body ) resp . Body . Close ( ) if err != nil { return fmt . Errorf ( " " , err ) } if len ( rawMetadata ) == 0 { return fmt . Errorf ( " " ) } return nil } , b , func ( err error , d time . Duration ) error { logrus . Printf ( " " , err , d ) return nil } ) ; err != nil { return nil , err } } 
func ( a * apiServer ) updateConfig ( config * auth . AuthConfig ) error { if config == nil { config = & auth . AuthConfig { } } newConfig , err := validateConfig ( config , internal ) if err != nil { return err } a . redirectAddress = a . configCache . SAMLSvc . DashURL } else { a . configCache = nil a . samlSP = nil a . redirectAddress = nil } return nil } 
func ( a * apiServer ) handleSAMLResponseInternal ( req * http . Request ) ( string , string , * errutil . HTTPError ) { a . configMu . Lock ( ) defer a . configMu . Unlock ( ) a . samlSPMu . Lock ( ) defer a . samlSPMu . Unlock ( ) if a . configCache == nil { return " " , " " , errutil . NewHTTPError ( http . StatusConflict , " " ) } if a . samlSP == nil { return " " , " " , errutil . NewHTTPError ( http . StatusConflict , " " ) } sp := a . samlSP if err := req . ParseForm ( ) ; err != nil { return " " , " " , errutil . NewHTTPError ( http . StatusConflict , " " , err ) } if err != nil { errMsg := fmt . Sprintf ( " " , err ) if invalidRespErr , ok := err . ( * saml . InvalidResponseError ) ; ok { errMsg += " \n " + invalidRespErr . PrivateErr . Error ( ) + " " } return " " , " " , errutil . NewHTTPError ( http . StatusBadRequest , errMsg ) } case assertion . Subject == nil : return " " , " " , errutil . NewHTTPError ( http . StatusConflict , " " ) case assertion . Subject . NameID == nil : return " " , " " , errutil . NewHTTPError ( http . StatusConflict , " " ) case assertion . Subject . NameID . Value == " " : return " " , " " , errutil . NewHTTPError ( http . StatusConflict , " " ) } if a . configCache . SAMLSvc . SessionDuration != 0 { expiration = time . Now ( ) . Add ( a . configCache . SAMLSvc . SessionDuration ) } authCode , err := a . getOneTimePassword ( req . Context ( ) , subject , expiration ) if err != nil { return " " , " " , errutil . NewHTTPError ( http . StatusInternalServerError , err . Error ( ) ) } } for _ , v := range attr . Values { groups = append ( groups , fmt . Sprintf ( " " , a . configCache . IDP . Name , v . Value ) ) } if err := a . setGroupsForUserInternal ( context . Background ( ) , subject , groups ) ; err != nil { return " " , " " , errutil . NewHTTPError ( http . StatusInternalServerError , err . Error ( ) ) } } } } return subject , authCode , nil } 
func ( a * apiServer ) handleSAMLResponse ( w http . ResponseWriter , req * http . Request ) { var subject , authCode string var err * errutil . HTTPError logRequest := " " a . LogReq ( logRequest ) defer func ( start time . Time ) { if subject != " " { logRequest = fmt . Sprintf ( " " , subject ) } a . LogResp ( logRequest , errutil . PrettyPrintCode ( err ) , err , time . Since ( start ) ) } ( time . Now ( ) ) subject , authCode , err = a . handleSAMLResponseInternal ( req ) if err != nil { http . Error ( w , err . Error ( ) , err . Code ( ) ) return } if a . redirectAddress != nil { u = * a . redirectAddress } u . RawQuery = url . Values { " " : [ ] string { authCode } } . Encode ( ) w . Header ( ) . Set ( " " , u . String ( ) ) w . WriteHeader ( http . StatusFound ) } 
func New ( ) string { var result string backoff . RetryNotify ( func ( ) error { uuid , err := uuid . NewV4 ( ) if err != nil { return err } result = uuid . String ( ) return nil } , backoff . NewInfiniteBackOff ( ) , func ( err error , d time . Duration ) error { fmt . Printf ( " " , err ) return nil } ) return result } 
func ( h * HTTPError ) Code ( ) int { if h == nil { return http . StatusOK } return h . code } 
func PrettyPrintCode ( h * HTTPError ) string { codeNumber := h . Code ( ) codeText := http . StatusText ( h . Code ( ) ) return fmt . Sprintf ( " " , codeNumber , codeText ) } 
func NewHTTPError ( code int , formatStr string , args ... interface { } ) * HTTPError { return & HTTPError { code : code , err : fmt . Sprintf ( formatStr , args ... ) , } } 
func NewStorage ( objC obj . Client , prefix string ) * Storage { return & Storage { objC : objC , prefix : prefix , } } 
func ( s * Storage ) NewReader ( ctx context . Context , dataRefs [ ] * DataRef ) io . ReadCloser { if len ( dataRefs ) == 0 { return ioutil . NopCloser ( & bytes . Buffer { } ) } return newReader ( ctx , s . objC , s . prefix , dataRefs ) } 
func ( s * Storage ) NewWriter ( ctx context . Context ) * Writer { return newWriter ( ctx , s . objC , s . prefix ) } 
func ( s * Storage ) DeleteAll ( ctx context . Context ) error { return s . objC . Walk ( ctx , s . prefix , func ( hash string ) error { return s . objC . Delete ( ctx , hash ) } ) } 
func Chunk ( data [ ] byte , chunkSize int ) [ ] [ ] byte { var result [ ] [ ] byte for i := 0 ; i < len ( data ) ; i += chunkSize { end := i + chunkSize if end > len ( data ) { end = len ( data ) } result = append ( result , data [ i : end ] ) } return result } 
func ChunkReader ( r io . Reader , f func ( [ ] byte ) error ) ( int , error ) { var total int buf := GetBuffer ( ) defer PutBuffer ( buf ) for { n , err := r . Read ( buf ) if n == 0 && err != nil { if err == io . EOF { return total , nil } return total , err } if err := f ( buf [ : n ] ) ; err != nil { return total , err } total += n } } 
func NewStreamingBytesReader ( streamingBytesClient StreamingBytesClient , cancel context . CancelFunc ) io . ReadCloser { return & streamingBytesReader { streamingBytesClient : streamingBytesClient , cancel : cancel } } 
func WriteToStreamingBytesServer ( reader io . Reader , streamingBytesServer StreamingBytesServer ) error { buf := GetBuffer ( ) defer PutBuffer ( buf ) _ , err := io . CopyBuffer ( NewStreamingBytesWriter ( streamingBytesServer ) , ReaderWrapper { reader } , buf ) return err } 
func WriteFromStreamingBytesClient ( streamingBytesClient StreamingBytesClient , writer io . Writer ) error { for bytesValue , err := streamingBytesClient . Recv ( ) ; err != io . EOF ; bytesValue , err = streamingBytesClient . Recv ( ) { if err != nil { return err } if _ , err = writer . Write ( bytesValue . Value ) ; err != nil { return err } } return nil } 
func NewAPIServer ( env * serviceenv . ServiceEnv , etcdPrefix string , namespace string , workerImage string , workerSidecarImage string , workerImagePullPolicy string , storageRoot string , storageBackend string , storageHostPath string , iamRole string , imagePullSecret string , noExposeDockerSocket bool , reporter * metrics . Reporter , workerUsesRoot bool , workerGrpcPort uint16 , port uint16 , pprofPort uint16 , httpPort uint16 , peerPort uint16 , ) ( ppsclient . APIServer , error ) { apiServer := & apiServer { Logger : log . NewLogger ( " " ) , env : env , etcdPrefix : etcdPrefix , namespace : namespace , workerImage : workerImage , workerSidecarImage : workerSidecarImage , workerImagePullPolicy : workerImagePullPolicy , storageRoot : storageRoot , storageBackend : storageBackend , storageHostPath : storageHostPath , iamRole : iamRole , imagePullSecret : imagePullSecret , noExposeDockerSocket : noExposeDockerSocket , reporter : reporter , workerUsesRoot : workerUsesRoot , pipelines : ppsdb . Pipelines ( env . GetEtcdClient ( ) , etcdPrefix ) , jobs : ppsdb . Jobs ( env . GetEtcdClient ( ) , etcdPrefix ) , monitorCancels : make ( map [ string ] func ( ) ) , workerGrpcPort : workerGrpcPort , port : port , pprofPort : pprofPort , httpPort : httpPort , peerPort : peerPort , } apiServer . validateKube ( ) go apiServer . master ( ) return apiServer , nil } 
func NewSidecarAPIServer ( env * serviceenv . ServiceEnv , etcdPrefix string , iamRole string , reporter * metrics . Reporter , workerGrpcPort uint16 , pprofPort uint16 , httpPort uint16 , peerPort uint16 , ) ( ppsclient . APIServer , error ) { apiServer := & apiServer { Logger : log . NewLogger ( " " ) , env : env , etcdPrefix : etcdPrefix , iamRole : iamRole , reporter : reporter , workerUsesRoot : true , pipelines : ppsdb . Pipelines ( env . GetEtcdClient ( ) , etcdPrefix ) , jobs : ppsdb . Jobs ( env . GetEtcdClient ( ) , etcdPrefix ) , workerGrpcPort : workerGrpcPort , pprofPort : pprofPort , httpPort : httpPort , peerPort : peerPort , } return apiServer , nil } 
func NewEnterpriseServer ( env * serviceenv . ServiceEnv , etcdPrefix string ) ( ec . APIServer , error ) { s := & apiServer { pachLogger : log . NewLogger ( " " ) , env : env , enterpriseToken : col . NewCollection ( env . GetEtcdClient ( ) , etcdPrefix , s . enterpriseExpiration . Store ( time . Time { } ) go s . watchEnterpriseToken ( etcdPrefix ) return s , nil } 
func validateActivationCode ( code string ) ( expiration time . Time , err error ) { if block == nil { return time . Time { } , fmt . Errorf ( " " ) } pub , err := x509 . ParsePKIXPublicKey ( block . Bytes ) if err != nil { return time . Time { } , fmt . Errorf ( " " , err . Error ( ) ) } rsaPub , ok := pub . ( * rsa . PublicKey ) if ! ok { return time . Time { } , fmt . Errorf ( " " ) } if err != nil { return time . Time { } , fmt . Errorf ( " " ) } activationCode := & activationCode { } if err := json . Unmarshal ( decodedActivationCode , & activationCode ) ; err != nil { return time . Time { } , fmt . Errorf ( " " ) } if err != nil { return time . Time { } , fmt . Errorf ( " " ) } } if err := json . Unmarshal ( [ ] byte ( activationCode . Token ) , & token ) ; err != nil { return time . Time { } , fmt . Errorf ( " " ) } if err != nil { return time . Time { } , fmt . Errorf ( " " ) } } return expiration , nil } 
func ( a * apiServer ) Activate ( ctx context . Context , req * ec . ActivateRequest ) ( resp * ec . ActivateResponse , retErr error ) { a . LogReq ( req ) defer func ( start time . Time ) { a . pachLogger . Log ( req , resp , retErr , time . Since ( start ) ) } ( time . Now ( ) ) if err != nil { return nil , fmt . Errorf ( " " , err . Error ( ) ) } if err == nil && expiration . After ( customExpiration ) { expiration = customExpiration } } expirationProto , err := types . TimestampProto ( expiration ) if err != nil { return nil , fmt . Errorf ( " \" \" " , expiration . String ( ) , err . Error ( ) ) } if _ , err := col . NewSTM ( ctx , a . env . GetEtcdClient ( ) , func ( stm col . STM ) error { e := a . enterpriseToken . ReadWrite ( stm ) } ) ; err != nil { return nil , err } } return nil } , backoff . RetryEvery ( time . Second ) ) ; err != nil { return nil , err } time . Sleep ( time . Second ) return & ec . ActivateResponse { Info : & ec . TokenInfo { Expires : expirationProto , } , } , nil } 
func ( a * apiServer ) GetState ( ctx context . Context , req * ec . GetStateRequest ) ( resp * ec . GetStateResponse , retErr error ) { a . LogReq ( req ) defer func ( start time . Time ) { a . pachLogger . Log ( req , resp , retErr , time . Since ( start ) ) } ( time . Now ( ) ) expiration , ok := a . enterpriseExpiration . Load ( ) . ( time . Time ) if ! ok { return nil , fmt . Errorf ( " " ) } if expiration . IsZero ( ) { return & ec . GetStateResponse { State : ec . State_NONE } , nil } expirationProto , err := types . TimestampProto ( expiration ) if err != nil { return nil , fmt . Errorf ( " \" \" " , expiration . String ( ) , err . Error ( ) ) } resp = & ec . GetStateResponse { Info : & ec . TokenInfo { Expires : expirationProto , } , } if time . Now ( ) . After ( expiration ) { resp . State = ec . State_EXPIRED } else { resp . State = ec . State_ACTIVE } return resp , nil } 
func ( a * apiServer ) Deactivate ( ctx context . Context , req * ec . DeactivateRequest ) ( resp * ec . DeactivateResponse , retErr error ) { a . LogReq ( req ) defer func ( start time . Time ) { a . pachLogger . Log ( req , resp , retErr , time . Since ( start ) ) } ( time . Now ( ) ) pachClient := a . env . GetPachClient ( ctx ) if err := pachClient . DeleteAll ( ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } if _ , err := col . NewSTM ( ctx , a . env . GetEtcdClient ( ) , func ( stm col . STM ) error { } ) ; err != nil { return nil , err } } return nil } , backoff . RetryEvery ( time . Second ) ) ; err != nil { return nil , err } time . Sleep ( time . Second ) return & ec . DeactivateResponse { } , nil } 
func Command ( name string , arg ... string ) * Cmd { cmd := & Cmd { Path : name , Args : append ( [ ] string { name } , arg ... ) , } if filepath . Base ( name ) == name { if lp , err := exec . LookPath ( name ) ; err != nil { cmd . lookPathErr = err } else { cmd . Path = lp } } return cmd } 
func CommandContext ( ctx context . Context , name string , arg ... string ) * Cmd { if ctx == nil { panic ( " " ) } cmd := Command ( name , arg ... ) cmd . ctx = ctx return cmd } 
func ( c * Cmd ) Run ( ) error { if err := c . Start ( ) ; err != nil { return err } return c . Wait ( ) } 
func lookExtensions ( path , dir string ) ( string , error ) { if filepath . Base ( path ) == path { path = filepath . Join ( " " , path ) } if dir == " " { return exec . LookPath ( path ) } if filepath . VolumeName ( path ) != " " { return exec . LookPath ( path ) } if len ( path ) > 1 && os . IsPathSeparator ( path [ 0 ] ) { return exec . LookPath ( path ) } dirandpath := filepath . Join ( dir , path ) if err != nil { return " " , err } ext := strings . TrimPrefix ( lp , dirandpath ) return path + ext , nil } 
func ( c * Cmd ) Start ( ) error { if c . lookPathErr != nil { c . closeDescriptors ( c . closeAfterStart ) c . closeDescriptors ( c . closeAfterWait ) return c . lookPathErr } if runtime . GOOS == " " { lp , err := lookExtensions ( c . Path , c . Dir ) if err != nil { c . closeDescriptors ( c . closeAfterStart ) c . closeDescriptors ( c . closeAfterWait ) return err } c . Path = lp } if c . Process != nil { return errors . New ( " " ) } if c . ctx != nil { select { case <- c . ctx . Done ( ) : c . closeDescriptors ( c . closeAfterStart ) c . closeDescriptors ( c . closeAfterWait ) return c . ctx . Err ( ) default : } } type F func ( * Cmd ) ( * os . File , error ) for _ , setupFd := range [ ] F { ( * Cmd ) . stdin , ( * Cmd ) . stdout , ( * Cmd ) . stderr } { fd , err := setupFd ( c ) if err != nil { c . closeDescriptors ( c . closeAfterStart ) c . closeDescriptors ( c . closeAfterWait ) return err } c . childFiles = append ( c . childFiles , fd ) } c . childFiles = append ( c . childFiles , c . ExtraFiles ... ) var err error c . Process , err = os . StartProcess ( c . Path , c . argv ( ) , & os . ProcAttr { Dir : c . Dir , Files : c . childFiles , Env : dedupEnv ( c . envv ( ) ) , Sys : c . SysProcAttr , } ) if err != nil { c . closeDescriptors ( c . closeAfterStart ) c . closeDescriptors ( c . closeAfterWait ) return err } c . closeDescriptors ( c . closeAfterStart ) c . errch = make ( chan error , len ( c . goroutine ) ) for _ , fn := range c . goroutine { go func ( fn func ( ) error ) { c . errch <- fn ( ) } ( fn ) } if c . ctx != nil { c . waitDone = make ( chan struct { } ) go func ( ) { select { case <- c . ctx . Done ( ) : c . Process . Kill ( ) case <- c . waitDone : } } ( ) } return nil } 
func ( c * Cmd ) Wait ( ) error { if c . Process == nil { return errors . New ( " " ) } if c . finished { return errors . New ( " " ) } c . finished = true state , err := c . Process . Wait ( ) return c . WaitIO ( state , err ) } 
func ( c * Cmd ) WaitIO ( state * os . ProcessState , err error ) ( retErr error ) { if c . waitDone != nil { close ( c . waitDone ) } c . ProcessState = state if err != nil { return err } else if ! state . Success ( ) { return & ExitError { ProcessState : state } } for range c . goroutine { if err := <- c . errch ; err != nil && retErr == nil { retErr = err } } c . closeDescriptors ( c . closeAfterWait ) return retErr } 
func ( c * Cmd ) Output ( ) ( [ ] byte , error ) { if c . Stdout != nil { return nil , errors . New ( " " ) } var stdout bytes . Buffer c . Stdout = & stdout captureErr := c . Stderr == nil if captureErr { c . Stderr = & prefixSuffixSaver { N : 32 << 10 } } err := c . Run ( ) if err != nil && captureErr { if ee , ok := err . ( * ExitError ) ; ok { ee . Stderr = c . Stderr . ( * prefixSuffixSaver ) . Bytes ( ) } } return stdout . Bytes ( ) , err } 
func ( c * Cmd ) CombinedOutput ( ) ( [ ] byte , error ) { if c . Stdout != nil { return nil , errors . New ( " " ) } if c . Stderr != nil { return nil , errors . New ( " " ) } var b bytes . Buffer c . Stdout = & b c . Stderr = & b err := c . Run ( ) return b . Bytes ( ) , err } 
func ( c * Cmd ) StdinPipe ( ) ( io . WriteCloser , error ) { if c . Stdin != nil { return nil , errors . New ( " " ) } if c . Process != nil { return nil , errors . New ( " " ) } pr , pw , err := os . Pipe ( ) if err != nil { return nil , err } c . Stdin = pr c . closeAfterStart = append ( c . closeAfterStart , pr ) wc := & closeOnce { File : pw } c . closeAfterWait = append ( c . closeAfterWait , closerFunc ( wc . safeClose ) ) return wc , nil } 
func ( c * closeOnce ) safeClose ( ) error { c . writers . Lock ( ) err := c . Close ( ) c . writers . Unlock ( ) return err } 
func ( c * Cmd ) StdoutPipe ( ) ( io . ReadCloser , error ) { if c . Stdout != nil { return nil , errors . New ( " " ) } if c . Process != nil { return nil , errors . New ( " " ) } pr , pw , err := os . Pipe ( ) if err != nil { return nil , err } c . Stdout = pw c . closeAfterStart = append ( c . closeAfterStart , pw ) c . closeAfterWait = append ( c . closeAfterWait , pr ) return pr , nil } 
func dedupEnvCase ( caseInsensitive bool , env [ ] string ) [ ] string { out := make ( [ ] string , 0 , len ( env ) ) saw := map [ string ] int { } for _ , kv := range env { eq := strings . Index ( kv , " " ) if eq < 0 { out = append ( out , kv ) continue } k := kv [ : eq ] if caseInsensitive { k = strings . ToLower ( k ) } if dupIdx , isDup := saw [ k ] ; isDup { out [ dupIdx ] = kv continue } saw [ k ] = len ( out ) out = append ( out , kv ) } return out } 
func VisitInput ( input * Input , f func ( * Input ) ) { switch { case input == nil : return case input . Cross != nil : for _ , input := range input . Cross { VisitInput ( input , f ) } case input . Union != nil : for _ , input := range input . Union { VisitInput ( input , f ) } } f ( input ) } 
func InputName ( input * Input ) string { switch { case input == nil : return " " case input . Pfs != nil : return input . Pfs . Name case input . Cross != nil : if len ( input . Cross ) > 0 { return InputName ( input . Cross [ 0 ] ) } case input . Union != nil : if len ( input . Union ) > 0 { return InputName ( input . Union [ 0 ] ) } } return " " } 
func SortInput ( input * Input ) { VisitInput ( input , func ( input * Input ) { SortInputs := func ( inputs [ ] * Input ) { sort . SliceStable ( inputs , func ( i , j int ) bool { return InputName ( inputs [ i ] ) < InputName ( inputs [ j ] ) } ) } switch { case input . Cross != nil : SortInputs ( input . Cross ) case input . Union != nil : SortInputs ( input . Union ) } } ) } 
func InputBranches ( input * Input ) [ ] * pfs . Branch { var result [ ] * pfs . Branch VisitInput ( input , func ( input * Input ) { if input . Pfs != nil { result = append ( result , & pfs . Branch { Repo : & pfs . Repo { Name : input . Pfs . Repo } , Name : input . Pfs . Branch , } ) } if input . Cron != nil { result = append ( result , & pfs . Branch { Repo : & pfs . Repo { Name : input . Cron . Repo } , Name : " " , } ) } if input . Git != nil { result = append ( result , & pfs . Branch { Repo : & pfs . Repo { Name : input . Git . Name } , Name : input . Git . Branch , } ) } } ) return result } 
func ValidateGitCloneURL ( url string ) error { exampleURL := " " if url == " " { return fmt . Errorf ( " " , exampleURL ) } if err := o . Validate ( ) ; err != nil { return err } if ! strings . HasSuffix ( url , " " ) { } if ! strings . HasPrefix ( url , " " ) { } return nil } 
func containsEmpty ( vals [ ] string ) bool { for _ , val := range vals { if val == " " { return true } } return false } 
func deployCmds ( noMetrics * bool , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command var opts * assets . AssetOpts var dryRun bool var outputFormat string var dev bool var hostPath string deployLocal := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) ( retErr error ) { metrics := ! * noMetrics if metrics && ! dev { start := time . Now ( ) startMetricsWait := _metrics . StartReportAndFlushUserAction ( " " , start ) defer startMetricsWait ( ) defer func ( ) { finishMetricsWait := _metrics . FinishReportAndFlushUserAction ( " " , retErr , start ) finishMetricsWait ( ) } ( ) } manifest := getEncoder ( outputFormat ) if dev { } if err := assets . WriteLocalAssets ( manifest , opts , hostPath ) ; err != nil { return err } return kubectlCreate ( dryRun , manifest , opts , metrics ) } ) , } deployLocal . Flags ( ) . StringVar ( & hostPath , " " , " " , " " ) deployLocal . Flags ( ) . BoolVarP ( & dev , " " , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( deployLocal , " " ) ) deployGoogle := & cobra . Command { Use : " " , Short : " " , Long : `Deploy a Pachyderm cluster running on Google Cloud Platform. <bucket-name>: A Google Cloud Storage bucket where Pachyderm will store PFS data. <disk-size>: Size of Google Compute Engine persistent disks in GB (assumed to all be the same). <credentials-file>: A file containing the private key for the account (downloaded from Google Compute Engine).` , Run : cmdutil . RunBoundedArgs ( 2 , 3 , func ( args [ ] string ) ( retErr error ) { metrics := ! * noMetrics if metrics { start := time . Now ( ) startMetricsWait := _metrics . StartReportAndFlushUserAction ( " " , start ) defer startMetricsWait ( ) defer func ( ) { finishMetricsWait := _metrics . FinishReportAndFlushUserAction ( " " , retErr , start ) finishMetricsWait ( ) } ( ) } volumeSize , err := strconv . Atoi ( args [ 1 ] ) if err != nil { return fmt . Errorf ( " " , args [ 1 ] ) } manifest := getEncoder ( outputFormat ) opts . BlockCacheSize = " " var cred string if len ( args ) == 3 { credBytes , err := ioutil . ReadFile ( args [ 2 ] ) if err != nil { return fmt . Errorf ( " " , args [ 2 ] , err ) } cred = string ( credBytes ) } bucket := strings . TrimPrefix ( args [ 0 ] , " " ) if err = assets . WriteGoogleAssets ( manifest , opts , bucket , cred , volumeSize ) ; err != nil { return err } return kubectlCreate ( dryRun , manifest , opts , metrics ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( deployGoogle , " " ) ) var objectStoreBackend string var persistentDiskBackend string var secure bool var isS3V2 bool deployCustom := & cobra . Command { Use : " " , Short : " " , Long : `Deploy a custom Pachyderm cluster configuration. If <object store backend> is \"s3\", then the arguments are: <volumes> <size of volumes (in GB)> <bucket> <id> <secret> <endpoint>` , Run : cmdutil . RunBoundedArgs ( 4 , 7 , func ( args [ ] string ) ( retErr error ) { metrics := ! * noMetrics if metrics { start := time . Now ( ) startMetricsWait := _metrics . StartReportAndFlushUserAction ( " " , start ) defer startMetricsWait ( ) defer func ( ) { finishMetricsWait := _metrics . FinishReportAndFlushUserAction ( " " , retErr , start ) finishMetricsWait ( ) } ( ) } manifest := getEncoder ( outputFormat ) err := assets . WriteCustomAssets ( manifest , opts , args , objectStoreBackend , persistentDiskBackend , secure , isS3V2 ) if err != nil { return err } return kubectlCreate ( dryRun , manifest , opts , metrics ) } ) , } deployCustom . Flags ( ) . BoolVarP ( & secure , " " , " " , false , " " ) deployCustom . Flags ( ) . StringVar ( & persistentDiskBackend , " " , " " , " " + " " ) deployCustom . Flags ( ) . StringVar ( & objectStoreBackend , " " , " " , " " + " " ) deployCustom . Flags ( ) . BoolVar ( & isS3V2 , " " , false , " " ) commands = append ( commands , cmdutil . CreateAlias ( deployCustom , " " ) ) var cloudfrontDistribution string var creds string var iamRole string var vault string deployAmazon := & cobra . Command { Use : " " , Short : " " , Long : `Deploy a Pachyderm cluster running on AWS. <bucket-name>: An S3 bucket where Pachyderm will store PFS data. <region>: The AWS region where Pachyderm is being deployed (e.g. us-west-1) <disk-size>: Size of EBS volumes, in GB (assumed to all be the same).` , Run : cmdutil . RunFixedArgs ( 3 , func ( args [ ] string ) ( retErr error ) { metrics := ! * noMetrics if metrics { start := time . Now ( ) startMetricsWait := _metrics . StartReportAndFlushUserAction ( " " , start ) defer startMetricsWait ( ) defer func ( ) { finishMetricsWait := _metrics . FinishReportAndFlushUserAction ( " " , retErr , start ) finishMetricsWait ( ) } ( ) } if creds == " " && vault == " " && iamRole == " " { return fmt . Errorf ( " " ) } // populate 'amazonCreds' & validate var amazonCreds * assets . AmazonCreds s := bufio . NewScanner ( os . Stdin ) if creds != " " { parts := strings . Split ( creds , " " ) if len ( parts ) < 2 || len ( parts ) > 3 || containsEmpty ( parts [ : 2 ] ) { return fmt . Errorf ( " " ) } amazonCreds = & assets . AmazonCreds { ID : parts [ 0 ] , Secret : parts [ 1 ] } if len ( parts ) > 2 { amazonCreds . Token = parts [ 2 ] } if ! awsAccessKeyIDRE . MatchString ( amazonCreds . ID ) { fmt . Printf ( " " + " \n " , awsAccessKeyIDRE ) if s . Scan ( ) ; s . Text ( ) [ 0 ] != 'y' && s . Text ( ) [ 0 ] != 'Y' { os . Exit ( 1 ) } } if ! awsSecretRE . MatchString ( amazonCreds . Secret ) { fmt . Printf ( " " + " \n " , awsSecretRE ) if s . Scan ( ) ; s . Text ( ) [ 0 ] != 'y' && s . Text ( ) [ 0 ] != 'Y' { os . Exit ( 1 ) } } } if vault != " " { if amazonCreds != nil { return fmt . Errorf ( " " ) } parts := strings . Split ( vault , " " ) if len ( parts ) != 3 || containsEmpty ( parts ) { return fmt . Errorf ( " " ) } amazonCreds = & assets . AmazonCreds { VaultAddress : parts [ 0 ] , VaultRole : parts [ 1 ] , VaultToken : parts [ 2 ] } } if iamRole != " " { if amazonCreds != nil { return fmt . Errorf ( " " ) } opts . IAMRole = iamRole } volumeSize , err := strconv . Atoi ( args [ 2 ] ) if err != nil { return fmt . Errorf ( " " , args [ 2 ] ) } if strings . TrimSpace ( cloudfrontDistribution ) != " " { fmt . Printf ( " " + " \n " ) } bucket , region := strings . TrimPrefix ( args [ 0 ] , " " ) , args [ 1 ] if ! awsRegionRE . MatchString ( region ) { fmt . Printf ( " " + " \n " , awsRegionRE ) if s . Scan ( ) ; s . Text ( ) [ 0 ] != 'y' && s . Text ( ) [ 0 ] != 'Y' { os . Exit ( 1 ) } } // generate manifest and write assets manifest := getEncoder ( outputFormat ) if err = assets . WriteAmazonAssets ( manifest , opts , region , bucket , volumeSize , amazonCreds , cloudfrontDistribution ) ; err != nil { return err } return kubectlCreate ( dryRun , manifest , opts , metrics ) } ) , } deployAmazon . Flags ( ) . StringVar ( & cloudfrontDistribution , " " , " " , " " + " " + " " ) deployAmazon . Flags ( ) . StringVar ( & creds , " " , " " , " \" \" \" \" " ) deployAmazon . Flags ( ) . StringVar ( & vault , " " , " " , " \" \" " ) deployAmazon . Flags ( ) . StringVar ( & iamRole , " " , " " , fmt . Sprintf ( " " , assets . IAMAnnotation ) ) commands = append ( commands , cmdutil . CreateAlias ( deployAmazon , " " ) ) deployMicrosoft := & cobra . Command { Use : " " , Short : " " , Long : `Deploy a Pachyderm cluster running on Microsoft Azure. <container>: An Azure container where Pachyderm will store PFS data. <disk-size>: Size of persistent volumes, in GB (assumed to all be the same).` , Run : cmdutil . RunFixedArgs ( 4 , func ( args [ ] string ) ( retErr error ) { metrics := ! * noMetrics if metrics { start := time . Now ( ) startMetricsWait := _metrics . StartReportAndFlushUserAction ( " " , start ) defer startMetricsWait ( ) defer func ( ) { finishMetricsWait := _metrics . FinishReportAndFlushUserAction ( " " , retErr , start ) finishMetricsWait ( ) } ( ) } if _ , err := base64 . StdEncoding . DecodeString ( args [ 2 ] ) ; err != nil { return fmt . Errorf ( " " , args [ 2 ] ) } if opts . EtcdVolume != " " { tempURI , err := url . ParseRequestURI ( opts . EtcdVolume ) if err != nil { return fmt . Errorf ( " " , opts . EtcdVolume ) } opts . EtcdVolume = tempURI . String ( ) } volumeSize , err := strconv . Atoi ( args [ 3 ] ) if err != nil { return fmt . Errorf ( " " , args [ 3 ] ) } manifest := getEncoder ( outputFormat ) container := strings . TrimPrefix ( args [ 0 ] , " " ) accountName , accountKey := args [ 1 ] , args [ 2 ] if err = assets . WriteMicrosoftAssets ( manifest , opts , container , accountName , accountKey , volumeSize ) ; err != nil { return err } return kubectlCreate ( dryRun , manifest , opts , metrics ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( deployMicrosoft , " " ) ) deployStorageSecrets := func ( data map [ string ] [ ] byte ) error { c , err := client . NewOnUserMachine ( ! * noMetrics , ! * noPortForwarding , " " ) if err != nil { return fmt . Errorf ( " " , err ) } defer c . Close ( ) _ , err = c . DeployStorageSecret ( context . Background ( ) , & deployclient . DeployStorageSecretRequest { Secrets : data , } ) if err != nil { return fmt . Errorf ( " " , err ) } return nil } deployStorageAmazon := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunBoundedArgs ( 3 , 4 , func ( args [ ] string ) error { var token string if len ( args ) == 4 { token = args [ 3 ] } return deployStorageSecrets ( assets . AmazonSecret ( args [ 0 ] , " " , args [ 1 ] , args [ 2 ] , token , " " ) ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( deployStorageAmazon , " " ) ) deployStorageGoogle := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) error { credBytes , err := ioutil . ReadFile ( args [ 0 ] ) if err != nil { return fmt . Errorf ( " " , args [ 0 ] , err ) } return deployStorageSecrets ( assets . GoogleSecret ( " " , string ( credBytes ) ) ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( deployStorageGoogle , " " ) ) deployStorageAzure := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 2 , func ( args [ ] string ) error { return deployStorageSecrets ( assets . MicrosoftSecret ( " " , args [ 0 ] , args [ 1 ] ) ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( deployStorageAzure , " " ) ) deployStorage := & cobra . Command { Short : " " , Long : " " , } commands = append ( commands , cmdutil . CreateAlias ( deployStorage , " " ) ) listImages := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { for _ , image := range assets . Images ( opts ) { fmt . Println ( image ) } return nil } ) , } commands = append ( commands , cmdutil . CreateAlias ( listImages , " " ) ) exportImages := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) ( retErr error ) { file , err := os . Create ( args [ 0 ] ) if err != nil { return err } defer func ( ) { if err := file . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return images . Export ( opts , file ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( exportImages , " " ) ) importImages := & cobra . Command { Use : " " , Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 1 , func ( args [ ] string ) ( retErr error ) { file , err := os . Open ( args [ 0 ] ) if err != nil { return err } defer func ( ) { if err := file . Close ( ) ; err != nil && retErr == nil { retErr = err } } ( ) return images . Import ( opts , file ) } ) , } commands = append ( commands , cmdutil . CreateAlias ( importImages , " " ) ) var blockCacheSize string var dashImage string var dashOnly bool var etcdCPURequest string var etcdMemRequest string var etcdNodes int var etcdStorageClassName string var etcdVolume string var exposeObjectAPI bool var imagePullSecret string var localRoles bool var logLevel string var namespace string var newHashTree bool var noDash bool var noExposeDockerSocket bool var noGuaranteed bool var noRBAC bool var pachdCPURequest string var pachdNonCacheMemRequest string var pachdShards int var registry string var tlsCertKey string deploy := & cobra . Command { Short : " " , Long : " " , PersistentPreRun : cmdutil . Run ( func ( [ ] string ) error { dashImage = getDefaultOrLatestDashImage ( dashImage , dryRun ) opts = & assets . AssetOpts { FeatureFlags : assets . FeatureFlags { NewHashTree : newHashTree , } , PachdShards : uint64 ( pachdShards ) , Version : version . PrettyPrintVersion ( version . Version ) , LogLevel : logLevel , Metrics : ! * noMetrics , PachdCPURequest : pachdCPURequest , PachdNonCacheMemRequest : pachdNonCacheMemRequest , BlockCacheSize : blockCacheSize , EtcdCPURequest : etcdCPURequest , EtcdMemRequest : etcdMemRequest , EtcdNodes : etcdNodes , EtcdVolume : etcdVolume , EtcdStorageClassName : etcdStorageClassName , DashOnly : dashOnly , NoDash : noDash , DashImage : dashImage , Registry : registry , ImagePullSecret : imagePullSecret , NoGuaranteed : noGuaranteed , NoRBAC : noRBAC , LocalRoles : localRoles , Namespace : namespace , NoExposeDockerSocket : noExposeDockerSocket , ExposeObjectAPI : exposeObjectAPI , } if tlsCertKey != " " { if len ( certKey ) != 2 { return fmt . Errorf ( " " , certKey ) } opts . TLS = & assets . TLSOpts { ServerCert : certKey [ 0 ] , ServerKey : certKey [ 1 ] , } } return nil } ) , } deploy . PersistentFlags ( ) . IntVar ( & pachdShards , " " , 16 , " " ) deploy . PersistentFlags ( ) . IntVar ( & etcdNodes , " " , 0 , " " ) deploy . PersistentFlags ( ) . StringVar ( & etcdVolume , " " , " " , " " ) deploy . PersistentFlags ( ) . StringVar ( & etcdStorageClassName , " " , " " , " " ) deploy . PersistentFlags ( ) . BoolVar ( & dryRun , " " , false , " " ) deploy . PersistentFlags ( ) . StringVarP ( & outputFormat , " " , " " , " " , " " ) deploy . PersistentFlags ( ) . StringVar ( & logLevel , " " , " " , " \" \" \" \" \" \" " ) deploy . PersistentFlags ( ) . BoolVar ( & dashOnly , " " , false , " \" \" " ) deploy . PersistentFlags ( ) . BoolVar ( & noDash , " " , false , " " ) deploy . PersistentFlags ( ) . StringVar ( & registry , " " , " " , " " ) deploy . PersistentFlags ( ) . StringVar ( & imagePullSecret , " " , " " , " " ) deploy . PersistentFlags ( ) . StringVar ( & dashImage , " " , " " , " " ) deploy . PersistentFlags ( ) . BoolVar ( & noGuaranteed , " " , false , " " ) deploy . PersistentFlags ( ) . BoolVar ( & noRBAC , " " , false , " " ) deploy . PersistentFlags ( ) . BoolVar ( & localRoles , " " , false , " " ) deploy . PersistentFlags ( ) . StringVar ( & namespace , " " , " " , " " ) deploy . PersistentFlags ( ) . BoolVar ( & noExposeDockerSocket , " " , false , " " ) deploy . PersistentFlags ( ) . BoolVar ( & exposeObjectAPI , " " , false , " " ) deploy . PersistentFlags ( ) . StringVar ( & tlsCertKey , " " , " " , " \" \" " ) deploy . PersistentFlags ( ) . BoolVar ( & newHashTree , " " , false , " " ) deploy . PersistentFlags ( ) . StringVar ( & blockCacheSize , " " , " " , " " + " " ) deploy . PersistentFlags ( ) . StringVar ( & pachdNonCacheMemRequest , " " , " " , " " + " " + " " ) deploy . PersistentFlags ( ) . StringVar ( & etcdCPURequest , " " , " " , " " + " " + " " ) deploy . PersistentFlags ( ) . StringVar ( & etcdMemRequest , " " , " " , " " + " " + " " ) commands = append ( commands , cmdutil . CreateAlias ( deploy , " " ) ) return commands } 
func Cmds ( noMetrics * bool , noPortForwarding * bool ) [ ] * cobra . Command { var commands [ ] * cobra . Command commands = append ( commands , deployCmds ( noMetrics , noPortForwarding ) ... ) var all bool var namespace string undeploy := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { if all { fmt . Printf ( ` By using the --all flag, you are going to delete everything, including the persistent volumes where metadata is stored. If your persistent volumes were dynamically provisioned (i.e. if you used the "--dynamic-etcd-nodes" flag), the underlying volumes will be removed, making metadata such repos, commits, pipelines, and jobs unrecoverable. If your persistent volume was manually provisioned (i.e. if you used the "--static-etcd-volume" flag), the underlying volume will not be removed. ` ) } fmt . Println ( " " ) r := bufio . NewReader ( os . Stdin ) bytes , err := r . ReadBytes ( '\n' ) if err != nil { return err } if bytes [ 0 ] == 'y' || bytes [ 0 ] == 'Y' { io := cmdutil . IO { Stdout : os . Stdout , Stderr : os . Stderr , } assets := [ ] string { " " , " " , " " , " " , " " , " " , " " , " " , } if all { assets = append ( assets , [ ] string { " " , " " , " " , } ... ) } for _ , asset := range assets { if err := cmdutil . RunIO ( io , " " , " " , asset , " " , " " , " " , namespace ) ; err != nil { return err } } } return nil } ) , } undeploy . Flags ( ) . BoolVarP ( & all , " " , " " , false , ` Delete everything, including the persistent volumes where metadata is stored. If your persistent volumes were dynamically provisioned (i.e. if you used the "--dynamic-etcd-nodes" flag), the underlying volumes will be removed, making metadata such repos, commits, pipelines, and jobs unrecoverable. If your persistent volume was manually provisioned (i.e. if you used the "--static-etcd-volume" flag), the underlying volume will not be removed.` ) undeploy . Flags ( ) . StringVar ( & namespace , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( undeploy , " " ) ) var updateDashDryRun bool var updateDashOutputFormat string updateDash := & cobra . Command { Short : " " , Long : " " , Run : cmdutil . RunFixedArgs ( 0 , func ( args [ ] string ) error { if err := cmdutil . RunIO ( io , " " , " " , " " , " " , " " ) ; err != nil { return err } if err := cmdutil . RunIO ( io , " " , " " , " " , " " , " " ) ; err != nil { return err } } opts := & assets . AssetOpts { DashOnly : true , DashImage : getDefaultOrLatestDashImage ( " " , updateDashDryRun ) , } assets . WriteDashboardAssets ( manifest , opts ) return kubectlCreate ( updateDashDryRun , manifest , opts , false ) } ) , } updateDash . Flags ( ) . BoolVar ( & updateDashDryRun , " " , false , " " ) updateDash . Flags ( ) . StringVarP ( & updateDashOutputFormat , " " , " " , " " , " " ) commands = append ( commands , cmdutil . CreateAlias ( updateDash , " " ) ) return commands } 
func Main ( do func ( interface { } ) error , appEnv interface { } , decoders ... Decoder ) { if err := Populate ( appEnv , decoders ... ) ; err != nil { mainError ( err ) } if err := do ( appEnv ) ; err != nil { mainError ( err ) } os . Exit ( 0 ) } 
func NewAPIServer ( address string , storageRoot string , clusterInfo * admin . ClusterInfo ) APIServer { return & apiServer { Logger : log . NewLogger ( " " ) , address : address , storageRoot : storageRoot , clusterInfo : clusterInfo , } } 
func UnescapeHTML ( s string ) string { s = strings . Replace ( s , " \\ " , " " , - 1 ) s = strings . Replace ( s , " \\ " , " " , - 1 ) return s } 
func Ago ( timestamp * types . Timestamp ) string { t , _ := types . TimestampFromProto ( timestamp ) if t . Equal ( time . Time { } ) { return " " } return fmt . Sprintf ( " " , units . HumanDuration ( time . Since ( t ) ) ) } 
func TimeDifference ( from * types . Timestamp , to * types . Timestamp ) string { tFrom , _ := types . TimestampFromProto ( from ) tTo , _ := types . TimestampFromProto ( to ) return units . HumanDuration ( tTo . Sub ( tFrom ) ) } 
func Duration ( d * types . Duration ) string { duration , _ := types . DurationFromProto ( d ) return units . HumanDuration ( duration ) } 
func ( c APIClient ) InspectCluster ( ) ( * admin . ClusterInfo , error ) { clusterInfo , err := c . AdminAPIClient . InspectCluster ( c . Ctx ( ) , & types . Empty { } ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } return clusterInfo , nil } 
func ( c APIClient ) Extract ( objects bool , f func ( op * admin . Op ) error ) error { extractClient , err := c . AdminAPIClient . Extract ( c . Ctx ( ) , & admin . ExtractRequest { NoObjects : ! objects } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } for { op , err := extractClient . Recv ( ) if err == io . EOF { break } if err != nil { return grpcutil . ScrubGRPC ( err ) } if err := f ( op ) ; err != nil { return err } } return nil } 
func ( c APIClient ) ExtractAll ( objects bool ) ( [ ] * admin . Op , error ) { var result [ ] * admin . Op if err := c . Extract ( objects , func ( op * admin . Op ) error { result = append ( result , op ) return nil } ) ; err != nil { return nil , err } return result , nil } 
func ( c APIClient ) ExtractWriter ( objects bool , w io . Writer ) error { writer := pbutil . NewWriter ( w ) return c . Extract ( objects , func ( op * admin . Op ) error { _ , err := writer . Write ( op ) return err } ) } 
func ( c APIClient ) ExtractURL ( url string ) error { extractClient , err := c . AdminAPIClient . Extract ( c . Ctx ( ) , & admin . ExtractRequest { URL : url } ) if err != nil { return grpcutil . ScrubGRPC ( err ) } resp , err := extractClient . Recv ( ) if err == nil { return fmt . Errorf ( " " , resp ) } if err != io . EOF { return err } return nil } 
func ( c APIClient ) ExtractPipeline ( pipelineName string ) ( * pps . CreatePipelineRequest , error ) { op , err := c . AdminAPIClient . ExtractPipeline ( c . Ctx ( ) , & admin . ExtractPipelineRequest { Pipeline : NewPipeline ( pipelineName ) } ) if err != nil { return nil , grpcutil . ScrubGRPC ( err ) } if op . Op1_9 == nil || op . Op1_9 . Pipeline == nil { return nil , fmt . Errorf ( " " ) } return op . Op1_9 . Pipeline , nil } 
func ( c APIClient ) Restore ( ops [ ] * admin . Op ) ( retErr error ) { restoreClient , err := c . AdminAPIClient . Restore ( c . Ctx ( ) ) if err != nil { return grpcutil . ScrubGRPC ( err ) } defer func ( ) { if _ , err := restoreClient . CloseAndRecv ( ) ; err != nil && retErr == nil { retErr = grpcutil . ScrubGRPC ( err ) } } ( ) for _ , op := range ops { if err := restoreClient . Send ( & admin . RestoreRequest { Op : op } ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } } return nil } 
func ( c APIClient ) RestoreReader ( r io . Reader ) ( retErr error ) { restoreClient , err := c . AdminAPIClient . Restore ( c . Ctx ( ) ) if err != nil { return grpcutil . ScrubGRPC ( err ) } defer func ( ) { if _ , err := restoreClient . CloseAndRecv ( ) ; err != nil && retErr == nil { retErr = grpcutil . ScrubGRPC ( err ) } } ( ) reader := pbutil . NewReader ( r ) op := & admin . Op { } for { if err := reader . Read ( op ) ; err != nil { if err == io . EOF { break } return err } if err := restoreClient . Send ( & admin . RestoreRequest { Op : op } ) ; err != nil { return grpcutil . ScrubGRPC ( err ) } } return nil } 
func ( c APIClient ) RestoreFrom ( objects bool , otherC * APIClient ) ( retErr error ) { restoreClient , err := c . AdminAPIClient . Restore ( c . Ctx ( ) ) if err != nil { return grpcutil . ScrubGRPC ( err ) } defer func ( ) { if _ , err := restoreClient . CloseAndRecv ( ) ; err != nil && retErr == nil { retErr = grpcutil . ScrubGRPC ( err ) } } ( ) return otherC . Extract ( objects , func ( op * admin . Op ) error { return restoreClient . Send ( & admin . RestoreRequest { Op : op } ) } ) } 
func ( c APIClient ) RestoreURL ( url string ) ( retErr error ) { restoreClient , err := c . AdminAPIClient . Restore ( c . Ctx ( ) ) if err != nil { return grpcutil . ScrubGRPC ( err ) } defer func ( ) { if _ , err := restoreClient . CloseAndRecv ( ) ; err != nil && retErr == nil { retErr = grpcutil . ScrubGRPC ( err ) } } ( ) return grpcutil . ScrubGRPC ( restoreClient . Send ( & admin . RestoreRequest { URL : url } ) ) } 
func NewEvaluableExpression ( expression string ) ( * EvaluableExpression , error ) { functions := make ( map [ string ] ExpressionFunction ) return NewEvaluableExpressionWithFunctions ( expression , functions ) } 
func NewEvaluableExpressionFromTokens ( tokens [ ] ExpressionToken ) ( * EvaluableExpression , error ) { var ret * EvaluableExpression var err error ret = new ( EvaluableExpression ) ret . QueryDateFormat = isoDateFormat err = checkBalance ( tokens ) if err != nil { return nil , err } err = checkExpressionSyntax ( tokens ) if err != nil { return nil , err } ret . tokens , err = optimizeTokens ( tokens ) if err != nil { return nil , err } ret . evaluationStages , err = planStages ( ret . tokens ) if err != nil { return nil , err } ret . ChecksTypes = true return ret , nil } 
func NewEvaluableExpressionWithFunctions ( expression string , functions map [ string ] ExpressionFunction ) ( * EvaluableExpression , error ) { var ret * EvaluableExpression var err error ret = new ( EvaluableExpression ) ret . QueryDateFormat = isoDateFormat ret . inputExpression = expression ret . tokens , err = parseTokens ( expression , functions ) if err != nil { return nil , err } err = checkBalance ( ret . tokens ) if err != nil { return nil , err } err = checkExpressionSyntax ( ret . tokens ) if err != nil { return nil , err } ret . tokens , err = optimizeTokens ( ret . tokens ) if err != nil { return nil , err } ret . evaluationStages , err = planStages ( ret . tokens ) if err != nil { return nil , err } ret . ChecksTypes = true return ret , nil } 
func ( this EvaluableExpression ) Evaluate ( parameters map [ string ] interface { } ) ( interface { } , error ) { if parameters == nil { return this . Eval ( nil ) } return this . Eval ( MapParameters ( parameters ) ) } 
func ( this EvaluableExpression ) Eval ( parameters Parameters ) ( interface { } , error ) { if this . evaluationStages == nil { return nil , nil } if parameters != nil { parameters = & sanitizedParameters { parameters } } else { parameters = DUMMY_PARAMETERS } return this . evaluateStage ( this . evaluationStages , parameters ) } 
func ( this EvaluableExpression ) Vars ( ) [ ] string { var varlist [ ] string for _ , val := range this . Tokens ( ) { if val . Kind == VARIABLE { varlist = append ( varlist , val . Value . ( string ) ) } } return varlist } 
func ( this OperatorSymbol ) IsModifierType ( candidate [ ] OperatorSymbol ) bool { for _ , symbolType := range candidate { if this == symbolType { return true } } return false } 
func ( this OperatorSymbol ) String ( ) string { switch this { case NOOP : return " " case VALUE : return " " case EQ : return " " case NEQ : return " " case GT : return " " case LT : return " " case GTE : return " " case LTE : return " " case REQ : return " " case NREQ : return " " case AND : return " " case OR : return " " case IN : return " " case BITWISE_AND : return " " case BITWISE_OR : return " " case BITWISE_XOR : return " " case BITWISE_LSHIFT : return " " case BITWISE_RSHIFT : return " " case PLUS : return " " case MINUS : return " " case MULTIPLY : return " " case DIVIDE : return " " case MODULUS : return " " case EXPONENT : return " " case NEGATE : return " " case INVERT : return " " case BITWISE_NOT : return " " case TERNARY_TRUE : return " " case TERNARY_FALSE : return " " case COALESCE : return " " } return " " } 
func ( this EvaluableExpression ) ToSQLQuery ( ) ( string , error ) { var stream * tokenStream var transactions * expressionOutputStream var transaction string var err error stream = newTokenStream ( this . tokens ) transactions = new ( expressionOutputStream ) for stream . hasNext ( ) { transaction , err = this . findNextSQLString ( stream , transactions ) if err != nil { return " " , err } transactions . add ( transaction ) } return transactions . createString ( " " ) , nil } 
func ( kind TokenKind ) String ( ) string { switch kind { case PREFIX : return " " case NUMERIC : return " " case BOOLEAN : return " " case STRING : return " " case PATTERN : return " " case TIME : return " " case VARIABLE : return " " case FUNCTION : return " " case SEPARATOR : return " " case COMPARATOR : return " " case LOGICALOP : return " " case MODIFIER : return " " case CLAUSE : return " " case CLAUSE_CLOSE : return " " case TERNARY : return " " case ACCESSOR : return " " } return " " } 
func readUntilFalse ( stream * lexerStream , includeWhitespace bool , breakWhitespace bool , allowEscaping bool , condition func ( rune ) bool ) ( string , bool ) { var tokenBuffer bytes . Buffer var character rune var conditioned bool conditioned = false for stream . canRead ( ) { character = stream . readCharacter ( ) tokenBuffer . WriteString ( string ( character ) ) continue } if unicode . IsSpace ( character ) { if breakWhitespace && tokenBuffer . Len ( ) > 0 { conditioned = true break } if ! includeWhitespace { continue } } if condition ( character ) { tokenBuffer . WriteString ( string ( character ) ) } else { conditioned = true stream . rewind ( 1 ) break } } return tokenBuffer . String ( ) , conditioned } 
func optimizeTokens ( tokens [ ] ExpressionToken ) ( [ ] ExpressionToken , error ) { var token ExpressionToken var symbol OperatorSymbol var err error var index int for index , token = range tokens { } symbol = comparatorSymbols [ token . Value . ( string ) ] if symbol != REQ && symbol != NREQ { continue } index ++ token = tokens [ index ] if token . Kind == STRING { token . Kind = PATTERN token . Value , err = regexp . Compile ( token . Value . ( string ) ) if err != nil { return tokens , err } tokens [ index ] = token } } return tokens , nil } 
func checkBalance ( tokens [ ] ExpressionToken ) error { var stream * tokenStream var token ExpressionToken var parens int stream = newTokenStream ( tokens ) for stream . hasNext ( ) { token = stream . next ( ) if token . Kind == CLAUSE { parens ++ continue } if token . Kind == CLAUSE_CLOSE { parens -- continue } } if parens != 0 { return errors . New ( " " ) } return nil } 
func tryParseTime ( candidate string ) ( time . Time , bool ) { var ret time . Time var found bool timeFormats := [ ... ] string { time . ANSIC , time . UnixDate , time . RubyDate , time . Kitchen , time . RFC3339 , time . RFC3339Nano , " " , for _ , format := range timeFormats { ret , found = tryParseExactTime ( candidate , format ) if found { return ret , true } } return time . Now ( ) , false } 
func makePrecedentFromPlanner ( planner * precedencePlanner ) precedent { var generated precedent var nextRight precedent generated = func ( stream * tokenStream ) ( * evaluationStage , error ) { return planPrecedenceLevel ( stream , planner . typeErrorFormat , planner . validSymbols , planner . validKinds , nextRight , planner . next , ) } if planner . nextRight != nil { nextRight = planner . nextRight } else { nextRight = generated } return generated } 
func planStages ( tokens [ ] ExpressionToken ) ( * evaluationStage , error ) { stream := newTokenStream ( tokens ) stage , err := planTokens ( stream ) if err != nil { return nil , err } stage = elideLiterals ( stage ) return stage , nil } 
func planPrecedenceLevel ( stream * tokenStream , typeErrorFormat string , validSymbols map [ string ] OperatorSymbol , validKinds [ ] TokenKind , rightPrecedent precedent , leftPrecedent precedent ) ( * evaluationStage , error ) { var token ExpressionToken var symbol OperatorSymbol var leftStage , rightStage * evaluationStage var checks typeChecks var err error var keyFound bool if leftPrecedent != nil { leftStage , err = leftPrecedent ( stream ) if err != nil { return nil , err } } for stream . hasNext ( ) { token = stream . next ( ) if len ( validKinds ) > 0 { keyFound = false for _ , kind := range validKinds { if kind == token . Kind { keyFound = true break } } if ! keyFound { break } } if validSymbols != nil { if ! isString ( token . Value ) { break } symbol , keyFound = validSymbols [ token . Value . ( string ) ] if ! keyFound { break } } if rightPrecedent != nil { rightStage , err = rightPrecedent ( stream ) if err != nil { return nil , err } } checks = findTypeChecks ( symbol ) return & evaluationStage { symbol : symbol , leftStage : leftStage , rightStage : rightStage , operator : stageSymbolMap [ symbol ] , leftTypeCheck : checks . left , rightTypeCheck : checks . right , typeCheck : checks . combined , typeErrorFormat : typeErrorFormat , } , nil } stream . rewind ( ) return leftStage , nil } 
func planFunction ( stream * tokenStream ) ( * evaluationStage , error ) { var token ExpressionToken var rightStage * evaluationStage var err error token = stream . next ( ) if token . Kind != FUNCTION { stream . rewind ( ) return planAccessor ( stream ) } rightStage , err = planAccessor ( stream ) if err != nil { return nil , err } return & evaluationStage { symbol : FUNCTIONAL , rightStage : rightStage , operator : makeFunctionStage ( token . Value . ( ExpressionFunction ) ) , typeErrorFormat : " " , } , nil } 
func planValue ( stream * tokenStream ) ( * evaluationStage , error ) { var token ExpressionToken var symbol OperatorSymbol var ret * evaluationStage var operator evaluationOperator var err error if ! stream . hasNext ( ) { return nil , nil } token = stream . next ( ) switch token . Kind { case CLAUSE : ret , err = planTokens ( stream ) if err != nil { return nil , err } return ret , nil case CLAUSE_CLOSE : return nil , nil case VARIABLE : operator = makeParameterStage ( token . Value . ( string ) ) case NUMERIC : fallthrough case STRING : fallthrough case PATTERN : fallthrough case BOOLEAN : symbol = LITERAL operator = makeLiteralStage ( token . Value ) case TIME : symbol = LITERAL operator = makeLiteralStage ( float64 ( token . Value . ( time . Time ) . Unix ( ) ) ) case PREFIX : stream . rewind ( ) return planPrefix ( stream ) } if operator == nil { errorMsg := fmt . Sprintf ( " " , token . Kind . String ( ) , token . Value ) return nil , errors . New ( errorMsg ) } return & evaluationStage { symbol : symbol , operator : operator , } , nil } 
func findTypeChecks ( symbol OperatorSymbol ) typeChecks { switch symbol { case GT : fallthrough case LT : fallthrough case GTE : fallthrough case LTE : return typeChecks { combined : comparatorTypeCheck , } case REQ : fallthrough case NREQ : return typeChecks { left : isString , right : isRegexOrString , } case AND : fallthrough case OR : return typeChecks { left : isBool , right : isBool , } case IN : return typeChecks { right : isArray , } case BITWISE_LSHIFT : fallthrough case BITWISE_RSHIFT : fallthrough case BITWISE_OR : fallthrough case BITWISE_AND : fallthrough case BITWISE_XOR : return typeChecks { left : isFloat64 , right : isFloat64 , } case PLUS : return typeChecks { combined : additionTypeCheck , } case MINUS : fallthrough case MULTIPLY : fallthrough case DIVIDE : fallthrough case MODULUS : fallthrough case EXPONENT : return typeChecks { left : isFloat64 , right : isFloat64 , } case NEGATE : return typeChecks { right : isFloat64 , } case INVERT : return typeChecks { right : isBool , } case BITWISE_NOT : return typeChecks { right : isFloat64 , } case TERNARY_TRUE : return typeChecks { left : isBool , } case NEQ : return typeChecks { } case TERNARY_FALSE : fallthrough case COALESCE : fallthrough default : return typeChecks { } } } 
func reorderStages ( rootStage * evaluationStage ) { var currentStage , nextStage * evaluationStage var precedence , currentPrecedence operatorPrecedence nextStage = rootStage precedence = findOperatorPrecedenceForSymbol ( rootStage . symbol ) for nextStage != nil { currentStage = nextStage nextStage = currentStage . rightStage } currentPrecedence = findOperatorPrecedenceForSymbol ( currentStage . symbol ) if currentPrecedence == precedence { identicalPrecedences = append ( identicalPrecedences , currentStage ) continue } } identicalPrecedences = [ ] * evaluationStage { currentStage } precedence = currentPrecedence } if len ( identicalPrecedences ) > 1 { mirrorStageSubtree ( identicalPrecedences ) } } 
func mirrorStageSubtree ( stages [ ] * evaluationStage ) { var rootStage , inverseStage , carryStage , frontStage * evaluationStage stagesLength := len ( stages ) frontStage . rightStage = frontStage . leftStage frontStage . leftStage = carryStage } frontStage = stages [ stagesLength - 1 ] carryStage = frontStage . leftStage frontStage . leftStage = rootStage . rightStage rootStage . rightStage = carryStage inverseStage = stages [ stagesLength - i - 1 ] carryStage = frontStage . rightStage frontStage . rightStage = inverseStage . rightStage inverseStage . rightStage = carryStage } inverseStage = stages [ stagesLength - i - 1 ] frontStage . swapWith ( inverseStage ) } } 
func elideLiterals ( root * evaluationStage ) * evaluationStage { if root . leftStage != nil { root . leftStage = elideLiterals ( root . leftStage ) } if root . rightStage != nil { root . rightStage = elideLiterals ( root . rightStage ) } return elideStage ( root ) } 
func elideStage ( root * evaluationStage ) * evaluationStage { var leftValue , rightValue , result interface { } var err error } case IN : return root } if err != nil { return root } rightValue , err = root . rightStage . operator ( nil , nil , nil ) if err != nil { return root } if err != nil { return root } err = typeCheck ( root . rightTypeCheck , rightValue , root . symbol , root . typeErrorFormat ) if err != nil { return root } if root . typeCheck != nil && ! root . typeCheck ( leftValue , rightValue ) { return root } if err != nil { return root } return & evaluationStage { symbol : LITERAL , operator : makeLiteralStage ( result ) , } } 
func additionTypeCheck ( left interface { } , right interface { } ) bool { if isFloat64 ( left ) && isFloat64 ( right ) { return true } if ! isString ( left ) && ! isString ( right ) { return false } return true } 
func comparatorTypeCheck ( left interface { } , right interface { } ) bool { if isFloat64 ( left ) && isFloat64 ( right ) { return true } if isString ( left ) && isString ( right ) { return true } return false } 
func IgnoreFields ( typ interface { } , names ... string ) cmp . Option { sf := newStructFilter ( typ , names ... ) return cmp . FilterPath ( sf . filter , cmp . Ignore ( ) ) } 
func IgnoreTypes ( typs ... interface { } ) cmp . Option { tf := newTypeFilter ( typs ... ) return cmp . FilterPath ( tf . filter , cmp . Ignore ( ) ) } 
func IgnoreInterfaces ( ifaces interface { } ) cmp . Option { tf := newIfaceFilter ( ifaces ) return cmp . FilterPath ( tf . filter , cmp . Ignore ( ) ) } 
func IgnoreUnexported ( typs ... interface { } ) cmp . Option { ux := newUnexportedFilter ( typs ... ) return cmp . FilterPath ( ux . filter , cmp . Ignore ( ) ) } 
func IgnoreSliceElements ( discardFunc interface { } ) cmp . Option { vf := reflect . ValueOf ( discardFunc ) if ! function . IsType ( vf . Type ( ) , function . ValuePredicate ) || vf . IsNil ( ) { panic ( fmt . Sprintf ( " " , discardFunc ) ) } return cmp . FilterPath ( func ( p cmp . Path ) bool { si , ok := p . Index ( - 1 ) . ( cmp . SliceIndex ) if ! ok { return false } if ! si . Type ( ) . AssignableTo ( vf . Type ( ) . In ( 0 ) ) { return false } vx , vy := si . Values ( ) if vx . IsValid ( ) && vf . Call ( [ ] reflect . Value { vx } ) [ 0 ] . Bool ( ) { return true } if vy . IsValid ( ) && vf . Call ( [ ] reflect . Value { vy } ) [ 0 ] . Bool ( ) { return true } return false } , cmp . Ignore ( ) ) } 
func IgnoreMapEntries ( discardFunc interface { } ) cmp . Option { vf := reflect . ValueOf ( discardFunc ) if ! function . IsType ( vf . Type ( ) , function . KeyValuePredicate ) || vf . IsNil ( ) { panic ( fmt . Sprintf ( " " , discardFunc ) ) } return cmp . FilterPath ( func ( p cmp . Path ) bool { mi , ok := p . Index ( - 1 ) . ( cmp . MapIndex ) if ! ok { return false } if ! mi . Key ( ) . Type ( ) . AssignableTo ( vf . Type ( ) . In ( 0 ) ) || ! mi . Type ( ) . AssignableTo ( vf . Type ( ) . In ( 1 ) ) { return false } k := mi . Key ( ) vx , vy := mi . Values ( ) if vx . IsValid ( ) && vf . Call ( [ ] reflect . Value { k , vx } ) [ 0 ] . Bool ( ) { return true } if vy . IsValid ( ) && vf . Call ( [ ] reflect . Value { k , vy } ) [ 0 ] . Bool ( ) { return true } return false } , cmp . Ignore ( ) ) } 
func ( s * textList ) AppendEllipsis ( ds diffStats ) { hasStats := ds != diffStats { } if len ( * s ) == 0 || ! ( * s ) [ len ( * s ) - 1 ] . Value . Equal ( textEllipsis ) { if hasStats { * s = append ( * s , textRecord { Value : textEllipsis , Comment : ds } ) } else { * s = append ( * s , textRecord { Value : textEllipsis } ) } return } if hasStats { ( * s ) [ len ( * s ) - 1 ] . Comment = ( * s ) [ len ( * s ) - 1 ] . Comment . ( diffStats ) . Append ( ds ) } } 
func ( s diffStats ) String ( ) string { var ss [ ] string var sum int labels := [ ... ] string { " " , " " , " " , " " , " " } counts := [ ... ] int { s . NumIgnored , s . NumIdentical , s . NumRemoved , s . NumInserted , s . NumModified } for i , n := range counts { if n > 0 { ss = append ( ss , fmt . Sprintf ( " " , n , labels [ i ] ) ) } sum += n } if sum > 1 { name = name + " " if strings . HasSuffix ( name , " " ) { name = name [ : len ( name ) - 2 ] + " " } } case 1 , 2 : return strings . Join ( ss , " " ) + " " + name default : return strings . Join ( ss [ : n - 1 ] , " " ) + " " + ss [ n - 1 ] + " " + name } } 
func IsType ( t reflect . Type , ft funcType ) bool { if t == nil || t . Kind ( ) != reflect . Func || t . IsVariadic ( ) { return false } ni , no := t . NumIn ( ) , t . NumOut ( ) switch ft { case tbFunc : } case ttbFunc : } case trbFunc : } case tibFunc : } case trFunc : } } return false } 
func NameOf ( v reflect . Value ) string { fnc := runtime . FuncForPC ( v . Pointer ( ) ) if fnc == nil { return " " } fullName := fnc . Name ( ) var name string for len ( fullName ) > 0 { inParen := strings . HasSuffix ( fullName , " " ) fullName = strings . TrimSuffix ( fullName , " " ) s := lastIdentRx . FindString ( fullName ) if s == " " { break } name = s + " " + name fullName = strings . TrimSuffix ( fullName , s ) if i := strings . LastIndexByte ( fullName , '(' ) ; inParen && i >= 0 { fullName = fullName [ : i ] } fullName = strings . TrimSuffix ( fullName , " " ) } return strings . TrimSuffix ( name , " " ) } 
func PointerOf ( v reflect . Value ) Pointer { } 
func SortSlices ( lessFunc interface { } ) cmp . Option { vf := reflect . ValueOf ( lessFunc ) if ! function . IsType ( vf . Type ( ) , function . Less ) || vf . IsNil ( ) { panic ( fmt . Sprintf ( " " , lessFunc ) ) } ss := sliceSorter { vf . Type ( ) . In ( 0 ) , vf } return cmp . FilterValues ( ss . filter , cmp . Transformer ( " " , ss . sort ) ) } 
func SortMaps ( lessFunc interface { } ) cmp . Option { vf := reflect . ValueOf ( lessFunc ) if ! function . IsType ( vf . Type ( ) , function . Less ) || vf . IsNil ( ) { panic ( fmt . Sprintf ( " " , lessFunc ) ) } ms := mapSorter { vf . Type ( ) . In ( 0 ) , vf } return cmp . FilterValues ( ms . filter , cmp . Transformer ( " " , ms . sort ) ) } 
func ( es EditScript ) String ( ) string { b := make ( [ ] byte , len ( es ) ) for i , e := range es { switch e { case Identity : b [ i ] = '.' case UniqueX : b [ i ] = 'X' case UniqueY : b [ i ] = 'Y' case Modified : b [ i ] = 'M' default : panic ( " " ) } } return string ( b ) } 
func ( es EditScript ) stats ( ) ( s struct { NI , NX , NY , NM int } ) { for _ , e := range es { switch e { case Identity : s . NI ++ case UniqueX : s . NX ++ case UniqueY : s . NY ++ case Modified : s . NM ++ default : panic ( " " ) } } return } 
func Difference ( nx , ny int , f EqualFunc ) ( es EditScript ) { revPath := path { - 1 , point { nx , ny } , make ( EditScript , 0 ) } fwdFrontier := fwdPath . point revFrontier := revPath . point for { } for stop1 , stop2 , i := false , false , 0 ; ! ( stop1 && stop2 ) && searchBudget > 0 ; i ++ { p := point { fwdFrontier . X + z , fwdFrontier . Y - z } switch { case p . X >= revPath . X || p . Y < fwdPath . Y : stop1 = true case p . Y >= revPath . Y || p . X < fwdPath . X : stop2 = true case f ( p . X , p . Y ) . Equal ( ) : fwdPath . append ( Identity ) } fwdPath . append ( Identity ) } fwdFrontier = fwdPath . point stop1 , stop2 = true , true default : searchBudget -- } debug . Update ( ) } } else { fwdFrontier . Y ++ } } for stop1 , stop2 , i := false , false , 0 ; ! ( stop1 && stop2 ) && searchBudget > 0 ; i ++ { p := point { revFrontier . X - z , revFrontier . Y + z } switch { case fwdPath . X >= p . X || revPath . Y < p . Y : stop1 = true case fwdPath . Y >= p . Y || revPath . X < p . X : stop2 = true case f ( p . X - 1 , p . Y - 1 ) . Equal ( ) : revPath . append ( Identity ) } revPath . append ( Identity ) } revFrontier = revPath . point stop1 , stop2 = true , true default : searchBudget -- } debug . Update ( ) } } else { revFrontier . Y -- } } for i := len ( revPath . es ) - 1 ; i >= 0 ; i -- { t := revPath . es [ i ] revPath . es = revPath . es [ : i ] fwdPath . append ( t ) } debug . Finish ( ) return fwdPath . es } 
func ( p * path ) connect ( dst point , f EqualFunc ) { if p . dir > 0 { case r . Similar ( ) : p . append ( Modified ) case dst . X - p . X >= dst . Y - p . Y : p . append ( UniqueX ) default : p . append ( UniqueY ) } } for dst . X > p . X { p . append ( UniqueX ) } for dst . Y > p . Y { p . append ( UniqueY ) } } else { case r . Similar ( ) : p . append ( Modified ) case p . Y - dst . Y >= p . X - dst . X : p . append ( UniqueY ) default : p . append ( UniqueX ) } } for p . X > dst . X { p . append ( UniqueX ) } for p . Y > dst . Y { p . append ( UniqueY ) } } } 
func EquateApprox ( fraction , margin float64 ) cmp . Option { if margin < 0 || fraction < 0 || math . IsNaN ( margin ) || math . IsNaN ( fraction ) { panic ( " " ) } a := approximator { fraction , margin } return cmp . Options { cmp . FilterValues ( areRealF64s , cmp . Comparer ( a . compareF64 ) ) , cmp . FilterValues ( areRealF32s , cmp . Comparer ( a . compareF32 ) ) , } } 
func EquateNaNs ( ) cmp . Option { return cmp . Options { cmp . FilterValues ( areNaNsF64s , cmp . Comparer ( equateAlways ) ) , cmp . FilterValues ( areNaNsF32s , cmp . Comparer ( equateAlways ) ) , } } 
func ( pa Path ) Index ( i int ) PathStep { if i < 0 { i = len ( pa ) + i } if i < 0 || i >= len ( pa ) { return pathStep { } } return pa [ i ] } 
func ( pa Path ) String ( ) string { var ss [ ] string for _ , s := range pa { if _ , ok := s . ( StructField ) ; ok { ss = append ( ss , s . String ( ) ) } } return strings . TrimPrefix ( strings . Join ( ss , " " ) , " " ) } 
func ( pa Path ) GoString ( ) string { var ssPre , ssPost [ ] string var numIndirect int for i , s := range pa { var nextStep PathStep if i + 1 < len ( pa ) { nextStep = pa [ i + 1 ] } switch s := s . ( type ) { case Indirect : numIndirect ++ pPre , pPost := " " , " " switch nextStep . ( type ) { case Indirect : continue case StructField : numIndirect -- case nil : pPre , pPost = " " , " " } if numIndirect > 0 { ssPre = append ( ssPre , pPre + strings . Repeat ( " " , numIndirect ) ) ssPost = append ( ssPost , pPost ) } numIndirect = 0 continue case Transform : ssPre = append ( ssPre , s . trans . name + " " ) ssPost = append ( ssPost , " " ) continue } ssPost = append ( ssPost , s . String ( ) ) } for i , j := 0 , len ( ssPre ) - 1 ; i < j ; i , j = i + 1 , j - 1 { ssPre [ i ] , ssPre [ j ] = ssPre [ j ] , ssPre [ i ] } return strings . Join ( ssPre , " " ) + strings . Join ( ssPost , " " ) } 
func ( si SliceIndex ) Key ( ) int { if si . xkey != si . ykey { return - 1 } return si . xkey } 
func ( r * defaultReporter ) String ( ) string { assert ( r . root != nil && r . curr == nil ) if r . root . NumDiff == 0 { return " " } return formatOptions { } . FormatDiff ( r . root ) . String ( ) } 
func ( opts formatOptions ) FormatType ( t reflect . Type , s textNode ) textNode { } default : return s } case elideType : return s } if t . Name ( ) == " " { } typeName = strings . Replace ( typeName , " " , " " , - 1 ) typeName = strings . Replace ( typeName , " " , " " , - 1 ) } hasBraces := strings . HasPrefix ( s . Prefix , " " ) && strings . HasSuffix ( s . Suffix , " " ) if hasParens || hasBraces { return textWrap { typeName , s , " " } } } return textWrap { typeName + " " , s , " " } } 
func ( opts formatOptions ) FormatValue ( v reflect . Value , m visitedPointers ) ( out textNode ) { if ! v . IsValid ( ) { return nil } t := v . Type ( ) case fmt . Stringer : return textLine ( " " + formatString ( v . String ( ) ) ) } } } defer func ( ) { if ! skipType { out = opts . FormatType ( t , out ) } } ( ) var ptr string switch t . Kind ( ) { case reflect . Bool : return textLine ( fmt . Sprint ( v . Bool ( ) ) ) case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 : return textLine ( fmt . Sprint ( v . Int ( ) ) ) case reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 , reflect . Uintptr : } return textLine ( fmt . Sprint ( v . Uint ( ) ) ) case reflect . Float32 , reflect . Float64 : return textLine ( fmt . Sprint ( v . Float ( ) ) ) case reflect . Complex64 , reflect . Complex128 : return textLine ( fmt . Sprint ( v . Complex ( ) ) ) case reflect . String : return textLine ( formatString ( v . String ( ) ) ) case reflect . UnsafePointer , reflect . Chan , reflect . Func : return textLine ( formatPointer ( v ) ) case reflect . Struct : var list textList for i := 0 ; i < v . NumField ( ) ; i ++ { vv := v . Field ( i ) if value . IsZero ( vv ) { continue } s := opts . WithTypeMode ( autoType ) . FormatValue ( vv , m ) list = append ( list , textRecord { Key : t . Field ( i ) . Name , Value : s } ) } return textWrap { " " , list , " " } case reflect . Slice : if v . IsNil ( ) { return textNil } if opts . PrintAddresses { ptr = formatPointer ( v ) } fallthrough case reflect . Array : var list textList for i := 0 ; i < v . Len ( ) ; i ++ { vi := v . Index ( i ) if vi . CanAddr ( ) { if m . Visit ( p ) { var out textNode out = textLine ( formatPointer ( p ) ) out = opts . WithTypeMode ( emitType ) . FormatType ( p . Type ( ) , out ) out = textWrap { " " , out , " " } list = append ( list , textRecord { Value : out } ) continue } } s := opts . WithTypeMode ( elideType ) . FormatValue ( vi , m ) list = append ( list , textRecord { Value : s } ) } return textWrap { ptr + " " , list , " " } case reflect . Map : if v . IsNil ( ) { return textNil } if m . Visit ( v ) { return textLine ( formatPointer ( v ) ) } var list textList for _ , k := range value . SortKeys ( v . MapKeys ( ) ) { sk := formatMapKey ( k ) sv := opts . WithTypeMode ( elideType ) . FormatValue ( v . MapIndex ( k ) , m ) list = append ( list , textRecord { Key : sk , Value : sv } ) } if opts . PrintAddresses { ptr = formatPointer ( v ) } return textWrap { ptr + " " , list , " " } case reflect . Ptr : if v . IsNil ( ) { return textNil } if m . Visit ( v ) || opts . ShallowPointers { return textLine ( formatPointer ( v ) ) } if opts . PrintAddresses { ptr = formatPointer ( v ) } skipType = true return textWrap { " " + ptr , opts . FormatValue ( v . Elem ( ) , m ) , " " } case reflect . Interface : if v . IsNil ( ) { return textNil } return opts . WithTypeMode ( emitType ) . FormatValue ( v . Elem ( ) , m ) default : panic ( fmt . Sprintf ( " " , v . Kind ( ) ) ) } } 
func formatMapKey ( v reflect . Value ) string { var opts formatOptions opts . TypeMode = elideType opts . AvoidStringer = true opts . ShallowPointers = true s := opts . FormatValue ( v , visitedPointers { } ) . String ( ) return strings . TrimSpace ( s ) } 
func formatString ( s string ) string { if len ( qs ) == 1 + len ( s ) + 1 { return qs } } if strings . IndexFunc ( s , rawInvalid ) < 0 { return " " + s + " " } return qs } 
func formatHex ( u uint64 ) string { var f string switch { case u <= 0xff : f = " " case u <= 0xffff : f = " " case u <= 0xffffff : f = " " case u <= 0xffffffff : f = " " case u <= 0xffffffffff : f = " " case u <= 0xffffffffffff : f = " " case u <= 0xffffffffffffff : f = " " case u <= 0xffffffffffffffff : f = " " } return fmt . Sprintf ( f , u ) } 
func formatPointer ( v reflect . Value ) string { p := v . Pointer ( ) if flags . Deterministic { p = 0xdeadf00f } return fmt . Sprintf ( " ) } 
func ( m visitedPointers ) Visit ( v reflect . Value ) bool { p := value . PointerOf ( v ) _ , visited := m [ p ] m [ p ] = struct { } { } return visited } 
func AcyclicTransformer ( name string , xformFunc interface { } ) cmp . Option { xf := xformFilter { cmp . Transformer ( name , xformFunc ) } return cmp . FilterPath ( xf . filter , xf . xform ) } 
func retrieveUnexportedField ( v reflect . Value , f reflect . StructField ) reflect . Value { return reflect . NewAt ( f . Type , unsafe . Pointer ( v . UnsafeAddr ( ) + f . Offset ) ) . Elem ( ) } 
func filterField ( typ interface { } , name string , opt cmp . Option ) cmp . Option { return cmp . FilterPath ( sf . filter , opt ) } 
func ( ft * fieldTree ) insert ( cname [ ] string ) { if ft . sub == nil { ft . sub = make ( map [ string ] fieldTree ) } if len ( cname ) == 0 { ft . ok = true return } sub := ft . sub [ cname [ 0 ] ] sub . insert ( cname [ 1 : ] ) ft . sub [ cname [ 0 ] ] = sub } 
func ( ft fieldTree ) matchPrefix ( p cmp . Path ) bool { for _ , ps := range p { switch ps := ps . ( type ) { case cmp . StructField : ft = ft . sub [ ps . Name ( ) ] if ft . ok { return true } if len ( ft . sub ) == 0 { return false } case cmp . Indirect : default : return false } } return false } 
func canonicalName ( t reflect . Type , sel string ) ( [ ] string , error ) { var name string sel = strings . TrimPrefix ( sel , " " ) if sel == " " { return nil , fmt . Errorf ( " " ) } if i := strings . IndexByte ( sel , '.' ) ; i < 0 { name , sel = sel , " " } else { name , sel = sel [ : i ] , sel [ i : ] } } if t . Kind ( ) != reflect . Struct { return nil , fmt . Errorf ( " " , t ) } } sf , ok := t . FieldByName ( name ) if ! ok { return [ ] string { name } , fmt . Errorf ( " " ) } var ss [ ] string for i := range sf . Index { ss = append ( ss , t . FieldByIndex ( sf . Index [ : i + 1 ] ) . Name ) } if sel == " " { return ss , nil } ssPost , err := canonicalName ( sf . Type , sel ) return append ( ss , ssPost ... ) , err } 
func FilterPath ( f func ( Path ) bool , opt Option ) Option { if f == nil { panic ( " " ) } if opt := normalizeOption ( opt ) ; opt != nil { return & pathFilter { fnc : f , opt : opt } } return nil } 
func FilterValues ( f interface { } , opt Option ) Option { v := reflect . ValueOf ( f ) if ! function . IsType ( v . Type ( ) , function . ValueFilter ) || v . IsNil ( ) { panic ( fmt . Sprintf ( " " , f ) ) } if opt := normalizeOption ( opt ) ; opt != nil { vf := & valuesFilter { fnc : v , opt : opt } if ti := v . Type ( ) . In ( 0 ) ; ti . Kind ( ) != reflect . Interface || ti . NumMethod ( ) > 0 { vf . typ = ti } return vf } return nil } 
func Transformer ( name string , f interface { } ) Option { v := reflect . ValueOf ( f ) if ! function . IsType ( v . Type ( ) , function . Transformer ) || v . IsNil ( ) { panic ( fmt . Sprintf ( " " , f ) ) } if name == " " { name = function . NameOf ( v ) if ! identsRx . MatchString ( name ) { name = " / Lambda-symbol as placeholder name } } else if ! identsRx . MatchString ( name ) { panic ( fmt . Sprintf ( " " , name ) ) } tr := & transformer { name : name , fnc : reflect . ValueOf ( f ) } if ti := v . Type ( ) . In ( 0 ) ; ti . Kind ( ) != reflect . Interface || ti . NumMethod ( ) > 0 { tr . typ = ti } return tr } 
func Comparer ( f interface { } ) Option { v := reflect . ValueOf ( f ) if ! function . IsType ( v . Type ( ) , function . Equal ) || v . IsNil ( ) { panic ( fmt . Sprintf ( " " , f ) ) } cm := & comparer { fnc : v } if ti := v . Type ( ) . In ( 0 ) ; ti . Kind ( ) != reflect . Interface || ti . NumMethod ( ) > 0 { cm . typ = ti } return cm } 
func AllowUnexported ( types ... interface { } ) Option { if ! supportAllowUnexported { panic ( " " ) } m := make ( map [ reflect . Type ] bool ) for _ , typ := range types { t := reflect . TypeOf ( typ ) if t . Kind ( ) != reflect . Struct { panic ( fmt . Sprintf ( " " , typ ) ) } m [ t ] = true } return visibleStructs ( m ) } 
func Reporter ( r interface { } ) Option { return reporter { r } } 
func normalizeOption ( src Option ) Option { switch opts := flattenOptions ( nil , Options { src } ) ; len ( opts ) { case 0 : return nil case 1 : return opts [ 0 ] default : return opts } } 
func flattenOptions ( dst , src Options ) Options { for _ , opt := range src { switch opt := opt . ( type ) { case nil : continue case Options : dst = flattenOptions ( dst , opt ) case coreOption : dst = append ( dst , opt ) default : panic ( fmt . Sprintf ( " " , opt ) ) } } return dst } 
func ( opts formatOptions ) CanFormatDiffSlice ( v * valueNode ) bool { switch { case opts . DiffMode != diffUnknown : return false case v . NumDiff == 0 : return false case v . NumIgnored + v . NumCompared + v . NumTransformed > 0 : case ! v . ValueX . IsValid ( ) || ! v . ValueY . IsValid ( ) : return false } switch t := v . Type ; t . Kind ( ) { case reflect . String : case reflect . Array , reflect . Slice : } } default : return false } return v . ValueX . Len ( ) >= minLength && v . ValueY . Len ( ) >= minLength } 
func ( opts formatOptions ) FormatDiffSlice ( v * valueNode ) textNode { assert ( opts . DiffMode == diffUnknown ) t , vx , vy := v . Type , v . ValueX , v . ValueY var sx , sy string switch { case t . Kind ( ) == reflect . String : sx , sy = vx . String ( ) , vy . String ( ) isText = true case t . Kind ( ) == reflect . Slice && t . Elem ( ) == reflect . TypeOf ( byte ( 0 ) ) : sx , sy = string ( vx . Bytes ( ) ) , string ( vy . Bytes ( ) ) isBinary = true case t . Kind ( ) == reflect . Array : vx2 . Set ( vx ) vy2 . Set ( vy ) vx , vy = vx2 , vy2 } if isText || isBinary { var numLines , lastLineIdx , maxLineLen int isBinary = false for i , r := range sx + sy { if ! ( unicode . IsPrint ( r ) || unicode . IsSpace ( r ) ) || r == utf8 . RuneError { isBinary = true break } if r == '\n' { if maxLineLen < i - lastLineIdx { lastLineIdx = i - lastLineIdx } lastLineIdx = i + 1 numLines ++ } } isText = ! isBinary isLinedText = isText && numLines >= 4 && maxLineLen <= 256 } var delim string switch { ssy := strings . Split ( sy , " \n " ) list = opts . formatDiffSlice ( reflect . ValueOf ( ssx ) , reflect . ValueOf ( ssy ) , 1 , " " , func ( v reflect . Value , d diffMode ) textRecord { s := formatString ( v . Index ( 0 ) . String ( ) ) return textRecord { Diff : d , Value : textLine ( s ) } } , ) delim = " \n " return textRecord { Diff : d , Value : textLine ( s ) } } , ) delim = " " for i := 0 ; i < v . Len ( ) ; i ++ { ss = append ( ss , formatHex ( v . Index ( i ) . Uint ( ) ) ) } s := strings . Join ( ss , " " ) comment := commentString ( fmt . Sprintf ( " " , d , formatASCII ( v . String ( ) ) ) ) return textRecord { Diff : d , Value : textLine ( s ) , Comment : comment } } , ) if t . Elem ( ) . Kind ( ) == reflect . Bool { chunkSize = 16 } else { switch t . Elem ( ) . Bits ( ) { case 8 : chunkSize = 16 case 16 : chunkSize = 12 case 32 : chunkSize = 8 default : chunkSize = 8 } } list = opts . formatDiffSlice ( vx , vy , chunkSize , t . Elem ( ) . Kind ( ) . String ( ) , func ( v reflect . Value , d diffMode ) textRecord { var ss [ ] string for i := 0 ; i < v . Len ( ) ; i ++ { switch t . Elem ( ) . Kind ( ) { case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 : ss = append ( ss , fmt . Sprint ( v . Index ( i ) . Int ( ) ) ) case reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 , reflect . Uintptr : ss = append ( ss , formatHex ( v . Index ( i ) . Uint ( ) ) ) case reflect . Bool , reflect . Float32 , reflect . Float64 , reflect . Complex64 , reflect . Complex128 : ss = append ( ss , fmt . Sprint ( v . Index ( i ) . Interface ( ) ) ) } } s := strings . Join ( ss , " " ) return textRecord { Diff : d , Value : textLine ( s ) } } , ) } if ! isText { } return opts . FormatType ( t , out ) } switch t . Kind ( ) { case reflect . String : out = textWrap { " " , out , fmt . Sprintf ( " " , delim ) } if t != reflect . TypeOf ( string ( " " ) ) { out = opts . FormatType ( t , out ) } case reflect . Slice : out = textWrap { " " , out , fmt . Sprintf ( " " , delim ) } if t != reflect . TypeOf ( [ ] byte ( nil ) ) { out = opts . FormatType ( t , out ) } } return out } 
func formatASCII ( s string ) string { b := bytes . Repeat ( [ ] byte { '.' } , len ( s ) ) for i := 0 ; i < len ( s ) ; i ++ { if ' ' <= s [ i ] && s [ i ] <= '~' { b [ i ] = s [ i ] } } return string ( b ) } 
func coalesceAdjacentEdits ( name string , es diff . EditScript ) ( groups [ ] diffStats ) { var prevCase int lastStats := func ( i int ) * diffStats { if prevCase != i { groups = append ( groups , diffStats { Name : name } ) prevCase = i } return & groups [ len ( groups ) - 1 ] } for _ , e := range es { switch e { case diff . Identity : lastStats ( 1 ) . NumIdentical ++ case diff . UniqueX : lastStats ( 2 ) . NumRemoved ++ case diff . UniqueY : lastStats ( 2 ) . NumInserted ++ case diff . Modified : lastStats ( 2 ) . NumModified ++ } } return groups } 
func coalesceInterveningIdentical ( groups [ ] diffStats , windowSize int ) [ ] diffStats { groups , groupsOrig := groups [ : 0 ] , groups for i , ds := range groupsOrig { if len ( groups ) >= 2 && ds . NumDiff ( ) > 0 { prev := & groups [ len ( groups ) - 2 ] curr := & groups [ len ( groups ) - 1 ] next := & groupsOrig [ i ] hadX , hadY := prev . NumRemoved > 0 , prev . NumInserted > 0 hasX , hasY := next . NumRemoved > 0 , next . NumInserted > 0 if ( ( hadX || hasX ) && ( hadY || hasY ) ) && curr . NumIdentical <= windowSize { * prev = ( * prev ) . Append ( * curr ) . Append ( * next ) groups = groups [ : len ( groups ) - 1 ] continue } } groups = append ( groups , ds ) } return groups } 
func SortKeys ( vs [ ] reflect . Value ) [ ] reflect . Value { if len ( vs ) == 0 { return vs } for _ , v := range vs [ 1 : ] { if isLess ( vs2 [ len ( vs2 ) - 1 ] , v ) { vs2 = append ( vs2 , v ) } } return vs2 } 
func isLess ( x , y reflect . Value ) bool { switch x . Type ( ) . Kind ( ) { case reflect . Bool : return ! x . Bool ( ) && y . Bool ( ) case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 : return x . Int ( ) < y . Int ( ) case reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 , reflect . Uintptr : return x . Uint ( ) < y . Uint ( ) case reflect . Float32 , reflect . Float64 : fx , fy := x . Float ( ) , y . Float ( ) return fx < fy || math . IsNaN ( fx ) && ! math . IsNaN ( fy ) case reflect . Complex64 , reflect . Complex128 : cx , cy := x . Complex ( ) , y . Complex ( ) rx , ix , ry , iy := real ( cx ) , imag ( cx ) , real ( cy ) , imag ( cy ) if rx == ry || ( math . IsNaN ( rx ) && math . IsNaN ( ry ) ) { return ix < iy || math . IsNaN ( ix ) && ! math . IsNaN ( iy ) } return rx < ry || math . IsNaN ( rx ) && ! math . IsNaN ( ry ) case reflect . Ptr , reflect . UnsafePointer , reflect . Chan : return x . Pointer ( ) < y . Pointer ( ) case reflect . String : return x . String ( ) < y . String ( ) case reflect . Array : for i := 0 ; i < x . Len ( ) ; i ++ { if isLess ( x . Index ( i ) , y . Index ( i ) ) { return true } if isLess ( y . Index ( i ) , x . Index ( i ) ) { return false } } return false case reflect . Struct : for i := 0 ; i < x . NumField ( ) ; i ++ { if isLess ( x . Field ( i ) , y . Field ( i ) ) { return true } if isLess ( y . Field ( i ) , x . Field ( i ) ) { return false } } return false case reflect . Interface : vx , vy := x . Elem ( ) , y . Elem ( ) if ! vx . IsValid ( ) || ! vy . IsValid ( ) { return ! vx . IsValid ( ) && vy . IsValid ( ) } tx , ty := vx . Type ( ) , vy . Type ( ) if tx == ty { return isLess ( x . Elem ( ) , y . Elem ( ) ) } if tx . Kind ( ) != ty . Kind ( ) { return vx . Kind ( ) < vy . Kind ( ) } if tx . String ( ) != ty . String ( ) { return tx . String ( ) < ty . String ( ) } if tx . PkgPath ( ) != ty . PkgPath ( ) { return tx . PkgPath ( ) < ty . PkgPath ( ) } default : } } 
func ( opts formatOptions ) FormatDiff ( v * valueNode ) textNode { } outy := opts . FormatValue ( v . ValueY , visitedPointers { } ) if v . NumIgnored > 0 && v . NumSame == 0 { return textEllipsis } else if outx . Len ( ) < outy . Len ( ) { return outx } else { return outy } } var list textList outx := opts . WithTypeMode ( elideType ) . FormatValue ( v . ValueX , visitedPointers { } ) outy := opts . WithTypeMode ( elideType ) . FormatValue ( v . ValueY , visitedPointers { } ) if outx != nil { list = append ( list , textRecord { Diff : '-' , Value : outx } ) } if outy != nil { list = append ( list , textRecord { Diff : '+' , Value : outy } ) } return opts . WithTypeMode ( emitType ) . FormatType ( v . Type , list ) case diffRemoved : return opts . FormatValue ( v . ValueX , visitedPointers { } ) case diffInserted : return opts . FormatValue ( v . ValueY , visitedPointers { } ) default : panic ( " " ) } } out = textWrap { " " + v . TransformerName + " " , out , " " } return opts . FormatType ( v . Type , out ) } else { switch k := v . Type . Kind ( ) ; k { case reflect . Struct , reflect . Array , reflect . Slice , reflect . Map : return opts . FormatType ( v . Type , opts . formatDiffList ( v . Records , k ) ) case reflect . Ptr : return textWrap { " " , opts . FormatDiff ( v . Value ) , " " } case reflect . Interface : return opts . WithTypeMode ( emitType ) . FormatDiff ( v . Value ) default : panic ( fmt . Sprintf ( " " , k ) ) } } } 
func coalesceAdjacentRecords ( name string , recs [ ] reportRecord ) ( groups [ ] diffStats ) { var prevCase int lastStats := func ( i int ) * diffStats { if prevCase != i { groups = append ( groups , diffStats { Name : name } ) prevCase = i } return & groups [ len ( groups ) - 1 ] } for _ , r := range recs { switch rv := r . Value ; { case rv . NumIgnored > 0 && rv . NumSame + rv . NumDiff == 0 : lastStats ( 1 ) . NumIgnored ++ case rv . NumDiff == 0 : lastStats ( 1 ) . NumIdentical ++ case rv . NumDiff > 0 && ! rv . ValueY . IsValid ( ) : lastStats ( 2 ) . NumRemoved ++ case rv . NumDiff > 0 && ! rv . ValueX . IsValid ( ) : lastStats ( 2 ) . NumInserted ++ default : lastStats ( 2 ) . NumModified ++ } } return groups } 
func Equal ( x , y interface { } , opts ... Option ) bool { vx := reflect . ValueOf ( x ) vy := reflect . ValueOf ( y ) if ! vx . IsValid ( ) || ! vy . IsValid ( ) || vx . Type ( ) != vy . Type ( ) { t = reflect . TypeOf ( ( * interface { } ) ( nil ) ) . Elem ( ) if vx . IsValid ( ) { vvx := reflect . New ( t ) . Elem ( ) vvx . Set ( vx ) vx = vvx } if vy . IsValid ( ) { vvy := reflect . New ( t ) . Elem ( ) vvy . Set ( vy ) vy = vvy } } else { t = vx . Type ( ) } s := newState ( opts ) s . compareAny ( & pathStep { t , vx , vy } ) return s . result . Equal ( ) } 
func Diff ( x , y interface { } , opts ... Option ) string { r := new ( defaultReporter ) eq := Equal ( x , y , Options ( opts ) , Reporter ( r ) ) d := r . String ( ) if ( d == " " ) != eq { panic ( " " ) } return d } 
func ( s * state ) statelessCompare ( step PathStep ) diff . Result { s . result = diff . Result { } s . reporters = nil s . compareAny ( step ) res := s . result s . result , s . reporters = oldResult , oldReporters return res } 
func sanitizeValue ( v reflect . Value , t reflect . Type ) reflect . Value { } } return v } 
func ( rc * recChecker ) Check ( p Path ) { const minLen = 1 << 16 if rc . next == 0 { rc . next = minLen } if len ( p ) < rc . next { return } rc . next <<= 1 m := map [ Option ] int { } for _ , ps := range p { if t , ok := ps . ( Transform ) ; ok { t := t . Option ( ) if m [ t ] == 1 { ss = append ( ss , fmt . Sprintf ( " " , t , tf . In ( 0 ) , tf . Out ( 0 ) ) ) } m [ t ] ++ } } if len ( ss ) > 0 { const warning = " " const help = " " set := strings . Join ( ss , " \n \t " ) panic ( fmt . Sprintf ( " \n \t \n " , warning , set , help ) ) } } 
func ( dc * dynChecker ) Next ( ) bool { ok := dc . curr == dc . next if ok { dc . curr = 0 dc . next ++ } dc . curr ++ return ok } 
func makeAddressable ( v reflect . Value ) reflect . Value { if v . CanAddr ( ) { return v } vc := reflect . New ( v . Type ( ) ) . Elem ( ) vc . Set ( v ) return vc } 
func String ( key , val string ) Field { return Field { key : key , fieldType : stringType , stringVal : val , } } 
func Bool ( key string , val bool ) Field { var numericVal int64 if val { numericVal = 1 } return Field { key : key , fieldType : boolType , numericVal : numericVal , } } 
func Int ( key string , val int ) Field { return Field { key : key , fieldType : intType , numericVal : int64 ( val ) , } } 
func Int32 ( key string , val int32 ) Field { return Field { key : key , fieldType : int32Type , numericVal : int64 ( val ) , } } 
func Int64 ( key string , val int64 ) Field { return Field { key : key , fieldType : int64Type , numericVal : val , } } 
func Uint32 ( key string , val uint32 ) Field { return Field { key : key , fieldType : uint32Type , numericVal : int64 ( val ) , } } 
func Uint64 ( key string , val uint64 ) Field { return Field { key : key , fieldType : uint64Type , numericVal : int64 ( val ) , } } 
func Float32 ( key string , val float32 ) Field { return Field { key : key , fieldType : float32Type , numericVal : int64 ( math . Float32bits ( val ) ) , } } 
func Float64 ( key string , val float64 ) Field { return Field { key : key , fieldType : float64Type , numericVal : int64 ( math . Float64bits ( val ) ) , } } 
func Error ( err error ) Field { return Field { key : " " , fieldType : errorType , interfaceVal : err , } } 
func Object ( key string , obj interface { } ) Field { return Field { key : key , fieldType : objectType , interfaceVal : obj , } } 
func ( lf Field ) Marshal ( visitor Encoder ) { switch lf . fieldType { case stringType : visitor . EmitString ( lf . key , lf . stringVal ) case boolType : visitor . EmitBool ( lf . key , lf . numericVal != 0 ) case intType : visitor . EmitInt ( lf . key , int ( lf . numericVal ) ) case int32Type : visitor . EmitInt32 ( lf . key , int32 ( lf . numericVal ) ) case int64Type : visitor . EmitInt64 ( lf . key , int64 ( lf . numericVal ) ) case uint32Type : visitor . EmitUint32 ( lf . key , uint32 ( lf . numericVal ) ) case uint64Type : visitor . EmitUint64 ( lf . key , uint64 ( lf . numericVal ) ) case float32Type : visitor . EmitFloat32 ( lf . key , math . Float32frombits ( uint32 ( lf . numericVal ) ) ) case float64Type : visitor . EmitFloat64 ( lf . key , math . Float64frombits ( uint64 ( lf . numericVal ) ) ) case errorType : if err , ok := lf . interfaceVal . ( error ) ; ok { visitor . EmitString ( lf . key , err . Error ( ) ) } else { visitor . EmitString ( lf . key , " " ) } case objectType : visitor . EmitObject ( lf . key , lf . interfaceVal ) case lazyLoggerType : visitor . EmitLazyLogger ( lf . interfaceVal . ( LazyLogger ) ) case noopType : } 
func ( lf Field ) Value ( ) interface { } { switch lf . fieldType { case stringType : return lf . stringVal case boolType : return lf . numericVal != 0 case intType : return int ( lf . numericVal ) case int32Type : return int32 ( lf . numericVal ) case int64Type : return int64 ( lf . numericVal ) case uint32Type : return uint32 ( lf . numericVal ) case uint64Type : return uint64 ( lf . numericVal ) case float32Type : return math . Float32frombits ( uint32 ( lf . numericVal ) ) case float64Type : return math . Float64frombits ( uint64 ( lf . numericVal ) ) case errorType , objectType , lazyLoggerType : return lf . interfaceVal case noopType : return nil default : return nil } } 
func ( lf Field ) String ( ) string { return fmt . Sprint ( lf . key , " " , lf . Value ( ) ) } 
func ( r SpanReference ) Apply ( o * StartSpanOptions ) { if r . ReferencedContext != nil { o . References = append ( o . References , r ) } } 
func ( t StartTime ) Apply ( o * StartSpanOptions ) { o . StartTime = time . Time ( t ) } 
func ( t Tags ) Apply ( o * StartSpanOptions ) { if o . Tags == nil { o . Tags = make ( map [ string ] interface { } ) } for k , v := range t { o . Tags [ k ] = v } } 
func ( t Tag ) Apply ( o * StartSpanOptions ) { if o . Tags == nil { o . Tags = make ( map [ string ] interface { } ) } o . Tags [ t . Key ] = t . Value } 
func ( t Tag ) Set ( s Span ) { s . SetTag ( t . Key , t . Value ) } 
func ( t * TextMapPropagator ) Inject ( spanContext MockSpanContext , carrier interface { } ) error { writer , ok := carrier . ( opentracing . TextMapWriter ) if ! ok { return opentracing . ErrInvalidCarrier } writer . Set ( mockTextMapIdsPrefix + " " , strconv . Itoa ( spanContext . SpanID ) ) writer . Set ( mockTextMapIdsPrefix + " " , fmt . Sprint ( spanContext . Sampled ) ) if t . HTTPHeaders { safeVal = url . QueryEscape ( baggageVal ) } writer . Set ( mockTextMapBaggagePrefix + baggageKey , safeVal ) } return nil } 
func ( t * TextMapPropagator ) Extract ( carrier interface { } ) ( MockSpanContext , error ) { reader , ok := carrier . ( opentracing . TextMapReader ) if ! ok { return emptyContext , opentracing . ErrInvalidCarrier } rval := MockSpanContext { 0 , 0 , true , nil } err := reader . ForeachKey ( func ( key , val string ) error { lowerKey := strings . ToLower ( key ) switch { case lowerKey == mockTextMapIdsPrefix + " " : if err != nil { return err } rval . TraceID = i case lowerKey == mockTextMapIdsPrefix + " " : if err != nil { return err } rval . SpanID = i case lowerKey == mockTextMapIdsPrefix + " " : b , err := strconv . ParseBool ( val ) if err != nil { return err } rval . Sampled = b case strings . HasPrefix ( lowerKey , mockTextMapBaggagePrefix ) : } safeVal := val if t . HTTPHeaders { } } rval . Baggage [ lowerKey [ len ( mockTextMapBaggagePrefix ) : ] ] = safeVal } return nil } ) if rval . TraceID == 0 || rval . SpanID == 0 { return emptyContext , opentracing . ErrSpanContextNotFound } if err != nil { return emptyContext , err } return rval , nil } 
func ( ld * LogData ) ToLogRecord ( ) LogRecord { var literalTimestamp time . Time if ld . Timestamp . IsZero ( ) { literalTimestamp = time . Now ( ) } else { literalTimestamp = ld . Timestamp } rval := LogRecord { Timestamp : literalTimestamp , } if ld . Payload == nil { rval . Fields = [ ] log . Field { log . String ( " " , ld . Event ) , } } else { rval . Fields = [ ] log . Field { log . String ( " " , ld . Event ) , log . Object ( " " , ld . Payload ) , } } return rval } 
func New ( ) * MockTracer { t := & MockTracer { finishedSpans : [ ] * MockSpan { } , injectors : make ( map [ interface { } ] Injector ) , extractors : make ( map [ interface { } ] Extractor ) , } t . RegisterInjector ( opentracing . TextMap , textPropagator ) t . RegisterExtractor ( opentracing . TextMap , textPropagator ) httpPropagator := & TextMapPropagator { HTTPHeaders : true } t . RegisterInjector ( opentracing . HTTPHeaders , httpPropagator ) t . RegisterExtractor ( opentracing . HTTPHeaders , httpPropagator ) return t } 
func ( t * MockTracer ) FinishedSpans ( ) [ ] * MockSpan { t . RLock ( ) defer t . RUnlock ( ) spans := make ( [ ] * MockSpan , len ( t . finishedSpans ) ) copy ( spans , t . finishedSpans ) return spans } 
func ( t * MockTracer ) Reset ( ) { t . Lock ( ) defer t . Unlock ( ) t . finishedSpans = [ ] * MockSpan { } } 
func ( t * MockTracer ) StartSpan ( operationName string , opts ... opentracing . StartSpanOption ) opentracing . Span { sso := opentracing . StartSpanOptions { } for _ , o := range opts { o . Apply ( & sso ) } return newMockSpan ( t , operationName , sso ) } 
func ( t * MockTracer ) RegisterInjector ( format interface { } , injector Injector ) { t . injectors [ format ] = injector } 
func ( t * MockTracer ) RegisterExtractor ( format interface { } , extractor Extractor ) { t . extractors [ format ] = extractor } 
func ( t * MockTracer ) Inject ( sm opentracing . SpanContext , format interface { } , carrier interface { } ) error { spanContext , ok := sm . ( MockSpanContext ) if ! ok { return opentracing . ErrInvalidCarrier } injector , ok := t . injectors [ format ] if ! ok { return opentracing . ErrUnsupportedFormat } return injector . Inject ( spanContext , carrier ) } 
func ( t * MockTracer ) Extract ( format interface { } , carrier interface { } ) ( opentracing . SpanContext , error ) { extractor , ok := t . extractors [ format ] if ! ok { return nil , opentracing . ErrUnsupportedFormat } return extractor . Extract ( carrier ) } 
func ContextWithSpan ( ctx context . Context , span Span ) context . Context { return context . WithValue ( ctx , activeSpanKey , span ) } 
func SpanFromContext ( ctx context . Context ) Span { val := ctx . Value ( activeSpanKey ) if sp , ok := val . ( Span ) ; ok { return sp } return nil } 
func StartSpanFromContext ( ctx context . Context , operationName string , opts ... StartSpanOption ) ( Span , context . Context ) { return StartSpanFromContextWithTracer ( ctx , GlobalTracer ( ) , operationName , opts ... ) } 
func ( tag spanKindTagName ) Set ( span opentracing . Span , value SpanKindEnum ) { span . SetTag ( string ( tag ) , value ) } 
func ( tag stringTagName ) Set ( span opentracing . Span , value string ) { span . SetTag ( string ( tag ) , value ) } 
func ( tag uint32TagName ) Set ( span opentracing . Span , value uint32 ) { span . SetTag ( string ( tag ) , value ) } 
func ( tag uint16TagName ) Set ( span opentracing . Span , value uint16 ) { span . SetTag ( string ( tag ) , value ) } 
func ( tag boolTagName ) Set ( span opentracing . Span , value bool ) { span . SetTag ( string ( tag ) , value ) } 
func ( tag ipv4Tag ) SetString ( span opentracing . Span , value string ) { span . SetTag ( string ( tag ) , value ) } 
func StartSpan ( operationName string , opts ... StartSpanOption ) Span { return globalTracer . tracer . StartSpan ( operationName , opts ... ) } 
func InterleavedKVToFields ( keyValues ... interface { } ) ( [ ] Field , error ) { if len ( keyValues ) % 2 != 0 { return nil , fmt . Errorf ( " " , len ( keyValues ) ) } fields := make ( [ ] Field , len ( keyValues ) / 2 ) for i := 0 ; i * 2 < len ( keyValues ) ; i ++ { key , ok := keyValues [ i * 2 ] . ( string ) if ! ok { return nil , fmt . Errorf ( " " , i , keyValues [ i * 2 ] ) } switch typedVal := keyValues [ i * 2 + 1 ] . ( type ) { case bool : fields [ i ] = Bool ( key , typedVal ) case string : fields [ i ] = String ( key , typedVal ) case int : fields [ i ] = Int ( key , typedVal ) case int8 : fields [ i ] = Int32 ( key , int32 ( typedVal ) ) case int16 : fields [ i ] = Int32 ( key , int32 ( typedVal ) ) case int32 : fields [ i ] = Int32 ( key , typedVal ) case int64 : fields [ i ] = Int64 ( key , typedVal ) case uint : fields [ i ] = Uint64 ( key , uint64 ( typedVal ) ) case uint64 : fields [ i ] = Uint64 ( key , typedVal ) case uint8 : fields [ i ] = Uint32 ( key , uint32 ( typedVal ) ) case uint16 : fields [ i ] = Uint32 ( key , uint32 ( typedVal ) ) case uint32 : fields [ i ] = Uint32 ( key , typedVal ) case float32 : fields [ i ] = Float32 ( key , typedVal ) case float64 : fields [ i ] = Float64 ( key , typedVal ) default : } } return fields , nil } 
func ( c TextMapCarrier ) ForeachKey ( handler func ( key , val string ) error ) error { for k , v := range c { if err := handler ( k , v ) ; err != nil { return err } } return nil } 
func ( m * MockKeyValue ) EmitString ( key , value string ) { m . Key = key m . ValueKind = reflect . TypeOf ( value ) . Kind ( ) m . ValueString = fmt . Sprint ( value ) } 
func ( m * MockKeyValue ) EmitLazyLogger ( value log . LazyLogger ) { var meta MockKeyValue value ( & meta ) m . Key = meta . Key m . ValueKind = meta . ValueKind m . ValueString = meta . ValueString } 
func RunAPIChecks ( t * testing . T , newTracer func ( ) ( tracer opentracing . Tracer , closer func ( ) ) , opts ... APICheckOption , ) { s := & APICheckSuite { newTracer : newTracer } for _ , opt := range opts { opt ( s ) } suite . Run ( t , s ) } 
func CheckBaggageValues ( val bool ) APICheckOption { return func ( s * APICheckSuite ) { s . opts . CheckBaggageValues = val } } 
func CheckExtract ( val bool ) APICheckOption { return func ( s * APICheckSuite ) { s . opts . CheckExtract = val } } 
func CheckInject ( val bool ) APICheckOption { return func ( s * APICheckSuite ) { s . opts . CheckInject = val } } 
func CheckEverything ( ) APICheckOption { return func ( s * APICheckSuite ) { s . opts . CheckBaggageValues = true s . opts . CheckExtract = true s . opts . CheckInject = true } } 
func UseProbe ( probe APICheckProbe ) APICheckOption { return func ( s * APICheckSuite ) { s . opts . Probe = probe } } 
func ( c MockSpanContext ) WithBaggageItem ( key , value string ) MockSpanContext { var newBaggage map [ string ] string if c . Baggage == nil { newBaggage = map [ string ] string { key : value } } else { newBaggage = make ( map [ string ] string , len ( c . Baggage ) + 1 ) for k , v := range c . Baggage { newBaggage [ k ] = v } newBaggage [ key ] = value } } 
func ( s * MockSpan ) Tags ( ) map [ string ] interface { } { s . RLock ( ) defer s . RUnlock ( ) tags := make ( map [ string ] interface { } ) for k , v := range s . tags { tags [ k ] = v } return tags } 
func ( s * MockSpan ) Tag ( k string ) interface { } { s . RLock ( ) defer s . RUnlock ( ) return s . tags [ k ] } 
func ( s * MockSpan ) Logs ( ) [ ] MockLogRecord { s . RLock ( ) defer s . RUnlock ( ) logs := make ( [ ] MockLogRecord , len ( s . logs ) ) copy ( logs , s . logs ) return logs } 
func ( s * MockSpan ) Context ( ) opentracing . SpanContext { s . Lock ( ) defer s . Unlock ( ) return s . SpanContext } 
func ( s * MockSpan ) SetTag ( key string , value interface { } ) opentracing . Span { s . Lock ( ) defer s . Unlock ( ) if key == string ( ext . SamplingPriority ) { if v , ok := value . ( uint16 ) ; ok { s . SpanContext . Sampled = v > 0 return s } if v , ok := value . ( int ) ; ok { s . SpanContext . Sampled = v > 0 return s } } s . tags [ key ] = value return s } 
func ( s * MockSpan ) SetBaggageItem ( key , val string ) opentracing . Span { s . Lock ( ) defer s . Unlock ( ) s . SpanContext = s . SpanContext . WithBaggageItem ( key , val ) return s } 
func ( s * MockSpan ) BaggageItem ( key string ) string { s . RLock ( ) defer s . RUnlock ( ) return s . SpanContext . Baggage [ key ] } 
func ( s * MockSpan ) Finish ( ) { s . Lock ( ) s . FinishTime = time . Now ( ) s . Unlock ( ) s . tracer . recordSpan ( s ) } 
func ( s * MockSpan ) FinishWithOptions ( opts opentracing . FinishOptions ) { s . Lock ( ) s . FinishTime = opts . FinishTime s . Unlock ( ) } } else { s . logFieldsWithTimestamp ( ld . Timestamp , log . String ( " " , ld . Event ) ) } } s . tracer . recordSpan ( s ) } 
func ( s * MockSpan ) String ( ) string { return fmt . Sprintf ( " " , s . SpanContext . TraceID , s . SpanContext . SpanID , s . ParentID , s . SpanContext . Sampled , s . OperationName ) } 
func ( s * MockSpan ) LogFields ( fields ... log . Field ) { s . logFieldsWithTimestamp ( time . Now ( ) , fields ... ) } 
func ( s * MockSpan ) logFieldsWithTimestamp ( ts time . Time , fields ... log . Field ) { lr := MockLogRecord { Timestamp : ts , Fields : make ( [ ] MockKeyValue , len ( fields ) ) , } for i , f := range fields { outField := & ( lr . Fields [ i ] ) f . Marshal ( outField ) } s . Lock ( ) defer s . Unlock ( ) s . logs = append ( s . logs , lr ) } 
func ( s * MockSpan ) LogKV ( keyValues ... interface { } ) { if len ( keyValues ) % 2 != 0 { s . LogFields ( log . Error ( fmt . Errorf ( " " , len ( keyValues ) ) ) ) return } fields , err := log . InterleavedKVToFields ( keyValues ... ) if err != nil { s . LogFields ( log . Error ( err ) , log . String ( " " , " " ) ) return } s . LogFields ( fields ... ) } 
func ( s * MockSpan ) LogEvent ( event string ) { s . LogFields ( log . String ( " " , event ) ) } 
func ( s * MockSpan ) LogEventWithPayload ( event string , payload interface { } ) { s . LogFields ( log . String ( " " , event ) , log . Object ( " " , payload ) ) } 
func ( s * MockSpan ) SetOperationName ( operationName string ) opentracing . Span { s . Lock ( ) defer s . Unlock ( ) s . OperationName = operationName return s } 
func newOpenShiftClientConfigLoadingRules ( ) * clientConfigLoadingRules { chain := [ ] string { } envVarFile := os . Getenv ( " " ) if len ( envVarFile ) != 0 { chain = append ( chain , filepath . SplitList ( envVarFile ) ... ) } else { chain = append ( chain , recommendedHomeFile ) } return & clientConfigLoadingRules { Precedence : chain , } 
func ( config * deferredLoadingClientConfig ) ClientConfig ( ) ( * restConfig , error ) { mergedClientConfig , err := config . createClientConfig ( ) if err != nil { return nil , err } mergedConfig , err := mergedClientConfig . ClientConfig ( ) if err != nil { return nil , err } } 
func ( config * directClientConfig ) ClientConfig ( ) ( * restConfig , error ) { if err := config . ConfirmUsable ( ) ; err != nil { return nil , err } configAuthInfo := config . getAuthInfo ( ) configClusterInfo := config . getCluster ( ) clientConfig := & restConfig { } clientConfig . Host = configClusterInfo . Server if u , err := url . ParseRequestURI ( clientConfig . Host ) ; err == nil && u . Opaque == " " && len ( u . Path ) > 1 { u . RawQuery = " " u . Fragment = " " clientConfig . Host = u . String ( ) } if err != nil { return nil , err } mergo . Merge ( clientConfig , userAuthPartialConfig ) serverAuthPartialConfig , err := getServerIdentificationPartialConfig ( configAuthInfo , configClusterInfo ) if err != nil { return nil , err } mergo . Merge ( clientConfig , serverAuthPartialConfig ) } return clientConfig , nil } 
func getServerIdentificationPartialConfig ( configAuthInfo clientcmdAuthInfo , configClusterInfo clientcmdCluster ) ( * restConfig , error ) { mergedConfig := & restConfig { } configClientConfig . CAFile = configClusterInfo . CertificateAuthority configClientConfig . CAData = configClusterInfo . CertificateAuthorityData configClientConfig . Insecure = configClusterInfo . InsecureSkipTLSVerify mergo . Merge ( mergedConfig , configClientConfig ) return mergedConfig , nil } 
func getUserIdentificationPartialConfig ( configAuthInfo clientcmdAuthInfo ) ( * restConfig , error ) { mergedConfig := & restConfig { } } if len ( configAuthInfo . ClientCertificate ) > 0 || len ( configAuthInfo . ClientCertificateData ) > 0 { mergedConfig . CertFile = configAuthInfo . ClientCertificate mergedConfig . CertData = configAuthInfo . ClientCertificateData mergedConfig . KeyFile = configAuthInfo . ClientKey mergedConfig . KeyData = configAuthInfo . ClientKeyData } if len ( configAuthInfo . Username ) > 0 || len ( configAuthInfo . Password ) > 0 { mergedConfig . Username = configAuthInfo . Username mergedConfig . Password = configAuthInfo . Password } } 
func canIdentifyUser ( config restConfig ) bool { return len ( config . Username ) > 0 || ( len ( config . CertFile ) > 0 || len ( config . CertData ) > 0 ) || len ( config . BearerToken ) > 0 } 
func ( config * directClientConfig ) ConfirmUsable ( ) error { var validationErrors [ ] error validationErrors = append ( validationErrors , validateAuthInfo ( config . getAuthInfoName ( ) , config . getAuthInfo ( ) ) ... ) validationErrors = append ( validationErrors , validateClusterInfo ( config . getClusterName ( ) , config . getCluster ( ) ) ... ) } return newErrConfigurationInvalid ( validationErrors ) } 
func ( config * directClientConfig ) getContext ( ) clientcmdContext { contexts := config . config . Contexts contextName := config . getContextName ( ) var mergedContext clientcmdContext if configContext , exists := contexts [ contextName ] ; exists { mergo . Merge ( & mergedContext , configContext ) } } 
func validateClusterInfo ( clusterName string , clusterInfo clientcmdCluster ) [ ] error { var validationErrors [ ] error if reflect . DeepEqual ( clientcmdCluster { } , clusterInfo ) { return [ ] error { errEmptyCluster } } if len ( clusterInfo . Server ) == 0 { if len ( clusterName ) == 0 { validationErrors = append ( validationErrors , errors . Errorf ( " " ) ) } else { validationErrors = append ( validationErrors , errors . Errorf ( " " , clusterName ) ) } } } if len ( clusterInfo . CertificateAuthority ) != 0 { clientCertCA , err := os . Open ( clusterInfo . CertificateAuthority ) defer clientCertCA . Close ( ) if err != nil { validationErrors = append ( validationErrors , errors . Errorf ( " " , clusterInfo . CertificateAuthority , clusterName , err ) ) } } return validationErrors } 
func validateAuthInfo ( authInfoName string , authInfo clientcmdAuthInfo ) [ ] error { var validationErrors [ ] error usingAuthPath := false methods := make ( [ ] string , 0 , 3 ) if len ( authInfo . Token ) != 0 { methods = append ( methods , " " ) } if len ( authInfo . Username ) != 0 || len ( authInfo . Password ) != 0 { methods = append ( methods , " " ) } if len ( authInfo . ClientCertificate ) != 0 || len ( authInfo . ClientCertificateData ) != 0 { } } } if len ( authInfo . ClientCertificate ) != 0 { clientCertFile , err := os . Open ( authInfo . ClientCertificate ) defer clientCertFile . Close ( ) if err != nil { validationErrors = append ( validationErrors , errors . Errorf ( " " , authInfo . ClientCertificate , authInfoName , err ) ) } } if len ( authInfo . ClientKey ) != 0 { clientKeyFile , err := os . Open ( authInfo . ClientKey ) defer clientKeyFile . Close ( ) if err != nil { validationErrors = append ( validationErrors , errors . Errorf ( " " , authInfo . ClientKey , authInfoName , err ) ) } } } } return validationErrors } 
func ( config * directClientConfig ) getAuthInfo ( ) clientcmdAuthInfo { authInfos := config . config . AuthInfos authInfoName := config . getAuthInfoName ( ) var mergedAuthInfo clientcmdAuthInfo if configAuthInfo , exists := authInfos [ authInfoName ] ; exists { mergo . Merge ( & mergedAuthInfo , configAuthInfo ) } } 
func ( config * directClientConfig ) getCluster ( ) clientcmdCluster { clusterInfos := config . config . Clusters clusterInfoName := config . getClusterName ( ) var mergedClusterInfo clientcmdCluster mergo . Merge ( & mergedClusterInfo , defaultCluster ) mergo . Merge ( & mergedClusterInfo , envVarCluster ) if configClusterInfo , exists := clusterInfos [ clusterInfoName ] ; exists { mergo . Merge ( & mergedClusterInfo , configClusterInfo ) } } 
func newAggregate ( errlist [ ] error ) error { if len ( errlist ) == 0 { return nil } for _ , e := range errlist { if e != nil { errs = append ( errs , e ) } } if len ( errs ) == 0 { return nil } return aggregateErr ( errs ) } 
func ( rules * clientConfigLoadingRules ) Load ( ) ( * clientcmdConfig , error ) { errlist := [ ] error { } kubeConfigFiles := [ ] string { } kubeconfigs := [ ] * clientcmdConfig { } } config , err := loadFromFile ( filename ) if os . IsNotExist ( err ) { } if err != nil { errlist = append ( errlist , errors . Wrapf ( err , " \" \" " , filename ) ) continue } kubeconfigs = append ( kubeconfigs , config ) } for _ , kubeconfig := range kubeconfigs { mergo . Merge ( mapConfig , kubeconfig ) } for i := len ( kubeconfigs ) - 1 ; i >= 0 ; i -- { kubeconfig := kubeconfigs [ i ] mergo . Merge ( nonMapConfig , kubeconfig ) } mergo . Merge ( config , mapConfig ) mergo . Merge ( config , nonMapConfig ) } return config , newAggregate ( errlist ) } 
func loadFromFile ( filename string ) ( * clientcmdConfig , error ) { kubeconfigBytes , err := ioutil . ReadFile ( filename ) if err != nil { return nil , err } config , err := load ( kubeconfigBytes ) if err != nil { return nil , err } config . AuthInfos [ key ] = obj } for key , obj := range config . Clusters { obj . LocationOfOrigin = filename config . Clusters [ key ] = obj } for key , obj := range config . Contexts { obj . LocationOfOrigin = filename config . Contexts [ key ] = obj } if config . AuthInfos == nil { config . AuthInfos = map [ string ] * clientcmdAuthInfo { } } if config . Clusters == nil { config . Clusters = map [ string ] * clientcmdCluster { } } if config . Contexts == nil { config . Contexts = map [ string ] * clientcmdContext { } } return config , nil } 
func load ( data [ ] byte ) ( * clientcmdConfig , error ) { config := clientcmdNewConfig ( ) } if err != nil { return nil , err } if err := json . Unmarshal ( data , config ) ; err != nil { return nil , err } return config , nil } 
func resolveLocalPaths ( config * clientcmdConfig ) error { for _ , cluster := range config . Clusters { if len ( cluster . LocationOfOrigin ) == 0 { continue } base , err := filepath . Abs ( filepath . Dir ( cluster . LocationOfOrigin ) ) if err != nil { return errors . Wrapf ( err , " " , cluster . LocationOfOrigin ) } if err := resolvePaths ( getClusterFileReferences ( cluster ) , base ) ; err != nil { return err } } for _ , authInfo := range config . AuthInfos { if len ( authInfo . LocationOfOrigin ) == 0 { continue } base , err := filepath . Abs ( filepath . Dir ( authInfo . LocationOfOrigin ) ) if err != nil { return errors . Wrapf ( err , " " , authInfo . LocationOfOrigin ) } if err := resolvePaths ( getAuthInfoFileReferences ( authInfo ) , base ) ; err != nil { return err } } return nil } 
func resolvePaths ( refs [ ] * string , base string ) error { for _ , ref := range refs { } } } return nil } 
func restClientFor ( config * restConfig ) ( * url . URL , * http . Client , error ) { if err != nil { return nil , nil , err } transport , err := transportFor ( config ) if err != nil { return nil , nil , err } var httpClient * http . Client if transport != http . DefaultTransport { httpClient = & http . Client { Transport : transport } } } 
func defaultServerURL ( host string , defaultTLS bool ) ( * url . URL , error ) { if host == " " { return nil , errors . Errorf ( " " ) } base := host hostURL , err := url . Parse ( base ) if err != nil { return nil , err } if hostURL . Scheme == " " { scheme := " " if defaultTLS { scheme = " " } hostURL , err = url . Parse ( scheme + base ) if err != nil { return nil , err } if hostURL . Path != " " && hostURL . Path != " " { return nil , errors . Errorf ( " " , base ) } } } 
func defaultServerURLFor ( config * restConfig ) ( * url . URL , error ) { hasCert := len ( config . CertFile ) != 0 || len ( config . CertData ) != 0 defaultTLS := hasCA || hasCert || config . Insecure host := config . Host if host == " " { host = " " } } 
func isConfigTransportTLS ( config restConfig ) bool { baseURL , err := defaultServerURLFor ( & config ) if err != nil { return false } return baseURL . Scheme == " " } 
func transportNew ( config * restConfig ) ( http . RoundTripper , error ) { err error ) rt , err = tlsCacheGet ( config ) if err != nil { return nil , err } } return rt , nil } 
func newProxierWithNoProxyCIDR ( delegate func ( req * http . Request ) ( * url . URL , error ) ) func ( req * http . Request ) ( * url . URL , error ) { noProxyRules := strings . Split ( noProxyEnv , " " ) cidrs := [ ] * net . IPNet { } for _ , noProxyRule := range noProxyRules { _ , cidr , _ := net . ParseCIDR ( noProxyRule ) if cidr != nil { cidrs = append ( cidrs , cidr ) } } if len ( cidrs ) == 0 { return delegate } return func ( req * http . Request ) ( * url . URL , error ) { host := req . URL . Host host , _ , err = net . SplitHostPort ( req . URL . Host ) if err != nil { return delegate ( req ) } } ip := net . ParseIP ( host ) if ip == nil { return delegate ( req ) } for _ , cidr := range cidrs { if cidr . Contains ( ip ) { return nil , nil } } return delegate ( req ) } } 
func tlsCacheGet ( config * restConfig ) ( http . RoundTripper , error ) { if err != nil { return nil , err } } } return t , nil } 
func loadTLSFiles ( c * restConfig ) error { var err error c . CAData , err = dataFromSliceOrFile ( c . CAData , c . CAFile ) if err != nil { return err } c . CertData , err = dataFromSliceOrFile ( c . CertData , c . CertFile ) if err != nil { return err } c . KeyData , err = dataFromSliceOrFile ( c . KeyData , c . KeyFile ) if err != nil { return err } return nil } 
func ( c * restConfig ) HasCA ( ) bool { return len ( c . CAData ) > 0 || len ( c . CAFile ) > 0 } 
func ( c * restConfig ) HasCertAuth ( ) bool { return len ( c . CertData ) != 0 || len ( c . CertFile ) != 0 } 
func clientcmdNewConfig ( ) * clientcmdConfig { return & clientcmdConfig { Clusters : make ( map [ string ] * clientcmdCluster ) , AuthInfos : make ( map [ string ] * clientcmdAuthInfo ) , Contexts : make ( map [ string ] * clientcmdContext ) , } } 
func newImageSource ( ctx context . Context , sys * types . SystemContext , ref daemonReference ) ( types . ImageSource , error ) { c , err := newDockerClient ( sys ) if err != nil { return nil , errors . Wrap ( err , " " ) } if err != nil { return nil , errors . Wrap ( err , " " ) } defer inputStream . Close ( ) src , err := tarfile . NewSourceFromStream ( inputStream ) if err != nil { return nil , err } return & daemonImageSource { ref : ref , Source : src , } , nil } 
func manifestSchema2FromComponents ( config manifest . Schema2Descriptor , src types . ImageSource , configBlob [ ] byte , layers [ ] manifest . Schema2Descriptor ) genericManifest { return & manifestSchema2 { src : src , configBlob : configBlob , m : manifest . Schema2FromComponents ( config , layers ) , } } 
func ( m * manifestSchema2 ) OCIConfig ( ctx context . Context ) ( * imgspecv1 . Image , error ) { configBlob , err := m . ConfigBlob ( ctx ) if err != nil { return nil , err } if err := json . Unmarshal ( configBlob , configOCI ) ; err != nil { return nil , err } return configOCI , nil } 
func ( m * manifestSchema2 ) ConfigBlob ( ctx context . Context ) ( [ ] byte , error ) { if m . configBlob == nil { if m . src == nil { return nil , errors . Errorf ( " " ) } stream , _ , err := m . src . GetBlob ( ctx , manifest . BlobInfoFromSchema2Descriptor ( m . m . ConfigDescriptor ) , none . NoCache ) if err != nil { return nil , err } defer stream . Close ( ) blob , err := ioutil . ReadAll ( stream ) if err != nil { return nil , err } computedDigest := digest . FromBytes ( blob ) if computedDigest != m . m . ConfigDescriptor . Digest { return nil , errors . Errorf ( " " , computedDigest , m . m . ConfigDescriptor . Digest ) } m . configBlob = blob } return m . configBlob , nil } 
func ( m * manifestSchema2 ) Inspect ( ctx context . Context ) ( * types . ImageInspectInfo , error ) { getter := func ( info types . BlobInfo ) ( [ ] byte , error ) { if info . Digest != m . ConfigInfo ( ) . Digest { } config , err := m . ConfigBlob ( ctx ) if err != nil { return nil , err } return config , nil } return m . m . Inspect ( getter ) } 
func ( m * manifestSchema2 ) UpdatedImage ( ctx context . Context , options types . ManifestUpdateOptions ) ( types . Image , error ) { copy := manifestSchema2 { if options . LayerInfos != nil { if err := copy . m . UpdateLayerInfos ( options . LayerInfos ) ; err != nil { return nil , err } } case imgspecv1 . MediaTypeImageManifest : return copy . convertToManifestOCI1 ( ctx ) default : return nil , errors . Errorf ( " " , manifest . DockerV2Schema2MediaType , options . ManifestMIMEType ) } return memoryImageFromManifest ( & copy ) , nil } 
func ( m * manifestSchema2 ) convertToManifestSchema1 ( ctx context . Context , dest types . ImageDestination ) ( types . Image , error ) { configBytes , err := m . ConfigBlob ( ctx ) if err != nil { return nil , err } imageConfig := & manifest . Schema2Image { } if err := json . Unmarshal ( configBytes , imageConfig ) ; err != nil { return nil , err } history := make ( [ ] manifest . Schema1History , len ( imageConfig . History ) ) nonemptyLayerIndex := 0 var parentV1ID string v1ID := " " haveGzippedEmptyLayer := false if len ( imageConfig . History ) == 0 { } for v2Index , historyEntry := range imageConfig . History { parentV1ID = v1ID v1Index := len ( imageConfig . History ) - 1 - v2Index var blobDigest digest . Digest if historyEntry . EmptyLayer { if ! haveGzippedEmptyLayer { logrus . Debugf ( " " ) if err != nil { return nil , errors . Wrap ( err , " " ) } if info . Digest != GzippedEmptyLayerDigest { return nil , errors . Errorf ( " " , info . Digest , GzippedEmptyLayerDigest ) } haveGzippedEmptyLayer = true } blobDigest = GzippedEmptyLayerDigest } else { if nonemptyLayerIndex >= len ( m . m . LayersDescriptors ) { return nil , errors . Errorf ( " " , len ( m . m . LayersDescriptors ) ) } blobDigest = m . m . LayersDescriptors [ nonemptyLayerIndex ] . Digest nonemptyLayerIndex ++ } if err != nil { return nil , err } v1ID = v fakeImage := manifest . Schema1V1Compatibility { ID : v1ID , Parent : parentV1ID , Comment : historyEntry . Comment , Created : historyEntry . Created , Author : historyEntry . Author , ThrowAway : historyEntry . EmptyLayer , } fakeImage . ContainerConfig . Cmd = [ ] string { historyEntry . CreatedBy } v1CompatibilityBytes , err := json . Marshal ( & fakeImage ) if err != nil { return nil , errors . Errorf ( " " , fakeImage ) } fsLayers [ v1Index ] = manifest . Schema1FSLayers { BlobSum : blobDigest } history [ v1Index ] = manifest . Schema1History { V1Compatibility : string ( v1CompatibilityBytes ) } if err != nil { return nil , err } v1Config , err := v1ConfigFromConfigJSON ( configBytes , v1ID , parentV1ID , imageConfig . History [ len ( imageConfig . History ) - 1 ] . EmptyLayer ) if err != nil { return nil , err } history [ 0 ] . V1Compatibility = string ( v1Config ) m1 , err := manifestSchema1FromComponents ( dest . Reference ( ) . DockerReference ( ) , fsLayers , history , imageConfig . Architecture ) if err != nil { return nil , err } return memoryImageFromManifest ( m1 ) , nil } 
func configuredSignatureStorageBase ( sys * types . SystemContext , ref dockerReference , write bool ) ( signatureStorageBase , error ) { logrus . Debugf ( `Using registries.d directory %s for sigstore configuration` , dirPath ) config , err := loadAndMergeConfig ( dirPath ) if err != nil { return nil , err } topLevel := config . signatureTopLevel ( ref , write ) if topLevel == " " { return nil , nil } url , err := url . Parse ( topLevel ) if err != nil { return nil , errors . Wrapf ( err , " " , topLevel ) } if path . Clean ( repo ) != repo { } url . Path = url . Path + " " + repo return url , nil } 
func registriesDirPath ( sys * types . SystemContext ) string { if sys != nil { if sys . RegistriesDirPath != " " { return sys . RegistriesDirPath } if sys . RootForImplicitAbsolutePaths != " " { return filepath . Join ( sys . RootForImplicitAbsolutePaths , systemRegistriesDirPath ) } } return systemRegistriesDirPath } 
func loadAndMergeConfig ( dirPath string ) ( * registryConfiguration , error ) { mergedConfig := registryConfiguration { Docker : map [ string ] registryNamespace { } } dockerDefaultMergedFrom := " " nsMergedFrom := map [ string ] string { } dir , err := os . Open ( dirPath ) if err != nil { if os . IsNotExist ( err ) { return & mergedConfig , nil } return nil , err } configNames , err := dir . Readdirnames ( 0 ) if err != nil { return nil , err } for _ , configName := range configNames { if ! strings . HasSuffix ( configName , " " ) { continue } configPath := filepath . Join ( dirPath , configName ) configBytes , err := ioutil . ReadFile ( configPath ) if err != nil { return nil , err } var config registryConfiguration err = yaml . Unmarshal ( configBytes , & config ) if err != nil { return nil , errors . Wrapf ( err , " " , configPath ) } if config . DefaultDocker != nil { if mergedConfig . DefaultDocker != nil { return nil , errors . Errorf ( `Error parsing signature storage configuration: "default-docker" defined both in "%s" and "%s"` , dockerDefaultMergedFrom , configPath ) } mergedConfig . DefaultDocker = config . DefaultDocker dockerDefaultMergedFrom = configPath } for nsName , nsConfig := range config . Docker { } mergedConfig . Docker [ nsName ] = nsConfig nsMergedFrom [ nsName ] = configPath } } return & mergedConfig , nil } 
func ( config * registryConfiguration ) signatureTopLevel ( ref dockerReference , write bool ) string { if config . Docker != nil { if ns , ok := config . Docker [ identity ] ; ok { logrus . Debugf ( ` Using "docker" namespace %s` , identity ) if url := ns . signatureTopLevel ( write ) ; url != " " { return url } } if url := ns . signatureTopLevel ( write ) ; url != " " { return url } } } } if url := config . DefaultDocker . signatureTopLevel ( write ) ; url != " " { return url } } logrus . Debugf ( " " , ref . PolicyConfigurationIdentity ( ) ) return " " } 
func ( ns registryNamespace ) signatureTopLevel ( write bool ) string { if write && ns . SigStoreStaging != " " { logrus . Debugf ( ` Using %s` , ns . SigStoreStaging ) return ns . SigStoreStaging } if ns . SigStore != " " { logrus . Debugf ( ` Using %s` , ns . SigStore ) return ns . SigStore } return " " } 
func signatureStorageURL ( base signatureStorageBase , manifestDigest digest . Digest , index int ) * url . URL { if base == nil { return nil } url := * base url . Path = fmt . Sprintf ( " " , url . Path , manifestDigest . Algorithm ( ) , manifestDigest . Hex ( ) , index + 1 ) return & url } 
func ( t openshiftTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return ParseReference ( reference ) } 
func ( t openshiftTransport ) ValidatePolicyConfigurationScope ( scope string ) error { if scopeRegexp . FindStringIndex ( scope ) == nil { return errors . Errorf ( " " , scope ) } return nil } 
func ParseReference ( ref string ) ( types . ImageReference , error ) { r , err := reference . ParseNormalizedNamed ( ref ) if err != nil { return nil , errors . Wrapf ( err , " " , ref ) } tagged , ok := r . ( reference . NamedTagged ) if ! ok { return nil , errors . Errorf ( " " , ref ) } return NewReference ( tagged ) } 
func NewReference ( dockerRef reference . NamedTagged ) ( types . ImageReference , error ) { r := strings . SplitN ( reference . Path ( dockerRef ) , " " , 3 ) if len ( r ) != 2 { return nil , errors . Errorf ( " " , reference . FamiliarString ( dockerRef ) ) } return openshiftReference { namespace : r [ 0 ] , stream : r [ 1 ] , dockerReference : dockerRef , } , nil } 
func ( ref openshiftReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { src , err := newImageSource ( sys , ref ) if err != nil { return nil , err } return genericImage . FromSource ( ctx , sys , src ) } 
func serverDefault ( ) * tls . Config { return & tls . Config { } 
func dockerCertDir ( sys * types . SystemContext , hostPort string ) ( string , error ) { if sys != nil && sys . DockerCertPath != " " { return sys . DockerCertPath , nil } if sys != nil && sys . DockerPerHostCertDirPath != " " { return filepath . Join ( sys . DockerPerHostCertDirPath , hostPort ) , nil } var ( hostCertDir string fullCertDirPath string ) for _ , systemPerHostCertDirPath := range systemPerHostCertDirPaths { if sys != nil && sys . RootForImplicitAbsolutePaths != " " { hostCertDir = filepath . Join ( sys . RootForImplicitAbsolutePaths , systemPerHostCertDirPath ) } else { hostCertDir = systemPerHostCertDirPath } fullCertDirPath = filepath . Join ( hostCertDir , hostPort ) _ , err := os . Stat ( fullCertDirPath ) if err == nil { break } if os . IsNotExist ( err ) { continue } if os . IsPermission ( err ) { logrus . Debugf ( " " , err ) continue } if err != nil { return " " , err } } return fullCertDirPath , nil } 
func newDockerClientFromRef ( sys * types . SystemContext , ref dockerReference , write bool , actions string ) ( * dockerClient , error ) { registry := reference . Domain ( ref . ref ) username , password , err := config . GetAuthentication ( sys , registry ) if err != nil { return nil , errors . Wrapf ( err , " " ) } sigBase , err := configuredSignatureStorageBase ( sys , ref , write ) if err != nil { return nil , err } client , err := newDockerClient ( sys , registry , ref . ref . Name ( ) ) if err != nil { return nil , err } client . username = username client . password = password client . signatureBase = sigBase client . scope . actions = actions client . scope . remoteName = reference . Path ( ref . ref ) return client , nil } 
func newDockerClient ( sys * types . SystemContext , registry , reference string ) ( * dockerClient , error ) { hostName := registry if registry == dockerHostname { registry = dockerRegistry } tlsClientConfig := serverDefault ( ) if err != nil { return nil , err } if err := tlsclientconfig . SetupCertificates ( certDir , tlsClientConfig ) ; err != nil { return nil , err } reg , err := sysregistriesv2 . FindRegistry ( sys , reference ) if err != nil { return nil , errors . Wrapf ( err , " " ) } if reg != nil { skipVerify = reg . Insecure } tlsClientConfig . InsecureSkipVerify = skipVerify return & dockerClient { sys : sys , registry : registry , tlsClientConfig : tlsClientConfig , } , nil } 
func CheckAuth ( ctx context . Context , sys * types . SystemContext , username , password , registry string ) error { client , err := newDockerClient ( sys , registry , registry ) if err != nil { return errors . Wrapf ( err , " " ) } client . username = username client . password = password resp , err := client . makeRequest ( ctx , " " , " " , nil , nil , v2Auth , nil ) if err != nil { return err } defer resp . Body . Close ( ) switch resp . StatusCode { case http . StatusOK : return nil case http . StatusUnauthorized : return ErrUnauthorizedForCredentials default : return errors . Errorf ( " " , resp . StatusCode , http . StatusText ( resp . StatusCode ) ) } } 
func SearchRegistry ( ctx context . Context , sys * types . SystemContext , registry , image string , limit int ) ( [ ] SearchResult , error ) { type V2Results struct { } type V1Results struct { } v2Res := & V2Results { } v1Res := & V1Results { } if err != nil { return nil , errors . Wrapf ( err , " " ) } if registry == dockerHostname { hostname = dockerV1Hostname } client , err := newDockerClient ( sys , hostname , registry ) if err != nil { return nil , errors . Wrapf ( err , " " ) } client . username = username client . password = password q := u . Query ( ) q . Set ( " " , image ) q . Set ( " " , strconv . Itoa ( limit ) ) u . RawQuery = q . Encode ( ) logrus . Debugf ( " " ) resp , err := client . makeRequest ( ctx , " " , u . String ( ) , nil , nil , noAuth , nil ) if err != nil { logrus . Debugf ( " " , registry , err ) } else { defer resp . Body . Close ( ) if resp . StatusCode != http . StatusOK { logrus . Debugf ( " " , registry , resp . StatusCode , http . StatusText ( resp . StatusCode ) ) } else { if err := json . NewDecoder ( resp . Body ) . Decode ( v1Res ) ; err != nil { return nil , err } return v1Res . Results , nil } } } logrus . Debugf ( " " ) resp , err := client . makeRequest ( ctx , " " , " " , nil , nil , v2Auth , nil ) if err != nil { logrus . Debugf ( " " , registry , err ) } else { defer resp . Body . Close ( ) if resp . StatusCode != http . StatusOK { logrus . Errorf ( " " , registry , resp . StatusCode , http . StatusText ( resp . StatusCode ) ) } else { if err := json . NewDecoder ( resp . Body ) . Decode ( v2Res ) ; err != nil { return nil , err } searchRes := [ ] SearchResult { } for _ , repo := range v2Res . Repositories { if strings . Contains ( repo , image ) { res := SearchResult { Name : repo , } searchRes = append ( searchRes , res ) } } return searchRes , nil } } return nil , errors . Wrapf ( err , " " , registry ) } 
func ( c * dockerClient ) makeRequest ( ctx context . Context , method , path string , headers map [ string ] [ ] string , stream io . Reader , auth sendAuth , extraScope * authScope ) ( * http . Response , error ) { if err := c . detectProperties ( ctx ) ; err != nil { return nil , err } url := fmt . Sprintf ( " " , c . scheme , c . registry , path ) return c . makeRequestToResolvedURL ( ctx , method , url , headers , stream , - 1 , auth , extraScope ) } 
func ( c * dockerClient ) makeRequestToResolvedURL ( ctx context . Context , method , url string , headers map [ string ] [ ] string , stream io . Reader , streamLen int64 , auth sendAuth , extraScope * authScope ) ( * http . Response , error ) { req , err := http . NewRequest ( method , url , stream ) if err != nil { return nil , err } req = req . WithContext ( ctx ) if streamLen != - 1 { } req . Header . Set ( " " , " " ) for n , h := range headers { for _ , hh := range h { req . Header . Add ( n , hh ) } } if c . sys != nil && c . sys . DockerRegistryUserAgent != " " { req . Header . Add ( " " , c . sys . DockerRegistryUserAgent ) } if auth == v2Auth { if err := c . setupRequestAuth ( req , extraScope ) ; err != nil { return nil , err } } logrus . Debugf ( " " , method , url ) } 
func ( c * dockerClient ) doHTTP ( req * http . Request ) ( * http . Response , error ) { tr := tlsclientconfig . NewTransport ( ) tr . TLSClientConfig = c . tlsClientConfig httpClient := & http . Client { Transport : tr } return httpClient . Do ( req ) } 
func ( c * dockerClient ) setupRequestAuth ( req * http . Request , extraScope * authScope ) error { if len ( c . challenges ) == 0 { return nil } schemeNames := make ( [ ] string , 0 , len ( c . challenges ) ) for _ , challenge := range c . challenges { schemeNames = append ( schemeNames , challenge . Scheme ) switch challenge . Scheme { case " " : req . SetBasicAuth ( c . username , c . password ) return nil case " " : cacheKey := " " scopes := [ ] authScope { c . scope } if extraScope != nil { scopes = append ( scopes , * extraScope ) } var token bearerToken t , inCache := c . tokenCache . Load ( cacheKey ) if inCache { token = t . ( bearerToken ) } if ! inCache || time . Now ( ) . After ( token . expirationTime ) { t , err := c . getBearerToken ( req . Context ( ) , challenge , scopes ) if err != nil { return err } token = * t c . tokenCache . Store ( cacheKey , token ) } req . Header . Set ( " " , fmt . Sprintf ( " " , token . Token ) ) return nil default : logrus . Debugf ( " " , challenge . Scheme ) } } logrus . Infof ( " " , strings . Join ( schemeNames , " " ) ) return nil } 
func ( c * dockerClient ) detectPropertiesHelper ( ctx context . Context ) error { if c . scheme != " " { return nil } } ping := func ( scheme string ) error { url := fmt . Sprintf ( resolvedPingV2URL , scheme , c . registry ) resp , err := c . makeRequestToResolvedURL ( ctx , " " , url , nil , nil , - 1 , noAuth , nil ) if err != nil { logrus . Debugf ( " " , url , err . Error ( ) , err ) return err } defer resp . Body . Close ( ) logrus . Debugf ( " " , url , resp . StatusCode ) if resp . StatusCode != http . StatusOK && resp . StatusCode != http . StatusUnauthorized { return errors . Errorf ( " " , c . registry , resp . StatusCode , http . StatusText ( resp . StatusCode ) ) } c . challenges = parseAuthHeader ( resp . Header ) c . scheme = scheme c . supportsSignatures = resp . Header . Get ( " " ) == " " return nil } err := ping ( " " ) if err != nil && c . tlsClientConfig . InsecureSkipVerify { err = ping ( " " ) } if err != nil { err = errors . Wrap ( err , " " ) if c . sys != nil && c . sys . DockerDisableV1Ping { return err } resp , err := c . makeRequestToResolvedURL ( ctx , " " , url , nil , nil , - 1 , noAuth , nil ) if err != nil { logrus . Debugf ( " " , url , err . Error ( ) , err ) return false } defer resp . Body . Close ( ) logrus . Debugf ( " " , url , resp . StatusCode ) if resp . StatusCode != http . StatusOK && resp . StatusCode != http . StatusUnauthorized { return false } return true } isV1 := pingV1 ( " " ) if ! isV1 && c . tlsClientConfig . InsecureSkipVerify { isV1 = pingV1 ( " " ) } if isV1 { err = ErrV1NotSupported } } return err } 
func ( c * dockerClient ) detectProperties ( ctx context . Context ) error { c . detectPropertiesOnce . Do ( func ( ) { c . detectPropertiesError = c . detectPropertiesHelper ( ctx ) } ) return c . detectPropertiesError } 
func ( c * dockerClient ) getExtensionsSignatures ( ctx context . Context , ref dockerReference , manifestDigest digest . Digest ) ( * extensionSignatureList , error ) { path := fmt . Sprintf ( extensionsSignaturePath , reference . Path ( ref . ref ) , manifestDigest ) res , err := c . makeRequest ( ctx , " " , path , nil , nil , v2Auth , nil ) if err != nil { return nil , err } defer res . Body . Close ( ) if res . StatusCode != http . StatusOK { return nil , errors . Wrapf ( client . HandleErrorResponse ( res ) , " " , manifestDigest , ref . ref . Name ( ) ) } body , err := ioutil . ReadAll ( res . Body ) if err != nil { return nil , err } var parsedBody extensionSignatureList if err := json . Unmarshal ( body , & parsedBody ) ; err != nil { return nil , errors . Wrapf ( err , " " ) } return & parsedBody , nil } 
func SetupCertificates ( dir string , tlsc * tls . Config ) error { logrus . Debugf ( " " , dir ) fs , err := ioutil . ReadDir ( dir ) if err != nil { if os . IsNotExist ( err ) { return nil } if os . IsPermission ( err ) { logrus . Debugf ( " " , dir , err ) return nil } return err } for _ , f := range fs { fullPath := filepath . Join ( dir , f . Name ( ) ) if strings . HasSuffix ( f . Name ( ) , " " ) { logrus . Debugf ( " " , fullPath ) data , err := ioutil . ReadFile ( fullPath ) if err != nil { if os . IsNotExist ( err ) { continue } return err } if tlsc . RootCAs == nil { systemPool , err := tlsconfig . SystemCertPool ( ) if err != nil { return errors . Wrap ( err , " " ) } tlsc . RootCAs = systemPool } tlsc . RootCAs . AppendCertsFromPEM ( data ) } if strings . HasSuffix ( f . Name ( ) , " " ) { certName := f . Name ( ) keyName := certName [ : len ( certName ) - 5 ] + " " logrus . Debugf ( " " , fullPath ) if ! hasFile ( fs , keyName ) { return errors . Errorf ( " " , keyName , certName ) } cert , err := tls . LoadX509KeyPair ( filepath . Join ( dir , certName ) , filepath . Join ( dir , keyName ) ) if err != nil { return err } tlsc . Certificates = append ( tlsc . Certificates , cert ) } if strings . HasSuffix ( f . Name ( ) , " " ) { keyName := f . Name ( ) certName := keyName [ : len ( keyName ) - 4 ] + " " logrus . Debugf ( " " , fullPath ) if ! hasFile ( fs , certName ) { return errors . Errorf ( " " , certName , keyName ) } } } return nil } 
func NewTransport ( ) * http . Transport { direct := & net . Dialer { Timeout : 30 * time . Second , KeepAlive : 30 * time . Second , DualStack : true , } tr := & http . Transport { Proxy : http . ProxyFromEnvironment , Dial : direct . Dial , TLSHandshakeTimeout : 10 * time . Second , proxyDialer , err := sockets . DialerFromEnvironment ( direct ) if err == nil { tr . Dial = proxyDialer . Dial } return tr } 
func normalizeRegistries ( regs * registries ) { for i := range regs . Registries { regs . Registries [ i ] = strings . TrimRight ( regs . Registries [ i ] , " " ) } } 
func readRegistryConf ( sys * types . SystemContext ) ( [ ] byte , error ) { return ioutil . ReadFile ( RegistriesConfPath ( sys ) ) } 
func loadRegistryConf ( sys * types . SystemContext ) ( * tomlConfig , error ) { config := & tomlConfig { } configBytes , err := readConf ( sys ) if err != nil { return nil , err } err = toml . Unmarshal ( configBytes , & config ) normalizeRegistries ( & config . Registries . Search ) normalizeRegistries ( & config . Registries . Insecure ) normalizeRegistries ( & config . Registries . Block ) return config , err } 
func GetRegistries ( sys * types . SystemContext ) ( [ ] string , error ) { config , err := loadRegistryConf ( sys ) if err != nil { return nil , err } return config . Registries . Search . Registries , nil } 
func GetInsecureRegistries ( sys * types . SystemContext ) ( [ ] string , error ) { config , err := loadRegistryConf ( sys ) if err != nil { return nil , err } return config . Registries . Insecure . Registries , nil } 
func RegistriesConfPath ( ctx * types . SystemContext ) string { path := systemRegistriesConfPath if ctx != nil { if ctx . SystemRegistriesConfPath != " " { path = ctx . SystemRegistriesConfPath } else if ctx . RootForImplicitAbsolutePaths != " " { path = filepath . Join ( ctx . RootForImplicitAbsolutePaths , systemRegistriesConfPath ) } } return path } 
func NewOptionalBool ( b bool ) OptionalBool { o := OptionalBoolFalse if b == true { o = OptionalBoolTrue } return o } 
func ( pc * PolicyContext ) changeState ( expected , new policyContextState ) error { if pc . state != expected { return errors . Errorf ( `"Invalid PolicyContext state, expected "%s", found "%s"` , expected , pc . state ) } pc . state = new return nil } 
func NewPolicyContext ( policy * Policy ) ( * PolicyContext , error ) { pc := & PolicyContext { Policy : policy , state : pcInitializing } } return pc , nil } 
func ( pc * PolicyContext ) Destroy ( ) error { if err := pc . changeState ( pcReady , pcDestroying ) ; err != nil { return err } } 
func policyIdentityLogName ( ref types . ImageReference ) string { return ref . Transport ( ) . Name ( ) + " " + ref . PolicyConfigurationIdentity ( ) } 
func ( pc * PolicyContext ) requirementsForImageRef ( ref types . ImageReference ) PolicyRequirements { if transportScopes , ok := pc . Policy . Transports [ transportName ] ; ok { if req , ok := transportScopes [ identity ] ; ok { logrus . Debugf ( ` Using transport "%s" policy section %s` , transportName , identity ) return req } return req } } return req } } logrus . Debugf ( " " ) return pc . Policy . Default } 
func ( pc * PolicyContext ) GetSignaturesWithAcceptedAuthor ( ctx context . Context , image types . UnparsedImage ) ( sigs [ ] * Signature , finalErr error ) { if err := pc . changeState ( pcReady , pcInUse ) ; err != nil { return nil , err } defer func ( ) { if err := pc . changeState ( pcInUse , pcReady ) ; err != nil { sigs = nil finalErr = err } } ( ) logrus . Debugf ( " " , policyIdentityLogName ( image . Reference ( ) ) ) reqs := pc . requirementsForImageRef ( image . Reference ( ) ) if err != nil { return nil , err } res := make ( [ ] * Signature , 0 , len ( unverifiedSignatures ) ) for sigNumber , sig := range unverifiedSignatures { var acceptedSig * Signature rejected := false interpretingReqs : for reqNumber , req := range reqs { rejected = true break interpretingReqs } logrus . Debugf ( " " , reqNumber ) if acceptedSig == nil { acceptedSig = as } else if * as != * acceptedSig { rejected = true acceptedSig = nil break interpretingReqs } case sarRejected : logrus . Debugf ( " " , reqNumber , err . Error ( ) ) rejected = true break interpretingReqs case sarUnknown : if err != nil { rejected = true break interpretingReqs } logrus . Debugf ( " " , reqNumber ) default : rejected = true break interpretingReqs } } res = append ( res , acceptedSig ) } else { logrus . Debugf ( " " ) } } return res , nil } 
func ( pc * PolicyContext ) IsRunningImageAllowed ( ctx context . Context , image types . UnparsedImage ) ( res bool , finalErr error ) { if err := pc . changeState ( pcReady , pcInUse ) ; err != nil { return false , err } defer func ( ) { if err := pc . changeState ( pcInUse , pcReady ) ; err != nil { res = false finalErr = err } } ( ) logrus . Debugf ( " " , policyIdentityLogName ( image . Reference ( ) ) ) reqs := pc . requirementsForImageRef ( image . Reference ( ) ) if len ( reqs ) == 0 { return false , PolicyRequirementError ( " " ) } for reqNumber , req := range reqs { if ! allowed { logrus . Debugf ( " " , reqNumber ) return false , err } logrus . Debugf ( " " , reqNumber ) } return true , nil } 
func ParseImageName ( imgName string ) ( types . ImageReference , error ) { parts := strings . SplitN ( imgName , " " , 2 ) if len ( parts ) != 2 { return nil , errors . Errorf ( `Invalid image name "%s", expected colon-separated transport:reference` , imgName ) } transport := transports . Get ( parts [ 0 ] ) if transport == nil { return nil , errors . Errorf ( `Invalid image name "%s", unknown transport "%s"` , imgName , parts [ 0 ] ) } return transport . ParseReference ( parts [ 1 ] ) } 
func BlobInfoFromOCI1Descriptor ( desc imgspecv1 . Descriptor ) types . BlobInfo { return types . BlobInfo { Digest : desc . Digest , Size : desc . Size , URLs : desc . URLs , Annotations : desc . Annotations , MediaType : desc . MediaType , } } 
func OCI1FromManifest ( manifest [ ] byte ) ( * OCI1 , error ) { oci1 := OCI1 { } if err := json . Unmarshal ( manifest , & oci1 ) ; err != nil { return nil , err } return & oci1 , nil } 
func OCI1FromComponents ( config imgspecv1 . Descriptor , layers [ ] imgspecv1 . Descriptor ) * OCI1 { return & OCI1 { imgspecv1 . Manifest { Versioned : specs . Versioned { SchemaVersion : 2 } , Config : config , Layers : layers , } , } } 
func ( m * OCI1 ) LayerInfos ( ) [ ] LayerInfo { blobs := [ ] LayerInfo { } for _ , layer := range m . Layers { blobs = append ( blobs , LayerInfo { BlobInfo : BlobInfoFromOCI1Descriptor ( layer ) , EmptyLayer : false , } ) } return blobs } 
func ( m * OCI1 ) UpdateLayerInfos ( layerInfos [ ] types . BlobInfo ) error { if len ( m . Layers ) != len ( layerInfos ) { return errors . Errorf ( " " , len ( m . Layers ) , len ( layerInfos ) ) } original := m . Layers m . Layers = make ( [ ] imgspecv1 . Descriptor , len ( layerInfos ) ) for i , info := range layerInfos { m . Layers [ i ] . MediaType = original [ i ] . MediaType m . Layers [ i ] . Digest = info . Digest m . Layers [ i ] . Size = info . Size m . Layers [ i ] . Annotations = info . Annotations m . Layers [ i ] . URLs = info . URLs } return nil } 
func ( m * OCI1 ) Inspect ( configGetter func ( types . BlobInfo ) ( [ ] byte , error ) ) ( * types . ImageInspectInfo , error ) { config , err := configGetter ( m . ConfigInfo ( ) ) if err != nil { return nil , err } v1 := & imgspecv1 . Image { } if err := json . Unmarshal ( config , v1 ) ; err != nil { return nil , err } d1 := & Schema2V1Image { } json . Unmarshal ( config , d1 ) i := & types . ImageInspectInfo { Tag : " " , Created : v1 . Created , DockerVersion : d1 . DockerVersion , Labels : v1 . Config . Labels , Architecture : v1 . Architecture , Os : v1 . OS , Layers : layerInfosToStrings ( m . LayerInfos ( ) ) , } return i , nil } 
func ( m * OCI1 ) ImageID ( [ ] digest . Digest ) ( string , error ) { if err := m . Config . Digest . Validate ( ) ; err != nil { return " " , err } return m . Config . Digest . Hex ( ) , nil } 
func ( t dockerTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return ParseReference ( reference ) } 
func ParseReference ( refString string ) ( types . ImageReference , error ) { if ! strings . HasPrefix ( refString , " " ) { return nil , errors . Errorf ( " " , refString ) } ref , err := reference . ParseNormalizedNamed ( strings . TrimPrefix ( refString , " " ) ) if err != nil { return nil , err } ref = reference . TagNameOnly ( ref ) return NewReference ( ref ) } 
func newReference ( ref reference . Named ) ( dockerReference , error ) { if reference . IsNameOnly ( ref ) { return dockerReference { } , errors . Errorf ( " " , reference . FamiliarString ( ref ) ) } _ , isDigested := ref . ( reference . Canonical ) if isTagged && isDigested { return dockerReference { } , errors . Errorf ( " " ) } return dockerReference { ref : ref , } , nil } 
func ( ref dockerReference ) PolicyConfigurationIdentity ( ) string { res , err := policyconfiguration . DockerReferenceIdentity ( ref . ref ) if res == " " || err != nil { } return res } 
func ( ref dockerReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { return newImage ( ctx , sys , ref ) } 
func ( ref dockerReference ) DeleteImage ( ctx context . Context , sys * types . SystemContext ) error { return deleteImage ( ctx , sys , ref ) } 
func ( ref dockerReference ) tagOrDigest ( ) ( string , error ) { if ref , ok := ref . ref . ( reference . Canonical ) ; ok { return ref . Digest ( ) . String ( ) , nil } if ref , ok := ref . ref . ( reference . NamedTagged ) ; ok { return ref . Tag ( ) , nil } } 
func newDigestingReader ( source io . Reader , expectedDigest digest . Digest ) ( * digestingReader , error ) { if err := expectedDigest . Validate ( ) ; err != nil { return nil , errors . Errorf ( " " , expectedDigest ) } digestAlgorithm := expectedDigest . Algorithm ( ) if ! digestAlgorithm . Available ( ) { return nil , errors . Errorf ( " " , expectedDigest , digestAlgorithm ) } return & digestingReader { source : source , digester : digestAlgorithm . Digester ( ) , expectedDigest : expectedDigest , validationFailed : false , } , nil } 
func Image ( ctx context . Context , policyContext * signature . PolicyContext , destRef , srcRef types . ImageReference , options * Options ) ( manifest [ ] byte , retErr error ) { } reportWriter := ioutil . Discard if options . ReportWriter != nil { reportWriter = options . ReportWriter } dest , err := destRef . NewImageDestination ( ctx , options . DestinationCtx ) if err != nil { return nil , errors . Wrapf ( err , " " , transports . ImageName ( destRef ) ) } defer func ( ) { if err := dest . Close ( ) ; err != nil { retErr = errors . Wrapf ( retErr , " " , err ) } } ( ) rawSource , err := srcRef . NewImageSource ( ctx , options . SourceCtx ) if err != nil { return nil , errors . Wrapf ( err , " " , transports . ImageName ( srcRef ) ) } defer func ( ) { if err := rawSource . Close ( ) ; err != nil { retErr = errors . Wrapf ( retErr , " " , err ) } } ( ) if ! isTTY ( reportWriter ) { progressOutput = ioutil . Discard } copyInParallel := dest . HasThreadSafePutBlob ( ) && rawSource . HasThreadSafeGetBlob ( ) c := & copier { dest : dest , rawSource : rawSource , reportWriter : reportWriter , progressOutput : progressOutput , progressInterval : options . ProgressInterval , progress : options . Progress , copyInParallel : copyInParallel , unparsedToplevel := image . UnparsedInstance ( rawSource , nil ) multiImage , err := isMultiImage ( ctx , unparsedToplevel ) if err != nil { return nil , errors . Wrapf ( err , " " , transports . ImageName ( srcRef ) ) } if ! multiImage { } } else { if err != nil { return nil , errors . Wrapf ( err , " " , transports . ImageName ( srcRef ) ) } logrus . Debugf ( " " , instanceDigest ) unparsedInstance := image . UnparsedInstance ( rawSource , & instanceDigest ) if manifest , err = c . copyOneImage ( ctx , policyContext , options , unparsedInstance ) ; err != nil { return nil , err } } if err := c . dest . Commit ( ctx ) ; err != nil { return nil , errors . Wrap ( err , " " ) } return manifest , nil } 
func ( c * copier ) copyOneImage ( ctx context . Context , policyContext * signature . PolicyContext , options * Options , unparsedImage * image . UnparsedImage ) ( manifestBytes [ ] byte , retErr error ) { if err != nil { } if multiImage { return nil , fmt . Errorf ( " " ) } } src , err := image . FromUnparsedImage ( ctx , options . SourceCtx , unparsedImage ) if err != nil { return nil , errors . Wrapf ( err , " " , transports . ImageName ( c . rawSource . Reference ( ) ) ) } if named := c . dest . Reference ( ) . DockerReference ( ) ; named != nil { if digested , ok := named . ( reference . Digested ) ; ok { destIsDigestedReference = true sourceManifest , _ , err := src . Manifest ( ctx ) if err != nil { return nil , errors . Wrapf ( err , " " ) } matches , err := manifest . MatchesDigest ( sourceManifest , digested . Digest ( ) ) if err != nil { return nil , errors . Wrapf ( err , " " ) } if ! matches { return nil , errors . New ( " " ) } } } if err := checkImageDestinationForCurrentRuntimeOS ( ctx , options . DestinationCtx , src , c . dest ) ; err != nil { return nil , err } var sigs [ ] [ ] byte if options . RemoveSignatures { sigs = [ ] [ ] byte { } } else { c . Printf ( " \n " ) s , err := src . Signatures ( ctx ) if err != nil { return nil , errors . Wrap ( err , " " ) } sigs = s } if len ( sigs ) != 0 { c . Printf ( " \n " ) if err := c . dest . SupportsSignatures ( ctx ) ; err != nil { return nil , errors . Wrap ( err , " " ) } } ic := imageCopier { c : c , manifestUpdates : & types . ManifestUpdateOptions { InformationOnly : types . ManifestUpdateInformation { Destination : c . dest } } , src : src , if err := ic . updateEmbeddedDockerReference ( ) ; err != nil { return nil , err } if err != nil { return nil , err } if err := ic . copyLayers ( ctx ) ; err != nil { return nil , err } if err != nil { logrus . Debugf ( " " , preferredManifestMIMEType , err ) } } for _ , manifestMIMEType := range otherManifestMIMETypeCandidates { logrus . Debugf ( " m nifestMIMEType) ic . manifestUpdates . ManifestMIMEType = manifestMIMEType attemptedManifest , err := ic . copyUpdatedConfigAndManifest ( ctx ) if err != nil { logrus . Debugf ( " " , manifestMIMEType , err ) errs = append ( errs , fmt . Sprintf ( " " , manifestMIMEType , err ) ) continue } // We have successfully uploaded a manifest. manifestBytes = attemptedManifest errs = nil // Mark this as a success so that we don't abort below. break } if errs != nil { return nil , fmt . Errorf ( " " , strings . Join ( errs , " " ) ) } } if options . SignBy != " " { newSig , err := c . createSignature ( manifestBytes , options . SignBy ) if err != nil { return nil , err } sigs = append ( sigs , newSig ) } c . Printf ( " \n " ) if err := c . dest . PutSignatures ( ctx , sigs ) ; err != nil { return nil , errors . Wrap ( err , " " ) } return manifestBytes , nil } 
func ( c * copier ) Printf ( format string , a ... interface { } ) { fmt . Fprintf ( c . reportWriter , format , a ... ) } 
func ( ic * imageCopier ) updateEmbeddedDockerReference ( ) error { if ic . c . dest . IgnoresEmbeddedDockerReference ( ) { return nil } destRef := ic . c . dest . Reference ( ) . DockerReference ( ) if destRef == nil { return nil } if ! ic . src . EmbeddedDockerReferenceConflicts ( destRef ) { return nil } if ! ic . canModifyManifest { return errors . Errorf ( " " , transports . ImageName ( ic . c . dest . Reference ( ) ) , destRef . String ( ) ) } ic . manifestUpdates . EmbeddedDockerReference = destRef return nil } 
func isTTY ( w io . Writer ) bool { if f , ok := w . ( * os . File ) ; ok { return terminal . IsTerminal ( int ( f . Fd ( ) ) ) } return false } 
func ( ic * imageCopier ) copyLayers ( ctx context . Context ) error { srcInfos := ic . src . LayerInfos ( ) numLayers := len ( srcInfos ) updatedSrcInfos , err := ic . src . LayerInfosForCopy ( ctx ) if err != nil { return err } srcInfosUpdated := false if updatedSrcInfos != nil && ! reflect . DeepEqual ( srcInfos , updatedSrcInfos ) { if ! ic . canModifyManifest { return errors . Errorf ( " " ) } srcInfos = updatedSrcInfos srcInfosUpdated = true } type copyLayerData struct { destInfo types . BlobInfo diffID digest . Digest err error } copyGroup . Add ( numLayers ) if ic . c . copyInParallel { copySemaphore = semaphore . NewWeighted ( int64 ( maxParallelDownloads ) ) } else { copySemaphore = semaphore . NewWeighted ( int64 ( 1 ) ) } data := make ( [ ] copyLayerData , numLayers ) copyLayerHelper := func ( index int , srcLayer types . BlobInfo , pool * mpb . Progress ) { defer copySemaphore . Release ( 1 ) defer copyGroup . Done ( ) cld := copyLayerData { } if ic . c . dest . AcceptsForeignLayerURLs ( ) && len ( srcLayer . URLs ) != 0 { } else { cld . destInfo = srcLayer logrus . Debugf ( " " , cld . destInfo . Digest , ic . c . dest . Reference ( ) . Transport ( ) . Name ( ) ) } } else { cld . destInfo , cld . diffID , cld . err = ic . copyLayer ( ctx , srcLayer , pool ) } data [ index ] = cld } func ( ) { defer progressCleanup ( ) for i , srcLayer := range srcInfos { copySemaphore . Acquire ( ctx , 1 ) go copyLayerHelper ( i , srcLayer , progressPool ) } } ( ) destInfos := make ( [ ] types . BlobInfo , numLayers ) diffIDs := make ( [ ] digest . Digest , numLayers ) for i , cld := range data { if cld . err != nil { return cld . err } destInfos [ i ] = cld . destInfo diffIDs [ i ] = cld . diffID } ic . manifestUpdates . InformationOnly . LayerInfos = destInfos if ic . diffIDsAreNeeded { ic . manifestUpdates . InformationOnly . LayerDiffIDs = diffIDs } if srcInfosUpdated || layerDigestsDiffer ( srcInfos , destInfos ) { ic . manifestUpdates . LayerInfos = destInfos } return nil } 
func layerDigestsDiffer ( a , b [ ] types . BlobInfo ) bool { if len ( a ) != len ( b ) { return true } for i := range a { if a [ i ] . Digest != b [ i ] . Digest { return true } } return false } 
func ( ic * imageCopier ) copyUpdatedConfigAndManifest ( ctx context . Context ) ( [ ] byte , error ) { pendingImage := ic . src if ! reflect . DeepEqual ( * ic . manifestUpdates , types . ManifestUpdateOptions { InformationOnly : ic . manifestUpdates . InformationOnly } ) { if ! ic . canModifyManifest { return nil , errors . Errorf ( " " ) } if ! ic . diffIDsAreNeeded && ic . src . UpdatedImageNeedsLayerDiffIDs ( * ic . manifestUpdates ) { } pi , err := ic . src . UpdatedImage ( ctx , * ic . manifestUpdates ) if err != nil { return nil , errors . Wrap ( err , " " ) } pendingImage = pi } manifest , _ , err := pendingImage . Manifest ( ctx ) if err != nil { return nil , errors . Wrap ( err , " " ) } if err := ic . c . copyConfig ( ctx , pendingImage ) ; err != nil { return nil , err } ic . c . Printf ( " \n " ) if err := ic . c . dest . PutManifest ( ctx , manifest ) ; err != nil { return nil , errors . Wrap ( err , " " ) } return manifest , nil } 
func ( c * copier ) newProgressPool ( ctx context . Context ) ( * mpb . Progress , func ( ) ) { ctx , cancel := context . WithCancel ( ctx ) pool := mpb . New ( mpb . WithWidth ( 40 ) , mpb . WithOutput ( c . progressOutput ) , mpb . WithContext ( ctx ) ) return pool , func ( ) { cancel ( ) pool . Wait ( ) } } 
func ( c * copier ) createProgressBar ( pool * mpb . Progress , info types . BlobInfo , kind string , onComplete string ) * mpb . Bar { prefix := fmt . Sprintf ( " " , kind , info . Digest . Encoded ( ) ) if len ( prefix ) > maxPrefixLen { prefix = prefix [ : maxPrefixLen ] } bar := pool . AddBar ( info . Size , mpb . BarClearOnComplete ( ) , mpb . PrependDecorators ( decor . Name ( prefix ) , ) , mpb . AppendDecorators ( decor . OnComplete ( decor . CountersKibiByte ( " " ) , " " + onComplete ) , ) , ) if c . progressOutput == ioutil . Discard { c . Printf ( " \n " , kind , info . Digest ) } return bar } 
func ( c * copier ) copyConfig ( ctx context . Context , src types . Image ) error { srcInfo := src . ConfigInfo ( ) if srcInfo . Digest != " " { configBlob , err := src . ConfigBlob ( ctx ) if err != nil { return errors . Wrapf ( err , " " , srcInfo . Digest ) } destInfo , err := func ( ) ( types . BlobInfo , error ) { defer progressCleanup ( ) bar := c . createProgressBar ( progressPool , srcInfo , " " , " " ) destInfo , err := c . copyBlobFromStream ( ctx , bytes . NewReader ( configBlob ) , srcInfo , nil , false , true , bar ) if err != nil { return types . BlobInfo { } , err } bar . SetTotal ( int64 ( len ( configBlob ) ) , true ) return destInfo , nil } ( ) if err != nil { return nil } if destInfo . Digest != srcInfo . Digest { return errors . Errorf ( " " , srcInfo . Digest , destInfo . Digest ) } } return nil } 
func ( ic * imageCopier ) copyLayer ( ctx context . Context , srcInfo types . BlobInfo , pool * mpb . Progress ) ( types . BlobInfo , digest . Digest , error ) { cachedDiffID := ic . c . blobInfoCache . UncompressedDigest ( srcInfo . Digest ) diffIDIsNeeded := ic . diffIDsAreNeeded && cachedDiffID == " " if err != nil { return types . BlobInfo { } , " " , errors . Wrapf ( err , " " , srcInfo . Digest ) } if reused { logrus . Debugf ( " " , srcInfo . Digest ) bar := ic . c . createProgressBar ( pool , srcInfo , " " , " " ) bar . SetTotal ( 0 , true ) return blobInfo , cachedDiffID , nil } } if err != nil { return types . BlobInfo { } , " " , errors . Wrapf ( err , " " , srcInfo . Digest ) } defer srcStream . Close ( ) bar := ic . c . createProgressBar ( pool , srcInfo , " " , " " ) blobInfo , diffIDChan , err := ic . copyLayerFromStream ( ctx , srcStream , types . BlobInfo { Digest : srcInfo . Digest , Size : srcBlobSize } , diffIDIsNeeded , bar ) if err != nil { return types . BlobInfo { } , " " , err } diffID := cachedDiffID if diffIDIsNeeded { select { case <- ctx . Done ( ) : return types . BlobInfo { } , " " , ctx . Err ( ) case diffIDResult := <- diffIDChan : if diffIDResult . err != nil { return types . BlobInfo { } , " " , errors . Wrap ( diffIDResult . err , " " ) } logrus . Debugf ( " " , diffIDResult . digest , srcInfo . Digest ) diffID = diffIDResult . digest } } bar . SetTotal ( srcInfo . Size , true ) return blobInfo , diffID , nil } 
func ( ic * imageCopier ) copyLayerFromStream ( ctx context . Context , srcStream io . Reader , srcInfo types . BlobInfo , diffIDIsNeeded bool , bar * mpb . Bar ) ( types . BlobInfo , <- chan diffIDResult , error ) { var getDiffIDRecorder func ( compression . DecompressorFunc ) io . Writer var diffIDChan chan diffIDResult err := errors . New ( " " ) if diffIDIsNeeded { diffIDChan = make ( chan diffIDResult , 1 ) pipeReader , pipeWriter := io . Pipe ( ) defer func ( ) { } ( ) getDiffIDRecorder = func ( decompressor compression . DecompressorFunc ) io . Writer { return pipeWriter } } blobInfo , err := ic . c . copyBlobFromStream ( ctx , srcStream , srcInfo , getDiffIDRecorder , ic . canModifyManifest , false , bar ) return blobInfo , diffIDChan , err // We need the defer  pipeWriter.CloseWithError() to happen HERE so that the caller can block on reading from diffIDChan } 
func diffIDComputationGoroutine ( dest chan <- diffIDResult , layerStream io . ReadCloser , decompressor compression . DecompressorFunc ) { result := diffIDResult { digest : " " , err : errors . New ( " " ) , } defer func ( ) { dest <- result } ( ) defer layerStream . Close ( ) result . digest , result . err = computeDiffID ( layerStream , decompressor ) } 
func computeDiffID ( stream io . Reader , decompressor compression . DecompressorFunc ) ( digest . Digest , error ) { if decompressor != nil { s , err := decompressor ( stream ) if err != nil { return " " , err } defer s . Close ( ) stream = s } return digest . Canonical . FromReader ( stream ) } 
func ( c * copier ) copyBlobFromStream ( ctx context . Context , srcStream io . Reader , srcInfo types . BlobInfo , getOriginalLayerCopyWriter func ( decompressor compression . DecompressorFunc ) io . Writer , canModifyBlob bool , isConfig bool , bar * mpb . Bar ) ( types . BlobInfo , error ) { if err != nil { return types . BlobInfo { } , errors . Wrapf ( err , " " , srcInfo . Digest ) } var destStream io . Reader = digestingReader if err != nil { return types . BlobInfo { } , errors . Wrapf ( err , " " , srcInfo . Digest ) } isCompressed := decompressor != nil destStream = bar . ProxyReader ( destStream ) if getOriginalLayerCopyWriter != nil { destStream = io . TeeReader ( destStream , getOriginalLayerCopyWriter ( decompressor ) ) originalLayerReader = destStream } var compressionOperation types . LayerCompression if canModifyBlob && c . dest . DesiredLayerCompression ( ) == types . Compress && ! isCompressed { logrus . Debugf ( " " ) compressionOperation = types . Compress pipeReader , pipeWriter := io . Pipe ( ) defer pipeReader . Close ( ) destStream = pipeReader inputInfo . Digest = " " inputInfo . Size = - 1 } else if canModifyBlob && c . dest . DesiredLayerCompression ( ) == types . Decompress && isCompressed { logrus . Debugf ( " " ) compressionOperation = types . Decompress s , err := decompressor ( destStream ) if err != nil { return types . BlobInfo { } , err } defer s . Close ( ) destStream = s inputInfo . Digest = " " inputInfo . Size = - 1 } else { logrus . Debugf ( " " ) compressionOperation = types . PreserveOriginal inputInfo = srcInfo } } if err != nil { return types . BlobInfo { } , errors . Wrap ( err , " " ) } _ , err := io . Copy ( ioutil . Discard , originalLayerReader ) if err != nil { return types . BlobInfo { } , errors . Wrapf ( err , " " , srcInfo . Digest ) } } if digestingReader . validationFailed { } if inputInfo . Digest != " " && uploadedInfo . Digest != inputInfo . Digest { return types . BlobInfo { } , errors . Errorf ( " " , srcInfo . Digest , inputInfo . Digest , uploadedInfo . Digest ) } if digestingReader . validationSucceeded { case types . Compress : c . blobInfoCache . RecordDigestUncompressedPair ( uploadedInfo . Digest , srcInfo . Digest ) case types . Decompress : c . blobInfoCache . RecordDigestUncompressedPair ( srcInfo . Digest , uploadedInfo . Digest ) default : return types . BlobInfo { } , errors . Errorf ( " " , compressionOperation ) } } return uploadedInfo , nil } 
func compressGoroutine ( dest * io . PipeWriter , src io . Reader ) { err := errors . New ( " " ) defer func ( ) { } ( ) zipper := pgzip . NewWriter ( dest ) defer zipper . Close ( ) _ , err = io . Copy ( zipper , src ) } 
func newDockerClient ( sys * types . SystemContext ) ( * dockerclient . Client , error ) { host := dockerclient . DefaultDockerHost if sys != nil && sys . DockerDaemonHost != " " { host = sys . DockerDaemonHost } if err != nil { return nil , err } var httpClient * http . Client if url . Scheme != " " { if url . Scheme == " " { httpClient = httpConfig ( ) } else { hc , err := tlsConfig ( sys ) if err != nil { return nil , err } httpClient = hc } } return dockerclient . NewClient ( host , defaultAPIVersion , httpClient , nil ) } 
func defaultPolicyPath ( sys * types . SystemContext ) string { if sys != nil { if sys . SignaturePolicyPath != " " { return sys . SignaturePolicyPath } if sys . RootForImplicitAbsolutePaths != " " { return filepath . Join ( sys . RootForImplicitAbsolutePaths , systemDefaultPolicyPath ) } } return systemDefaultPolicyPath } 
func NewPolicyFromFile ( fileName string ) ( * Policy , error ) { contents , err := ioutil . ReadFile ( fileName ) if err != nil { return nil , err } policy , err := NewPolicyFromBytes ( contents ) if err != nil { return nil , errors . Wrapf ( err , " " , fileName ) } return policy , nil } 
func NewPolicyFromBytes ( data [ ] byte ) ( * Policy , error ) { p := Policy { } if err := json . Unmarshal ( data , & p ) ; err != nil { return nil , InvalidPolicyFormatError ( err . Error ( ) ) } return & p , nil } 
func ( p * Policy ) UnmarshalJSON ( data [ ] byte ) error { * p = Policy { } transports := policyTransportsMap { } if err := paranoidUnmarshalJSONObject ( data , func ( key string ) interface { } { switch key { case " " : return & p . Default case " " : return & transports default : return nil } } ) ; err != nil { return err } if p . Default == nil { return InvalidPolicyFormatError ( " " ) } p . Transports = map [ string ] PolicyTransportScopes ( transports ) return nil } 
func ( m * policyTransportsMap ) UnmarshalJSON ( data [ ] byte ) error { if err := paranoidUnmarshalJSONObject ( data , func ( key string ) interface { } { } ptsWithTransport := policyTransportScopesWithTransport { transport : transport , dest : & PolicyTransportScopes { } , tmpMap [ key ] = ptsWithTransport . dest return & ptsWithTransport } ) ; err != nil { return err } for key , ptr := range tmpMap { ( * m ) [ key ] = * ptr } return nil } 
func ( m * policyTransportScopesWithTransport ) UnmarshalJSON ( data [ ] byte ) error { if err := paranoidUnmarshalJSONObject ( data , func ( key string ) interface { } { } if key != " " && m . transport != nil { if err := m . transport . ValidatePolicyConfigurationScope ( key ) ; err != nil { return nil } } ptr := & PolicyRequirements { } tmpMap [ key ] = ptr return ptr } ) ; err != nil { return err } for key , ptr := range tmpMap { ( * m . dest ) [ key ] = * ptr } return nil } 
func ( m * PolicyRequirements ) UnmarshalJSON ( data [ ] byte ) error { reqJSONs := [ ] json . RawMessage { } if err := json . Unmarshal ( data , & reqJSONs ) ; err != nil { return err } if len ( reqJSONs ) == 0 { return InvalidPolicyFormatError ( " " ) } res := make ( [ ] PolicyRequirement , len ( reqJSONs ) ) for i , reqJSON := range reqJSONs { req , err := newPolicyRequirementFromJSON ( reqJSON ) if err != nil { return err } res [ i ] = req } * m = res return nil } 
func newPolicyRequirementFromJSON ( data [ ] byte ) ( PolicyRequirement , error ) { var typeField prCommon if err := json . Unmarshal ( data , & typeField ) ; err != nil { return nil , err } var res PolicyRequirement switch typeField . Type { case prTypeInsecureAcceptAnything : res = & prInsecureAcceptAnything { } case prTypeReject : res = & prReject { } case prTypeSignedBy : res = & prSignedBy { } case prTypeSignedBaseLayer : res = & prSignedBaseLayer { } default : return nil , InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , typeField . Type ) ) } if err := json . Unmarshal ( data , & res ) ; err != nil { return nil , err } return res , nil } 
func ( pr * prInsecureAcceptAnything ) UnmarshalJSON ( data [ ] byte ) error { * pr = prInsecureAcceptAnything { } var tmp prInsecureAcceptAnything if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , } ) ; err != nil { return err } if tmp . Type != prTypeInsecureAcceptAnything { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } * pr = * newPRInsecureAcceptAnything ( ) return nil } 
func ( pr * prReject ) UnmarshalJSON ( data [ ] byte ) error { * pr = prReject { } var tmp prReject if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , } ) ; err != nil { return err } if tmp . Type != prTypeReject { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } * pr = * newPRReject ( ) return nil } 
func newPRSignedBy ( keyType sbKeyType , keyPath string , keyData [ ] byte , signedIdentity PolicyReferenceMatch ) ( * prSignedBy , error ) { if ! keyType . IsValid ( ) { return nil , InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , keyType ) ) } if len ( keyPath ) > 0 && len ( keyData ) > 0 { return nil , InvalidPolicyFormatError ( " " ) } if signedIdentity == nil { return nil , InvalidPolicyFormatError ( " " ) } return & prSignedBy { prCommon : prCommon { Type : prTypeSignedBy } , KeyType : keyType , KeyPath : keyPath , KeyData : keyData , SignedIdentity : signedIdentity , } , nil } 
func newPRSignedByKeyPath ( keyType sbKeyType , keyPath string , signedIdentity PolicyReferenceMatch ) ( * prSignedBy , error ) { return newPRSignedBy ( keyType , keyPath , nil , signedIdentity ) } 
func NewPRSignedByKeyPath ( keyType sbKeyType , keyPath string , signedIdentity PolicyReferenceMatch ) ( PolicyRequirement , error ) { return newPRSignedByKeyPath ( keyType , keyPath , signedIdentity ) } 
func newPRSignedByKeyData ( keyType sbKeyType , keyData [ ] byte , signedIdentity PolicyReferenceMatch ) ( * prSignedBy , error ) { return newPRSignedBy ( keyType , " " , keyData , signedIdentity ) } 
func NewPRSignedByKeyData ( keyType sbKeyType , keyData [ ] byte , signedIdentity PolicyReferenceMatch ) ( PolicyRequirement , error ) { return newPRSignedByKeyData ( keyType , keyData , signedIdentity ) } 
func ( pr * prSignedBy ) UnmarshalJSON ( data [ ] byte ) error { * pr = prSignedBy { } var tmp prSignedBy var gotKeyPath , gotKeyData = false , false var signedIdentity json . RawMessage if err := paranoidUnmarshalJSONObject ( data , func ( key string ) interface { } { switch key { case " " : return & tmp . Type case " " : return & tmp . KeyType case " " : gotKeyPath = true return & tmp . KeyPath case " " : gotKeyData = true return & tmp . KeyData case " " : return & signedIdentity default : return nil } } ) ; err != nil { return err } if tmp . Type != prTypeSignedBy { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } if signedIdentity == nil { tmp . SignedIdentity = NewPRMMatchRepoDigestOrExact ( ) } else { si , err := newPolicyReferenceMatchFromJSON ( signedIdentity ) if err != nil { return err } tmp . SignedIdentity = si } var res * prSignedBy var err error switch { case gotKeyPath && gotKeyData : return InvalidPolicyFormatError ( " " ) case gotKeyPath && ! gotKeyData : res , err = newPRSignedByKeyPath ( tmp . KeyType , tmp . KeyPath , tmp . SignedIdentity ) case ! gotKeyPath && gotKeyData : res , err = newPRSignedByKeyData ( tmp . KeyType , tmp . KeyData , tmp . SignedIdentity ) case ! gotKeyPath && ! gotKeyData : return InvalidPolicyFormatError ( " " ) default : } if err != nil { return err } * pr = * res return nil } 
func ( kt sbKeyType ) IsValid ( ) bool { switch kt { case SBKeyTypeGPGKeys , SBKeyTypeSignedByGPGKeys , SBKeyTypeX509Certificates , SBKeyTypeSignedByX509CAs : return true default : return false } } 
func ( kt * sbKeyType ) UnmarshalJSON ( data [ ] byte ) error { * kt = sbKeyType ( " " ) var s string if err := json . Unmarshal ( data , & s ) ; err != nil { return err } if ! sbKeyType ( s ) . IsValid ( ) { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , s ) ) } * kt = sbKeyType ( s ) return nil } 
func newPRSignedBaseLayer ( baseLayerIdentity PolicyReferenceMatch ) ( * prSignedBaseLayer , error ) { if baseLayerIdentity == nil { return nil , InvalidPolicyFormatError ( " " ) } return & prSignedBaseLayer { prCommon : prCommon { Type : prTypeSignedBaseLayer } , BaseLayerIdentity : baseLayerIdentity , } , nil } 
func ( pr * prSignedBaseLayer ) UnmarshalJSON ( data [ ] byte ) error { * pr = prSignedBaseLayer { } var tmp prSignedBaseLayer var baseLayerIdentity json . RawMessage if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , " " : & baseLayerIdentity , } ) ; err != nil { return err } if tmp . Type != prTypeSignedBaseLayer { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } bli , err := newPolicyReferenceMatchFromJSON ( baseLayerIdentity ) if err != nil { return err } res , err := newPRSignedBaseLayer ( bli ) if err != nil { } * pr = * res return nil } 
func newPolicyReferenceMatchFromJSON ( data [ ] byte ) ( PolicyReferenceMatch , error ) { var typeField prmCommon if err := json . Unmarshal ( data , & typeField ) ; err != nil { return nil , err } var res PolicyReferenceMatch switch typeField . Type { case prmTypeMatchExact : res = & prmMatchExact { } case prmTypeMatchRepoDigestOrExact : res = & prmMatchRepoDigestOrExact { } case prmTypeMatchRepository : res = & prmMatchRepository { } case prmTypeExactReference : res = & prmExactReference { } case prmTypeExactRepository : res = & prmExactRepository { } default : return nil , InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , typeField . Type ) ) } if err := json . Unmarshal ( data , & res ) ; err != nil { return nil , err } return res , nil } 
func ( prm * prmMatchExact ) UnmarshalJSON ( data [ ] byte ) error { * prm = prmMatchExact { } var tmp prmMatchExact if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , } ) ; err != nil { return err } if tmp . Type != prmTypeMatchExact { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } * prm = * newPRMMatchExact ( ) return nil } 
func ( prm * prmMatchRepoDigestOrExact ) UnmarshalJSON ( data [ ] byte ) error { * prm = prmMatchRepoDigestOrExact { } var tmp prmMatchRepoDigestOrExact if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , } ) ; err != nil { return err } if tmp . Type != prmTypeMatchRepoDigestOrExact { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } * prm = * newPRMMatchRepoDigestOrExact ( ) return nil } 
func ( prm * prmMatchRepository ) UnmarshalJSON ( data [ ] byte ) error { * prm = prmMatchRepository { } var tmp prmMatchRepository if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , } ) ; err != nil { return err } if tmp . Type != prmTypeMatchRepository { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } * prm = * newPRMMatchRepository ( ) return nil } 
func newPRMExactReference ( dockerReference string ) ( * prmExactReference , error ) { ref , err := reference . ParseNormalizedNamed ( dockerReference ) if err != nil { return nil , InvalidPolicyFormatError ( fmt . Sprintf ( " " , dockerReference , err . Error ( ) ) ) } if reference . IsNameOnly ( ref ) { return nil , InvalidPolicyFormatError ( fmt . Sprintf ( " " , dockerReference ) ) } return & prmExactReference { prmCommon : prmCommon { Type : prmTypeExactReference } , DockerReference : dockerReference , } , nil } 
func ( prm * prmExactReference ) UnmarshalJSON ( data [ ] byte ) error { * prm = prmExactReference { } var tmp prmExactReference if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , " " : & tmp . DockerReference , } ) ; err != nil { return err } if tmp . Type != prmTypeExactReference { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } res , err := newPRMExactReference ( tmp . DockerReference ) if err != nil { return err } * prm = * res return nil } 
func newPRMExactRepository ( dockerRepository string ) ( * prmExactRepository , error ) { if _ , err := reference . ParseNormalizedNamed ( dockerRepository ) ; err != nil { return nil , InvalidPolicyFormatError ( fmt . Sprintf ( " " , dockerRepository , err . Error ( ) ) ) } return & prmExactRepository { prmCommon : prmCommon { Type : prmTypeExactRepository } , DockerRepository : dockerRepository , } , nil } 
func ( prm * prmExactRepository ) UnmarshalJSON ( data [ ] byte ) error { * prm = prmExactRepository { } var tmp prmExactRepository if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & tmp . Type , " " : & tmp . DockerRepository , } ) ; err != nil { return err } if tmp . Type != prmTypeExactRepository { return InvalidPolicyFormatError ( fmt . Sprintf ( " \" \" " , tmp . Type ) ) } res , err := newPRMExactRepository ( tmp . DockerRepository ) if err != nil { return err } * prm = * res return nil } 
func newImageSource ( imageRef storageReference ) ( * storageImageSource , error ) { if err != nil { return nil , err } if img . Metadata != " " { if err := json . Unmarshal ( [ ] byte ( img . Metadata ) , image ) ; err != nil { return nil , errors . Wrap ( err , " " ) } } return image , nil } 
func ( s * storageImageSource ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( rc io . ReadCloser , n int64 , err error ) { if info . Digest == image . GzippedEmptyLayerDigest { return ioutil . NopCloser ( bytes . NewReader ( image . GzippedEmptyLayer ) ) , int64 ( len ( image . GzippedEmptyLayer ) ) , nil } rc , n , _ , err = s . getBlobAndLayerID ( info ) return rc , n , err } 
func ( s * storageImageSource ) getBlobAndLayerID ( info types . BlobInfo ) ( rc io . ReadCloser , n int64 , layerID string , err error ) { var layer storage . Layer var diffOptions * storage . DiffOptions if err != nil { return nil , - 1 , " " , err } if err != nil { return nil , - 1 , " " , err } r := bytes . NewReader ( b ) logrus . Debugf ( " " , info . Digest . String ( ) ) return ioutil . NopCloser ( r ) , int64 ( r . Len ( ) ) , " " , nil } i := s . layerPosition [ info . Digest ] s . layerPosition [ info . Digest ] = i + 1 s . getBlobMutex . Unlock ( ) if len ( layers ) > 0 { layer = layers [ i % len ( layers ) ] } diffOptions = & storage . DiffOptions { Compression : & noCompression , } if layer . UncompressedSize < 0 { n = - 1 } else { n = layer . UncompressedSize } logrus . Debugf ( " " , layer . ID , info . Digest ) rc , err = s . imageRef . transport . store . Diff ( " " , layer . ID , diffOptions ) if err != nil { return nil , - 1 , " " , err } return rc , n , layer . ID , err } 
func ( s * storageImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( manifestBlob [ ] byte , MIMEType string , err error ) { if instanceDigest != nil { return nil , " " , ErrNoManifestLists } if len ( s . cachedManifest ) == 0 { blob , err := s . imageRef . transport . store . ImageBigData ( s . image . ID , key ) if err != nil && ! os . IsNotExist ( err ) { } if err == nil { s . cachedManifest = blob } } } if err != nil { return nil , " " , err } s . cachedManifest = cachedBlob } } return s . cachedManifest , manifest . GuessMIMEType ( s . cachedManifest ) , err } 
func ( s * storageImageSource ) LayerInfosForCopy ( ctx context . Context ) ( [ ] types . BlobInfo , error ) { manifestBlob , manifestType , err := s . GetManifest ( ctx , nil ) if err != nil { return nil , errors . Wrapf ( err , " " , s . image . ID ) } man , err := manifest . FromBlob ( manifestBlob , manifestType ) if err != nil { return nil , errors . Wrapf ( err , " " , s . image . ID ) } uncompressedLayerType := " " switch manifestType { case imgspecv1 . MediaTypeImageManifest : uncompressedLayerType = imgspecv1 . MediaTypeImageLayer case manifest . DockerV2Schema1MediaType , manifest . DockerV2Schema1SignedMediaType , manifest . DockerV2Schema2MediaType : } physicalBlobInfos := [ ] types . BlobInfo { } layerID := s . image . TopLayer for layerID != " " { layer , err := s . imageRef . transport . store . Layer ( layerID ) if err != nil { return nil , errors . Wrapf ( err , " " , layerID , s . image . ID ) } if layer . UncompressedDigest == " " { return nil , errors . Errorf ( " " , layerID ) } if layer . UncompressedSize < 0 { return nil , errors . Errorf ( " " , layerID ) } blobInfo := types . BlobInfo { Digest : layer . UncompressedDigest , Size : layer . UncompressedSize , MediaType : uncompressedLayerType , } physicalBlobInfos = append ( [ ] types . BlobInfo { blobInfo } , physicalBlobInfos ... ) layerID = layer . Parent } res , err := buildLayerInfosForCopy ( man . LayerInfos ( ) , physicalBlobInfos ) if err != nil { return nil , errors . Wrapf ( err , " " , s . image . ID ) } return res , nil } 
func buildLayerInfosForCopy ( manifestInfos [ ] manifest . LayerInfo , physicalInfos [ ] types . BlobInfo ) ( [ ] types . BlobInfo , error ) { nextPhysical := 0 res := make ( [ ] types . BlobInfo , len ( manifestInfos ) ) for i , mi := range manifestInfos { if mi . EmptyLayer { res [ i ] = types . BlobInfo { Digest : image . GzippedEmptyLayerDigest , Size : int64 ( len ( image . GzippedEmptyLayer ) ) , MediaType : mi . MediaType , } } else { if nextPhysical >= len ( physicalInfos ) { return nil , fmt . Errorf ( " " , len ( physicalInfos ) ) } res [ i ] = physicalInfos [ nextPhysical ] nextPhysical ++ } } if nextPhysical != len ( physicalInfos ) { return nil , fmt . Errorf ( " " , nextPhysical , len ( physicalInfos ) ) } return res , nil } 
func ( s * storageImageSource ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( signatures [ ] [ ] byte , err error ) { if instanceDigest != nil { return nil , ErrNoManifestLists } var offset int sigslice := [ ] [ ] byte { } signature := [ ] byte { } if len ( s . SignatureSizes ) > 0 { signatureBlob , err := s . imageRef . transport . store . ImageBigData ( s . image . ID , " " ) if err != nil { return nil , errors . Wrapf ( err , " " , s . image . ID ) } signature = signatureBlob } for _ , length := range s . SignatureSizes { sigslice = append ( sigslice , signature [ offset : offset + length ] ) offset += length } if offset != len ( signature ) { return nil , errors . Errorf ( " " , len ( signatures ) - offset ) } return sigslice , nil } 
func newImageDestination ( imageRef storageReference ) ( * storageImageDestination , error ) { directory , err := ioutil . TempDir ( tmpdir . TemporaryDirectoryForBigFiles ( ) , " " ) if err != nil { return nil , errors . Wrapf ( err , " " ) } image := & storageImageDestination { imageRef : imageRef , directory : directory , blobDiffIDs : make ( map [ digest . Digest ] digest . Digest ) , fileSizes : make ( map [ digest . Digest ] int64 ) , filenames : make ( map [ digest . Digest ] string ) , SignatureSizes : [ ] int { } , } return image , nil } 
func ( s * storageImageDestination ) PutBlob ( ctx context . Context , stream io . Reader , blobinfo types . BlobInfo , cache types . BlobInfoCache , isConfig bool ) ( types . BlobInfo , error ) { if blobinfo . Digest . Validate ( ) == nil { if a := blobinfo . Digest . Algorithm ( ) ; a . Available ( ) { hasher = a . Digester ( ) } } diffID := digest . Canonical . Digester ( ) filename := s . computeNextBlobCacheFile ( ) file , err := os . OpenFile ( filename , os . O_CREATE | os . O_TRUNC | os . O_WRONLY | os . O_EXCL , 0600 ) if err != nil { return errorBlobInfo , errors . Wrapf ( err , " " , filename ) } defer file . Close ( ) counter := ioutils . NewWriteCounter ( hasher . Hash ( ) ) reader := io . TeeReader ( io . TeeReader ( stream , counter ) , file ) decompressed , err := archive . DecompressStream ( reader ) if err != nil { return errorBlobInfo , errors . Wrap ( err , " " ) } decompressed . Close ( ) if err != nil { return errorBlobInfo , errors . Wrapf ( err , " " , filename ) } } if blobinfo . Size >= 0 && blobinfo . Size != counter . Count { return errorBlobInfo , ErrBlobSizeMismatch } s . blobDiffIDs [ hasher . Digest ( ) ] = diffID . Digest ( ) s . fileSizes [ hasher . Digest ( ) ] = counter . Count s . filenames [ hasher . Digest ( ) ] = filename s . putBlobMutex . Unlock ( ) blobDigest := blobinfo . Digest if blobDigest . Validate ( ) != nil { blobDigest = hasher . Digest ( ) } blobSize := blobinfo . Size if blobSize < 0 { blobSize = counter . Count } return types . BlobInfo { Digest : blobDigest , Size : blobSize , MediaType : blobinfo . MediaType , } , nil } 
func ( s * storageImageDestination ) TryReusingBlob ( ctx context . Context , blobinfo types . BlobInfo , cache types . BlobInfoCache , canSubstitute bool ) ( bool , types . BlobInfo , error ) { defer s . putBlobMutex . Unlock ( ) if blobinfo . Digest == " " { return false , types . BlobInfo { } , errors . Errorf ( `Can not check for a blob with unknown digest` ) } if err := blobinfo . Digest . Validate ( ) ; err != nil { return false , types . BlobInfo { } , errors . Wrapf ( err , `Can not check for a blob with invalid digest` ) } } if err != nil && errors . Cause ( err ) != storage . ErrLayerUnknown { return false , types . BlobInfo { } , errors . Wrapf ( err , `Error looking for layers with digest %q` , blobinfo . Digest ) } if len ( layers ) > 0 { return true , types . BlobInfo { Digest : blobinfo . Digest , Size : layers [ 0 ] . UncompressedSize , MediaType : blobinfo . MediaType , } , nil } if err != nil && errors . Cause ( err ) != storage . ErrLayerUnknown { return false , types . BlobInfo { } , errors . Wrapf ( err , `Error looking for compressed layers with digest %q` , blobinfo . Digest ) } if len ( layers ) > 0 { return true , types . BlobInfo { Digest : blobinfo . Digest , Size : layers [ 0 ] . CompressedSize , MediaType : blobinfo . MediaType , } , nil } if err != nil && errors . Cause ( err ) != storage . ErrLayerUnknown { return false , types . BlobInfo { } , errors . Wrapf ( err , `Error looking for layers with digest %q` , uncompressedDigest ) } if len ( layers ) > 0 { s . blobDiffIDs [ uncompressedDigest ] = layers [ 0 ] . UncompressedDigest return true , types . BlobInfo { Digest : uncompressedDigest , Size : layers [ 0 ] . UncompressedSize , MediaType : blobinfo . MediaType , } , nil } } } } 
func ( s * storageImageDestination ) computeID ( m manifest . Manifest ) string { switch m := m . ( type ) { case * manifest . Schema1 : } blobSum := m . FSLayers [ i ] . BlobSum diffID , ok := s . blobDiffIDs [ blobSum ] if ! ok { logrus . Infof ( " " , blobSum . String ( ) ) return " " } diffIDs = append ( [ ] digest . Digest { diffID } , diffIDs ... ) } case * manifest . Schema2 , * manifest . OCI1 : } id , err := m . ImageID ( diffIDs ) if err != nil { return " " } return id } 
func ( s * storageImageDestination ) getConfigBlob ( info types . BlobInfo ) ( [ ] byte , error ) { if info . Digest == " " { return nil , errors . Errorf ( `no digest supplied when reading blob` ) } if err := info . Digest . Validate ( ) ; err != nil { return nil , errors . Wrapf ( err , `invalid digest supplied when reading blob` ) } if err2 != nil { return nil , errors . Wrapf ( err2 , `error reading blob from file %q` , filename ) } return contents , nil } } 
func ( s * storageImageDestination ) PutManifest ( ctx context . Context , manifestBlob [ ] byte ) error { if s . imageRef . named != nil { if digested , ok := s . imageRef . named . ( reference . Digested ) ; ok { matches , err := manifest . MatchesDigest ( manifestBlob , digested . Digest ( ) ) if err != nil { return err } if ! matches { return fmt . Errorf ( " " , digested . Digest ( ) ) } } } s . manifest = make ( [ ] byte , len ( manifestBlob ) ) copy ( s . manifest , manifestBlob ) return nil } 
func ( s * storageImageDestination ) PutSignatures ( ctx context . Context , signatures [ ] [ ] byte ) error { sizes := [ ] int { } sigblob := [ ] byte { } for _ , sig := range signatures { sizes = append ( sizes , len ( sig ) ) newblob := make ( [ ] byte , len ( sigblob ) + len ( sig ) ) copy ( newblob , sigblob ) copy ( newblob [ len ( sigblob ) : ] , sig ) sigblob = newblob } s . signatures = sigblob s . SignatureSizes = sizes return nil } 
func ( s * storageImageSource ) getSize ( ) ( int64 , error ) { var sum int64 if err != nil { return - 1 , errors . Wrapf ( err , " " , s . image . ID ) } for _ , dataName := range dataNames { bigSize , err := s . imageRef . transport . store . ImageBigDataSize ( s . image . ID , dataName ) if err != nil { return - 1 , errors . Wrapf ( err , " " , dataName , s . image . ID ) } sum += bigSize } } for layerID != " " { layer , err := s . imageRef . transport . store . Layer ( layerID ) if err != nil { return - 1 , err } if layer . UncompressedDigest == " " || layer . UncompressedSize < 0 { return - 1 , errors . Errorf ( " " , layerID ) } sum += layer . UncompressedSize if layer . Parent == " " { break } layerID = layer . Parent } return sum , nil } 
func newImage ( ctx context . Context , sys * types . SystemContext , s storageReference ) ( types . ImageCloser , error ) { src , err := newImageSource ( s ) if err != nil { return nil , err } img , err := image . FromSource ( ctx , sys , src ) if err != nil { return nil , err } size , err := src . getSize ( ) if err != nil { return nil , err } return & storageImageCloser { ImageCloser : img , size : size } , nil } 
func newImageSource ( ctx context . Context , ref archiveReference ) ( types . ImageSource , error ) { if ref . destinationRef != nil { logrus . Warnf ( " " ) } src , err := tarfile . NewSourceFromFile ( ref . path ) if err != nil { return nil , err } return & archiveImageSource { Source : src , ref : ref , } , nil } 
func ( noCache ) CandidateLocations ( transport types . ImageTransport , scope types . BICTransportScope , digest digest . Digest , canSubstitute bool ) [ ] types . BICReplacementCandidate { return nil } 
func newGPGSigningMechanismInDirectory ( optionalDir string ) ( SigningMechanism , error ) { m := & openpgpSigningMechanism { keyring : openpgp . EntityList { } , } gpgHome := optionalDir if gpgHome == " " { gpgHome = os . Getenv ( " " ) if gpgHome == " " { gpgHome = path . Join ( homedir . Get ( ) , " " ) } } pubring , err := ioutil . ReadFile ( path . Join ( gpgHome , " " ) ) if err != nil { if ! os . IsNotExist ( err ) { return nil , err } } else { _ , err := m . importKeysFromBytes ( pubring ) if err != nil { return nil , err } } return m , nil } 
func newEphemeralGPGSigningMechanism ( blob [ ] byte ) ( SigningMechanism , [ ] string , error ) { m := & openpgpSigningMechanism { keyring : openpgp . EntityList { } , } keyIdentities , err := m . importKeysFromBytes ( blob ) if err != nil { return nil , nil , err } return m , keyIdentities , nil } 
func ( m * openpgpSigningMechanism ) importKeysFromBytes ( blob [ ] byte ) ( [ ] string , error ) { keyring , err := openpgp . ReadKeyRing ( bytes . NewReader ( blob ) ) if err != nil { k , e2 := openpgp . ReadArmoredKeyRing ( bytes . NewReader ( blob ) ) if e2 != nil { return nil , err } keyring = k } keyIdentities := [ ] string { } for _ , entity := range keyring { if entity . PrimaryKey == nil { } m . keyring = append ( m . keyring , entity ) } return keyIdentities , nil } 
func ( m * openpgpSigningMechanism ) Sign ( input [ ] byte , keyIdentity string ) ( [ ] byte , error ) { return nil , SigningNotSupportedError ( " " ) } 
func ( m * openpgpSigningMechanism ) Verify ( unverifiedSignature [ ] byte ) ( contents [ ] byte , keyIdentity string , err error ) { md , err := openpgp . ReadMessage ( bytes . NewReader ( unverifiedSignature ) , m . keyring , nil , nil ) if err != nil { return nil , " " , err } if ! md . IsSigned { return nil , " " , errors . New ( " " ) } content , err := ioutil . ReadAll ( md . UnverifiedBody ) if err != nil { } if md . SignatureError != nil { return nil , " " , fmt . Errorf ( " " , md . SignatureError ) } if md . SignedBy == nil { return nil , " " , InvalidSignatureError { msg : fmt . Sprintf ( " " , md . Signature ) } } if md . Signature != nil { if md . Signature . SigLifetimeSecs != nil { expiry := md . Signature . CreationTime . Add ( time . Duration ( * md . Signature . SigLifetimeSecs ) * time . Second ) if time . Now ( ) . After ( expiry ) { return nil , " " , InvalidSignatureError { msg : fmt . Sprintf ( " " , expiry ) } } } } else if md . SignatureV3 == nil { } } 
func ( m openpgpSigningMechanism ) UntrustedSignatureContents ( untrustedSignature [ ] byte ) ( untrustedContents [ ] byte , shortKeyIdentifier string , err error ) { return gpgUntrustedSignatureContents ( untrustedSignature ) } 
func newImageSource ( ctx context . Context , sys * types . SystemContext , ref ociArchiveReference ) ( types . ImageSource , error ) { tempDirRef , err := createUntarTempDir ( ref ) if err != nil { return nil , errors . Wrap ( err , " " ) } unpackedSrc , err := tempDirRef . ociRefExtracted . NewImageSource ( ctx , sys ) if err != nil { if err := tempDirRef . deleteTempDir ( ) ; err != nil { return nil , errors . Wrapf ( err , " " , tempDirRef . tempDirectory ) } return nil , err } return & ociArchiveImageSource { ref : ref , unpackedSrc : unpackedSrc , tempDirRef : tempDirRef } , nil } 
func LoadManifestDescriptor ( imgRef types . ImageReference ) ( imgspecv1 . Descriptor , error ) { ociArchRef , ok := imgRef . ( ociArchiveReference ) if ! ok { return imgspecv1 . Descriptor { } , errors . Errorf ( " " ) } tempDirRef , err := createUntarTempDir ( ociArchRef ) if err != nil { return imgspecv1 . Descriptor { } , errors . Wrap ( err , " " ) } defer tempDirRef . deleteTempDir ( ) descriptor , err := ocilayout . LoadManifestDescriptor ( tempDirRef . ociRefExtracted ) if err != nil { return imgspecv1 . Descriptor { } , errors . Wrap ( err , " " ) } return descriptor , nil } 
func ( s * ociArchiveImageSource ) Close ( ) error { defer s . tempDirRef . deleteTempDir ( ) return s . unpackedSrc . Close ( ) } 
func ( s * ociArchiveImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { return s . unpackedSrc . GetManifest ( ctx , instanceDigest ) } 
func ( s * ociArchiveImageSource ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { return s . unpackedSrc . GetBlob ( ctx , info , cache ) } 
func ( s * ociArchiveImageSource ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { return s . unpackedSrc . GetSignatures ( ctx , instanceDigest ) } 
func ( os * orderedSet ) append ( s string ) { if _ , ok := os . included [ s ] ; ! ok { os . list = append ( os . list , s ) os . included [ s ] = struct { } { } } } 
func ( ic * imageCopier ) determineManifestConversion ( ctx context . Context , destSupportedManifestMIMETypes [ ] string , forceManifestMIMEType string ) ( string , [ ] string , error ) { _ , srcType , err := ic . src . Manifest ( ctx ) if err != nil { } normalizedSrcType := manifest . NormalizedMIMEType ( srcType ) if srcType != normalizedSrcType { logrus . Debugf ( " " , srcType , normalizedSrcType ) srcType = normalizedSrcType } if forceManifestMIMEType != " " { destSupportedManifestMIMETypes = [ ] string { forceManifestMIMEType } } if len ( destSupportedManifestMIMETypes ) == 0 { return srcType , [ ] string { } , nil } supportedByDest := map [ string ] struct { } { } for _ , t := range destSupportedManifestMIMETypes { supportedByDest [ t ] = struct { } { } } } if ! ic . canModifyManifest { return srcType , [ ] string { } , nil } } } } logrus . Debugf ( " " , srcType , strings . Join ( prioritizedTypes . list , " " ) ) if len ( prioritizedTypes . list ) == 0 { } preferredType := prioritizedTypes . list [ 0 ] if preferredType != srcType { ic . manifestUpdates . ManifestMIMEType = preferredType } else { logrus . Debugf ( " " ) } return preferredType , prioritizedTypes . list [ 1 : ] , nil } 
func isMultiImage ( ctx context . Context , img types . UnparsedImage ) ( bool , error ) { _ , mt , err := img . Manifest ( ctx ) if err != nil { return false , err } return manifest . MIMETypeIsMultiImage ( mt ) , nil } 
func lockPath ( path string ) { pl := func ( ) * pathLock { defer pathLocksMutex . Unlock ( ) pl , ok := pathLocks [ path ] if ok { pl . refCount ++ } else { pl = & pathLock { refCount : 1 , mutex : sync . Mutex { } } pathLocks [ path ] = pl } return pl } ( ) pl . mutex . Lock ( ) } 
func unlockPath ( path string ) { pathLocksMutex . Lock ( ) defer pathLocksMutex . Unlock ( ) pl , ok := pathLocks [ path ] if ! ok { } pl . mutex . Unlock ( ) pl . refCount -- if pl . refCount == 0 { delete ( pathLocks , path ) } } 
func ( bdc * cache ) view ( fn func ( tx * bolt . Tx ) error ) ( retErr error ) { } lockPath ( bdc . path ) defer unlockPath ( bdc . path ) db , err := bolt . Open ( bdc . path , 0600 , & bolt . Options { ReadOnly : true } ) if err != nil { return err } defer func ( ) { if err := db . Close ( ) ; retErr == nil && err != nil { retErr = err } } ( ) return db . View ( fn ) } 
func ( bdc * cache ) update ( fn func ( tx * bolt . Tx ) error ) ( retErr error ) { lockPath ( bdc . path ) defer unlockPath ( bdc . path ) db , err := bolt . Open ( bdc . path , 0600 , nil ) if err != nil { return err } defer func ( ) { if err := db . Close ( ) ; retErr == nil && err != nil { retErr = err } } ( ) return db . Update ( fn ) } 
func ( bdc * cache ) uncompressedDigest ( tx * bolt . Tx , anyDigest digest . Digest ) digest . Digest { if b := tx . Bucket ( uncompressedDigestBucket ) ; b != nil { if uncompressedBytes := b . Get ( [ ] byte ( anyDigest . String ( ) ) ) ; uncompressedBytes != nil { d , err := digest . Parse ( string ( uncompressedBytes ) ) if err == nil { return d } } if k , _ := c . First ( ) ; k != nil { } } } return " " } 
func ( bdc * cache ) UncompressedDigest ( anyDigest digest . Digest ) digest . Digest { var res digest . Digest if err := bdc . view ( func ( tx * bolt . Tx ) error { res = bdc . uncompressedDigest ( tx , anyDigest ) return nil } ) ; err != nil { } return res } 
func ( bdc * cache ) RecordDigestUncompressedPair ( anyDigest digest . Digest , uncompressed digest . Digest ) { _ = bdc . update ( func ( tx * bolt . Tx ) error { b , err := tx . CreateBucketIfNotExists ( uncompressedDigestBucket ) if err != nil { return err } key := [ ] byte ( anyDigest . String ( ) ) if previousBytes := b . Get ( key ) ; previousBytes != nil { previous , err := digest . Parse ( string ( previousBytes ) ) if err != nil { return err } if previous != uncompressed { logrus . Warnf ( " " , anyDigest , previous , uncompressed ) } } if err := b . Put ( key , [ ] byte ( uncompressed . String ( ) ) ) ; err != nil { return err } b , err = tx . CreateBucketIfNotExists ( digestByUncompressedBucket ) if err != nil { return err } b , err = b . CreateBucketIfNotExists ( [ ] byte ( uncompressed . String ( ) ) ) if err != nil { return err } if err := b . Put ( [ ] byte ( anyDigest . String ( ) ) , [ ] byte { } ) ; err != nil { } return nil } ) } 
func ( bdc * cache ) RecordKnownLocation ( transport types . ImageTransport , scope types . BICTransportScope , blobDigest digest . Digest , location types . BICLocationReference ) { _ = bdc . update ( func ( tx * bolt . Tx ) error { b , err := tx . CreateBucketIfNotExists ( knownLocationsBucket ) if err != nil { return err } b , err = b . CreateBucketIfNotExists ( [ ] byte ( transport . Name ( ) ) ) if err != nil { return err } b , err = b . CreateBucketIfNotExists ( [ ] byte ( scope . Opaque ) ) if err != nil { return err } b , err = b . CreateBucketIfNotExists ( [ ] byte ( blobDigest . String ( ) ) ) if err != nil { return err } value , err := time . Now ( ) . MarshalBinary ( ) if err != nil { return err } if err := b . Put ( [ ] byte ( location . Opaque ) , value ) ; err != nil { } return nil } ) } 
func ( bdc * cache ) appendReplacementCandidates ( candidates [ ] prioritize . CandidateWithTime , scopeBucket * bolt . Bucket , digest digest . Digest ) [ ] prioritize . CandidateWithTime { b := scopeBucket . Bucket ( [ ] byte ( digest . String ( ) ) ) if b == nil { return candidates } _ = b . ForEach ( func ( k , v [ ] byte ) error { t := time . Time { } if err := t . UnmarshalBinary ( v ) ; err != nil { return err } candidates = append ( candidates , prioritize . CandidateWithTime { Candidate : types . BICReplacementCandidate { Digest : digest , Location : types . BICLocationReference { Opaque : string ( k ) } , } , LastSeen : t , } ) return nil } ) return candidates } 
func ( bdc * cache ) CandidateLocations ( transport types . ImageTransport , scope types . BICTransportScope , primaryDigest digest . Digest , canSubstitute bool ) [ ] types . BICReplacementCandidate { res := [ ] prioritize . CandidateWithTime { } var uncompressedDigestValue digest . Digest if err := bdc . view ( func ( tx * bolt . Tx ) error { scopeBucket := tx . Bucket ( knownLocationsBucket ) if scopeBucket == nil { return nil } scopeBucket = scopeBucket . Bucket ( [ ] byte ( transport . Name ( ) ) ) if scopeBucket == nil { return nil } scopeBucket = scopeBucket . Bucket ( [ ] byte ( scope . Opaque ) ) if scopeBucket == nil { return nil } res = bdc . appendReplacementCandidates ( res , scopeBucket , primaryDigest ) if canSubstitute { if uncompressedDigestValue = bdc . uncompressedDigest ( tx , primaryDigest ) ; uncompressedDigestValue != " " { b := tx . Bucket ( digestByUncompressedBucket ) if b != nil { b = b . Bucket ( [ ] byte ( uncompressedDigestValue . String ( ) ) ) if b != nil { if err := b . ForEach ( func ( k , _ [ ] byte ) error { d , err := digest . Parse ( string ( k ) ) if err != nil { return err } if d != primaryDigest && d != uncompressedDigestValue { res = bdc . appendReplacementCandidates ( res , scopeBucket , d ) } return nil } ) ; err != nil { return err } } } if uncompressedDigestValue != primaryDigest { res = bdc . appendReplacementCandidates ( res , scopeBucket , uncompressedDigestValue ) } } } return nil } ) ; err != nil { } return prioritize . DestructivelyPrioritizeReplacementCandidates ( res , primaryDigest , uncompressedDigestValue ) } 
func TemporaryDirectoryForBigFiles ( ) string { var temporaryDirectoryForBigFiles string if runtime . GOOS == " " { temporaryDirectoryForBigFiles = os . TempDir ( ) } else { temporaryDirectoryForBigFiles = unixTempDirForBigFiles } return temporaryDirectoryForBigFiles } 
func gpgUntrustedSignatureContents ( untrustedSignature [ ] byte ) ( untrustedContents [ ] byte , shortKeyIdentifier string , err error ) { if err != nil { return nil , " " , err } if ! md . IsSigned { return nil , " " , errors . New ( " " ) } content , err := ioutil . ReadAll ( md . UnverifiedBody ) if err != nil { } } 
func newImageDestination ( sys * types . SystemContext , ref ociReference ) ( types . ImageDestination , error ) { var index * imgspecv1 . Index if indexExists ( ref ) { var err error index , err = ref . getIndex ( ) if err != nil { return nil , err } } else { index = & imgspecv1 . Index { Versioned : imgspec . Versioned { SchemaVersion : 2 , } , } } d := & ociImageDestination { ref : ref , index : * index } if sys != nil { d . sharedBlobDir = sys . OCISharedBlobDirPath d . acceptUncompressedLayers = sys . OCIAcceptUncompressedLayers } if err := ensureDirectoryExists ( d . ref . dir ) ; err != nil { return nil , err } } return d , nil } 
func ( d * ociImageDestination ) PutBlob ( ctx context . Context , stream io . Reader , inputInfo types . BlobInfo , cache types . BlobInfoCache , isConfig bool ) ( types . BlobInfo , error ) { blobFile , err := ioutil . TempFile ( d . ref . dir , " " ) if err != nil { return types . BlobInfo { } , err } succeeded := false explicitClosed := false defer func ( ) { if ! explicitClosed { blobFile . Close ( ) } if ! succeeded { os . Remove ( blobFile . Name ( ) ) } } ( ) digester := digest . Canonical . Digester ( ) tee := io . TeeReader ( stream , digester . Hash ( ) ) if err != nil { return types . BlobInfo { } , err } computedDigest := digester . Digest ( ) if inputInfo . Size != - 1 && size != inputInfo . Size { return types . BlobInfo { } , errors . Errorf ( " " , computedDigest , inputInfo . Size , size ) } if err := blobFile . Sync ( ) ; err != nil { return types . BlobInfo { } , err } } } blobPath , err := d . ref . blobPath ( computedDigest , d . sharedBlobDir ) if err != nil { return types . BlobInfo { } , err } if err := ensureParentDirectoryExists ( blobPath ) ; err != nil { return types . BlobInfo { } , err } explicitClosed = true if err := os . Rename ( blobFile . Name ( ) , blobPath ) ; err != nil { return types . BlobInfo { } , err } succeeded = true return types . BlobInfo { Digest : computedDigest , Size : size } , nil } 
func ( d * ociImageDestination ) TryReusingBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache , canSubstitute bool ) ( bool , types . BlobInfo , error ) { if info . Digest == " " { return false , types . BlobInfo { } , errors . Errorf ( `"Can not check for a blob with unknown digest` ) } blobPath , err := d . ref . blobPath ( info . Digest , d . sharedBlobDir ) if err != nil { return false , types . BlobInfo { } , err } finfo , err := os . Stat ( blobPath ) if err != nil && os . IsNotExist ( err ) { return false , types . BlobInfo { } , nil } if err != nil { return false , types . BlobInfo { } , err } return true , types . BlobInfo { Digest : info . Digest , Size : finfo . Size ( ) } , nil } 
func ( d * ociImageDestination ) PutManifest ( ctx context . Context , m [ ] byte ) error { digest , err := manifest . Digest ( m ) if err != nil { return err } desc := imgspecv1 . Descriptor { } desc . Digest = digest desc . Size = int64 ( len ( m ) ) blobPath , err := d . ref . blobPath ( digest , d . sharedBlobDir ) if err != nil { return err } if err := ensureParentDirectoryExists ( blobPath ) ; err != nil { return err } if err := ioutil . WriteFile ( blobPath , m , 0644 ) ; err != nil { return err } if d . ref . image != " " { annotations := make ( map [ string ] string ) annotations [ " " ] = d . ref . image desc . Annotations = annotations } desc . Platform = & imgspecv1 . Platform { Architecture : runtime . GOARCH , OS : runtime . GOOS , } d . addManifest ( & desc ) return nil } 
func ( d * ociImageDestination ) Commit ( ctx context . Context ) error { if err := ioutil . WriteFile ( d . ref . ociLayoutPath ( ) , [ ] byte ( `{"imageLayoutVersion": "1.0.0"}` ) , 0644 ) ; err != nil { return err } indexJSON , err := json . Marshal ( d . index ) if err != nil { return err } return ioutil . WriteFile ( d . ref . indexPath ( ) , indexJSON , 0644 ) } 
func indexExists ( ref ociReference ) bool { _ , err := os . Stat ( ref . indexPath ( ) ) if err == nil { return true } if os . IsNotExist ( err ) { return false } return true } 
func ( c * copier ) createSignature ( manifest [ ] byte , keyIdentity string ) ( [ ] byte , error ) { mech , err := signature . NewGPGSigningMechanism ( ) if err != nil { return nil , errors . Wrap ( err , " " ) } defer mech . Close ( ) if err := mech . SupportsSigning ( ) ; err != nil { return nil , errors . Wrap ( err , " " ) } dockerReference := c . dest . Reference ( ) . DockerReference ( ) if dockerReference == nil { return nil , errors . Errorf ( " " , transports . ImageName ( c . dest . Reference ( ) ) ) } c . Printf ( " \n " ) newSig , err := signature . SignDockerManifest ( manifest , dockerReference . String ( ) , mech , keyIdentity ) if err != nil { return nil , errors . Wrap ( err , " " ) } return newSig , nil } 
func manifestInstanceFromBlob ( ctx context . Context , sys * types . SystemContext , src types . ImageSource , manblob [ ] byte , mt string ) ( genericManifest , error ) { switch manifest . NormalizedMIMEType ( mt ) { case manifest . DockerV2Schema1MediaType , manifest . DockerV2Schema1SignedMediaType : return manifestSchema1FromManifest ( manblob ) case imgspecv1 . MediaTypeImageManifest : return manifestOCI1FromManifest ( src , manblob ) case manifest . DockerV2Schema2MediaType : return manifestSchema2FromManifest ( src , manblob ) case manifest . DockerV2ListMediaType : return manifestSchema2FromManifestList ( ctx , sys , src , manblob ) default : } } 
func manifestLayerInfosToBlobInfos ( layers [ ] manifest . LayerInfo ) [ ] types . BlobInfo { blobs := make ( [ ] types . BlobInfo , len ( layers ) ) for i , layer := range layers { blobs [ i ] = layer . BlobInfo } return blobs } 
func ( d * archiveImageDestination ) Commit ( ctx context . Context ) error { return d . Destination . Commit ( ctx ) } 
func ( t ociTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return ParseReference ( reference ) } 
func ParseReference ( reference string ) ( types . ImageReference , error ) { dir , image := internal . SplitPathAndImage ( reference ) return NewReference ( dir , image ) } 
func NewReference ( dir , image string ) ( types . ImageReference , error ) { resolved , err := explicitfilepath . ResolvePathToFullyExplicit ( dir ) if err != nil { return nil , err } if err := internal . ValidateOCIPath ( dir ) ; err != nil { return nil , err } if err = internal . ValidateImageName ( image ) ; err != nil { return nil , err } return ociReference { dir : dir , resolvedDir : resolved , image : image } , nil } 
func ( ref ociReference ) StringWithinTransport ( ) string { return fmt . Sprintf ( " " , ref . dir , ref . image ) } 
func ( ref ociReference ) PolicyConfigurationNamespaces ( ) [ ] string { res := [ ] string { } path := ref . resolvedDir for { lastSlash := strings . LastIndex ( path , " " ) } res = append ( res , path ) path = path [ : lastSlash ] } return res } 
func ( ref ociReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { src , err := newImageSource ( sys , ref ) if err != nil { return nil , err } return image . FromSource ( ctx , sys , src ) } 
func ( ref ociReference ) getIndex ( ) ( * imgspecv1 . Index , error ) { indexJSON , err := os . Open ( ref . indexPath ( ) ) if err != nil { return nil , err } defer indexJSON . Close ( ) index := & imgspecv1 . Index { } if err := json . NewDecoder ( indexJSON ) . Decode ( index ) ; err != nil { return nil , err } return index , nil } 
func LoadManifestDescriptor ( imgRef types . ImageReference ) ( imgspecv1 . Descriptor , error ) { ociRef , ok := imgRef . ( ociReference ) if ! ok { return imgspecv1 . Descriptor { } , errors . Errorf ( " " ) } return ociRef . getManifestDescriptor ( ) } 
func ( ref ociReference ) blobPath ( digest digest . Digest , sharedBlobDir string ) ( string , error ) { if err := digest . Validate ( ) ; err != nil { return " " , errors . Wrapf ( err , " " , digest ) } blobDir := filepath . Join ( ref . dir , " " ) if sharedBlobDir != " " { blobDir = sharedBlobDir } return filepath . Join ( blobDir , digest . Algorithm ( ) . String ( ) , digest . Hex ( ) ) , nil } 
func SignDockerManifest ( m [ ] byte , dockerReference string , mech SigningMechanism , keyIdentity string ) ( [ ] byte , error ) { manifestDigest , err := manifest . Digest ( m ) if err != nil { return nil , err } sig := newUntrustedSignature ( manifestDigest , dockerReference ) return sig . sign ( mech , keyIdentity ) } 
func VerifyDockerManifestSignature ( unverifiedSignature , unverifiedManifest [ ] byte , expectedDockerReference string , mech SigningMechanism , expectedKeyIdentity string ) ( * Signature , error ) { expectedRef , err := reference . ParseNormalizedNamed ( expectedDockerReference ) if err != nil { return nil , err } sig , err := verifyAndExtractSignature ( mech , unverifiedSignature , signatureAcceptanceRules { validateKeyIdentity : func ( keyIdentity string ) error { if keyIdentity != expectedKeyIdentity { return InvalidSignatureError { msg : fmt . Sprintf ( " " , keyIdentity , expectedKeyIdentity ) } } return nil } , validateSignedDockerReference : func ( signedDockerReference string ) error { signedRef , err := reference . ParseNormalizedNamed ( signedDockerReference ) if err != nil { return InvalidSignatureError { msg : fmt . Sprintf ( " " , signedDockerReference ) } } if signedRef . String ( ) != expectedRef . String ( ) { return InvalidSignatureError { msg : fmt . Sprintf ( " " , signedDockerReference , expectedDockerReference ) } } return nil } , validateSignedDockerManifestDigest : func ( signedDockerManifestDigest digest . Digest ) error { matches , err := manifest . MatchesDigest ( unverifiedManifest , signedDockerManifestDigest ) if err != nil { return err } if ! matches { return InvalidSignatureError { msg : fmt . Sprintf ( " " , signedDockerManifestDigest ) } } return nil } , } ) if err != nil { return nil , err } return sig , nil } 
func newOpenshiftClient ( ref openshiftReference ) ( * openshiftClient , error ) { logrus . Debugf ( " " , cmdConfig ) restConfig , err := cmdConfig . ClientConfig ( ) if err != nil { return nil , err } baseURL , httpClient , err := restClientFor ( restConfig ) if err != nil { return nil , err } logrus . Debugf ( " " , * baseURL ) if httpClient == nil { httpClient = http . DefaultClient } return & openshiftClient { ref : ref , baseURL : baseURL , httpClient : httpClient , bearerToken : restConfig . BearerToken , username : restConfig . Username , password : restConfig . Password , } , nil } 
func ( c * openshiftClient ) doRequest ( ctx context . Context , method , path string , requestBody [ ] byte ) ( [ ] byte , error ) { url := * c . baseURL url . Path = path var requestBodyReader io . Reader if requestBody != nil { logrus . Debugf ( " " , requestBody ) requestBodyReader = bytes . NewReader ( requestBody ) } req , err := http . NewRequest ( method , url . String ( ) , requestBodyReader ) if err != nil { return nil , err } req = req . WithContext ( ctx ) if len ( c . bearerToken ) != 0 { req . Header . Set ( " " , " " + c . bearerToken ) } else if len ( c . username ) != 0 { req . SetBasicAuth ( c . username , c . password ) } req . Header . Set ( " " , " " ) req . Header . Set ( " " , fmt . Sprintf ( " " , version . Version ) ) if requestBody != nil { req . Header . Set ( " " , " " ) } logrus . Debugf ( " " , method , url . String ( ) ) res , err := c . httpClient . Do ( req ) if err != nil { return nil , err } defer res . Body . Close ( ) body , err := ioutil . ReadAll ( res . Body ) if err != nil { return nil , err } logrus . Debugf ( " " , body ) var status status statusValid := false if err := json . Unmarshal ( body , & status ) ; err == nil && len ( status . Status ) > 0 { statusValid = true } switch { case res . StatusCode == http . StatusSwitchingProtocols : } case res . StatusCode >= http . StatusOK && res . StatusCode <= http . StatusPartialContent : } return nil , errors . Errorf ( " " , res . StatusCode , http . StatusText ( res . StatusCode ) , string ( body ) ) } return body , nil } 
func ( c * openshiftClient ) getImage ( ctx context . Context , imageStreamImageName string ) ( * image , error ) { body , err := c . doRequest ( ctx , " " , path , nil ) if err != nil { return nil , err } if err := json . Unmarshal ( body , & isi ) ; err != nil { return nil , err } return & isi . Image , nil } 
func ( c * openshiftClient ) convertDockerImageReference ( ref string ) ( string , error ) { parts := strings . SplitN ( ref , " " , 2 ) if len ( parts ) != 2 { return " " , errors . Errorf ( " " , ref ) } return reference . Domain ( c . ref . dockerReference ) + " " + parts [ 1 ] , nil } 
func newImageSource ( sys * types . SystemContext , ref openshiftReference ) ( types . ImageSource , error ) { client , err := newOpenshiftClient ( ref ) if err != nil { return nil , err } return & openshiftImageSource { client : client , sys : sys , } , nil } 
func ( s * openshiftImageSource ) Close ( ) error { if s . docker != nil { err := s . docker . Close ( ) s . docker = nil return err } return nil } 
func ( s * openshiftImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { if err := s . ensureImageIsResolved ( ctx ) ; err != nil { return nil , " " , err } return s . docker . GetManifest ( ctx , instanceDigest ) } 
func ( s * openshiftImageSource ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { if err := s . ensureImageIsResolved ( ctx ) ; err != nil { return nil , 0 , err } return s . docker . GetBlob ( ctx , info , cache ) } 
func ( s * openshiftImageSource ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { var imageName string if instanceDigest == nil { if err := s . ensureImageIsResolved ( ctx ) ; err != nil { return nil , err } imageName = s . imageStreamImageName } else { imageName = instanceDigest . String ( ) } image , err := s . client . getImage ( ctx , imageName ) if err != nil { return nil , err } var sigs [ ] [ ] byte for _ , sig := range image . Signatures { if sig . Type == imageSignatureTypeAtomic { sigs = append ( sigs , sig . Content ) } } return sigs , nil } 
func ( s * openshiftImageSource ) ensureImageIsResolved ( ctx context . Context ) error { if s . docker != nil { return nil } body , err := s . client . doRequest ( ctx , " " , path , nil ) if err != nil { return err } if err := json . Unmarshal ( body , & is ) ; err != nil { return err } var te * tagEvent for _ , tag := range is . Status . Tags { if tag . Tag != s . client . ref . dockerReference . Tag ( ) { continue } if len ( tag . Items ) > 0 { te = & tag . Items [ 0 ] break } } if te == nil { return errors . Errorf ( " " ) } logrus . Debugf ( " " , te ) dockerRefString , err := s . client . convertDockerImageReference ( te . DockerImageReference ) if err != nil { return err } logrus . Debugf ( " " , dockerRefString ) dockerRef , err := docker . ParseReference ( " " + dockerRefString ) if err != nil { return err } d , err := dockerRef . NewImageSource ( ctx , s . sys ) if err != nil { return err } s . docker = d s . imageStreamImageName = te . Image return nil } 
func newImageDestination ( ctx context . Context , sys * types . SystemContext , ref openshiftReference ) ( types . ImageDestination , error ) { client , err := newOpenshiftClient ( ref ) if err != nil { return nil , err } dockerRef , err := docker . ParseReference ( dockerRefString ) if err != nil { return nil , err } docker , err := dockerRef . NewImageDestination ( ctx , sys ) if err != nil { return nil , err } return & openshiftImageDestination { client : client , docker : docker , } , nil } 
func ( d * openshiftImageDestination ) TryReusingBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache , canSubstitute bool ) ( bool , types . BlobInfo , error ) { return d . docker . TryReusingBlob ( ctx , info , cache , canSubstitute ) } 
func ( d * openshiftImageDestination ) PutManifest ( ctx context . Context , m [ ] byte ) error { manifestDigest , err := manifest . Digest ( m ) if err != nil { return err } d . imageStreamImageName = manifestDigest . String ( ) return d . docker . PutManifest ( ctx , m ) } 
func ( d * openshiftImageDestination ) Commit ( ctx context . Context ) error { return d . docker . Commit ( ctx ) } 
func newUntrustedSignature ( dockerManifestDigest digest . Digest , dockerReference string ) untrustedSignature { timestamp := time . Now ( ) . Unix ( ) return untrustedSignature { UntrustedDockerManifestDigest : dockerManifestDigest , UntrustedDockerReference : dockerReference , UntrustedCreatorID : & creatorID , UntrustedTimestamp : & timestamp , } } 
func ( s untrustedSignature ) MarshalJSON ( ) ( [ ] byte , error ) { if s . UntrustedDockerManifestDigest == " " || s . UntrustedDockerReference == " " { return nil , errors . New ( " " ) } critical := map [ string ] interface { } { " " : signatureType , " " : map [ string ] string { " " : s . UntrustedDockerManifestDigest . String ( ) } , " " : map [ string ] string { " " : s . UntrustedDockerReference } , } optional := map [ string ] interface { } { } if s . UntrustedCreatorID != nil { optional [ " " ] = * s . UntrustedCreatorID } if s . UntrustedTimestamp != nil { optional [ " " ] = * s . UntrustedTimestamp } signature := map [ string ] interface { } { " " : critical , " " : optional , } return json . Marshal ( signature ) } 
func ( s * untrustedSignature ) UnmarshalJSON ( data [ ] byte ) error { err := s . strictUnmarshalJSON ( data ) if err != nil { if _ , ok := err . ( jsonFormatError ) ; ok { err = InvalidSignatureError { msg : err . Error ( ) } } } return err } 
func ( s * untrustedSignature ) strictUnmarshalJSON ( data [ ] byte ) error { var critical , optional json . RawMessage if err := paranoidUnmarshalJSONObjectExactFields ( data , map [ string ] interface { } { " " : & critical , " " : & optional , } ) ; err != nil { return err } var creatorID string var timestamp float64 var gotCreatorID , gotTimestamp = false , false if err := paranoidUnmarshalJSONObject ( optional , func ( key string ) interface { } { switch key { case " " : gotCreatorID = true return & creatorID case " " : gotTimestamp = true return & timestamp default : var ignore interface { } return & ignore } } ) ; err != nil { return err } if gotCreatorID { s . UntrustedCreatorID = & creatorID } if gotTimestamp { intTimestamp := int64 ( timestamp ) if float64 ( intTimestamp ) != timestamp { return InvalidSignatureError { msg : " " } } s . UntrustedTimestamp = & intTimestamp } var t string var image , identity json . RawMessage if err := paranoidUnmarshalJSONObjectExactFields ( critical , map [ string ] interface { } { " " : & t , " " : & image , " " : & identity , } ) ; err != nil { return err } if t != signatureType { return InvalidSignatureError { msg : fmt . Sprintf ( " " , t ) } } var digestString string if err := paranoidUnmarshalJSONObjectExactFields ( image , map [ string ] interface { } { " " : & digestString , } ) ; err != nil { return err } s . UntrustedDockerManifestDigest = digest . Digest ( digestString ) return paranoidUnmarshalJSONObjectExactFields ( identity , map [ string ] interface { } { " " : & s . UntrustedDockerReference , } ) } 
func ( s untrustedSignature ) sign ( mech SigningMechanism , keyIdentity string ) ( [ ] byte , error ) { json , err := json . Marshal ( s ) if err != nil { return nil , err } return mech . Sign ( json , keyIdentity ) } 
func verifyAndExtractSignature ( mech SigningMechanism , unverifiedSignature [ ] byte , rules signatureAcceptanceRules ) ( * Signature , error ) { signed , keyIdentity , err := mech . Verify ( unverifiedSignature ) if err != nil { return nil , err } if err := rules . validateKeyIdentity ( keyIdentity ) ; err != nil { return nil , err } var unmatchedSignature untrustedSignature if err := json . Unmarshal ( signed , & unmatchedSignature ) ; err != nil { return nil , InvalidSignatureError { msg : err . Error ( ) } } if err := rules . validateSignedDockerManifestDigest ( unmatchedSignature . UntrustedDockerManifestDigest ) ; err != nil { return nil , err } if err := rules . validateSignedDockerReference ( unmatchedSignature . UntrustedDockerReference ) ; err != nil { return nil , err } } 
func GetUntrustedSignatureInformationWithoutVerifying ( untrustedSignatureBytes [ ] byte ) ( * UntrustedSignatureInformation , error ) { if err != nil { return nil , err } defer mech . Close ( ) untrustedContents , shortKeyIdentifier , err := mech . UntrustedSignatureContents ( untrustedSignatureBytes ) if err != nil { return nil , err } var untrustedDecodedContents untrustedSignature if err := json . Unmarshal ( untrustedContents , & untrustedDecodedContents ) ; err != nil { return nil , InvalidSignatureError { msg : err . Error ( ) } } var timestamp * time . Time if untrustedDecodedContents . UntrustedTimestamp != nil { ts := time . Unix ( * untrustedDecodedContents . UntrustedTimestamp , 0 ) timestamp = & ts } return & UntrustedSignatureInformation { UntrustedDockerManifestDigest : untrustedDecodedContents . UntrustedDockerManifestDigest , UntrustedDockerReference : untrustedDecodedContents . UntrustedDockerReference , UntrustedCreatorID : untrustedDecodedContents . UntrustedCreatorID , UntrustedTimestamp : timestamp , UntrustedShortKeyIdentifier : shortKeyIdentifier , } , nil } 
func ( t daemonTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return ParseReference ( reference ) } 
func ( t daemonTransport ) ValidatePolicyConfigurationScope ( scope string ) error { } } 
func ParseReference ( refString string ) ( types . ImageReference , error ) { } return NewReference ( dgst , nil ) } ref , err := reference . ParseNormalizedNamed ( refString ) if err != nil { return nil , err } if reference . FamiliarName ( ref ) == digest . Canonical . String ( ) { return nil , errors . Errorf ( " " , refString , digest . Canonical ) } return NewReference ( " " , ref ) } 
func NewReference ( id digest . Digest , ref reference . Named ) ( types . ImageReference , error ) { if id != " " && ref != nil { return nil , errors . New ( " " ) } if ref != nil { if reference . IsNameOnly ( ref ) { return nil , errors . Errorf ( " " , reference . FamiliarString ( ref ) ) } _ , isDigested := ref . ( reference . Canonical ) if isTagged && isDigested { return nil , errors . Errorf ( " " ) } } return daemonReference { id : id , ref : ref , } , nil } 
func ( ref daemonReference ) StringWithinTransport ( ) string { switch { case ref . id != " " : return ref . id . String ( ) case ref . ref != nil : return reference . FamiliarString ( ref . ref ) default : } } 
func ( ref daemonReference ) PolicyConfigurationIdentity ( ) string { case ref . ref != nil : res , err := policyconfiguration . DockerReferenceIdentity ( ref . ref ) if res == " " || err != nil { } return res default : } } 
func ( ref daemonReference ) PolicyConfigurationNamespaces ( ) [ ] string { case ref . ref != nil : return policyconfiguration . DockerReferenceNamespaces ( ref . ref ) default : } } 
func ( e * Endpoint ) RewriteReference ( ref reference . Named , prefix string ) ( reference . Named , error ) { if ref == nil { return nil , fmt . Errorf ( " " ) } if prefix == " " { return ref , nil } refString := ref . String ( ) if refMatchesPrefix ( refString , prefix ) { newNamedRef := strings . Replace ( refString , prefix , e . Location , 1 ) newParsedRef , err := reference . ParseNamed ( newNamedRef ) if newParsedRef != nil { logrus . Debugf ( " " , refString , newParsedRef . String ( ) ) } if err != nil { return nil , errors . Wrapf ( err , " " ) } return newParsedRef , nil } return nil , fmt . Errorf ( " " , prefix , refString ) } 
func parseLocation ( input string ) ( string , error ) { trimmed := strings . TrimRight ( input , " " ) if trimmed == " " { return " " , & InvalidRegistries { s : " " } } if strings . HasPrefix ( trimmed , " " ) || strings . HasPrefix ( trimmed , " " ) { msg := fmt . Sprintf ( " " , input ) return " " , & InvalidRegistries { s : msg } } return trimmed , nil } 
func getV1Registries ( config * tomlConfig ) ( [ ] Registry , error ) { regMap := make ( map [ string ] * Registry ) getRegistry := func ( location string ) ( * Registry , error ) { location , err = parseLocation ( location ) if err != nil { return nil , err } reg , exists := regMap [ location ] if ! exists { reg = & Registry { Endpoint : Endpoint { Location : location } , Mirrors : [ ] Endpoint { } , Prefix : location , } regMap [ location ] = reg registryOrder = append ( registryOrder , location ) } return reg , nil } if err != nil { return nil , err } reg . Search = true } for _ , blocked := range config . V1TOMLConfig . Block . Registries { reg , err := getRegistry ( blocked ) if err != nil { return nil , err } reg . Blocked = true } for _ , insecure := range config . V1TOMLConfig . Insecure . Registries { reg , err := getRegistry ( insecure ) if err != nil { return nil , err } reg . Insecure = true } registries := [ ] Registry { } for _ , location := range registryOrder { reg := regMap [ location ] registries = append ( registries , * reg ) } return registries , nil } 
func postProcessRegistries ( regs [ ] Registry ) ( [ ] Registry , error ) { var registries [ ] Registry regMap := make ( map [ string ] [ ] Registry ) for _ , reg := range regs { var err error if err != nil { return nil , err } if reg . Prefix == " " { reg . Prefix = reg . Location } else { reg . Prefix , err = parseLocation ( reg . Prefix ) if err != nil { return nil , err } } if err != nil { return nil , err } } registries = append ( registries , reg ) regMap [ reg . Location ] = append ( regMap [ reg . Location ] , reg ) } for _ , other := range others { if reg . Insecure != other . Insecure { msg := fmt . Sprintf ( " " , reg . Location ) return nil , & InvalidRegistries { s : msg } } if reg . Blocked != other . Blocked { msg := fmt . Sprintf ( " " , reg . Location ) return nil , & InvalidRegistries { s : msg } } } } return registries , nil } 
func getConfigPath ( ctx * types . SystemContext ) string { confPath := systemRegistriesConfPath if ctx != nil { if ctx . SystemRegistriesConfPath != " " { confPath = ctx . SystemRegistriesConfPath } else if ctx . RootForImplicitAbsolutePaths != " " { confPath = filepath . Join ( ctx . RootForImplicitAbsolutePaths , systemRegistriesConfPath ) } } return confPath } 
func GetRegistries ( ctx * types . SystemContext ) ( [ ] Registry , error ) { configPath := getConfigPath ( ctx ) configMutex . Lock ( ) defer configMutex . Unlock ( ) } if err != nil { } return nil , err } registries := config . Registries if err != nil { return nil , err } if len ( v1Registries ) > 0 { if len ( registries ) > 0 { return nil , & InvalidRegistries { s : " " } } registries = v1Registries } registries , err = postProcessRegistries ( registries ) if err != nil { return nil , err } return registries , err } 
func FindUnqualifiedSearchRegistries ( ctx * types . SystemContext ) ( [ ] Registry , error ) { registries , err := GetRegistries ( ctx ) if err != nil { return nil , err } unqualified := [ ] Registry { } for _ , reg := range registries { if reg . Search { unqualified = append ( unqualified , reg ) } } return unqualified , nil } 
func refMatchesPrefix ( ref , prefix string ) bool { switch { case len ( ref ) < len ( prefix ) : return false case len ( ref ) == len ( prefix ) : return ref == prefix case len ( ref ) > len ( prefix ) : if ! strings . HasPrefix ( ref , prefix ) { return false } c := ref [ len ( prefix ) ] default : panic ( " " ) } } 
func FindRegistry ( ctx * types . SystemContext , ref string ) ( * Registry , error ) { registries , err := GetRegistries ( ctx ) if err != nil { return nil , err } reg := Registry { } prefixLen := 0 for _ , r := range registries { if refMatchesPrefix ( ref , r . Prefix ) { length := len ( r . Prefix ) if length > prefixLen { reg = r prefixLen = length } } } if prefixLen != 0 { return & reg , nil } return nil , nil } 
func readRegistryConf ( configPath string ) ( [ ] byte , error ) { configBytes , err := ioutil . ReadFile ( configPath ) return configBytes , err } 
func loadRegistryConf ( configPath string ) ( * tomlConfig , error ) { config := & tomlConfig { } configBytes , err := readConf ( configPath ) if err != nil { return nil , err } err = toml . Unmarshal ( configBytes , & config ) return config , err } 
func ( s stubTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return nil , fmt . Errorf ( `The transport "%s:" is not supported in this build` , string ( s ) ) } 
func FromSource ( ctx context . Context , sys * types . SystemContext , src types . ImageSource ) ( types . ImageCloser , error ) { img , err := FromUnparsedImage ( ctx , sys , UnparsedInstance ( src , nil ) ) if err != nil { return nil , err } return & imageCloser { Image : img , src : src , } , nil } 
func FromUnparsedImage ( ctx context . Context , sys * types . SystemContext , unparsed * UnparsedImage ) ( types . Image , error ) { if err != nil { return nil , err } parsedManifest , err := manifestInstanceFromBlob ( ctx , sys , unparsed . src , manifestBlob , manifestMIMEType ) if err != nil { return nil , err } return & sourcedImage { UnparsedImage : unparsed , manifestBlob : manifestBlob , manifestMIMEType : manifestMIMEType , genericManifest : parsedManifest , } , nil } 
func ( i * sourcedImage ) Manifest ( ctx context . Context ) ( [ ] byte , string , error ) { return i . manifestBlob , i . manifestMIMEType , nil } 
func ( r * tarballReference ) ConfigUpdate ( config imgspecv1 . Image , annotations map [ string ] string ) error { r . config = config if r . annotations == nil { r . annotations = make ( map [ string ] string ) } for k , v := range annotations { r . annotations [ k ] = v } return nil } 
func ( r * tarballReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { src , err := r . NewImageSource ( ctx , sys ) if err != nil { return nil , err } img , err := image . FromSource ( ctx , sys , src ) if err != nil { src . Close ( ) return nil , err } return img , nil } 
func newImageSource ( sys * types . SystemContext , ref ociReference ) ( types . ImageSource , error ) { tr := tlsclientconfig . NewTransport ( ) tr . TLSClientConfig = tlsconfig . ServerDefault ( ) if sys != nil && sys . OCICertPath != " " { if err := tlsclientconfig . SetupCertificates ( sys . OCICertPath , tr . TLSClientConfig ) ; err != nil { return nil , err } tr . TLSClientConfig . InsecureSkipVerify = sys . OCIInsecureSkipTLSVerify } client := & http . Client { } client . Transport = tr descriptor , err := ref . getManifestDescriptor ( ) if err != nil { return nil , err } d := & ociImageSource { ref : ref , descriptor : descriptor , client : client } if sys != nil { } return d , nil } 
func ( s * ociImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { var dig digest . Digest var mimeType string if instanceDigest == nil { dig = digest . Digest ( s . descriptor . Digest ) mimeType = s . descriptor . MediaType } else { dig = * instanceDigest } manifestPath , err := s . ref . blobPath ( dig , s . sharedBlobDir ) if err != nil { return nil , " " , err } m , err := ioutil . ReadFile ( manifestPath ) if err != nil { return nil , " " , err } return m , mimeType , nil } 
func ( s * ociImageSource ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { if len ( info . URLs ) != 0 { return s . getExternalBlob ( ctx , info . URLs ) } path , err := s . ref . blobPath ( info . Digest , s . sharedBlobDir ) if err != nil { return nil , 0 , err } r , err := os . Open ( path ) if err != nil { return nil , 0 , err } fi , err := r . Stat ( ) if err != nil { return nil , 0 , err } return r , fi . Size ( ) , nil } 
func ( s * ociImageSource ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { return [ ] [ ] byte { } , nil } 
func manifestOCI1FromComponents ( config imgspecv1 . Descriptor , src types . ImageSource , configBlob [ ] byte , layers [ ] imgspecv1 . Descriptor ) genericManifest { return & manifestOCI1 { src : src , configBlob : configBlob , m : manifest . OCI1FromComponents ( config , layers ) , } } 
func ( m * manifestOCI1 ) OCIConfig ( ctx context . Context ) ( * imgspecv1 . Image , error ) { cb , err := m . ConfigBlob ( ctx ) if err != nil { return nil , err } configOCI := & imgspecv1 . Image { } if err := json . Unmarshal ( cb , configOCI ) ; err != nil { return nil , err } return configOCI , nil } 
func ( m * manifestOCI1 ) UpdatedImage ( ctx context . Context , options types . ManifestUpdateOptions ) ( types . Image , error ) { copy := manifestOCI1 { if options . LayerInfos != nil { if err := copy . m . UpdateLayerInfos ( options . LayerInfos ) ; err != nil { return nil , err } } if err != nil { return nil , err } return m2 . UpdatedImage ( ctx , types . ManifestUpdateOptions { ManifestMIMEType : options . ManifestMIMEType , InformationOnly : options . InformationOnly , } ) case manifest . DockerV2Schema2MediaType : return copy . convertToManifestSchema2 ( ) default : return nil , errors . Errorf ( " " , imgspecv1 . MediaTypeImageManifest , options . ManifestMIMEType ) } return memoryImageFromManifest ( & copy ) , nil } 
func parseImageAndDockerReference ( image types . UnparsedImage , s2 string ) ( reference . Named , reference . Named , error ) { r1 := image . Reference ( ) . DockerReference ( ) if r1 == nil { return nil , nil , PolicyRequirementError ( fmt . Sprintf ( " " , transports . ImageName ( image . Reference ( ) ) ) ) } r2 , err := reference . ParseNormalizedNamed ( s2 ) if err != nil { return nil , nil , err } return r1 , r2 , nil } 
func parseDockerReferences ( s1 , s2 string ) ( reference . Named , reference . Named , error ) { r1 , err := reference . ParseNormalizedNamed ( s1 ) if err != nil { return nil , nil , err } r2 , err := reference . ParseNormalizedNamed ( s2 ) if err != nil { return nil , nil , err } return r1 , r2 , nil } 
func ImageName ( ref types . ImageReference ) string { return ref . Transport ( ) . Name ( ) + " " + ref . StringWithinTransport ( ) } 
func ListNames ( ) [ ] string { kt . mu . Lock ( ) defer kt . mu . Unlock ( ) deprecated := map [ string ] bool { " " : true , } var names [ ] string for _ , transport := range kt . transports { if ! deprecated [ transport . Name ( ) ] { names = append ( names , transport . Name ( ) ) } } sort . Strings ( names ) return names } 
func ( t ostreeTransport ) ValidatePolicyConfigurationScope ( scope string ) error { sep := strings . Index ( scope , " " ) if sep < 0 { return errors . Errorf ( " " , scope ) } repo := scope [ : sep ] if ! strings . HasPrefix ( repo , " " ) { return errors . Errorf ( " " , scope ) } cleaned := filepath . Clean ( repo ) if cleaned != repo { return errors . Errorf ( `Invalid ostree: scope %s: Uses non-canonical path format, perhaps try with path %s` , scope , cleaned ) } } 
func NewReference ( image string , repo string ) ( types . ImageReference , error ) { if err != nil { return nil , err } if reference . IsNameOnly ( ostreeImage ) { image = image + " " } resolved , err := explicitfilepath . ResolvePathToFullyExplicit ( repo ) if err != nil { } else { return nil , err } } } return ostreeReference { image : image , branchName : encodeOStreeRef ( image ) , repo : resolved , } , nil } 
func ( ref ostreeReference ) StringWithinTransport ( ) string { return fmt . Sprintf ( " " , ref . image , ref . repo ) } 
func ( ref ostreeReference ) PolicyConfigurationNamespaces ( ) [ ] string { s := strings . SplitN ( ref . image , " " , 2 ) if len ( s ) != 2 { } name := s [ 0 ] res := [ ] string { } for { res = append ( res , fmt . Sprintf ( " " , ref . repo , name ) ) lastSlash := strings . LastIndex ( name , " " ) if lastSlash == - 1 { break } name = name [ : lastSlash ] } return res } 
func ( ref ostreeReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { var tmpDir string if sys == nil || sys . OSTreeTmpDirPath == " " { tmpDir = os . TempDir ( ) } else { tmpDir = sys . OSTreeTmpDirPath } src , err := newImageSource ( tmpDir , ref ) if err != nil { return nil , err } return image . FromSource ( ctx , sys , src ) } 
func ( ref ostreeReference ) NewImageSource ( ctx context . Context , sys * types . SystemContext ) ( types . ImageSource , error ) { var tmpDir string if sys == nil || sys . OSTreeTmpDirPath == " " { tmpDir = os . TempDir ( ) } else { tmpDir = sys . OSTreeTmpDirPath } return newImageSource ( tmpDir , ref ) } 
func ( ref ostreeReference ) NewImageDestination ( ctx context . Context , sys * types . SystemContext ) ( types . ImageDestination , error ) { var tmpDir string if sys == nil || sys . OSTreeTmpDirPath == " " { tmpDir = os . TempDir ( ) } else { tmpDir = sys . OSTreeTmpDirPath } return newImageDestination ( ref , tmpDir ) } 
func ( ref ostreeReference ) signaturePath ( index int ) string { return filepath . Join ( " " , fmt . Sprintf ( " " , index + 1 ) ) } 
func paranoidUnmarshalJSONObject ( data [ ] byte , fieldResolver func ( string ) interface { } ) error { seenKeys := map [ string ] struct { } { } dec := json . NewDecoder ( bytes . NewReader ( data ) ) t , err := dec . Token ( ) if err != nil { return jsonFormatError ( err . Error ( ) ) } if t != json . Delim ( '{' ) { return jsonFormatError ( fmt . Sprintf ( " \" \" " , t ) ) } for { t , err := dec . Token ( ) if err != nil { return jsonFormatError ( err . Error ( ) ) } if t == json . Delim ( '}' ) { break } key , ok := t . ( string ) if ! ok { } if _ , ok := seenKeys [ key ] ; ok { return jsonFormatError ( fmt . Sprintf ( " \" \" " , key ) ) } seenKeys [ key ] = struct { } { } valuePtr := fieldResolver ( key ) if valuePtr == nil { return jsonFormatError ( fmt . Sprintf ( " \" \" " , key ) ) } } } if _ , err := dec . Token ( ) ; err != io . EOF { return jsonFormatError ( " " ) } return nil } 
func paranoidUnmarshalJSONObjectExactFields ( data [ ] byte , exactFields map [ string ] interface { } ) error { seenKeys := map [ string ] struct { } { } if err := paranoidUnmarshalJSONObject ( data , func ( key string ) interface { } { if valuePtr , ok := exactFields [ key ] ; ok { seenKeys [ key ] = struct { } { } return valuePtr } return nil } ) ; err != nil { return err } for key := range exactFields { if _ , ok := seenKeys [ key ] ; ! ok { return jsonFormatError ( fmt . Sprintf ( `Key "%s" missing in a JSON object` , key ) ) } } return nil } 
func ValidateImageName ( image string ) error { if len ( image ) == 0 { return nil } var err error if ! refRegexp . MatchString ( image ) { err = errors . Errorf ( " " , image ) } return err } 
func SplitPathAndImage ( reference string ) ( string , string ) { if runtime . GOOS == " " { return splitPathAndImageWindows ( reference ) } return splitPathAndImageNonWindows ( reference ) } 
func ValidateOCIPath ( path string ) error { if runtime . GOOS == " " { } } else { if strings . Contains ( path , " " ) { return errors . Errorf ( " " , path ) } } return nil } 
func ValidateScope ( scope string ) error { var err error if runtime . GOOS == " " { err = validateScopeWindows ( scope ) } else { err = validateScopeNonWindows ( scope ) } if err != nil { return err } cleaned := filepath . Clean ( scope ) if cleaned != scope { return errors . Errorf ( `Invalid scope %s: Uses non-canonical path format, perhaps try with path %s` , scope , cleaned ) } return nil } 
func BlobInfoFromSchema2Descriptor ( desc Schema2Descriptor ) types . BlobInfo { return types . BlobInfo { Digest : desc . Digest , Size : desc . Size , URLs : desc . URLs , MediaType : desc . MediaType , } } 
func Schema2FromManifest ( manifest [ ] byte ) ( * Schema2 , error ) { s2 := Schema2 { } if err := json . Unmarshal ( manifest , & s2 ) ; err != nil { return nil , err } return & s2 , nil } 
func Schema2FromComponents ( config Schema2Descriptor , layers [ ] Schema2Descriptor ) * Schema2 { return & Schema2 { SchemaVersion : 2 , MediaType : DockerV2Schema2MediaType , ConfigDescriptor : config , LayersDescriptors : layers , } } 
func ( m * Schema2 ) LayerInfos ( ) [ ] LayerInfo { blobs := [ ] LayerInfo { } for _ , layer := range m . LayersDescriptors { blobs = append ( blobs , LayerInfo { BlobInfo : BlobInfoFromSchema2Descriptor ( layer ) , EmptyLayer : false , } ) } return blobs } 
func ( m * Schema2 ) UpdateLayerInfos ( layerInfos [ ] types . BlobInfo ) error { if len ( m . LayersDescriptors ) != len ( layerInfos ) { return errors . Errorf ( " " , len ( m . LayersDescriptors ) , len ( layerInfos ) ) } original := m . LayersDescriptors m . LayersDescriptors = make ( [ ] Schema2Descriptor , len ( layerInfos ) ) for i , info := range layerInfos { m . LayersDescriptors [ i ] . MediaType = original [ i ] . MediaType m . LayersDescriptors [ i ] . Digest = info . Digest m . LayersDescriptors [ i ] . Size = info . Size m . LayersDescriptors [ i ] . URLs = info . URLs } return nil } 
func ( m * Schema2 ) Inspect ( configGetter func ( types . BlobInfo ) ( [ ] byte , error ) ) ( * types . ImageInspectInfo , error ) { config , err := configGetter ( m . ConfigInfo ( ) ) if err != nil { return nil , err } s2 := & Schema2Image { } if err := json . Unmarshal ( config , s2 ) ; err != nil { return nil , err } i := & types . ImageInspectInfo { Tag : " " , Created : & s2 . Created , DockerVersion : s2 . DockerVersion , Architecture : s2 . Architecture , Os : s2 . OS , Layers : layerInfosToStrings ( m . LayerInfos ( ) ) , } if s2 . Config != nil { i . Labels = s2 . Config . Labels } return i , nil } 
func ( m * Schema2 ) ImageID ( [ ] digest . Digest ) ( string , error ) { if err := m . ConfigDescriptor . Digest . Validate ( ) ; err != nil { return " " , err } return m . ConfigDescriptor . Digest . Hex ( ) , nil } 
func SetAuthentication ( sys * types . SystemContext , registry , username , password string ) error { return modifyJSON ( sys , func ( auths * dockerConfigFile ) ( bool , error ) { if ch , exists := auths . CredHelpers [ registry ] ; exists { return false , setAuthToCredHelper ( ch , registry , username , password ) } creds := base64 . StdEncoding . EncodeToString ( [ ] byte ( username + " " + password ) ) newCreds := dockerAuthConfig { Auth : creds } auths . AuthConfigs [ registry ] = newCreds return true , nil } ) } 
func GetAuthentication ( sys * types . SystemContext , registry string ) ( string , string , error ) { if sys != nil && sys . DockerAuthConfig != nil { return sys . DockerAuthConfig . Username , sys . DockerAuthConfig . Password , nil } dockerLegacyPath := filepath . Join ( homedir . Get ( ) , dockerLegacyHomePath ) var paths [ ] string pathToAuth , err := getPathToAuth ( sys ) if err == nil { paths = append ( paths , pathToAuth ) } else { } paths = append ( paths , filepath . Join ( homedir . Get ( ) , dockerHomePath ) , dockerLegacyPath ) for _ , path := range paths { legacyFormat := path == dockerLegacyPath username , password , err := findAuthentication ( registry , path , legacyFormat ) if err != nil { return " " , " " , err } if username != " " && password != " " { return username , password , nil } } return " " , " " , nil } 
func RemoveAuthentication ( sys * types . SystemContext , registry string ) error { return modifyJSON ( sys , func ( auths * dockerConfigFile ) ( bool , error ) { } if _ , ok := auths . AuthConfigs [ registry ] ; ok { delete ( auths . AuthConfigs , registry ) } else if _ , ok := auths . AuthConfigs [ normalizeRegistry ( registry ) ] ; ok { delete ( auths . AuthConfigs , normalizeRegistry ( registry ) ) } else { return false , ErrNotLoggedIn } return true , nil } ) } 
func RemoveAllAuthentication ( sys * types . SystemContext ) error { return modifyJSON ( sys , func ( auths * dockerConfigFile ) ( bool , error ) { auths . CredHelpers = make ( map [ string ] string ) auths . AuthConfigs = make ( map [ string ] dockerAuthConfig ) return true , nil } ) } 
func getPathToAuth ( sys * types . SystemContext ) ( string , error ) { if sys != nil { if sys . AuthFilePath != " " { return sys . AuthFilePath , nil } if sys . RootForImplicitAbsolutePaths != " " { return filepath . Join ( sys . RootForImplicitAbsolutePaths , fmt . Sprintf ( defaultPerUIDPathFormat , os . Getuid ( ) ) ) , nil } } runtimeDir := os . Getenv ( " " ) if runtimeDir != " " { if os . IsNotExist ( err ) { } return filepath . Join ( runtimeDir , xdgRuntimeDirPath ) , nil } return fmt . Sprintf ( defaultPerUIDPathFormat , os . Getuid ( ) ) , nil } 
func readJSONFile ( path string , legacyFormat bool ) ( dockerConfigFile , error ) { var auths dockerConfigFile raw , err := ioutil . ReadFile ( path ) if err != nil { if os . IsNotExist ( err ) { auths . AuthConfigs = map [ string ] dockerAuthConfig { } return auths , nil } return dockerConfigFile { } , err } if legacyFormat { if err = json . Unmarshal ( raw , & auths . AuthConfigs ) ; err != nil { return dockerConfigFile { } , errors . Wrapf ( err , " " , path ) } return auths , nil } if err = json . Unmarshal ( raw , & auths ) ; err != nil { return dockerConfigFile { } , errors . Wrapf ( err , " " , path ) } return auths , nil } 
func modifyJSON ( sys * types . SystemContext , editor func ( auths * dockerConfigFile ) ( bool , error ) ) error { path , err := getPathToAuth ( sys ) if err != nil { return err } dir := filepath . Dir ( path ) if _ , err := os . Stat ( dir ) ; os . IsNotExist ( err ) { if err = os . MkdirAll ( dir , 0700 ) ; err != nil { return errors . Wrapf ( err , " " , dir ) } } auths , err := readJSONFile ( path , false ) if err != nil { return errors . Wrapf ( err , " " , path ) } updated , err := editor ( & auths ) if err != nil { return errors . Wrapf ( err , " " , path ) } if updated { newData , err := json . MarshalIndent ( auths , " " , " \t " ) if err != nil { return errors . Wrapf ( err , " " , path ) } if err = ioutil . WriteFile ( path , newData , 0755 ) ; err != nil { return errors . Wrapf ( err , " " , path ) } } return nil } 
func findAuthentication ( registry , path string , legacyFormat bool ) ( string , string , error ) { auths , err := readJSONFile ( path , legacyFormat ) if err != nil { return " " , " " , errors . Wrapf ( err , " " , path ) } } } normalizedAuths := map [ string ] dockerAuthConfig { } for k , v := range auths . AuthConfigs { normalizedAuths [ normalizeRegistry ( k ) ] = v } if val , exists := normalizedAuths [ registry ] ; exists { return decodeDockerAuth ( val . Auth ) } return " " , " " , nil } 
func convertToHostname ( url string ) string { stripped := url if strings . HasPrefix ( url , " " ) { stripped = strings . TrimPrefix ( url , " " ) } else if strings . HasPrefix ( url , " " ) { stripped = strings . TrimPrefix ( url , " " ) } nameParts := strings . SplitN ( stripped , " " , 2 ) return nameParts [ 0 ] } 
func ( is * tarballImageSource ) GetBlob ( ctx context . Context , blobinfo types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { } } reader , err := os . Open ( is . filenames [ i ] ) if err != nil { return nil , - 1 , fmt . Errorf ( " " , is . filenames [ i ] , err ) } return reader , is . blobSizes [ i ] , nil } } return nil , - 1 , fmt . Errorf ( " " , blobinfo . Digest . String ( ) ) } 
func ( is * tarballImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { if instanceDigest != nil { return nil , " " , fmt . Errorf ( " " , transportName ) } return is . manifest , imgspecv1 . MediaTypeImageManifest , nil } 
func ( * tarballImageSource ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { if instanceDigest != nil { return nil , fmt . Errorf ( " " , transportName ) } return nil , nil } 
func ( * tarballImageSource ) LayerInfosForCopy ( ctx context . Context ) ( [ ] types . BlobInfo , error ) { return nil , nil } 
func NewDestination ( dest io . Writer , ref reference . NamedTagged ) * Destination { repoTags := [ ] reference . NamedTagged { } if ref != nil { repoTags = append ( repoTags , ref ) } return & Destination { writer : dest , tar : tar . NewWriter ( dest ) , repoTags : repoTags , blobs : make ( map [ digest . Digest ] types . BlobInfo ) , } } 
func ( d * Destination ) AddRepoTags ( tags [ ] reference . NamedTagged ) { d . repoTags = append ( d . repoTags , tags ... ) } 
func ( d * Destination ) PutBlob ( ctx context . Context , stream io . Reader , inputInfo types . BlobInfo , cache types . BlobInfoCache , isConfig bool ) ( types . BlobInfo , error ) { streamCopy , err := ioutil . TempFile ( tmpdir . TemporaryDirectoryForBigFiles ( ) , " " ) if err != nil { return types . BlobInfo { } , err } defer os . Remove ( streamCopy . Name ( ) ) defer streamCopy . Close ( ) digester := digest . Canonical . Digester ( ) tee := io . TeeReader ( stream , digester . Hash ( ) ) if err != nil { return types . BlobInfo { } , err } _ , err = streamCopy . Seek ( 0 , os . SEEK_SET ) if err != nil { return types . BlobInfo { } , err } inputInfo . Size = size if inputInfo . Digest == " " { inputInfo . Digest = digester . Digest ( ) } stream = streamCopy logrus . Debugf ( " " ) } if err != nil { return types . BlobInfo { } , err } if ok { return reusedInfo , nil } if isConfig { buf , err := ioutil . ReadAll ( stream ) if err != nil { return types . BlobInfo { } , errors . Wrap ( err , " " ) } d . config = buf if err := d . sendFile ( inputInfo . Digest . Hex ( ) + " " , inputInfo . Size , bytes . NewReader ( buf ) ) ; err != nil { return types . BlobInfo { } , errors . Wrap ( err , " " ) } } else { } } d . blobs [ inputInfo . Digest ] = types . BlobInfo { Digest : inputInfo . Digest , Size : inputInfo . Size } return types . BlobInfo { Digest : inputInfo . Digest , Size : inputInfo . Size } , nil } 
func ( d * Destination ) TryReusingBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache , canSubstitute bool ) ( bool , types . BlobInfo , error ) { if info . Digest == " " { return false , types . BlobInfo { } , errors . Errorf ( " " ) } if blob , ok := d . blobs [ info . Digest ] ; ok { return true , types . BlobInfo { Digest : info . Digest , Size : blob . Size } , nil } return false , types . BlobInfo { } , nil } 
func ( d * Destination ) PutManifest ( ctx context . Context , m [ ] byte ) error { if err := json . Unmarshal ( m , & man ) ; err != nil { return errors . Wrap ( err , " " ) } if man . SchemaVersion != 2 || man . MediaType != manifest . DockerV2Schema2MediaType { return errors . Errorf ( " " ) } layerPaths , lastLayerID , err := d . writeLegacyLayerMetadata ( man . LayersDescriptors ) if err != nil { return err } if len ( man . LayersDescriptors ) > 0 { if err := d . createRepositoriesFile ( lastLayerID ) ; err != nil { return err } } repoTags := [ ] string { } for _ , tag := range d . repoTags { repoTags = append ( repoTags , refString ) } items := [ ] ManifestItem { { Config : man . ConfigDescriptor . Digest . Hex ( ) + " " , RepoTags : repoTags , Layers : layerPaths , Parent : " " , LayerSources : nil , } } itemsBytes , err := json . Marshal ( & items ) if err != nil { return err } } 
func ( d * Destination ) writeLegacyLayerMetadata ( layerDescriptors [ ] manifest . Schema2Descriptor ) ( layerPaths [ ] string , lastLayerID string , err error ) { var chainID digest . Digest lastLayerID = " " for i , l := range layerDescriptors { } else { chainID = digest . Canonical . FromString ( chainID . String ( ) + " " + l . Digest . String ( ) ) } physicalLayerPath := l . Digest . Hex ( ) + " " } b := [ ] byte ( " " ) if err := d . sendBytes ( filepath . Join ( layerID , legacyVersionFileName ) , b ) ; err != nil { return nil , " " , errors . Wrap ( err , " " ) } layerConfig [ " " ] = layerID } err := json . Unmarshal ( d . config , & config ) if err != nil { return nil , " " , errors . Wrap ( err , " " ) } for _ , attr := range [ 7 ] string { " " , " " , " " , " " , " " , " " , " " } { layerConfig [ attr ] = config [ attr ] } } b , err := json . Marshal ( layerConfig ) if err != nil { return nil , " " , errors . Wrap ( err , " " ) } if err := d . sendBytes ( filepath . Join ( layerID , legacyConfigFileName ) , b ) ; err != nil { return nil , " " , errors . Wrap ( err , " " ) } lastLayerID = layerID } return layerPaths , lastLayerID , nil } 
func ( d * Destination ) sendSymlink ( path string , target string ) error { hdr , err := tar . FileInfoHeader ( & tarFI { path : path , size : 0 , isSymlink : true } , target ) if err != nil { return nil } logrus . Debugf ( " " , path , target ) return d . tar . WriteHeader ( hdr ) } 
func ( d * Destination ) sendBytes ( path string , b [ ] byte ) error { return d . sendFile ( path , int64 ( len ( b ) ) , bytes . NewReader ( b ) ) } 
func ( d * Destination ) sendFile ( path string , expectedSize int64 , stream io . Reader ) error { hdr , err := tar . FileInfoHeader ( & tarFI { path : path , size : expectedSize } , " " ) if err != nil { return nil } logrus . Debugf ( " " , path ) if err := d . tar . WriteHeader ( hdr ) ; err != nil { return err } if err != nil { return err } if size != expectedSize { return errors . Errorf ( " " , path , expectedSize , size ) } return nil } 
func ( d * Destination ) PutSignatures ( ctx context . Context , signatures [ ] [ ] byte ) error { if len ( signatures ) != 0 { return errors . Errorf ( " " ) } return nil } 
func ( d * Destination ) Commit ( ctx context . Context ) error { return d . tar . Close ( ) } 
func imageMatchesRepo ( image * storage . Image , ref reference . Named ) bool { repo := ref . Name ( ) for _ , name := range image . Names { if named , err := reference . ParseNormalizedNamed ( name ) ; err == nil { if named . Name ( ) == repo { return true } } } return false } 
func ( s * storageReference ) resolveImage ( ) ( * storage . Image , error ) { var loadedImage * storage . Image if s . id == " " && s . named != nil { if image != nil && err == nil { loadedImage = image s . id = image . ID } } if s . id == " " && s . named != nil { if digested , ok := s . named . ( reference . Digested ) ; ok { if err == nil && len ( images ) > 0 { for _ , image := range images { if imageMatchesRepo ( image , s . named ) { loadedImage = image s . id = image . ID break } } } } } if s . id == " " { logrus . Debugf ( " " , s . StringWithinTransport ( ) ) return nil , errors . Wrapf ( ErrNoSuchImage , " " , s . StringWithinTransport ( ) ) } if loadedImage == nil { img , err := s . transport . store . Image ( s . id ) if err != nil { return nil , errors . Wrapf ( err , " " , s . id ) } loadedImage = img } if s . named != nil { if ! imageMatchesRepo ( loadedImage , s . named ) { logrus . Errorf ( " " , s . StringWithinTransport ( ) ) return nil , ErrNoSuchImage } } } break } } } } return loadedImage , nil } 
func ( s storageReference ) Transport ( ) types . ImageTransport { return & storageTransport { store : s . transport . store , defaultUIDMap : s . transport . defaultUIDMap , defaultGIDMap : s . transport . defaultGIDMap , } } 
func ( s storageReference ) StringWithinTransport ( ) string { optionsList := " " options := s . transport . store . GraphOptions ( ) if len ( options ) > 0 { optionsList = " " + strings . Join ( options , " " ) } res := " " + s . transport . store . GraphDriverName ( ) + " " + s . transport . store . GraphRoot ( ) + " " + s . transport . store . RunRoot ( ) + optionsList + " " if s . named != nil { res = res + s . named . String ( ) } if s . id != " " { res = res + " " + s . id } return res } 
func ( s storageReference ) PolicyConfigurationNamespaces ( ) [ ] string { storeSpec := " " + s . transport . store . GraphDriverName ( ) + " " + s . transport . store . GraphRoot ( ) + " " driverlessStoreSpec := " " + s . transport . store . GraphRoot ( ) + " " namespaces := [ ] string { } if s . named != nil { if s . id != " " { } tagged , isTagged := s . named . ( reference . Tagged ) _ , isDigested := s . named . ( reference . Digested ) if isTagged && isDigested { } components := strings . Split ( s . named . Name ( ) , " " ) for len ( components ) > 0 { namespaces = append ( namespaces , storeSpec + strings . Join ( components , " " ) ) components = components [ : len ( components ) - 1 ] } } namespaces = append ( namespaces , storeSpec ) namespaces = append ( namespaces , driverlessStoreSpec ) return namespaces } 
func ( s storageReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { return newImage ( ctx , sys , s ) } 
func DockerReferenceIdentity ( ref reference . Named ) ( string , error ) { res := ref . Name ( ) tagged , isTagged := ref . ( reference . NamedTagged ) digested , isDigested := ref . ( reference . Canonical ) switch { case isTagged && isDigested : case ! isTagged && ! isDigested : case isTagged : res = res + " " + tagged . Tag ( ) case isDigested : res = res + " " + digested . Digest ( ) . String ( ) default : } return res , nil } 
func DockerReferenceNamespaces ( ref reference . Named ) [ ] string { name := ref . Name ( ) for { res = append ( res , name ) lastSlash := strings . LastIndex ( name , " " ) if lastSlash == - 1 { break } name = name [ : lastSlash ] } return res } 
func GzipDecompressor ( r io . Reader ) ( io . ReadCloser , error ) { return pgzip . NewReader ( r ) } 
func Bzip2Decompressor ( r io . Reader ) ( io . ReadCloser , error ) { return ioutil . NopCloser ( bzip2 . NewReader ( r ) ) , nil } 
func XzDecompressor ( r io . Reader ) ( io . ReadCloser , error ) { r , err := xz . NewReader ( r ) if err != nil { return nil , err } return ioutil . NopCloser ( r ) , nil } 
func DetectCompression ( input io . Reader ) ( DecompressorFunc , io . Reader , error ) { buffer := [ 8 ] byte { } n , err := io . ReadAtLeast ( input , buffer [ : ] , len ( buffer ) ) if err != nil && err != io . EOF && err != io . ErrUnexpectedEOF { } var decompressor DecompressorFunc for name , algo := range compressionAlgos { if bytes . HasPrefix ( buffer [ : n ] , algo . prefix ) { logrus . Debugf ( " " , name ) decompressor = algo . decompressor break } } if decompressor == nil { logrus . Debugf ( " " ) } return decompressor , io . MultiReader ( bytes . NewReader ( buffer [ : n ] ) , input ) , nil } 
func AutoDecompress ( stream io . Reader ) ( io . ReadCloser , bool , error ) { decompressor , stream , err := DetectCompression ( stream ) if err != nil { return nil , false , errors . Wrapf ( err , " " ) } var res io . ReadCloser if decompressor != nil { res , err = decompressor ( stream ) if err != nil { return nil , false , errors . Wrapf ( err , " " ) } } else { res = ioutil . NopCloser ( stream ) } return res , decompressor != nil , nil } 
func newImageDestination ( sys * types . SystemContext , ref dockerReference ) ( types . ImageDestination , error ) { c , err := newDockerClientFromRef ( sys , ref , true , " " ) if err != nil { return nil , err } return & dockerImageDestination { ref : ref , c : c , } , nil } 
func ( d * dockerImageDestination ) SupportsSignatures ( ctx context . Context ) error { if err := d . c . detectProperties ( ctx ) ; err != nil { return err } switch { case d . c . signatureBase != nil : return nil case d . c . supportsSignatures : return nil default : return errors . Errorf ( " " ) } } 
func ( d * dockerImageDestination ) PutBlob ( ctx context . Context , stream io . Reader , inputInfo types . BlobInfo , cache types . BlobInfoCache , isConfig bool ) ( types . BlobInfo , error ) { if inputInfo . Digest . String ( ) != " " { if err != nil { return types . BlobInfo { } , err } if haveBlob { return reusedInfo , nil } } logrus . Debugf ( " " , uploadPath ) res , err := d . c . makeRequest ( ctx , " " , uploadPath , nil , nil , v2Auth , nil ) if err != nil { return types . BlobInfo { } , err } defer res . Body . Close ( ) if res . StatusCode != http . StatusAccepted { logrus . Debugf ( " " , * res ) return types . BlobInfo { } , errors . Wrapf ( client . HandleErrorResponse ( res ) , " " , uploadPath , d . c . registry ) } uploadLocation , err := res . Location ( ) if err != nil { return types . BlobInfo { } , errors . Wrap ( err , " " ) } digester := digest . Canonical . Digester ( ) sizeCounter := & sizeCounter { } tee := io . TeeReader ( stream , io . MultiWriter ( digester . Hash ( ) , sizeCounter ) ) res , err = d . c . makeRequestToResolvedURL ( ctx , " " , uploadLocation . String ( ) , map [ string ] [ ] string { " " : { " " } } , tee , inputInfo . Size , v2Auth , nil ) if err != nil { logrus . Debugf ( " " , res ) return types . BlobInfo { } , err } defer res . Body . Close ( ) computedDigest := digester . Digest ( ) uploadLocation , err = res . Location ( ) if err != nil { return types . BlobInfo { } , errors . Wrap ( err , " " ) } uploadLocation . RawQuery = locationQuery . Encode ( ) res , err = d . c . makeRequestToResolvedURL ( ctx , " " , uploadLocation . String ( ) , map [ string ] [ ] string { " " : { " " } } , nil , - 1 , v2Auth , nil ) if err != nil { return types . BlobInfo { } , err } defer res . Body . Close ( ) if res . StatusCode != http . StatusCreated { logrus . Debugf ( " " , * res ) return types . BlobInfo { } , errors . Wrapf ( client . HandleErrorResponse ( res ) , " " , uploadLocation ) } logrus . Debugf ( " " , computedDigest ) cache . RecordKnownLocation ( d . ref . Transport ( ) , bicTransportScope ( d . ref ) , computedDigest , newBICLocationReference ( d . ref ) ) return types . BlobInfo { Digest : computedDigest , Size : sizeCounter . size } , nil } 
func ( d * dockerImageDestination ) blobExists ( ctx context . Context , repo reference . Named , digest digest . Digest , extraScope * authScope ) ( bool , int64 , error ) { checkPath := fmt . Sprintf ( blobsPath , reference . Path ( repo ) , digest . String ( ) ) logrus . Debugf ( " " , checkPath ) res , err := d . c . makeRequest ( ctx , " " , checkPath , nil , nil , v2Auth , extraScope ) if err != nil { return false , - 1 , err } defer res . Body . Close ( ) switch res . StatusCode { case http . StatusOK : logrus . Debugf ( " " ) return true , getBlobSize ( res ) , nil case http . StatusUnauthorized : logrus . Debugf ( " " ) return false , - 1 , errors . Wrapf ( client . HandleErrorResponse ( res ) , " " , digest , repo . Name ( ) ) case http . StatusNotFound : logrus . Debugf ( " " ) return false , - 1 , nil default : return false , - 1 , errors . Errorf ( " " , reference . Path ( d . ref . ref ) , res . StatusCode , http . StatusText ( res . StatusCode ) ) } } 
func ( d * dockerImageDestination ) mountBlob ( ctx context . Context , srcRepo reference . Named , srcDigest digest . Digest , extraScope * authScope ) error { u := url . URL { Path : fmt . Sprintf ( blobUploadPath , reference . Path ( d . ref . ref ) ) , RawQuery : url . Values { " " : { srcDigest . String ( ) } , " " : { reference . Path ( srcRepo ) } , } . Encode ( ) , } mountPath := u . String ( ) logrus . Debugf ( " " , mountPath ) res , err := d . c . makeRequest ( ctx , " " , mountPath , nil , nil , v2Auth , extraScope ) if err != nil { return err } defer res . Body . Close ( ) switch res . StatusCode { case http . StatusCreated : logrus . Debugf ( " " ) return nil case http . StatusAccepted : if err != nil { return errors . Wrap ( err , " " ) } logrus . Debugf ( " " , uploadLocation . String ( ) ) res2 , err := d . c . makeRequestToResolvedURL ( ctx , " " , uploadLocation . String ( ) , nil , nil , - 1 , v2Auth , extraScope ) if err != nil { logrus . Debugf ( " " , err ) } else { defer res2 . Body . Close ( ) if res2 . StatusCode != http . StatusNoContent { logrus . Debugf ( " " , http . StatusText ( res . StatusCode ) ) } } default : logrus . Debugf ( " " , * res ) return errors . Wrapf ( client . HandleErrorResponse ( res ) , " " , srcDigest , srcRepo . Name ( ) , d . ref . ref . Name ( ) ) } } 
func ( d * dockerImageDestination ) TryReusingBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache , canSubstitute bool ) ( bool , types . BlobInfo , error ) { if info . Digest == " " { return false , types . BlobInfo { } , errors . Errorf ( `"Can not check for a blob with unknown digest` ) } // First, check whether the blob happens to already exist at the destination. exists , size , err := d . blobExists ( ctx , d . ref . ref , info . Digest , nil ) if err != nil { return false , types . BlobInfo { } , err } if exists { cache . RecordKnownLocation ( d . ref . Transport ( ) , bicTransportScope ( d . ref ) , info . Digest , newBICLocationReference ( d . ref ) ) return true , types . BlobInfo { Digest : info . Digest , Size : size } , nil } // Then try reusing blobs from other locations. for _ , candidate := range cache . CandidateLocations ( d . ref . Transport ( ) , bicTransportScope ( d . ref ) , info . Digest , canSubstitute ) { candidateRepo , err := parseBICLocationReference ( candidate . Location ) if err != nil { logrus . Debugf ( " " , err ) continue } logrus . Debugf ( " " , candidate . Digest . String ( ) , candidateRepo . Name ( ) ) // Sanity checks: if reference . Domain ( candidateRepo ) != reference . Domain ( d . ref . ref ) { logrus . Debugf ( " " , reference . Domain ( candidateRepo ) , reference . Domain ( d . ref . ref ) ) continue } if candidateRepo . Name ( ) == d . ref . ref . Name ( ) && candidate . Digest == info . Digest { logrus . Debug ( " " ) continue } // Whatever happens here, don't abort the entire operation. It's likely we just don't have permissions, and if it is a critical network error, we will find out soon enough anyway. // Checking candidateRepo, and mounting from it, requires an // expanded token scope. extraScope := & authScope { remoteName : reference . Path ( candidateRepo ) , actions : " " , } // This existence check is not, strictly speaking, necessary: We only _really_ need it to get the blob size, and we could record that in the cache instead. // But a "failed" d.mountBlob currently leaves around an unterminated server-side upload, which we would try to cancel. // So, without this existence check, it would be 1 request on success, 2 requests on failure; with it, it is 2 requests on success, 1 request on failure. // On success we avoid the actual costly upload; so, in a sense, the success case is "free", but failures are always costly. // Even worse, docker/distribution does not actually reasonably implement canceling uploads // (it would require a "delete" action in the token, and Quay does not give that to anyone, so we can't ask); // so, be a nice client and don't create unnecesary upload sessions on the server. exists , size , err := d . blobExists ( ctx , candidateRepo , candidate . Digest , extraScope ) if err != nil { logrus . Debugf ( " " , err ) continue } if ! exists { // FIXME? Should we drop the blob from cache here (and elsewhere?)? continue // logrus.Debug() already happened in blobExists } if candidateRepo . Name ( ) != d . ref . ref . Name ( ) { if err := d . mountBlob ( ctx , candidateRepo , candidate . Digest , extraScope ) ; err != nil { logrus . Debugf ( " " , err ) continue } } cache . RecordKnownLocation ( d . ref . Transport ( ) , bicTransportScope ( d . ref ) , candidate . Digest , newBICLocationReference ( d . ref ) ) return true , types . BlobInfo { Digest : candidate . Digest , Size : size } , nil } return false , types . BlobInfo { } , nil } 
func ( d * dockerImageDestination ) PutManifest ( ctx context . Context , m [ ] byte ) error { digest , err := manifest . Digest ( m ) if err != nil { return err } d . manifestDigest = digest refTail , err := d . ref . tagOrDigest ( ) if err != nil { return err } path := fmt . Sprintf ( manifestPath , reference . Path ( d . ref . ref ) , refTail ) headers := map [ string ] [ ] string { } mimeType := manifest . GuessMIMEType ( m ) if mimeType != " " { headers [ " " ] = [ ] string { mimeType } } res , err := d . c . makeRequest ( ctx , " " , path , headers , bytes . NewReader ( m ) , v2Auth , nil ) if err != nil { return err } defer res . Body . Close ( ) if ! successStatus ( res . StatusCode ) { err = errors . Wrapf ( client . HandleErrorResponse ( res ) , " " , refTail , d . ref . ref . Name ( ) ) if isManifestInvalidError ( errors . Cause ( err ) ) { err = types . ManifestTypeRejectedError { Err : err } } return err } return nil } 
func isManifestInvalidError ( err error ) bool { errors , ok := err . ( errcode . Errors ) if ! ok || len ( errors ) == 0 { return false } err = errors [ 0 ] ec , ok := err . ( errcode . ErrorCoder ) if ! ok { return false } switch ec . ErrorCode ( ) { default : return false } } 
func ( d * dockerImageDestination ) putSignaturesToLookaside ( signatures [ ] [ ] byte ) error { } if d . manifestDigest . String ( ) == " " { } if url == nil { return errors . Errorf ( " " ) } err := d . putOneSignature ( url , signature ) if err != nil { return err } } if url == nil { return errors . Errorf ( " " ) } missing , err := d . c . deleteOneSignature ( url ) if err != nil { return err } if missing { break } } return nil } 
func ( d * dockerImageDestination ) putOneSignature ( url * url . URL , signature [ ] byte ) error { switch url . Scheme { case " " : logrus . Debugf ( " " , url . Path ) err := os . MkdirAll ( filepath . Dir ( url . Path ) , 0755 ) if err != nil { return err } err = ioutil . WriteFile ( url . Path , signature , 0644 ) if err != nil { return err } return nil case " " , " " : return errors . Errorf ( " " , url . Scheme , url . String ( ) ) default : return errors . Errorf ( " " , url . String ( ) ) } } 
func ( c * dockerClient ) deleteOneSignature ( url * url . URL ) ( missing bool , err error ) { switch url . Scheme { case " " : logrus . Debugf ( " " , url . Path ) err := os . Remove ( url . Path ) if err != nil && os . IsNotExist ( err ) { return true , nil } return false , err case " " , " " : return false , errors . Errorf ( " " , url . Scheme , url . String ( ) ) default : return false , errors . Errorf ( " " , url . String ( ) ) } } 
func ( d * dockerImageDestination ) putSignaturesToAPIExtension ( ctx context . Context , signatures [ ] [ ] byte ) error { } if d . manifestDigest . String ( ) == " " { } if err != nil { return err } existingSigNames := map [ string ] struct { } { } for _ , sig := range existingSignatures . Signatures { existingSigNames [ sig . Name ] = struct { } { } } sigExists : for _ , newSig := range signatures { for _ , existingSig := range existingSignatures . Signatures { if existingSig . Version == extensionSignatureSchemaVersion && existingSig . Type == extensionSignatureTypeAtomic && bytes . Equal ( existingSig . Content , newSig ) { continue sigExists } } for { randBytes := make ( [ ] byte , 16 ) n , err := rand . Read ( randBytes ) if err != nil || n != 16 { return errors . Wrapf ( err , " " , n ) } signatureName = fmt . Sprintf ( " " , d . manifestDigest . String ( ) , randBytes ) if _ , ok := existingSigNames [ signatureName ] ; ! ok { break } } sig := extensionSignature { Version : extensionSignatureSchemaVersion , Name : signatureName , Type : extensionSignatureTypeAtomic , Content : newSig , } body , err := json . Marshal ( sig ) if err != nil { return err } path := fmt . Sprintf ( extensionsSignaturePath , reference . Path ( d . ref . ref ) , d . manifestDigest . String ( ) ) res , err := d . c . makeRequest ( ctx , " " , path , nil , bytes . NewReader ( body ) , v2Auth , nil ) if err != nil { return err } defer res . Body . Close ( ) if res . StatusCode != http . StatusCreated { body , err := ioutil . ReadAll ( res . Body ) if err == nil { logrus . Debugf ( " " , string ( body ) ) } logrus . Debugf ( " " , res . StatusCode , res ) return errors . Wrapf ( client . HandleErrorResponse ( res ) , " " , path , d . c . registry ) } } return nil } 
func bicTransportScope ( ref dockerReference ) types . BICTransportScope { } 
func newBICLocationReference ( ref dockerReference ) types . BICLocationReference { } 
func parseBICLocationReference ( lr types . BICLocationReference ) ( reference . Named , error ) { return reference . ParseNormalizedNamed ( lr . Opaque ) } 
func NewSourceFromFile ( path string ) ( * Source , error ) { file , err := os . Open ( path ) if err != nil { return nil , errors . Wrapf ( err , " " , path ) } defer file . Close ( ) if err != nil { return nil , errors . Wrapf ( err , " " , path ) } defer stream . Close ( ) if ! isCompressed { return & Source { tarPath : path , } , nil } return NewSourceFromStream ( stream ) } 
func NewSourceFromStream ( inputStream io . Reader ) ( * Source , error ) { if err != nil { return nil , errors . Wrap ( err , " " ) } defer tarCopyFile . Close ( ) succeeded := false defer func ( ) { if ! succeeded { os . Remove ( tarCopyFile . Name ( ) ) } } ( ) if err != nil { return nil , errors . Wrap ( err , " " ) } defer uncompressedStream . Close ( ) } succeeded = true return & Source { tarPath : tarCopyFile . Name ( ) , removeTarPathOnClose : true , } , nil } 
func ( s * Source ) openTarComponent ( componentPath string ) ( io . ReadCloser , error ) { f , err := os . Open ( s . tarPath ) if err != nil { return nil , err } succeeded := false defer func ( ) { if ! succeeded { f . Close ( ) } } ( ) tarReader , header , err := findTarComponent ( f , componentPath ) if err != nil { return nil , err } if header == nil { return nil , os . ErrNotExist } if header . FileInfo ( ) . Mode ( ) & os . ModeType == os . ModeSymlink { } if err != nil { return nil , err } if header == nil { return nil , os . ErrNotExist } } if ! header . FileInfo ( ) . Mode ( ) . IsRegular ( ) { return nil , errors . Errorf ( " " , header . Name ) } succeeded = true return & tarReadCloser { Reader : tarReader , backingFile : f } , nil } 
func findTarComponent ( inputFile io . Reader , path string ) ( * tar . Reader , * tar . Header , error ) { t := tar . NewReader ( inputFile ) for { h , err := t . Next ( ) if err == io . EOF { break } if err != nil { return nil , nil , err } if h . Name == path { return t , h , nil } } return nil , nil , nil } 
func ( s * Source ) readTarComponent ( path string ) ( [ ] byte , error ) { file , err := s . openTarComponent ( path ) if err != nil { return nil , errors . Wrapf ( err , " " , path ) } defer file . Close ( ) bytes , err := ioutil . ReadAll ( file ) if err != nil { return nil , err } return bytes , nil } 
func ( s * Source ) ensureCachedDataIsPresent ( ) error { s . cacheDataLock . Do ( func ( ) { if err != nil { s . cacheDataResult = err return } return } if err != nil { s . cacheDataResult = err return } var parsedConfig manifest . Schema2Image if err := json . Unmarshal ( configBytes , & parsedConfig ) ; err != nil { s . cacheDataResult = errors . Wrapf ( err , " " , tarManifest [ 0 ] . Config ) return } knownLayers , err := s . prepareLayerData ( & tarManifest [ 0 ] , & parsedConfig ) if err != nil { s . cacheDataResult = err return } s . configBytes = configBytes s . configDigest = digest . FromBytes ( configBytes ) s . orderedDiffIDList = parsedConfig . RootFS . DiffIDs s . knownLayers = knownLayers } ) return s . cacheDataResult } 
func ( s * Source ) loadTarManifest ( ) ( [ ] ManifestItem , error ) { if err != nil { return nil , err } var items [ ] ManifestItem if err := json . Unmarshal ( bytes , & items ) ; err != nil { return nil , errors . Wrap ( err , " " ) } return items , nil } 
func ( s * Source ) Close ( ) error { if s . removeTarPathOnClose { return os . Remove ( s . tarPath ) } return nil } 
func ( s * Source ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { if instanceDigest != nil { } if s . generatedManifest == nil { if err := s . ensureCachedDataIsPresent ( ) ; err != nil { return nil , " " , err } m := manifest . Schema2 { SchemaVersion : 2 , MediaType : manifest . DockerV2Schema2MediaType , ConfigDescriptor : manifest . Schema2Descriptor { MediaType : manifest . DockerV2Schema2ConfigMediaType , Size : int64 ( len ( s . configBytes ) ) , Digest : s . configDigest , } , LayersDescriptors : [ ] manifest . Schema2Descriptor { } , } for _ , diffID := range s . orderedDiffIDList { li , ok := s . knownLayers [ diffID ] if ! ok { return nil , " " , errors . Errorf ( " " , diffID ) } m . LayersDescriptors = append ( m . LayersDescriptors , manifest . Schema2Descriptor { Digest : diffID , } manifestBytes , err := json . Marshal ( & m ) if err != nil { return nil , " " , err } s . generatedManifest = manifestBytes } return s . generatedManifest , manifest . DockerV2Schema2MediaType , nil } 
func ( s * Source ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { if err := s . ensureCachedDataIsPresent ( ) ; err != nil { return nil , 0 , err } if info . Digest == s . configDigest { } if li , ok := s . knownLayers [ info . Digest ] ; ok { if err != nil { return nil , 0 , err } closeUnderlyingStream := true defer func ( ) { if closeUnderlyingStream { underlyingStream . Close ( ) } } ( ) if err != nil { return nil , 0 , errors . Wrapf ( err , " " , info . Digest ) } newStream := uncompressedReadCloser { Reader : uncompressedStream , underlyingCloser : underlyingStream . Close , uncompressedCloser : uncompressedStream . Close , } closeUnderlyingStream = false return newStream , li . size , nil } return nil , 0 , errors . Errorf ( " " , info . Digest ) } 
func ( s * Source ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { if instanceDigest != nil { } return [ ] [ ] byte { } , nil } 
func newImageDestination ( ctx context . Context , sys * types . SystemContext , ref daemonReference ) ( types . ImageDestination , error ) { if ref . ref == nil { return nil , errors . Errorf ( " " , ref . StringWithinTransport ( ) ) } namedTaggedRef , ok := ref . ref . ( reference . NamedTagged ) if ! ok { return nil , errors . Errorf ( " " , ref . StringWithinTransport ( ) ) } var mustMatchRuntimeOS = true if sys != nil && sys . DockerDaemonHost != client . DefaultDockerHost { mustMatchRuntimeOS = false } c , err := newDockerClient ( sys ) if err != nil { return nil , errors . Wrap ( err , " " ) } reader , writer := io . Pipe ( ) goroutineContext , goroutineCancel := context . WithCancel ( ctx ) go imageLoadGoroutine ( goroutineContext , c , reader , statusChannel ) return & daemonImageDestination { ref : ref , mustMatchRuntimeOS : mustMatchRuntimeOS , Destination : tarfile . NewDestination ( writer , namedTaggedRef ) , goroutineCancel : goroutineCancel , statusChannel : statusChannel , writer : writer , committed : false , } , nil } 
func imageLoadGoroutine ( ctx context . Context , c * client . Client , reader * io . PipeReader , statusChannel chan <- error ) { err := errors . New ( " " ) defer func ( ) { logrus . Debugf ( " " , err ) statusChannel <- err } ( ) defer func ( ) { if err == nil { reader . Close ( ) } else { reader . CloseWithError ( err ) } } ( ) resp , err := c . ImageLoad ( ctx , reader , true ) if err != nil { err = errors . Wrap ( err , " " ) return } defer resp . Body . Close ( ) } 
func ( d * daemonImageDestination ) Close ( ) error { if ! d . committed { logrus . Debugf ( " " ) } d . goroutineCancel ( ) return nil } 
func ( d * daemonImageDestination ) Commit ( ctx context . Context ) error { logrus . Debugf ( " " ) if err := d . Destination . Commit ( ctx ) ; err != nil { return err } if err := d . writer . Close ( ) ; err != nil { return err } d . committed = true logrus . Debugf ( " " ) select { case <- ctx . Done ( ) : return ctx . Err ( ) case err := <- d . statusChannel : return err } } 
func ( t ociArchiveTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return ParseReference ( reference ) } 
func NewReference ( file , image string ) ( types . ImageReference , error ) { resolved , err := explicitfilepath . ResolvePathToFullyExplicit ( file ) if err != nil { return nil , err } if err := internal . ValidateOCIPath ( file ) ; err != nil { return nil , err } if err := internal . ValidateImageName ( image ) ; err != nil { return nil , err } return ociArchiveReference { file : file , resolvedFile : resolved , image : image } , nil } 
func ( ref ociArchiveReference ) StringWithinTransport ( ) string { return fmt . Sprintf ( " " , ref . file , ref . image ) } 
func ( ref ociArchiveReference ) PolicyConfigurationNamespaces ( ) [ ] string { res := [ ] string { } path := ref . resolvedFile for { lastSlash := strings . LastIndex ( path , " " ) } res = append ( res , path ) path = path [ : lastSlash ] } return res } 
func ( ref ociArchiveReference ) DeleteImage ( ctx context . Context , sys * types . SystemContext ) error { return errors . Errorf ( " " ) } 
func createOCIRef ( image string ) ( tempDirOCIRef , error ) { dir , err := ioutil . TempDir ( tmpdir . TemporaryDirectoryForBigFiles ( ) , " " ) if err != nil { return tempDirOCIRef { } , errors . Wrapf ( err , " " ) } ociRef , err := ocilayout . NewReference ( dir , image ) if err != nil { return tempDirOCIRef { } , err } tempDirRef := tempDirOCIRef { tempDirectory : dir , ociRefExtracted : ociRef } return tempDirRef , nil } 
func createUntarTempDir ( ref ociArchiveReference ) ( tempDirOCIRef , error ) { tempDirRef , err := createOCIRef ( ref . image ) if err != nil { return tempDirOCIRef { } , errors . Wrap ( err , " " ) } src := ref . resolvedFile dst := tempDirRef . tempDirectory } return tempDirOCIRef { } , errors . Wrapf ( err , " " , tempDirRef . tempDirectory ) } return tempDirRef , nil } 
func destructivelyPrioritizeReplacementCandidatesWithMax ( cs [ ] CandidateWithTime , primaryDigest , uncompressedDigest digest . Digest , maxCandidates int ) [ ] types . BICReplacementCandidate { resLength := len ( cs ) if resLength > maxCandidates { resLength = maxCandidates } res := make ( [ ] types . BICReplacementCandidate , resLength ) for i := range res { res [ i ] = cs [ i ] . Candidate } return res } 
func DestructivelyPrioritizeReplacementCandidates ( cs [ ] CandidateWithTime , primaryDigest , uncompressedDigest digest . Digest ) [ ] types . BICReplacementCandidate { return destructivelyPrioritizeReplacementCandidatesWithMax ( cs , primaryDigest , uncompressedDigest , replacementAttempts ) } 
func newImageDestination ( ref ostreeReference , tmpDirPath string ) ( types . ImageDestination , error ) { tmpDirPath = filepath . Join ( tmpDirPath , ref . branchName ) if err := ensureDirectoryExists ( tmpDirPath ) ; err != nil { return nil , err } return & ostreeImageDestination { ref , " " , manifestSchema { } , tmpDirPath , map [ string ] * blobToImport { } , " " , 0 , nil } , nil } 
func ( d * ostreeImageDestination ) Close ( ) error { if d . repo != nil { C . g_object_unref ( C . gpointer ( d . repo ) ) } return os . RemoveAll ( d . tmpDirPath ) } 
func ( d * ostreeImageDestination ) PutBlob ( ctx context . Context , stream io . Reader , inputInfo types . BlobInfo , cache types . BlobInfoCache , isConfig bool ) ( types . BlobInfo , error ) { tmpDir , err := ioutil . TempDir ( d . tmpDirPath , " " ) if err != nil { return types . BlobInfo { } , err } blobPath := filepath . Join ( tmpDir , " " ) blobFile , err := os . Create ( blobPath ) if err != nil { return types . BlobInfo { } , err } defer blobFile . Close ( ) digester := digest . Canonical . Digester ( ) tee := io . TeeReader ( stream , digester . Hash ( ) ) if err != nil { return types . BlobInfo { } , err } computedDigest := digester . Digest ( ) if inputInfo . Size != - 1 && size != inputInfo . Size { return types . BlobInfo { } , errors . Errorf ( " " , computedDigest , inputInfo . Size , size ) } if err := blobFile . Sync ( ) ; err != nil { return types . BlobInfo { } , err } hash := computedDigest . Hex ( ) d . blobs [ hash ] = & blobToImport { Size : size , Digest : computedDigest , BlobPath : blobPath } return types . BlobInfo { Digest : computedDigest , Size : size } , nil } 
func ( d * ostreeImageDestination ) TryReusingBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache , canSubstitute bool ) ( bool , types . BlobInfo , error ) { if d . repo == nil { repo , err := openRepo ( d . ref . repo ) if err != nil { return false , types . BlobInfo { } , err } d . repo = repo } branch := fmt . Sprintf ( " " , info . Digest . Hex ( ) ) found , data , err := readMetadata ( d . repo , branch , " " ) if err != nil || ! found { return found , types . BlobInfo { } , err } found , data , err = readMetadata ( d . repo , branch , " " ) if err != nil || ! found { return found , types . BlobInfo { } , err } found , data , err = readMetadata ( d . repo , branch , " " ) if err != nil || ! found { return found , types . BlobInfo { } , err } size , err := strconv . ParseInt ( data , 10 , 64 ) if err != nil { return false , types . BlobInfo { } , err } return true , types . BlobInfo { Digest : info . Digest , Size : size } , nil } 
func ( d * ostreeImageDestination ) PutManifest ( ctx context . Context , manifestBlob [ ] byte ) error { d . manifest = string ( manifestBlob ) if err := json . Unmarshal ( manifestBlob , & d . schema ) ; err != nil { return err } manifestPath := filepath . Join ( d . tmpDirPath , d . ref . manifestPath ( ) ) if err := ensureParentDirectoryExists ( manifestPath ) ; err != nil { return err } digest , err := manifest . Digest ( manifestBlob ) if err != nil { return err } d . digest = digest return ioutil . WriteFile ( manifestPath , manifestBlob , 0644 ) } 
func ResolvePathToFullyExplicit ( path string ) ( string , error ) { switch _ , err := os . Lstat ( path ) ; { case err == nil : return resolveExistingPathToFullyExplicit ( path ) case os . IsNotExist ( err ) : parent , file := filepath . Split ( path ) resolvedParent , err := resolveExistingPathToFullyExplicit ( parent ) if err != nil { return " " , err } if file == " " || file == " " { } resolvedPath := filepath . Join ( resolvedParent , file ) if cleanedResolvedPath != resolvedPath { } return resolvedPath , nil default : } } 
func resolveExistingPathToFullyExplicit ( path string ) ( string , error ) { resolved , err := filepath . Abs ( path ) if err != nil { return " " , err } resolved , err = filepath . EvalSymlinks ( resolved ) if err != nil { return " " , err } return filepath . Clean ( resolved ) , nil } 
func newImageDestination ( ref dirReference , compress bool ) ( types . ImageDestination , error ) { d := & dirImageDestination { ref : ref , compress : compress } if err != nil { return nil , errors . Wrapf ( err , " " , d . ref . resolvedPath ) } if dirExists { isEmpty , err := isDirEmpty ( d . ref . resolvedPath ) if err != nil { return nil , err } if ! isEmpty { versionExists , err := pathExists ( d . ref . versionPath ( ) ) if err != nil { return nil , errors . Wrapf ( err , " " , d . ref . versionPath ( ) ) } if versionExists { contents , err := ioutil . ReadFile ( d . ref . versionPath ( ) ) if err != nil { return nil , err } } } else { return nil , ErrNotContainerImageDir } } logrus . Debugf ( " " , d . ref . resolvedPath ) } } else { } } if err != nil { return nil , errors . Wrapf ( err , " " , d . ref . versionPath ( ) ) } return d , nil } 
func ( d * dirImageDestination ) PutManifest ( ctx context . Context , manifest [ ] byte ) error { return ioutil . WriteFile ( d . ref . manifestPath ( ) , manifest , 0644 ) } 
func isDirEmpty ( path string ) ( bool , error ) { files , err := ioutil . ReadDir ( path ) if err != nil { return false , err } return len ( files ) == 0 , nil } 
func removeDirContents ( path string ) error { files , err := ioutil . ReadDir ( path ) if err != nil { return err } for _ , file := range files { if err := os . RemoveAll ( filepath . Join ( path , file . Name ( ) ) ) ; err != nil { return err } } return nil } 
func newImage ( ctx context . Context , sys * types . SystemContext , ref dockerReference ) ( types . ImageCloser , error ) { s , err := newImageSource ( ctx , sys , ref ) if err != nil { return nil , err } img , err := image . FromSource ( ctx , sys , s ) if err != nil { return nil , err } return & Image { ImageCloser : img , src : s } , nil } 
func ( i * Image ) GetRepositoryTags ( ctx context . Context ) ( [ ] string , error ) { return GetRepositoryTags ( ctx , i . src . c . sys , i . src . ref ) } 
func GetRepositoryTags ( ctx context . Context , sys * types . SystemContext , ref types . ImageReference ) ( [ ] string , error ) { dr , ok := ref . ( dockerReference ) if ! ok { return nil , errors . Errorf ( " " ) } path := fmt . Sprintf ( tagsPath , reference . Path ( dr . ref ) ) client , err := newDockerClientFromRef ( sys , dr , false , " " ) if err != nil { return nil , errors . Wrap ( err , " " ) } tags := make ( [ ] string , 0 ) for { res , err := client . makeRequest ( ctx , " " , path , nil , nil , v2Auth , nil ) if err != nil { return nil , err } defer res . Body . Close ( ) if res . StatusCode != http . StatusOK { } var tagsHolder struct { Tags [ ] string } if err = json . NewDecoder ( res . Body ) . Decode ( & tagsHolder ) ; err != nil { return nil , err } tags = append ( tags , tagsHolder . Tags ... ) link := res . Header . Get ( " " ) if link == " " { break } linkURLStr := strings . Trim ( strings . Split ( link , " " ) [ 0 ] , " " ) linkURL , err := url . Parse ( linkURLStr ) if err != nil { return tags , err } if linkURL . RawQuery != " " { path += " " path += linkURL . RawQuery } } return tags , nil } 
func blobInfoCacheDir ( sys * types . SystemContext , euid int ) ( string , error ) { if sys != nil && sys . BlobInfoCacheDir != " " { return sys . BlobInfoCacheDir , nil } } return systemBlobInfoCacheDir , nil } if dataDir == " " { home := os . Getenv ( " " ) if home == " " { return " " , fmt . Errorf ( " " ) } dataDir = filepath . Join ( home , " " , " " ) } return filepath . Join ( dataDir , " " , " " ) , nil } 
func DefaultCache ( sys * types . SystemContext ) types . BlobInfoCache { dir , err := blobInfoCacheDir ( sys , getRootlessUID ( ) ) if err != nil { logrus . Debugf ( " " , blobInfoCacheFilename ) return memory . New ( ) } path := filepath . Join ( dir , blobInfoCacheFilename ) if err := os . MkdirAll ( dir , 0700 ) ; err != nil { logrus . Debugf ( " " , blobInfoCacheFilename , err ) return memory . New ( ) } logrus . Debugf ( " " , path ) return boltdb . New ( path ) } 
func ( t archiveTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return ParseReference ( reference ) } 
func ParseReference ( refString string ) ( types . ImageReference , error ) { if refString == " " { return nil , errors . Errorf ( " " , refString ) } parts := strings . SplitN ( refString , " " , 2 ) path := parts [ 0 ] var destinationRef reference . NamedTagged if err != nil { return nil , errors . Wrapf ( err , " " ) } ref = reference . TagNameOnly ( ref ) if _ , isDigest := ref . ( reference . Canonical ) ; isDigest { return nil , errors . Errorf ( " " , refString ) } refTagged , isTagged := ref . ( reference . NamedTagged ) if ! isTagged { } destinationRef = refTagged } return archiveReference { destinationRef : destinationRef , path : path , } , nil } 
func ( ref archiveReference ) StringWithinTransport ( ) string { if ref . destinationRef == nil { return ref . path } return fmt . Sprintf ( " " , ref . path , ref . destinationRef . String ( ) ) } 
func ( ref archiveReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { src , err := newImageSource ( ctx , ref ) if err != nil { return nil , err } return ctrImage . FromSource ( ctx , sys , src ) } 
func ( ref archiveReference ) NewImageSource ( ctx context . Context , sys * types . SystemContext ) ( types . ImageSource , error ) { return newImageSource ( ctx , ref ) } 
func ( ref archiveReference ) NewImageDestination ( ctx context . Context , sys * types . SystemContext ) ( types . ImageDestination , error ) { return newImageDestination ( sys , ref ) } 
func ( ref archiveReference ) DeleteImage ( ctx context . Context , sys * types . SystemContext ) error { } 
func New ( ) types . BlobInfoCache { return & cache { uncompressedDigests : map [ digest . Digest ] digest . Digest { } , digestsByUncompressed : map [ digest . Digest ] map [ digest . Digest ] struct { } { } , knownLocations : map [ locationKey ] map [ types . BICLocationReference ] time . Time { } , } } 
func ( mem * cache ) UncompressedDigest ( anyDigest digest . Digest ) digest . Digest { mem . mutex . Lock ( ) defer mem . mutex . Unlock ( ) return mem . uncompressedDigestLocked ( anyDigest ) } 
func ( mem * cache ) uncompressedDigestLocked ( anyDigest digest . Digest ) digest . Digest { if d , ok := mem . uncompressedDigests [ anyDigest ] ; ok { return d } } return " " } 
func ( mem * cache ) RecordDigestUncompressedPair ( anyDigest digest . Digest , uncompressed digest . Digest ) { mem . mutex . Lock ( ) defer mem . mutex . Unlock ( ) if previous , ok := mem . uncompressedDigests [ anyDigest ] ; ok && previous != uncompressed { logrus . Warnf ( " " , anyDigest , previous , uncompressed ) } mem . uncompressedDigests [ anyDigest ] = uncompressed anyDigestSet , ok := mem . digestsByUncompressed [ uncompressed ] if ! ok { anyDigestSet = map [ digest . Digest ] struct { } { } mem . digestsByUncompressed [ uncompressed ] = anyDigestSet } anyDigestSet [ anyDigest ] = struct { } { } } 
func ( mem * cache ) RecordKnownLocation ( transport types . ImageTransport , scope types . BICTransportScope , blobDigest digest . Digest , location types . BICLocationReference ) { mem . mutex . Lock ( ) defer mem . mutex . Unlock ( ) key := locationKey { transport : transport . Name ( ) , scope : scope , blobDigest : blobDigest } locationScope , ok := mem . knownLocations [ key ] if ! ok { locationScope = map [ types . BICLocationReference ] time . Time { } mem . knownLocations [ key ] = locationScope } locationScope [ location ] = time . Now ( ) } 
func ( mem * cache ) appendReplacementCandidates ( candidates [ ] prioritize . CandidateWithTime , transport types . ImageTransport , scope types . BICTransportScope , digest digest . Digest ) [ ] prioritize . CandidateWithTime { locations := mem . knownLocations [ locationKey { transport : transport . Name ( ) , scope : scope , blobDigest : digest } ] for l , t := range locations { candidates = append ( candidates , prioritize . CandidateWithTime { Candidate : types . BICReplacementCandidate { Digest : digest , Location : l , } , LastSeen : t , } ) } return candidates } 
func ( mem * cache ) CandidateLocations ( transport types . ImageTransport , scope types . BICTransportScope , primaryDigest digest . Digest , canSubstitute bool ) [ ] types . BICReplacementCandidate { mem . mutex . Lock ( ) defer mem . mutex . Unlock ( ) res := [ ] prioritize . CandidateWithTime { } res = mem . appendReplacementCandidates ( res , transport , scope , primaryDigest ) var uncompressedDigest digest . Digest if canSubstitute { if uncompressedDigest = mem . uncompressedDigestLocked ( primaryDigest ) ; uncompressedDigest != " " { otherDigests := mem . digestsByUncompressed [ uncompressedDigest ] for d := range otherDigests { if d != primaryDigest && d != uncompressedDigest { res = mem . appendReplacementCandidates ( res , transport , scope , d ) } } if uncompressedDigest != primaryDigest { res = mem . appendReplacementCandidates ( res , transport , scope , uncompressedDigest ) } } } return prioritize . DestructivelyPrioritizeReplacementCandidates ( res , primaryDigest , uncompressedDigest ) } 
func UnparsedInstance ( src types . ImageSource , instanceDigest * digest . Digest ) * UnparsedImage { return & UnparsedImage { src : src , instanceDigest : instanceDigest , } } 
func ( i * UnparsedImage ) Manifest ( ctx context . Context ) ( [ ] byte , string , error ) { if i . cachedManifest == nil { m , mt , err := i . src . GetManifest ( ctx , i . instanceDigest ) if err != nil { return nil , " " , err } if err != nil { return nil , " " , errors . Wrap ( err , " " ) } if ! matches { return nil , " " , errors . Errorf ( " " , digest ) } } i . cachedManifest = m i . cachedManifestMIMEType = mt } return i . cachedManifest , i . cachedManifestMIMEType , nil } 
func ( i * UnparsedImage ) expectedManifestDigest ( ) ( digest . Digest , bool ) { if i . instanceDigest != nil { return * i . instanceDigest , true } ref := i . Reference ( ) . DockerReference ( ) if ref != nil { if canonical , ok := ref . ( reference . Canonical ) ; ok { return canonical . Digest ( ) , true } } return " " , false } 
func ( i * UnparsedImage ) Signatures ( ctx context . Context ) ( [ ] [ ] byte , error ) { if i . cachedSignatures == nil { sigs , err := i . src . GetSignatures ( ctx , i . instanceDigest ) if err != nil { return nil , err } i . cachedSignatures = sigs } return i . cachedSignatures , nil } 
func newGPGSigningMechanismInDirectory ( optionalDir string ) ( SigningMechanism , error ) { ctx , err := newGPGMEContext ( optionalDir ) if err != nil { return nil , err } return & gpgmeSigningMechanism { ctx : ctx , ephemeralDir : " " , } , nil } 
func newEphemeralGPGSigningMechanism ( blob [ ] byte ) ( SigningMechanism , [ ] string , error ) { dir , err := ioutil . TempDir ( " " , " " ) if err != nil { return nil , nil , err } removeDir := true defer func ( ) { if removeDir { os . RemoveAll ( dir ) } } ( ) ctx , err := newGPGMEContext ( dir ) if err != nil { return nil , nil , err } mech := & gpgmeSigningMechanism { ctx : ctx , ephemeralDir : dir , } keyIdentities , err := mech . importKeysFromBytes ( blob ) if err != nil { return nil , nil , err } removeDir = false return mech , keyIdentities , nil } 
func newGPGMEContext ( optionalDir string ) ( * gpgme . Context , error ) { ctx , err := gpgme . New ( ) if err != nil { return nil , err } if err = ctx . SetProtocol ( gpgme . ProtocolOpenPGP ) ; err != nil { return nil , err } if optionalDir != " " { err := ctx . SetEngineInfo ( gpgme . ProtocolOpenPGP , " " , optionalDir ) if err != nil { return nil , err } } ctx . SetArmor ( false ) ctx . SetTextMode ( false ) return ctx , nil } 
func ( m * gpgmeSigningMechanism ) importKeysFromBytes ( blob [ ] byte ) ( [ ] string , error ) { inputData , err := gpgme . NewDataBytes ( blob ) if err != nil { return nil , err } res , err := m . ctx . Import ( inputData ) if err != nil { return nil , err } keyIdentities := [ ] string { } for _ , i := range res . Imports { if i . Result == nil { keyIdentities = append ( keyIdentities , i . Fingerprint ) } } return keyIdentities , nil } 
func ( m * gpgmeSigningMechanism ) Sign ( input [ ] byte , keyIdentity string ) ( [ ] byte , error ) { key , err := m . ctx . GetKey ( keyIdentity , true ) if err != nil { return nil , err } inputData , err := gpgme . NewDataBytes ( input ) if err != nil { return nil , err } var sigBuffer bytes . Buffer sigData , err := gpgme . NewDataWriter ( & sigBuffer ) if err != nil { return nil , err } if err = m . ctx . Sign ( [ ] * gpgme . Key { key } , inputData , sigData , gpgme . SigModeNormal ) ; err != nil { return nil , err } return sigBuffer . Bytes ( ) , nil } 
func ( m gpgmeSigningMechanism ) Verify ( unverifiedSignature [ ] byte ) ( contents [ ] byte , keyIdentity string , err error ) { signedBuffer := bytes . Buffer { } signedData , err := gpgme . NewDataWriter ( & signedBuffer ) if err != nil { return nil , " " , err } unverifiedSignatureData , err := gpgme . NewDataBytes ( unverifiedSignature ) if err != nil { return nil , " " , err } _ , sigs , err := m . ctx . Verify ( unverifiedSignatureData , nil , signedData ) if err != nil { return nil , " " , err } if len ( sigs ) != 1 { return nil , " " , InvalidSignatureError { msg : fmt . Sprintf ( " " , len ( sigs ) ) } } sig := sigs [ 0 ] } return signedBuffer . Bytes ( ) , sig . Fingerprint , nil } 
func newImageDestination ( ctx context . Context , sys * types . SystemContext , ref ociArchiveReference ) ( types . ImageDestination , error ) { tempDirRef , err := createOCIRef ( ref . image ) if err != nil { return nil , errors . Wrapf ( err , " " ) } unpackedDest , err := tempDirRef . ociRefExtracted . NewImageDestination ( ctx , sys ) if err != nil { if err := tempDirRef . deleteTempDir ( ) ; err != nil { return nil , errors . Wrapf ( err , " " , tempDirRef . tempDirectory ) } return nil , err } return & ociArchiveImageDestination { ref : ref , unpackedDest : unpackedDest , tempDirRef : tempDirRef } , nil } 
func ( d * ociArchiveImageDestination ) Close ( ) error { defer d . tempDirRef . deleteTempDir ( ) return d . unpackedDest . Close ( ) } 
func ( d * ociArchiveImageDestination ) SupportsSignatures ( ctx context . Context ) error { return d . unpackedDest . SupportsSignatures ( ctx ) } 
func ( d * ociArchiveImageDestination ) PutBlob ( ctx context . Context , stream io . Reader , inputInfo types . BlobInfo , cache types . BlobInfoCache , isConfig bool ) ( types . BlobInfo , error ) { return d . unpackedDest . PutBlob ( ctx , stream , inputInfo , cache , isConfig ) } 
func ( d * ociArchiveImageDestination ) TryReusingBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache , canSubstitute bool ) ( bool , types . BlobInfo , error ) { return d . unpackedDest . TryReusingBlob ( ctx , info , cache , canSubstitute ) } 
func ( d * ociArchiveImageDestination ) PutManifest ( ctx context . Context , m [ ] byte ) error { return d . unpackedDest . PutManifest ( ctx , m ) } 
func ( d * ociArchiveImageDestination ) Commit ( ctx context . Context ) error { if err := d . unpackedDest . Commit ( ctx ) ; err != nil { return errors . Wrapf ( err , " " , d . ref . image ) } return tarDirectory ( src , dst ) } 
func tarDirectory ( src , dst string ) error { if err != nil { return errors . Wrapf ( err , " " , src ) } if err != nil { return errors . Wrapf ( err , " " , dst ) } defer outFile . Close ( ) return err } 
func ( s storageTransport ) ParseStoreReference ( store storage . Store , ref string ) ( * storageReference , error ) { if ref == " " { return nil , errors . Wrapf ( ErrInvalidReference , " " , ref ) } if ref [ 0 ] == '[' { if closeIndex < 1 { return nil , errors . Wrapf ( ErrInvalidReference , " " , ref ) } ref = ref [ closeIndex + 1 : ] } id := " " if split != - 1 { possibleID := ref [ split + 1 : ] if possibleID == " " { return nil , errors . Wrapf ( ErrInvalidReference , " " , ref ) } } else if img , err := store . Image ( possibleID ) ; err == nil && img != nil && len ( possibleID ) >= minimumTruncatedIDLength && strings . HasPrefix ( img . ID , possibleID ) { } else { return nil , errors . Wrapf ( ErrInvalidReference , " " , possibleID ) } } } ref = " " } } var named reference . Named named , err = reference . ParseNormalizedNamed ( ref ) if err != nil { return nil , errors . Wrapf ( err , " " , ref ) } named = reference . TagNameOnly ( named ) } result , err := newReference ( storageTransport { store : store , defaultUIDMap : s . defaultUIDMap , defaultGIDMap : s . defaultGIDMap } , named , id ) if err != nil { return nil , err } logrus . Debugf ( " " , result . StringWithinTransport ( ) ) return result , nil } 
func ( s * storageTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { var store storage . Store if closeIndex < 1 { return nil , ErrInvalidReference } storeSpec := reference [ 1 : closeIndex ] reference = reference [ closeIndex + 1 : ] driverSplit := strings . SplitN ( storeSpec , " " , 2 ) if len ( driverSplit ) != 2 { if storeSpec == " " { return nil , ErrInvalidReference } } else { driverInfo = driverSplit [ 0 ] if driverInfo == " " { return nil , ErrInvalidReference } storeSpec = driverSplit [ 1 ] if storeSpec == " " { return nil , ErrInvalidReference } } optionsSplit := strings . SplitN ( storeSpec , " " , 2 ) if len ( optionsSplit ) == 2 { options = strings . Split ( optionsSplit [ 1 ] , " " ) storeSpec = optionsSplit [ 0 ] } runRootSplit := strings . SplitN ( storeSpec , " " , 2 ) if len ( runRootSplit ) == 2 { runRootInfo = runRootSplit [ 1 ] storeSpec = runRootSplit [ 0 ] } } if runRootInfo != " " && ! filepath . IsAbs ( runRootInfo ) { return nil , ErrPathNotAbsolute } store2 , err := storage . GetStore ( storage . StoreOptions { GraphDriverName : driverInfo , GraphRoot : rootInfo , RunRoot : runRootInfo , GraphDriverOptions : options , UIDMap : s . defaultUIDMap , GIDMap : s . defaultGIDMap , } ) if err != nil { return nil , err } store = store2 } else { if err != nil { return nil , err } store = store2 } return s . ParseStoreReference ( store , reference ) } 
func chooseDigestFromManifestList ( sys * types . SystemContext , blob [ ] byte ) ( digest . Digest , error ) { wantedArch := runtime . GOARCH if sys != nil && sys . ArchitectureChoice != " " { wantedArch = sys . ArchitectureChoice } wantedOS := runtime . GOOS if sys != nil && sys . OSChoice != " " { wantedOS = sys . OSChoice } list := manifestList { } if err := json . Unmarshal ( blob , & list ) ; err != nil { return " " , err } for _ , d := range list . Manifests { if d . Platform . Architecture == wantedArch && d . Platform . OS == wantedOS { return d . Digest , nil } } return " " , fmt . Errorf ( " " , wantedArch , wantedOS ) } 
func ChooseManifestInstanceFromManifestList ( ctx context . Context , sys * types . SystemContext , src types . UnparsedImage ) ( digest . Digest , error ) { if err != nil { return " " , err } if mt != manifest . DockerV2ListMediaType { return " " , fmt . Errorf ( " " , mt ) } return chooseDigestFromManifestList ( sys , blob ) } 
func ( s * dirImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { if instanceDigest != nil { return nil , " " , errors . Errorf ( `Getting target manifest not supported by "dir:"` ) } m , err := ioutil . ReadFile ( s . ref . manifestPath ( ) ) if err != nil { return nil , " " , err } return m , manifest . GuessMIMEType ( m ) , err } 
func ( s * dirImageSource ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { r , err := os . Open ( s . ref . layerPath ( info . Digest ) ) if err != nil { return nil , - 1 , err } fi , err := r . Stat ( ) if err != nil { return nil , - 1 , err } return r , fi . Size ( ) , nil } 
func ( s * dirImageSource ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { if instanceDigest != nil { return nil , errors . Errorf ( `Manifests lists are not supported by "dir:"` ) } signatures := [ ] [ ] byte { } for i := 0 ; ; i ++ { signature , err := ioutil . ReadFile ( s . ref . signaturePath ( i ) ) if err != nil { if os . IsNotExist ( err ) { break } return nil , err } signatures = append ( signatures , signature ) } return signatures , nil } 
func ( s * dirImageSource ) LayerInfosForCopy ( ctx context . Context ) ( [ ] types . BlobInfo , error ) { return nil , nil } 
func manifestSchema1FromComponents ( ref reference . Named , fsLayers [ ] manifest . Schema1FSLayers , history [ ] manifest . Schema1History , architecture string ) ( genericManifest , error ) { m , err := manifest . Schema1FromComponents ( ref , fsLayers , history , architecture ) if err != nil { return nil , err } return & manifestSchema1 { m : m } , nil } 
func ( m * manifestSchema1 ) OCIConfig ( ctx context . Context ) ( * imgspecv1 . Image , error ) { v2s2 , err := m . convertToManifestSchema2 ( nil , nil ) if err != nil { return nil , err } return v2s2 . OCIConfig ( ctx ) } 
func ( m * manifestSchema1 ) EmbeddedDockerReferenceConflicts ( ref reference . Named ) bool { var tag string if tagged , isTagged := ref . ( reference . NamedTagged ) ; isTagged { tag = tagged . Tag ( ) } else { tag = " " } return m . m . Name != name || m . m . Tag != tag } 
func ( m * manifestSchema1 ) Inspect ( context . Context ) ( * types . ImageInspectInfo , error ) { return m . m . Inspect ( nil ) } 
func ( m * manifestSchema1 ) UpdatedImageNeedsLayerDiffIDs ( options types . ManifestUpdateOptions ) bool { return ( options . ManifestMIMEType == manifest . DockerV2Schema2MediaType || options . ManifestMIMEType == imgspecv1 . MediaTypeImageManifest ) } 
func ( m * manifestSchema1 ) UpdatedImage ( ctx context . Context , options types . ManifestUpdateOptions ) ( types . Image , error ) { copy := manifestSchema1 { m : manifest . Schema1Clone ( m . m ) } if options . LayerInfos != nil { if err := copy . m . UpdateLayerInfos ( options . LayerInfos ) ; err != nil { return nil , err } } if options . EmbeddedDockerReference != nil { copy . m . Name = reference . Path ( options . EmbeddedDockerReference ) if tagged , isTagged := options . EmbeddedDockerReference . ( reference . NamedTagged ) ; isTagged { copy . m . Tag = tagged . Tag ( ) } else { copy . m . Tag = " " } } switch options . ManifestMIMEType { case " " : if err != nil { return nil , err } return memoryImageFromManifest ( m2 ) , nil case imgspecv1 . MediaTypeImageManifest : if err != nil { return nil , err } return m2 . UpdatedImage ( ctx , types . ManifestUpdateOptions { ManifestMIMEType : imgspecv1 . MediaTypeImageManifest , InformationOnly : options . InformationOnly , } ) default : return nil , errors . Errorf ( " " , manifest . DockerV2Schema1SignedMediaType , options . ManifestMIMEType ) } return memoryImageFromManifest ( & copy ) , nil } 
func ( m * manifestSchema1 ) convertToManifestSchema2 ( uploadedLayerInfos [ ] types . BlobInfo , layerDiffIDs [ ] digest . Digest ) ( genericManifest , error ) { if len ( m . m . ExtractedV1Compatibility ) == 0 { } if len ( m . m . ExtractedV1Compatibility ) != len ( m . m . FSLayers ) { return nil , errors . Errorf ( " " , len ( m . m . ExtractedV1Compatibility ) , len ( m . m . FSLayers ) ) } if uploadedLayerInfos != nil && len ( uploadedLayerInfos ) != len ( m . m . FSLayers ) { return nil , errors . Errorf ( " " , len ( uploadedLayerInfos ) , len ( m . m . FSLayers ) ) } if layerDiffIDs != nil && len ( layerDiffIDs ) != len ( m . m . FSLayers ) { return nil , errors . Errorf ( " " , len ( layerDiffIDs ) , len ( m . m . FSLayers ) ) } var layers [ ] manifest . Schema2Descriptor for v1Index := len ( m . m . ExtractedV1Compatibility ) - 1 ; v1Index >= 0 ; v1Index -- { v2Index := ( len ( m . m . ExtractedV1Compatibility ) - 1 ) - v1Index if ! m . m . ExtractedV1Compatibility [ v1Index ] . ThrowAway { var size int64 if uploadedLayerInfos != nil { size = uploadedLayerInfos [ v2Index ] . Size } var d digest . Digest if layerDiffIDs != nil { d = layerDiffIDs [ v2Index ] } layers = append ( layers , manifest . Schema2Descriptor { MediaType : " " , Size : size , Digest : m . m . FSLayers [ v1Index ] . BlobSum , } ) diffIDs = append ( diffIDs , d ) } } configJSON , err := m . m . ToSchema2Config ( diffIDs ) if err != nil { return nil , err } configDescriptor := manifest . Schema2Descriptor { MediaType : " " , Size : int64 ( len ( configJSON ) ) , Digest : digest . FromBytes ( configJSON ) , } return manifestSchema2FromComponents ( configDescriptor , nil , configJSON , layers ) , nil } 
func newImageSource ( ctx context . Context , sys * types . SystemContext , ref dockerReference ) ( * dockerImageSource , error ) { registry , err := sysregistriesv2 . FindRegistry ( sys , ref . ref . Name ( ) ) if err != nil { return nil , errors . Wrapf ( err , " " ) } if registry == nil { } manifestLoadErr error ) for _ , endpoint := range append ( registry . Mirrors , registry . Endpoint ) { logrus . Debugf ( " " , ref . ref , endpoint . Location ) newRef , err := endpoint . RewriteReference ( ref . ref , registry . Prefix ) if err != nil { return nil , err } dockerRef , err := newReference ( newRef ) if err != nil { return nil , err } client , err := newDockerClientFromRef ( sys , dockerRef , false , " " ) if err != nil { return nil , err } client . tlsClientConfig . InsecureSkipVerify = endpoint . Insecure testImageSource := & dockerImageSource { ref : dockerRef , c : client , } manifestLoadErr = testImageSource . ensureManifestIsLoaded ( ctx ) if manifestLoadErr == nil { imageSource = testImageSource break } } return imageSource , manifestLoadErr } 
func simplifyContentType ( contentType string ) string { if contentType == " " { return contentType } mimeType , _ , err := mime . ParseMediaType ( contentType ) if err != nil { return " " } return mimeType } 
func ( s * dockerImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { if instanceDigest != nil { return s . fetchManifest ( ctx , instanceDigest . String ( ) ) } err := s . ensureManifestIsLoaded ( ctx ) if err != nil { return nil , " " , err } return s . cachedManifest , s . cachedManifestMIMEType , nil } 
func ( s * dockerImageSource ) ensureManifestIsLoaded ( ctx context . Context ) error { if s . cachedManifest != nil { return nil } reference , err := s . ref . tagOrDigest ( ) if err != nil { return err } manblob , mt , err := s . fetchManifest ( ctx , reference ) if err != nil { return err } s . cachedManifestMIMEType = mt return nil } 
func ( s * dockerImageSource ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { if len ( info . URLs ) != 0 { return s . getExternalBlob ( ctx , info . URLs ) } path := fmt . Sprintf ( blobsPath , reference . Path ( s . ref . ref ) , info . Digest . String ( ) ) logrus . Debugf ( " " , path ) res , err := s . c . makeRequest ( ctx , " " , path , nil , nil , v2Auth , nil ) if err != nil { return nil , 0 , err } if res . StatusCode != http . StatusOK { } cache . RecordKnownLocation ( s . ref . Transport ( ) , bicTransportScope ( s . ref ) , info . Digest , newBICLocationReference ( s . ref ) ) return res . Body , getBlobSize ( res ) , nil } 
func ( s * dockerImageSource ) GetSignatures ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { if err := s . c . detectProperties ( ctx ) ; err != nil { return nil , err } switch { case s . c . signatureBase != nil : return s . getSignaturesFromLookaside ( ctx , instanceDigest ) case s . c . supportsSignatures : return s . getSignaturesFromAPIExtension ( ctx , instanceDigest ) default : return [ ] [ ] byte { } , nil } } 
func ( s * dockerImageSource ) manifestDigest ( ctx context . Context , instanceDigest * digest . Digest ) ( digest . Digest , error ) { if instanceDigest != nil { return * instanceDigest , nil } if digested , ok := s . ref . ref . ( reference . Digested ) ; ok { d := digested . Digest ( ) if d . Algorithm ( ) == digest . Canonical { return d , nil } } if err := s . ensureManifestIsLoaded ( ctx ) ; err != nil { return " " , err } return manifest . Digest ( s . cachedManifest ) } 
func ( s * dockerImageSource ) getSignaturesFromLookaside ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { manifestDigest , err := s . manifestDigest ( ctx , instanceDigest ) if err != nil { return nil , err } for i := 0 ; ; i ++ { url := signatureStorageURL ( s . c . signatureBase , manifestDigest , i ) if url == nil { return nil , errors . Errorf ( " " ) } signature , missing , err := s . getOneSignature ( ctx , url ) if err != nil { return nil , err } if missing { break } signatures = append ( signatures , signature ) } return signatures , nil } 
func ( s * dockerImageSource ) getOneSignature ( ctx context . Context , url * url . URL ) ( signature [ ] byte , missing bool , err error ) { switch url . Scheme { case " " : logrus . Debugf ( " " , url . Path ) sig , err := ioutil . ReadFile ( url . Path ) if err != nil { if os . IsNotExist ( err ) { return nil , true , nil } return nil , false , err } return sig , false , nil case " " , " " : logrus . Debugf ( " " , url ) req , err := http . NewRequest ( " " , url . String ( ) , nil ) if err != nil { return nil , false , err } req = req . WithContext ( ctx ) res , err := s . c . doHTTP ( req ) if err != nil { return nil , false , err } defer res . Body . Close ( ) if res . StatusCode == http . StatusNotFound { return nil , true , nil } else if res . StatusCode != http . StatusOK { return nil , false , errors . Errorf ( " " , url . String ( ) , res . StatusCode , http . StatusText ( res . StatusCode ) ) } sig , err := ioutil . ReadAll ( res . Body ) if err != nil { return nil , false , err } return sig , false , nil default : return nil , false , errors . Errorf ( " " , url . String ( ) ) } } 
func ( s * dockerImageSource ) getSignaturesFromAPIExtension ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] [ ] byte , error ) { manifestDigest , err := s . manifestDigest ( ctx , instanceDigest ) if err != nil { return nil , err } parsedBody , err := s . c . getExtensionsSignatures ( ctx , s . ref , manifestDigest ) if err != nil { return nil , err } var sigs [ ] [ ] byte for _ , sig := range parsedBody . Signatures { if sig . Version == extensionSignatureSchemaVersion && sig . Type == extensionSignatureTypeAtomic { sigs = append ( sigs , sig . Content ) } } return sigs , nil } 
func deleteImage ( ctx context . Context , sys * types . SystemContext , ref dockerReference ) error { if err != nil { return err } headers [ " " ] = [ ] string { manifest . DockerV2Schema2MediaType } refTail , err := ref . tagOrDigest ( ) if err != nil { return err } getPath := fmt . Sprintf ( manifestPath , reference . Path ( ref . ref ) , refTail ) get , err := c . makeRequest ( ctx , " " , getPath , headers , nil , v2Auth , nil ) if err != nil { return err } defer get . Body . Close ( ) manifestBody , err := ioutil . ReadAll ( get . Body ) if err != nil { return err } switch get . StatusCode { case http . StatusOK : case http . StatusNotFound : return errors . Errorf ( " " , ref . ref ) default : return errors . Errorf ( " " , ref . ref , manifestBody , get . Status ) } digest := get . Header . Get ( " " ) deletePath := fmt . Sprintf ( manifestPath , reference . Path ( ref . ref ) , digest ) if err != nil { return err } defer delete . Body . Close ( ) body , err := ioutil . ReadAll ( delete . Body ) if err != nil { return err } if delete . StatusCode != http . StatusAccepted { return errors . Errorf ( " " , deletePath , string ( body ) , delete . Status ) } if c . signatureBase != nil { manifestDigest , err := manifest . Digest ( manifestBody ) if err != nil { return err } for i := 0 ; ; i ++ { url := signatureStorageURL ( c . signatureBase , manifestDigest , i ) if url == nil { return errors . Errorf ( " " ) } missing , err := c . deleteOneSignature ( url ) if err != nil { return err } if missing { break } } } return nil } 
func ( i * memoryImage ) Manifest ( ctx context . Context ) ( [ ] byte , string , error ) { if i . serializedManifest == nil { m , err := i . genericManifest . serialize ( ) if err != nil { return nil , " " , err } i . serializedManifest = m } return i . serializedManifest , i . genericManifest . manifestMIMEType ( ) , nil } 
func ( i * memoryImage ) Signatures ( ctx context . Context ) ( [ ] [ ] byte , error ) { } 
func ( i * memoryImage ) LayerInfosForCopy ( ctx context . Context ) ( [ ] types . BlobInfo , error ) { return nil , nil } 
func Schema1FromManifest ( manifest [ ] byte ) ( * Schema1 , error ) { s1 := Schema1 { } if err := json . Unmarshal ( manifest , & s1 ) ; err != nil { return nil , err } if s1 . SchemaVersion != 1 { return nil , errors . Errorf ( " " , s1 . SchemaVersion ) } if err := s1 . initialize ( ) ; err != nil { return nil , err } if err := s1 . fixManifestLayers ( ) ; err != nil { return nil , err } return & s1 , nil } 
func Schema1FromComponents ( ref reference . Named , fsLayers [ ] Schema1FSLayers , history [ ] Schema1History , architecture string ) ( * Schema1 , error ) { var name , tag string if ref != nil { if tagged , ok := ref . ( reference . NamedTagged ) ; ok { tag = tagged . Tag ( ) } } s1 := Schema1 { Name : name , Tag : tag , Architecture : architecture , FSLayers : fsLayers , History : history , SchemaVersion : 1 , } if err := s1 . initialize ( ) ; err != nil { return nil , err } return & s1 , nil } 
func ( m * Schema1 ) initialize ( ) error { if len ( m . FSLayers ) != len ( m . History ) { return errors . New ( " " ) } if len ( m . FSLayers ) == 0 { return errors . New ( " " ) } m . ExtractedV1Compatibility = make ( [ ] Schema1V1Compatibility , len ( m . History ) ) for i , h := range m . History { if err := json . Unmarshal ( [ ] byte ( h . V1Compatibility ) , & m . ExtractedV1Compatibility [ i ] ) ; err != nil { return errors . Wrapf ( err , " " , i ) } } return nil } 
func ( m * Schema1 ) LayerInfos ( ) [ ] LayerInfo { layers := make ( [ ] LayerInfo , len ( m . FSLayers ) ) for i , layer := range m . FSLayers { } return layers } 
func ( m * Schema1 ) UpdateLayerInfos ( layerInfos [ ] types . BlobInfo ) error { } m . FSLayers = make ( [ ] Schema1FSLayers , len ( layerInfos ) ) for i , info := range layerInfos { } return nil } 
func ( m * Schema1 ) Serialize ( ) ( [ ] byte , error ) { if err != nil { return nil , err } return AddDummyV2S1Signature ( unsigned ) } 
func ( m * Schema1 ) fixManifestLayers ( ) error { } } if m . ExtractedV1Compatibility [ len ( m . ExtractedV1Compatibility ) - 1 ] . Parent != " " { return errors . New ( " " ) } var lastID string for _ , img := range m . ExtractedV1Compatibility { } lastID = img . ID idmap [ lastID ] = struct { } { } } m . History = append ( m . History [ : i ] , m . History [ i + 1 : ] ... ) m . ExtractedV1Compatibility = append ( m . ExtractedV1Compatibility [ : i ] , m . ExtractedV1Compatibility [ i + 1 : ] ... ) } else if m . ExtractedV1Compatibility [ i ] . Parent != m . ExtractedV1Compatibility [ i + 1 ] . ID { return errors . Errorf ( " " , m . ExtractedV1Compatibility [ i + 1 ] . ID , m . ExtractedV1Compatibility [ i ] . Parent ) } } return nil } 
func ( m * Schema1 ) Inspect ( _ func ( types . BlobInfo ) ( [ ] byte , error ) ) ( * types . ImageInspectInfo , error ) { s1 := & Schema2V1Image { } if err := json . Unmarshal ( [ ] byte ( m . History [ 0 ] . V1Compatibility ) , s1 ) ; err != nil { return nil , err } i := & types . ImageInspectInfo { Tag : m . Tag , Created : & s1 . Created , DockerVersion : s1 . DockerVersion , Architecture : s1 . Architecture , Os : s1 . OS , Layers : layerInfosToStrings ( m . LayerInfos ( ) ) , } if s1 . Config != nil { i . Labels = s1 . Config . Labels } return i , nil } 
func ( m * Schema1 ) ToSchema2Config ( diffIDs [ ] digest . Digest ) ( [ ] byte , error ) { } s1 := Schema2V1Image { } config := [ ] byte ( m . History [ 0 ] . V1Compatibility ) err := json . Unmarshal ( config , & s1 ) if err != nil { return nil , errors . Wrapf ( err , " " ) } if err != nil { return nil , errors . Wrapf ( err , " " , s1 ) } } for _ , compat := range m . ExtractedV1Compatibility { hitem := Schema2History { Created : compat . Created , CreatedBy : strings . Join ( compat . ContainerConfig . Cmd , " " ) , Author : compat . Author , Comment : compat . Comment , EmptyLayer : compat . ThrowAway , } convertedHistory = append ( [ ] Schema2History { hitem } , convertedHistory ... ) } err = json . Unmarshal ( config , & raw ) if err != nil { return nil , errors . Wrapf ( err , " " , s1 ) } delete ( raw , " " ) delete ( raw , " " ) delete ( raw , " " ) delete ( raw , " " ) delete ( raw , " " ) if err != nil { return nil , errors . Errorf ( " " , rootFS , err ) } rawRootfs := json . RawMessage ( rootfs ) raw [ " " ] = & rawRootfs history , err := json . Marshal ( convertedHistory ) if err != nil { return nil , errors . Errorf ( " " , convertedHistory , err ) } rawHistory := json . RawMessage ( history ) raw [ " " ] = & rawHistory if err != nil { return nil , errors . Errorf ( " " , s1 , err ) } return config , nil } 
func ( m * Schema1 ) ImageID ( diffIDs [ ] digest . Digest ) ( string , error ) { image , err := m . ToSchema2Config ( diffIDs ) if err != nil { return " " , err } return digest . FromBytes ( image ) . Hex ( ) , nil } 
func GuessMIMEType ( manifest [ ] byte ) string { SchemaVersion int `json:"schemaVersion"` Signatures interface { } `json:"signatures"` } { } if err := json . Unmarshal ( manifest , & meta ) ; err != nil { return " " } switch meta . MediaType { case DockerV2Schema2MediaType , DockerV2ListMediaType : } } return DockerV2Schema1MediaType case 2 : } `json:"config"` Layers [ ] imgspecv1 . Descriptor `json:"layers"` } { } if err := json . Unmarshal ( manifest , & ociMan ) ; err != nil { return " " } if ociMan . Config . MediaType == imgspecv1 . MediaTypeImageConfig && len ( ociMan . Layers ) != 0 { return imgspecv1 . MediaTypeImageManifest } ociIndex := struct { Manifests [ ] imgspecv1 . Descriptor `json:"manifests"` } { } if err := json . Unmarshal ( manifest , & ociIndex ) ; err != nil { return " " } if len ( ociIndex . Manifests ) != 0 && ociIndex . Manifests [ 0 ] . MediaType == imgspecv1 . MediaTypeImageManifest { return imgspecv1 . MediaTypeImageIndex } return DockerV2Schema2MediaType } return " " } 
func Digest ( manifest [ ] byte ) ( digest . Digest , error ) { if GuessMIMEType ( manifest ) == DockerV2Schema1SignedMediaType { sig , err := libtrust . ParsePrettySignature ( manifest , " " ) if err != nil { return " " , err } manifest , err = sig . Payload ( ) if err != nil { } } return digest . FromBytes ( manifest ) , nil } 
func MatchesDigest ( manifest [ ] byte , expectedDigest digest . Digest ) ( bool , error ) { if err != nil { return false , err } return expectedDigest == actualDigest , nil } 
func AddDummyV2S1Signature ( manifest [ ] byte ) ( [ ] byte , error ) { key , err := libtrust . GenerateECP256PrivateKey ( ) if err != nil { return nil , err } js , err := libtrust . NewJSONSignature ( manifest ) if err != nil { return nil , err } if err := js . Sign ( key ) ; err != nil { } return js . PrettySignature ( " " ) } 
func NormalizedMIMEType ( input string ) string { switch input { case DockerV2Schema1MediaType , DockerV2Schema1SignedMediaType , imgspecv1 . MediaTypeImageManifest , DockerV2Schema2MediaType , DockerV2ListMediaType : return input default : } } 
func FromBlob ( manblob [ ] byte , mt string ) ( Manifest , error ) { switch NormalizedMIMEType ( mt ) { case DockerV2Schema1MediaType , DockerV2Schema1SignedMediaType : return Schema1FromManifest ( manblob ) case imgspecv1 . MediaTypeImageManifest : return OCI1FromManifest ( manblob ) case DockerV2Schema2MediaType : return Schema2FromManifest ( manblob ) case DockerV2ListMediaType : return nil , fmt . Errorf ( " " ) default : } } 
func layerInfosToStrings ( infos [ ] LayerInfo ) [ ] string { layers := make ( [ ] string , len ( infos ) ) for i , info := range infos { layers [ i ] = info . Digest . String ( ) } return layers } 
func ( t dirTransport ) ParseReference ( reference string ) ( types . ImageReference , error ) { return NewReference ( reference ) } 
func ( t dirTransport ) ValidatePolicyConfigurationScope ( scope string ) error { if ! strings . HasPrefix ( scope , " " ) { return errors . Errorf ( " " , scope ) } } cleaned := filepath . Clean ( scope ) if cleaned != scope { return errors . Errorf ( `Invalid scope %s: Uses non-canonical format, perhaps try %s` , scope , cleaned ) } return nil } 
func NewReference ( path string ) ( types . ImageReference , error ) { resolved , err := explicitfilepath . ResolvePathToFullyExplicit ( path ) if err != nil { return nil , err } return dirReference { path : path , resolvedPath : resolved } , nil } 
func ( ref dirReference ) PolicyConfigurationNamespaces ( ) [ ] string { res := [ ] string { } path := ref . resolvedPath for { lastSlash := strings . LastIndex ( path , " " ) if lastSlash == - 1 || lastSlash == 0 { break } path = path [ : lastSlash ] res = append ( res , path ) } } 
func ( ref dirReference ) NewImage ( ctx context . Context , sys * types . SystemContext ) ( types . ImageCloser , error ) { src := newImageSource ( ref ) return image . FromSource ( ctx , sys , src ) } 
func ( ref dirReference ) NewImageSource ( ctx context . Context , sys * types . SystemContext ) ( types . ImageSource , error ) { return newImageSource ( ref ) , nil } 
func ( ref dirReference ) NewImageDestination ( ctx context . Context , sys * types . SystemContext ) ( types . ImageDestination , error ) { compress := false if sys != nil { compress = sys . DirForceCompress } return newImageDestination ( ref , compress ) } 
func ( ref dirReference ) layerPath ( digest digest . Digest ) string { } 
func ( ref dirReference ) signaturePath ( index int ) string { return filepath . Join ( ref . path , fmt . Sprintf ( " " , index + 1 ) ) } 
func newImageSource ( tmpDir string , ref ostreeReference ) ( types . ImageSource , error ) { return & ostreeImageSource { ref : ref , tmpDir : tmpDir , compressed : nil } , nil } 
func ( s * ostreeImageSource ) Close ( ) error { if s . repo != nil { C . g_object_unref ( C . gpointer ( s . repo ) ) } return nil } 
func ( s * ostreeImageSource ) GetManifest ( ctx context . Context , instanceDigest * digest . Digest ) ( [ ] byte , string , error ) { if instanceDigest != nil { return nil , " " , errors . Errorf ( `Manifest lists are not supported by "ostree:"` ) } if s . repo == nil { repo , err := openRepo ( s . ref . repo ) if err != nil { return nil , " " , err } s . repo = repo } b := fmt . Sprintf ( " " , s . ref . branchName ) found , out , err := readMetadata ( s . repo , b , " " ) if err != nil { return nil , " " , err } if ! found { return nil , " " , errors . New ( " " ) } m := [ ] byte ( out ) return m , manifest . GuessMIMEType ( m ) , nil } 
func ( s * ostreeImageSource ) GetBlob ( ctx context . Context , info types . BlobInfo , cache types . BlobInfoCache ) ( io . ReadCloser , int64 , error ) { blob := info . Digest . Hex ( ) if err != nil { return nil , - 1 , err } } compressedBlob , found := s . compressed [ info . Digest ] if found { blob = compressedBlob . Hex ( ) } branch := fmt . Sprintf ( " " , blob ) if s . repo == nil { repo , err := openRepo ( s . ref . repo ) if err != nil { return nil , 0 , err } s . repo = repo } layerSize , err := s . getLayerSize ( blob ) if err != nil { return nil , 0 , err } tarsplit , err := s . getTarSplitData ( blob ) if err != nil { return nil , 0 , err } if err != nil { return nil , 0 , err } return file , layerSize , nil } mf := bytes . NewReader ( tarsplit ) mfz , err := pgzip . NewReader ( mf ) if err != nil { return nil , 0 , err } metaUnpacker := storage . NewJSONUnpacker ( mfz ) getter , err := newOSTreePathFileGetter ( s . repo , branch ) if err != nil { mfz . Close ( ) return nil , 0 , err } ots := asm . NewOutputTarStream ( getter , metaUnpacker ) rc := ioutils . NewReadCloserWrapper ( ots , func ( ) error { getter . Close ( ) mfz . Close ( ) return ots . Close ( ) } ) return rc , layerSize , nil } 
func ( s * ostreeImageSource ) LayerInfosForCopy ( ctx context . Context ) ( [ ] types . BlobInfo , error ) { updatedBlobInfos := [ ] types . BlobInfo { } manifestBlob , manifestType , err := s . GetManifest ( ctx , nil ) if err != nil { return nil , err } man , err := manifest . FromBlob ( manifestBlob , manifestType ) s . compressed = make ( map [ digest . Digest ] digest . Digest ) layerBlobs := man . LayerInfos ( ) for _ , layerBlob := range layerBlobs { branch := fmt . Sprintf ( " " , layerBlob . Digest . Hex ( ) ) found , uncompressedDigestStr , err := readMetadata ( s . repo , branch , " " ) if err != nil || ! found { return nil , err } found , uncompressedSizeStr , err := readMetadata ( s . repo , branch , " " ) if err != nil || ! found { return nil , err } uncompressedSize , err := strconv . ParseInt ( uncompressedSizeStr , 10 , 64 ) if err != nil { return nil , err } uncompressedDigest := digest . Digest ( uncompressedDigestStr ) blobInfo := types . BlobInfo { Digest : uncompressedDigest , Size : uncompressedSize , MediaType : layerBlob . MediaType , } s . compressed [ uncompressedDigest ] = layerBlob . Digest updatedBlobInfos = append ( updatedBlobInfos , blobInfo ) } return updatedBlobInfos , nil } 
func New ( n int , ctor func ( ) Worker ) * Pool { p := & Pool { ctor : ctor , reqChan : make ( chan workRequest ) , } p . SetSize ( n ) return p } 
func NewFunc ( n int , f func ( interface { } ) interface { } ) * Pool { return New ( n , func ( ) Worker { return & closureWorker { processor : f , } } ) } 
func ( p * Pool ) Process ( payload interface { } ) interface { } { atomic . AddInt64 ( & p . queuedJobs , 1 ) request , open := <- p . reqChan if ! open { panic ( ErrPoolNotRunning ) } request . jobChan <- payload payload , open = <- request . retChan if ! open { panic ( ErrWorkerClosed ) } atomic . AddInt64 ( & p . queuedJobs , - 1 ) return payload } 
func ( p * Pool ) ProcessTimed ( payload interface { } , timeout time . Duration , ) ( interface { } , error ) { atomic . AddInt64 ( & p . queuedJobs , 1 ) defer atomic . AddInt64 ( & p . queuedJobs , - 1 ) tout := time . NewTimer ( timeout ) var request workRequest var open bool select { case request , open = <- p . reqChan : if ! open { return nil , ErrPoolNotRunning } case <- tout . C : return nil , ErrJobTimedOut } select { case request . jobChan <- payload : case <- tout . C : request . interruptFunc ( ) return nil , ErrJobTimedOut } select { case payload , open = <- request . retChan : if ! open { return nil , ErrWorkerClosed } case <- tout . C : request . interruptFunc ( ) return nil , ErrJobTimedOut } tout . Stop ( ) return payload , nil } 
func ( p * Pool ) SetSize ( n int ) { p . workerMut . Lock ( ) defer p . workerMut . Unlock ( ) lWorkers := len ( p . workers ) if lWorkers == n { return } } } } } 
func ( p * Pool ) GetSize ( ) int { p . workerMut . Lock ( ) defer p . workerMut . Unlock ( ) return len ( p . workers ) } 
func GetPerspectiveTransform ( rect , dst [ ] CvPoint2D32f ) * Mat { mat := CreateMat ( 3 , 3 , CV_64F ) result := C . cvGetPerspectiveTransform ( ( * C . CvPoint2D32f ) ( & rect [ 0 ] ) , ( * C . CvPoint2D32f ) ( & dst [ 0 ] ) , ( * C . struct_CvMat ) ( mat ) ) return ( * Mat ) ( result ) } 
func WarpPerspective ( src , dst * IplImage , mapMatrix * Mat , flags int , fillVal Scalar ) { C . cvWarpPerspective ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , ( * C . struct_CvMat ) ( mapMatrix ) , C . int ( flags ) , ( C . CvScalar ) ( fillVal ) ) } 
func ( image * IplImage ) FindContours ( mode , method int , offset Point ) * Seq { storage := C . cvCreateMemStorage ( 0 ) header_size := ( C . size_t ) ( unsafe . Sizeof ( C . CvContour { } ) ) var seq * C . CvSeq C . cvFindContours ( unsafe . Pointer ( image ) , storage , & seq , C . int ( header_size ) , C . int ( mode ) , C . int ( method ) , C . cvPoint ( C . int ( offset . X ) , C . int ( offset . Y ) ) ) return ( * Seq ) ( seq ) } 
func DrawContours ( image * IplImage , contours * Seq , externalColor , holeColor Scalar , maxLevel , thickness , lineType int , offset Point ) { C . cvDrawContours ( unsafe . Pointer ( image ) , ( * C . CvSeq ) ( contours ) , ( C . CvScalar ) ( externalColor ) , ( C . CvScalar ) ( holeColor ) , C . int ( maxLevel ) , C . int ( thickness ) , C . int ( lineType ) , C . cvPoint ( C . int ( offset . X ) , C . int ( offset . Y ) ) ) } 
func ApproxPoly ( src * Seq , header_size int , storage * MemStorage , method int , eps float64 , recursive int ) * Seq { seq := C . cvApproxPoly ( unsafe . Pointer ( src ) , C . int ( header_size ) , ( * C . CvMemStorage ) ( storage ) , C . int ( method ) , C . double ( eps ) , C . int ( recursive ) ) return ( * Seq ) ( seq ) } 
func ArcLength ( curve * Seq , slice Slice , is_closed bool ) float64 { is_closed_int := 0 if is_closed { is_closed_int = 1 } return float64 ( C . cvArcLength ( unsafe . Pointer ( curve ) , ( C . CvSlice ) ( slice ) , C . int ( is_closed_int ) ) ) } 
func ContourArea ( contour * Seq , slice Slice , oriented int ) float64 { return float64 ( C . cvContourArea ( unsafe . Pointer ( contour ) , ( C . CvSlice ) ( slice ) , C . int ( oriented ) ) ) } 
func FitEllipse2 ( points unsafe . Pointer ) Box2D { box := C . cvFitEllipse2 ( points ) center := Point2D32f { float32 ( box . center . x ) , float32 ( box . center . y ) } size := Size2D32f { float32 ( box . size . width ) , float32 ( box . size . height ) } angle := float32 ( box . angle ) return Box2D { center , size , angle } } 
func MinAreaRect ( points unsafe . Pointer ) Box2D { box := C . cvMinAreaRect2 ( points , nil ) center := Point2D32f { float32 ( box . center . x ) , float32 ( box . center . y ) } size := Size2D32f { float32 ( box . size . width ) , float32 ( box . size . height ) } angle := float32 ( box . angle ) return Box2D { center , size , angle } } 
func BoundingRect ( points unsafe . Pointer ) Rect { return ( Rect ) ( C . cvBoundingRect ( points , C . int ( 0 ) ) ) } 
func KMeans ( data * Mat , k int , termcrit TermCriteria , attempts int , rng RNG , flags int ) ( labels , centers * Mat ) { var compactness C . double labels = CreateMat ( data . Rows ( ) , 1 , CV_32S ) centers = CreateMat ( k , 1 , data . Type ( ) ) C . cvKMeans2 ( unsafe . Pointer ( data ) , C . int ( k ) , unsafe . Pointer ( labels ) , ( C . CvTermCriteria ) ( termcrit ) , C . int ( attempts ) , ( * C . CvRNG ) ( & rng ) , C . int ( flags ) , unsafe . Pointer ( centers ) , & compactness ) return labels , centers } 
func DecodeImageMem ( data [ ] byte ) * IplImage { buf := CreateMatHeader ( 1 , len ( data ) , CV_8U ) buf . SetData ( unsafe . Pointer ( & data [ 0 ] ) , CV_AUTOSTEP ) defer buf . Release ( ) return DecodeImage ( unsafe . Pointer ( buf ) , CV_LOAD_IMAGE_UNCHANGED ) } 
func FromImage ( img image . Image ) * IplImage { b := img . Bounds ( ) model := color . RGBAModel dst := CreateImage ( b . Max . X - b . Min . X , b . Max . Y - b . Min . Y , IPL_DEPTH_8U , 4 ) for y := b . Min . Y ; y < b . Max . Y ; y ++ { for x := b . Min . X ; x < b . Max . X ; x ++ { px := img . At ( x , y ) c := model . Convert ( px ) . ( color . RGBA ) value := NewScalar ( float64 ( c . B ) , float64 ( c . G ) , float64 ( c . R ) , float64 ( c . A ) ) dst . Set2D ( x - b . Min . X , y - b . Min . Y , value ) } } return dst } 
func FromImageUnsafe ( img * image . RGBA ) * IplImage { b := img . Bounds ( ) buf := CreateImageHeader ( b . Max . X - b . Min . X , b . Max . Y - b . Min . Y , IPL_DEPTH_8U , 4 ) dst := CreateImage ( b . Max . X - b . Min . X , b . Max . Y - b . Min . Y , IPL_DEPTH_8U , 4 ) buf . SetData ( unsafe . Pointer ( & img . Pix [ 0 ] ) , CV_AUTOSTEP ) CvtColor ( buf , dst , CV_RGBA2BGRA ) buf . Release ( ) return dst } 
func ( img * IplImage ) ToImage ( ) image . Image { var height , width , channels , step int = img . Height ( ) , img . Width ( ) , img . Channels ( ) , img . WidthStep ( ) out := image . NewNRGBA ( image . Rect ( 0 , 0 , width , height ) ) if img . Depth ( ) != IPL_DEPTH_8U { return nil } var limg_ptr unsafe . Pointer = unsafe . Pointer ( limg ) var data [ ] C . char = ( * [ 1 << 30 ] C . char ) ( limg_ptr ) [ : height * step : height * step ] c := color . NRGBA { R : uint8 ( 0 ) , G : uint8 ( 0 ) , B : uint8 ( 0 ) , A : uint8 ( 255 ) } c . G = uint8 ( data [ y * step + x + 1 ] ) c . R = uint8 ( data [ y * step + x + 2 ] ) if channels == 4 { c . A = uint8 ( data [ y * step + x + 3 ] ) } out . SetNRGBA ( int ( x / channels ) , y , c ) } } return out } 
func GcvMatToMat64 ( mat GcvMat ) * mat64 . Dense { col := mat . GetCols ( ) row := mat . GetRows ( ) data := [ ] float64 { } for i := 0 ; i < row ; i ++ { for j := 0 ; j < col ; j ++ { if fltPtr , ok := mat . GcvAtf64 ( i , j ) . ( * float64 ) ; ok { data = append ( data , * fltPtr ) } else { panic ( " " ) } } } return mat64 . NewDense ( row , col , data ) } 
func Mat64ToGcvMat ( mat * mat64 . Dense ) GcvMat { row , col := mat . Dims ( ) rawData := NewGcvFloat64Vector ( int64 ( row * col ) ) for i := 0 ; i < row ; i ++ { for j := 0 ; j < col ; j ++ { rawData . Set ( i * col + j , mat . At ( i , j ) ) } } return Mat64ToGcvMat_ ( row , col , rawData ) } 
func ( r * Rect ) TL ( ) Point { return Point { int ( r . x ) , int ( r . y ) } } 
func ( r * Rect ) BR ( ) Point { return Point { int ( r . x ) + int ( r . width ) , int ( r . y ) + int ( r . height ) } } 
func NewCvPoint ( x , y int ) CvPoint { return CvPoint { C . int ( x ) , C . int ( y ) } } 
func ( p CvPoint ) ToPoint ( ) Point { return Point { int ( p . x ) , int ( p . y ) } } 
func NewCvPoint2D32f ( x , y float32 ) CvPoint2D32f { return CvPoint2D32f { C . float ( x ) , C . float ( y ) } } 
func ( p CvPoint2D32f ) ToPoint ( ) Point2D32f { return Point2D32f { float32 ( p . x ) , float32 ( p . y ) } } 
func ( box * Box2D ) CVBox ( ) C . CvBox2D { var cvBox C . CvBox2D cvBox . angle = C . float ( box . angle ) cvBox . center . x = C . float ( box . center . X ) cvBox . center . y = C . float ( box . center . Y ) cvBox . size . width = C . float ( box . size . Width ) cvBox . size . height = C . float ( box . size . Height ) return cvBox } 
func ( box * Box2D ) Points ( ) [ ] Point2D32f { var pts [ 4 ] C . CvPoint2D32f C . cvBoxPoints ( box . CVBox ( ) , ( * C . CvPoint2D32f ) ( unsafe . Pointer ( & pts [ 0 ] ) ) , ) outPts := make ( [ ] Point2D32f , 4 ) for i , p := range pts { outPts [ i ] . X = float32 ( p . x ) outPts [ i ] . Y = float32 ( p . y ) } return outPts } 
func WholeSeq ( ) Slice { slice := C . cvSlice ( C . int ( 0 ) , C . CV_WHOLE_SEQ_END_INDEX ) return ( Slice ) ( slice ) } 
func ( s Scalar ) Val ( ) [ 4 ] float64 { return [ 4 ] float64 { float64 ( s . val [ 0 ] ) , float64 ( s . val [ 1 ] ) , float64 ( s . val [ 2 ] ) , float64 ( s . val [ 3 ] ) , } } 
func initSystem ( args [ ] string ) int { argc := C . int ( len ( args ) ) argv := make ( [ ] * C . char , len ( args ) ) for i := 0 ; i < len ( args ) ; i ++ { argv [ i ] = C . CString ( args [ i ] ) } rv := C . cvInitSystem ( argc , ( * * C . char ) ( unsafe . Pointer ( & argv ) ) ) return int ( rv ) } 
func WaitKey ( delay int ) int { key := C . cvWaitKey ( C . int ( delay ) ) return int ( key ) } 
func NewWindow ( name string , flags ... int ) * Window { win_flags := C . int ( CV_WINDOW_AUTOSIZE ) if len ( flags ) > 0 { win_flags = C . int ( flags [ 0 ] ) } win := & Window { name : name , name_c : C . CString ( name ) , flags : win_flags , trackbarHandle : make ( map [ string ] TrackbarFunc , 50 ) , trackbarMax : make ( map [ string ] int , 50 ) , trackbarVal : make ( map [ string ] int , 50 ) , trackbarName : make ( map [ string ] ( * C . char ) , 50 ) , trackbarParam : make ( map [ string ] ( [ ] interface { } ) , 50 ) , } C . cvNamedWindow ( win . name_c , win . flags ) C . GoOpenCV_SetMouseCallback ( win . name_c ) allWindows [ win . name ] = win return win } 
func ( win * Window ) SetProperty ( prop_id int , value float64 ) { C . cvSetWindowProperty ( win . name_c , C . int ( prop_id ) , C . double ( value ) ) } 
func ( win * Window ) ShowImage ( image * IplImage ) { win . image = image C . cvShowImage ( win . name_c , unsafe . Pointer ( image ) ) } 
func ( win * Window ) Resize ( width , height int ) { C . cvResizeWindow ( win . name_c , C . int ( width ) , C . int ( height ) ) } 
func ( win * Window ) GetHandle ( ) unsafe . Pointer { p := C . cvGetWindowHandle ( win . name_c ) return unsafe . Pointer ( p ) } 
func ( win * Window ) CreateTrackbar ( name string , value , count int , on_changed TrackbarFunc , param ... interface { } ) bool { bar_name := C . CString ( name ) switch f := on_changed . ( type ) { case TrackbarFuncA : win . trackbarHandle [ name ] = TrackbarFunc ( f ) case TrackbarFuncB : win . trackbarHandle [ name ] = TrackbarFunc ( f ) case func ( pos int ) : win . trackbarHandle [ name ] = TrackbarFunc ( f ) case func ( pos int , param ... interface { } ) : win . trackbarHandle [ name ] = TrackbarFunc ( f ) default : panic ( " " ) } win . trackbarVal [ name ] = value win . trackbarMax [ name ] = count if len ( param ) > 0 { win . trackbarParam [ name ] = param } else { win . trackbarParam [ name ] = nil } rv := C . GoOpenCV_CreateTrackbar ( bar_name , win . name_c , C . int ( value ) , C . int ( count ) ) return bool ( rv != 0 ) } 
func goTrackbarCallback ( barName_ , winName_ * C . char , pos C . int ) { runtime . LockOSThread ( ) defer runtime . UnlockOSThread ( ) winName := C . GoString ( winName_ ) barName := C . GoString ( barName_ ) win , ok := allWindows [ winName ] if ! ok { return } trackbarHandle , ok := win . trackbarHandle [ barName ] if ! ok { return } if trackbarHandle == nil { return } if fa , ok := trackbarHandle . ( func ( pos int ) ) ; ok { fa ( int ( pos ) ) } else if fb , ok := trackbarHandle . ( func ( pos int , param ... interface { } ) ) ; ok { param := win . trackbarParam [ barName ] if param != nil { fb ( int ( pos ) , param ... ) } else { fb ( int ( pos ) ) } } } 
func ( win * Window ) GetTrackbarPos ( name string ) ( value , max int ) { rv := C . cvGetTrackbarPos ( win . trackbarName [ name ] , win . name_c ) return int ( rv ) , win . trackbarMax [ name ] } 
func ( win * Window ) SetMouseCallback ( on_mouse MouseFunc , param ... interface { } ) { switch f := on_mouse . ( type ) { case MouseFuncA : win . mouseHandle = MouseFunc ( f ) case MouseFuncB : win . mouseHandle = MouseFunc ( f ) case func ( event , x , y , flags int ) : win . mouseHandle = MouseFunc ( f ) case func ( event , x , y , flags int , param ... interface { } ) : win . mouseHandle = MouseFunc ( f ) default : panic ( " " ) } if len ( param ) > 0 { win . param = param } else { win . param = nil } } 
func goMouseCallback ( name * C . char , event , x , y , flags C . int ) { runtime . LockOSThread ( ) defer runtime . UnlockOSThread ( ) winName := C . GoString ( name ) win , ok := allWindows [ winName ] if ! ok { return } if win . mouseHandle == nil { return } if fa , ok := win . mouseHandle . ( func ( event , x , y , flags int ) ) ; ok { fa ( int ( event ) , int ( x ) , int ( y ) , int ( flags ) ) return } if fb , ok := win . mouseHandle . ( func ( event , x , y , flags int , param ... interface { } ) ) ; ok { if win . param != nil { fb ( int ( event ) , int ( x ) , int ( y ) , int ( flags ) , win . param ... ) } else { fb ( int ( event ) , int ( x ) , int ( y ) , int ( flags ) ) } return } } 
func ( win * Window ) Destroy ( ) { C . cvDestroyWindow ( win . name_c ) delete ( allWindows , win . name ) for _ , bar_name := range win . trackbarName { C . GoOpenCV_DestroyTrackbar ( bar_name , win . name_c ) C . free ( unsafe . Pointer ( bar_name ) ) } C . free ( unsafe . Pointer ( win . name_c ) ) win . name_c = nil } 
func LoadImage ( filename string , iscolor_ ... int ) * IplImage { iscolor := CV_LOAD_IMAGE_COLOR if len ( iscolor_ ) > 0 { iscolor = iscolor_ [ 0 ] } name_c := C . CString ( filename ) defer C . free ( unsafe . Pointer ( name_c ) ) rv := C . cvLoadImage ( name_c , C . int ( iscolor ) ) return ( * IplImage ) ( rv ) } 
func SaveImage ( filename string , image * IplImage , params [ ] int ) int { name_c := C . CString ( filename ) defer C . free ( unsafe . Pointer ( name_c ) ) var firstParam * C . int if len ( params ) > 0 { var params_c [ ] C . int for _ , param := range params { params_c = append ( params_c , C . int ( param ) ) } firstParam = & params_c [ 0 ] } rv := C . cvSaveImage ( name_c , unsafe . Pointer ( image ) , firstParam ) return int ( rv ) } 
func DecodeImage ( buf unsafe . Pointer , iscolor int ) * IplImage { rv := C . cvDecodeImage ( ( * C . CvMat ) ( buf ) , C . int ( iscolor ) ) return ( * IplImage ) ( rv ) } 
func EncodeImage ( ext string , image unsafe . Pointer , params [ ] int ) * Mat { var firstParam * C . int if len ( params ) > 0 { var params_c [ ] C . int for _ , param := range params { params_c = append ( params_c , C . int ( param ) ) } firstParam = & params_c [ 0 ] } ext_c := C . CString ( ext ) defer C . free ( unsafe . Pointer ( ext_c ) ) rv := C . cvEncodeImage ( ext_c , ( image ) , firstParam ) return ( * Mat ) ( rv ) } 
func ConvertImage ( src , dst unsafe . Pointer , flags int ) { C . cvConvertImage ( src , dst , C . int ( flags ) ) } 
func NewFileCapture ( filename string ) * Capture { filename_c := C . CString ( filename ) defer C . free ( unsafe . Pointer ( filename_c ) ) cap := C . cvCreateFileCapture ( filename_c ) return ( * Capture ) ( cap ) } 
func NewCameraCapture ( index int ) * Capture { cap := C . cvCreateCameraCapture ( C . int ( index ) ) return ( * Capture ) ( cap ) } 
func ( capture * Capture ) GrabFrame ( ) bool { rv := C . cvGrabFrame ( ( * C . CvCapture ) ( capture ) ) return ( rv != C . int ( 0 ) ) } 
func ( capture * Capture ) RetrieveFrame ( streamIdx int ) * IplImage { rv := C . cvRetrieveFrame ( ( * C . CvCapture ) ( capture ) , C . int ( streamIdx ) ) return ( * IplImage ) ( rv ) } 
func ( capture * Capture ) QueryFrame ( ) * IplImage { rv := C . cvQueryFrame ( ( * C . CvCapture ) ( capture ) ) return ( * IplImage ) ( rv ) } 
func ( capture * Capture ) Release ( ) { cap_c := ( * C . CvCapture ) ( capture ) C . cvReleaseCapture ( & cap_c ) } 
func ( capture * Capture ) GetProperty ( property_id int ) float64 { rv := C . cvGetCaptureProperty ( ( * C . CvCapture ) ( capture ) , C . int ( property_id ) , ) return float64 ( rv ) } 
func ( capture * Capture ) GetDomain ( ) int { rv := C . cvGetCaptureDomain ( ( * C . CvCapture ) ( capture ) ) return int ( rv ) } 
func FOURCC ( c1 , c2 , c3 , c4 int8 ) uint32 { rv := C . GoOpenCV_FOURCC_ ( C . int ( c1 ) , C . int ( c2 ) , C . int ( c3 ) , C . int ( c4 ) ) return uint32 ( rv ) } 
func NewVideoWriter ( filename string , fourcc int , fps float32 , frame_width , frame_height , is_color int ) * VideoWriter { size := C . cvSize ( C . int ( frame_width ) , C . int ( frame_height ) ) filename_c := C . CString ( filename ) defer C . free ( unsafe . Pointer ( filename_c ) ) rv := C . cvCreateVideoWriter ( filename_c , C . int ( fourcc ) , C . double ( fps ) , size , C . int ( is_color ) , ) return ( * VideoWriter ) ( rv ) } 
func ( writer * VideoWriter ) WriteFrame ( image * IplImage ) int { rv := C . cvWriteFrame ( ( * C . CvVideoWriter ) ( writer ) , ( * C . IplImage ) ( image ) ) return int ( rv ) } 
func ( writer * VideoWriter ) Release ( ) { writer_c := ( * C . CvVideoWriter ) ( writer ) C . cvReleaseVideoWriter ( & writer_c ) } 
func GcvInitCameraMatrix2D ( objPts , imgPts * mat64 . Dense , dims [ 2 ] int , aspectRatio float64 ) ( camMat * mat64 . Dense ) { objDim , nObjPts := objPts . Dims ( ) imgDim , nImgPts := imgPts . Dims ( ) if objDim != 3 || imgDim != 2 || nObjPts != nImgPts { panic ( " " ) } objPtsVec := NewGcvPoint3f32Vector ( int64 ( nObjPts ) ) imgPtsVec := NewGcvPoint2f32Vector ( int64 ( nObjPts ) ) for j := 0 ; j < nObjPts ; j ++ { objPtsVec . Set ( j , NewGcvPoint3f32 ( mat64 . Col ( nil , j , objPts ) ... ) ) } for j := 0 ; j < nObjPts ; j ++ { imgPtsVec . Set ( j , NewGcvPoint2f32 ( mat64 . Col ( nil , j , imgPts ) ... ) ) } _imgSize := NewGcvSize2i ( dims [ 0 ] , dims [ 1 ] ) camMat = GcvMatToMat64 ( GcvInitCameraMatrix2D_ ( objPtsVec , imgPtsVec , _imgSize , aspectRatio ) ) return camMat } 
func GcvRodrigues ( src * mat64 . Dense ) ( dst * mat64 . Dense ) { gcvSrc := Mat64ToGcvMat ( src ) gcvDst := NewGcvMat ( ) GcvRodrigues_ ( gcvSrc , gcvDst ) dst = GcvMatToMat64 ( gcvDst ) return dst } 
func Alloc ( size int ) unsafe . Pointer { return unsafe . Pointer ( C . cvAlloc ( C . size_t ( size ) ) ) } 
func CreateImageHeader ( w , h , depth , channels int ) * IplImage { hdr := C . cvCreateImageHeader ( C . cvSize ( C . int ( w ) , C . int ( h ) ) , C . int ( depth ) , C . int ( channels ) , ) return ( * IplImage ) ( hdr ) } 
func ( img * IplImage ) InitHeader ( w , h , depth , channels , origin , align int ) { C . cvInitImageHeader ( ( * C . IplImage ) ( img ) , C . cvSize ( C . int ( w ) , C . int ( h ) ) , C . int ( depth ) , C . int ( channels ) , C . int ( origin ) , C . int ( align ) , ) } 
func CreateImage ( w , h , depth , channels int ) * IplImage { size := C . cvSize ( C . int ( w ) , C . int ( h ) ) img := C . cvCreateImage ( size , C . int ( depth ) , C . int ( channels ) ) return ( * IplImage ) ( img ) } 
func Merge ( imgBlue , imgGreen , imgRed , imgAlpha , dst * IplImage ) { C . cvMerge ( unsafe . Pointer ( imgBlue ) , unsafe . Pointer ( imgGreen ) , unsafe . Pointer ( imgRed ) , unsafe . Pointer ( imgAlpha ) , unsafe . Pointer ( dst ) , ) } 
func Split ( src , imgBlue , imgGreen , imgRed , imgAlpha * IplImage ) { C . cvSplit ( unsafe . Pointer ( src ) , unsafe . Pointer ( imgBlue ) , unsafe . Pointer ( imgGreen ) , unsafe . Pointer ( imgRed ) , unsafe . Pointer ( imgAlpha ) , ) } 
func AddWeighted ( src1 * IplImage , alpha float64 , src2 * IplImage , beta float64 , gamma float64 , dst * IplImage ) { C . cvAddWeighted ( unsafe . Pointer ( src1 ) , C . double ( alpha ) , unsafe . Pointer ( src2 ) , C . double ( beta ) , C . double ( gamma ) , unsafe . Pointer ( dst ) , ) } 
func ( img * IplImage ) SetData ( data unsafe . Pointer , step int ) { C . cvSetData ( unsafe . Pointer ( img ) , data , C . int ( step ) ) } 
func ( img * IplImage ) ReleaseHeader ( ) { img_c := ( * C . IplImage ) ( img ) C . cvReleaseImageHeader ( & img_c ) } 
func ( img * IplImage ) Release ( ) { img_c := ( * C . IplImage ) ( img ) C . cvReleaseImage ( & img_c ) } 
func ( img * IplImage ) Clone ( ) * IplImage { p := C . cvCloneImage ( ( * C . IplImage ) ( img ) ) return ( * IplImage ) ( p ) } 
func ( img * IplImage ) SetCOI ( coi int ) { C . cvSetImageCOI ( ( * C . IplImage ) ( img ) , C . int ( coi ) ) } 
func ( img * IplImage ) GetCOI ( ) int { coi := C . cvGetImageCOI ( ( * C . IplImage ) ( img ) ) return int ( coi ) } 
func ( img * IplImage ) SetROI ( rect Rect ) { C . cvSetImageROI ( ( * C . IplImage ) ( img ) , C . CvRect ( rect ) ) } 
func ( img * IplImage ) GetROI ( ) Rect { r := C . cvGetImageROI ( ( * C . IplImage ) ( img ) ) return Rect ( r ) } 
func ( img * IplImage ) Reshape ( channels , rows , _type int ) * Mat { total := img . Width ( ) * img . Height ( ) header := CreateMat ( rows , total / rows , _type ) n := C . cvReshape ( unsafe . Pointer ( img ) , ( * C . CvMat ) ( header ) , C . int ( channels ) , C . int ( rows ) ) return ( * Mat ) ( n ) } 
func ( img * IplImage ) Get1D ( x int ) Scalar { ret := C . cvGet1D ( unsafe . Pointer ( img ) , C . int ( x ) ) return Scalar ( ret ) } 
func ( img * IplImage ) Get2D ( x , y int ) Scalar { ret := C . cvGet2D ( unsafe . Pointer ( img ) , C . int ( y ) , C . int ( x ) ) return Scalar ( ret ) } 
func ( img * IplImage ) Get3D ( x , y , z int ) Scalar { ret := C . cvGet3D ( unsafe . Pointer ( img ) , C . int ( z ) , C . int ( y ) , C . int ( x ) ) return Scalar ( ret ) } 
func ( img * IplImage ) Set ( value Scalar ) { C . cvSet ( unsafe . Pointer ( img ) , ( C . CvScalar ) ( value ) , nil ) } 
func ( img * IplImage ) Set1D ( x int , value Scalar ) { C . cvSet1D ( unsafe . Pointer ( img ) , C . int ( x ) , ( C . CvScalar ) ( value ) ) } 
func ( img * IplImage ) Set2D ( x , y int , value Scalar ) { C . cvSet2D ( unsafe . Pointer ( img ) , C . int ( y ) , C . int ( x ) , ( C . CvScalar ) ( value ) ) } 
func ( img * IplImage ) Set3D ( x , y , z int , value Scalar ) { C . cvSet3D ( unsafe . Pointer ( img ) , C . int ( z ) , C . int ( y ) , C . int ( x ) , ( C . CvScalar ) ( value ) ) } 
func ( img * IplImage ) GetMat ( ) * Mat { var null C . int tmp := CreateMat ( img . Height ( ) , img . Width ( ) , CV_32S ) m := C . cvGetMat ( unsafe . Pointer ( img ) , ( * C . CvMat ) ( tmp ) , & null , C . int ( 0 ) ) return ( * Mat ) ( m ) } 
func CreateMatHeader ( rows , cols , type_ int ) * Mat { mat := C . cvCreateMatHeader ( C . int ( rows ) , C . int ( cols ) , C . int ( type_ ) , ) return ( * Mat ) ( mat ) } 
func CreateMat ( rows , cols , type_ int ) * Mat { mat := C . cvCreateMat ( C . int ( rows ) , C . int ( cols ) , C . int ( type_ ) , ) return ( * Mat ) ( mat ) } 
func ( mat * Mat ) InitHeader ( rows , cols , type_ int , data unsafe . Pointer , step int ) { C . cvInitMatHeader ( ( * C . CvMat ) ( mat ) , C . int ( rows ) , C . int ( cols ) , C . int ( type_ ) , data , C . int ( step ) , ) } 
func ( mat * Mat ) SetData ( data unsafe . Pointer , step int ) { C . cvSetData ( unsafe . Pointer ( mat ) , data , C . int ( step ) ) } 
func ( mat * Mat ) Release ( ) { mat_c := ( * C . CvMat ) ( mat ) C . cvReleaseMat ( & mat_c ) } 
func ( mat * Mat ) Clone ( ) * Mat { mat_new := C . cvCloneMat ( ( * C . CvMat ) ( mat ) ) return ( * Mat ) ( mat_new ) } 
func ( m * Mat ) Reshape ( channels , rows int ) * Mat { total := m . Cols ( ) * m . Rows ( ) n := CreateMat ( rows , total / rows , m . Type ( ) ) C . cvReshape ( unsafe . Pointer ( m ) , ( * C . CvMat ) ( n ) , C . int ( channels ) , C . int ( rows ) ) return n } 
func GetSubRect ( arr Arr , submat * Mat , rect Rect ) * Mat { mat_new := C . cvGetSubRect ( unsafe . Pointer ( arr ) , ( * C . CvMat ) ( submat ) , ( C . CvRect ) ( rect ) , ) return ( * Mat ) ( mat_new ) } 
func GetRows ( arr Arr , submat * Mat , start_row , end_row , delta_row int ) * Mat { mat_new := C . cvGetRows ( unsafe . Pointer ( arr ) , ( * C . CvMat ) ( submat ) , C . int ( start_row ) , C . int ( end_row ) , C . int ( delta_row ) , ) return ( * Mat ) ( mat_new ) } 
func GetCols ( arr Arr , submat * Mat , start_col , end_col int ) * Mat { mat_new := C . cvGetCols ( unsafe . Pointer ( arr ) , ( * C . CvMat ) ( submat ) , C . int ( start_col ) , C . int ( end_col ) , ) return ( * Mat ) ( mat_new ) } 
func GetDiag ( arr Arr , submat * Mat , diag int ) * Mat { mat_new := C . cvGetDiag ( unsafe . Pointer ( arr ) , ( * C . CvMat ) ( submat ) , C . int ( diag ) , ) return ( * Mat ) ( mat_new ) } 
func ( m * Mat ) Get1D ( x int ) Scalar { ret := C . cvGet1D ( unsafe . Pointer ( m ) , C . int ( x ) ) return Scalar ( ret ) } 
func ( m * Mat ) Get2D ( x , y int ) Scalar { ret := C . cvGet2D ( unsafe . Pointer ( m ) , C . int ( x ) , C . int ( y ) ) return Scalar ( ret ) } 
func ( m * Mat ) Get3D ( x , y , z int ) Scalar { ret := C . cvGet3D ( unsafe . Pointer ( m ) , C . int ( x ) , C . int ( y ) , C . int ( z ) ) return Scalar ( ret ) } 
func ( m * Mat ) Set1D ( x int , value Scalar ) { C . cvSet1D ( unsafe . Pointer ( m ) , C . int ( x ) , ( C . CvScalar ) ( value ) ) } 
func ( m * Mat ) Set2D ( x , y int , value Scalar ) { C . cvSet2D ( unsafe . Pointer ( m ) , C . int ( x ) , C . int ( y ) , ( C . CvScalar ) ( value ) ) } 
func ( m * Mat ) Set3D ( x , y , z int , value Scalar ) { C . cvSet3D ( unsafe . Pointer ( m ) , C . int ( x ) , C . int ( y ) , C . int ( z ) , ( C . CvScalar ) ( value ) ) } 
func ( m * Mat ) GetImage ( channels int ) * IplImage { tmp := CreateImage ( m . Cols ( ) , m . Rows ( ) , m . Type ( ) , channels ) img := C . cvGetImage ( unsafe . Pointer ( m ) , ( * C . IplImage ) ( tmp ) ) return ( * IplImage ) ( img ) } 
func ScalarToRawData ( scalar * Scalar , data unsafe . Pointer , type_ , extend_to_12 int ) { C . cvScalarToRawData ( ( * C . CvScalar ) ( scalar ) , data , C . int ( type_ ) , C . int ( extend_to_12 ) , ) } 
func CreateMatNDHeader ( sizes [ ] int , type_ int ) * MatND { dims := C . int ( len ( sizes ) ) sizes_c := make ( [ ] C . int , len ( sizes ) ) for i := 0 ; i < len ( sizes ) ; i ++ { sizes_c [ i ] = C . int ( sizes [ i ] ) } mat := C . cvCreateMatNDHeader ( dims , ( * C . int ) ( & sizes_c [ 0 ] ) , C . int ( type_ ) , ) return ( * MatND ) ( mat ) } 
func CreateMatND ( sizes [ ] int , type_ int ) * MatND { dims := C . int ( len ( sizes ) ) sizes_c := make ( [ ] C . int , len ( sizes ) ) for i := 0 ; i < len ( sizes ) ; i ++ { sizes_c [ i ] = C . int ( sizes [ i ] ) } mat := C . cvCreateMatND ( dims , ( * C . int ) ( & sizes_c [ 0 ] ) , C . int ( type_ ) , ) return ( * MatND ) ( mat ) } 
func ( mat * MatND ) InitMatNDHeader ( sizes [ ] int , type_ int , data unsafe . Pointer ) { dims := C . int ( len ( sizes ) ) sizes_c := make ( [ ] C . int , len ( sizes ) ) for i := 0 ; i < len ( sizes ) ; i ++ { sizes_c [ i ] = C . int ( sizes [ i ] ) } C . cvInitMatNDHeader ( ( * C . CvMatND ) ( mat ) , dims , ( * C . int ) ( & sizes_c [ 0 ] ) , C . int ( type_ ) , data , ) } 
func ( mat * MatND ) Release ( ) { mat_c := ( * C . CvMatND ) ( mat ) C . cvReleaseMatND ( & mat_c ) } 
func ( mat * MatND ) Clone ( ) * MatND { mat_c := ( * C . CvMatND ) ( mat ) mat_ret := C . cvCloneMatND ( mat_c ) return ( * MatND ) ( mat_ret ) } 
func CreateSparseMat ( sizes [ ] int , type_ int ) * SparseMat { dims := C . int ( len ( sizes ) ) sizes_c := make ( [ ] C . int , len ( sizes ) ) for i := 0 ; i < len ( sizes ) ; i ++ { sizes_c [ i ] = C . int ( sizes [ i ] ) } mat := C . cvCreateSparseMat ( dims , ( * C . int ) ( & sizes_c [ 0 ] ) , C . int ( type_ ) , ) return ( * SparseMat ) ( mat ) } 
func ( mat * SparseMat ) Release ( ) { mat_c := ( * C . CvSparseMat ) ( mat ) C . cvReleaseSparseMat ( & mat_c ) } 
func ( mat * SparseMat ) Clone ( ) * SparseMat { mat_c := ( * C . CvSparseMat ) ( mat ) mat_ret := C . cvCloneSparseMat ( mat_c ) return ( * SparseMat ) ( mat_ret ) } 
func ( mat * SparseMat ) InitSparseMatIterator ( iter * SparseMatIterator ) * SparseNode { mat_c := ( * C . CvSparseMat ) ( mat ) node := C . cvInitSparseMatIterator ( mat_c , ( * C . CvSparseMatIterator ) ( iter ) ) return ( * SparseNode ) ( node ) } 
func ( iter * SparseMatIterator ) Next ( ) * SparseNode { node := C . cvGetNextSparseNode ( ( * C . CvSparseMatIterator ) ( iter ) ) return ( * SparseNode ) ( node ) } 
func GetSizeWidth ( img * IplImage ) int { size := C . cvGetSize ( unsafe . Pointer ( img ) ) w := int ( size . width ) return w } 
func Copy ( src , dst , mask * IplImage ) { C . cvCopy ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) ) } 
func Not ( src , dst * IplImage ) { C . cvNot ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , ) } 
func And ( src1 , src2 , dst * IplImage ) { AndWithMask ( src1 , src2 , dst , nil ) } 
func AndWithMask ( src1 , src2 , dst , mask * IplImage ) { C . cvAnd ( unsafe . Pointer ( src1 ) , unsafe . Pointer ( src2 ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func AndScalar ( src * IplImage , value Scalar , dst * IplImage ) { AndScalarWithMask ( src , value , dst , nil ) } 
func AndScalarWithMask ( src * IplImage , value Scalar , dst , mask * IplImage ) { C . cvAndS ( unsafe . Pointer ( src ) , ( C . CvScalar ) ( value ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func Or ( src1 , src2 , dst * IplImage ) { OrWithMask ( src1 , src2 , dst , nil ) } 
func OrWithMask ( src1 , src2 , dst , mask * IplImage ) { C . cvOr ( unsafe . Pointer ( src1 ) , unsafe . Pointer ( src2 ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func OrScalar ( src * IplImage , value Scalar , dst * IplImage ) { OrScalarWithMask ( src , value , dst , nil ) } 
func OrScalarWithMask ( src * IplImage , value Scalar , dst , mask * IplImage ) { C . cvOrS ( unsafe . Pointer ( src ) , ( C . CvScalar ) ( value ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func Xor ( src1 , src2 , dst * IplImage ) { XorWithMask ( src1 , src2 , dst , nil ) } 
func XorWithMask ( src1 , src2 , dst , mask * IplImage ) { C . cvXor ( unsafe . Pointer ( src1 ) , unsafe . Pointer ( src2 ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func XorScalar ( src * IplImage , value Scalar , dst * IplImage ) { XorScalarWithMask ( src , value , dst , nil ) } 
func XorScalarWithMask ( src * IplImage , value Scalar , dst , mask * IplImage ) { C . cvXorS ( unsafe . Pointer ( src ) , ( C . CvScalar ) ( value ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func Add ( src1 , src2 , dst * IplImage ) { AddWithMask ( src1 , src2 , dst , nil ) } 
func AddWithMask ( src1 , src2 , dst , mask * IplImage ) { C . cvAdd ( unsafe . Pointer ( src1 ) , unsafe . Pointer ( src2 ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func AddScalar ( src * IplImage , value Scalar , dst * IplImage ) { AddScalarWithMask ( src , value , dst , nil ) } 
func AddScalarWithMask ( src * IplImage , value Scalar , dst , mask * IplImage ) { C . cvAddS ( unsafe . Pointer ( src ) , ( C . CvScalar ) ( value ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func Subtract ( src1 , src2 , dst * IplImage ) { SubtractWithMask ( src1 , src2 , dst , nil ) } 
func SubtractWithMask ( src1 , src2 , dst , mask * IplImage ) { C . cvSub ( unsafe . Pointer ( src1 ) , unsafe . Pointer ( src2 ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func SubScalar ( src * IplImage , value Scalar , dst * IplImage ) { SubScalarWithMask ( src , value , dst , nil ) } 
func SubScalarWithMask ( src * IplImage , value Scalar , dst , mask * IplImage ) { C . cvSubS ( unsafe . Pointer ( src ) , ( C . CvScalar ) ( value ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func SubScalarRev ( value Scalar , src , dst * IplImage ) { SubScalarWithMaskRev ( value , src , dst , nil ) } 
func SubScalarWithMaskRev ( value Scalar , src , dst , mask * IplImage ) { C . cvSubRS ( unsafe . Pointer ( src ) , ( C . CvScalar ) ( value ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( mask ) , ) } 
func AbsDiff ( src1 , src2 , dst * IplImage ) { C . cvAbsDiff ( unsafe . Pointer ( src1 ) , unsafe . Pointer ( src2 ) , unsafe . Pointer ( dst ) , ) } 
func AbsDiffScalar ( src * IplImage , value Scalar , dst * IplImage ) { C . cvAbsDiffS ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , ( C . CvScalar ) ( value ) , ) } 
func ( src * IplImage ) Avg ( mask * IplImage ) Scalar { return ( Scalar ) ( C . cvAvg ( unsafe . Pointer ( src ) , unsafe . Pointer ( mask ) ) ) } 
func ( src * IplImage ) EqualizeHist ( dst * IplImage ) { C . cvEqualizeHist ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) ) } 
func MeanStdDevWithMask ( src , mask * IplImage ) ( Scalar , Scalar ) { var mean , stdDev Scalar C . cvAvgSdv ( unsafe . Pointer ( src ) , ( * C . CvScalar ) ( & mean ) , ( * C . CvScalar ) ( & stdDev ) , unsafe . Pointer ( mask ) , ) return mean , stdDev } 
func CreateSeq ( seq_flags , elem_size int ) * Seq { return ( * Seq ) ( C . cvCreateSeq ( C . int ( seq_flags ) , C . size_t ( unsafe . Sizeof ( Seq { } ) ) , C . size_t ( elem_size ) , C . cvCreateMemStorage ( C . int ( 0 ) ) , ) ) } 
func ( seq * Seq ) Push ( element unsafe . Pointer ) unsafe . Pointer { return unsafe . Pointer ( C . cvSeqPush ( ( * C . struct_CvSeq ) ( seq ) , element ) ) } 
func ( seq * Seq ) Pop ( element unsafe . Pointer ) { C . cvSeqPop ( ( * C . struct_CvSeq ) ( seq ) , element ) } 
func ( seq * Seq ) PushFront ( element unsafe . Pointer ) unsafe . Pointer { return unsafe . Pointer ( ( C . cvSeqPushFront ( ( * C . struct_CvSeq ) ( seq ) , element ) ) ) } 
func ( seq * Seq ) PopFront ( element unsafe . Pointer ) { C . cvSeqPopFront ( ( * C . struct_CvSeq ) ( seq ) , element ) } 
func ( seq * Seq ) GetElemAt ( index int ) unsafe . Pointer { return ( unsafe . Pointer ) ( C . cvGetSeqElem ( ( * C . struct_CvSeq ) ( seq ) , C . int ( index ) , ) ) } 
func ( seq * Seq ) RemoveAt ( index int ) { C . cvSeqRemove ( ( * C . struct_CvSeq ) ( seq ) , C . int ( index ) ) } 
func Line ( image * IplImage , pt1 , pt2 Point , color Scalar , thickness , line_type , shift int ) { C . cvLine ( unsafe . Pointer ( image ) , C . cvPoint ( C . int ( pt1 . X ) , C . int ( pt1 . Y ) ) , C . cvPoint ( C . int ( pt2 . X ) , C . int ( pt2 . Y ) ) , ( C . CvScalar ) ( color ) , C . int ( thickness ) , C . int ( line_type ) , C . int ( shift ) , ) } 
func InitFont ( fontFace int , hscale , vscale , shear float32 , thickness , lineType int ) * Font { font := new ( Font ) C . cvInitFont ( & font . font , C . int ( fontFace ) , C . double ( hscale ) , C . double ( vscale ) , C . double ( shear ) , C . int ( thickness ) , C . int ( lineType ) , ) return font } 
func ( this * Font ) PutText ( image * IplImage , text string , pt1 Point , color Scalar ) { C . cvPutText ( unsafe . Pointer ( image ) , C . CString ( text ) , C . cvPoint ( C . int ( pt1 . X ) , C . int ( pt1 . Y ) ) , & this . font , ( C . CvScalar ) ( color ) , ) } 
func Smooth ( src , dst * IplImage , smoothtype , param1 , param2 int , param3 , param4 float64 ) { C . cvSmooth ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , C . int ( smoothtype ) , C . int ( param1 ) , C . int ( param2 ) , C . double ( param3 ) , C . double ( param4 ) , ) } 
func Laplace ( src , dst * IplImage , aperture_size int ) { C . cvLaplace ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , C . int ( aperture_size ) ) } 
func ConvertScale ( a , b * IplImage , scale , shift float64 ) { C . cvConvertScale ( unsafe . Pointer ( a ) , unsafe . Pointer ( b ) , C . double ( scale ) , C . double ( shift ) ) } 
func CvtColor ( src , dst * IplImage , code int ) { C . cvCvtColor ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , C . int ( code ) ) } 
func Canny ( image , edges * IplImage , threshold1 , threshold2 float64 , aperture_size int ) { C . cvCanny ( unsafe . Pointer ( image ) , unsafe . Pointer ( edges ) , C . double ( threshold1 ) , C . double ( threshold2 ) , C . int ( aperture_size ) , ) } 
func Sobel ( src , dst * IplImage , xorder , yorder , aperture_size int ) { C . cvSobel ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , C . int ( xorder ) , C . int ( yorder ) , C . int ( aperture_size ) , ) } 
func Inpaint ( src , inpaint_mask , dst * IplImage , inpaintRange float64 , flags int ) { C . cvInpaint ( unsafe . Pointer ( src ) , unsafe . Pointer ( inpaint_mask ) , unsafe . Pointer ( dst ) , C . double ( inpaintRange ) , C . int ( flags ) , ) } 
func Threshold ( src , dst * IplImage , threshold , max_value float64 , threshold_type int ) { C . cvThreshold ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , C . double ( threshold ) , C . double ( max_value ) , C . int ( threshold_type ) , ) } 
func AdaptiveThreshold ( src , dst * IplImage , max_value float64 , adaptive_method , threshold_type , block_size int , thresh_C float64 ) { C . cvAdaptiveThreshold ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , C . double ( max_value ) , C . int ( adaptive_method ) , C . int ( threshold_type ) , C . int ( block_size ) , C . double ( thresh_C ) , ) } 
func CreateStructuringElement ( cols , rows , anchor_x , anchor_y , shape int ) * IplConvKernel { return ( * IplConvKernel ) ( C . cvCreateStructuringElementEx ( C . int ( cols ) , C . int ( rows ) , C . int ( anchor_x ) , C . int ( anchor_y ) , C . int ( shape ) , nil , } 
func ( k * IplConvKernel ) ReleaseElement ( ) { C . cvReleaseStructuringElement ( ( * * C . IplConvKernel ) ( unsafe . Pointer ( & k ) ) , ) } 
func Dilate ( src , dst * IplImage , element * IplConvKernel , iterations int ) { C . cvDilate ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , ( * C . IplConvKernel ) ( unsafe . Pointer ( element ) ) , C . int ( iterations ) , ) } 
func Erode ( src , dst * IplImage , element * IplConvKernel , iterations int ) { C . cvErode ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , ( * C . IplConvKernel ) ( unsafe . Pointer ( element ) ) , C . int ( iterations ) , ) } 
func MorphologyEx ( src , dst , temp * IplImage , element * IplConvKernel , operation int , iterations int ) { C . cvMorphologyEx ( unsafe . Pointer ( src ) , unsafe . Pointer ( dst ) , unsafe . Pointer ( temp ) , ( * C . IplConvKernel ) ( unsafe . Pointer ( element ) ) , C . int ( operation ) , C . int ( iterations ) , ) } 
func Delay ( delay time . Duration ) Option { return func ( c * Config ) { c . delay = delay } } 
func BackOffDelay ( n uint , config * Config ) time . Duration { return config . delay * ( 1 << ( n - 1 ) ) } 
func ( e Error ) Error ( ) string { logWithNumber := make ( [ ] string , lenWithoutNil ( e ) ) for i , l := range e { if l != nil { logWithNumber [ i ] = fmt . Sprintf ( " " , i + 1 , l . Error ( ) ) } } return fmt . Sprintf ( " \n " , strings . Join ( logWithNumber , " \n " ) ) } 
func ( r * RequestBuilder ) Arguments ( args ... string ) * RequestBuilder { r . args = append ( r . args , args ... ) return r } 
func ( r * RequestBuilder ) BodyString ( body string ) * RequestBuilder { return r . Body ( strings . NewReader ( body ) ) } 
func ( r * RequestBuilder ) BodyBytes ( body [ ] byte ) * RequestBuilder { return r . Body ( bytes . NewReader ( body ) ) } 
func ( r * RequestBuilder ) Body ( body io . Reader ) * RequestBuilder { r . body = body return r } 
func ( r * RequestBuilder ) Option ( key string , value interface { } ) * RequestBuilder { var s string switch v := value . ( type ) { case bool : s = strconv . FormatBool ( v ) case string : s = v case [ ] byte : s = string ( v ) default : } if r . opts == nil { r . opts = make ( map [ string ] string , 1 ) } r . opts [ key ] = s return r } 
func ( r * RequestBuilder ) Header ( name , value string ) * RequestBuilder { if r . headers == nil { r . headers = make ( map [ string ] string , 1 ) } r . headers [ name ] = value return r } 
func ( r * RequestBuilder ) Send ( ctx context . Context ) ( * Response , error ) { req := NewRequest ( ctx , r . shell . url , r . command , r . args ... ) req . Opts = r . opts req . Headers = r . headers req . Body = r . body return req . Send ( & r . shell . httpcli ) } 
func ( r * RequestBuilder ) Exec ( ctx context . Context , res interface { } ) error { httpRes , err := r . Send ( ctx ) if err != nil { return err } if res == nil { lateErr := httpRes . Close ( ) if httpRes . Error != nil { return httpRes . Error } return lateErr } return httpRes . Decode ( res ) } 
func ( s * PubSubSubscription ) Next ( ) ( * Message , error ) { if s . resp . Error != nil { return nil , s . resp . Error } d := json . NewDecoder ( s . resp . Output ) var r struct { From [ ] byte `json:"from,omitempty"` Data [ ] byte `json:"data,omitempty"` Seqno [ ] byte `json:"seqno,omitempty"` TopicIDs [ ] string `json:"topicIDs,omitempty"` } err := d . Decode ( & r ) if err != nil { return nil , err } from , err := peer . IDFromBytes ( r . From ) if err != nil { return nil , err } return & Message { From : from , Data : r . Data , Seqno : r . Seqno , TopicIDs : r . TopicIDs , } , nil } 
func ( s * PubSubSubscription ) Cancel ( ) error { if s . resp . Output == nil { return nil } return s . resp . Output . Close ( ) } 
func ( s * Shell ) FileList ( path string ) ( * UnixLsObject , error ) { var out lsOutput if err := s . Request ( " " , path ) . Exec ( context . Background ( ) , & out ) ; err != nil { return nil , err } for _ , object := range out . Objects { return object , nil } return nil , fmt . Errorf ( " " ) } 
func ( s * Shell ) ID ( peer ... string ) ( * IdOutput , error ) { if len ( peer ) > 1 { return nil , fmt . Errorf ( " " ) } var out IdOutput if err := s . Request ( " " , peer ... ) . Exec ( context . Background ( ) , & out ) ; err != nil { return nil , err } return & out , nil } 
func ( s * Shell ) Cat ( path string ) ( io . ReadCloser , error ) { resp , err := s . Request ( " " , path ) . Send ( context . Background ( ) ) if err != nil { return nil , err } if resp . Error != nil { return nil , resp . Error } return resp . Output , nil } 
func ( s * Shell ) List ( path string ) ( [ ] * LsLink , error ) { var out struct { Objects [ ] LsObject } err := s . Request ( " " , path ) . Exec ( context . Background ( ) , & out ) if err != nil { return nil , err } if len ( out . Objects ) != 1 { return nil , errors . New ( " " ) } return out . Objects [ 0 ] . Links , nil } 
func ( s * Shell ) Pin ( path string ) error { return s . Request ( " " , path ) . Option ( " " , true ) . Exec ( context . Background ( ) , nil ) } 
func ( s * Shell ) Pins ( ) ( map [ string ] PinInfo , error ) { var raw struct { Keys map [ string ] PinInfo } return raw . Keys , s . Request ( " " ) . Exec ( context . Background ( ) , & raw ) } 
func ( s * Shell ) Version ( ) ( string , string , error ) { ver := struct { Version string Commit string } { } if err := s . Request ( " " ) . Exec ( context . Background ( ) , & ver ) ; err != nil { return " " , " " , err } return ver . Version , ver . Commit , nil } 
func ( s * Shell ) ObjectStat ( key string ) ( * ObjectStats , error ) { var stat ObjectStats err := s . Request ( " " , key ) . Exec ( context . Background ( ) , & stat ) if err != nil { return nil , err } return & stat , nil } 
func ( s * Shell ) StatsBW ( ctx context . Context ) ( * p2pmetrics . Stats , error ) { v := & p2pmetrics . Stats { } err := s . Request ( " " ) . Exec ( ctx , & v ) return v , err } 
func ( s * Shell ) SwarmPeers ( ctx context . Context ) ( * SwarmConnInfos , error ) { v := & SwarmConnInfos { } err := s . Request ( " " ) . Exec ( ctx , & v ) return v , err } 
func ( s * Shell ) SwarmConnect ( ctx context . Context , addr ... string ) error { var conn * swarmConnection err := s . Request ( " " ) . Arguments ( addr ... ) . Exec ( ctx , & conn ) return err } 
func DagPutOptions ( opts ... DagPutOption ) ( * DagPutSettings , error ) { options := & DagPutSettings { InputEnc : " " , Kind : " " , Pin : " " , Hash : " " , } for _ , opt := range opts { err := opt ( options ) if err != nil { return nil , err } } return options , nil } 
func ( dagOpts ) Pin ( pin string ) DagPutOption { return func ( opts * DagPutSettings ) error { opts . Pin = pin return nil } } 
func ( dagOpts ) InputEnc ( enc string ) DagPutOption { return func ( opts * DagPutSettings ) error { opts . InputEnc = enc return nil } } 
func ( dagOpts ) Kind ( kind string ) DagPutOption { return func ( opts * DagPutSettings ) error { opts . Kind = kind return nil } } 
func ( dagOpts ) Hash ( hash string ) DagPutOption { return func ( opts * DagPutSettings ) error { opts . Hash = hash return nil } } 
func ( s * Shell ) AddNoPin ( r io . Reader ) ( string , error ) { return s . Add ( r , Pin ( false ) ) } 
func ( s * Shell ) AddWithOpts ( r io . Reader , pin bool , rawLeaves bool ) ( string , error ) { return s . Add ( r , Pin ( pin ) , RawLeaves ( rawLeaves ) ) } 
func ( s * Shell ) AddDir ( dir string ) ( string , error ) { stat , err := os . Lstat ( dir ) if err != nil { return " " , err } sf , err := files . NewSerialFile ( dir , false , stat ) if err != nil { return " " , err } slf := files . NewSliceDirectory ( [ ] files . DirEntry { files . FileEntry ( filepath . Base ( dir ) , sf ) } ) reader := files . NewMultiFileReader ( slf , true ) resp , err := s . Request ( " " ) . Option ( " " , true ) . Body ( reader ) . Send ( context . Background ( ) ) if err != nil { return " " , nil } defer resp . Close ( ) if resp . Error != nil { return " " , resp . Error } dec := json . NewDecoder ( resp . Output ) var final string for { var out object err = dec . Decode ( & out ) if err != nil { if err == io . EOF { break } return " " , err } final = out . Hash } if final == " " { return " " , errors . New ( " " ) } return final , nil } 
func ( s * Shell ) Publish ( node string , value string ) error { var pubResp PublishResponse req := s . Request ( " " ) if node != " " { req . Arguments ( node ) } req . Arguments ( value ) return req . Exec ( context . Background ( ) , & pubResp ) } 
func ( s * Shell ) PublishWithDetails ( contentHash , key string , lifetime , ttl time . Duration , resolve bool ) ( * PublishResponse , error ) { var pubResp PublishResponse req := s . Request ( " " , contentHash ) . Option ( " " , resolve ) if key != " " { req . Option ( " " , key ) } if lifetime != 0 { req . Option ( " " , lifetime ) } if ttl . Seconds ( ) > 0 { req . Option ( " " , ttl ) } err := req . Exec ( context . Background ( ) , & pubResp ) if err != nil { return nil , err } return & pubResp , nil } 
func ( s * Shell ) Resolve ( id string ) ( string , error ) { req := s . Request ( " " ) if id != " " { req . Arguments ( id ) } var out struct { Path string } err := req . Exec ( context . Background ( ) , & out ) return out . Path , err } 
func ( pv PlanValue ) ResolveValue ( bindVars map [ string ] * querypb . BindVariable ) ( Value , error ) { switch { case pv . Key != " " : bv , err := pv . lookupValue ( bindVars ) if err != nil { return NULL , err } return MakeTrusted ( bv . Type , bv . Value ) , nil case ! pv . Value . IsNull ( ) : return pv . Value , nil case pv . ListKey != " " || pv . Values != nil : } return NULL , nil } 
func ResolveRows ( pvs [ ] PlanValue , bindVars map [ string ] * querypb . BindVariable ) ( [ ] [ ] Value , error ) { count , err := rowCount ( pvs , bindVars ) if err != nil { return nil , err } for i := range rows { rows [ i ] = make ( [ ] Value , len ( pvs ) ) } if err != nil { return nil , err } for i := range rows { rows [ i ] [ j ] = MakeTrusted ( bv . Type , bv . Value ) } case ! pv . Value . IsNull ( ) : for i := range rows { rows [ i ] [ j ] = pv . Value } case pv . ListKey != " " : bv , err := pv . lookupList ( bindVars ) if err != nil { } for i := range rows { rows [ i ] [ j ] = MakeTrusted ( bv . Values [ i ] . Type , bv . Values [ i ] . Value ) } case pv . Values != nil : for i := range rows { rows [ i ] [ j ] , err = pv . Values [ i ] . ResolveValue ( bindVars ) if err != nil { return nil , err } } } return rows , nil } 
func ( pq * ParsedQuery ) GenerateQuery ( bindVariables map [ string ] * querypb . BindVariable , extras map [ string ] Encodable ) ( [ ] byte , error ) { if len ( pq . bindLocations ) == 0 { return [ ] byte ( pq . Query ) , nil } buf := bytes . NewBuffer ( make ( [ ] byte , 0 , len ( pq . Query ) ) ) current := 0 for _ , loc := range pq . bindLocations { buf . WriteString ( pq . Query [ current : loc . offset ] ) name := pq . Query [ loc . offset : loc . offset + loc . length ] if encodable , ok := extras [ name [ 1 : ] ] ; ok { encodable . EncodeSQL ( buf ) } else { supplied , _ , err := FetchBindVar ( name , bindVariables ) if err != nil { return nil , err } EncodeValue ( buf , supplied ) } current = loc . offset + loc . length } buf . WriteString ( pq . Query [ current : ] ) return buf . Bytes ( ) , nil } 
func EncodeValue ( buf * bytes . Buffer , value * querypb . BindVariable ) { if value . Type != querypb . Type_TUPLE { v . EncodeSQL ( buf ) return } for i , bv := range value . Values { if i != 0 { buf . WriteString ( " " ) } sqltypes . ProtoToValue ( bv ) . EncodeSQL ( buf ) } buf . WriteByte ( ')' ) } 
func ( tkn * Tokenizer ) Lex ( lval * yySymType ) int { typ , val := tkn . Scan ( ) for typ == COMMENT { if tkn . AllowComments { break } typ , val = tkn . Scan ( ) } lval . bytes = val tkn . lastToken = val return typ } 
func ( tkn * Tokenizer ) skipStatement ( ) { ch := tkn . lastChar for ch != ';' && ch != eofChar { tkn . next ( ) ch = tkn . lastChar } } 
func ( tkn * Tokenizer ) reset ( ) { tkn . ParseTree = nil tkn . partialDDL = nil tkn . specialComment = nil tkn . posVarIndex = 0 tkn . nesting = 0 tkn . ForceEOF = false } 
func Preview ( sql string ) int { trimmed := StripLeadingComments ( sql ) firstWord := trimmed if end := strings . IndexFunc ( trimmed , unicode . IsSpace ) ; end != - 1 { firstWord = trimmed [ : end ] } firstWord = strings . TrimLeftFunc ( firstWord , func ( r rune ) bool { return ! unicode . IsLetter ( r ) } ) switch loweredFirstWord { case " " : return StmtSelect case " " : return StmtStream case " " : return StmtInsert case " " : return StmtReplace case " " : return StmtUpdate case " " : return StmtDelete } switch strings . ToLower ( trimmedNoComments ) { case " " , " " : return StmtBegin case " " : return StmtCommit case " " : return StmtRollback } switch loweredFirstWord { case " " , " " , " " , " " , " " : return StmtDDL case " " : return StmtSet case " " : return StmtShow case " " : return StmtUse case " " , " " , " " , " " , " " , " " : return StmtOther } if strings . Index ( trimmed , " " ) == 0 { return StmtComment } return StmtUnknown } 
func NewPlanValue ( node Expr ) ( sqltypes . PlanValue , error ) { switch node := node . ( type ) { case * SQLVal : switch node . Type { case ValArg : return sqltypes . PlanValue { Key : string ( node . Val [ 1 : ] ) } , nil case IntVal : n , err := sqltypes . NewIntegral ( string ( node . Val ) ) if err != nil { return sqltypes . PlanValue { } , fmt . Errorf ( " " , err ) } return sqltypes . PlanValue { Value : n } , nil case StrVal : return sqltypes . PlanValue { Value : sqltypes . MakeTrusted ( sqltypes . VarBinary , node . Val ) } , nil case HexVal : v , err := node . HexDecode ( ) if err != nil { return sqltypes . PlanValue { } , fmt . Errorf ( " " , err ) } return sqltypes . PlanValue { Value : sqltypes . MakeTrusted ( sqltypes . VarBinary , v ) } , nil } case ListArg : return sqltypes . PlanValue { ListKey : string ( node [ 2 : ] ) } , nil case ValTuple : pv := sqltypes . PlanValue { Values : make ( [ ] sqltypes . PlanValue , 0 , len ( node ) ) , } for _ , val := range node { innerpv , err := NewPlanValue ( val ) if err != nil { return sqltypes . PlanValue { } , err } if innerpv . ListKey != " " || innerpv . Values != nil { return sqltypes . PlanValue { } , errors . New ( " " ) } pv . Values = append ( pv . Values , innerpv ) } return pv , nil case * NullVal : return sqltypes . PlanValue { } , nil } return sqltypes . PlanValue { } , fmt . Errorf ( " " , String ( node ) ) } 
func StringIn ( str string , values ... string ) bool { for _ , val := range values { if str == val { return true } } return false } 
func NewTrackedBuffer ( nodeFormatter NodeFormatter ) * TrackedBuffer { return & TrackedBuffer { Buffer : new ( bytes . Buffer ) , nodeFormatter : nodeFormatter , } } 
func NewStringArena ( size int ) * StringArena { sa := & StringArena { buf : make ( [ ] byte , 0 , size ) } pbytes := ( * reflect . SliceHeader ) ( unsafe . Pointer ( & sa . buf ) ) pstring := ( * reflect . StringHeader ) ( unsafe . Pointer ( & sa . str ) ) pstring . Data = pbytes . Data pstring . Len = pbytes . Cap return sa } 
func ( sa * StringArena ) NewString ( b [ ] byte ) string { if len ( b ) == 0 { return " " } if len ( sa . buf ) + len ( b ) > cap ( sa . buf ) { return string ( b ) } start := len ( sa . buf ) sa . buf = append ( sa . buf , b ... ) return sa . str [ start : start + len ( b ) ] } 
func ( sa * StringArena ) SpaceLeft ( ) int { return cap ( sa . buf ) - len ( sa . buf ) } 
func String ( b [ ] byte ) ( s string ) { if len ( b ) == 0 { return " " } pbytes := ( * reflect . SliceHeader ) ( unsafe . Pointer ( & b ) ) pstring := ( * reflect . StringHeader ) ( unsafe . Pointer ( & s ) ) pstring . Data = pbytes . Data pstring . Len = pbytes . Len return } 
func Parse ( sql string ) ( Statement , error ) { tokenizer := NewStringTokenizer ( sql ) if yyParse ( tokenizer ) != 0 { if tokenizer . partialDDL != nil { log . Printf ( " " , sql , tokenizer . LastError ) tokenizer . ParseTree = tokenizer . partialDDL return tokenizer . ParseTree , nil } return nil , tokenizer . LastError } return tokenizer . ParseTree , nil } 
func ParseStrictDDL ( sql string ) ( Statement , error ) { tokenizer := NewStringTokenizer ( sql ) if yyParse ( tokenizer ) != 0 { return nil , tokenizer . LastError } return tokenizer . ParseTree , nil } 
func ParseNext ( tokenizer * Tokenizer ) ( Statement , error ) { if tokenizer . lastChar == ';' { tokenizer . next ( ) tokenizer . skipBlank ( ) } if tokenizer . lastChar == eofChar { return nil , io . EOF } tokenizer . reset ( ) tokenizer . multi = true if yyParse ( tokenizer ) != 0 { if tokenizer . partialDDL != nil { tokenizer . ParseTree = tokenizer . partialDDL return tokenizer . ParseTree , nil } return nil , tokenizer . LastError } return tokenizer . ParseTree , nil } 
func Append ( buf * bytes . Buffer , node SQLNode ) { tbuf := & TrackedBuffer { Buffer : buf , } node . Format ( tbuf ) } 
func ( node * Update ) Format ( buf * TrackedBuffer ) { buf . Myprintf ( " " , node . Comments , node . TableExprs , node . Exprs , node . Where , node . OrderBy , node . Limit ) } 
func ( node * DDL ) Format ( buf * TrackedBuffer ) { switch node . Action { case CreateStr : if node . TableSpec == nil { buf . Myprintf ( " " , node . Action , node . NewName ) } else { buf . Myprintf ( " " , node . Action , node . NewName , node . TableSpec ) } case DropStr : exists := " " if node . IfExists { exists = " " } buf . Myprintf ( " " , node . Action , exists , node . Table ) case RenameStr : buf . Myprintf ( " " , node . Action , node . Table , node . NewName ) case AlterStr : if node . PartitionSpec != nil { buf . Myprintf ( " " , node . Action , node . Table , node . PartitionSpec ) } else { buf . Myprintf ( " " , node . Action , node . Table ) } case CreateVindexStr : buf . Myprintf ( " " , node . Action , node . VindexSpec . Name , node . VindexSpec ) case AddColVindexStr : buf . Myprintf ( " " , node . Table , node . Action , node . VindexSpec . Name ) for i , col := range node . VindexCols { if i != 0 { buf . Myprintf ( " " , col ) } else { buf . Myprintf ( " " , col ) } } buf . Myprintf ( " " ) if node . VindexSpec . Type . String ( ) != " " { buf . Myprintf ( " " , node . VindexSpec ) } case DropColVindexStr : buf . Myprintf ( " " , node . Table , node . Action , node . VindexSpec . Name ) default : buf . Myprintf ( " " , node . Action , node . Table ) } } 
func ( node * Show ) Format ( buf * TrackedBuffer ) { if node . Type == " " && node . ShowTablesOpt != nil { opt := node . ShowTablesOpt if opt . DbName != " " { if opt . Filter != nil { buf . Myprintf ( " " , opt . Extended , opt . Full , opt . DbName , opt . Filter ) } else { buf . Myprintf ( " " , opt . Extended , opt . Full , opt . DbName ) } } else { if opt . Filter != nil { buf . Myprintf ( " " , opt . Extended , opt . Full , opt . Filter ) } else { buf . Myprintf ( " " , opt . Extended , opt . Full ) } } return } if node . Scope == " " { buf . Myprintf ( " " , node . Type ) } else { buf . Myprintf ( " " , node . Scope , node . Type ) } if node . HasOnTable ( ) { buf . Myprintf ( " " , node . OnTable ) } } 
func ( node * ShowFilter ) Format ( buf * TrackedBuffer ) { if node . Like != " " { buf . Myprintf ( " " , node . Like ) } else { buf . Myprintf ( " " , node . Filter ) } } 
func ExprFromValue ( value sqltypes . Value ) ( Expr , error ) { case value . IsIntegral ( ) : return NewIntVal ( value . ToBytes ( ) ) , nil case value . IsFloat ( ) || value . Type ( ) == sqltypes . Decimal : return NewFloatVal ( value . ToBytes ( ) ) , nil case value . IsQuoted ( ) : return NewStrVal ( value . ToBytes ( ) ) , nil default : } } 
func ( node * SubstrExpr ) Format ( buf * TrackedBuffer ) { if node . To == nil { buf . Myprintf ( " " , node . Name , node . From ) } else { buf . Myprintf ( " " , node . Name , node . From , node . To ) } } 
func ( node * SetExpr ) Format ( buf * TrackedBuffer ) { } else { buf . Myprintf ( " " , node . Name . String ( ) , node . Expr ) } } 
func Backtick ( in string ) string { var buf bytes . Buffer buf . WriteByte ( '`' ) for _ , c := range in { buf . WriteRune ( c ) if c == '`' { buf . WriteByte ( '`' ) } } buf . WriteByte ( '`' ) return buf . String ( ) } 
func NewValue ( typ querypb . Type , val [ ] byte ) ( v Value , err error ) { switch { case IsSigned ( typ ) : if _ , err := strconv . ParseInt ( string ( val ) , 0 , 64 ) ; err != nil { return NULL , err } return MakeTrusted ( typ , val ) , nil case IsUnsigned ( typ ) : if _ , err := strconv . ParseUint ( string ( val ) , 0 , 64 ) ; err != nil { return NULL , err } return MakeTrusted ( typ , val ) , nil case IsFloat ( typ ) || typ == Decimal : if _ , err := strconv . ParseFloat ( string ( val ) , 64 ) ; err != nil { return NULL , err } return MakeTrusted ( typ , val ) , nil case IsQuoted ( typ ) || typ == Null : return MakeTrusted ( typ , val ) , nil } } 
func ( v Value ) String ( ) string { if v . typ == Null { return " " } if v . IsQuoted ( ) { return fmt . Sprintf ( " " , v . typ , v . val ) } return fmt . Sprintf ( " " , v . typ , v . val ) } 
func ( v Value ) EncodeSQL ( b BinWriter ) { switch { case v . typ == Null : b . Write ( nullstr ) case v . IsQuoted ( ) : encodeBytesSQL ( v . val , b ) default : b . Write ( v . val ) } } 
func ( iv InsertValues ) EncodeSQL ( buf * bytes . Buffer ) { for i , rows := range iv { if i != 0 { buf . WriteString ( " " ) } buf . WriteByte ( '(' ) for j , bv := range rows { if j != 0 { buf . WriteString ( " " ) } bv . EncodeSQL ( buf ) } buf . WriteByte ( ')' ) } } 
func ( tpl * TupleEqualityList ) EncodeSQL ( buf * bytes . Buffer ) { if len ( tpl . Columns ) == 1 { tpl . encodeAsIn ( buf ) return } tpl . encodeAsEquality ( buf ) } 
func ( nz * normalizer ) WalkStatement ( node SQLNode ) ( bool , error ) { switch node := node . ( type ) { case * Select : _ = Walk ( nz . WalkSelect , node ) case * SQLVal : nz . convertSQLVal ( node ) case * ComparisonExpr : nz . convertComparison ( node ) } return true , nil } 
func ( nz * normalizer ) WalkSelect ( node SQLNode ) ( bool , error ) { switch node := node . ( type ) { case * SQLVal : nz . convertSQLValDedup ( node ) case * ComparisonExpr : nz . convertComparison ( node ) } return true , nil } 
func GetBindvars ( stmt Statement ) map [ string ] struct { } { bindvars := make ( map [ string ] struct { } ) _ = Walk ( func ( node SQLNode ) ( kontinue bool , err error ) { switch node := node . ( type ) { case * SQLVal : if node . Type == ValArg { bindvars [ string ( node . Val [ 1 : ] ) ] = struct { } { } } case ListArg : bindvars [ string ( node [ 2 : ] ) ] = struct { } { } } return true , nil } , stmt ) return bindvars } 
func BindVariablesEqual ( x , y map [ string ] * querypb . BindVariable ) bool { return reflect . DeepEqual ( & querypb . BoundQuery { BindVariables : x } , & querypb . BoundQuery { BindVariables : y } ) } 
func New ( options ... Options ) * JWTMiddleware { var opts Options if len ( options ) == 0 { opts = Options { } } else { opts = options [ 0 ] } if opts . UserProperty == " " { opts . UserProperty = " " } if opts . ErrorHandler == nil { opts . ErrorHandler = OnError } if opts . Extractor == nil { opts . Extractor = FromAuthHeader } return & JWTMiddleware { Options : opts , } } 
func ( m * JWTMiddleware ) HandlerWithNext ( w http . ResponseWriter , r * http . Request , next http . HandlerFunc ) { err := m . CheckJWT ( w , r ) } } 
func FromAuthHeader ( r * http . Request ) ( string , error ) { authHeader := r . Header . Get ( " " ) if authHeader == " " { return " " , nil } if len ( authHeaderParts ) != 2 || strings . ToLower ( authHeaderParts [ 0 ] ) != " " { return " " , errors . New ( " " ) } return authHeaderParts [ 1 ] , nil } 
func FromParameter ( param string ) TokenExtractor { return func ( r * http . Request ) ( string , error ) { return r . URL . Query ( ) . Get ( param ) , nil } } 
func FromFirst ( extractors ... TokenExtractor ) TokenExtractor { return func ( r * http . Request ) ( string , error ) { for _ , ex := range extractors { token , err := ex ( r ) if err != nil { return " " , err } if token != " " { return token , nil } } return " " , nil } } 
func ( p * PubSub ) getHelloPacket ( ) * RPC { var rpc RPC for t := range p . myTopics { as := & pb . RPC_SubOpts { Topicid : proto . String ( t ) , Subscribe : proto . Bool ( true ) , } rpc . Subscriptions = append ( rpc . Subscriptions , as ) } return & rpc } 
func NewFloodsubWithProtocols ( ctx context . Context , h host . Host , ps [ ] protocol . ID , opts ... Option ) ( * PubSub , error ) { rt := & FloodSubRouter { protocols : ps , } return NewPubSub ( ctx , h , rt , opts ... ) } 
func NewFloodSub ( ctx context . Context , h host . Host , opts ... Option ) ( * PubSub , error ) { return NewFloodsubWithProtocols ( ctx , h , [ ] protocol . ID { FloodSubID } , opts ... ) } 
func NewLRUBlacklist ( cap int ) ( Blacklist , error ) { c , err := lru . New ( cap ) if err != nil { return nil , err } b := & LRUBlacklist { lru : c } return b , nil } 
func NewRandomSub ( ctx context . Context , h host . Host , opts ... Option ) ( * PubSub , error ) { rt := & RandomSubRouter { peers : make ( map [ peer . ID ] protocol . ID ) , } return NewPubSub ( ctx , h , rt , opts ... ) } 
func NewGossipSub ( ctx context . Context , h host . Host , opts ... Option ) ( * PubSub , error ) { rt := & GossipSubRouter { peers : make ( map [ peer . ID ] protocol . ID ) , mesh : make ( map [ string ] map [ peer . ID ] struct { } ) , fanout : make ( map [ string ] map [ peer . ID ] struct { } ) , lastpub : make ( map [ string ] int64 ) , gossip : make ( map [ peer . ID ] [ ] * pb . ControlIHave ) , control : make ( map [ peer . ID ] * pb . ControlMessage ) , mcache : NewMessageCache ( GossipSubHistoryGossip , GossipSubHistoryLength ) , } return NewPubSub ( ctx , h , rt , opts ... ) } 
func NewPubSub ( ctx context . Context , h host . Host , rt PubSubRouter , opts ... Option ) ( * PubSub , error ) { ps := & PubSub { host : h , ctx : ctx , rt : rt , signID : h . ID ( ) , signKey : h . Peerstore ( ) . PrivKey ( h . ID ( ) ) , signStrict : true , incoming : make ( chan * RPC , 32 ) , publish : make ( chan * Message ) , newPeers : make ( chan peer . ID ) , newPeerStream : make ( chan inet . Stream ) , newPeerError : make ( chan peer . ID ) , peerDead : make ( chan peer . ID ) , cancelCh : make ( chan * Subscription ) , getPeers : make ( chan * listPeerReq ) , addSub : make ( chan * addSubReq ) , getTopics : make ( chan * topicReq ) , sendMsg : make ( chan * sendReq , 32 ) , addVal : make ( chan * addValReq ) , rmVal : make ( chan * rmValReq ) , validateThrottle : make ( chan struct { } , defaultValidateThrottle ) , eval : make ( chan func ( ) ) , myTopics : make ( map [ string ] map [ * Subscription ] struct { } ) , topics : make ( map [ string ] map [ peer . ID ] struct { } ) , peers : make ( map [ peer . ID ] chan * RPC ) , topicVals : make ( map [ string ] * topicVal ) , blacklist : NewMapBlacklist ( ) , blacklistPeer : make ( chan peer . ID ) , seenMessages : timecache . NewTimeCache ( TimeCacheDuration ) , counter : uint64 ( time . Now ( ) . UnixNano ( ) ) , } for _ , opt := range opts { err := opt ( ps ) if err != nil { return nil , err } } if ps . signStrict && ps . signKey == nil { return nil , fmt . Errorf ( " " ) } rt . Attach ( ps ) for _ , id := range rt . Protocols ( ) { h . SetStreamHandler ( id , ps . handleNewStream ) } h . Network ( ) . Notify ( ( * PubSubNotif ) ( ps ) ) go ps . processLoop ( ctx ) return ps , nil } 
func WithValidateThrottle ( n int ) Option { return func ( ps * PubSub ) error { ps . validateThrottle = make ( chan struct { } , n ) return nil } } 
func WithMessageSigning ( enabled bool ) Option { return func ( p * PubSub ) error { if enabled { p . signKey = p . host . Peerstore ( ) . PrivKey ( p . signID ) if p . signKey == nil { return fmt . Errorf ( " " , p . signID ) } } else { p . signKey = nil p . signStrict = false } return nil } } 
func WithMessageAuthor ( author peer . ID ) Option { return func ( p * PubSub ) error { if author == " " { author = p . host . ID ( ) } if p . signKey != nil { newSignKey := p . host . Peerstore ( ) . PrivKey ( author ) if newSignKey == nil { return fmt . Errorf ( " " , p . signID ) } p . signKey = newSignKey } p . signID = author return nil } } 
func WithStrictSignatureVerification ( required bool ) Option { return func ( p * PubSub ) error { p . signStrict = required return nil } } 
func WithBlacklist ( b Blacklist ) Option { return func ( p * PubSub ) error { p . blacklist = b return nil } } 
func ( p * PubSub ) processLoop ( ctx context . Context ) { defer func ( ) { } p . peers = nil p . topics = nil } ( ) for { select { case pid := <- p . newPeers : if _ , ok := p . peers [ pid ] ; ok { log . Warning ( " " , pid ) continue } if p . blacklist . Contains ( pid ) { log . Warning ( " " , pid ) continue } messages := make ( chan * RPC , 32 ) messages <- p . getHelloPacket ( ) go p . handleNewPeer ( ctx , pid , messages ) p . peers [ pid ] = messages case s := <- p . newPeerStream : pid := s . Conn ( ) . RemotePeer ( ) ch , ok := p . peers [ pid ] if ! ok { log . Warning ( " " , pid ) s . Reset ( ) continue } if p . blacklist . Contains ( pid ) { log . Warning ( " " , pid ) close ( ch ) s . Reset ( ) continue } p . rt . AddPeer ( pid , s . Protocol ( ) ) case pid := <- p . newPeerError : delete ( p . peers , pid ) case pid := <- p . peerDead : ch , ok := p . peers [ pid ] if ! ok { continue } close ( ch ) if p . host . Network ( ) . Connectedness ( pid ) == inet . Connected { messages := make ( chan * RPC , 32 ) messages <- p . getHelloPacket ( ) go p . handleNewPeer ( ctx , pid , messages ) p . peers [ pid ] = messages continue } delete ( p . peers , pid ) for _ , t := range p . topics { delete ( t , pid ) } p . rt . RemovePeer ( pid ) case treq := <- p . getTopics : var out [ ] string for t := range p . myTopics { out = append ( out , t ) } treq . resp <- out case sub := <- p . cancelCh : p . handleRemoveSubscription ( sub ) case sub := <- p . addSub : p . handleAddSubscription ( sub ) case preq := <- p . getPeers : tmap , ok := p . topics [ preq . topic ] if preq . topic != " " && ! ok { preq . resp <- nil continue } var peers [ ] peer . ID for p := range p . peers { if preq . topic != " " { _ , ok := tmap [ p ] if ! ok { continue } } peers = append ( peers , p ) } preq . resp <- peers case rpc := <- p . incoming : p . handleIncomingRPC ( rpc ) case msg := <- p . publish : vals := p . getValidators ( msg ) p . pushMsg ( vals , p . host . ID ( ) , msg ) case req := <- p . sendMsg : p . publishMessage ( req . from , req . msg . Message ) case req := <- p . addVal : p . addValidator ( req ) case req := <- p . rmVal : p . rmValidator ( req ) case thunk := <- p . eval : thunk ( ) case pid := <- p . blacklistPeer : log . Infof ( " " , pid ) p . blacklist . Add ( pid ) ch , ok := p . peers [ pid ] if ok { close ( ch ) delete ( p . peers , pid ) for _ , t := range p . topics { delete ( t , pid ) } p . rt . RemovePeer ( pid ) } case <- ctx . Done ( ) : log . Info ( " " ) return } } } 
func ( p * PubSub ) handleRemoveSubscription ( sub * Subscription ) { subs := p . myTopics [ sub . topic ] if subs == nil { return } sub . err = fmt . Errorf ( " " ) close ( sub . ch ) delete ( subs , sub ) if len ( subs ) == 0 { delete ( p . myTopics , sub . topic ) p . announce ( sub . topic , false ) p . rt . Leave ( sub . topic ) } } 
func ( p * PubSub ) handleAddSubscription ( req * addSubReq ) { sub := req . sub subs := p . myTopics [ sub . topic ] p . rt . Join ( sub . topic ) } subs = p . myTopics [ sub . topic ] } sub . ch = make ( chan * Message , 32 ) sub . cancelCh = p . cancelCh p . myTopics [ sub . topic ] [ sub ] = struct { } { } req . resp <- sub } 
func ( p * PubSub ) announce ( topic string , sub bool ) { subopt := & pb . RPC_SubOpts { Topicid : & topic , Subscribe : & sub , } out := rpcWithSubs ( subopt ) for pid , peer := range p . peers { select { case peer <- out : default : log . Infof ( " " , pid ) go p . announceRetry ( pid , topic , sub ) } } } 
func ( p * PubSub ) notifySubs ( msg * pb . Message ) { for _ , topic := range msg . GetTopicIDs ( ) { subs := p . myTopics [ topic ] for f := range subs { select { case f . ch <- & Message { msg } : default : log . Infof ( " " , topic ) } } } } 
func ( p * PubSub ) seenMessage ( id string ) bool { return p . seenMessages . Has ( id ) } 
func ( p * PubSub ) subscribedToMsg ( msg * pb . Message ) bool { if len ( p . myTopics ) == 0 { return false } for _ , t := range msg . GetTopicIDs ( ) { if _ , ok := p . myTopics [ t ] ; ok { return true } } return false } 
func msgID ( pmsg * pb . Message ) string { return string ( pmsg . GetFrom ( ) ) + string ( pmsg . GetSeqno ( ) ) } 
func ( p * PubSub ) pushMsg ( vals [ ] * topicVal , src peer . ID , msg * Message ) { return } return } return } if p . seenMessage ( id ) { return } if len ( vals ) > 0 || msg . Signature != nil { <- p . validateThrottle } ( ) default : log . Warningf ( " " , src ) } return } p . publishMessage ( src , msg . Message ) } 
func ( p * PubSub ) validate ( vals [ ] * topicVal , src peer . ID , msg * Message ) { if msg . Signature != nil { if ! p . validateSignature ( msg ) { log . Warningf ( " " , src ) return } } if len ( vals ) > 0 { if ! p . validateTopic ( vals , src , msg ) { log . Warningf ( " " , src ) return } } } 
func ( p * PubSub ) validateSingleTopic ( val * topicVal , src peer . ID , msg * Message ) bool { select { case val . validateThrottle <- struct { } { } : ctx , cancel := context . WithCancel ( p . ctx ) defer cancel ( ) res := val . validateMsg ( ctx , src , msg ) <- val . validateThrottle return res default : log . Debugf ( " " , val . topic ) return false } } 
func ( p * PubSub ) getValidators ( msg * Message ) [ ] * topicVal { var vals [ ] * topicVal for _ , topic := range msg . GetTopicIDs ( ) { val , ok := p . topicVals [ topic ] if ! ok { continue } vals = append ( vals , val ) } return vals } 
func ( p * PubSub ) Subscribe ( topic string , opts ... SubOpt ) ( * Subscription , error ) { td := pb . TopicDescriptor { Name : & topic } return p . SubscribeByTopicDescriptor ( & td , opts ... ) } 
func ( p * PubSub ) SubscribeByTopicDescriptor ( td * pb . TopicDescriptor , opts ... SubOpt ) ( * Subscription , error ) { if td . GetAuth ( ) . GetMode ( ) != pb . TopicDescriptor_AuthOpts_NONE { return nil , fmt . Errorf ( " " ) } if td . GetEnc ( ) . GetMode ( ) != pb . TopicDescriptor_EncOpts_NONE { return nil , fmt . Errorf ( " " ) } sub := & Subscription { topic : td . GetName ( ) , } for _ , opt := range opts { err := opt ( sub ) if err != nil { return nil , err } } out := make ( chan * Subscription , 1 ) p . addSub <- & addSubReq { sub : sub , resp : out , } return <- out , nil } 
func ( p * PubSub ) GetTopics ( ) [ ] string { out := make ( chan [ ] string , 1 ) p . getTopics <- & topicReq { resp : out } return <- out } 
func ( p * PubSub ) Publish ( topic string , data [ ] byte ) error { seqno := p . nextSeqno ( ) m := & pb . Message { Data : data , TopicIDs : [ ] string { topic } , From : [ ] byte ( p . host . ID ( ) ) , Seqno : seqno , } if p . signKey != nil { m . From = [ ] byte ( p . signID ) err := signMessage ( p . signID , p . signKey , m ) if err != nil { return err } } p . publish <- & Message { m } return nil } 
func ( p * PubSub ) ListPeers ( topic string ) [ ] peer . ID { out := make ( chan [ ] peer . ID ) p . getPeers <- & listPeerReq { resp : out , topic : topic , } return <- out } 
func WithValidatorTimeout ( timeout time . Duration ) ValidatorOpt { return func ( addVal * addValReq ) error { addVal . timeout = timeout return nil } } 
func WithValidatorConcurrency ( n int ) ValidatorOpt { return func ( addVal * addValReq ) error { addVal . throttle = n return nil } } 
func ( p * PubSub ) RegisterTopicValidator ( topic string , val Validator , opts ... ValidatorOpt ) error { addVal := & addValReq { topic : topic , validate : val , resp : make ( chan error , 1 ) , } for _ , opt := range opts { err := opt ( addVal ) if err != nil { return err } } p . addVal <- addVal return <- addVal . resp } 
func ( p * PubSub ) UnregisterTopicValidator ( topic string ) error { rmVal := & rmValReq { topic : topic , resp : make ( chan error , 1 ) , } p . rmVal <- rmVal return <- rmVal . resp } 
func DefaultMetricPrefix ( name string , tags map [ string ] string ) string { return MetricWithPrefix ( " " , name , tags ) } 
func MetricWithPrefix ( prefix , name string , tags map [ string ] string ) string { buf := bufPool . Get ( ) . ( * bytes . Buffer ) buf . Reset ( ) if prefix != " " { buf . WriteString ( prefix ) } buf . WriteString ( name ) addKeys := make ( [ ] string , 0 , 5 ) switch { case strings . HasPrefix ( name , " " ) : addKeys = append ( addKeys , " " , " " , " " ) if strings . HasPrefix ( name , " " ) { addKeys = append ( addKeys , " " ) } case strings . HasPrefix ( name , " " ) : addKeys = append ( addKeys , " " , " " , " " ) } for _ , k := range addKeys { buf . WriteByte ( '.' ) v , ok := tags [ k ] if ok { writeClean ( buf , v ) } else { buf . WriteString ( " " ) buf . WriteString ( k ) } } m := buf . String ( ) bufPool . Put ( buf ) return m } 
func writeClean ( buf * bytes . Buffer , v string ) { for i := 0 ; i < len ( v ) ; i ++ { c := v [ i ] switch c { case '{' , '}' , '/' , '\\' , ':' , '.' , ' ' , '\t' , '\r' , '\n' : buf . WriteByte ( '-' ) default : buf . WriteByte ( c ) } } } 
func NewClient ( ch * tchannel . Channel , targetService string , opts * ClientOptions ) * Client { client := & Client { ch : ch , targetService : targetService , } if opts != nil && opts . HostPort != " " { client . hostPort = opts . HostPort } return client } 
func ( c * Client ) Call ( ctx Context , method string , arg , resp interface { } ) error { var ( headers = ctx . Headers ( ) respHeaders map [ string ] string respErr ErrApplication errAt string isOK bool ) err := c . ch . RunWithRetry ( ctx , func ( ctx context . Context , rs * tchannel . RequestState ) error { respHeaders , respErr , isOK = nil , nil , false errAt = " " call , err := c . startCall ( ctx , method , & tchannel . CallOptions { Format : tchannel . JSON , RequestState : rs , } ) if err != nil { return err } isOK , errAt , err = makeCall ( call , headers , arg , & respHeaders , resp , & respErr ) return err } ) if err != nil { } if ! isOK { return respErr } return nil } 
func wrapCall ( ctx Context , call * tchannel . OutboundCall , method string , arg , resp interface { } ) error { var respHeaders map [ string ] string var respErr ErrApplication isOK , errAt , err := makeCall ( call , ctx . Headers ( ) , arg , & respHeaders , resp , & respErr ) if err != nil { return fmt . Errorf ( " " , errAt , err ) } if ! isOK { return respErr } ctx . SetResponseHeaders ( respHeaders ) return nil } 
func CallPeer ( ctx Context , peer * tchannel . Peer , serviceName , method string , arg , resp interface { } ) error { call , err := peer . BeginCall ( ctx , serviceName , method , & tchannel . CallOptions { Format : tchannel . JSON } ) if err != nil { return err } return wrapCall ( ctx , call , method , arg , resp ) } 
func CallSC ( ctx Context , sc * tchannel . SubChannel , method string , arg , resp interface { } ) error { call , err := sc . BeginCall ( ctx , method , & tchannel . CallOptions { Format : tchannel . JSON } ) if err != nil { return err } return wrapCall ( ctx , call , method , arg , resp ) } 
func ReadResponse ( call tchannel . ArgReadable ) ( * http . Response , error ) { var arg2 [ ] byte if err := tchannel . NewArgReader ( call . Arg2Reader ( ) ) . Read ( & arg2 ) ; err != nil { return nil , err } rb := typed . NewReadBuffer ( arg2 ) statusCode := rb . ReadUint16 ( ) message := readVarintString ( rb ) response := & http . Response { StatusCode : int ( statusCode ) , Status : fmt . Sprintf ( " " , statusCode , message ) , Proto : " " , ProtoMajor : 1 , ProtoMinor : 1 , Header : make ( http . Header ) , } readHeaders ( rb , response . Header ) if err := rb . Err ( ) ; err != nil { return nil , err } arg3Reader , err := call . Arg3Reader ( ) if err != nil { return nil , err } response . Body = arg3Reader return response , nil } 
func ( w * tchanResponseWriter ) writeHeaders ( ) { wb . WriteUint16 ( uint16 ( w . statusCode ) ) writeVarintString ( wb , http . StatusText ( w . statusCode ) ) writeHeaders ( wb , w . headers ) arg2Writer , err := w . response . Arg2Writer ( ) if err != nil { w . err = err return } if _ , w . err = wb . FlushTo ( arg2Writer ) ; w . err != nil { return } if w . err = arg2Writer . Close ( ) ; w . err != nil { return } w . arg3Writer , w . err = w . response . Arg3Writer ( ) } 
func ResponseWriter ( response tchannel . ArgWritable ) ( http . ResponseWriter , func ( ) error ) { responseWriter := newTChanResponseWriter ( response ) return responseWriter , responseWriter . finish } 
func WriteHeaders ( w io . Writer , headers map [ string ] string ) error { for k , v := range headers { size += 4 size += len ( k ) + len ( v ) } buf := make ( [ ] byte , size ) writeBuffer := typed . NewWriteBuffer ( buf ) writeBuffer . WriteUint16 ( uint16 ( len ( headers ) ) ) for k , v := range headers { writeBuffer . WriteLen16String ( k ) writeBuffer . WriteLen16String ( v ) } if err := writeBuffer . Err ( ) ; err != nil { return err } } _ , err := writeBuffer . FlushTo ( w ) return err } 
func ReadHeaders ( r io . Reader ) ( map [ string ] string , error ) { reader := typed . NewReader ( r ) m , err := readHeaders ( reader ) reader . Release ( ) return m , err } 
func NewTCPRawRelay ( dests [ ] string ) ( Relay , error ) { return newTCPRelay ( dests , func ( _ bool , src , dst net . Conn ) { io . Copy ( src , dst ) } ) } 
func ( f * FailStrategy ) UnmarshalText ( text [ ] byte ) error { switch strategy := string ( text ) ; strategy { case " " , " " : * f = FailStrategyFatal case " " : * f = FailStrategyIgnore default : return fmt . Errorf ( " " , strategy ) } return nil } 
func NewClient ( ch * tchannel . Channel , config Configuration , opts * ClientOptions ) ( * Client , error ) { client := & Client { tchan : ch , quit : make ( chan struct { } ) } if opts != nil { client . opts = * opts } if client . opts . Timeout == 0 { client . opts . Timeout = 3 * time . Second } if client . opts . TimeoutPerAttempt == 0 { client . opts . TimeoutPerAttempt = time . Second } if client . opts . Handler == nil { client . opts . Handler = nullHandler { } } if client . opts . TimeSleep == nil { client . opts . TimeSleep = time . Sleep } if err := parseConfig ( & config ) ; err != nil { return nil , err } } client . jsonClient = tjson . NewClient ( ch , hyperbahnServiceName , nil ) thriftClient := tthrift . NewClient ( ch , hyperbahnServiceName , nil ) client . hyperbahnClient = htypes . NewTChanHyperbahnClient ( thriftClient ) return client , nil } 
func parseConfig ( config * Configuration ) error { if config . InitialNodesFile != " " { f , err := os . Open ( config . InitialNodesFile ) if err != nil { return err } defer f . Close ( ) decoder := json . NewDecoder ( f ) if err := decoder . Decode ( & config . InitialNodes ) ; err != nil { return err } } if len ( config . InitialNodes ) == 0 { return fmt . Errorf ( " " ) } for _ , node := range config . InitialNodes { if _ , _ , err := net . SplitHostPort ( node ) ; err != nil { return fmt . Errorf ( " " , node , err ) } } return nil } 
func addPeer ( ch * tchannel . Channel , hostPort string ) { peers := ch . GetSubChannel ( hyperbahnServiceName ) . Peers ( ) peers . Add ( hostPort ) } 
func ( c * Client ) Advertise ( otherServices ... tchannel . Registrar ) error { c . getServiceNames ( otherServices ) if err := c . initialAdvertise ( ) ; err != nil { return err } c . opts . Handler . On ( Advertised ) go c . advertiseLoop ( ) return nil } 
func verifyHandler ( t reflect . Type ) error { if t . NumIn ( ) != 2 || t . NumOut ( ) != 2 { return fmt . Errorf ( " " ) } isStructPtr := func ( t reflect . Type ) bool { return t . Kind ( ) == reflect . Ptr && t . Elem ( ) . Kind ( ) == reflect . Struct } isMap := func ( t reflect . Type ) bool { return t . Kind ( ) == reflect . Map && t . Key ( ) . Kind ( ) == reflect . String } validateArgRes := func ( t reflect . Type , name string ) error { if ! isStructPtr ( t ) && ! isMap ( t ) { return fmt . Errorf ( " " , name ) } return nil } if t . In ( 0 ) != typeOfContext { return fmt . Errorf ( " " ) } if err := validateArgRes ( t . In ( 1 ) , " " ) ; err != nil { return err } if err := validateArgRes ( t . Out ( 0 ) , " " ) ; err != nil { return err } if ! t . Out ( 1 ) . AssignableTo ( typeOfError ) { return fmt . Errorf ( " " ) } return nil } 
func Register ( registrar tchannel . Registrar , funcs Handlers , onError func ( context . Context , error ) ) error { handlers := make ( map [ string ] * handler ) handler := tchannel . HandlerFunc ( func ( ctx context . Context , call * tchannel . InboundCall ) { h , ok := handlers [ string ( call . Method ( ) ) ] if ! ok { onError ( ctx , fmt . Errorf ( " " , call . Method ( ) ) ) return } if err := h . Handle ( ctx , call ) ; err != nil { onError ( ctx , err ) } } ) for m , f := range funcs { h , err := toHandler ( f ) if err != nil { return fmt . Errorf ( " " , m , err ) } h . tracer = func ( ) opentracing . Tracer { return tchannel . TracerFromRegistrar ( registrar ) } handlers [ m ] = h registrar . Register ( handler , m ) } return nil } 
func ( h * handler ) Handle ( tctx context . Context , call * tchannel . InboundCall ) error { var headers map [ string ] string if err := tchannel . NewArgReader ( call . Arg2Reader ( ) ) . ReadJSON ( & headers ) ; err != nil { return fmt . Errorf ( " " , err ) } tctx = tchannel . ExtractInboundSpan ( tctx , call , headers , h . tracer ( ) ) ctx := WithHeaders ( tctx , headers ) var arg3 reflect . Value var callArg reflect . Value if h . isArgMap { arg3 = reflect . New ( h . argType ) } else { arg3 = reflect . New ( h . argType . Elem ( ) ) callArg = arg3 } if err := tchannel . NewArgReader ( call . Arg3Reader ( ) ) . ReadJSON ( arg3 . Interface ( ) ) ; err != nil { return fmt . Errorf ( " " , err ) } args := [ ] reflect . Value { reflect . ValueOf ( ctx ) , callArg } results := h . handler . Call ( args ) res := results [ 0 ] . Interface ( ) err := results [ 1 ] . Interface ( ) } call . Response ( ) . SetApplicationError ( ) Message string `json:"message"` } { Type : " " , Message : err . ( error ) . Error ( ) , } } if err := tchannel . NewArgWriter ( call . Response ( ) . Arg2Writer ( ) ) . WriteJSON ( ctx . ResponseHeaders ( ) ) ; err != nil { return err } return tchannel . NewArgWriter ( call . Response ( ) . Arg3Writer ( ) ) . WriteJSON ( res ) } 
func ( s * Server ) Start ( ) error { if s . HostPort == " " { s . HostPort = " " + common . DefaultServerPort } channelOpts := & tchannel . ChannelOptions { Tracer : s . Tracer , } ch , err := tchannel . NewChannel ( common . DefaultServiceName , channelOpts ) if err != nil { return err } if err := ch . ListenAndServe ( s . HostPort ) ; err != nil { return err } s . HostPort = ch . PeerInfo ( ) . HostPort log . Printf ( " \n " , s . HostPort ) s . Ch = ch return nil } 
func ( s * Server ) Port ( ) string { hostPortSplit := strings . Split ( s . HostPort , " " ) port := hostPortSplit [ len ( hostPortSplit ) - 1 ] return port } 
func ( l * PeerList ) SetStrategy ( sc ScoreCalculator ) { l . Lock ( ) defer l . Unlock ( ) l . scoreCalculator = sc for _ , ps := range l . peersByHostPort { newScore := l . scoreCalculator . GetScore ( ps . Peer ) l . updatePeer ( ps , newScore ) } } 
func ( l * PeerList ) Add ( hostPort string ) * Peer { if ps , ok := l . exists ( hostPort ) ; ok { return ps . Peer } l . Lock ( ) defer l . Unlock ( ) if p , ok := l . peersByHostPort [ hostPort ] ; ok { return p . Peer } p := l . parent . Add ( hostPort ) p . addSC ( ) ps := newPeerScore ( p , l . scoreCalculator . GetScore ( p ) ) l . peersByHostPort [ hostPort ] = ps l . peerHeap . addPeer ( ps ) return p } 
func ( l * PeerList ) GetNew ( prevSelected map [ string ] struct { } ) ( * Peer , error ) { l . Lock ( ) defer l . Unlock ( ) if l . peerHeap . Len ( ) == 0 { return nil , ErrNoPeers } if peer == nil { peer = l . choosePeer ( prevSelected , false ) } if peer == nil { return nil , ErrNoNewPeers } return peer , nil } 
func ( l * PeerList ) Get ( prevSelected map [ string ] struct { } ) ( * Peer , error ) { peer , err := l . GetNew ( prevSelected ) if err == ErrNoNewPeers { l . Lock ( ) peer = l . choosePeer ( nil , false ) l . Unlock ( ) } else if err != nil { return nil , err } if peer == nil { return nil , ErrNoPeers } return peer , nil } 
func ( l * PeerList ) Remove ( hostPort string ) error { l . Lock ( ) defer l . Unlock ( ) p , ok := l . peersByHostPort [ hostPort ] if ! ok { return ErrPeerNotFound } p . delSC ( ) delete ( l . peersByHostPort , hostPort ) l . peerHeap . removePeer ( p ) return nil } 
func ( l * PeerList ) GetOrAdd ( hostPort string ) * Peer { if ps , ok := l . exists ( hostPort ) ; ok { return ps . Peer } return l . Add ( hostPort ) } 
func ( l * PeerList ) Copy ( ) map [ string ] * Peer { l . RLock ( ) defer l . RUnlock ( ) listCopy := make ( map [ string ] * Peer ) for k , v := range l . peersByHostPort { listCopy [ k ] = v . Peer } return listCopy } 
func ( l * PeerList ) Len ( ) int { l . RLock ( ) defer l . RUnlock ( ) return l . peerHeap . Len ( ) } 
func ( l * PeerList ) exists ( hostPort string ) ( * peerScore , bool ) { l . RLock ( ) ps , ok := l . peersByHostPort [ hostPort ] l . RUnlock ( ) return ps , ok } 
func ( l * PeerList ) getPeerScore ( hostPort string ) ( * peerScore , uint64 , bool ) { ps , ok := l . peersByHostPort [ hostPort ] if ! ok { return nil , 0 , false } return ps , ps . score , ok } 
func ( l * PeerList ) onPeerChange ( p * Peer ) { l . RLock ( ) ps , psScore , ok := l . getPeerScore ( p . hostPort ) sc := l . scoreCalculator l . RUnlock ( ) if ! ok { return } newScore := sc . GetScore ( ps . Peer ) if newScore == psScore { return } l . Lock ( ) l . updatePeer ( ps , newScore ) l . Unlock ( ) } 
func ( l * PeerList ) updatePeer ( ps * peerScore , newScore uint64 ) { if ps . score == newScore { return } ps . score = newScore l . peerHeap . updatePeer ( ps ) } 
func ( p * Peer ) getConn ( i int ) * Connection { inboundLen := len ( p . inboundConnections ) if i < inboundLen { return p . inboundConnections [ i ] } return p . outboundConnections [ i - inboundLen ] } 
func ( p * Peer ) getActiveConn ( ) ( * Connection , bool ) { p . RLock ( ) conn , ok := p . getActiveConnLocked ( ) p . RUnlock ( ) return conn , ok } 
func ( p * Peer ) GetConnection ( ctx context . Context ) ( * Connection , error ) { if activeConn , ok := p . getActiveConn ( ) ; ok { return activeConn , nil } defer p . newConnLock . Unlock ( ) } } 
func ( p * Peer ) getConnectionRelay ( timeout time . Duration ) ( * Connection , error ) { if conn , ok := p . getActiveConn ( ) ; ok { return conn , nil } defer p . newConnLock . Unlock ( ) } defer cancel ( ) return p . Connect ( ctx ) } 
func ( p * Peer ) canRemove ( ) bool { p . RLock ( ) count := len ( p . inboundConnections ) + len ( p . outboundConnections ) + int ( p . scCount ) p . RUnlock ( ) return count == 0 } 
func ( p * Peer ) addConnection ( c * Connection , direction connectionDirection ) error { conns := p . connectionsFor ( direction ) if c . readState ( ) != connectionActive { return ErrInvalidConnectionState } p . Lock ( ) * conns = append ( * conns , c ) p . Unlock ( ) return nil } 
func ( p * Peer ) removeConnection ( connsPtr * [ ] * Connection , changed * Connection ) bool { conns := * connsPtr for i , c := range conns { if c == changed { conns [ i ] , conns [ last ] = conns [ last ] , nil * connsPtr = conns [ : last ] return true } } return false } 
func ( p * Peer ) connectionCloseStateChange ( changed * Connection ) { if changed . IsActive ( ) { return } p . Lock ( ) found := p . removeConnection ( & p . inboundConnections , changed ) if ! found { found = p . removeConnection ( & p . outboundConnections , changed ) } p . Unlock ( ) if found { p . onClosedConnRemoved ( p ) } } 
func ( p * Peer ) Connect ( ctx context . Context ) ( * Connection , error ) { return p . channel . Connect ( ctx , p . hostPort ) } 
func ( p * Peer ) BeginCall ( ctx context . Context , serviceName , methodName string , callOptions * CallOptions ) ( * OutboundCall , error ) { if callOptions == nil { callOptions = defaultCallOptions } callOptions . RequestState . AddSelectedPeer ( p . HostPort ( ) ) if err := validateCall ( ctx , serviceName , methodName , callOptions ) ; err != nil { return nil , err } conn , err := p . GetConnection ( ctx ) if err != nil { return nil , err } call , err := conn . beginCall ( ctx , serviceName , methodName , callOptions ) if err != nil { return nil , err } return call , err } 
func ( p * Peer ) NumConnections ( ) ( inbound int , outbound int ) { p . RLock ( ) inbound = len ( p . inboundConnections ) outbound = len ( p . outboundConnections ) p . RUnlock ( ) return inbound , outbound } 
func ( p * Peer ) NumPendingOutbound ( ) int { count := 0 p . RLock ( ) for _ , c := range p . outboundConnections { count += c . outbound . count ( ) } for _ , c := range p . inboundConnections { count += c . outbound . count ( ) } p . RUnlock ( ) return count } 
func isEphemeralHostPort ( hostPort string ) bool { return hostPort == " " || hostPort == ephemeralHostPort || strings . HasSuffix ( hostPort , " " ) } 
func ( h * kvHandler ) Get ( ctx thrift . Context , key string ) ( string , error ) { if err := isValidKey ( key ) ; err != nil { return " " , err } h . RLock ( ) defer h . RUnlock ( ) if val , ok := h . vals [ key ] ; ok { return val , nil } return " " , & keyvalue . KeyNotFound { Key : key } } 
func ( h * kvHandler ) Set ( ctx thrift . Context , key , value string ) error { if err := isValidKey ( key ) ; err != nil { return err } h . Lock ( ) defer h . Unlock ( ) h . vals [ key ] = value return nil } 
func ( h * kvHandler ) ClearAll ( ctx thrift . Context ) error { if ! isAdmin ( ctx ) { return & keyvalue . NotAuthorized { } } h . Lock ( ) defer h . Unlock ( ) h . vals = make ( map [ string ] string ) return nil } 
func ( ccc channelConnectionCommon ) Tracer ( ) opentracing . Tracer { if ccc . tracer != nil { return ccc . tracer } return opentracing . GlobalTracer ( ) } 
func NewChannel ( serviceName string , opts * ChannelOptions ) ( * Channel , error ) { if serviceName == " " { return nil , ErrNoServiceName } if opts == nil { opts = & ChannelOptions { } } processName := opts . ProcessName if processName == " " { processName = fmt . Sprintf ( " " , filepath . Base ( os . Args [ 0 ] ) , os . Getpid ( ) ) } logger := opts . Logger if logger == nil { logger = NullLogger } statsReporter := opts . StatsReporter if statsReporter == nil { statsReporter = NullStatsReporter } timeNow := opts . TimeNow if timeNow == nil { timeNow = time . Now } timeTicker := opts . TimeTicker if timeTicker == nil { timeTicker = time . NewTicker } chID := _nextChID . Inc ( ) logger = logger . WithFields ( LogField { " " , serviceName } , LogField { " " , processName } , LogField { " " , chID } , ) if err := opts . validateIdleCheck ( ) ; err != nil { return nil , err } ch := & Channel { channelConnectionCommon : channelConnectionCommon { log : logger , relayLocal : toStringSet ( opts . RelayLocalHandlers ) , statsReporter : statsReporter , subChannels : & subChannelMap { } , timeNow : timeNow , timeTicker : timeTicker , tracer : opts . Tracer , } , chID : chID , connectionOptions : opts . DefaultConnectionOptions . withDefaults ( ) , relayHost : opts . RelayHost , relayMaxTimeout : validateRelayMaxTimeout ( opts . RelayMaxTimeout , logger ) , relayTimerVerify : opts . RelayTimerVerification , closed : make ( chan struct { } ) , } ch . peers = newRootPeerList ( ch , opts . OnPeerStatusChanged ) . newChild ( ) if opts . Handler != nil { ch . handler = opts . Handler } else { ch . handler = channelHandler { ch } } ch . mutable . peerInfo = LocalPeerInfo { PeerInfo : PeerInfo { ProcessName : processName , HostPort : ephemeralHostPort , IsEphemeral : true , Version : PeerVersion { Language : " " , LanguageVersion : strings . TrimPrefix ( runtime . Version ( ) , " " ) , TChannelVersion : VersionInfo , } , } , ServiceName : serviceName , } ch . mutable . state = ChannelClient ch . mutable . conns = make ( map [ uint32 ] * Connection ) ch . createCommonStats ( ) } registerNewChannel ( ch ) if opts . RelayHost != nil { opts . RelayHost . SetChannel ( ch ) } return ch , nil } 
func ( ch * Channel ) Serve ( l net . Listener ) error { mutable := & ch . mutable mutable . Lock ( ) defer mutable . Unlock ( ) if mutable . l != nil { return errAlreadyListening } mutable . l = tnet . Wrap ( l ) if mutable . state != ChannelClient { return errInvalidStateForOp } mutable . state = ChannelListening mutable . peerInfo . HostPort = l . Addr ( ) . String ( ) mutable . peerInfo . IsEphemeral = false ch . log = ch . log . WithFields ( LogField { " " , mutable . peerInfo . HostPort } ) ch . log . Info ( " " ) go ch . serve ( ) return nil } 
func ( ch * Channel ) ListenAndServe ( hostPort string ) error { mutable := & ch . mutable mutable . RLock ( ) if mutable . l != nil { mutable . RUnlock ( ) return errAlreadyListening } l , err := net . Listen ( " " , hostPort ) if err != nil { mutable . RUnlock ( ) return err } mutable . RUnlock ( ) return ch . Serve ( l ) } 
func ( ch * Channel ) Register ( h Handler , methodName string ) { if _ , ok := ch . handler . ( channelHandler ) ; ! ok { panic ( " " ) } ch . GetSubChannel ( ch . PeerInfo ( ) . ServiceName ) . Register ( h , methodName ) } 
func ( ch * Channel ) PeerInfo ( ) LocalPeerInfo { ch . mutable . RLock ( ) peerInfo := ch . mutable . peerInfo ch . mutable . RUnlock ( ) return peerInfo } 
func ( ch * Channel ) GetSubChannel ( serviceName string , opts ... SubChannelOption ) * SubChannel { sub , added := ch . subChannels . getOrAdd ( serviceName , ch ) if added { for _ , opt := range opts { opt ( sub ) } } return sub } 
func ( ch * Channel ) BeginCall ( ctx context . Context , hostPort , serviceName , methodName string , callOptions * CallOptions ) ( * OutboundCall , error ) { p := ch . RootPeers ( ) . GetOrAdd ( hostPort ) return p . BeginCall ( ctx , serviceName , methodName , callOptions ) } 
func ( ch * Channel ) serve ( ) { acceptBackoff := 0 * time . Millisecond for { netConn , err := ch . mutable . l . Accept ( ) if err != nil { } else { acceptBackoff *= 2 } if max := 1 * time . Second ; acceptBackoff > max { acceptBackoff = max } ch . log . WithFields ( ErrField ( err ) , LogField { " " , acceptBackoff } , ) . Warn ( " " ) time . Sleep ( acceptBackoff ) continue } else { } ch . log . WithFields ( ErrField ( err ) ) . Fatal ( " " ) return } } acceptBackoff = 0 if _ , err := ch . inboundHandshake ( context . Background ( ) , netConn , events ) ; err != nil { netConn . Close ( ) } } ( ) } } 
func ( ch * Channel ) Ping ( ctx context . Context , hostPort string ) error { peer := ch . RootPeers ( ) . GetOrAdd ( hostPort ) conn , err := peer . GetConnection ( ctx ) if err != nil { return err } return conn . ping ( ctx ) } 
func ( ch * Channel ) StatsTags ( ) map [ string ] string { m := make ( map [ string ] string ) for k , v := range ch . commonStatsTags { m [ k ] = v } return m } 
func ( ch * Channel ) Connect ( ctx context . Context , hostPort string ) ( * Connection , error ) { switch state := ch . State ( ) ; state { case ChannelClient , ChannelListening : break default : ch . log . Debugf ( " " , state ) return nil , errInvalidStateForOp } ctx , cancel = context . WithTimeout ( ctx , params . connectTimeout ) defer cancel ( ) } events := connectionEvents { OnActive : ch . outboundConnectionActive , OnCloseStateChange : ch . connectionCloseStateChange , OnExchangeUpdated : ch . exchangeUpdated , } if err := ctx . Err ( ) ; err != nil { return nil , GetContextError ( err ) } timeout := getTimeout ( ctx ) tcpConn , err := dialContext ( ctx , hostPort ) if err != nil { if ne , ok := err . ( net . Error ) ; ok && ne . Timeout ( ) { ch . log . WithFields ( LogField { " " , hostPort } , LogField { " " , timeout } , ) . Info ( " " ) err = ErrTimeout } else if ctx . Err ( ) == context . Canceled { ch . log . WithFields ( LogField { " " , hostPort } , ) . Info ( " " ) err = GetContextError ( ErrRequestCancelled ) } else { ch . log . WithFields ( ErrField ( err ) , LogField { " " , hostPort } , ) . Info ( " " ) } return nil , err } conn , err := ch . outboundHandshake ( ctx , tcpConn , hostPort , events ) if conn != nil { ch . addConnectionToPeer ( hostPort , conn , outbound ) } } return conn , err } 
func ( ch * Channel ) exchangeUpdated ( c * Connection ) { if c . remotePeerInfo . HostPort == " " { } p , ok := ch . RootPeers ( ) . Get ( c . remotePeerInfo . HostPort ) if ! ok { return } ch . updatePeer ( p ) } 
func ( ch * Channel ) updatePeer ( p * Peer ) { ch . peers . onPeerChange ( p ) ch . subChannels . updatePeer ( p ) p . callOnUpdateComplete ( ) } 
func ( ch * Channel ) addConnection ( c * Connection , direction connectionDirection ) bool { ch . mutable . Lock ( ) defer ch . mutable . Unlock ( ) if c . readState ( ) != connectionActive { return false } switch state := ch . mutable . state ; state { case ChannelClient , ChannelListening : break default : return false } ch . mutable . conns [ c . connID ] = c return true } 
func ( ch * Channel ) removeClosedConn ( c * Connection ) { if c . readState ( ) != connectionClosed { return } ch . mutable . Lock ( ) delete ( ch . mutable . conns , c . connID ) ch . mutable . Unlock ( ) } 
func ( ch * Channel ) connectionCloseStateChange ( c * Connection ) { ch . removeClosedConn ( c ) if peer , ok := ch . RootPeers ( ) . Get ( c . remotePeerInfo . HostPort ) ; ok { peer . connectionCloseStateChange ( c ) ch . updatePeer ( peer ) } if c . outboundHP != " " && c . outboundHP != c . remotePeerInfo . HostPort { ch . updatePeer ( peer ) } } chState := ch . State ( ) if chState != ChannelStartClose && chState != ChannelInboundClosed { return } ch . mutable . RLock ( ) minState := ch . getMinConnectionState ( ) ch . mutable . RUnlock ( ) var updateTo ChannelState if minState >= connectionClosed { updateTo = ChannelClosed } else if minState >= connectionInboundClosed && chState == ChannelStartClose { updateTo = ChannelInboundClosed } var updatedToState ChannelState if updateTo > 0 { ch . mutable . Lock ( ) updatedToState = updateTo } ch . mutable . Unlock ( ) chState = updateTo } c . log . Debugf ( " " , chState , minState ) if updatedToState == ChannelClosed { ch . onClosed ( ) } } 
func ( ch * Channel ) State ( ) ChannelState { ch . mutable . RLock ( ) state := ch . mutable . state ch . mutable . RUnlock ( ) return state } 
func ( ch * Channel ) Close ( ) { ch . Logger ( ) . Info ( " " ) var connections [ ] * Connection var channelClosed bool func ( ) { ch . mutable . Lock ( ) defer ch . mutable . Unlock ( ) if ch . mutable . state == ChannelClosed { ch . Logger ( ) . Info ( " " ) return } if ch . mutable . l != nil { ch . mutable . l . Close ( ) } ch . mutable . state = ChannelStartClose if len ( ch . mutable . conns ) == 0 { ch . mutable . state = ChannelClosed channelClosed = true } for _ , c := range ch . mutable . conns { connections = append ( connections , c ) } } ( ) for _ , c := range connections { c . close ( LogField { " " , " " } ) } if channelClosed { ch . onClosed ( ) } } 
func NewReader ( reader io . Reader ) * Reader { r := readerPool . Get ( ) . ( * Reader ) r . reader = reader r . err = nil return r } 
func ( r * Reader ) ReadUint16 ( ) uint16 { if r . err != nil { return 0 } buf := r . buf [ : 2 ] var readN int readN , r . err = io . ReadFull ( r . reader , buf ) if readN < 2 { return 0 } return binary . BigEndian . Uint16 ( buf ) } 
func ( r * Reader ) ReadString ( n int ) string { if r . err != nil { return " " } var buf [ ] byte if n <= maxPoolStringLen { buf = r . buf [ : n ] } else { buf = make ( [ ] byte , n ) } var readN int readN , r . err = io . ReadFull ( r . reader , buf ) if readN < n { return " " } s := string ( buf ) return s } 
func ( r * Reader ) ReadLen16String ( ) string { len := r . ReadUint16 ( ) return r . ReadString ( int ( len ) ) } 
func ( b * Behavior ) Register ( ch * tchannel . Channel ) { b . registerThrift ( ch ) b . registerJSON ( ch ) } 
func ( b * Behavior ) Run ( t crossdock . T ) { logParams ( t ) sampled , err := strconv . ParseBool ( t . Param ( sampledParam ) ) if err != nil { t . Fatalf ( " " , sampledParam , err ) } baggage := randomBaggage ( ) level1 := & Request { ServerRole : RoleS1 , } server1 := t . Param ( server1NameParam ) level2 := & Downstream { ServiceName : t . Param ( server2NameParam ) , ServerRole : RoleS2 , HostPort : fmt . Sprintf ( " " , b . serviceToHost ( t . Param ( server2NameParam ) ) , b . ServerPort , ) , Encoding : t . Param ( server2EncodingParam ) , } level1 . Downstream = level2 level3 := & Downstream { ServiceName : t . Param ( server3NameParam ) , ServerRole : RoleS3 , HostPort : fmt . Sprintf ( " " , b . serviceToHost ( t . Param ( server3NameParam ) ) , b . ServerPort , ) , Encoding : t . Param ( server3EncodingParam ) , } level2 . Downstream = level3 resp , err := b . startTrace ( t , level1 , sampled , baggage ) if err != nil { t . Errorf ( " " , server1 , err . Error ( ) ) return } log . Printf ( " " , resp . Span , resp . Downstream ) traceID := resp . Span . TraceID require := crossdock . Require ( t ) require . NotEmpty ( traceID , " " , server1 ) if validateTrace ( t , level1 . Downstream , resp , server1 , 1 , traceID , sampled , baggage ) { t . Successf ( " " ) log . Println ( " " ) } else { log . Println ( " " ) } } 
func ( tp * relayTimerPool ) Get ( ) * relayTimer { timer , ok := tp . pool . Get ( ) . ( * relayTimer ) if ok { timer . released = false return timer } rt := & relayTimer { pool : tp , } if ! rt . timer . Stop ( ) { panic ( " " ) } return rt } 
func ( tp * relayTimerPool ) Put ( rt * relayTimer ) { if tp . verify { } tp . pool . Put ( rt ) } 
func ( rt * relayTimer ) Start ( d time . Duration , items * relayItems , id uint32 , isOriginator bool ) { rt . verifyNotReleased ( ) if rt . active { panic ( " " ) } rt . active = true rt . items = items rt . id = id rt . isOriginator = isOriginator if wasActive := rt . timer . Reset ( d ) ; wasActive { panic ( " " ) } } 
func ( rt * relayTimer ) Stop ( ) bool { rt . verifyNotReleased ( ) stopped := rt . timer . Stop ( ) if stopped { rt . markTimerInactive ( ) } return stopped } 
func ( rt * relayTimer ) Release ( ) { rt . verifyNotReleased ( ) if rt . active { panic ( " " ) } rt . released = true rt . pool . Put ( rt ) } 
func NewLogger ( writer io . Writer , fields ... LogField ) Logger { return & writerLogger { writer , fields } } 
func NewTCPFrameRelay ( dests [ ] string , modifier func ( bool , * tchannel . Frame ) * tchannel . Frame ) ( Relay , error ) { var err error r := & tcpFrameRelay { modifier : modifier } r . tcpRelay , err = newTCPRelay ( dests , r . handleConnFrameRelay ) if err != nil { return nil , err } return r , nil } 
func NewTallyReporter ( scope tally . Scope ) tchannel . StatsReporter { return & wrapper { scope : scope , byTags : make ( map [ knownTags ] * taggedScope ) , } } 
func ( kt knownTags ) tallyTags ( ) map [ string ] string { tallyTags := make ( map [ string ] string , 5 ) if kt . dest != " " { tallyTags [ " " ] = kt . dest } if kt . source != " " { tallyTags [ " " ] = kt . source } if kt . procedure != " " { tallyTags [ " " ] = kt . procedure } if kt . retryCount != " " { tallyTags [ " " ] = kt . retryCount } return tallyTags } 
func Isolated ( s * SubChannel ) { s . Lock ( ) s . peers = s . topChannel . peers . newSibling ( ) s . peers . SetStrategy ( newLeastPendingCalculator ( ) ) s . Unlock ( ) } 
func ( c * SubChannel ) BeginCall ( ctx context . Context , methodName string , callOptions * CallOptions ) ( * OutboundCall , error ) { if callOptions == nil { callOptions = defaultCallOptions } peer , err := c . peers . Get ( callOptions . RequestState . PrevSelectedPeers ( ) ) if err != nil { return nil , err } return peer . BeginCall ( ctx , c . ServiceName ( ) , methodName , callOptions ) } 
func ( c * SubChannel ) Isolated ( ) bool { c . RLock ( ) defer c . RUnlock ( ) return c . topChannel . Peers ( ) != c . peers } 
func ( c * SubChannel ) Register ( h Handler , methodName string ) { handlers , ok := c . handler . ( * handlerMap ) if ! ok { panic ( fmt . Sprintf ( " " , c . ServiceName ( ) , ) ) } handlers . register ( h , methodName ) } 
func ( c * SubChannel ) GetHandlers ( ) map [ string ] Handler { handlers , ok := c . handler . ( * handlerMap ) if ! ok { panic ( fmt . Sprintf ( " " , c . ServiceName ( ) , ) ) } handlers . RLock ( ) handlersMap := make ( map [ string ] Handler , len ( handlers . handlers ) ) for k , v := range handlers . handlers { handlersMap [ k ] = v } handlers . RUnlock ( ) return handlersMap } 
func ( c * SubChannel ) StatsTags ( ) map [ string ] string { tags := c . topChannel . StatsTags ( ) tags [ " " ] = c . serviceName return tags } 
func ( subChMap * subChannelMap ) registerNewSubChannel ( serviceName string , ch * Channel ) ( _ * SubChannel , added bool ) { subChMap . Lock ( ) defer subChMap . Unlock ( ) if subChMap . subchannels == nil { subChMap . subchannels = make ( map [ string ] * SubChannel ) } if sc , ok := subChMap . subchannels [ serviceName ] ; ok { return sc , false } sc := newSubChannel ( serviceName , ch ) subChMap . subchannels [ serviceName ] = sc return sc , true } 
func ( subChMap * subChannelMap ) get ( serviceName string ) ( * SubChannel , bool ) { subChMap . RLock ( ) sc , ok := subChMap . subchannels [ serviceName ] subChMap . RUnlock ( ) return sc , ok } 
func ( subChMap * subChannelMap ) getOrAdd ( serviceName string , ch * Channel ) ( _ * SubChannel , added bool ) { if sc , ok := subChMap . get ( serviceName ) ; ok { return sc , false } return subChMap . registerNewSubChannel ( serviceName , ch ) } 
func ( c * Client ) Discover ( serviceName string ) ( [ ] string , error ) { ctx , cancel := thrift . NewContext ( time . Second ) defer cancel ( ) result , err := c . hyperbahnClient . Discover ( ctx , & hyperbahn . DiscoveryQuery { ServiceName : serviceName } ) if err != nil { return nil , err } var hostPorts [ ] string for _ , peer := range result . GetPeers ( ) { hostPorts = append ( hostPorts , servicePeerToHostPort ( peer ) ) } return hostPorts , nil } 
func ( c * Client ) Start ( ) error { if err := c . listen ( ) ; err != nil { return err } go func ( ) { http . Serve ( c . listener , c . mux ) } ( ) return nil } 
func ( c * Client ) listen ( ) error { c . setDefaultPort ( & c . ClientHostPort , " " + common . DefaultClientPortHTTP ) c . setDefaultPort ( & c . ServerPort , common . DefaultServerPort ) c . mux = http . NewServeMux ( ) c . mux . Handle ( " " , crossdock . Handler ( c . Behaviors , true ) ) listener , err := net . Listen ( " " , c . ClientHostPort ) if err != nil { return err } c . listener = listener c . ClientHostPort = listener . Addr ( ) . String ( ) return nil } 
func WriteRequest ( call tchannel . ArgWritable , req * http . Request ) error { wb . WriteLen8String ( req . Method ) writeVarintString ( wb , req . URL . String ( ) ) writeHeaders ( wb , req . Header ) arg2Writer , err := call . Arg2Writer ( ) if err != nil { return err } if _ , err := wb . FlushTo ( arg2Writer ) ; err != nil { return err } if err := arg2Writer . Close ( ) ; err != nil { return err } arg3Writer , err := call . Arg3Writer ( ) if err != nil { return err } if req . Body != nil { if _ , err = io . Copy ( arg3Writer , req . Body ) ; err != nil { return err } } return arg3Writer . Close ( ) } 
func ReadRequest ( call tchannel . ArgReadable ) ( * http . Request , error ) { var arg2 [ ] byte if err := tchannel . NewArgReader ( call . Arg2Reader ( ) ) . Read ( & arg2 ) ; err != nil { return nil , err } rb := typed . NewReadBuffer ( arg2 ) method := rb . ReadLen8String ( ) url := readVarintString ( rb ) r , err := http . NewRequest ( method , url , nil ) if err != nil { return nil , err } readHeaders ( rb , r . Header ) if err := rb . Err ( ) ; err != nil { return nil , err } r . Body , err = call . Arg3Reader ( ) return r , err } 
func NewReadBufferWithSize ( size int ) * ReadBuffer { return & ReadBuffer { buffer : make ( [ ] byte , size ) , remaining : nil } } 
func ( r * ReadBuffer ) ReadByte ( ) ( byte , error ) { if r . err != nil { return 0 , r . err } if len ( r . remaining ) < 1 { r . err = ErrEOF return 0 , r . err } b := r . remaining [ 0 ] r . remaining = r . remaining [ 1 : ] return b , nil } 
func ( r * ReadBuffer ) ReadBytes ( n int ) [ ] byte { if r . err != nil { return nil } if len ( r . remaining ) < n { r . err = ErrEOF return nil } b := r . remaining [ 0 : n ] r . remaining = r . remaining [ n : ] return b } 
func ( r * ReadBuffer ) ReadString ( n int ) string { if b := r . ReadBytes ( n ) ; b != nil { } return " " } 
func ( r * ReadBuffer ) ReadUint16 ( ) uint16 { if b := r . ReadBytes ( 2 ) ; b != nil { return binary . BigEndian . Uint16 ( b ) } return 0 } 
func ( r * ReadBuffer ) ReadUint32 ( ) uint32 { if b := r . ReadBytes ( 4 ) ; b != nil { return binary . BigEndian . Uint32 ( b ) } return 0 } 
func ( r * ReadBuffer ) ReadUint64 ( ) uint64 { if b := r . ReadBytes ( 8 ) ; b != nil { return binary . BigEndian . Uint64 ( b ) } return 0 } 
func ( r * ReadBuffer ) ReadUvarint ( ) uint64 { v , _ := binary . ReadUvarint ( r ) return v } 
func ( r * ReadBuffer ) ReadLen8String ( ) string { n := r . ReadSingleByte ( ) return r . ReadString ( int ( n ) ) } 
func ( r * ReadBuffer ) ReadLen16String ( ) string { n := r . ReadUint16 ( ) return r . ReadString ( int ( n ) ) } 
func ( r * ReadBuffer ) FillFrom ( ior io . Reader , n int ) ( int , error ) { if len ( r . buffer ) < n { return 0 , ErrEOF } r . err = nil r . remaining = r . buffer [ : n ] return io . ReadFull ( ior , r . remaining ) } 
func ( r * ReadBuffer ) Wrap ( b [ ] byte ) { r . buffer = b r . remaining = b r . err = nil } 
func ( w * WriteBuffer ) WriteSingleByte ( n byte ) { if w . err != nil { return } if len ( w . remaining ) == 0 { w . setErr ( ErrBufferFull ) return } w . remaining [ 0 ] = n w . remaining = w . remaining [ 1 : ] } 
func ( w * WriteBuffer ) WriteBytes ( in [ ] byte ) { if b := w . reserve ( len ( in ) ) ; b != nil { copy ( b , in ) } } 
func ( w * WriteBuffer ) WriteUint16 ( n uint16 ) { if b := w . reserve ( 2 ) ; b != nil { binary . BigEndian . PutUint16 ( b , n ) } } 
func ( w * WriteBuffer ) WriteUint32 ( n uint32 ) { if b := w . reserve ( 4 ) ; b != nil { binary . BigEndian . PutUint32 ( b , n ) } } 
func ( w * WriteBuffer ) WriteUint64 ( n uint64 ) { if b := w . reserve ( 8 ) ; b != nil { binary . BigEndian . PutUint64 ( b , n ) } } 
func ( w * WriteBuffer ) WriteUvarint ( n uint64 ) { varBytes := binary . PutUvarint ( buf , n ) if b := w . reserve ( varBytes ) ; b != nil { copy ( b , buf [ 0 : varBytes ] ) } } 
func ( w * WriteBuffer ) WriteString ( s string ) { } } 
func ( w * WriteBuffer ) WriteLen8String ( s string ) { if int ( byte ( len ( s ) ) ) != len ( s ) { w . setErr ( errStringTooLong ) } w . WriteSingleByte ( byte ( len ( s ) ) ) w . WriteString ( s ) } 
func ( w * WriteBuffer ) WriteLen16String ( s string ) { if int ( uint16 ( len ( s ) ) ) != len ( s ) { w . setErr ( errStringTooLong ) } w . WriteUint16 ( uint16 ( len ( s ) ) ) w . WriteString ( s ) } 
func ( w * WriteBuffer ) DeferByte ( ) ByteRef { if len ( w . remaining ) == 0 { w . setErr ( ErrBufferFull ) return ByteRef ( nil ) } bufRef := ByteRef ( w . remaining [ 0 : ] ) w . remaining = w . remaining [ 1 : ] return bufRef } 
func ( w * WriteBuffer ) DeferBytes ( n int ) BytesRef { return BytesRef ( w . deferred ( n ) ) } 
func ( w * WriteBuffer ) FlushTo ( iow io . Writer ) ( int , error ) { dirty := w . buffer [ 0 : w . BytesWritten ( ) ] return iow . Write ( dirty ) } 
func ( w * WriteBuffer ) Reset ( ) { w . remaining = w . buffer w . err = nil } 
func ( w * WriteBuffer ) Wrap ( b [ ] byte ) { w . buffer = b w . remaining = b } 
func ( ref Uint16Ref ) Update ( n uint16 ) { if ref != nil { binary . BigEndian . PutUint16 ( ref , n ) } } 
func ( ref Uint32Ref ) Update ( n uint32 ) { if ref != nil { binary . BigEndian . PutUint32 ( ref , n ) } } 
func ( ref Uint64Ref ) Update ( n uint64 ) { if ref != nil { binary . BigEndian . PutUint64 ( ref , n ) } } 
func ( ref BytesRef ) Update ( b [ ] byte ) { if ref != nil { copy ( ref , b ) } } 
func ( ref BytesRef ) UpdateString ( s string ) { if ref != nil { copy ( ref , s ) } } 
func ( r * fragmentingReader ) ArgReader ( last bool ) ( ArgReader , error ) { if err := r . BeginArgument ( last ) ; err != nil { return nil , err } return r , nil } 
func ( f * writableFragment ) finish ( hasMoreFragments bool ) { f . checksumRef . Update ( f . checksum . Sum ( ) ) if hasMoreFragments { f . flagsRef . Update ( hasMoreFragmentsFlag ) } else { f . checksum . Release ( ) } } 
func newWritableChunk ( checksum Checksum , contents * typed . WriteBuffer ) * writableChunk { return & writableChunk { size : 0 , sizeRef : contents . DeferUint16 ( ) , checksum : checksum , contents : contents , } } 
func ( c * writableChunk ) writeAsFits ( b [ ] byte ) int { if len ( b ) > c . contents . BytesRemaining ( ) { b = b [ : c . contents . BytesRemaining ( ) ] } c . checksum . Add ( b ) c . contents . WriteBytes ( b ) written := len ( b ) c . size += uint16 ( written ) return written } 
func newFragmentingWriter ( logger Logger , sender fragmentSender , checksum Checksum ) * fragmentingWriter { return & fragmentingWriter { logger : logger , sender : sender , checksum : checksum , state : fragmentingWriteStart , } } 
func ( w * fragmentingWriter ) ArgWriter ( last bool ) ( ArgWriter , error ) { if err := w . BeginArgument ( last ) ; err != nil { return nil , err } return w , nil } 
func ( w * fragmentingWriter ) BeginArgument ( last bool ) error { if w . err != nil { return w . err } switch { case w . state == fragmentingWriteComplete : w . err = errComplete return w . err case w . state . isWritingArgument ( ) : w . err = errAlreadyWritingArgument return w . err } if w . curFragment , w . err = w . sender . newFragment ( initial , w . checksum ) ; w . err != nil { return w . err } } } w . curChunk = newWritableChunk ( w . checksum , w . curFragment . contents ) w . state = fragmentingWriteInArgument if last { w . state = fragmentingWriteInLastArgument } return nil } 
func ( w * fragmentingWriter ) Write ( b [ ] byte ) ( int , error ) { if w . err != nil { return 0 , w . err } if ! w . state . isWritingArgument ( ) { w . err = errNotWritingArgument return 0 , w . err } totalWritten := 0 for { bytesWritten := w . curChunk . writeAsFits ( b ) totalWritten += bytesWritten if bytesWritten == len ( b ) { } } b = b [ bytesWritten : ] } } 
func ( w * fragmentingWriter ) Flush ( ) error { w . curChunk . finish ( ) w . curFragment . finish ( true ) if w . err = w . sender . flushFragment ( w . curFragment ) ; w . err != nil { return w . err } if w . curFragment , w . err = w . sender . newFragment ( false , w . checksum ) ; w . err != nil { return w . err } w . curChunk = newWritableChunk ( w . checksum , w . curFragment . contents ) return nil } 
func ( w * fragmentingWriter ) Close ( ) error { last := w . state == fragmentingWriteInLastArgument if w . err != nil { return w . err } if ! w . state . isWritingArgument ( ) { w . err = errNotWritingArgument return w . err } w . curChunk . finish ( ) w . curFragment . finish ( false ) w . err = w . sender . flushFragment ( w . curFragment ) w . sender . doneSending ( ) return w . err } w . state = fragmentingWriteWaitingForArgument if w . curFragment . contents . BytesRemaining ( ) > chunkHeaderSize { } if w . err = w . sender . flushFragment ( w . curFragment ) ; w . err != nil { return w . err } if w . curFragment , w . err = w . sender . newFragment ( false , w . checksum ) ; w . err != nil { return w . err } return nil } 
func ( c * Connection ) beginCall ( ctx context . Context , serviceName , methodName string , callOptions * CallOptions ) ( * OutboundCall , error ) { now := c . timeNow ( ) switch state := c . readState ( ) ; state { case connectionActive : break case connectionStartClose , connectionInboundClosed , connectionClosed : return nil , ErrConnectionClosed default : return nil , errConnectionUnknownState { " " , state } } deadline , ok := ctx . Deadline ( ) if ! ok { } if timeToLive < time . Millisecond { return nil , ErrTimeout } if err := ctx . Err ( ) ; err != nil { return nil , GetContextError ( err ) } requestID := c . NextMessageID ( ) mex , err := c . outbound . newExchange ( ctx , c . opts . FramePool , messageTypeCallReq , requestID , mexChannelBufferSize ) if err != nil { return nil , err } return nil , ErrConnectionClosed } callOptions . setHeaders ( headers ) if opts := currentCallOptions ( ctx ) ; opts != nil { opts . overrideHeaders ( headers ) } call := new ( OutboundCall ) call . mex = mex call . conn = c call . callReq = callReq { id : requestID , Headers : headers , Service : serviceName , TimeToLive : timeToLive , } call . statsReporter = c . statsReporter call . createStatsTags ( c . commonStatsTags , callOptions , methodName ) call . log = c . log . WithFields ( LogField { " " , requestID } ) } return new ( callReqContinue ) } call . contents = newFragmentingWriter ( call . log , call , c . opts . ChecksumType . New ( ) ) response := new ( OutboundCallResponse ) response . startedAt = now response . timeNow = c . timeNow response . requestState = callOptions . RequestState response . mex = mex response . log = c . log . WithFields ( LogField { " " , requestID } ) response . span = c . startOutboundSpan ( ctx , serviceName , methodName , call , now ) response . messageForFragment = func ( initial bool ) message { if initial { return & response . callRes } return new ( callResContinue ) } response . contents = newFragmentingReader ( response . log , response ) response . statsReporter = call . statsReporter response . commonStatsTags = call . commonStatsTags call . response = response if err := call . writeMethod ( [ ] byte ( methodName ) ) ; err != nil { return nil , err } return call , nil } 
func ( c * Connection ) handleCallRes ( frame * Frame ) bool { if err := c . outbound . forwardPeerFrame ( frame ) ; err != nil { return true } return false } 
func ( call * OutboundCall ) createStatsTags ( connectionTags map [ string ] string , callOptions * CallOptions , method string ) { call . commonStatsTags = map [ string ] string { " " : call . callReq . Service , } for k , v := range connectionTags { call . commonStatsTags [ k ] = v } if callOptions . Format != HTTP { call . commonStatsTags [ " " ] = string ( method ) } } 
func ( call * OutboundCall ) writeMethod ( method [ ] byte ) error { call . statsReporter . IncCounter ( " " , call . commonStatsTags , 1 ) return NewArgWriter ( call . arg1Writer ( ) ) . Write ( method ) } 
func ( response * OutboundCallResponse ) Arg2Reader ( ) ( ArgReader , error ) { var method [ ] byte if err := NewArgReader ( response . arg1Reader ( ) ) . Read ( & method ) ; err != nil { return nil , err } return response . arg2Reader ( ) } 
func ( c * Connection ) handleError ( frame * Frame ) bool { errMsg := errorMessage { id : frame . Header . ID , } rbuf := typed . NewReadBuffer ( frame . SizedPayload ( ) ) if err := errMsg . read ( rbuf ) ; err != nil { c . log . WithFields ( LogField { " " , c . remotePeerInfo } , ErrField ( err ) , ) . Warn ( " " ) c . connectionError ( " " , err ) return true } if errMsg . errCode == ErrCodeProtocol { c . log . WithFields ( LogField { " " , c . remotePeerInfo } , LogField { " " , errMsg . message } , ) . Warn ( " " ) c . connectionError ( " " , errMsg . AsSystemError ( ) ) return true } if err := c . outbound . forwardPeerFrame ( frame ) ; err != nil { c . log . WithFields ( LogField { " " , frame . Header . String ( ) } , LogField { " " , errMsg . id } , LogField { " " , errMsg . message } , LogField { " " , errMsg . errCode } , ErrField ( err ) , ) . Info ( " " ) return true } } 
func ( response * OutboundCallResponse ) doneReading ( unexpected error ) { now := response . timeNow ( ) isSuccess := unexpected == nil && ! response . ApplicationError ( ) lastAttempt := isSuccess || ! response . requestState . HasRetries ( unexpected ) } if ! isSuccess && lastAttempt { ext . Error . Set ( span , true ) } span . FinishWithOptions ( opentracing . FinishOptions { FinishTime : now } ) } latency := now . Sub ( response . startedAt ) response . statsReporter . RecordTimer ( " " , response . commonStatsTags , latency ) if lastAttempt { requestLatency := response . requestState . SinceStart ( now , latency ) response . statsReporter . RecordTimer ( " " , response . commonStatsTags , requestLatency ) } if retryCount := response . requestState . RetryCount ( ) ; retryCount > 0 { retryTags := cloneTags ( response . commonStatsTags ) retryTags [ " " ] = fmt . Sprint ( retryCount ) response . statsReporter . IncCounter ( " " , retryTags , 1 ) } if unexpected != nil { if lastAttempt { response . statsReporter . IncCounter ( " " , response . commonStatsTags , 1 ) } } else { response . statsReporter . IncCounter ( " " , response . commonStatsTags , 1 ) } response . mex . shutdown ( ) } 
func ( w * reqResWriter ) argWriter ( last bool , inState reqResWriterState , outState reqResWriterState ) ( ArgWriter , error ) { if w . err != nil { return nil , w . err } if w . state != inState { return nil , w . failed ( errReqResWriterStateMismatch { state : w . state , expectedState : inState } ) } argWriter , err := w . contents . ArgWriter ( last ) if err != nil { return nil , w . failed ( err ) } w . state = outState return argWriter , nil } 
func ( w * reqResWriter ) newFragment ( initial bool , checksum Checksum ) ( * writableFragment , error ) { if err := w . mex . checkError ( ) ; err != nil { return nil , w . failed ( err ) } message := w . messageForFragment ( initial ) frame . Header . ID = w . mex . msgID frame . Header . messageType = message . messageType ( ) fragment := new ( writableFragment ) fragment . frame = frame fragment . flagsRef = wbuf . DeferByte ( ) if err := message . write ( wbuf ) ; err != nil { return nil , err } wbuf . WriteSingleByte ( byte ( checksum . TypeCode ( ) ) ) fragment . checksumRef = wbuf . DeferBytes ( checksum . Size ( ) ) fragment . checksum = checksum fragment . contents = wbuf return fragment , wbuf . Err ( ) } 
func ( w * reqResWriter ) flushFragment ( fragment * writableFragment ) error { if w . err != nil { return w . err } frame := fragment . frame . ( * Frame ) frame . Header . SetPayloadSize ( uint16 ( fragment . contents . BytesWritten ( ) ) ) if err := w . mex . checkError ( ) ; err != nil { return w . failed ( err ) } select { case <- w . mex . ctx . Done ( ) : return w . failed ( GetContextError ( w . mex . ctx . Err ( ) ) ) case <- w . mex . errCh . c : return w . failed ( w . mex . errCh . err ) case w . conn . sendCh <- frame : return nil } } 
func ( w * reqResWriter ) failed ( err error ) error { w . log . Debugf ( " " , err , w . err ) if w . err != nil { return w . err } w . mex . shutdown ( ) w . err = err return w . err } 
func ( r * reqResReader ) arg1Reader ( ) ( ArgReader , error ) { return r . argReader ( false , reqResReaderPreArg1 , reqResReaderPreArg2 ) } 
func ( r * reqResReader ) arg2Reader ( ) ( ArgReader , error ) { return r . argReader ( false , reqResReaderPreArg2 , reqResReaderPreArg3 ) } 
func ( r * reqResReader ) arg3Reader ( ) ( ArgReader , error ) { return r . argReader ( true , reqResReaderPreArg3 , reqResReaderComplete ) } 
func ( r * reqResReader ) argReader ( last bool , inState reqResReaderState , outState reqResReaderState ) ( ArgReader , error ) { if r . state != inState { return nil , r . failed ( errReqResReaderStateMismatch { state : r . state , expectedState : inState } ) } argReader , err := r . contents . ArgReader ( last ) if err != nil { return nil , r . failed ( err ) } r . state = outState return argReader , nil } 
func ( r * reqResReader ) recvNextFragment ( initial bool ) ( * readableFragment , error ) { if r . initialFragment != nil { fragment := r . initialFragment r . initialFragment = nil r . previousFragment = fragment return fragment , nil } frame , err := r . mex . recvPeerFrameOfType ( message . messageType ( ) ) if err != nil { if err , ok := err . ( errorMessage ) ; ok { return nil , err } return nil , r . failed ( err ) } if err != nil { return nil , r . failed ( err ) } r . previousFragment = fragment return fragment , nil } 
func ( r * reqResReader ) releasePreviousFragment ( ) { fragment := r . previousFragment r . previousFragment = nil if fragment != nil { fragment . done ( ) } } 
func ( r * reqResReader ) failed ( err error ) error { r . log . Debugf ( " " , err , r . err ) if r . err != nil { return r . err } r . mex . shutdown ( ) r . err = err return r . err } 
func parseInboundFragment ( framePool FramePool , frame * Frame , message message ) ( * readableFragment , error ) { rbuf := typed . NewReadBuffer ( frame . SizedPayload ( ) ) fragment := new ( readableFragment ) fragment . flags = rbuf . ReadSingleByte ( ) if err := message . read ( rbuf ) ; err != nil { return nil , err } fragment . checksumType = ChecksumType ( rbuf . ReadSingleByte ( ) ) fragment . checksum = rbuf . ReadBytes ( fragment . checksumType . ChecksumSize ( ) ) fragment . contents = rbuf fragment . onDone = func ( ) { framePool . Release ( frame ) } return fragment , rbuf . Err ( ) } 
func NewContext ( timeout time . Duration ) ( Context , context . CancelFunc ) { ctx , cancel := tchannel . NewContext ( timeout ) return Wrap ( ctx ) , cancel } 
func WithHeaders ( ctx context . Context , headers map [ string ] string ) Context { return tchannel . WrapWithHeaders ( ctx , headers ) } 
func ( c * Connection ) healthCheck ( connID uint32 ) { defer close ( c . healthCheckDone ) opts := c . opts . HealthChecks ticker := c . timeTicker ( opts . Interval ) defer ticker . Stop ( ) consecutiveFailures := 0 for { select { case <- ticker . C : case <- c . healthCheckCtx . Done ( ) : return } ctx , cancel := context . WithTimeout ( c . healthCheckCtx , opts . Timeout ) err := c . ping ( ctx ) cancel ( ) c . healthCheckHistory . add ( err == nil ) if err == nil { if c . log . Enabled ( LogLevelDebug ) { c . log . Debug ( " " ) } consecutiveFailures = 0 continue } return } consecutiveFailures ++ c . log . WithFields ( LogFields { { " " , consecutiveFailures } , ErrField ( err ) , { " " , opts . FailuresToClose } , } ... ) . Warn ( " " ) if consecutiveFailures >= opts . FailuresToClose { c . close ( LogFields { { " " , " " } , ErrField ( err ) , } ... ) return } } } 
func ( cb * ContextBuilder ) SetTimeout ( timeout time . Duration ) * ContextBuilder { cb . Timeout = timeout return cb } 
func ( cb * ContextBuilder ) AddHeader ( key , value string ) * ContextBuilder { if cb . Headers == nil { cb . Headers = map [ string ] string { key : value } } else { cb . Headers [ key ] = value } return cb } 
func ( cb * ContextBuilder ) SetHeaders ( headers map [ string ] string ) * ContextBuilder { cb . Headers = headers cb . replaceParentHeaders = true return cb } 
func ( cb * ContextBuilder ) SetShardKey ( sk string ) * ContextBuilder { if cb . CallOptions == nil { cb . CallOptions = new ( CallOptions ) } cb . CallOptions . ShardKey = sk return cb } 
func ( cb * ContextBuilder ) SetFormat ( f Format ) * ContextBuilder { if cb . CallOptions == nil { cb . CallOptions = new ( CallOptions ) } cb . CallOptions . Format = f return cb } 
func ( cb * ContextBuilder ) SetRoutingKey ( rk string ) * ContextBuilder { if cb . CallOptions == nil { cb . CallOptions = new ( CallOptions ) } cb . CallOptions . RoutingKey = rk return cb } 
func ( cb * ContextBuilder ) SetRoutingDelegate ( rd string ) * ContextBuilder { if cb . CallOptions == nil { cb . CallOptions = new ( CallOptions ) } cb . CallOptions . RoutingDelegate = rd return cb } 
func ( cb * ContextBuilder ) SetConnectTimeout ( d time . Duration ) * ContextBuilder { cb . ConnectTimeout = d return cb } 
func ( cb * ContextBuilder ) SetRetryOptions ( retryOptions * RetryOptions ) * ContextBuilder { cb . RetryOptions = retryOptions return cb } 
func ( cb * ContextBuilder ) SetTimeoutPerAttempt ( timeoutPerAttempt time . Duration ) * ContextBuilder { if cb . RetryOptions == nil { cb . RetryOptions = & RetryOptions { } } cb . RetryOptions . TimeoutPerAttempt = timeoutPerAttempt return cb } 
func ( cb * ContextBuilder ) SetParentContext ( ctx context . Context ) * ContextBuilder { cb . ParentContext = ctx return cb } 
func ( cb * ContextBuilder ) Build ( ) ( ContextWithHeaders , context . CancelFunc ) { params := & tchannelCtxParams { options : cb . CallOptions , call : cb . incomingCall , retryOptions : cb . RetryOptions , connectTimeout : cb . ConnectTimeout , hideListeningOnOutbound : cb . hideListeningOnOutbound , tracingDisabled : cb . TracingDisabled , } parent := cb . ParentContext if parent == nil { parent = context . Background ( ) } else if headerCtx , ok := parent . ( headerCtx ) ; ok { } var ( ctx context . Context cancel context . CancelFunc ) if cb . Timeout == 0 && parentHasDeadline { ctx , cancel = context . WithCancel ( parent ) } else { ctx , cancel = context . WithTimeout ( parent , cb . Timeout ) } ctx = context . WithValue ( ctx , contextKeyTChannel , params ) return WrapWithHeaders ( ctx , cb . getHeaders ( ) ) , cancel } 
func ( c * CallOptions ) overrideHeaders ( headers transportHeaders ) { if c . Format != " " { headers [ ArgScheme ] = c . Format . String ( ) } if c . ShardKey != " " { headers [ ShardKey ] = c . ShardKey } if c . RoutingKey != " " { headers [ RoutingKey ] = c . RoutingKey } if c . RoutingDelegate != " " { headers [ RoutingDelegate ] = c . RoutingDelegate } if c . callerName != " " { headers [ CallerName ] = c . callerName } } 
func ( r ArgReadHelper ) Read ( bs * [ ] byte ) error { return r . read ( func ( ) error { var err error * bs , err = ioutil . ReadAll ( r . reader ) return err } ) } 
func ( r ArgReadHelper ) ReadJSON ( data interface { } ) error { return r . read ( func ( ) error { if _ , err := reader . Peek ( 1 ) ; err == io . EOF { } else if err != nil { return err } d := json . NewDecoder ( reader ) return d . Decode ( data ) } ) } 
func NewArgWriter ( writer io . WriteCloser , err error ) ArgWriteHelper { return ArgWriteHelper { writer , err } } 
func ( w ArgWriteHelper ) Write ( bs [ ] byte ) error { return w . write ( func ( ) error { _ , err := w . writer . Write ( bs ) return err } ) } 
func ( w ArgWriteHelper ) WriteJSON ( data interface { } ) error { return w . write ( func ( ) error { e := json . NewEncoder ( w . writer ) return e . Encode ( data ) } ) } 
func Register ( registrar tchannel . Registrar ) { handler := func ( ctx context . Context , call * tchannel . InboundCall ) { req , err := thttp . ReadRequest ( call ) if err != nil { registrar . Logger ( ) . WithFields ( tchannel . LogField { Key : " " , Value : err . Error ( ) } , ) . Warn ( " " ) return } serveHTTP ( req , call . Response ( ) ) } registrar . Register ( tchannel . HandlerFunc ( handler ) , " " ) } 
func ( r * relayItems ) Count ( ) int { r . RLock ( ) n := len ( r . items ) - int ( r . tombs ) r . RUnlock ( ) return n } 
func ( r * relayItems ) Get ( id uint32 ) ( relayItem , bool ) { r . RLock ( ) item , ok := r . items [ id ] r . RUnlock ( ) return item , ok } 
func ( r * relayItems ) Add ( id uint32 , item relayItem ) { r . Lock ( ) r . items [ id ] = item r . Unlock ( ) } 
func ( r * relayItems ) Delete ( id uint32 ) ( relayItem , bool ) { r . Lock ( ) item , ok := r . items [ id ] if ! ok { r . Unlock ( ) r . logger . WithFields ( LogField { " " , id } ) . Warn ( " " ) return item , false } delete ( r . items , id ) if item . tomb { r . tombs -- } r . Unlock ( ) item . timeout . Stop ( ) item . timeout . Release ( ) return item , ! item . tomb } 
func ( r * relayItems ) Entomb ( id uint32 , deleteAfter time . Duration ) ( relayItem , bool ) { r . Lock ( ) if r . tombs > _maxRelayTombs { r . Unlock ( ) r . logger . WithFields ( LogField { " " , id } ) . Warn ( " " ) return r . Delete ( id ) } item , ok := r . items [ id ] if ! ok { r . Unlock ( ) r . logger . WithFields ( LogField { " " , id } ) . Warn ( " " ) return item , false } if item . tomb { r . Unlock ( ) r . logger . WithFields ( LogField { " " , id } ) . Warn ( " " ) return item , false } r . tombs ++ item . tomb = true r . items [ id ] = item r . Unlock ( ) return item , true } 
func NewRelayer ( ch * Channel , conn * Connection ) * Relayer { r := & Relayer { relayHost : ch . RelayHost ( ) , maxTimeout : ch . relayMaxTimeout , localHandler : ch . relayLocal , outbound : newRelayItems ( conn . log . WithFields ( LogField { " " , " " } ) ) , inbound : newRelayItems ( conn . log . WithFields ( LogField { " " , " " } ) ) , peers : ch . RootPeers ( ) , conn : conn , relayConn : & relay . Conn { RemoteAddr : conn . conn . RemoteAddr ( ) . String ( ) , RemoteProcessName : conn . RemotePeerInfo ( ) . ProcessName , IsOutbound : conn . connDirection == outbound , } , logger : conn . log , } r . timeouts = newRelayTimerPool ( r . timeoutRelayItem , ch . relayTimerVerify ) return r } 
func ( r * Relayer ) Relay ( f * Frame ) error { if f . messageType ( ) != messageTypeCallReq { err := r . handleNonCallReq ( f ) if err == errUnknownID { } } return err } return r . handleCallReq ( newLazyCallReq ( f ) ) } 
func ( r * Relayer ) Receive ( f * Frame , fType frameType ) ( sent bool , failureReason string ) { id := f . Header . ID item , ok := items . Get ( id ) if ! ok { r . logger . WithFields ( LogField { " " , id } , ) . Warn ( " " ) return false , _relayErrorNotFound } finished := finishesCall ( f ) if item . tomb { } } else if len ( failMsg ) > 0 { item . call . Failed ( failMsg ) } } select { case r . conn . sendCh <- f : default : items := r . receiverItems ( fType ) err := _relayErrorDestConnSlow } r . failRelayItem ( items , id , err ) return false , err } if finished { r . finishRelayItem ( items , id ) } return true , " " } 
func ( r * Relayer ) handleNonCallReq ( f * Frame ) error { frameType := frameTypeFor ( f ) finished := finishesCall ( f ) if frameType == responseFrame { items = r . inbound } item , ok := items . Get ( f . Header . ID ) if ! ok { return errUnknownID } if item . tomb { } originalID := f . Header . ID f . Header . ID = item . remapID sent , failure := item . destination . Receive ( f , frameType ) if ! sent { r . failRelayItem ( items , originalID , failure ) return nil } if finished { r . finishRelayItem ( items , originalID ) } return nil } 
func ( r * Relayer ) addRelayItem ( isOriginator bool , id , remapID uint32 , destination * Relayer , ttl time . Duration , span Span , call RelayCall ) relayItem { item := relayItem { call : call , remapID : remapID , destination : destination , span : span , } items := r . inbound if isOriginator { items = r . outbound } item . timeout = r . timeouts . Get ( ) items . Add ( id , item ) item . timeout . Start ( ttl , items , id , isOriginator ) return item } 
func ( r * Relayer ) failRelayItem ( items * relayItems , id uint32 , failure string ) { item , ok := items . Get ( id ) if ! ok { items . logger . WithFields ( LogField { " " , id } ) . Warn ( " " ) return } } if ! ok { return } if item . call != nil { } item . call . Failed ( failure ) item . call . End ( ) } r . decrementPending ( ) } 
func WriteStruct ( writer io . Writer , s thrift . TStruct ) error { wp := getProtocolWriter ( writer ) err := s . Write ( wp . protocol ) thriftProtocolPool . Put ( wp ) return err } 
func ReadStruct ( reader io . Reader , s thrift . TStruct ) error { wp := getProtocolReader ( reader ) err := s . Read ( wp . protocol ) thriftProtocolPool . Put ( wp ) return err } 
func EnsureEmpty ( r io . Reader , stage string ) error { buf := _bufPool . Get ( ) . ( * [ ] byte ) defer _bufPool . Put ( buf ) n , err := r . Read ( * buf ) if n > 0 { return fmt . Errorf ( " " , stage , ( * buf ) [ : n ] ) } if err == io . EOF { return nil } return err } 
func NewServer ( optFns ... Option ) Server { opts := getOptions ( optFns ) if opts . external { return newExternalServer ( opts ) } ch , err := tchannel . NewChannel ( opts . svcName , & tchannel . ChannelOptions { Logger : tchannel . NewLevelLogger ( tchannel . NewLogger ( os . Stderr ) , tchannel . LogLevelWarn ) , } ) if err != nil { panic ( " " + err . Error ( ) ) } if err := ch . ListenAndServe ( " " ) ; err != nil { panic ( " " + err . Error ( ) ) } s := & internalServer { ch : ch , opts : opts , } tServer := thrift . NewServer ( ch ) tServer . Register ( gen . NewTChanSecondServiceServer ( handler { calls : & s . thriftCalls } ) ) ch . Register ( raw . Wrap ( rawHandler { calls : & s . rawCalls } ) , " " ) if len ( opts . advertiseHosts ) > 0 { if err := s . Advertise ( opts . advertiseHosts ) ; err != nil { panic ( " " + err . Error ( ) ) } } return s } 
func ( s * internalServer ) Advertise ( hyperbahnHosts [ ] string ) error { config := hyperbahn . Configuration { InitialNodes : hyperbahnHosts } hc , err := hyperbahn . NewClient ( s . ch , config , nil ) if err != nil { panic ( " " + err . Error ( ) ) } return hc . Advertise ( ) } 
func ( c * Connection ) handleCallReq ( frame * Frame ) bool { now := c . timeNow ( ) switch state := c . readState ( ) ; state { case connectionActive : break case connectionStartClose , connectionInboundClosed , connectionClosed : c . SendSystemError ( frame . Header . ID , callReqSpan ( frame ) , ErrChannelClosed ) return true default : panic ( fmt . Errorf ( " " , state ) ) } callReq := new ( callReq ) callReq . id = frame . Header . ID initialFragment , err := parseInboundFragment ( c . opts . FramePool , frame , callReq ) if err != nil { return true } call := new ( InboundCall ) call . conn = c ctx , cancel := newIncomingContext ( call , callReq . TimeToLive ) mex , err := c . inbound . newExchange ( ctx , c . opts . FramePool , callReq . messageType ( ) , frame . Header . ID , mexChannelBufferSize ) if err != nil { if err == errDuplicateMex { err = errInboundRequestAlreadyActive } c . log . WithFields ( LogField { " " , frame . Header } ) . Error ( " " ) c . protocolError ( frame . Header . ID , errInboundRequestAlreadyActive ) return true } return true } response := new ( InboundCallResponse ) response . call = call response . calledAt = now response . timeNow = c . timeNow response . span = c . extractInboundSpan ( callReq ) if response . span != nil { mex . ctx = opentracing . ContextWithSpan ( mex . ctx , response . span ) } response . mex = mex response . conn = c response . cancel = cancel response . log = c . log . WithFields ( LogField { " " , callReq . ID ( ) } ) response . contents = newFragmentingWriter ( response . log , response , initialFragment . checksumType . New ( ) ) response . headers = transportHeaders { } response . messageForFragment = func ( initial bool ) message { if initial { callRes := new ( callRes ) callRes . Headers = response . headers callRes . ResponseCode = responseOK if response . applicationError { callRes . ResponseCode = responseApplicationError } return callRes } return new ( callResContinue ) } call . mex = mex call . initialFragment = initialFragment call . serviceName = string ( callReq . Service ) call . headers = callReq . Headers call . response = response call . log = c . log . WithFields ( LogField { " " , callReq . ID ( ) } ) call . messageForFragment = func ( initial bool ) message { return new ( callReqContinue ) } call . contents = newFragmentingReader ( call . log , call ) call . statsReporter = c . statsReporter call . createStatsTags ( c . commonStatsTags ) response . statsReporter = c . statsReporter response . commonStatsTags = call . commonStatsTags setResponseHeaders ( call . headers , response . headers ) go c . dispatchInbound ( c . connID , callReq . ID ( ) , call , frame ) return false } 
func ( c * Connection ) handleCallReqContinue ( frame * Frame ) bool { if err := c . inbound . forwardPeerFrame ( frame ) ; err != nil { } return false } 
func ( call * InboundCall ) createStatsTags ( connectionTags map [ string ] string ) { call . commonStatsTags = map [ string ] string { " " : call . CallerName ( ) , } for k , v := range connectionTags { call . commonStatsTags [ k ] = v } } 
func ( c * Connection ) dispatchInbound ( _ uint32 , _ uint32 , call * InboundCall , frame * Frame ) { if call . log . Enabled ( LogLevelDebug ) { call . log . Debugf ( " " , call . ServiceName ( ) , c . remotePeerInfo ) } if err := call . readMethod ( ) ; err != nil { call . log . WithFields ( LogField { " " , c . remotePeerInfo } , ErrField ( err ) , ) . Error ( " " ) c . opts . FramePool . Release ( frame ) return } call . commonStatsTags [ " " ] = call . methodString call . statsReporter . IncCounter ( " " , call . commonStatsTags , 1 ) if span := call . response . span ; span != nil { span . SetOperationName ( call . methodString ) } } case <- call . mex . errCh . c : if c . log . Enabled ( LogLevelDebug ) { call . log . Debugf ( " " , call . mex . errCh . err ) } call . mex . inboundExpired ( ) } } ( ) c . handler . Handle ( call . mex . ctx , call ) } 
func ( call * InboundCall ) CallOptions ( ) * CallOptions { return & CallOptions { callerName : call . CallerName ( ) , Format : call . Format ( ) , ShardKey : call . ShardKey ( ) , RoutingDelegate : call . RoutingDelegate ( ) , RoutingKey : call . RoutingKey ( ) , } } 
func ( call * InboundCall ) readMethod ( ) error { var arg1 [ ] byte if err := NewArgReader ( call . arg1Reader ( ) ) . Read ( & arg1 ) ; err != nil { return call . failed ( err ) } call . method = arg1 call . methodString = string ( arg1 ) return nil } 
func ( call * InboundCall ) Response ( ) * InboundCallResponse { if call . err != nil { } return call . response } 
func ( response * InboundCallResponse ) SendSystemError ( err error ) error { if response . err != nil { return response . err } response . systemError = true response . doneSending ( ) response . call . releasePreviousFragment ( ) span := CurrentSpan ( response . mex . ctx ) return response . conn . SendSystemError ( response . mex . msgID , * span , err ) } 
func ( response * InboundCallResponse ) SetApplicationError ( ) error { if response . state > reqResWriterPreArg2 { return response . failed ( errReqResWriterStateMismatch { state : response . state , expectedState : reqResWriterPreArg2 , } ) } response . applicationError = true return nil } 
func ( response * InboundCallResponse ) Arg2Writer ( ) ( ArgWriter , error ) { if err := NewArgWriter ( response . arg1Writer ( ) ) . Write ( nil ) ; err != nil { return nil , err } return response . arg2Writer ( ) } 
func ( response * InboundCallResponse ) doneSending ( ) { if span := response . span ; span != nil { if response . applicationError || response . systemError { ext . Error . Set ( span , true ) } span . FinishWithOptions ( opentracing . FinishOptions { FinishTime : now } ) } latency := now . Sub ( response . calledAt ) response . statsReporter . RecordTimer ( " " , response . commonStatsTags , latency ) if response . systemError { } else { response . statsReporter . IncCounter ( " " , response . commonStatsTags , 1 ) } } } 
func newState ( v * parser . Thrift , all map [ string ] parseState ) * State { typedefs := make ( map [ string ] * parser . Type ) for k , v := range v . Typedefs { typedefs [ k ] = v . Type } for k := range v . Enums { typedefs [ k ] = i64Type } return & State { typedefs , nil , all } } 
func ( s * State ) rootType ( thriftType * parser . Type ) * parser . Type { if state , newType , include := s . checkInclude ( thriftType ) ; include != nil { return state . rootType ( newType ) } if v , ok := s . typedefs [ thriftType . Name ] ; ok { return s . rootType ( v ) } return thriftType } 
func ( s * State ) checkInclude ( thriftType * parser . Type ) ( * State , * parser . Type , * Include ) { parts := strings . SplitN ( thriftType . Name , " " , 2 ) if len ( parts ) < 2 { return nil , nil , nil } newType := * thriftType newType . Name = parts [ 1 ] include := s . includes [ parts [ 0 ] ] state := s . all [ include . file ] return state . global , & newType , include } 
func ( s * State ) isResultPointer ( thriftType * parser . Type ) bool { _ , basicGoType := thriftToGo [ s . rootType ( thriftType ) . Name ] return ! basicGoType } 
func ( s * State ) goType ( thriftType * parser . Type ) string { return s . goTypePrefix ( " " , thriftType ) } 
func ( s * State ) goTypePrefix ( prefix string , thriftType * parser . Type ) string { switch thriftType . Name { case " " : return " " case " " : return " " + s . goType ( thriftType . ValueType ) case " " : return " " + s . goType ( thriftType . ValueType ) + " " case " " : return " " + s . goType ( thriftType . KeyType ) + " " + s . goType ( thriftType . ValueType ) } } } goThriftName := goPublicFieldName ( thriftType . Name ) goThriftName = prefix + goThriftName if _ , ok := thriftToGo [ rootType . Name ] ; ok { return goThriftName } if rootType . Name == " " || rootType . Name == " " || rootType . Name == " " { return goThriftName } } } 
func NewContext ( timeout time . Duration ) ( context . Context , context . CancelFunc ) { return NewContextBuilder ( timeout ) . Build ( ) } 
func newIncomingContext ( call IncomingCall , timeout time . Duration ) ( context . Context , context . CancelFunc ) { return NewContextBuilder ( timeout ) . setIncomingCall ( call ) . Build ( ) } 
func CurrentCall ( ctx context . Context ) IncomingCall { if params := getTChannelParams ( ctx ) ; params != nil { return params . call } return nil } 
func ( p * KeyValueClient ) Get ( key string ) ( r string , err error ) { if err = p . sendGet ( key ) ; err != nil { return } return p . recvGet ( ) } 
func ( p * KeyValueClient ) Set ( key string , value string ) ( err error ) { if err = p . sendSet ( key , value ) ; err != nil { return } return p . recvSet ( ) } 
func New ( seed int64 ) * rand . Rand { return rand . New ( & lockedSource { src : rand . NewSource ( seed ) } ) } 
func ( h * metaHandler ) Health ( ctx Context , req * meta . HealthRequest ) ( * meta . HealthStatus , error ) { ok , message := h . healthFn ( ctx , metaReqToReq ( req ) ) if message == " " { return & meta . HealthStatus { Ok : ok } , nil } return & meta . HealthStatus { Ok : ok , Message : & message } , nil } 
func ( p * MetaClient ) Health ( hr * HealthRequest ) ( r * HealthStatus , err error ) { if err = p . sendHealth ( hr ) ; err != nil { return } return p . recvHealth ( ) } 
func ( c headerCtx ) Headers ( ) map [ string ] string { if h := c . headers ( ) ; h != nil { return h . reqHeaders } return nil } 
func ( c headerCtx ) ResponseHeaders ( ) map [ string ] string { if h := c . headers ( ) ; h != nil { return h . respHeaders } return nil } 
func ( c headerCtx ) SetResponseHeaders ( headers map [ string ] string ) { if h := c . headers ( ) ; h != nil { h . respHeaders = headers return } panic ( " " ) } 
func ( c headerCtx ) Child ( ) ContextWithHeaders { var headersCopy headersContainer if h := c . headers ( ) ; h != nil { headersCopy = * h } return Wrap ( context . WithValue ( c . Context , contextKeyHeaders , & headersCopy ) ) } 
func Wrap ( ctx context . Context ) ContextWithHeaders { hctx := headerCtx { Context : ctx } if h := hctx . headers ( ) ; h != nil { return hctx } } 
func WrapWithHeaders ( ctx context . Context , headers map [ string ] string ) ContextWithHeaders { h := & headersContainer { reqHeaders : headers , } newCtx := context . WithValue ( ctx , contextKeyHeaders , h ) return headerCtx { Context : newCtx } } 
func WithoutHeaders ( ctx context . Context ) context . Context { return context . WithValue ( context . WithValue ( ctx , contextKeyTChannel , nil ) , contextKeyHeaders , nil ) } 
func ( e * errNotifier ) Notify ( err error ) error { } } e . err = err close ( e . c ) return nil } 
func ( mex * messageExchange ) checkError ( ) error { if err := mex . ctx . Err ( ) ; err != nil { return GetContextError ( err ) } return mex . errCh . checkErr ( ) } 
func ( mex * messageExchange ) forwardPeerFrame ( frame * Frame ) error { } select { case mex . recvCh <- frame : return nil case <- mex . ctx . Done ( ) : case <- mex . errCh . c : default : } return mex . errCh . err } } 
func ( mex * messageExchange ) recvPeerFrame ( ) ( * Frame , error ) { } select { case frame := <- mex . recvCh : if err := mex . checkFrame ( frame ) ; err != nil { return nil , err } return frame , nil case <- mex . ctx . Done ( ) : return nil , GetContextError ( mex . ctx . Err ( ) ) case <- mex . errCh . c : } return frame , nil default : } return nil , mex . errCh . err } } 
func ( mex * messageExchange ) recvPeerFrameOfType ( msgType messageType ) ( * Frame , error ) { frame , err := mex . recvPeerFrame ( ) if err != nil { return nil , err } switch frame . Header . messageType { case msgType : return frame , nil case messageTypeError : errMsg := errorMessage { id : frame . Header . ID , } var rbuf typed . ReadBuffer rbuf . Wrap ( frame . SizedPayload ( ) ) if err := errMsg . read ( & rbuf ) ; err != nil { return nil , err } return nil , errMsg default : return nil , errUnexpectedFrameType } } 
func ( mex * messageExchange ) shutdown ( ) { } if mex . errChNotified . CAS ( false , true ) { mex . errCh . Notify ( errMexShutdown ) } mex . mexset . removeExchange ( mex . msgID ) } 
func newMessageExchangeSet ( log Logger , name string ) * messageExchangeSet { return & messageExchangeSet { name : name , log : log . WithFields ( LogField { " " , name } ) , exchanges : make ( map [ uint32 ] * messageExchange ) , expiredExchanges : make ( map [ uint32 ] struct { } ) , } } 
func ( mexset * messageExchangeSet ) addExchange ( mex * messageExchange ) error { if mexset . shutdown { return errMexSetShutdown } if _ , ok := mexset . exchanges [ mex . msgID ] ; ok { return errDuplicateMex } mexset . exchanges [ mex . msgID ] = mex return nil } 
func ( mexset * messageExchangeSet ) newExchange ( ctx context . Context , framePool FramePool , msgType messageType , msgID uint32 , bufferSize int ) ( * messageExchange , error ) { if mexset . log . Enabled ( LogLevelDebug ) { mexset . log . Debugf ( " " , mexset . name , msgType , msgID ) } mex := & messageExchange { msgType : msgType , msgID : msgID , ctx : ctx , recvCh : make ( chan * Frame , bufferSize ) , errCh : newErrNotifier ( ) , mexset : mexset , framePool : framePool , } mexset . Lock ( ) addErr := mexset . addExchange ( mex ) mexset . Unlock ( ) if addErr != nil { logger := mexset . log . WithFields ( LogField { " " , mex . msgID } , LogField { " " , mex . msgType } , LogField { " " , mexset . name } , ) if addErr == errMexSetShutdown { logger . Warn ( " " ) } else if addErr == errDuplicateMex { logger . Warn ( " " ) } return nil , addErr } mexset . onAdded ( ) } 
func ( mexset * messageExchangeSet ) deleteExchange ( msgID uint32 ) ( found , timedOut bool ) { if _ , found := mexset . exchanges [ msgID ] ; found { delete ( mexset . exchanges , msgID ) return true , false } if _ , expired := mexset . expiredExchanges [ msgID ] ; expired { delete ( mexset . expiredExchanges , msgID ) return false , true } return false , false } 
func ( mexset * messageExchangeSet ) removeExchange ( msgID uint32 ) { if mexset . log . Enabled ( LogLevelDebug ) { mexset . log . Debugf ( " " , mexset . name , msgID ) } mexset . Lock ( ) found , expired := mexset . deleteExchange ( msgID ) mexset . Unlock ( ) if ! found && ! expired { mexset . log . WithFields ( LogField { " " , msgID } , ) . Error ( " " ) return } } 
func ( mexset * messageExchangeSet ) expireExchange ( msgID uint32 ) { mexset . log . Debugf ( " " , mexset . name , msgID , ) mexset . Lock ( ) if found || expired { } mexset . Unlock ( ) if expired { mexset . log . WithFields ( LogField { " " , msgID } ) . Info ( " " ) } mexset . onRemoved ( ) } 
func ( mexset * messageExchangeSet ) forwardPeerFrame ( frame * Frame ) error { if mexset . log . Enabled ( LogLevelDebug ) { mexset . log . Debugf ( " " , mexset . name , frame . Header ) } mexset . RLock ( ) mex := mexset . exchanges [ frame . Header . ID ] mexset . RUnlock ( ) if mex == nil { return nil } if err := mex . forwardPeerFrame ( frame ) ; err != nil { mexset . log . WithFields ( LogField { " " , frame . Header . String ( ) } , LogField { " " , frame . Header . FrameSize ( ) } , LogField { " " , mexset . name } , ErrField ( err ) , ) . Info ( " " ) return err } return nil } 
func ( mexset * messageExchangeSet ) copyExchanges ( ) ( shutdown bool , exchanges map [ uint32 ] * messageExchange ) { if mexset . shutdown { return true , nil } exchangesCopy := make ( map [ uint32 ] * messageExchange , len ( mexset . exchanges ) ) for k , mex := range mexset . exchanges { exchangesCopy [ k ] = mex } return false , exchangesCopy } 
func ( mexset * messageExchangeSet ) stopExchanges ( err error ) { if mexset . log . Enabled ( LogLevelDebug ) { mexset . log . Debugf ( " " , mexset . count ( ) , err ) } mexset . Lock ( ) shutdown , exchanges := mexset . copyExchanges ( ) mexset . shutdown = true mexset . Unlock ( ) if shutdown { mexset . log . Debugf ( " " ) return } for _ , mex := range exchanges { } } } 
func ( fh FrameHeader ) MarshalJSON ( ) ( [ ] byte , error ) { s := struct { ID uint32 `json:"id"` MsgType messageType `json:"msgType"` Size uint16 `json:"size"` } { fh . ID , fh . messageType , fh . size } return json . Marshal ( s ) } 
func NewFrame ( payloadCapacity int ) * Frame { f := & Frame { } f . buffer = make ( [ ] byte , payloadCapacity + FrameHeaderSize ) f . Payload = f . buffer [ FrameHeaderSize : ] f . headerBuffer = f . buffer [ : FrameHeaderSize ] return f } 
func ( f * Frame ) ReadBody ( header [ ] byte , r io . Reader ) error { } switch payloadSize := f . Header . PayloadSize ( ) ; { case payloadSize > MaxFramePayloadSize : return fmt . Errorf ( " " , f . Header . size ) case payloadSize > 0 : _ , err := io . ReadFull ( r , f . SizedPayload ( ) ) return err default : } } 
func ( f * Frame ) ReadIn ( r io . Reader ) error { header := make ( [ ] byte , FrameHeaderSize ) if _ , err := io . ReadFull ( r , header ) ; err != nil { return err } return f . ReadBody ( header , r ) } 
func ( f * Frame ) WriteOut ( w io . Writer ) error { var wbuf typed . WriteBuffer wbuf . Wrap ( f . headerBuffer ) if err := f . Header . write ( & wbuf ) ; err != nil { return err } fullFrame := f . buffer [ : f . Header . FrameSize ( ) ] if _ , err := w . Write ( fullFrame ) ; err != nil { return err } return nil } 
func ( r RetryOn ) CanRetry ( err error ) bool { if r == RetryNever { return false } if r == RetryDefault { r = RetryConnectionError } code := getErrCode ( err ) if code == ErrCodeBusy || code == ErrCodeDeclined { return true } } switch r { case RetryConnectionError : return code == ErrCodeNetwork case RetryUnexpected : return code == ErrCodeUnexpected case RetryIdempotent : return true } return false } 
func ( rs * RequestState ) HasRetries ( err error ) bool { if rs == nil { return false } rOpts := rs . retryOpts return rs . Attempt < rOpts . MaxAttempts && rOpts . RetryOn . CanRetry ( err ) } 
func ( rs * RequestState ) SinceStart ( now time . Time , fallback time . Duration ) time . Duration { if rs == nil { return fallback } return now . Sub ( rs . Start ) } 
func ( rs * RequestState ) AddSelectedPeer ( hostPort string ) { if rs == nil { return } host := getHost ( hostPort ) if rs . SelectedPeers == nil { rs . SelectedPeers = map [ string ] struct { } { hostPort : { } , host : { } , } } else { rs . SelectedPeers [ hostPort ] = struct { } { } rs . SelectedPeers [ host ] = struct { } { } } } 
func ( ch * Channel ) RunWithRetry ( runCtx context . Context , f RetriableFunc ) error { var err error opts := getRetryOptions ( runCtx ) rs := ch . getRequestState ( opts ) defer requestStatePool . Put ( rs ) for i := 0 ; i < opts . MaxAttempts ; i ++ { rs . Attempt ++ if opts . TimeoutPerAttempt == 0 { err = f ( runCtx , rs ) } else { attemptCtx , cancel := context . WithTimeout ( runCtx , opts . TimeoutPerAttempt ) err = f ( attemptCtx , rs ) cancel ( ) } if err == nil { return nil } if ! opts . RetryOn . CanRetry ( err ) { if ch . log . Enabled ( LogLevelInfo ) { ch . log . WithFields ( ErrField ( err ) ) . Info ( " " ) } return err } ch . log . WithFields ( ErrField ( err ) , LogField { " " , rs . Attempt } , LogField { " " , opts . MaxAttempts } , ) . Info ( " " ) } } 
func getHost ( hostPort string ) string { for i := 0 ; i < len ( hostPort ) ; i ++ { if hostPort [ i ] == ':' { return hostPort [ : i ] } } return hostPort } 
func ( t ChecksumType ) ChecksumSize ( ) int { switch t { case ChecksumTypeNone : return 0 case ChecksumTypeCrc32 , ChecksumTypeCrc32C : return crc32 . Size case ChecksumTypeFarmhash : return 4 default : return 0 } } 
func ( t ChecksumType ) New ( ) Checksum { s := t . pool ( ) . Get ( ) . ( Checksum ) s . Reset ( ) return s } 
func parseTemplates ( skipTChannel bool , templateFiles [ ] string ) ( [ ] * Template , error ) { var templates [ ] * Template if ! skipTChannel { templates = append ( templates , & Template { name : " " , template : template . Must ( parseTemplate ( tchannelTmpl ) ) , } ) } for _ , f := range templateFiles { t , err := parseTemplateFile ( f ) if err != nil { return nil , err } templates = append ( templates , t ) } return templates , nil } 
func NewStringSliceFlag ( name string , usage string ) * [ ] string { var ss stringSliceFlag flag . Var ( & ss , name , usage ) return ( * [ ] string ) ( & ss ) } 
func ( t * Template ) withStateFuncs ( td TemplateData ) * template . Template { return t . template . Funcs ( map [ string ] interface { } { " " : td . global . goType , } ) } 
func ( ch * Channel ) IntrospectState ( opts * IntrospectionOptions ) * RuntimeState { if opts == nil { opts = & IntrospectionOptions { } } ch . mutable . RLock ( ) state := ch . mutable . state numConns := len ( ch . mutable . conns ) inactiveConns := make ( [ ] * Connection , 0 , numConns ) connIDs := make ( [ ] uint32 , 0 , numConns ) for id , conn := range ch . mutable . conns { connIDs = append ( connIDs , id ) if ! conn . IsActive ( ) { inactiveConns = append ( inactiveConns , conn ) } } ch . mutable . RUnlock ( ) ch . State ( ) return & RuntimeState { ID : ch . chID , ChannelState : state . String ( ) , CreatedStack : ch . createdStack , LocalPeer : ch . PeerInfo ( ) , SubChannels : ch . subChannels . IntrospectState ( opts ) , RootPeers : ch . RootPeers ( ) . IntrospectState ( opts ) , Peers : ch . Peers ( ) . IntrospectList ( opts ) , NumConnections : numConns , Connections : connIDs , InactiveConnections : getConnectionRuntimeState ( inactiveConns , opts ) , OtherChannels : ch . IntrospectOthers ( opts ) , RuntimeVersion : introspectRuntimeVersion ( ) , } } 
func ( ch * Channel ) IntrospectOthers ( opts * IntrospectionOptions ) map [ string ] [ ] ChannelInfo { if ! opts . IncludeOtherChannels { return nil } channelMap . Lock ( ) defer channelMap . Unlock ( ) states := make ( map [ string ] [ ] ChannelInfo ) for svc , channels := range channelMap . existing { channelInfos := make ( [ ] ChannelInfo , 0 , len ( channels ) ) for _ , otherChan := range channels { if ch == otherChan { continue } channelInfos = append ( channelInfos , otherChan . ReportInfo ( opts ) ) } states [ svc ] = channelInfos } return states } 
func ( ch * Channel ) ReportInfo ( opts * IntrospectionOptions ) ChannelInfo { return ChannelInfo { ID : ch . chID , CreatedStack : ch . createdStack , LocalPeer : ch . PeerInfo ( ) , } } 
func ( l * RootPeerList ) IntrospectState ( opts * IntrospectionOptions ) map [ string ] PeerRuntimeState { return fromPeerList ( l , opts ) } 
func ( subChMap * subChannelMap ) IntrospectState ( opts * IntrospectionOptions ) map [ string ] SubChannelRuntimeState { m := make ( map [ string ] SubChannelRuntimeState ) subChMap . RLock ( ) for k , sc := range subChMap . subchannels { state := SubChannelRuntimeState { Service : k , Isolated : sc . Isolated ( ) , } if state . Isolated { state . IsolatedPeers = sc . Peers ( ) . IntrospectList ( opts ) } if hmap , ok := sc . handler . ( * handlerMap ) ; ok { state . Handler . Type = methodHandler methods := make ( [ ] string , 0 , len ( hmap . handlers ) ) for k := range hmap . handlers { methods = append ( methods , k ) } sort . Strings ( methods ) state . Handler . Methods = methods } else { state . Handler . Type = overrideHandler } m [ k ] = state } subChMap . RUnlock ( ) return m } 
func ( p * Peer ) IntrospectState ( opts * IntrospectionOptions ) PeerRuntimeState { p . RLock ( ) defer p . RUnlock ( ) return PeerRuntimeState { HostPort : p . hostPort , InboundConnections : getConnectionRuntimeState ( p . inboundConnections , opts ) , OutboundConnections : getConnectionRuntimeState ( p . outboundConnections , opts ) , ChosenCount : p . chosenCount . Load ( ) , SCCount : p . scCount , } } 
func ( c * Connection ) IntrospectState ( opts * IntrospectionOptions ) ConnectionRuntimeState { c . stateMut . RLock ( ) defer c . stateMut . RUnlock ( ) if c . relay != nil { state . Relayer = c . relay . IntrospectState ( opts ) } return state } 
func ( r * Relayer ) IntrospectState ( opts * IntrospectionOptions ) RelayerRuntimeState { count := r . inbound . Count ( ) + r . outbound . Count ( ) return RelayerRuntimeState { Count : count , InboundItems : r . inbound . IntrospectState ( opts , " " ) , OutboundItems : r . outbound . IntrospectState ( opts , " " ) , MaxTimeout : r . maxTimeout , } } 
func ( ri * relayItems ) IntrospectState ( opts * IntrospectionOptions , name string ) RelayItemSetState { ri . RLock ( ) defer ri . RUnlock ( ) setState := RelayItemSetState { Name : name , Count : ri . Count ( ) , } if opts . IncludeExchanges { setState . Items = make ( map [ string ] RelayItemState , len ( ri . items ) ) for k , v := range ri . items { if ! opts . IncludeTombstones && v . tomb { continue } state := RelayItemState { ID : k , RemapID : v . remapID , DestinationConnectionID : v . destination . conn . connID , Tomb : v . tomb , } setState . Items [ strconv . Itoa ( int ( k ) ) ] = state } } return setState } 
func ( mexset * messageExchangeSet ) IntrospectState ( opts * IntrospectionOptions ) ExchangeSetRuntimeState { mexset . RLock ( ) setState := ExchangeSetRuntimeState { Name : mexset . name , Count : len ( mexset . exchanges ) , } if opts . IncludeExchanges { setState . Exchanges = make ( map [ string ] ExchangeRuntimeState , len ( mexset . exchanges ) ) for k , v := range mexset . exchanges { state := ExchangeRuntimeState { ID : k , MessageType : v . msgType , } setState . Exchanges [ strconv . Itoa ( int ( k ) ) ] = state } } mexset . RUnlock ( ) return setState } 
func ( l * PeerList ) IntrospectList ( opts * IntrospectionOptions ) [ ] SubPeerScore { var peers [ ] SubPeerScore l . RLock ( ) for _ , ps := range l . peerHeap . peerScores { peers = append ( peers , SubPeerScore { HostPort : ps . Peer . hostPort , Score : ps . score , } ) } l . RUnlock ( ) return peers } 
func ( ch * Channel ) IntrospectNumConnections ( ) int { ch . mutable . RLock ( ) numConns := len ( ch . mutable . conns ) ch . mutable . RUnlock ( ) return numConns } 
func ( ch * Channel ) registerInternal ( ) { endpoints := [ ] struct { name string handler func ( [ ] byte ) interface { } } { { " " , ch . handleIntrospection } , { " " , handleInternalRuntime } , } tchanSC := ch . GetSubChannel ( " " ) for _ , ep := range endpoints { handler := func ( ctx context . Context , call * InboundCall ) { var arg2 , arg3 [ ] byte if err := NewArgReader ( call . Arg2Reader ( ) ) . Read ( & arg2 ) ; err != nil { return } if err := NewArgReader ( call . Arg3Reader ( ) ) . Read ( & arg3 ) ; err != nil { return } if err := NewArgWriter ( call . Response ( ) . Arg2Writer ( ) ) . Write ( nil ) ; err != nil { return } NewArgWriter ( call . Response ( ) . Arg3Writer ( ) ) . WriteJSON ( ep . handler ( arg3 ) ) } ch . Register ( HandlerFunc ( handler ) , ep . name ) tchanSC . Register ( HandlerFunc ( handler ) , ep . name ) } } 
func NewContext ( timeout time . Duration ) ( Context , context . CancelFunc ) { ctx , cancel := tchannel . NewContext ( timeout ) return tchannel . WrapWithHeaders ( ctx , nil ) , cancel } 
func ReadArgs ( call * tchannel . InboundCall ) ( * Args , error ) { var args Args args . Caller = call . CallerName ( ) args . Format = call . Format ( ) args . Method = string ( call . Method ( ) ) if err := tchannel . NewArgReader ( call . Arg2Reader ( ) ) . Read ( & args . Arg2 ) ; err != nil { return nil , err } if err := tchannel . NewArgReader ( call . Arg3Reader ( ) ) . Read ( & args . Arg3 ) ; err != nil { return nil , err } return & args , nil } 
func WriteResponse ( response * tchannel . InboundCallResponse , resp * Res ) error { if resp . SystemErr != nil { return response . SendSystemError ( resp . SystemErr ) } if resp . IsErr { if err := response . SetApplicationError ( ) ; err != nil { return err } } if err := tchannel . NewArgWriter ( response . Arg2Writer ( ) ) . Write ( resp . Arg2 ) ; err != nil { return err } return tchannel . NewArgWriter ( response . Arg3Writer ( ) ) . Write ( resp . Arg3 ) } 
func Wrap ( handler Handler ) tchannel . Handler { return tchannel . HandlerFunc ( func ( ctx context . Context , call * tchannel . InboundCall ) { args , err := ReadArgs ( call ) if err != nil { handler . OnError ( ctx , err ) return } resp , err := handler . Handle ( ctx , args ) response := call . Response ( ) if err != nil { resp = & Res { SystemErr : err , } } if err := WriteResponse ( response , resp ) ; err != nil { handler . OnError ( ctx , err ) } } ) } 
func ( s * injectableSpan ) initFromOpenTracing ( span opentracing . Span ) error { return span . Tracer ( ) . Inject ( span . Context ( ) , zipkinSpanFormat , s ) } 
func CurrentSpan ( ctx context . Context ) * Span { if sp := opentracing . SpanFromContext ( ctx ) ; sp != nil { var injectable injectableSpan if err := injectable . initFromOpenTracing ( sp ) ; err == nil { span := Span ( injectable ) return & span } return & emptySpan } 
func ( c * Connection ) startOutboundSpan ( ctx context . Context , serviceName , methodName string , call * OutboundCall , startTime time . Time ) opentracing . Span { var parent opentracing . SpanContext if s := opentracing . SpanFromContext ( ctx ) ; s != nil { parent = s . Context ( ) } span := c . Tracer ( ) . StartSpan ( methodName , opentracing . ChildOf ( parent ) , opentracing . StartTime ( startTime ) , ) if isTracingDisabled ( ctx ) { ext . SamplingPriority . Set ( span , 0 ) } ext . SpanKindRPCClient . Set ( span ) ext . PeerService . Set ( span , serviceName ) c . setPeerHostPort ( span ) span . SetTag ( " " , call . callReq . Headers [ ArgScheme ] ) var injectable injectableSpan if err := injectable . initFromOpenTracing ( span ) ; err == nil { call . callReq . Tracing = Span ( injectable ) } else { call . callReq . Tracing . initRandom ( ) } return span } 
func InjectOutboundSpan ( response * OutboundCallResponse , headers map [ string ] string ) map [ string ] string { span := response . span if span == nil { return headers } newHeaders := make ( map [ string ] string ) carrier := tracingHeadersCarrier ( newHeaders ) if err := span . Tracer ( ) . Inject ( span . Context ( ) , opentracing . TextMap , carrier ) ; err != nil { } if len ( newHeaders ) == 0 { return headers } for k , v := range headers { } } return newHeaders } 
func ( c * Connection ) extractInboundSpan ( callReq * callReq ) opentracing . Span { spanCtx , err := c . Tracer ( ) . Extract ( zipkinSpanFormat , & callReq . Tracing ) if err != nil { if err != opentracing . ErrUnsupportedFormat && err != opentracing . ErrSpanContextNotFound { c . log . WithFields ( ErrField ( err ) ) . Error ( " " ) } return nil } if spanCtx == nil { return nil } operationName := " " span := c . Tracer ( ) . StartSpan ( operationName , ext . RPCServerOption ( spanCtx ) ) span . SetTag ( " " , callReq . Headers [ ArgScheme ] ) ext . PeerService . Set ( span , callReq . Headers [ CallerName ] ) c . setPeerHostPort ( span ) return span } 
func ExtractInboundSpan ( ctx context . Context , call * InboundCall , headers map [ string ] string , tracer opentracing . Tracer ) context . Context { var span = call . Response ( ) . span if span != nil { if headers != nil { if sc , err := tracer . Extract ( opentracing . TextMap , carrier ) ; err == nil { sc . ForeachBaggageItem ( func ( k , v string ) bool { span . SetBaggageItem ( k , v ) return true } ) } carrier . RemoveTracingKeys ( ) } } else { var parent opentracing . SpanContext if headers != nil { carrier := tracingHeadersCarrier ( headers ) if p , err := tracer . Extract ( opentracing . TextMap , carrier ) ; err == nil { parent = p } carrier . RemoveTracingKeys ( ) } span = tracer . StartSpan ( call . MethodString ( ) , ext . RPCServerOption ( parent ) ) ext . PeerService . Set ( span , call . CallerName ( ) ) span . SetTag ( " " , string ( call . Format ( ) ) ) call . conn . setPeerHostPort ( span ) call . Response ( ) . span = span } return opentracing . ContextWithSpan ( ctx , span ) } 
func TracerFromRegistrar ( registrar Registrar ) opentracing . Tracer { if tracerProvider , ok := registrar . ( tracerProvider ) ; ok { return tracerProvider . Tracer ( ) } return opentracing . GlobalTracer ( ) } 
func intToIP4 ( ip uint32 ) net . IP { return net . IP { byte ( ip >> 24 & 0xff ) , byte ( ip >> 16 & 0xff ) , byte ( ip >> 8 & 0xff ) , byte ( ip & 0xff ) , } } 
func servicePeerToHostPort ( peer * hyperbahn . ServicePeer ) string { host := intToIP4 ( uint32 ( * peer . IP . Ipv4 ) ) . String ( ) port := strconv . Itoa ( int ( peer . Port ) ) return net . JoinHostPort ( host , port ) } 
func NewStatsdReporter ( addr , prefix string ) ( tchannel . StatsReporter , error ) { client , err := statsd . NewBufferedClient ( addr , prefix , time . Second , 0 ) if err != nil { return nil , err } return NewStatsdReporterClient ( client ) , nil } 
func ( r * ToS ) UnmarshalText ( data [ ] byte ) error { if v , ok := _tosNameToValue [ string ( data ) ] ; ok { * r = v return nil } return fmt . Errorf ( " " , string ( data ) ) } 
func ( ph * peerHeap ) Push ( x interface { } ) { n := len ( ph . peerScores ) item := x . ( * peerScore ) item . index = n ph . peerScores = append ( ph . peerScores , item ) } 
func ( ph * peerHeap ) Pop ( ) interface { } { old := * ph n := len ( old . peerScores ) item := old . peerScores [ n - 1 ] item . index = - 1 ph . peerScores = old . peerScores [ : n - 1 ] return item } 
func ( ph * peerHeap ) updatePeer ( peerScore * peerScore ) { heap . Fix ( ph , peerScore . index ) } 
func ( ph * peerHeap ) removePeer ( peerScore * peerScore ) { heap . Remove ( ph , peerScore . index ) } 
func ( ph * peerHeap ) pushPeer ( peerScore * peerScore ) { ph . order ++ newOrder := ph . order peerScore . order = newOrder + uint64 ( ph . rng . Intn ( randRange ) ) heap . Push ( ph , peerScore ) } 
func ( ph * peerHeap ) addPeer ( peerScore * peerScore ) { ph . pushPeer ( peerScore ) ph . swapOrder ( peerScore . index , r ) } 
func NewClient ( ch * tchannel . Channel , serviceName string , opts * ClientOptions ) TChanClient { client := & client { ch : ch , sc : ch . GetSubChannel ( serviceName ) , serviceName : serviceName , } if opts != nil { client . opts = * opts } return client } 
func readResponse ( response * tchannel . OutboundCallResponse , resp thrift . TStruct ) ( map [ string ] string , bool , error ) { reader , err := response . Arg2Reader ( ) if err != nil { return nil , false , err } headers , err := ReadHeaders ( reader ) if err != nil { return nil , false , err } if err := argreader . EnsureEmpty ( reader , " " ) ; err != nil { return nil , false , err } if err := reader . Close ( ) ; err != nil { return nil , false , err } success := ! response . ApplicationError ( ) reader , err = response . Arg3Reader ( ) if err != nil { return headers , success , err } if err := ReadStruct ( reader , resp ) ; err != nil { return headers , success , err } if err := argreader . EnsureEmpty ( reader , " " ) ; err != nil { return nil , false , err } return headers , success , reader . Close ( ) } 
func ( l * RootPeerList ) Add ( hostPort string ) * Peer { l . RLock ( ) if p , ok := l . peersByHostPort [ hostPort ] ; ok { l . RUnlock ( ) return p } l . RUnlock ( ) l . Lock ( ) defer l . Unlock ( ) if p , ok := l . peersByHostPort [ hostPort ] ; ok { return p } var p * Peer l . peersByHostPort [ hostPort ] = p return p } 
func ( l * RootPeerList ) GetOrAdd ( hostPort string ) * Peer { peer , ok := l . Get ( hostPort ) if ok { return peer } return l . Add ( hostPort ) } 
func ( l * RootPeerList ) Get ( hostPort string ) ( * Peer , bool ) { l . RLock ( ) p , ok := l . peersByHostPort [ hostPort ] l . RUnlock ( ) return p , ok } 
func fnv32a ( s string ) uint32 { const ( initial = 2166136261 prime = 16777619 ) hash := uint32 ( initial ) for i := 0 ; i < len ( s ) ; i ++ { hash ^= uint32 ( s [ i ] ) hash *= prime } return hash } 
func WithTimeout ( timeout time . Duration ) Option { return func ( opts * options ) { opts . timeout = timeout } } 
func ( s * Service ) ExtendsServicePrefix ( ) string { if dotIndex := strings . Index ( s . Extends , " " ) ; dotIndex > 0 { return s . ExtendsPrefix } return " " } 
func ( s * Service ) Methods ( ) [ ] * Method { if s . methods != nil { return s . methods } for _ , m := range s . Service . Methods { s . methods = append ( s . methods , & Method { m , s , s . state } ) } sort . Sort ( byMethodName ( s . methods ) ) return s . methods } 
func ( s * Service ) InheritedMethods ( ) [ ] string { if s . inheritedMethods != nil { return s . inheritedMethods } for svc := s . ExtendsService ; svc != nil ; svc = svc . ExtendsService { for m := range svc . Service . Methods { s . inheritedMethods = append ( s . inheritedMethods , m ) } } sort . Strings ( s . inheritedMethods ) return s . inheritedMethods } 
func ( m * Method ) Arguments ( ) [ ] * Field { var args [ ] * Field for _ , f := range m . Method . Arguments { args = append ( args , & Field { f , m . state } ) } return args } 
func ( m * Method ) ArgList ( ) string { args := [ ] string { " " + contextType ( ) } for _ , arg := range m . Arguments ( ) { args = append ( args , arg . Declaration ( ) ) } return strings . Join ( args , " " ) } 
func ( m * Method ) CallList ( reqStruct string ) string { args := [ ] string { " " } for _ , arg := range m . Arguments ( ) { args = append ( args , reqStruct + " " + arg . ArgStructName ( ) ) } return strings . Join ( args , " " ) } 
func ( m * Method ) RetType ( ) string { if ! m . HasReturn ( ) { return " " } return fmt . Sprintf ( " " , m . state . goType ( m . Method . ReturnType ) , " " ) } 
func ( m * Method ) WrapResult ( respVar string ) string { if ! m . HasReturn ( ) { panic ( " " ) } if m . state . isResultPointer ( m . ReturnType ) { return respVar } return " " + respVar } 
func ( m * Method ) ReturnWith ( respName string , errName string ) string { if ! m . HasReturn ( ) { return errName } return fmt . Sprintf ( " " , respName , errName ) } 
func ( a * Field ) Declaration ( ) string { return fmt . Sprintf ( " " , a . Name ( ) , a . ArgType ( ) ) } 
func camelCase ( name string , publicName bool ) string { parts := strings . Split ( name , " " ) startAt := 1 if publicName { startAt = 0 } for i := startAt ; i < len ( parts ) ; i ++ { name := parts [ i ] if name == " " { continue } } else { name = strings . ToUpper ( name [ 0 : 1 ] ) + name [ 1 : ] } if isInitialism := commonInitialisms [ strings . ToUpper ( name ) ] ; isInitialism { name = strings . ToUpper ( name ) } parts [ i ] = name } return strings . Join ( parts , " " ) } 
func startIdleSweep ( ch * Channel , opts * ChannelOptions ) * idleSweep { is := & idleSweep { ch : ch , maxIdleTime : opts . MaxIdleTime , idleCheckInterval : opts . IdleCheckInterval , } is . start ( ) return is } 
func ( is * idleSweep ) start ( ) { if is . started || is . idleCheckInterval <= 0 { return } is . ch . log . WithFields ( LogField { " " , is . idleCheckInterval } , LogField { " " , is . maxIdleTime } , ) . Info ( " " ) is . started = true is . stopCh = make ( chan struct { } ) go is . pollerLoop ( ) } 
func ( is * idleSweep ) Stop ( ) { if ! is . started { return } is . started = false is . ch . log . Info ( " " ) close ( is . stopCh ) } 
func ResolveWithGoPath ( filename string ) ( string , error ) { for _ , file := range goPathCandidates ( filename ) { if _ , err := os . Stat ( file ) ; ! os . IsNotExist ( err ) { return file , nil } } return " " , fmt . Errorf ( " " , filename ) } 
func setExtends ( state map [ string ] parseState ) error { for _ , v := range state { for _ , s := range v . services { if s . Extends == " " { continue } var searchServices [ ] * Service var searchFor string parts := strings . SplitN ( s . Extends , " " , 2 ) searchFor = s . Extends } else { include := v . global . includes [ parts [ 0 ] ] s . ExtendsPrefix = include . pkg + " " searchServices = state [ include . file ] . services searchFor = parts [ 1 ] } foundService := sort . Search ( len ( searchServices ) , func ( i int ) bool { return searchServices [ i ] . Name >= searchFor } ) if foundService == len ( searchServices ) { return fmt . Errorf ( " " , s . Extends , s . Name ) } s . ExtendsService = searchServices [ foundService ] } } return nil } 
func ( f ErrorHandlerFunc ) Handle ( ctx context . Context , call * InboundCall ) { if err := f ( ctx , call ) ; err != nil { if GetSystemErrorCode ( err ) == ErrCodeUnexpected { call . log . WithFields ( f . getLogFields ( ) ... ) . WithFields ( ErrField ( err ) ) . Error ( " " ) } call . Response ( ) . SendSystemError ( err ) } } 
func ( hmap * handlerMap ) register ( h Handler , method string ) { hmap . Lock ( ) defer hmap . Unlock ( ) if hmap . handlers == nil { hmap . handlers = make ( map [ string ] Handler ) } hmap . handlers [ method ] = h } 
func ( hmap * handlerMap ) find ( method [ ] byte ) Handler { hmap . RLock ( ) handler := hmap . handlers [ string ( method ) ] hmap . RUnlock ( ) return handler } 
func ( c tracingHeadersCarrier ) Set ( key , val string ) { prefixedKey := tracingKeyEncoding . mapAndCache ( key ) c [ prefixedKey ] = val } 
func ( c tracingHeadersCarrier ) ForeachKey ( handler func ( key , val string ) error ) error { for k , v := range c { if ! strings . HasPrefix ( k , tracingKeyPrefix ) { continue } noPrefixKey := tracingKeyDecoding . mapAndCache ( k ) if err := handler ( noPrefixKey , v ) ; err != nil { return err } } return nil } 
func NewClient ( hosts [ ] string , optFns ... Option ) Client { opts := getOptions ( optFns ) if opts . external { return newExternalClient ( hosts , opts ) } if opts . numClients > 1 { return newInternalMultiClient ( hosts , opts ) } return newClient ( hosts , opts ) } 
func scoreAddr ( iface net . Interface , addr net . Addr ) ( int , net . IP ) { var ip net . IP if netAddr , ok := addr . ( * net . IPNet ) ; ok { ip = netAddr . IP } else if netIP , ok := addr . ( * net . IPAddr ) ; ok { ip = netIP . IP } else { return - 1 , nil } var score int if ip . To4 ( ) != nil { score += 300 } if iface . Flags & net . FlagLoopback == 0 && ! ip . IsLoopback ( ) { score += 100 if iface . Flags & net . FlagUp != 0 { score += 100 } } if isLocalMacAddr ( iface . HardwareAddr ) { score -= 50 } return score , ip } 
func ListenIP ( ) ( net . IP , error ) { interfaces , err := net . Interfaces ( ) if err != nil { return nil , err } return listenIP ( interfaces ) } 
func ( p * FirstClient ) Echo ( msg string ) ( r string , err error ) { if err = p . sendEcho ( msg ) ; err != nil { return } return p . recvEcho ( ) } 
func Wrap ( l net . Listener ) net . Listener { return & listener { Listener : l , cond : sync . NewCond ( & sync . Mutex { } ) } } 
func ( s * listener ) Accept ( ) ( net . Conn , error ) { s . incRef ( ) defer s . decRef ( ) return s . Listener . Accept ( ) } 
func ( s * listener ) Close ( ) error { if err := s . Listener . Close ( ) ; err != nil { return err } s . cond . L . Lock ( ) for s . refs > 0 { s . cond . Wait ( ) } s . cond . L . Unlock ( ) return nil } 
func ReadArgsV2 ( r tchannel . ArgReadable ) ( [ ] byte , [ ] byte , error ) { var arg2 , arg3 [ ] byte if err := tchannel . NewArgReader ( r . Arg2Reader ( ) ) . Read ( & arg2 ) ; err != nil { return nil , nil , err } if err := tchannel . NewArgReader ( r . Arg3Reader ( ) ) . Read ( & arg3 ) ; err != nil { return nil , nil , err } return arg2 , arg3 , nil } 
func WriteArgs ( call * tchannel . OutboundCall , arg2 , arg3 [ ] byte ) ( [ ] byte , [ ] byte , * tchannel . OutboundCallResponse , error ) { if err := tchannel . NewArgWriter ( call . Arg2Writer ( ) ) . Write ( arg2 ) ; err != nil { return nil , nil , nil , err } if err := tchannel . NewArgWriter ( call . Arg3Writer ( ) ) . Write ( arg3 ) ; err != nil { return nil , nil , nil , err } resp := call . Response ( ) var respArg2 [ ] byte if err := tchannel . NewArgReader ( resp . Arg2Reader ( ) ) . Read ( & respArg2 ) ; err != nil { return nil , nil , nil , err } var respArg3 [ ] byte if err := tchannel . NewArgReader ( resp . Arg3Reader ( ) ) . Read ( & respArg3 ) ; err != nil { return nil , nil , nil , err } return respArg2 , respArg3 , resp , nil } 
func Call ( ctx context . Context , ch * tchannel . Channel , hostPort string , serviceName , method string , arg2 , arg3 [ ] byte ) ( [ ] byte , [ ] byte , * tchannel . OutboundCallResponse , error ) { call , err := ch . BeginCall ( ctx , hostPort , serviceName , method , nil ) if err != nil { return nil , nil , nil , err } return WriteArgs ( call , arg2 , arg3 ) } 
func CallSC ( ctx context . Context , sc * tchannel . SubChannel , method string , arg2 , arg3 [ ] byte ) ( [ ] byte , [ ] byte , * tchannel . OutboundCallResponse , error ) { call , err := sc . BeginCall ( ctx , method , nil ) if err != nil { return nil , nil , nil , err } return WriteArgs ( call , arg2 , arg3 ) } 
func CallV2 ( ctx context . Context , sc * tchannel . SubChannel , cArgs CArgs ) ( * CRes , error ) { call , err := sc . BeginCall ( ctx , cArgs . Method , cArgs . CallOptions ) if err != nil { return nil , err } arg2 , arg3 , res , err := WriteArgs ( call , cArgs . Arg2 , cArgs . Arg3 ) if err != nil { return nil , err } return & CRes { Arg2 : arg2 , Arg3 : arg3 , AppError : res . ApplicationError ( ) , } , nil } 
func NewRealRelay ( services map [ string ] [ ] string ) ( Relay , error ) { hosts := & fixedHosts { hosts : services } ch , err := tchannel . NewChannel ( " " , & tchannel . ChannelOptions { RelayHost : relaytest . HostFunc ( hosts . Get ) , Logger : tchannel . NewLevelLogger ( tchannel . NewLogger ( os . Stderr ) , tchannel . LogLevelWarn ) , } ) if err != nil { return nil , err } if err := ch . ListenAndServe ( " " ) ; err != nil { return nil , err } return & realRelay { ch : ch , hosts : hosts , } , nil } 
func NewServer ( registrar tchannel . Registrar ) * Server { metaHandler := newMetaHandler ( ) server := & Server { ch : registrar , log : registrar . Logger ( ) , handlers : make ( map [ string ] handler ) , metaHandler : metaHandler , ctxFn : defaultContextFn , } server . Register ( newTChanMetaServer ( metaHandler ) ) if ch , ok := registrar . ( * tchannel . Channel ) ; ok { } return server } 
func ( s * Server ) Register ( svr TChanServer , opts ... RegisterOption ) { service := svr . Service ( ) handler := & handler { server : svr } for _ , opt := range opts { opt . Apply ( handler ) } s . Lock ( ) s . handlers [ service ] = * handler s . Unlock ( ) for _ , m := range svr . Methods ( ) { s . ch . Register ( s , service + " " + m ) } } 
func ( s * Server ) RegisterHealthHandler ( f HealthFunc ) { wrapped := func ( ctx Context , r HealthRequest ) ( bool , string ) { return f ( ctx ) } s . metaHandler . setHandler ( wrapped ) } 
func ( s * Server ) SetContextFn ( f func ( ctx context . Context , method string , headers map [ string ] string ) Context ) { s . ctxFn = f } 
func ( s * Server ) Handle ( ctx context . Context , call * tchannel . InboundCall ) { op := call . MethodString ( ) service , method , ok := getServiceMethod ( op ) if ! ok { log . Fatalf ( " " , op ) } s . RLock ( ) handler , ok := s . handlers [ service ] s . RUnlock ( ) if ! ok { log . Fatalf ( " " , service ) } if err := s . handle ( ctx , handler , method , call ) ; err != nil { s . onError ( call , err ) } } 
func ( c SystemErrCode ) MetricsKey ( ) string { switch c { case ErrCodeInvalid : case ErrCodeTimeout : return " " case ErrCodeCancelled : return " " case ErrCodeBusy : return " " case ErrCodeDeclined : return " " case ErrCodeUnexpected : return " " case ErrCodeBadRequest : return " " case ErrCodeNetwork : return " " case ErrCodeProtocol : return " " default : return c . String ( ) } } 
func NewSystemError ( code SystemErrCode , msg string , args ... interface { } ) error { return SystemError { code : code , msg : fmt . Sprintf ( msg , args ... ) } } 
func NewWrappedSystemError ( code SystemErrCode , wrapped error ) error { if se , ok := wrapped . ( SystemError ) ; ok { return se } return SystemError { code : code , msg : fmt . Sprint ( wrapped ) , wrapped : wrapped } } 
func ( se SystemError ) Error ( ) string { return fmt . Sprintf ( " " , se . Code ( ) , se . msg ) } 
func GetContextError ( err error ) error { if err == context . DeadlineExceeded { return ErrTimeout } if err == context . Canceled { return ErrRequestCancelled } return err } 
func GetSystemErrorCode ( err error ) SystemErrCode { if err == nil { return ErrCodeInvalid } if se , ok := err . ( SystemError ) ; ok { return se . Code ( ) } return ErrCodeUnexpected } 
func GetSystemErrorMessage ( err error ) string { if se , ok := err . ( SystemError ) ; ok { return se . Message ( ) } return err . Error ( ) } 
func getTimeout ( ctx context . Context ) time . Duration { deadline , ok := ctx . Deadline ( ) if ! ok { return DefaultConnectTimeout } return deadline . Sub ( time . Now ( ) ) } 
func ( c * Connection ) ping ( ctx context . Context ) error { req := & pingReq { id : c . NextMessageID ( ) } mex , err := c . outbound . newExchange ( ctx , c . opts . FramePool , req . messageType ( ) , req . ID ( ) , 1 ) if err != nil { return c . connectionError ( " " , err ) } defer c . outbound . removeExchange ( req . ID ( ) ) if err := c . sendMessage ( req ) ; err != nil { return c . connectionError ( " " , err ) } return c . recvMessage ( ctx , & pingRes { } , mex ) } 
func ( c * Connection ) handlePingRes ( frame * Frame ) bool { if err := c . outbound . forwardPeerFrame ( frame ) ; err != nil { c . log . WithFields ( LogField { " " , frame . Header } ) . Warn ( " " ) return true } } 
func ( c * Connection ) handlePingReq ( frame * Frame ) { if state := c . readState ( ) ; state != connectionActive { c . protocolError ( frame . Header . ID , errConnNotActive { " " , state } ) return } pingRes := & pingRes { id : frame . Header . ID } if err := c . sendMessage ( pingRes ) ; err != nil { c . connectionError ( " " , err ) } } 
func ( c * Connection ) sendMessage ( msg message ) error { frame := c . opts . FramePool . Get ( ) if err := frame . write ( msg ) ; err != nil { c . opts . FramePool . Release ( frame ) return err } select { case c . sendCh <- frame : return nil default : return ErrSendBufferFull } } 
func ( c * Connection ) recvMessage ( ctx context . Context , msg message , mex * messageExchange ) error { frame , err := mex . recvPeerFrameOfType ( msg . messageType ( ) ) if err != nil { if err , ok := err . ( errorMessage ) ; ok { return err . AsSystemError ( ) } return err } err = frame . read ( msg ) c . opts . FramePool . Release ( frame ) return err } 
func ( c * Connection ) SendSystemError ( id uint32 , span Span , err error ) error { frame := c . opts . FramePool . Get ( ) if err := frame . write ( & errorMessage { id : id , errCode : GetSystemErrorCode ( err ) , tracing : span , message : GetSystemErrorMessage ( err ) , } ) ; err != nil { return fmt . Errorf ( " " , err ) } return fmt . Errorf ( " " , c . state ) } select { case c . sendCh <- frame : default : c . log . WithFields ( LogField { " " , c . remotePeerInfo } , LogField { " " , id } , ErrField ( err ) , ) . Warn ( " " ) return fmt . Errorf ( " " ) } ) } 
func ( c * Connection ) connectionError ( site string , err error ) error { var closeLogFields LogFields if err == io . EOF { closeLogFields = LogFields { { " " , " " } } } else { closeLogFields = LogFields { { " " , " " } , ErrField ( err ) , } } c . stopHealthCheck ( ) err = c . logConnectionError ( site , err ) c . close ( closeLogFields ... ) c . inbound . stopExchanges ( err ) } return err } 
func ( c * Connection ) withStateLock ( f func ( ) error ) error { c . stateMut . Lock ( ) err := f ( ) c . stateMut . Unlock ( ) return err } 
func ( c * Connection ) withStateRLock ( f func ( ) error ) error { c . stateMut . RLock ( ) err := f ( ) c . stateMut . RUnlock ( ) return err } 
func ( c * Connection ) readFrames ( _ uint32 ) { headerBuf := make ( [ ] byte , FrameHeaderSize ) handleErr := func ( err error ) { if ! c . closeNetworkCalled . Load ( ) { c . connectionError ( " " , err ) } else { c . log . Debugf ( " " , err ) } } for { return } frame := c . opts . FramePool . Get ( ) if err := frame . ReadBody ( headerBuf , c . conn ) ; err != nil { handleErr ( err ) c . opts . FramePool . Release ( frame ) return } c . updateLastActivity ( frame ) var releaseFrame bool if c . relay == nil { releaseFrame = c . handleFrameNoRelay ( frame ) } else { releaseFrame = c . handleFrameRelay ( frame ) } if releaseFrame { c . opts . FramePool . Release ( frame ) } } } 
func ( c * Connection ) writeFrames ( _ uint32 ) { for { select { case f := <- c . sendCh : if c . log . Enabled ( LogLevelDebug ) { c . log . Debugf ( " " , f . Header ) } c . updateLastActivity ( f ) err := f . WriteOut ( c . conn ) c . opts . FramePool . Release ( f ) if err != nil { c . connectionError ( " " , err ) return } case <- c . stopCh : } return } } } 
func ( c * Connection ) updateLastActivity ( frame * Frame ) { } } 
func ( c * Connection ) hasPendingCalls ( ) bool { if c . inbound . count ( ) > 0 || c . outbound . count ( ) > 0 { return true } if ! c . relay . canClose ( ) { return true } return false } 
func ( c * Connection ) checkExchanges ( ) { c . callOnExchangeChange ( ) moveState := func ( fromState , toState connectionState ) bool { err := c . withStateLock ( func ( ) error { if c . state != fromState { return errors . New ( " " ) } c . state = toState return nil } ) return err == nil } curState := c . readState ( ) origState := curState if curState != connectionClosed && c . stoppedExchanges . Load ( ) { if moveState ( curState , connectionClosed ) { curState = connectionClosed } } if curState == connectionStartClose { if ! c . relay . canClose ( ) { return } if c . inbound . count ( ) == 0 && moveState ( connectionStartClose , connectionInboundClosed ) { curState = connectionInboundClosed } } if curState == connectionInboundClosed { return } if c . outbound . count ( ) == 0 && moveState ( connectionInboundClosed , connectionClosed ) { curState = connectionClosed } } if curState != origState { } c . log . WithFields ( LogField { " " , curState } , ) . Debug ( " " ) c . callOnCloseStateChange ( ) } } 
func ( c * Connection ) closeNetwork ( ) { c . stopHealthCheck ( ) c . closeNetworkCalled . Store ( true ) if err := c . conn . Close ( ) ; err != nil { c . log . WithFields ( LogField { " " , c . remotePeerInfo } , ErrField ( err ) , ) . Warn ( " " ) } } 
func ( c * Connection ) getLastActivityTime ( ) time . Time { return time . Unix ( 0 , c . lastActivity . Load ( ) ) } 
func Validate ( svc * parser . Service ) error { for _ , m := range svc . Methods { if err := validateMethod ( svc , m ) ; err != nil { return err } } return nil } 
func fuzzInterval ( interval time . Duration ) time . Duration { return time . Duration ( rand . Int63n ( int64 ( interval ) ) ) } 
func ( c * Client ) logFailedRegistrationRetry ( errLogger tchannel . Logger , consecutiveFailures uint ) { logFn := errLogger . Info if consecutiveFailures > maxAdvertiseFailures { logFn = errLogger . Warn } logFn ( " " ) } 
func ( c * Client ) advertiseLoop ( ) { sleepFor := c . fuzzedAdvertiseInterval ( ) consecutiveFailures := uint ( 0 ) for { c . sleep ( sleepFor ) if c . IsClosed ( ) { c . tchan . Logger ( ) . Infof ( " " ) return } if err := c . sendAdvertise ( ) ; err != nil { consecutiveFailures ++ errLogger := c . tchan . Logger ( ) . WithFields ( tchannel . ErrField ( err ) ) if consecutiveFailures >= maxAdvertiseFailures && c . opts . FailStrategy == FailStrategyFatal { c . opts . Handler . OnError ( ErrAdvertiseFailed { Cause : err , WillRetry : false } ) errLogger . Fatal ( " " ) } c . logFailedRegistrationRetry ( errLogger , consecutiveFailures ) c . opts . Handler . OnError ( ErrAdvertiseFailed { Cause : err , WillRetry : true } ) } } else { c . opts . Handler . On ( Readvertised ) sleepFor = c . fuzzedAdvertiseInterval ( ) consecutiveFailures = 0 } } } 
func ( c * Client ) initialAdvertise ( ) error { var err error for attempt := uint ( 0 ) ; attempt < maxAdvertiseFailures ; attempt ++ { err = c . sendAdvertise ( ) if err == nil || err == errEphemeralPeer { break } c . tchan . Logger ( ) . WithFields ( tchannel . ErrField ( err ) ) . Info ( " " ) c . sleep ( sleepFor ) } return err } 
func ( p * HyperbahnClient ) Discover ( query * DiscoveryQuery ) ( r * DiscoveryResult_ , err error ) { if err = p . sendDiscover ( query ) ; err != nil { return } return p . recvDiscover ( ) } 
func newLazyCallReq ( f * Frame ) lazyCallReq { if msgType := f . Header . messageType ; msgType != messageTypeCallReq { panic ( fmt . Errorf ( " " , msgType ) ) } cr := lazyCallReq { Frame : f } serviceLen := f . Payload [ _serviceLenIndex ] numHeaders := int ( f . Payload [ headerStart ] ) cur := int ( headerStart ) + 1 for i := 0 ; i < numHeaders ; i ++ { keyLen := int ( f . Payload [ cur ] ) cur ++ key := f . Payload [ cur : cur + keyLen ] cur += keyLen valLen := int ( f . Payload [ cur ] ) cur ++ val := f . Payload [ cur : cur + valLen ] cur += valLen if bytes . Equal ( key , _callerNameKeyBytes ) { cr . caller = val } else if bytes . Equal ( key , _routingDelegateKeyBytes ) { cr . delegate = val } else if bytes . Equal ( key , _routingKeyKeyBytes ) { cr . key = val } } cur += 1 + checkSumType . ChecksumSize ( ) cur += 2 cr . method = f . Payload [ cur : cur + arg1Len ] return cr } 
func ( f lazyCallReq ) Service ( ) [ ] byte { l := f . Payload [ _serviceLenIndex ] return f . Payload [ _serviceNameIndex : _serviceNameIndex + l ] } 
func ( f lazyCallReq ) TTL ( ) time . Duration { ttl := binary . BigEndian . Uint32 ( f . Payload [ _ttlIndex : _ttlIndex + _ttlLen ] ) return time . Duration ( ttl ) * time . Millisecond } 
func ( f lazyCallReq ) SetTTL ( d time . Duration ) { ttl := uint32 ( d / time . Millisecond ) binary . BigEndian . PutUint32 ( f . Payload [ _ttlIndex : _ttlIndex + _ttlLen ] , ttl ) } 
func finishesCall ( f * Frame ) bool { switch f . messageType ( ) { case messageTypeError : return true case messageTypeCallRes , messageTypeCallResContinue : flags := f . Payload [ _flagsIndex ] return flags & hasMoreFragmentsFlag == 0 default : return false } } 
func ( ps * PlatformStrings ) Flat ( ) [ ] string { unique := make ( map [ string ] struct { } ) for _ , s := range ps . Generic { unique [ s ] = struct { } { } } for _ , ss := range ps . OS { for _ , s := range ss { unique [ s ] = struct { } { } } } for _ , ss := range ps . Arch { for _ , s := range ss { unique [ s ] = struct { } { } } } for _ , ss := range ps . Platform { for _ , s := range ss { unique [ s ] = struct { } { } } } flat := make ( [ ] string , 0 , len ( unique ) ) for s := range unique { flat = append ( flat , s ) } sort . Strings ( flat ) return flat } 
func ( ps * PlatformStrings ) Map ( f func ( s string ) ( string , error ) ) ( PlatformStrings , [ ] error ) { var errors [ ] error mapSlice := func ( ss [ ] string ) ( [ ] string , error ) { rs := make ( [ ] string , 0 , len ( ss ) ) for _ , s := range ss { if r , err := f ( s ) ; err != nil { errors = append ( errors , err ) } else if r != " " { rs = append ( rs , r ) } } return rs , nil } result , _ := ps . MapSlice ( mapSlice ) return result , errors } 
func ( ps * PlatformStrings ) MapSlice ( f func ( [ ] string ) ( [ ] string , error ) ) ( PlatformStrings , [ ] error ) { var errors [ ] error mapSlice := func ( ss [ ] string ) [ ] string { rs , err := f ( ss ) if err != nil { errors = append ( errors , err ) return nil } return rs } mapStringMap := func ( m map [ string ] [ ] string ) map [ string ] [ ] string { if m == nil { return nil } rm := make ( map [ string ] [ ] string ) for k , ss := range m { ss = mapSlice ( ss ) if len ( ss ) > 0 { rm [ k ] = ss } } if len ( rm ) == 0 { return nil } return rm } mapPlatformMap := func ( m map [ Platform ] [ ] string ) map [ Platform ] [ ] string { if m == nil { return nil } rm := make ( map [ Platform ] [ ] string ) for k , ss := range m { ss = mapSlice ( ss ) if len ( ss ) > 0 { rm [ k ] = ss } } if len ( rm ) == 0 { return nil } return rm } result := PlatformStrings { Generic : mapSlice ( ps . Generic ) , OS : mapStringMap ( ps . OS ) , Arch : mapStringMap ( ps . Arch ) , Platform : mapPlatformMap ( ps . Platform ) , } return result , errors } 
func ExprFromValue ( val interface { } ) bzl . Expr { if e , ok := val . ( bzl . Expr ) ; ok { return e } rv := reflect . ValueOf ( val ) switch rv . Kind ( ) { case reflect . Bool : tok := " " if rv . Bool ( ) { tok = " " } return & bzl . LiteralExpr { Token : tok } case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 , reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 : return & bzl . LiteralExpr { Token : fmt . Sprintf ( " " , val ) } case reflect . Float32 , reflect . Float64 : return & bzl . LiteralExpr { Token : fmt . Sprintf ( " " , val ) } case reflect . String : return & bzl . StringExpr { Value : val . ( string ) } case reflect . Slice , reflect . Array : var list [ ] bzl . Expr for i := 0 ; i < rv . Len ( ) ; i ++ { elem := ExprFromValue ( rv . Index ( i ) . Interface ( ) ) list = append ( list , elem ) } return & bzl . ListExpr { List : list } case reflect . Map : rkeys := rv . MapKeys ( ) sort . Sort ( byString ( rkeys ) ) args := make ( [ ] bzl . Expr , len ( rkeys ) ) for i , rk := range rkeys { label := fmt . Sprintf ( " " , mapKeyString ( rk ) ) k := & bzl . StringExpr { Value : label } v := ExprFromValue ( rv . MapIndex ( rk ) . Interface ( ) ) if l , ok := v . ( * bzl . ListExpr ) ; ok { l . ForceMultiLine = true } args [ i ] = & bzl . KeyValueExpr { Key : k , Value : v } } args = append ( args , & bzl . KeyValueExpr { Key : & bzl . StringExpr { Value : " " } , Value : & bzl . ListExpr { } , } ) sel := & bzl . CallExpr { X : & bzl . Ident { Name : " " } , List : [ ] bzl . Expr { & bzl . DictExpr { List : args , ForceMultiLine : true } } , } return sel case reflect . Struct : switch val := val . ( type ) { case GlobValue : patternsValue := ExprFromValue ( val . Patterns ) globArgs := [ ] bzl . Expr { patternsValue } if len ( val . Excludes ) > 0 { excludesValue := ExprFromValue ( val . Excludes ) globArgs = append ( globArgs , & bzl . KeyValueExpr { Key : & bzl . StringExpr { Value : " " } , Value : excludesValue , } ) } return & bzl . CallExpr { X : & bzl . LiteralExpr { Token : " " } , List : globArgs , } case PlatformStrings : var pieces [ ] bzl . Expr if len ( val . Generic ) > 0 { pieces = append ( pieces , ExprFromValue ( val . Generic ) ) } if len ( val . OS ) > 0 { pieces = append ( pieces , ExprFromValue ( val . OS ) ) } if len ( val . Arch ) > 0 { pieces = append ( pieces , ExprFromValue ( val . Arch ) ) } if len ( val . Platform ) > 0 { pieces = append ( pieces , ExprFromValue ( val . Platform ) ) } if len ( pieces ) == 0 { return & bzl . ListExpr { } } else if len ( pieces ) == 1 { return pieces [ 0 ] } else { e := pieces [ 0 ] if list , ok := e . ( * bzl . ListExpr ) ; ok { list . ForceMultiLine = true } for _ , piece := range pieces [ 1 : ] { e = & bzl . BinaryExpr { X : e , Y : piece , Op : " " } } return e } } } log . Panicf ( " " , val ) return nil } 
func GetProtoConfig ( c * config . Config ) * ProtoConfig { pc := c . Exts [ protoName ] if pc == nil { return nil } return pc . ( * ProtoConfig ) } 
func inferProtoMode ( c * config . Config , rel string , f * rule . File ) { pc := GetProtoConfig ( c ) if pc . Mode != DefaultMode || pc . ModeExplicit { return } if pc . GoPrefix == wellKnownTypesGoPrefix { pc . Mode = LegacyMode return } if path . Base ( rel ) == " " { pc . Mode = DisableMode return } if f == nil { return } mode := DefaultMode outer : for _ , l := range f . Loads { name := l . Name ( ) if name == " " { break } if name == " " { mode = LegacyMode break } for _ , sym := range l . Symbols ( ) { if sym == " " { mode = DisableMode break outer } } } if mode == DefaultMode || pc . Mode == mode || c . ShouldFix && mode == LegacyMode { return } pc . Mode = mode } 
func MapExprStrings ( e bzl . Expr , f func ( string ) string ) bzl . Expr { if e == nil { return nil } switch expr := e . ( type ) { case * bzl . StringExpr : s := f ( expr . Value ) if s == " " { return nil } ret := * expr ret . Value = s return & ret case * bzl . ListExpr : var list [ ] bzl . Expr for _ , elem := range expr . List { elem = MapExprStrings ( elem , f ) if elem != nil { list = append ( list , elem ) } } if len ( list ) == 0 && len ( expr . List ) > 0 { return nil } ret := * expr ret . List = list return & ret case * bzl . DictExpr : var cases [ ] bzl . Expr isEmpty := true for _ , kv := range expr . List { keyval , ok := kv . ( * bzl . KeyValueExpr ) if ! ok { log . Panicf ( " " , kv ) } value := MapExprStrings ( keyval . Value , f ) if value != nil { cases = append ( cases , & bzl . KeyValueExpr { Key : keyval . Key , Value : value } ) if key , ok := keyval . Key . ( * bzl . StringExpr ) ; ! ok || key . Value != " " { isEmpty = false } } } if isEmpty { return nil } ret := * expr ret . List = cases return & ret case * bzl . CallExpr : if x , ok := expr . X . ( * bzl . Ident ) ; ! ok || x . Name != " " || len ( expr . List ) != 1 { log . Panicf ( " " , e ) } arg := MapExprStrings ( expr . List [ 0 ] , f ) if arg == nil { return nil } call := * expr call . List [ 0 ] = arg return & call case * bzl . BinaryExpr : x := MapExprStrings ( expr . X , f ) y := MapExprStrings ( expr . Y , f ) if x == nil { return y } if y == nil { return x } binop := * expr binop . X = x binop . Y = y return & binop default : return nil } } 
func FlattenExpr ( e bzl . Expr ) bzl . Expr { ps , err := extractPlatformStringsExprs ( e ) if err != nil { return e } ls := makeListSquasher ( ) addElem := func ( e bzl . Expr ) bool { s , ok := e . ( * bzl . StringExpr ) if ! ok { return false } ls . add ( s ) return true } addList := func ( e bzl . Expr ) bool { l , ok := e . ( * bzl . ListExpr ) if ! ok { return false } for _ , elem := range l . List { if ! addElem ( elem ) { return false } } return true } addDict := func ( d * bzl . DictExpr ) bool { for _ , kv := range d . List { if ! addList ( kv . ( * bzl . KeyValueExpr ) . Value ) { return false } } return true } if ps . generic != nil { if ! addList ( ps . generic ) { return e } } for _ , d := range [ ] * bzl . DictExpr { ps . os , ps . arch , ps . platform } { if d == nil { continue } if ! addDict ( d ) { return e } } return ls . list ( ) } 
func extractPlatformStringsExprs ( expr bzl . Expr ) ( platformStringsExprs , error ) { var ps platformStringsExprs if expr == nil { return ps , nil } for { binop , ok := expr . ( * bzl . BinaryExpr ) if ! ok { parts = append ( parts , expr ) break } parts = append ( parts , binop . Y ) expr = binop . X } } ps . generic = part case * bzl . CallExpr : x , ok := part . X . ( * bzl . Ident ) if ! ok || x . Name != " " || len ( part . List ) != 1 { return platformStringsExprs { } , fmt . Errorf ( " " ) } arg , ok := part . List [ 0 ] . ( * bzl . DictExpr ) if ! ok { return platformStringsExprs { } , fmt . Errorf ( " " ) } var dict * * bzl . DictExpr for _ , item := range arg . List { kv := item . ( * bzl . KeyValueExpr ) k , ok := kv . Key . ( * bzl . StringExpr ) if ! ok { return platformStringsExprs { } , fmt . Errorf ( " " ) } if k . Value == " " { continue } key , err := label . Parse ( k . Value ) if err != nil { return platformStringsExprs { } , fmt . Errorf ( " " , k . Value ) } if KnownOSSet [ key . Name ] { dict = & ps . os break } if KnownArchSet [ key . Name ] { dict = & ps . arch break } osArch := strings . Split ( key . Name , " " ) if len ( osArch ) != 2 || ! KnownOSSet [ osArch [ 0 ] ] || ! KnownArchSet [ osArch [ 1 ] ] { return platformStringsExprs { } , fmt . Errorf ( " " , k . Value ) } dict = & ps . platform break } if dict == nil { } if * dict != nil { return platformStringsExprs { } , fmt . Errorf ( " " ) } * dict = arg } } return ps , nil } 
func makePlatformStringsExpr ( ps platformStringsExprs ) bzl . Expr { makeSelect := func ( dict * bzl . DictExpr ) bzl . Expr { return & bzl . CallExpr { X : & bzl . Ident { Name : " " } , List : [ ] bzl . Expr { dict } , } } forceMultiline := func ( e bzl . Expr ) { switch e := e . ( type ) { case * bzl . ListExpr : e . ForceMultiLine = true case * bzl . CallExpr : e . List [ 0 ] . ( * bzl . DictExpr ) . ForceMultiLine = true } } var parts [ ] bzl . Expr if ps . generic != nil { parts = append ( parts , ps . generic ) } if ps . os != nil { parts = append ( parts , makeSelect ( ps . os ) ) } if ps . arch != nil { parts = append ( parts , makeSelect ( ps . arch ) ) } if ps . platform != nil { parts = append ( parts , makeSelect ( ps . platform ) ) } if len ( parts ) == 0 { return nil } if len ( parts ) == 1 { return parts [ 0 ] } expr := parts [ 0 ] forceMultiline ( expr ) for _ , part := range parts [ 1 : ] { forceMultiline ( part ) expr = & bzl . BinaryExpr { Op : " " , X : expr , Y : part , } } return expr } 
func ( p Platform ) String ( ) string { switch { case p . OS != " " && p . Arch != " " : return p . OS + " " + p . Arch case p . OS != " " : return p . OS case p . Arch != " " : return p . Arch default : return " " } } 
func Find ( dir string ) ( string , error ) { dir , err := filepath . Abs ( dir ) if err != nil { return " " , err } for { _ , err = os . Stat ( filepath . Join ( dir , workspaceFile ) ) if err == nil { return dir , nil } if ! os . IsNotExist ( err ) { return " " , err } if strings . HasSuffix ( dir , string ( os . PathSeparator ) ) { } dir = filepath . Dir ( dir ) } } 
func moveLocations ( from , to , str string ) string { matches := locationsRegexp . FindAllStringSubmatchIndex ( str , - 1 ) buf := new ( bytes . Buffer ) pos := 0 for _ , match := range matches { buf . WriteString ( str [ pos : match [ 2 ] ] ) label := str [ match [ 2 ] : match [ 3 ] ] moved := moveLabel ( from , to , label ) buf . WriteString ( moved ) buf . WriteString ( str [ match [ 3 ] : match [ 1 ] ] ) pos = match [ 1 ] } buf . WriteString ( str [ pos : ] ) return buf . String ( ) } 
func runGazelle ( mode mode , dirs [ ] string ) error { if mode == fastMode && len ( dirs ) == 0 { return nil } args := [ ] string { os . Getenv ( " " ) , " " , * gazelleLabel , " " , " " } args = append ( args , " " ) if mode == fastMode { args = append ( args , " " ) args = append ( args , dirs ... ) } cmd := exec . Command ( args [ 0 ] , args [ 1 : ] ... ) cmd . Stdout = os . Stdout cmd . Stderr = os . Stderr log . Printf ( " \n " , strings . Join ( cmd . Args , " " ) ) return cmd . Run ( ) } 
func restoreBuildFilesInRepo ( ) { err := filepath . Walk ( " " , func ( path string , info os . FileInfo , err error ) error { if err != nil { log . Print ( err ) return nil } restoreBuildFilesInDir ( path ) return nil } ) if err != nil { log . Print ( err ) } } 
func FixLoads ( f * rule . File , knownLoads [ ] rule . LoadInfo ) { knownFiles := make ( map [ string ] bool ) knownKinds := make ( map [ string ] string ) for _ , l := range knownLoads { knownFiles [ l . Name ] = true for _ , k := range l . Symbols { knownKinds [ k ] = l . Name } } otherLoadedKinds := make ( map [ string ] bool ) for _ , l := range f . Loads { if knownFiles [ l . Name ( ) ] { loads = append ( loads , l ) continue } for _ , sym := range l . Symbols ( ) { otherLoadedKinds [ sym ] = true } } for _ , r := range f . Rules { kind := r . Kind ( ) if file , ok := knownKinds [ kind ] ; ok && ! otherLoadedKinds [ kind ] { if usedKinds [ file ] == nil { usedKinds [ file ] = make ( map [ string ] bool ) } usedKinds [ file ] [ kind ] = true } } first := true for _ , l := range loads { if l . Name ( ) != file { continue } if first { fixLoad ( l , file , usedKinds [ file ] , knownKinds ) first = false } else { fixLoad ( l , file , nil , knownKinds ) } if l . IsEmpty ( ) { l . Delete ( ) } } if first { load := fixLoad ( nil , file , usedKinds [ file ] , knownKinds ) if load != nil { index := newLoadIndex ( f , known . After ) load . Insert ( f , index ) } } } } 
func fixLoad ( load * rule . Load , file string , kinds map [ string ] bool , knownKinds map [ string ] string ) * rule . Load { if load == nil { if len ( kinds ) == 0 { return nil } load = rule . NewLoad ( file ) } for k := range kinds { load . Add ( k ) } for _ , k := range load . Symbols ( ) { if knownKinds [ k ] != " " && ! kinds [ k ] { load . Remove ( k ) } } return load } 
func newLoadIndex ( f * rule . File , after [ ] string ) int { if len ( after ) == 0 { return 0 } index := 0 for _ , r := range f . Rules { for _ , a := range after { if r . Kind ( ) == a && r . Index ( ) >= index { index = r . Index ( ) + 1 } } } return index } 
func CheckGazelleLoaded ( f * rule . File ) error { needGazelle := false for _ , l := range f . Loads { if strings . HasPrefix ( l . Name ( ) , " " ) { needGazelle = true } } if ! needGazelle { return nil } for _ , r := range f . Rules { if r . Name ( ) == " " { return nil } } for _ , d := range f . Directives { if d . Key != " " { continue } if fs := strings . Fields ( d . Value ) ; len ( fs ) > 0 && fs [ 0 ] == " " { return nil } } return fmt . Errorf ( `%s: error: bazel_gazelle is not declared in WORKSPACE. Without this repository, Gazelle cannot safely modify the WORKSPACE file. See the instructions at https:If the bazel_gazelle is declared inside a macro, you can suppress this error by adding a comment like this to WORKSPACE: # gazelle:repo bazel_gazelle ` , f . Path ) } 
func removeLegacyGoRepository ( f * rule . File ) { for _ , l := range f . Loads { if l . Name ( ) == " " { l . Remove ( " " ) if l . IsEmpty ( ) { l . Delete ( ) } } } } 
func ( x Version ) Compare ( y Version ) int { n := len ( x ) if len ( y ) < n { n = len ( y ) } for i := 0 ; i < n ; i ++ { cmp := x [ i ] - y [ i ] if cmp != 0 { return cmp } } return len ( x ) - len ( y ) } 
func ParseVersion ( vs string ) ( Version , error ) { i := strings . IndexByte ( vs , '-' ) if i >= 0 { vs = vs [ : i ] } cstrs := strings . Split ( vs , " " ) v := make ( Version , len ( cstrs ) ) for i , cstr := range cstrs { cn , err := strconv . Atoi ( cstr ) if err != nil { return nil , fmt . Errorf ( " " , cstr ) } if cn < 0 { return nil , fmt . Errorf ( " " , cstr ) } v [ i ] = cn } return v , nil } 
func EmptyFile ( path , pkg string ) * File { return & File { File : & bzl . File { Path : path , Type : bzl . TypeBuild } , Path : path , Pkg : pkg , } } 
func LoadFile ( path , pkg string ) ( * File , error ) { data , err := ioutil . ReadFile ( path ) if err != nil { return nil , err } return LoadData ( path , pkg , data ) } 
func LoadWorkspaceFile ( path , pkg string ) ( * File , error ) { data , err := ioutil . ReadFile ( path ) if err != nil { return nil , err } return LoadWorkspaceData ( path , pkg , data ) } 
func LoadMacroFile ( path , pkg , defName string ) ( * File , error ) { data , err := ioutil . ReadFile ( path ) if err != nil { return nil , err } return LoadMacroData ( path , pkg , defName , data ) } 
func EmptyMacroFile ( path , pkg , defName string ) ( * File , error ) { _ , err := os . Create ( path ) if err != nil { return nil , err } return LoadMacroData ( path , pkg , defName , nil ) } 
func LoadData ( path , pkg string , data [ ] byte ) ( * File , error ) { ast , err := bzl . ParseBuild ( path , data ) if err != nil { return nil , err } return ScanAST ( pkg , ast ) , nil } 
func LoadWorkspaceData ( path , pkg string , data [ ] byte ) ( * File , error ) { ast , err := bzl . ParseWorkspace ( path , data ) if err != nil { return nil , err } return ScanAST ( pkg , ast ) , nil } 
func LoadMacroData ( path , pkg , defName string , data [ ] byte ) ( * File , error ) { ast , err := bzl . ParseBzl ( path , data ) if err != nil { return nil , err } return ScanASTBody ( pkg , defName , ast ) , nil } 
func ScanAST ( pkg string , bzlFile * bzl . File ) * File { return ScanASTBody ( pkg , " " , bzlFile ) } 
func ScanASTBody ( pkg , defName string , bzlFile * bzl . File ) * File { f := & File { File : bzlFile , Pkg : pkg , Path : bzlFile . Path , } var defStmt * bzl . DefStmt f . Rules , f . Loads , defStmt = scanExprs ( defName , bzlFile . Stmt ) if defStmt != nil { f . Rules , _ , _ = scanExprs ( " " , defStmt . Body ) f . function = & function { stmt : defStmt , inserted : true , } if len ( defStmt . Body ) == 1 { if v , ok := defStmt . Body [ 0 ] . ( * bzl . BranchStmt ) ; ok && v . Token == " " { f . function . hasPass = true } } } else if defName != " " { f . function = & function { stmt : & bzl . DefStmt { Name : defName } , inserted : false , } } f . Directives = ParseDirectives ( bzlFile ) return f } 
func MatchBuildFileName ( dir string , names [ ] string , files [ ] os . FileInfo ) string { for _ , name := range names { for _ , fi := range files { if fi . Name ( ) == name && ! fi . IsDir ( ) { return filepath . Join ( dir , name ) } } } return " " } 
func ( f * File ) SyncMacroFile ( from * File ) { fromFunc := * from . function . stmt _ , _ , toFunc := scanExprs ( from . function . stmt . Name , f . File . Stmt ) if toFunc != nil { * toFunc = fromFunc } else { f . File . Stmt = append ( f . File . Stmt , & fromFunc ) } } 
func ( f * File ) MacroName ( ) string { if f . function != nil && f . function . stmt != nil { return f . function . stmt . Name } return " " } 
func ( f * File ) Sync ( ) { var loadInserts , loadDeletes , loadStmts [ ] * stmt var r , w int for r , w = 0 , 0 ; r < len ( f . Loads ) ; r ++ { s := f . Loads [ r ] s . sync ( ) if s . deleted { loadDeletes = append ( loadDeletes , & s . stmt ) continue } if s . inserted { loadInserts = append ( loadInserts , & s . stmt ) s . inserted = false } else { loadStmts = append ( loadStmts , & s . stmt ) } f . Loads [ w ] = s w ++ } f . Loads = f . Loads [ : w ] var ruleInserts , ruleDeletes , ruleStmts [ ] * stmt for r , w = 0 , 0 ; r < len ( f . Rules ) ; r ++ { s := f . Rules [ r ] s . sync ( ) if s . deleted { ruleDeletes = append ( ruleDeletes , & s . stmt ) continue } if s . inserted { ruleInserts = append ( ruleInserts , & s . stmt ) s . inserted = false } else { ruleStmts = append ( ruleStmts , & s . stmt ) } f . Rules [ w ] = s w ++ } f . Rules = f . Rules [ : w ] if f . function == nil { deletes := append ( ruleDeletes , loadDeletes ... ) inserts := append ( ruleInserts , loadInserts ... ) stmts := append ( ruleStmts , loadStmts ... ) updateStmt ( & f . File . Stmt , inserts , deletes , stmts ) } else { updateStmt ( & f . File . Stmt , loadInserts , loadDeletes , loadStmts ) if f . function . hasPass && len ( ruleInserts ) > 0 { f . function . stmt . Body = [ ] bzl . Expr { } f . function . hasPass = false } updateStmt ( & f . function . stmt . Body , ruleInserts , ruleDeletes , ruleStmts ) if len ( f . function . stmt . Body ) == 0 { f . function . stmt . Body = append ( f . function . stmt . Body , & bzl . BranchStmt { Token : " " } ) f . function . hasPass = true } if ! f . function . inserted { f . File . Stmt = append ( f . File . Stmt , f . function . stmt ) f . function . inserted = true } } } 
func ( f * File ) Format ( ) [ ] byte { f . Sync ( ) return bzl . Format ( f . File ) } 
func ( f * File ) Save ( path string ) error { f . Sync ( ) data := bzl . Format ( f . File ) return ioutil . WriteFile ( path , data , 0666 ) } 
func ( f * File ) HasDefaultVisibility ( ) bool { for _ , r := range f . Rules { if r . Kind ( ) == " " && r . Attr ( " " ) != nil { return true } } return false } 
func NewLoad ( name string ) * Load { return & Load { stmt : stmt { expr : & bzl . LoadStmt { Module : & bzl . StringExpr { Value : name } , ForceCompact : true , } , } , name : name , symbols : make ( map [ string ] identPair ) , } } 
func ( l * Load ) Symbols ( ) [ ] string { syms := make ( [ ] string , 0 , len ( l . symbols ) ) for sym := range l . symbols { syms = append ( syms , sym ) } sort . Strings ( syms ) return syms } 
func ( l * Load ) Has ( sym string ) bool { _ , ok := l . symbols [ sym ] return ok } 
func ( l * Load ) Add ( sym string ) { if _ , ok := l . symbols [ sym ] ; ! ok { i := & bzl . Ident { Name : sym } l . symbols [ sym ] = identPair { to : i , from : i } l . updated = true } } 
func ( l * Load ) Remove ( sym string ) { if _ , ok := l . symbols [ sym ] ; ok { delete ( l . symbols , sym ) l . updated = true } } 
func ( l * Load ) Insert ( f * File , index int ) { l . index = index l . inserted = true f . Loads = append ( f . Loads , l ) } 
func NewRule ( kind , name string ) * Rule { nameAttr := & bzl . AssignExpr { LHS : & bzl . Ident { Name : " " } , RHS : & bzl . StringExpr { Value : name } , Op : " " , } r := & Rule { stmt : stmt { expr : & bzl . CallExpr { X : & bzl . Ident { Name : kind } , List : [ ] bzl . Expr { nameAttr } , } , } , kind : kind , attrs : map [ string ] * bzl . AssignExpr { " " : nameAttr } , private : map [ string ] interface { } { } , } return r } 
func ( r * Rule ) SetKind ( kind string ) { r . kind = kind r . updated = true } 
func ( r * Rule ) AttrKeys ( ) [ ] string { keys := make ( [ ] string , 0 , len ( r . attrs ) ) for k := range r . attrs { keys = append ( keys , k ) } sort . SliceStable ( keys , func ( i , j int ) bool { if cmp := bt . NamePriority [ keys [ i ] ] - bt . NamePriority [ keys [ j ] ] ; cmp != 0 { return cmp < 0 } return keys [ i ] < keys [ j ] } ) return keys } 
func ( r * Rule ) Attr ( key string ) bzl . Expr { attr , ok := r . attrs [ key ] if ! ok { return nil } return attr . RHS } 
func ( r * Rule ) AttrString ( key string ) string { attr , ok := r . attrs [ key ] if ! ok { return " " } str , ok := attr . RHS . ( * bzl . StringExpr ) if ! ok { return " " } return str . Value } 
func ( r * Rule ) AttrStrings ( key string ) [ ] string { attr , ok := r . attrs [ key ] if ! ok { return nil } list , ok := attr . RHS . ( * bzl . ListExpr ) if ! ok { return nil } strs := make ( [ ] string , 0 , len ( list . List ) ) for _ , e := range list . List { if str , ok := e . ( * bzl . StringExpr ) ; ok { strs = append ( strs , str . Value ) } } return strs } 
func ( r * Rule ) DelAttr ( key string ) { delete ( r . attrs , key ) r . updated = true } 
func ( r * Rule ) SetAttr ( key string , value interface { } ) { rhs := ExprFromValue ( value ) if attr , ok := r . attrs [ key ] ; ok { attr . RHS = rhs } else { r . attrs [ key ] = & bzl . AssignExpr { LHS : & bzl . Ident { Name : key } , RHS : rhs , Op : " " , } } r . updated = true } 
func ( r * Rule ) PrivateAttrKeys ( ) [ ] string { keys := make ( [ ] string , 0 , len ( r . private ) ) for k := range r . private { keys = append ( keys , k ) } sort . Strings ( keys ) return keys } 
func ( r * Rule ) SetPrivateAttr ( key string , value interface { } ) { r . private [ key ] = value } 
func ( r * Rule ) Insert ( f * File ) { if f . function == nil { stmt = f . File . Stmt } else { stmt = f . function . stmt . Body } r . index = len ( stmt ) r . inserted = true f . Rules = append ( f . Rules , r ) } 
func ( r * Rule ) IsEmpty ( info KindInfo ) bool { if info . NonEmptyAttrs == nil { return false } for k := range info . NonEmptyAttrs { if _ , ok := r . attrs [ k ] ; ok { return false } } return true } 
func ShouldKeep ( e bzl . Expr ) bool { for _ , c := range append ( e . Comment ( ) . Before , e . Comment ( ) . Suffix ... ) { text := strings . TrimSpace ( strings . TrimPrefix ( c . Token , " " ) ) if text == " " { return true } } return false } 
func CheckInternalVisibility ( rel , visibility string ) string { if i := strings . LastIndex ( rel , " " ) ; i >= 0 { visibility = fmt . Sprintf ( " " , rel [ : i ] ) } else if strings . HasPrefix ( rel , " " ) { visibility = " " } return visibility } 
func New ( repo , pkg , name string ) Label { return Label { Repo : repo , Pkg : pkg , Name : name } } 
func Parse ( s string ) ( Label , error ) { origStr := s relative := true var repo string if strings . HasPrefix ( s , " " ) { relative = false endRepo := strings . Index ( s , " " ) if endRepo < 0 { return NoLabel , fmt . Errorf ( " " , origStr ) } repo = s [ len ( " " ) : endRepo ] if ! labelRepoRegexp . MatchString ( repo ) { return NoLabel , fmt . Errorf ( " " , origStr ) } s = s [ endRepo : ] } var pkg string if strings . HasPrefix ( s , " " ) { relative = false endPkg := strings . Index ( s , " " ) if endPkg < 0 { pkg = s [ len ( " " ) : ] s = " " } else { pkg = s [ len ( " " ) : endPkg ] s = s [ endPkg : ] } if ! labelPkgRegexp . MatchString ( pkg ) { return NoLabel , fmt . Errorf ( " " , origStr ) } } if s == " " { return NoLabel , fmt . Errorf ( " " , origStr ) } name := strings . TrimPrefix ( s , " " ) if ! labelNameRegexp . MatchString ( name ) { return NoLabel , fmt . Errorf ( " " , origStr ) } if pkg == " " && name == " " { return NoLabel , fmt . Errorf ( " " , origStr ) } if name == " " { name = path . Base ( pkg ) } return Label { Repo : repo , Pkg : pkg , Name : name , Relative : relative , } , nil } 
func ( l Label ) Abs ( repo , pkg string ) Label { if ! l . Relative { return l } return Label { Repo : repo , Pkg : pkg , Name : l . Name } } 
func ( l Label ) Rel ( repo , pkg string ) Label { if l . Relative || l . Repo != repo { return l } if l . Pkg == pkg { return Label { Name : l . Name , Relative : true } } return Label { Pkg : l . Pkg , Name : l . Name } } 
func ( l Label ) Equal ( other Label ) bool { return l . Repo == other . Repo && l . Pkg == other . Pkg && l . Name == other . Name && l . Relative == other . Relative } 
func ( l Label ) Contains ( other Label ) bool { if l . Relative { log . Panicf ( " " , l ) } if other . Relative { log . Panicf ( " " , other ) } result := l . Repo == other . Repo && pathtools . HasPrefix ( other . Pkg , l . Pkg ) return result } 
func ImportPathToBazelRepoName ( importpath string ) string { importpath = strings . ToLower ( importpath ) components := strings . Split ( importpath , " " ) labels := strings . Split ( components [ 0 ] , " " ) var reversed [ ] string for i := range labels { l := labels [ len ( labels ) - i - 1 ] reversed = append ( reversed , l ) } repo := strings . Join ( append ( reversed , components [ 1 : ] ... ) , " " ) return strings . NewReplacer ( " " , " " , " " , " " ) . Replace ( repo ) } 
func isSemverPrefix ( v string ) bool { dots := 0 for i := 0 ; i < len ( v ) ; i ++ { switch v [ i ] { case '-' , '+' : return false case '.' : dots ++ if dots >= 2 { return false } } } return true } 
func generateFromPath ( w io . Writer , rootPath string ) error { return filepath . Walk ( rootPath , func ( path string , info os . FileInfo , err error ) error { if err != nil { return err } if ! strings . HasSuffix ( path , " " ) { return nil } relPath , err := filepath . Rel ( rootPath , path ) if err != nil || strings . HasPrefix ( relPath , " " ) { log . Panicf ( " " , path , rootPath ) } relPath = filepath . ToSlash ( relPath ) if strings . HasPrefix ( relPath , " " ) { protoLabel , goLabel := protoLabels ( " " , " " ) fmt . Fprintf ( w , " \n " , relPath , protoLabel , packagePath , goLabel ) return nil } packagePath , packageName , err := loadGoPackage ( path ) if err != nil { log . Print ( err ) return nil } protoLabel , goLabel := protoLabels ( relPath , packageName ) fmt . Fprintf ( w , " \n " , relPath , protoLabel , packagePath , goLabel ) return nil } ) } 
func Walk ( c * config . Config , cexts [ ] config . Configurer , dirs [ ] string , mode Mode , wf WalkFunc ) { knownDirectives := make ( map [ string ] bool ) for _ , cext := range cexts { for _ , d := range cext . KnownDirectives ( ) { knownDirectives [ d ] = true } } symlinks := symlinkResolver { visited : [ ] string { c . RepoRoot } } updateRels := buildUpdateRelMap ( c . RepoRoot , dirs ) var visit func ( * config . Config , string , string , bool ) visit = func ( c * config . Config , dir , rel string , updateParent bool ) { haveError := false if err != nil { log . Print ( err ) return } f , err := loadBuildFile ( c , rel , dir , files ) if err != nil { log . Print ( err ) haveError = true } c = configure ( cexts , knownDirectives , c , rel , f ) wc := getWalkConfig ( c ) if wc . isExcluded ( rel , " " ) { return } var subdirs , regularFiles [ ] string for _ , fi := range files { base := fi . Name ( ) switch { case base == " " || wc . isExcluded ( rel , base ) : continue case fi . IsDir ( ) || fi . Mode ( ) & os . ModeSymlink != 0 && symlinks . follow ( c , dir , rel , base ) : subdirs = append ( subdirs , base ) default : regularFiles = append ( regularFiles , base ) } } shouldUpdate := shouldUpdate ( rel , mode , updateParent , updateRels ) for _ , sub := range subdirs { if subRel := path . Join ( rel , sub ) ; shouldVisit ( subRel , mode , updateRels ) { visit ( c , filepath . Join ( dir , sub ) , subRel , shouldUpdate ) } } update := ! haveError && ! wc . ignore && shouldUpdate if shouldCall ( rel , mode , updateRels ) { genFiles := findGenFiles ( wc , f ) wf ( dir , rel , c , update , f , subdirs , regularFiles , genFiles ) } } visit ( c , c . RepoRoot , " " , false ) } 
func buildUpdateRelMap ( root string , dirs [ ] string ) map [ string ] bool { relMap := make ( map [ string ] bool ) for _ , dir := range dirs { rel , _ := filepath . Rel ( root , dir ) rel = filepath . ToSlash ( rel ) if rel == " " { rel = " " } i := 0 for { next := strings . IndexByte ( rel [ i : ] , '/' ) + i if next - i < 0 { relMap [ rel ] = true break } prefix := rel [ : next ] relMap [ prefix ] = relMap [ prefix ] i = next + 1 } } return relMap } 
func shouldCall ( rel string , mode Mode , updateRels map [ string ] bool ) bool { return mode != UpdateDirsMode || updateRels [ rel ] } 
func shouldUpdate ( rel string , mode Mode , updateParent bool , updateRels map [ string ] bool ) bool { return mode == VisitAllUpdateSubdirsMode && updateParent || updateRels [ rel ] } 
func shouldVisit ( rel string , mode Mode , updateRels map [ string ] bool ) bool { if mode != UpdateDirsMode { return true } _ , ok := updateRels [ rel ] return ok } 
func ( r * symlinkResolver ) follow ( c * config . Config , dir , rel , base string ) bool { if dir == c . RepoRoot && strings . HasPrefix ( base , " " ) { } linkRel := path . Join ( rel , base ) for _ , follow := range wc . follow { if linkRel == follow { return true } } dest , err := filepath . EvalSymlinks ( fullpath ) if err != nil { return false } if ! filepath . IsAbs ( dest ) { dest , err = filepath . Abs ( filepath . Join ( dir , dest ) ) if err != nil { return false } } for _ , p := range r . visited { if pathtools . HasPrefix ( dest , p ) || pathtools . HasPrefix ( p , dest ) { return false } } r . visited = append ( r . visited , dest ) stat , err := os . Stat ( fullpath ) if err != nil { return false } return stat . IsDir ( ) } 
func MergeRules ( src , dst * Rule , mergeable map [ string ] bool , filename string ) { if dst . ShouldKeep ( ) { return } } dstValue := dstAttr . RHS if mergedValue , err := mergeExprs ( nil , dstValue ) ; err != nil { start , end := dstValue . Span ( ) log . Printf ( " " , filename , start . Line , start . LineRune , end . Line , end . LineRune ) } else if mergedValue == nil { dst . DelAttr ( key ) } else { dst . SetAttr ( key , mergedValue ) } } if dstAttr , ok := dst . attrs [ key ] ; ! ok { dst . SetAttr ( key , srcValue ) } else if mergeable [ key ] && ! ShouldKeep ( dstAttr ) { dstValue := dstAttr . RHS if mergedValue , err := mergeExprs ( srcValue , dstValue ) ; err != nil { start , end := dstValue . Span ( ) log . Printf ( " " , filename , start . Line , start . LineRune , end . Line , end . LineRune ) } else { dst . SetAttr ( key , mergedValue ) } } } } 
func mergeExprs ( src , dst bzl . Expr ) ( bzl . Expr , error ) { if ShouldKeep ( dst ) { return nil , nil } if src == nil && ( dst == nil || isScalar ( dst ) ) { return nil , nil } if isScalar ( src ) { return src , nil } srcExprs , err := extractPlatformStringsExprs ( src ) if err != nil { return nil , err } dstExprs , err := extractPlatformStringsExprs ( dst ) if err != nil { return nil , err } mergedExprs , err := mergePlatformStringsExprs ( srcExprs , dstExprs ) if err != nil { return nil , err } return makePlatformStringsExpr ( mergedExprs ) , nil } 
func SquashRules ( src , dst * Rule , filename string ) error { if dst . ShouldKeep ( ) { return nil } for key , srcAttr := range src . attrs { srcValue := srcAttr . RHS if dstAttr , ok := dst . attrs [ key ] ; ! ok { dst . SetAttr ( key , srcValue ) } else if ! ShouldKeep ( dstAttr ) { dstValue := dstAttr . RHS if squashedValue , err := squashExprs ( srcValue , dstValue ) ; err != nil { start , end := dstValue . Span ( ) return fmt . Errorf ( " " , filename , start . Line , start . LineRune , end . Line , end . LineRune ) } else { dst . SetAttr ( key , squashedValue ) } } } dst . expr . Comment ( ) . Before = append ( dst . expr . Comment ( ) . Before , src . expr . Comment ( ) . Before ... ) dst . expr . Comment ( ) . Suffix = append ( dst . expr . Comment ( ) . Suffix , src . expr . Comment ( ) . Suffix ... ) dst . expr . Comment ( ) . After = append ( dst . expr . Comment ( ) . After , src . expr . Comment ( ) . After ... ) return nil } 
func MergeFile ( oldFile * rule . File , emptyRules , genRules [ ] * rule . Rule , phase Phase , kinds map [ string ] rule . KindInfo ) { getMergeAttrs := func ( r * rule . Rule ) map [ string ] bool { if phase == PreResolve { return kinds [ r . Kind ( ) ] . MergeableAttrs } else { return kinds [ r . Kind ( ) ] . ResolveAttrs } } } rule . MergeRules ( emptyRule , oldRule , getMergeAttrs ( emptyRule ) , oldFile . Path ) if oldRule . IsEmpty ( kinds [ oldRule . Kind ( ) ] ) { oldRule . Delete ( ) } } } oldFile . Sync ( ) matchErrors := make ( [ ] error , len ( genRules ) ) substitutions := make ( map [ string ] string ) for i , genRule := range genRules { oldRule , err := Match ( oldFile . Rules , genRule , kinds [ genRule . Kind ( ) ] ) if err != nil { continue } matchRules [ i ] = oldRule if oldRule != nil { if oldRule . Name ( ) != genRule . Name ( ) { substitutions [ genRule . Name ( ) ] = oldRule . Name ( ) } } } } } } if matchRules [ i ] == nil { genRule . Insert ( oldFile ) } else { rule . MergeRules ( genRule , matchRules [ i ] , getMergeAttrs ( genRule ) , oldFile . Path ) } } } 
func substituteRule ( r * rule . Rule , substitutions map [ string ] string , info rule . KindInfo ) { for attr := range info . SubstituteAttrs { if expr := r . Attr ( attr ) ; expr != nil { expr = rule . MapExprStrings ( expr , func ( s string ) string { if rename , ok := substitutions [ strings . TrimPrefix ( s , " " ) ] ; ok { return " " + rename } else { return s } } ) r . SetAttr ( attr , expr ) } } } 
func Match ( rules [ ] * rule . Rule , x * rule . Rule , info rule . KindInfo ) ( * rule . Rule , error ) { xname := x . Name ( ) xkind := x . Kind ( ) var nameMatches [ ] * rule . Rule var kindMatches [ ] * rule . Rule for _ , y := range rules { if xname == y . Name ( ) { nameMatches = append ( nameMatches , y ) } if xkind == y . Kind ( ) { kindMatches = append ( kindMatches , y ) } } if len ( nameMatches ) == 1 { y := nameMatches [ 0 ] if xkind != y . Kind ( ) { return nil , fmt . Errorf ( " " , xkind , xname , y . Kind ( ) ) } return y , nil } if len ( nameMatches ) > 1 { return nil , fmt . Errorf ( " " , xkind , xname ) } for _ , key := range info . MatchAttrs { var attrMatches [ ] * rule . Rule xvalue := x . AttrString ( key ) if xvalue == " " { continue } for _ , y := range kindMatches { if xvalue == y . AttrString ( key ) { attrMatches = append ( attrMatches , y ) } } if len ( attrMatches ) == 1 { return attrMatches [ 0 ] , nil } else if len ( attrMatches ) > 1 { return nil , fmt . Errorf ( " " , xkind , xname , key , xvalue ) } } if info . MatchAny { if len ( kindMatches ) == 1 { return kindMatches [ 0 ] , nil } else if len ( kindMatches ) > 1 { return nil , fmt . Errorf ( " " , xkind , xname ) } } return nil , nil } 
func runClient ( ) error { startTime := time . Now ( ) conn , err := net . Dial ( " " , * socketPath ) if err != nil { if err := startServer ( ) ; err != nil { return fmt . Errorf ( " " , err ) } for retry := 0 ; retry < 3 ; retry ++ { conn , err = net . Dial ( " " , * socketPath ) if err == nil { break } } if err != nil { return fmt . Errorf ( " " , err ) } } defer conn . Close ( ) if _ , err := io . Copy ( os . Stderr , conn ) ; err != nil { log . Print ( err ) } elapsedTime := time . Since ( startTime ) log . Printf ( " " , elapsedTime . Seconds ( ) ) return nil } 
func ParseDirectives ( f * bzl . File ) [ ] Directive { var directives [ ] Directive parseComment := func ( com bzl . Comment ) { match := directiveRe . FindStringSubmatch ( com . Token ) if match == nil { return } key , value := match [ 1 ] , match [ 2 ] directives = append ( directives , Directive { key , value } ) } for _ , s := range f . Stmt { coms := s . Comment ( ) for _ , com := range coms . Before { parseComment ( com ) } for _ , com := range coms . After { parseComment ( com ) } } return directives } 
func UpdateRepo ( rc * RemoteCache , importPath string ) ( Repo , error ) { root , name , err := rc . Root ( importPath ) if err != nil { return Repo { } , err } remote , vcs , err := rc . Remote ( root ) if err != nil { return Repo { } , err } commit , tag , err := rc . Head ( remote , vcs ) if err != nil { return Repo { } , err } repo := Repo { Name : name , GoPrefix : root , Commit : commit , Tag : tag , Remote : remote , VCS : vcs , } return repo , nil } 
func NewRemoteCache ( knownRepos [ ] Repo ) ( r * RemoteCache , cleanup func ( ) error ) { r = & RemoteCache { RepoRootForImportPath : vcs . RepoRootForImportPath , HeadCmd : defaultHeadCmd , root : remoteCacheMap { cache : make ( map [ string ] * remoteCacheEntry ) } , remote : remoteCacheMap { cache : make ( map [ string ] * remoteCacheEntry ) } , head : remoteCacheMap { cache : make ( map [ string ] * remoteCacheEntry ) } , mod : remoteCacheMap { cache : make ( map [ string ] * remoteCacheEntry ) } , } r . ModInfo = func ( importPath string ) ( string , error ) { return defaultModInfo ( r , importPath ) } for _ , repo := range knownRepos { r . root . cache [ repo . GoPrefix ] = & remoteCacheEntry { value : rootValue { root : repo . GoPrefix , name : repo . Name , } , } if repo . Remote != " " { r . remote . cache [ repo . GoPrefix ] = & remoteCacheEntry { value : remoteValue { remote : repo . Remote , vcs : repo . VCS , } , } } r . mod . cache [ repo . GoPrefix ] = & remoteCacheEntry { value : modValue { path : repo . GoPrefix , name : repo . Name , known : true , } , } } return r , r . cleanup } 
func ( r * RemoteCache ) Root ( importPath string ) ( root , name string , err error ) { for { v , ok , err := r . root . get ( prefix ) if ok { if err != nil { return " " , " " , err } value := v . ( rootValue ) return value . root , value . name , nil } prefix = path . Dir ( prefix ) if prefix == " " || prefix == " " { break } } var components [ ] string if rest != " " { components = strings . Split ( rest , " " ) } if len ( components ) < p . missing { return " " , " " , fmt . Errorf ( " " , importPath , p . prefix ) } root = p . prefix for _ , c := range components [ : p . missing ] { root = path . Join ( root , c ) } name = label . ImportPathToBazelRepoName ( root ) return root , name , nil } } name = label . ImportPathToBazelRepoName ( root ) return root , name , nil } if err != nil { return nil , err } return rootValue { res . Root , label . ImportPathToBazelRepoName ( res . Root ) } , nil } ) if err != nil { return " " , " " , err } value := v . ( rootValue ) return value . root , value . name , nil } 
func ( r * RemoteCache ) Remote ( root string ) ( remote , vcs string , err error ) { v , err := r . remote . ensure ( root , func ( ) ( interface { } , error ) { repo , err := r . RepoRootForImportPath ( root , false ) if err != nil { return nil , err } return remoteValue { remote : repo . Repo , vcs : repo . VCS . Cmd } , nil } ) if err != nil { return " " , " " , err } value := v . ( remoteValue ) return value . remote , value . vcs , nil } 
func ( r * RemoteCache ) Head ( remote , vcs string ) ( commit , tag string , err error ) { if vcs != " " { return " " , " " , fmt . Errorf ( " " , remote , vcs ) } v , err := r . head . ensure ( remote , func ( ) ( interface { } , error ) { commit , err := r . HeadCmd ( remote , vcs ) if err != nil { return nil , err } return headValue { commit : commit } , nil } ) if err != nil { return " " , " " , err } value := v . ( headValue ) return value . commit , value . tag , nil } 
func ( r * RemoteCache ) Mod ( importPath string ) ( modPath , name string , err error ) { for { v , ok , err := r . mod . get ( prefix ) if ok { if err != nil { return " " , " " , err } value := v . ( modValue ) if value . known { return value . path , value . name , nil } else { break } } prefix = path . Dir ( prefix ) if prefix == " " || prefix == " " { break } } if err != nil { return nil , err } return modValue { path : modPath , name : label . ImportPathToBazelRepoName ( modPath ) , } , nil } ) if err != nil { return " " , " " , err } value := v . ( modValue ) return value . path , value . name , nil } 
func ( m * remoteCacheMap ) get ( key string ) ( value interface { } , ok bool , err error ) { m . mu . Lock ( ) e , ok := m . cache [ key ] m . mu . Unlock ( ) if ! ok { return nil , ok , nil } if e . ready != nil { <- e . ready } return e . value , ok , e . err } 
func ( m * remoteCacheMap ) ensure ( key string , load func ( ) ( interface { } , error ) ) ( interface { } , error ) { m . mu . Lock ( ) e , ok := m . cache [ key ] if ! ok { e = & remoteCacheEntry { ready : make ( chan struct { } ) } m . cache [ key ] = e m . mu . Unlock ( ) e . value , e . err = load ( ) close ( e . ready ) } else { m . mu . Unlock ( ) if e . ready != nil { <- e . ready } } return e . value , e . err } 
func HasPrefix ( p , prefix string ) bool { return prefix == " " || p == prefix || strings . HasPrefix ( p , prefix + " " ) } 
func TrimPrefix ( p , prefix string ) string { if prefix == " " { return p } if prefix == p { return " " } return strings . TrimPrefix ( p , prefix + " " ) } 
func RelBaseName ( rel , prefix , root string ) string { base := path . Base ( rel ) if base == " " || base == " " { base = path . Base ( prefix ) } if base == " " || base == " " { base = filepath . Base ( root ) } if base == " " || base == " " { base = " " } return base } 
func ( c * Config ) Clone ( ) * Config { cc := * c cc . Exts = make ( map [ string ] interface { } ) for k , v := range c . Exts { cc . Exts [ k ] = v } cc . KindMap = make ( map [ string ] MappedKind ) for k , v := range c . KindMap { cc . KindMap [ k ] = v } return & cc } 
func ( c * Config ) IsValidBuildFileName ( name string ) bool { for _ , n := range c . ValidBuildFileNames { if name == n { return true } } return false } 
func ( l tagLine ) check ( c * config . Config , os , arch string ) bool { if len ( l ) == 0 { return false } for _ , g := range l { if g . check ( c , os , arch ) { return true } } return false } 
func ( g tagGroup ) check ( c * config . Config , os , arch string ) bool { goConf := getGoConfig ( c ) for _ , t := range g { if strings . HasPrefix ( t , " " ) { } not := strings . HasPrefix ( t , " " ) if not { t = t [ 1 : ] } if isIgnoredTag ( t ) { } var match bool if _ , ok := rule . KnownOSSet [ t ] ; ok { if os == " " { return false } match = os == t } else if _ , ok := rule . KnownArchSet [ t ] ; ok { if arch == " " { return false } match = arch == t } else { match = goConf . genericTags [ t ] } if not { match = ! match } if ! match { return false } } return true } 
func fileNameInfo ( path_ string ) fileInfo { name := filepath . Base ( path_ ) var ext ext switch path . Ext ( name ) { case " " : ext = goExt case " " , " " , " " , " " , " " , " " : ext = cExt case " " , " " , " " , " " : ext = hExt case " " : ext = sExt case " " : ext = csExt case " " : ext = protoExt default : ext = unknownExt } if strings . HasPrefix ( name , " " ) || strings . HasPrefix ( name , " " ) { ext = unknownExt } var goos , goarch string l := strings . Split ( name [ : len ( name ) - len ( path . Ext ( name ) ) ] , " " ) if len ( l ) >= 2 && l [ len ( l ) - 1 ] == " " { isTest = ext == goExt l = l [ : len ( l ) - 1 ] } switch { case len ( l ) >= 3 && rule . KnownOSSet [ l [ len ( l ) - 2 ] ] && rule . KnownArchSet [ l [ len ( l ) - 1 ] ] : goos = l [ len ( l ) - 2 ] goarch = l [ len ( l ) - 1 ] case len ( l ) >= 2 && rule . KnownOSSet [ l [ len ( l ) - 1 ] ] : goos = l [ len ( l ) - 1 ] case len ( l ) >= 2 && rule . KnownArchSet [ l [ len ( l ) - 1 ] ] : goarch = l [ len ( l ) - 1 ] } return fileInfo { path : path_ , name : name , ext : ext , isTest : isTest , goos : goos , goarch : goarch , } } 
func otherFileInfo ( path string ) fileInfo { info := fileNameInfo ( path ) if info . ext == unknownExt { return info } tags , err := readTags ( info . path ) if err != nil { log . Printf ( " " , info . path , err ) return info } info . tags = tags return info } 
func goFileInfo ( path , rel string ) fileInfo { info := fileNameInfo ( path ) fset := token . NewFileSet ( ) pf , err := parser . ParseFile ( fset , info . path , nil , parser . ImportsOnly | parser . ParseComments ) if err != nil { log . Printf ( " " , info . path , err ) return info } info . packageName = pf . Name . Name if info . isTest && strings . HasSuffix ( info . packageName , " " ) { info . packageName = info . packageName [ : len ( info . packageName ) - len ( " " ) ] } for _ , decl := range pf . Decls { d , ok := decl . ( * ast . GenDecl ) if ! ok { continue } for _ , dspec := range d . Specs { spec , ok := dspec . ( * ast . ImportSpec ) if ! ok { continue } quoted := spec . Path . Value path , err := strconv . Unquote ( quoted ) if err != nil { log . Printf ( " " , info . path , err ) continue } if path == " " { if info . isTest { log . Printf ( " " , info . path ) } info . isCgo = true cg := spec . Doc if cg == nil && len ( d . Specs ) == 1 { cg = d . Doc } if cg != nil { if err := saveCgo ( & info , rel , cg ) ; err != nil { log . Printf ( " " , info . path , err ) } } continue } info . imports = append ( info . imports , path ) } } tags , err := readTags ( info . path ) if err != nil { log . Printf ( " " , info . path , err ) return info } info . tags = tags return info } 
func saveCgo ( info * fileInfo , rel string , cg * ast . CommentGroup ) error { text := cg . Text ( ) for _ , line := range strings . Split ( text , " \n " ) { orig := line if len ( line ) < 5 || line [ : 4 ] != " " || ( line [ 4 ] != ' ' && line [ 4 ] != '\t' ) { continue } i := strings . Index ( line , " " ) if i < 0 { return fmt . Errorf ( " " , info . path , orig ) } line , optstr := strings . TrimSpace ( line [ : i ] ) , strings . TrimSpace ( line [ i + 1 : ] ) if len ( f ) < 1 { return fmt . Errorf ( " " , info . path , orig ) } verb := f [ len ( f ) - 1 ] tags := parseTagsInGroups ( f [ : len ( f ) - 1 ] ) if err != nil { return fmt . Errorf ( " " , info . path , orig ) } var ok bool for i , opt := range opts { if opt , ok = expandSrcDir ( opt , rel ) ; ! ok { return fmt . Errorf ( " " , info . path , orig ) } opts [ i ] = opt } joinedStr := strings . Join ( opts , optSeparator ) case " " : info . clinkopts = append ( info . clinkopts , taggedOpts { tags , joinedStr } ) case " " : return fmt . Errorf ( " " , info . path , orig ) default : return fmt . Errorf ( " " , info . path , orig ) } } return nil } 
func splitQuoted ( s string ) ( r [ ] string , err error ) { var args [ ] string arg := make ( [ ] rune , len ( s ) ) escaped := false quoted := false quote := '\x00' i := 0 for _ , rune := range s { switch { case escaped : escaped = false case rune == '\\' : escaped = true continue case quote != '\x00' : if rune == quote { quote = '\x00' continue } case rune == '"' || rune == '\'' : quoted = true quote = rune continue case unicode . IsSpace ( rune ) : if quoted || i > 0 { quoted = false args = append ( args , string ( arg [ : i ] ) ) i = 0 } continue } arg [ i ] = rune i ++ } if quoted || i > 0 { args = append ( args , string ( arg [ : i ] ) ) } if quote != 0 { err = errors . New ( " " ) } else if escaped { err = errors . New ( " " ) } return args , err } 
func expandSrcDir ( str string , srcdir string ) ( string , bool ) { if srcdir == " " { srcdir = " " } if len ( chunks ) < 2 { return str , safeCgoName ( str , false ) } ok := true for _ , chunk := range chunks { ok = ok && ( chunk == " " || safeCgoName ( chunk , false ) ) } ok = ok && ( srcdir == " " || safeCgoName ( srcdir , true ) ) res := strings . Join ( chunks , srcdir ) return res , ok && res != " " } 
func safeCgoName ( s string , spaces bool ) bool { if s == " " { return false } safe := safeBytes if ! spaces { safe = safe [ len ( safeSpaces ) : ] } for i := 0 ; i < len ( s ) ; i ++ { if c := s [ i ] ; c < utf8 . RuneSelf && bytes . IndexByte ( safe , c ) < 0 { return false } } return true } 
func readTags ( path string ) ( [ ] tagLine , error ) { f , err := os . Open ( path ) if err != nil { return nil , err } defer f . Close ( ) scanner := bufio . NewScanner ( f ) end := 0 for scanner . Scan ( ) { line := strings . TrimSpace ( scanner . Text ( ) ) if line == " " { end = len ( lines ) continue } if strings . HasPrefix ( line , " " ) { lines = append ( lines , line [ len ( " " ) : ] ) continue } break } if err := scanner . Err ( ) ; err != nil { return nil , err } lines = lines [ : end ] for _ , line := range lines { fields := strings . Fields ( line ) if len ( fields ) > 0 && fields [ 0 ] == " " { tagLines = append ( tagLines , parseTagsInGroups ( fields [ 1 : ] ) ) } } return tagLines , nil } 
func checkConstraints ( c * config . Config , os , arch , osSuffix , archSuffix string , fileTags [ ] tagLine , cgoTags tagLine ) bool { if osSuffix != " " && osSuffix != os || archSuffix != " " && archSuffix != arch { return false } for _ , l := range fileTags { if ! l . check ( c , os , arch ) { return false } } if len ( cgoTags ) > 0 && ! cgoTags . check ( c , os , arch ) { return false } return true } 
func isIgnoredTag ( tag string ) bool { if tag == " " || tag == " " || tag == " " { return true } if len ( tag ) < 5 || ! strings . HasPrefix ( tag , " " ) { return false } if tag [ 2 ] < '0' || tag [ 2 ] > '9' || tag [ 3 ] != '.' { return false } for _ , c := range tag [ 4 : ] { if c < '0' || c > '9' { return false } } return true } 
func protoFileInfo ( path_ string , protoInfo proto . FileInfo ) fileInfo { info := fileNameInfo ( path_ ) } if strings . LastIndexByte ( opt . Value , '/' ) == - 1 { info . packageName = opt . Value } else { if i := strings . LastIndexByte ( opt . Value , ';' ) ; i != - 1 { info . importPath = opt . Value [ : i ] info . packageName = opt . Value [ i + 1 : ] } else { info . importPath = opt . Value info . packageName = path . Base ( opt . Value ) } } } } info . imports = protoInfo . Imports info . hasServices = protoInfo . HasServices return info } 
func FindRuleWithOverride ( c * config . Config , imp ImportSpec , lang string ) ( label . Label , bool ) { rc := getResolveConfig ( c ) for i := len ( rc . overrides ) - 1 ; i >= 0 ; i -- { o := rc . overrides [ i ] if o . matches ( imp , lang ) { return o . dep , true } } return label . NoLabel , false } 
func NewRuleIndex ( mrslv func ( r * rule . Rule , pkgRel string ) Resolver ) * RuleIndex { return & RuleIndex { labelMap : make ( map [ label . Label ] * ruleRecord ) , mrslv : mrslv , } } 
func ( ix * RuleIndex ) AddRule ( c * config . Config , r * rule . Rule , f * rule . File ) { var imps [ ] ImportSpec if rslv := ix . mrslv ( r , f . Pkg ) ; rslv != nil { imps = rslv . Imports ( c , r , f ) } } record := & ruleRecord { rule : r , label : label . New ( c . RepoName , f . Pkg , r . Name ( ) ) , file : f , importedAs : imps , } if _ , ok := ix . labelMap [ record . label ] ; ok { log . Printf ( " " , record . label ) return } ix . rules = append ( ix . rules , record ) ix . labelMap [ record . label ] = record } 
func ( ix * RuleIndex ) Finish ( ) { for _ , r := range ix . rules { ix . collectEmbeds ( r ) } ix . buildImportIndex ( ) } 
func ( ix * RuleIndex ) buildImportIndex ( ) { ix . importMap = make ( map [ ImportSpec ] [ ] * ruleRecord ) for _ , r := range ix . rules { if r . embedded { continue } indexed := make ( map [ ImportSpec ] bool ) for _ , imp := range r . importedAs { if indexed [ imp ] { continue } indexed [ imp ] = true ix . importMap [ imp ] = append ( ix . importMap [ imp ] , r ) } } } 
func ( ix * RuleIndex ) FindRulesByImport ( imp ImportSpec , lang string ) [ ] FindResult { matches := ix . importMap [ imp ] results := make ( [ ] FindResult , 0 , len ( matches ) ) for _ , m := range matches { if ix . mrslv ( m . rule , " " ) . Name ( ) != lang { continue } results = append ( results , FindResult { Label : m . label , Embeds : m . embeds , } ) } return results } 
func ( r FindResult ) IsSelfImport ( from label . Label ) bool { if from . Equal ( r . Label ) { return true } for _ , e := range r . Embeds { if from . Equal ( e ) { return true } } return false } 
func applyKindMappings ( mappedKinds [ ] config . MappedKind , loads [ ] rule . LoadInfo ) [ ] rule . LoadInfo { if len ( mappedKinds ) == 0 { return loads } copy ( mappedLoads , loads ) for _ , mappedKind := range mappedKinds { mappedLoads = appendOrMergeKindMapping ( mappedLoads , mappedKind ) } return mappedLoads } 
func appendOrMergeKindMapping ( mappedLoads [ ] rule . LoadInfo , mappedKind config . MappedKind ) [ ] rule . LoadInfo { return mappedLoads } } } 
func RuleName ( names ... string ) string { base := " " for _ , name := range names { notIdent := func ( c rune ) bool { return ! ( 'A' <= c && c <= 'Z' || 'a' <= c && c <= 'z' || '0' <= c && c <= '9' || c == '_' ) } if i := strings . LastIndexFunc ( name , notIdent ) ; i >= 0 { name = name [ i + 1 : ] } if name != " " { base = name break } } return base + " " } 
func buildPackages ( pc * ProtoConfig , dir , rel string , protoFiles , genFiles [ ] string ) [ ] * Package { packageMap := make ( map [ string ] * Package ) for _ , name := range protoFiles { info := protoFileInfo ( dir , name ) key := info . PackageName if pc . groupOption != " " { for _ , opt := range info . Options { if opt . Key == pc . groupOption { key = opt . Value break } } } if packageMap [ key ] == nil { packageMap [ key ] = newPackage ( info . PackageName ) } packageMap [ key ] . addFile ( info ) } switch pc . Mode { case DefaultMode : pkg , err := selectPackage ( dir , rel , packageMap ) if err != nil { log . Print ( err ) } if pkg == nil { return nil } for _ , name := range genFiles { pkg . addGenFile ( dir , name ) } return [ ] * Package { pkg } case PackageMode : pkgs := make ( [ ] * Package , 0 , len ( packageMap ) ) for _ , pkg := range packageMap { pkgs = append ( pkgs , pkg ) } return pkgs default : return nil } } 
func selectPackage ( dir , rel string , packageMap map [ string ] * Package ) ( * Package , error ) { if len ( packageMap ) == 0 { return nil , nil } if len ( packageMap ) == 1 { for _ , pkg := range packageMap { return pkg , nil } } defaultPackageName := strings . Replace ( rel , " " , " " , - 1 ) for _ , pkg := range packageMap { if pkgName := goPackageName ( pkg ) ; pkgName != " " && pkgName == defaultPackageName { return pkg , nil } } return nil , fmt . Errorf ( " " , dir ) } 
func goPackageName ( pkg * Package ) string { if opt , ok := pkg . Options [ " " ] ; ok { if i := strings . IndexByte ( opt , ';' ) ; i >= 0 { return opt [ i + 1 : ] } else if i := strings . LastIndexByte ( opt , '/' ) ; i >= 0 { return opt [ i + 1 : ] } else { return opt } } if pkg . Name != " " { return strings . Replace ( pkg . Name , " " , " " , - 1 ) } if len ( pkg . Files ) == 1 { for s := range pkg . Files { return strings . TrimSuffix ( s , " " ) } } return " " } 
func generateProto ( pc * ProtoConfig , rel string , pkg * Package , shouldSetVisibility bool ) * rule . Rule { var name string if pc . Mode == DefaultMode { name = RuleName ( goPackageName ( pkg ) , pc . GoPrefix , rel ) } else { name = RuleName ( pkg . Options [ pc . groupOption ] , pkg . Name , rel ) } r := rule . NewRule ( " " , name ) srcs := make ( [ ] string , 0 , len ( pkg . Files ) ) for f := range pkg . Files { srcs = append ( srcs , f ) } sort . Strings ( srcs ) if len ( srcs ) > 0 { r . SetAttr ( " " , srcs ) } r . SetPrivateAttr ( PackageKey , * pkg ) imports := make ( [ ] string , 0 , len ( pkg . Imports ) ) for i := range pkg . Imports { imports = append ( imports , i ) } sort . Strings ( imports ) for k , v := range pkg . Options { r . SetPrivateAttr ( k , v ) } if shouldSetVisibility { vis := rule . CheckInternalVisibility ( rel , " " ) r . SetAttr ( " " , [ ] string { vis } ) } if pc . stripImportPrefix != " " { r . SetAttr ( " " , pc . stripImportPrefix ) } if pc . importPrefix != " " { r . SetAttr ( " " , pc . importPrefix ) } return r } 
func generateEmpty ( f * rule . File , regularFiles , genFiles [ ] string ) [ ] * rule . Rule { if f == nil { return nil } knownFiles := make ( map [ string ] bool ) for _ , f := range regularFiles { knownFiles [ f ] = true } for _ , f := range genFiles { knownFiles [ f ] = true } var empty [ ] * rule . Rule outer : for _ , r := range f . Rules { if r . Kind ( ) != " " { continue } srcs := r . AttrStrings ( " " ) if len ( srcs ) == 0 && r . Attr ( " " ) != nil { } for _ , src := range r . AttrStrings ( " " ) { if knownFiles [ src ] { continue outer } } empty = append ( empty , rule . NewRule ( " " , r . Name ( ) ) ) } return empty } 
func buildProtoRegexp ( ) * regexp . Regexp { hexEscape := `\\[xX][0-9a-fA-f]{2}` octEscape := `\\[0-7]{3}` charEscape := `\\[abfnrtv'"\\]` charValue := strings . Join ( [ ] string { hexEscape , octEscape , charEscape , " \x00 \\ \\ \" \\ \\ " } , " " ) strLit := `'(?:` + charValue + `|")*'|"(?:` + charValue + `|')*"` ident := `[A-Za-z][A-Za-z0-9_]*` fullIdent := ident + `(?:\.` + ident + `)*` importStmt := `\bimport\s*(?:public|weak)?\s*(?P<import>` + strLit + `)\s*;` packageStmt := `\bpackage\s*(?P<package>` + fullIdent + `)\s*;` optionStmt := `\boption\s*(?P<optkey>` + fullIdent + `)\s*=\s*(?P<optval>` + strLit + `)\s*;` serviceStmt := `(?P<service>service)` comment := `//[^\n]*` protoReSrc := strings . Join ( [ ] string { importStmt , packageStmt , optionStmt , serviceStmt , comment } , " " ) return regexp . MustCompile ( protoReSrc ) } 
func ImportRepoRules ( filename string , repoCache * RemoteCache ) ( [ ] * rule . Rule , error ) { format := getLockFileFormat ( filename ) if format == unknownFormat { return nil , fmt . Errorf ( `%s: unrecognized lock file format. Expected "Gopkg.lock", "go.mod", or "Godeps.json"` , filename ) } parser := lockFileParsers [ format ] repos , err := parser ( filename , repoCache ) if err != nil { return nil , fmt . Errorf ( " " , filename , err ) } sort . Stable ( byName ( repos ) ) rules := make ( [ ] * rule . Rule , 0 , len ( repos ) ) for _ , repo := range repos { rules = append ( rules , GenerateRule ( repo ) ) } return rules , nil } 
func MergeRules ( genRules [ ] * rule . Rule , existingRules map [ * rule . File ] [ ] string , destFile * rule . File , kinds map [ string ] rule . KindInfo ) [ ] * rule . File { sort . Stable ( byRuleName ( genRules ) ) repoMap := make ( map [ string ] * rule . File ) for file , repoNames := range existingRules { if file . Path == destFile . Path && file . MacroName ( ) != " " && file . MacroName ( ) == destFile . MacroName ( ) { file = destFile } for _ , name := range repoNames { repoMap [ name ] = file } } rulesByFile := make ( map [ * rule . File ] [ ] * rule . Rule ) for _ , rule := range genRules { dest := destFile if file , ok := repoMap [ rule . Name ( ) ] ; ok { dest = file } rulesByFile [ dest ] = append ( rulesByFile [ dest ] , rule ) } updatedFiles := make ( map [ string ] * rule . File ) for f , rules := range rulesByFile { merger . MergeFile ( f , nil , rules , merger . PreResolve , kinds ) f . Sync ( ) if uf , ok := updatedFiles [ f . Path ] ; ok { uf . SyncMacroFile ( f ) } else { updatedFiles [ f . Path ] = f } } files := make ( [ ] * rule . File , 0 , len ( updatedFiles ) ) for _ , f := range updatedFiles { files = append ( files , f ) } return files } 
func GenerateRule ( repo Repo ) * rule . Rule { r := rule . NewRule ( " " , repo . Name ) if repo . Commit != " " { r . SetAttr ( " " , repo . Commit ) } if repo . Tag != " " { r . SetAttr ( " " , repo . Tag ) } r . SetAttr ( " " , repo . GoPrefix ) if repo . Remote != " " { r . SetAttr ( " " , repo . Remote ) } if repo . VCS != " " { r . SetAttr ( " " , repo . VCS ) } if repo . Version != " " { r . SetAttr ( " " , repo . Version ) } if repo . Sum != " " { r . SetAttr ( " " , repo . Sum ) } if repo . Replace != " " { r . SetAttr ( " " , repo . Replace ) } return r } 
func FindExternalRepo ( repoRoot , name string ) ( string , error ) { cleanPath , err := filepath . EvalSymlinks ( externalPath ) if err != nil { return " " , err } st , err := os . Stat ( cleanPath ) if err != nil { return " " , err } if ! st . IsDir ( ) { return " " , fmt . Errorf ( " " , externalPath ) } return cleanPath , nil } 
func ListRepositories ( workspace * rule . File ) ( repos [ ] Repo , repoNamesByFile map [ * rule . File ] [ ] string , err error ) { repoNamesByFile = make ( map [ * rule . File ] [ ] string ) repos , repoNamesByFile [ workspace ] = getRepos ( workspace . Rules ) for _ , d := range workspace . Directives { switch d . Key { case " " : f , defName , err := parseRepositoryMacroDirective ( d . Value ) if err != nil { return nil , nil , err } f = filepath . Join ( filepath . Dir ( workspace . Path ) , filepath . Clean ( f ) ) macroFile , err := rule . LoadMacroFile ( f , " " , defName ) if err != nil { return nil , nil , err } currRepos , names := getRepos ( macroFile . Rules ) repoNamesByFile [ macroFile ] = names repos = append ( repos , currRepos ... ) } } return repos , repoNamesByFile , nil } 
func migrateLibraryEmbed ( c * config . Config , f * rule . File ) { for _ , r := range f . Rules { if ! isGoRule ( r . Kind ( ) ) { continue } libExpr := r . Attr ( " " ) if libExpr == nil || rule . ShouldKeep ( libExpr ) || r . Attr ( " " ) != nil { continue } r . DelAttr ( " " ) r . SetAttr ( " " , & bzl . ListExpr { List : [ ] bzl . Expr { libExpr } } ) } } 
func migrateGrpcCompilers ( c * config . Config , f * rule . File ) { for _ , r := range f . Rules { if r . Kind ( ) != " " || r . ShouldKeep ( ) || r . Attr ( " " ) != nil { continue } r . SetKind ( " " ) r . SetAttr ( " " , [ ] string { grpcCompilerLabel } ) } } 
func squashCgoLibrary ( c * config . Config , f * rule . File ) { for _ , r := range f . Rules { if r . Kind ( ) == " " && r . Name ( ) == " " && ! r . ShouldKeep ( ) { if cgoLibrary != nil { log . Printf ( " " , f . Path ) continue } cgoLibrary = r continue } if r . Kind ( ) == " " && r . Name ( ) == defaultLibName { if goLibrary != nil { log . Printf ( " " , f . Path ) } goLibrary = r continue } } if cgoLibrary == nil { return } if ! c . ShouldFix { log . Printf ( " " , f . Path ) return } if goLibrary == nil { cgoLibrary . SetKind ( " " ) cgoLibrary . SetName ( defaultLibName ) cgoLibrary . SetAttr ( " " , true ) return } if err := rule . SquashRules ( cgoLibrary , goLibrary , f . Path ) ; err != nil { log . Print ( err ) return } goLibrary . DelAttr ( " " ) goLibrary . SetAttr ( " " , true ) cgoLibrary . Delete ( ) } 
func flattenSrcs ( c * config . Config , f * rule . File ) { for _ , r := range f . Rules { if ! isGoRule ( r . Kind ( ) ) { continue } oldSrcs := r . Attr ( " " ) if oldSrcs == nil { continue } flatSrcs := rule . FlattenExpr ( oldSrcs ) if flatSrcs != oldSrcs { r . SetAttr ( " " , flatSrcs ) } } } 
func removeLegacyProto ( c * config . Config , f * rule . File ) { } for _ , l := range f . Loads { if l . Name ( ) == " " { protoLoads = append ( protoLoads , l ) } } var protoFilegroups , protoRules [ ] * rule . Rule for _ , r := range f . Rules { if r . Kind ( ) == " " && r . Name ( ) == legacyProtoFilegroupName { protoFilegroups = append ( protoFilegroups , r ) } if r . Kind ( ) == " " { protoRules = append ( protoRules , r ) } } if len ( protoLoads ) + len ( protoFilegroups ) == 0 { return } if ! c . ShouldFix { log . Printf ( " " , f . Path ) return } } for _ , r := range protoFilegroups { r . Delete ( ) } if len ( protoLoads ) > 0 { for _ , r := range protoRules { r . Delete ( ) } } } 
func removeLegacyGazelle ( c * config . Config , f * rule . File ) { for _ , l := range f . Loads { if l . Name ( ) == " " && l . Has ( " " ) { l . Remove ( " " ) if l . IsEmpty ( ) { l . Delete ( ) } } } } 
func selectPackage ( c * config . Config , dir string , packageMap map [ string ] * goPackage ) ( * goPackage , error ) { buildablePackages := make ( map [ string ] * goPackage ) for name , pkg := range packageMap { if pkg . isBuildable ( c ) { buildablePackages [ name ] = pkg } } if len ( buildablePackages ) == 0 { return nil , & build . NoGoError { Dir : dir } } if len ( buildablePackages ) == 1 { for _ , pkg := range buildablePackages { return pkg , nil } } if pkg , ok := buildablePackages [ defaultPackageName ( c , dir ) ] ; ok { return pkg , nil } err := & build . MultiplePackageError { Dir : dir } for name , pkg := range buildablePackages { err . Files = append ( err . Files , pkg . firstGoFile ( ) ) } return nil , err } 
func ( g * generator ) options ( opts rule . PlatformStrings , pkgRel string ) rule . PlatformStrings { fixPath := func ( opt string ) string { if strings . HasPrefix ( opt , " " ) { return opt } return path . Clean ( path . Join ( pkgRel , opt ) ) } fixGroups := func ( groups [ ] string ) ( [ ] string , error ) { fixedGroups := make ( [ ] string , len ( groups ) ) for i , group := range groups { opts := strings . Split ( group , optSeparator ) fixedOpts := make ( [ ] string , len ( opts ) ) isPath := false for j , opt := range opts { if isPath { opt = fixPath ( opt ) isPath = false goto next } for _ , short := range shortOptPrefixes { if strings . HasPrefix ( opt , short ) && len ( opt ) > len ( short ) { opt = short + fixPath ( opt [ len ( short ) : ] ) goto next } } for _ , long := range longOptPrefixes { if opt == long { isPath = true goto next } } next : fixedOpts [ j ] = escapeOption ( opt ) } fixedGroups [ i ] = strings . Join ( fixedOpts , " " ) } return fixedGroups , nil } opts , errs := opts . MapSlice ( fixGroups ) if errs != nil { log . Panicf ( " " , pkgRel , errs ) } return opts } 
func ( mr * metaResolver ) AddBuiltin ( kindName string , resolver resolve . Resolver ) { mr . builtins [ kindName ] = resolver } 
func ( mr * metaResolver ) MappedKind ( pkgRel string , kind config . MappedKind ) { mr . mappedKinds [ pkgRel ] = append ( mr . mappedKinds [ pkgRel ] , kind ) } 
func ( mr metaResolver ) Resolver ( r * rule . Rule , pkgRel string ) resolve . Resolver { for _ , mappedKind := range mr . mappedKinds [ pkgRel ] { if mappedKind . KindName == r . Kind ( ) { return mr . builtins [ mappedKind . FromKind ] } } return mr . builtins [ r . Kind ( ) ] } 
func sortExprLabels ( e bzl . Expr , _ [ ] bzl . Expr ) { list , ok := e . ( * bzl . ListExpr ) if ! ok || len ( list . List ) == 0 { return } keys := make ( [ ] stringSortKey , len ( list . List ) ) for i , elem := range list . List { s , ok := elem . ( * bzl . StringExpr ) if ! ok { return } keys [ i ] = makeSortKey ( i , s ) } before := keys [ 0 ] . x . Comment ( ) . Before keys [ 0 ] . x . Comment ( ) . Before = nil sort . Sort ( byStringExpr ( keys ) ) keys [ 0 ] . x . Comment ( ) . Before = append ( before , keys [ 0 ] . x . Comment ( ) . Before ... ) for i , k := range keys { list . List [ i ] = k . x } } 
func checkRulesGoVersion ( repoRoot string ) { const message = `Gazelle may not be compatible with this version of rules_go. Update io_bazel_rules_go to a newer version in your WORKSPACE file.` rulesGoPath , err := repo . FindExternalRepo ( repoRoot , config . RulesGoRepoName ) if err != nil { return } defBzlPath := filepath . Join ( rulesGoPath , " " , " " ) defBzlContent , err := ioutil . ReadFile ( defBzlPath ) if err != nil { return } versionRe := regexp . MustCompile ( `(?m)^RULES_GO_VERSION = ['"]([0-9.]*)['"]` ) match := versionRe . FindSubmatch ( defBzlContent ) if match == nil { log . Printf ( " \n " , config . RulesGoRepoName , message ) return } vstr := string ( match [ 1 ] ) v , err := version . ParseVersion ( vstr ) if err != nil { log . Printf ( " \n " , vstr , config . RulesGoRepoName , message ) } if v . Compare ( minimumRulesGoVersion ) < 0 { log . Printf ( " \n " , v , minimumRulesGoVersion , message ) } } 
func ( gc * goConfig ) preprocessTags ( ) { if gc . genericTags == nil { gc . genericTags = make ( map [ string ] bool ) } gc . genericTags [ " " ] = true } 
func ( gc * goConfig ) setBuildTags ( tags string ) error { if tags == " " { return nil } for _ , t := range strings . Split ( tags , " " ) { if strings . HasPrefix ( t , " " ) { return fmt . Errorf ( " " , t ) } gc . genericTags [ t ] = true } return nil } 
func checkPrefix ( prefix string ) error { if strings . HasPrefix ( prefix , " " ) || build . IsLocalImport ( prefix ) { return fmt . Errorf ( " " , prefix ) } return nil } 
func splitValue ( value string ) [ ] string { parts := strings . Split ( value , " " ) values := make ( [ ] string , 0 , len ( parts ) ) for _ , part := range parts { values = append ( values , strings . TrimSpace ( part ) ) } return values } 
func copyGoModToTemp ( filename string ) ( tempDir string , err error ) { goModOrig , err := os . Open ( filename ) if err != nil { return " " , err } defer goModOrig . Close ( ) tempDir , err = ioutil . TempDir ( " " , " " ) if err != nil { return " " , err } goModCopy , err := os . Create ( filepath . Join ( tempDir , " " ) ) if err != nil { os . Remove ( tempDir ) return " " , err } defer func ( ) { if cerr := goModCopy . Close ( ) ; err == nil && cerr != nil { err = cerr } } ( ) _ , err = io . Copy ( goModCopy , goModOrig ) if err != nil { os . RemoveAll ( tempDir ) return " " , err } return tempDir , err } 
func findGoTool ( ) string { path := " " if goroot , ok := os . LookupEnv ( " " ) ; ok { path = filepath . Join ( goroot , " " , " " ) } if runtime . GOOS == " " { path += " " } return path } 
func ( pkg * goPackage ) addFile ( c * config . Config , info fileInfo , cgo bool ) error { switch { case info . ext == unknownExt || ! cgo && ( info . ext == cExt || info . ext == csExt ) : return nil case info . ext == protoExt : if pcMode := getProtoMode ( c ) ; pcMode == proto . LegacyMode { } case info . isTest : if info . isCgo { return fmt . Errorf ( " " , info . path ) } pkg . test . addFile ( c , info ) default : pkg . library . addFile ( c , info ) } return nil } 
func ( pkg * goPackage ) isBuildable ( c * config . Config ) bool { return pkg . firstGoFile ( ) != " " || ! pkg . proto . sources . isEmpty ( ) } 
func ( pkg * goPackage ) firstGoFile ( ) string { goSrcs := [ ] platformStringsBuilder { pkg . library . sources , pkg . binary . sources , pkg . test . sources , } for _ , sb := range goSrcs { if sb . strs != nil { for s := range sb . strs { if strings . HasSuffix ( s , " " ) { return s } } } } return " " } 
func getPlatformStringsAddFunction ( c * config . Config , info fileInfo , cgoTags tagLine ) func ( sb * platformStringsBuilder , ss ... string ) { isOSSpecific , isArchSpecific := isOSArchSpecific ( info , cgoTags ) switch { case ! isOSSpecific && ! isArchSpecific : if checkConstraints ( c , " " , " " , info . goos , info . goarch , info . tags , cgoTags ) { return func ( sb * platformStringsBuilder , ss ... string ) { for _ , s := range ss { sb . addGenericString ( s ) } } } case isOSSpecific && ! isArchSpecific : var osMatch [ ] string for _ , os := range rule . KnownOSs { if checkConstraints ( c , os , " " , info . goos , info . goarch , info . tags , cgoTags ) { osMatch = append ( osMatch , os ) } } if len ( osMatch ) > 0 { return func ( sb * platformStringsBuilder , ss ... string ) { for _ , s := range ss { sb . addOSString ( s , osMatch ) } } } case ! isOSSpecific && isArchSpecific : var archMatch [ ] string for _ , arch := range rule . KnownArchs { if checkConstraints ( c , " " , arch , info . goos , info . goarch , info . tags , cgoTags ) { archMatch = append ( archMatch , arch ) } } if len ( archMatch ) > 0 { return func ( sb * platformStringsBuilder , ss ... string ) { for _ , s := range ss { sb . addArchString ( s , archMatch ) } } } default : var platformMatch [ ] rule . Platform for _ , platform := range rule . KnownPlatforms { if checkConstraints ( c , platform . OS , platform . Arch , info . goos , info . goarch , info . tags , cgoTags ) { platformMatch = append ( platformMatch , platform ) } } if len ( platformMatch ) > 0 { return func ( sb * platformStringsBuilder , ss ... string ) { for _ , s := range ss { sb . addPlatformString ( s , platformMatch ) } } } } return func ( _ * platformStringsBuilder , _ ... string ) { } } 
func startServer ( ) error { exe , err := os . Executable ( ) if err != nil { return err } args := [ ] string { " " } args = append ( args , os . Args [ 1 : ] ... ) cmd := exec . Command ( exe , args ... ) log . Printf ( " " , strings . Join ( cmd . Args , " " ) ) if err := cmd . Start ( ) ; err != nil { return err } if err := cmd . Process . Release ( ) ; err != nil { return err } return nil } 
func runServer ( ) error { if err != nil { return err } defer logFile . Close ( ) log . SetOutput ( logFile ) ln , err := net . Listen ( " " , * socketPath ) if err != nil { return err } uln := ln . ( * net . UnixListener ) uln . SetUnlinkOnClose ( true ) defer ln . Close ( ) if err := uln . SetDeadline ( time . Now ( ) . Add ( * serverTimeout ) ) ; err != nil { return err } log . Printf ( " " , os . Getpid ( ) ) isWatching := err == nil if err != nil { log . Print ( err ) } if isWatching { defer cancelWatch ( ) } for { c , err := ln . Accept ( ) if err != nil { if operr , ok := err . ( * net . OpError ) ; ok { if operr . Timeout ( ) { return nil } if operr . Temporary ( ) { log . Printf ( " " , err ) continue } } return err } log . SetOutput ( io . MultiWriter ( c , logFile ) ) dirs := getAndClearWrittenDirs ( ) for _ , dir := range dirs { restoreBuildFilesInDir ( dir ) } if err := runGazelle ( mode , dirs ) ; err != nil { log . Print ( err ) } log . SetOutput ( logFile ) c . Close ( ) if isWatching { mode = fastMode } } } 
func watchDir ( root string , record func ( string ) ) ( cancel func ( ) , err error ) { w , err := fsnotify . NewWatcher ( ) if err != nil { return nil , err } dirs , errs := listDirs ( root ) for _ , err := range errs { log . Print ( err ) } gitDir := filepath . Join ( root , " " ) for _ , dir := range dirs { if dir == gitDir { continue } if err := w . Add ( dir ) ; err != nil { log . Print ( err ) } } done := make ( chan struct { } ) go func ( ) { for { select { case ev := <- w . Events : if shouldIgnore ( ev . Name ) { continue } if ev . Op == fsnotify . Create { if st , err := os . Lstat ( ev . Name ) ; err != nil { log . Print ( err ) } else if st . IsDir ( ) { dirs , errs := listDirs ( ev . Name ) for _ , err := range errs { log . Print ( err ) } for _ , dir := range dirs { if err := w . Add ( dir ) ; err != nil { log . Print ( err ) } recordWrite ( dir ) } } } else { recordWrite ( filepath . Dir ( ev . Name ) ) } case err := <- w . Errors : log . Print ( err ) case <- done : if err := w . Close ( ) ; err != nil { log . Print ( err ) } return } } } ( ) return func ( ) { close ( done ) } , nil } 
func listDirs ( dir string ) ( [ ] string , [ ] error ) { var dirs [ ] string var errs [ ] error err := filepath . Walk ( dir , func ( path string , info os . FileInfo , err error ) error { if err != nil { errs = append ( errs , err ) return nil } if info . IsDir ( ) { dirs = append ( dirs , path ) } return nil } ) if err != nil { errs = append ( errs , err ) } return dirs , errs } 
func shouldIgnore ( p string ) bool { p = strings . TrimPrefix ( filepath . ToSlash ( p ) , " " ) base := path . Base ( p ) return strings . HasPrefix ( p , " " ) || base == " " || base == " " || base == " " } 
func recordWrite ( path string ) { dirSetMutex . Lock ( ) defer dirSetMutex . Unlock ( ) dirSet [ path ] = true } 
func getAndClearWrittenDirs ( ) [ ] string { dirSetMutex . Lock ( ) defer dirSetMutex . Unlock ( ) dirs := make ( [ ] string , 0 , len ( dirSet ) ) for d := range dirSet { dirs = append ( dirs , d ) } dirSet = make ( map [ string ] bool ) return dirs } 
func Start ( command * exec . Cmd , outWriter io . Writer , errWriter io . Writer ) ( * Session , error ) { exited := make ( chan struct { } ) session := & Session { Command : command , Out : gbytes . NewBuffer ( ) , Err : gbytes . NewBuffer ( ) , Exited : exited , lock : & sync . Mutex { } , exitCode : - 1 , } var commandOut , commandErr io . Writer commandOut , commandErr = session . Out , session . Err if outWriter != nil { commandOut = io . MultiWriter ( commandOut , outWriter ) } if errWriter != nil { commandErr = io . MultiWriter ( commandErr , errWriter ) } command . Stdout = commandOut command . Stderr = commandErr err := command . Start ( ) if err == nil { go session . monitorForExit ( exited ) trackedSessionsMutex . Lock ( ) defer trackedSessionsMutex . Unlock ( ) trackedSessions = append ( trackedSessions , session ) } return session , err } 
func ( s * Session ) ExitCode ( ) int { s . lock . Lock ( ) defer s . lock . Unlock ( ) return s . exitCode } 
func ( s * Session ) Wait ( timeout ... interface { } ) * Session { EventuallyWithOffset ( 1 , s , timeout ... ) . Should ( Exit ( ) ) return s } 
func ( s * Session ) Signal ( signal os . Signal ) * Session { if s . processIsAlive ( ) { s . Command . Process . Signal ( signal ) } return s } 
func KillAndWait ( timeout ... interface { } ) { trackedSessionsMutex . Lock ( ) defer trackedSessionsMutex . Unlock ( ) for _ , session := range trackedSessions { session . Kill ( ) . Wait ( timeout ... ) } trackedSessions = [ ] * Session { } } 
func TerminateAndWait ( timeout ... interface { } ) { trackedSessionsMutex . Lock ( ) defer trackedSessionsMutex . Unlock ( ) for _ , session := range trackedSessions { session . Terminate ( ) . Wait ( timeout ... ) } } 
func Kill ( ) { trackedSessionsMutex . Lock ( ) defer trackedSessionsMutex . Unlock ( ) for _ , session := range trackedSessions { session . Kill ( ) } } 
func Terminate ( ) { trackedSessionsMutex . Lock ( ) defer trackedSessionsMutex . Unlock ( ) for _ , session := range trackedSessions { session . Terminate ( ) } } 
func Signal ( signal os . Signal ) { trackedSessionsMutex . Lock ( ) defer trackedSessionsMutex . Unlock ( ) for _ , session := range trackedSessions { session . Signal ( signal ) } } 
func Interrupt ( ) { trackedSessionsMutex . Lock ( ) defer trackedSessionsMutex . Unlock ( ) for _ , session := range trackedSessions { session . Interrupt ( ) } } 
func CombineHandlers ( handlers ... http . HandlerFunc ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { for _ , handler := range handlers { handler ( w , req ) } } } 
func VerifyRequest ( method string , path interface { } , rawQuery ... string ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { Expect ( req . Method ) . Should ( Equal ( method ) , " " ) switch p := path . ( type ) { case types . GomegaMatcher : Expect ( req . URL . Path ) . Should ( p , " " ) default : Expect ( req . URL . Path ) . Should ( Equal ( path ) , " " ) } if len ( rawQuery ) > 0 { values , err := url . ParseQuery ( rawQuery [ 0 ] ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) , " " ) Expect ( req . URL . Query ( ) ) . Should ( Equal ( values ) , " " ) } } } 
func VerifyContentType ( contentType string ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { Expect ( req . Header . Get ( " " ) ) . Should ( Equal ( contentType ) ) } } 
func VerifyMimeType ( mimeType string ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { Expect ( strings . Split ( req . Header . Get ( " " ) , " " ) [ 0 ] ) . Should ( Equal ( mimeType ) ) } } 
func VerifyBasicAuth ( username string , password string ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { auth := req . Header . Get ( " " ) Expect ( auth ) . ShouldNot ( Equal ( " " ) , " " ) decoded , err := base64 . StdEncoding . DecodeString ( auth [ 6 : ] ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) Expect ( string ( decoded ) ) . Should ( Equal ( fmt . Sprintf ( " " , username , password ) ) , " " ) } } 
func VerifyHeader ( header http . Header ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { for key , values := range header { key = http . CanonicalHeaderKey ( key ) Expect ( req . Header [ key ] ) . Should ( Equal ( values ) , " " , key ) } } } 
func VerifyHeaderKV ( key string , values ... string ) http . HandlerFunc { return VerifyHeader ( http . Header { key : values } ) } 
func VerifyBody ( expectedBody [ ] byte ) http . HandlerFunc { return CombineHandlers ( func ( w http . ResponseWriter , req * http . Request ) { body , err := ioutil . ReadAll ( req . Body ) req . Body . Close ( ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) Expect ( body ) . Should ( Equal ( expectedBody ) , " " ) } , ) } 
func VerifyJSON ( expectedJSON string ) http . HandlerFunc { return CombineHandlers ( VerifyMimeType ( " " ) , func ( w http . ResponseWriter , req * http . Request ) { body , err := ioutil . ReadAll ( req . Body ) req . Body . Close ( ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) Expect ( body ) . Should ( MatchJSON ( expectedJSON ) , " " ) } , ) } 
func VerifyJSONRepresenting ( object interface { } ) http . HandlerFunc { data , err := json . Marshal ( object ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) return CombineHandlers ( VerifyContentType ( " " ) , VerifyJSON ( string ( data ) ) , ) } 
func VerifyForm ( values url . Values ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { err := r . ParseForm ( ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) for key , vals := range values { Expect ( r . Form [ key ] ) . Should ( Equal ( vals ) , " " , key ) } } } 
func VerifyFormKV ( key string , values ... string ) http . HandlerFunc { return VerifyForm ( url . Values { key : values } ) } 
func VerifyProtoRepresenting ( expected proto . Message ) http . HandlerFunc { return CombineHandlers ( VerifyContentType ( " " ) , func ( w http . ResponseWriter , req * http . Request ) { body , err := ioutil . ReadAll ( req . Body ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) req . Body . Close ( ) expectedType := reflect . TypeOf ( expected ) actualValuePtr := reflect . New ( expectedType . Elem ( ) ) actual , ok := actualValuePtr . Interface ( ) . ( proto . Message ) Expect ( ok ) . Should ( BeTrue ( ) , " " ) err = proto . Unmarshal ( body , actual ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) , " " ) Expect ( actual ) . Should ( Equal ( expected ) , " " ) } , ) } 
func RespondWith ( statusCode int , body interface { } , optionalHeader ... http . Header ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { if len ( optionalHeader ) == 1 { copyHeader ( optionalHeader [ 0 ] , w . Header ( ) ) } w . WriteHeader ( statusCode ) switch x := body . ( type ) { case string : w . Write ( [ ] byte ( x ) ) case [ ] byte : w . Write ( x ) default : Expect ( body ) . Should ( BeNil ( ) , " " ) } } } 
func RespondWithJSONEncoded ( statusCode int , object interface { } , optionalHeader ... http . Header ) http . HandlerFunc { data , err := json . Marshal ( object ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) var headers http . Header if len ( optionalHeader ) == 1 { headers = optionalHeader [ 0 ] } else { headers = make ( http . Header ) } if _ , found := headers [ " " ] ; ! found { headers [ " " ] = [ ] string { " " } } return RespondWith ( statusCode , string ( data ) , headers ) } 
func RespondWithJSONEncodedPtr ( statusCode * int , object interface { } , optionalHeader ... http . Header ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { data , err := json . Marshal ( object ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) var headers http . Header if len ( optionalHeader ) == 1 { headers = optionalHeader [ 0 ] } else { headers = make ( http . Header ) } if _ , found := headers [ " " ] ; ! found { headers [ " " ] = [ ] string { " " } } copyHeader ( headers , w . Header ( ) ) w . WriteHeader ( * statusCode ) w . Write ( data ) } } 
func RespondWithProto ( statusCode int , message proto . Message , optionalHeader ... http . Header ) http . HandlerFunc { return func ( w http . ResponseWriter , req * http . Request ) { data , err := proto . Marshal ( message ) Expect ( err ) . ShouldNot ( HaveOccurred ( ) ) var headers http . Header if len ( optionalHeader ) == 1 { headers = optionalHeader [ 0 ] } else { headers = make ( http . Header ) } if _ , found := headers [ " " ] ; ! found { headers [ " " ] = [ ] string { " " } } copyHeader ( headers , w . Header ( ) ) w . WriteHeader ( statusCode ) w . Write ( data ) } } 
func RegisterFailHandlerWithT ( t types . TWithHelper , handler types . GomegaFailHandler ) { if handler == nil { globalFailWrapper = nil return } globalFailWrapper = & types . GomegaFailWrapper { Fail : handler , TWithHelper : t , } } 
func InterceptGomegaFailures ( f func ( ) ) [ ] string { originalHandler := globalFailWrapper . Fail failures := [ ] string { } RegisterFailHandler ( func ( message string , callerSkip ... int ) { failures = append ( failures , message ) } ) f ( ) RegisterFailHandler ( originalHandler ) return failures } 
func ExpectWithOffset ( offset int , actual interface { } , extra ... interface { } ) Assertion { if globalFailWrapper == nil { panic ( nilFailHandlerPanic ) } return assertion . New ( actual , globalFailWrapper , offset , extra ... ) } 
func EventuallyWithOffset ( offset int , actual interface { } , intervals ... interface { } ) AsyncAssertion { if globalFailWrapper == nil { panic ( nilFailHandlerPanic ) } timeoutInterval := defaultEventuallyTimeout pollingInterval := defaultEventuallyPollingInterval if len ( intervals ) > 0 { timeoutInterval = toDuration ( intervals [ 0 ] ) } if len ( intervals ) > 1 { pollingInterval = toDuration ( intervals [ 1 ] ) } return asyncassertion . New ( asyncassertion . AsyncAssertionTypeEventually , actual , globalFailWrapper , timeoutInterval , pollingInterval , offset ) } 
func ConsistentlyWithOffset ( offset int , actual interface { } , intervals ... interface { } ) AsyncAssertion { if globalFailWrapper == nil { panic ( nilFailHandlerPanic ) } timeoutInterval := defaultConsistentlyDuration pollingInterval := defaultConsistentlyPollingInterval if len ( intervals ) > 0 { timeoutInterval = toDuration ( intervals [ 0 ] ) } if len ( intervals ) > 1 { pollingInterval = toDuration ( intervals [ 1 ] ) } return asyncassertion . New ( asyncassertion . AsyncAssertionTypeConsistently , actual , globalFailWrapper , timeoutInterval , pollingInterval , offset ) } 
func ( g * WithT ) Expect ( actual interface { } , extra ... interface { } ) Assertion { return assertion . New ( actual , testingtsupport . BuildTestingTGomegaFailWrapper ( g . t ) , 0 , extra ... ) } 
func ( g * WithT ) Eventually ( actual interface { } , intervals ... interface { } ) AsyncAssertion { timeoutInterval := defaultEventuallyTimeout pollingInterval := defaultEventuallyPollingInterval if len ( intervals ) > 0 { timeoutInterval = toDuration ( intervals [ 0 ] ) } if len ( intervals ) > 1 { pollingInterval = toDuration ( intervals [ 1 ] ) } return asyncassertion . New ( asyncassertion . AsyncAssertionTypeEventually , actual , testingtsupport . BuildTestingTGomegaFailWrapper ( g . t ) , timeoutInterval , pollingInterval , 0 ) } 
func ( g * WithT ) Consistently ( actual interface { } , intervals ... interface { } ) AsyncAssertion { timeoutInterval := defaultConsistentlyDuration pollingInterval := defaultConsistentlyPollingInterval if len ( intervals ) > 0 { timeoutInterval = toDuration ( intervals [ 0 ] ) } if len ( intervals ) > 1 { pollingInterval = toDuration ( intervals [ 1 ] ) } return asyncassertion . New ( asyncassertion . AsyncAssertionTypeConsistently , actual , testingtsupport . BuildTestingTGomegaFailWrapper ( g . t ) , timeoutInterval , pollingInterval , 0 ) } 
func Message ( actual interface { } , message string , expected ... interface { } ) string { if len ( expected ) == 0 { return fmt . Sprintf ( " \n \n " , Object ( actual , 1 ) , message ) } return fmt . Sprintf ( " \n \n \n " , Object ( actual , 1 ) , message , Object ( expected [ 0 ] , 1 ) ) } 
func Object ( object interface { } , indentation uint ) string { indent := strings . Repeat ( Indent , int ( indentation ) ) value := reflect . ValueOf ( object ) return fmt . Sprintf ( " " , indent , formatType ( object ) , formatValue ( value , indentation ) ) } 
func IndentString ( s string , indentation uint ) string { components := strings . Split ( s , " \n " ) result := " " indent := strings . Repeat ( Indent , int ( indentation ) ) for i , component := range components { result += indent + component if i < len ( components ) - 1 { result += " \n " } } return result } 
func isPrintableString ( str string ) bool { for _ , runeValue := range str { if ! strconv . IsPrint ( runeValue ) { return false } } return true } 
func Exit ( optionalExitCode ... int ) * exitMatcher { exitCode := - 1 if len ( optionalExitCode ) > 0 { exitCode = optionalExitCode [ 0 ] } return & exitMatcher { exitCode : exitCode , } } 
func MatchFields ( options Options , fields Fields ) types . GomegaMatcher { return & FieldsMatcher { Fields : fields , IgnoreExtras : options & IgnoreExtras != 0 , IgnoreMissing : options & IgnoreMissing != 0 , } } 
func Say ( expected string , args ... interface { } ) * sayMatcher { if len ( args ) > 0 { expected = fmt . Sprintf ( expected , args ... ) } return & sayMatcher { re : regexp . MustCompile ( expected ) , } } 
func Receive ( args ... interface { } ) types . GomegaMatcher { var arg interface { } if len ( args ) > 0 { arg = args [ 0 ] } return & matchers . ReceiveMatcher { Arg : arg , } } 
func MatchRegexp ( regexp string , args ... interface { } ) types . GomegaMatcher { return & matchers . MatchRegexpMatcher { Regexp : regexp , Args : args , } } 
func ContainSubstring ( substr string , args ... interface { } ) types . GomegaMatcher { return & matchers . ContainSubstringMatcher { Substr : substr , Args : args , } } 
func HavePrefix ( prefix string , args ... interface { } ) types . GomegaMatcher { return & matchers . HavePrefixMatcher { Prefix : prefix , Args : args , } } 
func HaveSuffix ( suffix string , args ... interface { } ) types . GomegaMatcher { return & matchers . HaveSuffixMatcher { Suffix : suffix , Args : args , } } 
func HaveKeyWithValue ( key interface { } , value interface { } ) types . GomegaMatcher { return & matchers . HaveKeyWithValueMatcher { Key : key , Value : value , } } 
func BeNumerically ( comparator string , compareTo ... interface { } ) types . GomegaMatcher { return & matchers . BeNumericallyMatcher { Comparator : comparator , CompareTo : compareTo , } } 
func BeTemporally ( comparator string , compareTo time . Time , threshold ... time . Duration ) types . GomegaMatcher { return & matchers . BeTemporallyMatcher { Comparator : comparator , CompareTo : compareTo , Threshold : threshold , } } 
func And ( ms ... types . GomegaMatcher ) types . GomegaMatcher { return & matchers . AndMatcher { Matchers : ms } } 
func Or ( ms ... types . GomegaMatcher ) types . GomegaMatcher { return & matchers . OrMatcher { Matchers : ms } } 
func Not ( matcher types . GomegaMatcher ) types . GomegaMatcher { return & matchers . NotMatcher { Matcher : matcher } } 
func WithTransform ( transform interface { } , matcher types . GomegaMatcher ) types . GomegaMatcher { return matchers . NewWithTransformMatcher ( transform , matcher ) } 
func Build ( packagePath string , args ... string ) ( compiledPath string , err error ) { return doBuild ( build . Default . GOPATH , packagePath , nil , args ... ) } 
func BuildWithEnvironment ( packagePath string , env [ ] string , args ... string ) ( compiledPath string , err error ) { return doBuild ( build . Default . GOPATH , packagePath , env , args ... ) } 
func BuildIn ( gopath string , packagePath string , args ... string ) ( compiledPath string , err error ) { return doBuild ( gopath , packagePath , nil , args ... ) } 
func CleanupBuildArtifacts ( ) { mu . Lock ( ) defer mu . Unlock ( ) if tmpDir != " " { os . RemoveAll ( tmpDir ) tmpDir = " " } } 
func TimeoutCloser ( c io . Closer , timeout time . Duration ) io . Closer { return timeoutReaderWriterCloser { c : c , d : timeout } } 
func TimeoutReader ( r io . Reader , timeout time . Duration ) io . Reader { return timeoutReaderWriterCloser { r : r , d : timeout } } 
func TimeoutWriter ( w io . Writer , timeout time . Duration ) io . Writer { return timeoutReaderWriterCloser { w : w , d : timeout } } 
func BufferWithBytes ( bytes [ ] byte ) * Buffer { return & Buffer { lock : & sync . Mutex { } , contents : bytes , } } 
func BufferReader ( reader io . Reader ) * Buffer { b := & Buffer { lock : & sync . Mutex { } , } go func ( ) { io . Copy ( b , reader ) b . Close ( ) } ( ) return b } 
func ( b * Buffer ) Write ( p [ ] byte ) ( n int , err error ) { b . lock . Lock ( ) defer b . lock . Unlock ( ) if b . closed { return 0 , errors . New ( " " ) } b . contents = append ( b . contents , p ... ) return len ( p ) , nil } 
func ( b * Buffer ) Read ( d [ ] byte ) ( int , error ) { b . lock . Lock ( ) defer b . lock . Unlock ( ) if b . closed { return 0 , errors . New ( " " ) } if uint64 ( len ( b . contents ) ) <= b . readCursor { return 0 , io . EOF } n := copy ( d , b . contents [ b . readCursor : ] ) b . readCursor += uint64 ( n ) return n , nil } 
func ( b * Buffer ) Close ( ) error { b . lock . Lock ( ) defer b . lock . Unlock ( ) b . closed = true return nil } 
func ( b * Buffer ) Closed ( ) bool { b . lock . Lock ( ) defer b . lock . Unlock ( ) return b . closed } 
func ( b * Buffer ) Contents ( ) [ ] byte { b . lock . Lock ( ) defer b . lock . Unlock ( ) contents := make ( [ ] byte , len ( b . contents ) ) copy ( contents , b . contents ) return contents } 
func ( b * Buffer ) Detect ( desired string , args ... interface { } ) chan bool { formattedRegexp := desired if len ( args ) > 0 { formattedRegexp = fmt . Sprintf ( desired , args ... ) } re := regexp . MustCompile ( formattedRegexp ) b . lock . Lock ( ) defer b . lock . Unlock ( ) if b . detectCloser == nil { b . detectCloser = make ( chan interface { } ) } closer := b . detectCloser response := make ( chan bool ) go func ( ) { ticker := time . NewTicker ( 10 * time . Millisecond ) defer ticker . Stop ( ) defer close ( response ) for { select { case <- ticker . C : b . lock . Lock ( ) data , cursor := b . contents [ b . readCursor : ] , b . readCursor loc := re . FindIndex ( data ) b . lock . Unlock ( ) if loc != nil { response <- true b . lock . Lock ( ) newCursorPosition := cursor + uint64 ( loc [ 1 ] ) if newCursorPosition >= b . readCursor { b . readCursor = newCursorPosition } b . lock . Unlock ( ) return } case <- closer : return } } } ( ) return response } 
func ( b * Buffer ) CancelDetects ( ) { b . lock . Lock ( ) defer b . lock . Unlock ( ) close ( b . detectCloser ) b . detectCloser = nil } 
func Nest ( path string , err error ) error { if ag , ok := err . ( AggregateError ) ; ok { var errs AggregateError for _ , e := range ag { errs = append ( errs , Nest ( path , e ) ) } return errs } if ne , ok := err . ( * NestedError ) ; ok { return & NestedError { Path : path + ne . Path , Err : ne . Err , } } return & NestedError { Path : path , Err : err , } } 
func ( err AggregateError ) Error ( ) string { if len ( err ) == 0 { } if len ( err ) == 1 { return err [ 0 ] . Error ( ) } result := fmt . Sprintf ( " " , err [ 0 ] . Error ( ) ) for i := 1 ; i < len ( err ) ; i ++ { result += fmt . Sprintf ( " " , err [ i ] . Error ( ) ) } result += " " return result } 
func MatchAllElements ( identifier Identifier , elements Elements ) types . GomegaMatcher { return & ElementsMatcher { Identifier : identifier , Elements : elements , } } 
func MatchElements ( identifier Identifier , options Options , elements Elements ) types . GomegaMatcher { return & ElementsMatcher { Identifier : identifier , Elements : elements , IgnoreExtras : options & IgnoreExtras != 0 , IgnoreMissing : options & IgnoreMissing != 0 , AllowDuplicates : options & AllowDuplicates != 0 , } } 
func SetMockService ( m * MockService ) { m . Cache = & cache . MockAppCacheService { } m . Plan = & app . MockPlanService { } m . Platform = & app . MockPlatformService { } m . PlatformImage = & image . MockPlatformImageService { } m . Team = & auth . MockTeamService { } m . UserQuota = & quota . MockQuotaService { } m . AppQuota = & quota . MockQuotaService { } m . Cluster = & provision . MockClusterService { } m . ServiceBroker = & service . MockServiceBrokerService { } m . ServiceBrokerCatalogCache = & service . MockServiceBrokerCatalogCacheService { } servicemanager . AppCache = m . Cache servicemanager . Plan = m . Plan servicemanager . Platform = m . Platform servicemanager . PlatformImage = m . PlatformImage servicemanager . Team = m . Team servicemanager . UserQuota = m . UserQuota servicemanager . AppQuota = m . AppQuota servicemanager . Cluster = m . Cluster servicemanager . ServiceBroker = m . ServiceBroker servicemanager . ServiceBrokerCatalogCache = m . ServiceBrokerCatalogCache } 
func Open ( addr , dbname string ) ( storage * Storage , err error ) { sessionLock . RLock ( ) if sessions [ addr ] == nil { sessionLock . RUnlock ( ) sessionLock . Lock ( ) if sessions [ addr ] == nil { sessions [ addr ] , err = open ( addr ) } sessionLock . Unlock ( ) if err != nil { return } } else { sessionLock . RUnlock ( ) } cloned := sessions [ addr ] . Clone ( ) runtime . SetFinalizer ( cloned , sessionFinalizer ) storage = & Storage { session : cloned , dbname : dbname , } return } 
func FindMachineByIdOrAddress ( id string , address string ) ( Machine , error ) { coll , err := collection ( ) if err != nil { return Machine { } , err } defer coll . Close ( ) var result Machine query := bson . M { } if id != " " { query [ " " ] = id } else { query [ " " ] = address } err = coll . Find ( query ) . One ( & result ) if err == mgo . ErrNotFound { err = ErrMachineNotFound } return result , err } 
func ( w * FlushingWriter ) Write ( data [ ] byte ) ( written int , err error ) { w . writeMutex . Lock ( ) defer w . writeMutex . Unlock ( ) w . wrote = true written , err = w . ResponseWriter . Write ( data ) if err != nil { return } if f , ok := w . ResponseWriter . ( http . Flusher ) ; ok { defer func ( ) { if r := recover ( ) ; r != nil { msg := fmt . Sprintf ( " " , r ) log . Debugf ( msg ) err = errors . Errorf ( msg ) } } ( ) f . Flush ( ) } return } 
func ( w * FlushingWriter ) Hijack ( ) ( net . Conn , * bufio . ReadWriter , error ) { if hijacker , ok := w . ResponseWriter . ( http . Hijacker ) ; ok { return hijacker . Hijack ( ) } return nil , nil , errors . New ( " " ) } 
func ListDeploys ( filter * Filter , skip , limit int ) ( [ ] DeployData , error ) { appsList , err := List ( filter ) if err != nil { return nil , err } apps := make ( [ ] string , len ( appsList ) ) for i , a := range appsList { apps [ i ] = a . GetName ( ) } evts , err := event . List ( & event . Filter { Target : event . Target { Type : event . TargetTypeApp } , Raw : bson . M { " " : bson . M { " " : apps } } , KindNames : [ ] string { permission . PermAppDeploy . FullName ( ) } , KindType : event . KindTypePermission , Limit : limit , Skip : skip , } ) if err != nil { return nil , err } validImages , err := findValidImages ( appsList ... ) if err != nil { return nil , err } list := make ( [ ] DeployData , len ( evts ) ) for i := range evts { list [ i ] = * eventToDeployData ( & evts [ i ] , validImages , false ) } return list , nil } 
func Deploy ( opts DeployOptions ) ( string , error ) { if opts . Event == nil { return " " , errors . Errorf ( " " ) } if opts . Rollback && ! regexp . MustCompile ( " " ) . MatchString ( opts . Image ) { imageName , err := image . GetAppImageBySuffix ( opts . App . Name , opts . Image ) if err != nil { return " " , err } opts . Image = imageName } logWriter := LogWriter { App : opts . App } logWriter . Async ( ) defer logWriter . Close ( ) opts . Event . SetLogWriter ( io . MultiWriter ( & tsuruIo . NoErrorWriter { Writer : opts . OutputStream } , & logWriter ) ) imageID , err := deployToProvisioner ( & opts , opts . Event ) rebuild . RoutesRebuildOrEnqueue ( opts . App . Name ) quotaErr := opts . App . fixQuota ( ) if quotaErr != nil { log . Errorf ( " " , quotaErr ) } if err != nil { var logLines [ ] Applog if provision . IsStartupError ( err ) { logLines , _ = opts . App . lastLogs ( 10 , Applog { Source : " " , } , true ) } err = & errorWithLog { err : err , logs : logLines } return " " , err } err = incrementDeploy ( opts . App ) if err != nil { log . Errorf ( " " , opts ) } if opts . Kind == DeployImage || opts . Kind == DeployRollback { if ! opts . App . UpdatePlatform { opts . App . SetUpdatePlatform ( true ) } } else if opts . App . UpdatePlatform { opts . App . SetUpdatePlatform ( false ) } return imageID , nil } 
func eventList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { var filter * event . Filter err := ParseInput ( r , & filter ) if err != nil { return err } filter . LoadKindNames ( r . Form ) filter . PruneUserValues ( ) filter . Permissions , err = t . Permissions ( ) if err != nil { return err } events , err := event . List ( filter ) if err != nil { return err } if len ( events ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( events ) } 
func kindList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { kinds , err := event . GetKinds ( ) if err != nil { return err } if len ( kinds ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( kinds ) } 
func eventInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { uuid := r . URL . Query ( ) . Get ( " " ) if ! bson . IsObjectIdHex ( uuid ) { msg := fmt . Sprintf ( " " , uuid ) return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } objID := bson . ObjectIdHex ( uuid ) e , err := event . GetByID ( objID ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } scheme , err := permission . SafeGet ( e . Allowed . Scheme ) if err != nil { return err } allowed := permission . Check ( t , scheme , e . Allowed . Contexts ... ) if ! allowed { return permission . ErrUnauthorized } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( e ) } 
func eventCancel ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { uuid := r . URL . Query ( ) . Get ( " " ) if ! bson . IsObjectIdHex ( uuid ) { msg := fmt . Sprintf ( " " , uuid ) return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } objID := bson . ObjectIdHex ( uuid ) e , err := event . GetByID ( objID ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } reason := InputValue ( r , " " ) if reason == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } scheme , err := permission . SafeGet ( e . AllowedCancel . Scheme ) if err != nil { return err } allowed := permission . Check ( t , scheme , e . AllowedCancel . Contexts ... ) if ! allowed { return permission . ErrUnauthorized } err = e . TryCancel ( reason , t . GetUserName ( ) ) if err != nil { if err == event . ErrNotCancelable { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } return err } w . WriteHeader ( http . StatusNoContent ) return nil } 
func eventBlockList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermEventBlockRead ) { return permission . ErrUnauthorized } var active * bool if activeStr := InputValue ( r , " " ) ; activeStr != " " { b , _ := strconv . ParseBool ( activeStr ) active = & b } blocks , err := event . ListBlocks ( active ) if err != nil { return err } if len ( blocks ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( blocks ) } 
func eventBlockAdd ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermEventBlockAdd ) { return permission . ErrUnauthorized } var block event . Block err = ParseInput ( r , & block ) if err != nil { return err } if block . Reason == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeEventBlock } , Kind : permission . PermEventBlockAdd , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermEventBlockReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Target . Value = block . ID . Hex ( ) evt . Done ( err ) } ( ) return event . AddBlock ( & block ) } 
func eventBlockRemove ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermEventBlockRemove ) { return permission . ErrUnauthorized } uuid := r . URL . Query ( ) . Get ( " " ) if ! bson . IsObjectIdHex ( uuid ) { msg := fmt . Sprintf ( " " , uuid ) return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } objID := bson . ObjectIdHex ( uuid ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeEventBlock , Value : objID . Hex ( ) } , Kind : permission . PermEventBlockRemove , Owner : t , CustomData : [ ] map [ string ] interface { } { { " " : " " , " " : objID . Hex ( ) } , } , Allowed : event . Allowed ( permission . PermEventBlockReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = event . RemoveBlock ( objID ) if _ , ok := err . ( * event . ErrActiveEventBlockNotFound ) ; ok { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } 
func getUserQuota ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { allowed := permission . Check ( t , permission . PermUserUpdateQuota ) if ! allowed { return permission . ErrUnauthorized } email := r . URL . Query ( ) . Get ( " " ) user , err := auth . GetUserByEmail ( email ) if err == authTypes . ErrUserNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( user . Quota ) } 
func changeUserQuota ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { email := r . URL . Query ( ) . Get ( " " ) allowed := permission . Check ( t , permission . PermUserUpdateQuota , permission . Context ( permTypes . CtxUser , email ) ) if ! allowed { return permission . ErrUnauthorized } user , err := auth . GetUserByEmail ( email ) if err == authTypes . ErrUserNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } else if err != nil { return err } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeUser , Value : email } , Kind : permission . PermUserUpdateQuota , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , email ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) limit , err := strconv . Atoi ( InputValue ( r , " " ) ) if err != nil { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } err = servicemanager . UserQuota . SetLimit ( user . Email , limit ) if err == quota . ErrLimitLowerThanAllocated { return & errors . HTTP { Code : http . StatusForbidden , Message : err . Error ( ) , } } return err } 
func changeAppQuota ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppAdminQuota , contextsForApp ( & a ) ... ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeApp , Value : appName } , Kind : permission . PermAppAdminQuota , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) limit , err := strconv . Atoi ( InputValue ( r , " " ) ) if err != nil { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } err = a . SetQuotaLimit ( limit ) if err == quota . ErrLimitLowerThanAllocated { return & errors . HTTP { Code : http . StatusForbidden , Message : err . Error ( ) , } } return err } 
func ( r * DelayedRouter ) AddAll ( version , path string , h http . Handler ) * mux . Route { return r . addRoute ( version , path , h , " " , " " , " " , " " ) } 
func samlRequestTimeout ( schemeData map [ string ] string ) int { p := schemeData [ " " ] timeout , _ := strconv . Atoi ( p ) return timeout } 
func RegisterHandler ( path string , method string , h http . Handler ) { RegisterHandlerVersion ( " " , path , method , h ) } 
func RegisterHandlerVersion ( version , path , method string , h http . Handler ) { var th TsuruHandler th . version = version th . path = path th . method = method th . h = h tsuruHandlerList = append ( tsuruHandlerList , th ) } 
func RunServer ( dry bool ) http . Handler { err := log . Init ( ) if err != nil { stdLog . Fatalf ( " " , err ) } err = InitializeDBServices ( ) if err != nil { fatal ( err ) } m := apiRouter . NewRouter ( ) for _ , handler := range tsuruHandlerList { m . Add ( handler . version , handler . method , handler . path , handler . h ) } if disableIndex , _ := config . GetBool ( " " ) ; ! disableIndex { m . Add ( " " , " " , " " , Handler ( index ) ) } m . Add ( " " , " " , " " , Handler ( info ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceInstances ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceInstance ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeServiceInstance ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( createServiceInstance ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( updateServiceInstance ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( bindServiceInstance ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( unbindServiceInstance ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceInstanceStatus ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceInstanceGrantTeam ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceInstanceRevokeTeam ) ) proxyInstanceHandler := AuthorizationRequiredHandler ( serviceInstanceProxy ) proxyServiceHandler := AuthorizationRequiredHandler ( serviceProxy ) m . AddAll ( " " , " " , proxyInstanceHandler ) m . AddAll ( " " , " " , proxyServiceHandler ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceCreate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( servicePlans ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceDoc ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceAddDoc ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( grantServiceAccess ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( revokeServiceAccess ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( appDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( appInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( setCName ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( unsetCName ) ) runHandler := AuthorizationRequiredHandler ( runCommand ) m . Add ( " " , " " , " " , runHandler ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( restart ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( start ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( stop ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( sleep ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( getAppQuota ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( changeAppQuota ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( updateApp ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( getEnv ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( setEnv ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( unsetEnv ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( appList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( createApp ) ) forceDeleteLockHandler := AuthorizationRequiredHandler ( forceDeleteLock ) m . Add ( " " , " " , " " , forceDeleteLockHandler ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addUnits ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeUnits ) ) registerUnitHandler := AuthorizationRequiredHandler ( registerUnit ) m . Add ( " " , " " , " " , registerUnitHandler ) setUnitStatusHandler := AuthorizationRequiredHandler ( setUnitStatus ) m . Add ( " " , " " , " " , setUnitStatusHandler ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( grantAppAccess ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( revokeAppAccess ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( appLog ) ) logPostHandler := AuthorizationRequiredHandler ( addLog ) m . Add ( " " , " " , " " , logPostHandler ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( deployRollback ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( deployRollbackUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( deployRebuild ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( appMetricEnvs ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( appRebuildRoutes ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listCertificates ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( setCertificate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( unsetCertificate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addAppRouter ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( updateAppRouter ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeAppRouter ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listAppRouters ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( setNodeStatus ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( deploysList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( deployInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( eventList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( eventBlockList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( eventBlockAdd ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( eventBlockRemove ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( kindList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( eventInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( eventCancel ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( webhookList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( webhookCreate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( webhookInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( webhookUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( webhookDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( platformList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( platformAdd ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( platformUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( platformRemove ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( platformInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( platformRollback ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( deploy ) ) diffDeployHandler := AuthorizationRequiredHandler ( diffDeploy ) m . Add ( " " , " " , " " , diffDeployHandler ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( build ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listUsers ) ) m . Add ( " " , " " , " " , Handler ( createUser ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( userInfo ) ) m . Add ( " " , " " , " " , Handler ( authScheme ) ) m . Add ( " " , " " , " " , Handler ( login ) ) m . Add ( " " , " " , " " , Handler ( samlCallbackLogin ) ) m . Add ( " " , " " , " " , Handler ( samlMetadata ) ) m . Add ( " " , " " , " " , Handler ( resetPassword ) ) m . Add ( " " , " " , " " , Handler ( login ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( getUserQuota ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( changeUserQuota ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( logout ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( changePassword ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeUser ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listKeys ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addKeyToUser ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeKeyFromUser ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( showAPIToken ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( regenerateAPIToken ) ) m . Add ( " " , " " , " " , websocket . Handler ( addLogs ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( teamList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( createTeam ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeTeam ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( updateTeam ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( teamInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( swap ) ) m . Add ( " " , " " , " " , http . HandlerFunc ( healthcheck ) ) m . Add ( " " , " " , " " , http . HandlerFunc ( healthcheck ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( machinesList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( machineDestroy ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( templatesList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( templateCreate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( templateUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( templateDestroy ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listPlans ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addPlan ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removePlan ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( poolList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addPoolHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removePoolHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( poolUpdateHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addTeamToPoolHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeTeamToPoolHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( poolConstraintList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( poolConstraintSet ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listRoles ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( roleUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addRole ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( roleInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeRole ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addPermissions ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removePermissions ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( assignRole ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( dissociateRole ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listDefaultRoles ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addDefaultRole ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeDefaultRole ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listPermissions ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( assignRoleToToken ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( dissociateRoleFromToken ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( dumpGoroutines ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( indexHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( cmdlineHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( profileHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( symbolHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( indexHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( indexHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( indexHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( indexHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( traceHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleHistoryHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleGetConfig ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleRunHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleListRules ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleSetRule ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleDeleteRule ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleDeleteRule ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listNodesHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listUnitsByApp ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listUnitsByNode ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addNodeHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( updateNodeHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeNodeHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( rebalanceNodesHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( infoNodeHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerCreate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerUpgrade ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( installHostAdd ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( installHostList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( installHostInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeHealingRead ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeHealingUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeHealingDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( healingHistoryHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listRouters ) ) m . Add ( " " , " " , " " , promhttp . Handler ( ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( provisionerList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( createCluster ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( updateCluster ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listClusters ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( deleteCluster ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumesList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumeInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumeDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumeCreate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumeUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumeBind ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumeUnbind ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( volumePlansList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( tokenList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( tokenInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( tokenCreate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( tokenDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( tokenUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceBrokerList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceBrokerAdd ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceBrokerUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( serviceBrokerDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listNodesHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listUnitsByApp ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listUnitsByNode ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( addNodeHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( updateNodeHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( removeNodeHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( rebalanceNodesHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerList ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerCreate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerInfo ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeContainerUpgrade ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeHealingRead ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeHealingUpdate ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( nodeHealingDelete ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( healingHistoryHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleHistoryHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleGetConfig ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleRunHandler ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleListRules ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleSetRule ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleDeleteRule ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( autoScaleDeleteRule ) ) m . Add ( " " , " " , " " , AuthorizationRequiredHandler ( listRouters ) ) n := negroni . New ( ) n . Use ( negroni . NewRecovery ( ) ) n . Use ( negroni . HandlerFunc ( contextClearerMiddleware ) ) if ! dry { n . Use ( newLoggerMiddleware ( ) ) } n . UseHandler ( m ) n . Use ( negroni . HandlerFunc ( flushingWriterMiddleware ) ) n . Use ( negroni . HandlerFunc ( setRequestIDHeaderMiddleware ) ) n . Use ( negroni . HandlerFunc ( errorHandlingMiddleware ) ) n . Use ( negroni . HandlerFunc ( setVersionHeadersMiddleware ) ) n . Use ( negroni . HandlerFunc ( authTokenMiddleware ) ) n . Use ( & appLockMiddleware { excludedHandlers : [ ] http . Handler { logPostHandler , runHandler , forceDeleteLockHandler , registerUnitHandler , setUnitStatusHandler , diffDeployHandler , } } ) n . UseHandler ( http . HandlerFunc ( runDelayedHandler ) ) if ! dry { err := startServer ( n ) if err != nil { fatal ( err ) } } return n } 
func validateTLSCertificate ( c * tls . Certificate , roots * x509 . CertPool ) error { configHost , err := config . GetString ( " " ) if err != nil { return err } urlHost , err := url . Parse ( configHost ) if err != nil { return err } hostname := urlHost . Hostname ( ) if c == nil || len ( c . Certificate ) == 0 { return errors . New ( " " ) } var intermediateCertPool * x509 . CertPool if len ( c . Certificate ) > 1 { intermediateCertPool = x509 . NewCertPool ( ) for i := 1 ; i < len ( c . Certificate ) ; i ++ { var intermerdiateCert * x509 . Certificate if intermerdiateCert , err = x509 . ParseCertificate ( c . Certificate [ i ] ) ; err != nil { return err } intermediateCertPool . AddCert ( intermerdiateCert ) } } leafCert , err := x509 . ParseCertificate ( c . Certificate [ 0 ] ) if err != nil { return err } _ , err = leafCert . Verify ( x509 . VerifyOptions { DNSName : hostname , Roots : roots , Intermediates : intermediateCertPool , } ) return err } 
func Check ( names ... string ) [ ] Result { results := make ( [ ] Result , 0 , len ( checkers ) ) nameSet := set . FromSlice ( names ) isAll := nameSet . Includes ( " " ) for _ , checker := range checkers { if ! isAll && ! nameSet . Includes ( checker . name ) { continue } startTime := time . Now ( ) if err := checker . check ( ) ; err != nil && err != ErrDisabledComponent { results = append ( results , Result { Name : checker . name , Status : " " + err . Error ( ) , Duration : time . Since ( startTime ) , } ) } else if err == nil { results = append ( results , Result { Name : checker . name , Status : HealthCheckOK , Duration : time . Since ( startTime ) , } ) } } return results } 
func indexHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermDebug ) { return permission . ErrUnauthorized } pprof . Index ( w , r ) return nil } 
func cmdlineHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermDebug ) { return permission . ErrUnauthorized } pprof . Cmdline ( w , r ) return nil } 
func profileHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermDebug ) { return permission . ErrUnauthorized } pprof . Profile ( w , r ) return nil } 
func symbolHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermDebug ) { return permission . ErrUnauthorized } pprof . Symbol ( w , r ) return nil } 
func traceHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermDebug ) { return permission . ErrUnauthorized } pprof . Trace ( w , r ) return nil } 
func DiscoverRepositoryPath ( dir string ) ( string , error ) { _ , err := os . Stat ( dir ) if os . IsNotExist ( err ) { return " " , ErrRepositoryNotFound } dir = filepath . Join ( dir , " " ) for dir != " " { fi , err := os . Stat ( dir ) if err == nil && fi . IsDir ( ) { return dir , nil } dir = filepath . Join ( dir , " " , " " , " " ) } return " " , ErrRepositoryNotFound } 
func OpenRepository ( p string ) ( * Repository , error ) { if ! strings . HasSuffix ( p , " " ) && ! strings . HasSuffix ( p , " " ) { p = filepath . Join ( p , " " ) } p = strings . TrimRight ( p , " " ) fi , err := os . Stat ( filepath . Join ( p , " " ) ) if err == nil && ! fi . IsDir ( ) { return & Repository { path : p } , nil } return nil , ErrRepositoryNotFound } 
func ( r * Repository ) RemoteURL ( name string ) ( string , error ) { config , err := os . Open ( filepath . Join ( r . path , " " ) ) if err != nil { return " " , err } defer config . Close ( ) line := fmt . Sprintf ( " " , name ) scanner := bufio . NewScanner ( config ) scanner . Split ( bufio . ScanLines ) for scanner . Scan ( ) { if scanner . Text ( ) == line { scanner . Scan ( ) return strings . Split ( scanner . Text ( ) , " " ) [ 1 ] , nil } } return " " , errRemoteNotFound { name } } 
func tokenList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { tokens , err := servicemanager . TeamToken . FindByUserToken ( t ) if err != nil { return err } if len ( tokens ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( tokens ) } 
func tokenInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { tokenID := r . URL . Query ( ) . Get ( " " ) if tokenID == " " { w . WriteHeader ( http . StatusBadRequest ) return nil } teamToken , err := servicemanager . TeamToken . Info ( tokenID , t ) if err == authTypes . ErrTeamTokenNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } if err != nil { return err } allowed := permission . Check ( t , permission . PermTeamTokenRead , permission . Context ( permTypes . CtxTeam , teamToken . Team ) , ) if ! allowed { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( teamToken ) } 
func tokenCreate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var args authTypes . TeamTokenCreateArgs err = ParseInput ( r , & args ) if err != nil { return err } if args . Team == " " { args . Team , err = autoTeamOwner ( t , permission . PermTeamTokenCreate ) if err != nil { return err } } allowed := permission . Check ( t , permission . PermTeamTokenCreate , permission . Context ( permTypes . CtxTeam , args . Team ) , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : teamTarget ( args . Team ) , Kind : permission . PermTeamTokenCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermTeamReadEvents , permission . Context ( permTypes . CtxTeam , args . Team ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) token , err := servicemanager . TeamToken . Create ( args , t ) if err != nil { return err } if err != nil { if err == authTypes . ErrTeamTokenAlreadyExists { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) , } } return err } w . WriteHeader ( http . StatusCreated ) return json . NewEncoder ( w ) . Encode ( token ) } 
func tokenUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var args authTypes . TeamTokenUpdateArgs err = ParseInput ( r , & args ) if err != nil { return err } args . TokenID = r . URL . Query ( ) . Get ( " " ) teamToken , err := servicemanager . TeamToken . FindByTokenID ( args . TokenID ) if err != nil { if err == authTypes . ErrTeamTokenNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } allowed := permission . Check ( t , permission . PermTeamTokenUpdate , permission . Context ( permTypes . CtxTeam , teamToken . Team ) , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : teamTarget ( teamToken . Team ) , Kind : permission . PermTeamTokenUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermTeamReadEvents , permission . Context ( permTypes . CtxTeam , teamToken . Team ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) teamToken , err = servicemanager . TeamToken . Update ( args , t ) if err == authTypes . ErrTeamTokenNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } if err != nil { return err } return json . NewEncoder ( w ) . Encode ( teamToken ) } 
func tokenDelete ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { tokenID := r . URL . Query ( ) . Get ( " " ) teamToken , err := servicemanager . TeamToken . FindByTokenID ( tokenID ) if err != nil { if err == authTypes . ErrTeamTokenNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } teamName := teamToken . Team allowed := permission . Check ( t , permission . PermTeamTokenDelete , permission . Context ( permTypes . CtxTeam , teamName ) , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : teamTarget ( teamName ) , Kind : permission . PermTeamTokenDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermTeamReadEvents , permission . Context ( permTypes . CtxTeam , teamName ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = servicemanager . TeamToken . Delete ( tokenID ) if err == authTypes . ErrTeamTokenNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } 
func addRole ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermRoleCreate ) { return permission . ErrUnauthorized } roleName := InputValue ( r , " " ) if roleName == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : permTypes . ErrInvalidRoleName . Error ( ) , } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) _ , err = permission . NewRole ( roleName , InputValue ( r , " " ) , InputValue ( r , " " ) ) if err == permTypes . ErrInvalidRoleName { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } if err == permTypes . ErrRoleAlreadyExists { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) , } } if err == nil { w . WriteHeader ( http . StatusCreated ) } return err } 
func removeRole ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermRoleDelete ) { return permission . ErrUnauthorized } roleName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) usersWithRole , err := auth . ListUsersWithRole ( roleName ) if err != nil { return err } if len ( usersWithRole ) != 0 { return & errors . HTTP { Code : http . StatusPreconditionFailed , Message : permTypes . ErrRemoveRoleWithUsers . Error ( ) } } err = permission . DestroyRole ( roleName ) if err == permTypes . ErrRoleNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } 
func listRoles ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! ( permission . Check ( t , permission . PermRoleUpdate ) || permission . Check ( t , permission . PermRoleUpdateAssign ) || permission . Check ( t , permission . PermRoleUpdateDissociate ) || permission . Check ( t , permission . PermRoleCreate ) || permission . Check ( t , permission . PermRoleDelete ) ) { return permission . ErrUnauthorized } roles , err := permission . ListRoles ( ) if err != nil { return err } b , err := json . Marshal ( roles ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) _ , err = w . Write ( b ) return err } 
func roleInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! ( permission . Check ( t , permission . PermRoleUpdate ) || permission . Check ( t , permission . PermRoleUpdateAssign ) || permission . Check ( t , permission . PermRoleUpdateDissociate ) || permission . Check ( t , permission . PermRoleCreate ) || permission . Check ( t , permission . PermRoleDelete ) ) { return permission . ErrUnauthorized } roleName := r . URL . Query ( ) . Get ( " " ) role , err := permission . FindRole ( roleName ) if err == permTypes . ErrRoleNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } if err != nil { return err } b , err := json . Marshal ( role ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) _ , err = w . Write ( b ) return err } 
func addPermissions ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermRoleUpdatePermissionAdd ) { return permission . ErrUnauthorized } roleName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleUpdatePermissionAdd , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) role , err := permission . FindRole ( roleName ) if err != nil { return err } users , err := auth . ListUsersWithRole ( roleName ) if err != nil { return err } err = runWithPermSync ( users , func ( ) error { permissions , _ := InputValues ( r , " " ) return role . AddPermissions ( permissions ... ) } ) if err == permTypes . ErrInvalidPermissionName { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } if perr , ok := err . ( * permTypes . ErrPermissionNotFound ) ; ok { return & errors . HTTP { Code : http . StatusBadRequest , Message : perr . Error ( ) , } } if perr , ok := err . ( * permTypes . ErrPermissionNotAllowed ) ; ok { return & errors . HTTP { Code : http . StatusConflict , Message : perr . Error ( ) , } } return err } 
func removePermissions ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermRoleUpdatePermissionRemove ) { return permission . ErrUnauthorized } roleName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleUpdatePermissionRemove , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) permName := r . URL . Query ( ) . Get ( " " ) role , err := permission . FindRole ( roleName ) if err != nil { if err == permTypes . ErrRoleNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } users , err := auth . ListUsersWithRole ( roleName ) if err != nil { return err } err = runWithPermSync ( users , func ( ) error { return role . RemovePermissions ( permName ) } ) return err } 
func assignRole ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermRoleUpdateAssign ) { return permission . ErrUnauthorized } roleName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleUpdateAssign , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) email := InputValue ( r , " " ) contextValue := InputValue ( r , " " ) user , err := auth . GetUserByEmail ( email ) if err != nil { return err } err = canUseRole ( t , roleName , contextValue ) if err != nil { return err } err = runWithPermSync ( [ ] auth . User { * user } , func ( ) error { return user . AddRole ( roleName , contextValue ) } ) return err } 
func listPermissions ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermRoleUpdate ) { return permission . ErrUnauthorized } lst := permission . PermissionRegistry . Permissions ( ) sort . Sort ( lst ) permList := make ( [ ] permissionSchemeData , len ( lst ) ) for i , perm := range lst { contexts := perm . AllowedContexts ( ) contextNames := make ( [ ] string , len ( contexts ) ) for j , ctx := range contexts { contextNames [ j ] = string ( ctx ) } permList [ i ] = permissionSchemeData { Name : perm . FullName ( ) , Contexts : contextNames , } } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( permList ) } 
func addDefaultRole ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermRoleDefaultCreate ) { return permission . ErrUnauthorized } rolesMap := map [ string ] [ ] string { } for evtName := range permTypes . RoleEventMap { roles , _ := InputValues ( r , evtName ) for _ , roleName := range roles { rolesMap [ roleName ] = append ( rolesMap [ roleName ] , evtName ) } } for roleName , evts := range rolesMap { evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleDefaultCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) role , err := permission . FindRole ( roleName ) if err != nil { if err == permTypes . ErrRoleNotFound { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } return err } for _ , evtName := range evts { err = role . AddEvent ( evtName ) if err != nil { if _ , ok := err . ( permTypes . ErrRoleEventWrongContext ) ; ok { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } return err } } } return nil } 
func listDefaultRoles ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermRoleDefaultCreate ) && ! permission . Check ( t , permission . PermRoleDefaultDelete ) { return permission . ErrUnauthorized } roles , err := permission . ListRolesWithEvents ( ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( roles ) } 
func roleUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { roleName := InputValue ( r , " " ) newName := InputValue ( r , " " ) contextType := InputValue ( r , " " ) description := InputValue ( r , " " ) var wantedPerms [ ] * permission . PermissionScheme if newName != " " { wantedPerms = append ( wantedPerms , permission . PermRoleUpdateName ) } if contextType != " " { wantedPerms = append ( wantedPerms , permission . PermRoleUpdateContextType ) } if description != " " { wantedPerms = append ( wantedPerms , permission . PermRoleUpdateDescription ) } if len ( wantedPerms ) == 0 { msg := " " return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } for _ , perm := range wantedPerms { if ! permission . Check ( t , perm ) { return permission . ErrUnauthorized } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleUpdate ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = auth . UpdateRoleFromAllUsers ( roleName , newName , contextType , description ) if err != nil { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } return nil } 
func assignRoleToToken ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermRoleUpdateAssign ) { return permission . ErrUnauthorized } tokenID := InputValue ( r , " " ) contextValue := InputValue ( r , " " ) roleName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeRole , Value : roleName } , Kind : permission . PermRoleUpdateAssign , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermRoleReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = canUseRole ( t , roleName , contextValue ) if err != nil { return err } err = servicemanager . TeamToken . AddRole ( tokenID , roleName , contextValue ) if err == authTypes . ErrTeamTokenNotFound { w . WriteHeader ( http . StatusNotFound ) return nil } return err } 
func ( s * appLister ) List ( selector labels . Selector ) ( ret [ ] * v1 . App , err error ) { err = cache . ListAll ( s . indexer , selector , func ( m interface { } ) { ret = append ( ret , m . ( * v1 . App ) ) } ) return ret , err } 
func ( s * appLister ) Apps ( namespace string ) AppNamespaceLister { return appNamespaceLister { indexer : s . indexer , namespace : namespace } } 
func ( s appNamespaceLister ) List ( selector labels . Selector ) ( ret [ ] * v1 . App , err error ) { err = cache . ListAllByNamespace ( s . indexer , s . namespace , selector , func ( m interface { } ) { ret = append ( ret , m . ( * v1 . App ) ) } ) return ret , err } 
func ( d * DockerMachine ) RegisterMachine ( opts RegisterMachineOpts ) ( * Machine , error ) { if ! d . temp { return nil , errors . New ( " " ) } if opts . Base . CustomData == nil { return nil , errors . New ( " " ) } opts . Base . CustomData [ " " ] = filepath . Join ( d . client . GetMachinesDir ( ) , opts . Base . Id , " " ) rawDriver , err := json . Marshal ( opts . Base . CustomData ) if err != nil { return nil , errors . WithMessage ( err , " " ) } h , err := d . client . NewHost ( opts . DriverName , rawDriver ) if err != nil { return nil , errors . WithStack ( err ) } err = ioutil . WriteFile ( h . Driver . GetSSHKeyPath ( ) , opts . SSHPrivateKey , 0700 ) if err != nil { return nil , errors . WithStack ( err ) } err = ioutil . WriteFile ( h . AuthOptions ( ) . CaCertPath , opts . Base . CaCert , 0700 ) if err != nil { return nil , errors . WithStack ( err ) } err = ioutil . WriteFile ( h . AuthOptions ( ) . ClientCertPath , opts . Base . ClientCert , 0700 ) if err != nil { return nil , errors . WithStack ( err ) } err = ioutil . WriteFile ( h . AuthOptions ( ) . ClientKeyPath , opts . Base . ClientKey , 0700 ) if err != nil { return nil , errors . WithStack ( err ) } err = d . client . Save ( h ) if err != nil { return nil , errors . WithStack ( err ) } savedHost , err := d . client . Load ( h . Name ) if err != nil { return nil , errors . WithStack ( err ) } return & Machine { Base : opts . Base , Host : savedHost , } , nil } 
func StreamJSONResponse ( w io . Writer , response * http . Response ) error { if response == nil { return errors . New ( " " ) } defer response . Body . Close ( ) var err error output := tsuruio . NewStreamWriter ( w , nil ) for n := int64 ( 1 ) ; n > 0 && err == nil ; n , err = io . Copy ( output , response . Body ) { } if err != nil { return err } unparsed := output . Remaining ( ) if len ( unparsed ) > 0 { return errors . Errorf ( " " , string ( unparsed ) ) } return nil } 
func ( s * Storage ) DropDatabase ( name string ) error { return s . session . DB ( name ) . DropDatabase ( ) } 
func ( s * Storage ) Collection ( name string ) * Collection { return & Collection { Collection : s . session . DB ( s . dbname ) . C ( name ) } } 
func ( s * OAuthScheme ) loadConfig ( ) ( oauth2 . Config , error ) { if s . BaseConfig . ClientID != " " { return s . BaseConfig , nil } if s . Parser == nil { s . Parser = s } var emptyConfig oauth2 . Config clientId , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } clientSecret , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } scope , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } authURL , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } tokenURL , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } infoURL , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } callbackPort , err := config . GetInt ( " " ) if err != nil { log . Debugf ( " " , err ) } s . InfoURL = infoURL s . CallbackPort = callbackPort s . BaseConfig = oauth2 . Config { ClientID : clientId , ClientSecret : clientSecret , Scopes : [ ] string { scope } , Endpoint : oauth2 . Endpoint { AuthURL : authURL , TokenURL : tokenURL , } , } return s . BaseConfig , nil } 
func ( t * Target ) SetLogger ( l Logger ) { t . mut . Lock ( ) defer t . mut . Unlock ( ) t . logger = l } 
func ( t * Target ) Error ( v error ) { t . mut . RLock ( ) defer t . mut . RUnlock ( ) if t . logger != nil { t . logger . Errorf ( " " , v ) } } 
func ( t * Target ) Errorf ( format string , v ... interface { } ) { t . mut . RLock ( ) defer t . mut . RUnlock ( ) if t . logger != nil { t . logger . Errorf ( format , v ... ) for _ , item := range v { if _ , hasStack := item . ( withStack ) ; hasStack { t . logger . Errorf ( " " , item ) } } } } 
func ( t * Target ) Fatal ( v string ) { t . mut . RLock ( ) defer t . mut . RUnlock ( ) if t . logger != nil { t . logger . Fatal ( v ) } } 
func ( t * Target ) Debugf ( format string , v ... interface { } ) { t . mut . RLock ( ) defer t . mut . RUnlock ( ) if t . logger != nil { t . logger . Debugf ( format , v ... ) } } 
func ( t * Target ) GetStdLogger ( ) * log . Logger { t . mut . RLock ( ) defer t . mut . RUnlock ( ) if t . logger != nil { return t . logger . GetStdLogger ( ) } return nil } 
func ( c * ClusterClient ) Namespace ( ) string { if c . CustomData != nil && c . CustomData [ namespaceClusterKey ] != " " { return c . CustomData [ namespaceClusterKey ] } return " " } 
func recreateContainers ( p DockerProvisioner , w io . Writer , nodes ... cluster . Node ) error { return ensureContainersStarted ( p , w , true , nil , nodes ... ) } 
func checkProvisioner ( ) error { if value , _ := config . Get ( " " ) ; value == defaultProvisionerName || value == " " { return checkDocker ( ) } return nil } 
func checkDocker ( ) error { if _ , err := config . Get ( " " ) ; err != nil { return errors . New ( " " ) } err := checkDockerBasicConfig ( ) if err != nil { return err } err = checkScheduler ( ) if err != nil { return err } err = checkRouter ( ) if err != nil { return err } return checkCluster ( ) } 
func checkScheduler ( ) error { if servers , err := config . Get ( " " ) ; err == nil && servers != nil { return errors . Errorf ( `Using docker:servers is deprecated, please remove it your config and use "tsuru docker-node-add" do add docker nodes.` ) } isSegregate , err := config . GetBool ( " " ) if err == nil { if isSegregate { return config . NewWarning ( `Setting "docker:segregate" is not necessary anymore, this is the default behavior from now on.` ) } else { return errors . Errorf ( `You must remove "docker:segregate" from your config.` ) } } return nil } 
func checkRouter ( ) error { defaultRouter , _ := config . GetString ( " " ) if defaultRouter == " " { return errors . Errorf ( `You must configure a default router in "docker:router".` ) } isHipacheOld := false if defaultRouter == " " { hipacheOld , _ := config . Get ( " " ) isHipacheOld = hipacheOld != nil } routerConf , _ := config . Get ( " " + defaultRouter ) if isHipacheOld { return config . NewWarning ( `Setting "hipache:*" config entries is deprecated. You should configure your router with "routers:*". See http: } if routerConf == nil { return errors . Errorf ( `You must configure your default router %q in "routers:%s".` , defaultRouter , defaultRouter ) } routerType , _ := config . Get ( " " + defaultRouter + " " ) if routerType == nil { return errors . Errorf ( `You must configure your default router type in "routers:%s:type".` , defaultRouter ) } return nil } 
func addPlan ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { cpuShare , _ := strconv . Atoi ( InputValue ( r , " " ) ) isDefault , _ := strconv . ParseBool ( InputValue ( r , " " ) ) memory := getSize ( InputValue ( r , " " ) ) swap := getSize ( InputValue ( r , " " ) ) plan := appTypes . Plan { Name : InputValue ( r , " " ) , Memory : memory , Swap : swap , CpuShare : cpuShare , Default : isDefault , } allowed := permission . Check ( t , permission . PermPlanCreate ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePlan , Value : plan . Name } , Kind : permission . PermPlanCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPlanReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = servicemanager . Plan . Create ( plan ) if err == appTypes . ErrPlanAlreadyExists { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) , } } if err == appTypes . ErrLimitOfMemory || err == appTypes . ErrLimitOfCpuShare { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } if err == nil { w . WriteHeader ( http . StatusCreated ) } return err } 
func listPlans ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { plans , err := servicemanager . Plan . List ( ) if err != nil { return err } if len ( plans ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( plans ) } 
func removePlan ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermPlanDelete ) if ! allowed { return permission . ErrUnauthorized } planName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePlan , Value : planName } , Kind : permission . PermPlanDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPlanReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = servicemanager . Plan . Remove ( planName ) if err == appTypes . ErrPlanNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } 
func GetBuildImage ( app provision . App ) ( string , error ) { if usePlatformImage ( app ) { return getPlatformImage ( app ) } appImageName , err := AppCurrentImageName ( app . GetName ( ) ) if err != nil { return getPlatformImage ( app ) } return appImageName , nil } 
func poolList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { var teams , poolNames [ ] string isGlobal := false contexts := permission . ContextsForPermission ( t , permission . PermAppCreate ) contexts = append ( contexts , permission . ContextsForPermission ( t , permission . PermPoolRead ) ... ) for _ , c := range contexts { if c . CtxType == permTypes . CtxGlobal { isGlobal = true break } if c . CtxType == permTypes . CtxTeam { teams = append ( teams , c . Value ) } if c . CtxType == permTypes . CtxPool { poolNames = append ( poolNames , c . Value ) } } var pools [ ] pool . Pool var err error if isGlobal { pools , err = pool . ListAllPools ( ) if err != nil { return err } } else { pools , err = pool . ListPossiblePools ( teams ) if err != nil { return err } if len ( poolNames ) > 0 { namedPools , err := pool . ListPools ( poolNames ... ) if err != nil { return err } pools = append ( pools , namedPools ... ) } } poolsMap := make ( map [ string ] struct { } ) var poolList [ ] pool . Pool for _ , p := range pools { if _ , ok := poolsMap [ p . Name ] ; ok { continue } poolList = append ( poolList , p ) poolsMap [ p . Name ] = struct { } { } } if len ( poolList ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( poolList ) } 
func addPoolHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermPoolCreate ) if ! allowed { return permission . ErrUnauthorized } var addOpts pool . AddPoolOptions err = ParseInput ( r , & addOpts ) if err != nil { return err } if addOpts . Name == " " { return & terrors . HTTP { Code : http . StatusBadRequest , Message : pool . ErrPoolNameIsRequired . Error ( ) , } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : addOpts . Name } , Kind : permission . PermPoolCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permission . Context ( permTypes . CtxPool , addOpts . Name ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = pool . AddPool ( addOpts ) if err == pool . ErrDefaultPoolAlreadyExists || err == pool . ErrPoolAlreadyExists { return & terrors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) , } } if err == pool . ErrPoolNameIsRequired { return & terrors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } if err == nil { w . WriteHeader ( http . StatusCreated ) } return err } 
func removePoolHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermPoolDelete ) if ! allowed { return permission . ErrUnauthorized } poolName := r . URL . Query ( ) . Get ( " " ) filter := & app . Filter { } filter . Pool = poolName apps , err := app . List ( appFilterByContext ( [ ] permTypes . PermissionContext { } , filter ) ) if err != nil { return err } if len ( apps ) > 0 { return & terrors . HTTP { Code : http . StatusForbidden , Message : " " } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : poolName } , Kind : permission . PermPoolDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permission . Context ( permTypes . CtxPool , poolName ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = pool . RemovePool ( poolName ) if err == pool . ErrPoolNotFound { return & terrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } 
func addTeamToPoolHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { poolName := r . URL . Query ( ) . Get ( " " ) allowed := permission . Check ( t , permission . PermPoolUpdateTeamAdd , permission . Context ( permTypes . CtxPool , poolName ) ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : poolName } , Kind : permission . PermPoolUpdateTeamAdd , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permission . Context ( permTypes . CtxPool , poolName ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) if teams , ok := InputValues ( r , " " ) ; ok { err := pool . AddTeamsToPool ( poolName , teams ) if err == pool . ErrPoolNotFound { return & terrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } return & terrors . HTTP { Code : http . StatusBadRequest , Message : " " } } 
func poolUpdateHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermPoolUpdate ) if ! allowed { return permission . ErrUnauthorized } poolName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : poolName } , Kind : permission . PermPoolUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permission . Context ( permTypes . CtxPool , poolName ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) var updateOpts pool . UpdatePoolOptions err = ParseInput ( r , & updateOpts ) if err != nil { return err } err = pool . PoolUpdate ( poolName , updateOpts ) if err == pool . ErrPoolNotFound { return & terrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } if err == pool . ErrDefaultPoolAlreadyExists { return & terrors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) , } } return err } 
func poolConstraintList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermPoolReadConstraints ) { return permission . ErrUnauthorized } constraints , err := pool . ListPoolsConstraints ( nil ) if err != nil { return err } if len ( constraints ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( constraints ) } 
func poolConstraintSet ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermPoolUpdateConstraintsSet ) { return permission . ErrUnauthorized } var poolConstraint pool . PoolConstraint err = ParseInput ( r , & poolConstraint ) if err != nil { return err } if poolConstraint . PoolExpr == " " { return & terrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : poolConstraint . PoolExpr } , Kind : permission . PermPoolUpdateConstraintsSet , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) append := false if appendStr := InputValue ( r , " " ) ; appendStr != " " { append , _ = strconv . ParseBool ( appendStr ) } if append { return pool . AppendPoolConstraint ( & poolConstraint ) } return pool . SetPoolConstraint ( & poolConstraint ) } 
func ( u * Unit ) Available ( ) bool { return u . Status == StatusStarted || u . Status == StatusStarting || u . Status == StatusError } 
func Get ( name string ) ( Provisioner , error ) { pFunc , ok := provisioners [ name ] if ! ok { return nil , errors . Errorf ( " " , name ) } return pFunc ( ) } 
func Registry ( ) ( [ ] Provisioner , error ) { registry := make ( [ ] Provisioner , 0 , len ( provisioners ) ) for _ , pFunc := range provisioners { p , err := pFunc ( ) if err != nil { return nil , err } registry = append ( registry , p ) } return registry , nil } 
func ( e * Error ) Error ( ) string { var err string if e . Err != nil { err = e . Err . Error ( ) + " " + e . Reason } else { err = e . Reason } return err } 
func createUser ( w http . ResponseWriter , r * http . Request ) error { registrationEnabled , _ := config . GetBool ( " " ) if ! registrationEnabled { token := r . Header . Get ( " " ) t , err := app . AuthScheme . Auth ( token ) if err != nil { return createDisabledErr } if ! permission . Check ( t , permission . PermUserCreate ) { return createDisabledErr } } email := InputValue ( r , " " ) password := InputValue ( r , " " ) evt , err := event . New ( & event . Opts { Target : userTarget ( email ) , Kind : permission . PermUserCreate , RawOwner : event . Owner { Type : event . OwnerTypeUser , Name : email } , CustomData : event . FormToCustomData ( InputFields ( r , " " ) ) , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , email ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) u := auth . User { Email : email , Password : password , } _ , err = app . AuthScheme . Create ( & u ) if err != nil { return handleAuthError ( err ) } w . WriteHeader ( http . StatusCreated ) return nil } 
func login ( w http . ResponseWriter , r * http . Request ) ( err error ) { params := map [ string ] string { " " : r . URL . Query ( ) . Get ( " " ) , } fields := InputFields ( r ) for key , values := range fields { params [ key ] = values [ 0 ] } token , err := app . AuthScheme . Login ( params ) if err != nil { return handleAuthError ( err ) } return json . NewEncoder ( w ) . Encode ( map [ string ] string { " " : token . GetValue ( ) } ) } 
func logout ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { return app . AuthScheme . Logout ( t . GetValue ( ) ) } 
func changePassword ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { managed , ok := app . AuthScheme . ( auth . ManagedScheme ) if ! ok { return & errors . HTTP { Code : http . StatusBadRequest , Message : nonManagedSchemeMsg } } evt , err := event . New ( & event . Opts { Target : userTarget ( t . GetUserName ( ) ) , Kind : permission . PermUserUpdatePassword , Owner : t , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , t . GetUserName ( ) ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) oldPassword := InputValue ( r , " " ) newPassword := InputValue ( r , " " ) confirmPassword := InputValue ( r , " " ) if oldPassword == " " || newPassword == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } if newPassword != confirmPassword { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } err = managed . ChangePassword ( t , oldPassword , newPassword ) if err != nil { return handleAuthError ( err ) } return nil } 
func resetPassword ( w http . ResponseWriter , r * http . Request ) ( err error ) { managed , ok := app . AuthScheme . ( auth . ManagedScheme ) if ! ok { return & errors . HTTP { Code : http . StatusBadRequest , Message : nonManagedSchemeMsg } } email := r . URL . Query ( ) . Get ( " " ) token := InputValue ( r , " " ) evt , err := event . New ( & event . Opts { Target : userTarget ( email ) , Kind : permission . PermUserUpdateReset , RawOwner : event . Owner { Type : event . OwnerTypeUser , Name : email } , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , email ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) u , err := auth . GetUserByEmail ( email ) if err != nil { if err == authTypes . ErrUserNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } if token == " " { return managed . StartPasswordReset ( u ) } return managed . ResetPassword ( u , token ) } 
func updateTeam ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { name := r . URL . Query ( ) . Get ( " " ) type teamChange struct { NewName string Tags [ ] string } changeRequest := teamChange { } if err := ParseInput ( r , & changeRequest ) ; err != nil { return err } tags , _ := InputValues ( r , " " ) changeRequest . Tags = append ( changeRequest . Tags , tags ... ) allowed := permission . Check ( t , permission . PermTeamUpdate , permission . Context ( permTypes . CtxTeam , name ) , ) if ! allowed { return permission . ErrUnauthorized } _ , err := servicemanager . Team . FindByName ( name ) if err != nil { if err == authTypes . ErrTeamNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } evt , err := event . New ( & event . Opts { Target : teamTarget ( name ) , Kind : permission . PermTeamUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermTeamReadEvents , permission . Context ( permTypes . CtxTeam , name ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) if changeRequest . NewName == " " { return servicemanager . Team . Update ( name , changeRequest . Tags ) } u , err := t . User ( ) if err != nil { return err } err = servicemanager . Team . Create ( changeRequest . NewName , changeRequest . Tags , u ) if err != nil { return err } var toRollback [ ] func ( oldName , newName string ) error defer func ( ) { if err == nil { return } rollbackErr := servicemanager . Team . Remove ( changeRequest . NewName ) if rollbackErr != nil { log . Errorf ( " " , name , changeRequest . NewName ) } for _ , rollbackFn := range toRollback { rollbackErr := rollbackFn ( changeRequest . NewName , name ) if rollbackErr != nil { fnName := runtime . FuncForPC ( reflect . ValueOf ( rollbackFn ) . Pointer ( ) ) . Name ( ) log . Errorf ( " " , fnName , name , changeRequest . NewName ) } } } ( ) for _ , fn := range teamRenameFns { err = fn ( name , changeRequest . NewName ) if err != nil { return err } toRollback = append ( toRollback , fn ) } return servicemanager . Team . Remove ( name ) } 
func createTeam ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { allowed := permission . Check ( t , permission . PermTeamCreate ) if ! allowed { return permission . ErrUnauthorized } var team authTypes . Team if err := ParseInput ( r , & team ) ; err != nil { return err } tags , _ := InputValues ( r , " " ) team . Tags = append ( team . Tags , tags ... ) evt , err := event . New ( & event . Opts { Target : teamTarget ( team . Name ) , Kind : permission . PermTeamCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermTeamReadEvents , permission . Context ( permTypes . CtxTeam , team . Name ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) u , err := t . User ( ) if err != nil { return err } err = servicemanager . Team . Create ( team . Name , team . Tags , u ) switch err { case authTypes . ErrInvalidTeamName : return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } case authTypes . ErrTeamAlreadyExists : return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) } } if err == nil { w . WriteHeader ( http . StatusCreated ) } return err } 
func removeTeam ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { name := r . URL . Query ( ) . Get ( " " ) allowed := permission . Check ( t , permission . PermTeamDelete , permission . Context ( permTypes . CtxTeam , name ) , ) if ! allowed { return & errors . HTTP { Code : http . StatusNotFound , Message : fmt . Sprintf ( `Team "%s" not found.` , name ) } } evt , err := event . New ( & event . Opts { Target : teamTarget ( name ) , Kind : permission . PermTeamDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermTeamReadEvents , permission . Context ( permTypes . CtxTeam , name ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = servicemanager . Team . Remove ( name ) if err != nil { if _ , ok := err . ( * authTypes . ErrTeamStillUsed ) ; ok { msg := fmt . Sprintf ( " \n " , err ) return & errors . HTTP { Code : http . StatusForbidden , Message : msg } } if err == authTypes . ErrTeamNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : fmt . Sprintf ( `Team "%s" not found.` , name ) } } return err } return nil } 
func teamList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { permsForTeam := permission . PermissionRegistry . PermissionsWithContextType ( permTypes . CtxTeam ) teams , err := servicemanager . Team . List ( ) if err != nil { return err } teamsMap := map [ string ] authTypes . Team { } permsMap := map [ string ] [ ] string { } perms , err := t . Permissions ( ) if err != nil { return err } for _ , team := range teams { teamsMap [ team . Name ] = team teamCtx := permission . Context ( permTypes . CtxTeam , team . Name ) var parent * permission . PermissionScheme for _ , p := range permsForTeam { if parent != nil && parent . IsParent ( p ) { continue } if permission . CheckFromPermList ( perms , p , teamCtx ) { parent = p permsMap [ team . Name ] = append ( permsMap [ team . Name ] , p . FullName ( ) ) } } } if len ( permsMap ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } var result [ ] map [ string ] interface { } for name , permissions := range permsMap { result = append ( result , map [ string ] interface { } { " " : name , " " : teamsMap [ name ] . Tags , " " : permissions , } ) } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( result ) } 
func teamInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { teamName := r . URL . Query ( ) . Get ( " " ) team , err := servicemanager . Team . FindByName ( teamName ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } canRead := permission . Check ( t , permission . PermTeamRead ) if ! canRead { return permission . ErrUnauthorized } apps , err := app . List ( & app . Filter { Extra : map [ string ] [ ] string { " " : { team . Name } } , TeamOwner : team . Name } ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } pools , err := pool . ListPoolsForTeam ( team . Name ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } users , err := auth . ListUsers ( ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } cachedRoles := make ( map [ string ] permission . Role ) includedUsers := make ( [ ] * apiUser , 0 ) for _ , user := range users { for _ , roleInstance := range user . Roles { role , ok := cachedRoles [ roleInstance . Name ] if ! ok { roleFound , err := permission . FindRole ( roleInstance . Name ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } cachedRoles [ roleInstance . Name ] = roleFound role = cachedRoles [ roleInstance . Name ] } if role . ContextType == permTypes . CtxGlobal || ( role . ContextType == permTypes . CtxTeam && roleInstance . ContextValue == team . Name ) { canInclude := permission . Check ( t , permission . PermTeam ) if canInclude { roleMap := make ( map [ string ] * permission . Role ) perms , err := t . Permissions ( ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } userData , err := createAPIUser ( perms , & user , roleMap , canInclude ) if err != nil { return & errors . HTTP { Code : http . StatusInternalServerError , Message : err . Error ( ) } } includedUsers = append ( includedUsers , userData ) break } } } } result := map [ string ] interface { } { " " : team . Name , " " : team . Tags , " " : includedUsers , " " : pools , " " : apps , } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( result ) } 
func addKeyToUser ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { key := repository . Key { Body : InputValue ( r , " " ) , Name : InputValue ( r , " " ) , } var force bool if InputValue ( r , " " ) == " " { force = true } allowed := permission . Check ( t , permission . PermUserUpdateKeyAdd , permission . Context ( permTypes . CtxUser , t . GetUserName ( ) ) , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : userTarget ( t . GetUserName ( ) ) , Kind : permission . PermUserUpdateKeyAdd , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , t . GetUserName ( ) ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) if key . Body == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } u , err := auth . ConvertNewUser ( t . User ( ) ) if err != nil { return err } err = u . AddKey ( key , force ) if err == authTypes . ErrKeyDisabled || err == repository . ErrUserNotFound { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } if err == repository . ErrKeyAlreadyExists { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) } } return err } 
func removeKeyFromUser ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { key := repository . Key { Name : r . URL . Query ( ) . Get ( " " ) , } if key . Name == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } allowed := permission . Check ( t , permission . PermUserUpdateKeyRemove , permission . Context ( permTypes . CtxUser , t . GetUserName ( ) ) , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : userTarget ( t . GetUserName ( ) ) , Kind : permission . PermUserUpdateKeyRemove , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , t . GetUserName ( ) ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) u , err := auth . ConvertNewUser ( t . User ( ) ) if err != nil { return err } err = u . RemoveKey ( key ) if err == authTypes . ErrKeyDisabled { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } if err == repository . ErrKeyNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : " " } } return err } 
func listKeys ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { u , err := auth . ConvertNewUser ( t . User ( ) ) if err != nil { return err } keys , err := u . ListKeys ( ) if err == authTypes . ErrKeyDisabled { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } if err != nil { return err } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( keys ) } 
func removeUser ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { email := r . URL . Query ( ) . Get ( " " ) if email == " " { email = t . GetUserName ( ) } allowed := permission . Check ( t , permission . PermUserDelete , permission . Context ( permTypes . CtxUser , email ) , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : userTarget ( email ) , Kind : permission . PermUserDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , email ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) u , err := auth . GetUserByEmail ( email ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } appNames , err := deployableApps ( u , make ( map [ string ] * permission . Role ) ) if err != nil { return err } manager := repository . Manager ( ) for _ , name := range appNames { manager . RevokeAccess ( name , u . Email ) } if err := manager . RemoveUser ( u . Email ) ; err != nil { log . Errorf ( " " , err ) } return app . AuthScheme . Remove ( u ) } 
func authScheme ( w http . ResponseWriter , r * http . Request ) error { info , err := app . AuthScheme . Info ( ) if err != nil { return err } data := schemeData { Name : app . AuthScheme . Name ( ) , Data : info } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( data ) } 
func regenerateAPIToken ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { email := r . URL . Query ( ) . Get ( " " ) if email == " " { email = t . GetUserName ( ) } allowed := permission . Check ( t , permission . PermUserUpdateToken , permission . Context ( permTypes . CtxUser , email ) , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : userTarget ( email ) , Kind : permission . PermUserUpdateToken , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermUserReadEvents , permission . Context ( permTypes . CtxUser , email ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) u , err := auth . GetUserByEmail ( email ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } apiKey , err := u . RegenerateAPIKey ( ) if err != nil { return err } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( apiKey ) } 
func showAPIToken ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { u , err := auth . ConvertNewUser ( t . User ( ) ) if err != nil { return err } email := r . URL . Query ( ) . Get ( " " ) if email != " " { if ! permission . Check ( t , permission . PermUserUpdateToken ) { return permission . ErrUnauthorized } u , err = auth . GetUserByEmail ( email ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } } apiKey , err := u . ShowAPIKey ( ) if err != nil { return err } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( apiKey ) } 
func listUsers ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { userEmail := r . URL . Query ( ) . Get ( " " ) roleName := r . URL . Query ( ) . Get ( " " ) contextValue := r . URL . Query ( ) . Get ( " " ) users , err := auth . ListUsers ( ) if err != nil { return err } apiUsers := make ( [ ] apiUser , 0 , len ( users ) ) roleMap := make ( map [ string ] * permission . Role ) includeAll := permission . Check ( t , permission . PermUserUpdate ) perms , err := t . Permissions ( ) if err != nil { return err } for _ , user := range users { usrData , err := createAPIUser ( perms , & user , roleMap , includeAll ) if err != nil { return err } if usrData == nil { continue } if userEmail == " " && roleName == " " { apiUsers = append ( apiUsers , * usrData ) } if userEmail != " " && usrData . Email == userEmail { apiUsers = append ( apiUsers , * usrData ) } if roleName != " " { for _ , role := range usrData . Roles { if role . Name == roleName { if contextValue != " " && role . ContextValue == contextValue { apiUsers = append ( apiUsers , * usrData ) break } if contextValue == " " { apiUsers = append ( apiUsers , * usrData ) break } } } } } if len ( apiUsers ) == 0 { if contextValue != " " { return & errors . HTTP { Code : http . StatusNotFound , Message : " " } } user , err := auth . ConvertNewUser ( t . User ( ) ) if err != nil { return err } perm , err := user . Permissions ( ) if err != nil { return err } userData , err := createAPIUser ( perm , user , nil , true ) if err != nil { return err } apiUsers = append ( apiUsers , * userData ) } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( apiUsers ) } 
func userInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { user , err := auth . ConvertNewUser ( t . User ( ) ) if err != nil { return err } perms , err := t . Permissions ( ) if err != nil { return err } userData , err := createAPIUser ( perms , user , nil , true ) if err != nil { return err } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( userData ) } 
func platformAdd ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { name := InputValue ( r , " " ) file , _ , err := r . FormFile ( " " ) if err != nil { return & tErrors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } defer file . Close ( ) data , err := ioutil . ReadAll ( file ) if err != nil { return err } if len ( data ) == 0 { return & tErrors . HTTP { Code : http . StatusBadRequest , Message : appTypes . ErrMissingFileContent . Error ( ) } } args := make ( map [ string ] string ) for key , values := range r . Form { args [ key ] = values [ 0 ] } canCreatePlatform := permission . Check ( t , permission . PermPlatformCreate ) if ! canCreatePlatform { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := io . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & io . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePlatform , Value : name } , Kind : permission . PermPlatformCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPlatformReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) evt . SetLogWriter ( writer ) ctx , cancel := evt . CancelableContext ( context . Background ( ) ) err = servicemanager . Platform . Create ( appTypes . PlatformOptions { Name : name , Args : args , Data : data , Output : evt , Ctx : ctx , } ) cancel ( ) if err != nil { return err } writer . Write ( [ ] byte ( " \n " ) ) return nil } 
func platformUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { name := r . URL . Query ( ) . Get ( " " ) file , _ , _ := r . FormFile ( " " ) if file != nil { defer file . Close ( ) } args := make ( map [ string ] string ) for key , values := range r . Form { args [ key ] = values [ 0 ] } canUpdatePlatform := permission . Check ( t , permission . PermPlatformUpdate ) if ! canUpdatePlatform { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := io . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & io . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePlatform , Value : name } , Kind : permission . PermPlatformUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPlatformReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) evt . SetLogWriter ( writer ) ctx , cancel := evt . CancelableContext ( context . Background ( ) ) err = servicemanager . Platform . Update ( appTypes . PlatformOptions { Name : name , Args : args , Input : file , Output : evt , Ctx : ctx , } ) cancel ( ) if err == appTypes . ErrPlatformNotFound { return & tErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } if err != nil { return err } writer . Write ( [ ] byte ( " \n " ) ) return nil } 
func platformRemove ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { canDeletePlatform := permission . Check ( t , permission . PermPlatformDelete ) if ! canDeletePlatform { return permission . ErrUnauthorized } name := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePlatform , Value : name } , Kind : permission . PermPlatformDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPlatformReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = servicemanager . Platform . Remove ( name ) if err == appTypes . ErrPlatformNotFound { return & tErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } 
func platformList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { canUsePlat := permission . Check ( t , permission . PermPlatformUpdate ) || permission . Check ( t , permission . PermPlatformCreate ) platforms , err := servicemanager . Platform . List ( ! canUsePlat ) if err != nil { return err } if len ( platforms ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( platforms ) } 
func platformInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { name := r . URL . Query ( ) . Get ( " " ) canUsePlat := permission . Check ( t , permission . PermPlatformUpdate ) || permission . Check ( t , permission . PermPlatformCreate ) if ! canUsePlat { return permission . ErrUnauthorized } platform , err := servicemanager . Platform . FindByName ( name ) if err == appTypes . ErrPlatformNotFound { return & tErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } if err != nil { return err } images , err := servicemanager . PlatformImage . ListImagesOrDefault ( name ) if err != nil { return err } msg := map [ string ] interface { } { " " : platform , " " : images , } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( msg ) } 
func platformRollback ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { name := r . URL . Query ( ) . Get ( " " ) image := InputValue ( r , " " ) if image == " " { return & tErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } canUpdatePlatform := permission . Check ( t , permission . PermPlatformUpdate ) if ! canUpdatePlatform { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := io . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & io . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePlatform , Value : name } , Kind : permission . PermPlatformUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPlatformReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) evt . SetLogWriter ( writer ) ctx , cancel := evt . CancelableContext ( context . Background ( ) ) err = servicemanager . Platform . Rollback ( appTypes . PlatformOptions { Name : name , ImageName : image , Output : evt , Ctx : ctx , } ) cancel ( ) if err == appTypes . ErrPlatformNotFound { return & tErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } if err != nil { return err } writer . Write ( [ ] byte ( " \n " ) ) return nil } 
func moveContainerHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { params := map [ string ] string { } err = api . ParseInput ( r , & params ) if err != nil { return err } contId := r . URL . Query ( ) . Get ( " " ) to := params [ " " ] if to == " " { return & tsuruErrors . ValidationError { Message : fmt . Sprintf ( " " , contId , to ) } } cont , err := mainDockerProvisioner . GetContainer ( contId ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } permContexts , err := moveContainersPermissionContexts ( cont . HostAddr , to ) if err != nil { return err } if ! permission . Check ( t , permission . PermNodeUpdateMoveContainer , permContexts ... ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeContainer , Value : contId } , Kind : permission . PermNodeUpdateMoveContainer , Owner : t , CustomData : event . FormToCustomData ( r . Form ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permContexts ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 15 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) _ , err = mainDockerProvisioner . moveContainer ( contId , to , evt ) if err != nil { return errors . Wrap ( err , " " ) } fmt . Fprintf ( writer , " \n " ) return nil } 
func moveContainersHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { params := map [ string ] string { } err = api . ParseInput ( r , & params ) if err != nil { return err } from := params [ " " ] to := params [ " " ] if from == " " || to == " " { return & tsuruErrors . ValidationError { Message : fmt . Sprintf ( " " , from , to ) } } permContexts , err := moveContainersPermissionContexts ( from , to ) if err != nil { return err } if ! permission . Check ( t , permission . PermNodeUpdateMoveContainers , permContexts ... ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeNode , Value : from } , Kind : permission . PermNodeUpdateMoveContainers , Owner : t , CustomData : event . FormToCustomData ( r . Form ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permContexts ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 15 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) err = mainDockerProvisioner . MoveContainers ( from , to , evt ) if err != nil { return errors . Wrap ( err , " " ) } fmt . Fprintf ( evt , " \n " ) return nil } 
func logsConfigGetHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { pools , err := permission . ListContextValues ( t , permission . PermPoolUpdateLogs , true ) if err != nil { return err } configEntries , err := container . LogLoadAll ( ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) if len ( pools ) == 0 { return json . NewEncoder ( w ) . Encode ( configEntries ) } newMap := map [ string ] container . DockerLogConfig { } for _ , p := range pools { if entry , ok := configEntries [ p ] ; ok { newMap [ p ] = entry } } return json . NewEncoder ( w ) . Encode ( newMap ) } 
func logsConfigSetHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { pool := api . InputValue ( r , " " ) restart , _ := strconv . ParseBool ( api . InputValue ( r , " " ) ) var conf container . DockerLogConfig err = api . ParseInput ( r , & conf ) if err != nil { return err } var ctxs [ ] permTypes . PermissionContext if pool != " " { ctxs = append ( ctxs , permission . Context ( permTypes . CtxPool , pool ) ) } hasPermission := permission . Check ( t , permission . PermPoolUpdateLogs , ctxs ... ) if ! hasPermission { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : pool } , Kind : permission . PermPoolUpdateLogs , Owner : t , CustomData : event . FormToCustomData ( r . Form ) , DisableLock : true , Allowed : event . Allowed ( permission . PermPoolReadEvents , ctxs ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = conf . Save ( pool ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 15 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) fmt . Fprintln ( evt , " " ) if restart { filter := & app . Filter { } if pool != " " { filter . Pools = [ ] string { pool } } return tryRestartAppsByFilter ( filter , evt ) } return nil } 
func validateVersion ( supported , current string ) bool { if supported == " " { return true } vSupported , err := goVersion . NewVersion ( supported ) if err != nil { return false } vCurrent , err := goVersion . NewVersion ( current ) if err != nil { return false } return vCurrent . Compare ( vSupported ) >= 0 } 
func ReadTarget ( ) ( string , error ) { if target := os . Getenv ( " " ) ; target != " " { targets , err := getTargets ( ) if err == nil { if val , ok := targets [ target ] ; ok { return val , nil } } return target , nil } targetPath := JoinWithUserDir ( " " , " " ) target , err := readTarget ( targetPath ) if err == errUndefinedTarget { copyTargetFiles ( ) target , err = readTarget ( JoinWithUserDir ( " " ) ) } return target , err } 
func WriteTarget ( t string ) error { targetPath := JoinWithUserDir ( " " , " " ) targetFile , err := filesystem ( ) . OpenFile ( targetPath , syscall . O_WRONLY | syscall . O_CREAT | syscall . O_TRUNC , 0600 ) if err != nil { return err } defer targetFile . Close ( ) n , err := targetFile . WriteString ( t ) if n != len ( t ) || err != nil { return errors . New ( " " ) } return nil } 
func WriteOnTargetList ( label , target string ) error { label = strings . TrimSpace ( label ) target = strings . TrimSpace ( target ) targetExist , err := CheckIfTargetLabelExists ( label ) if err != nil { return err } if targetExist { return errors . New ( " " ) } targetsPath := JoinWithUserDir ( " " , " " ) targetsFile , err := filesystem ( ) . OpenFile ( targetsPath , syscall . O_RDWR | syscall . O_CREAT | syscall . O_APPEND , 0600 ) if err != nil { return err } defer targetsFile . Close ( ) content := label + " \t " + target + " \n " n , err := targetsFile . WriteString ( content ) if n != len ( content ) || err != nil { return errors . New ( " " ) } return nil } 
func ( s * SAMLAuthScheme ) loadConfig ( ) ( BaseConfig , error ) { if s . BaseConfig . EntityID != " " { return s . BaseConfig , nil } if s . Parser == nil { s . Parser = s } var emptyConfig BaseConfig publicCert , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } privateKey , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } idpURL , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } displayName , err := config . GetString ( " " ) if err != nil { displayName = " " log . Debugf ( " " , err ) } description , err := config . GetString ( " " ) if err != nil { description = " " log . Debugf ( " " , err ) } idpPublicCert , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } entityId , err := config . GetString ( " " ) if err != nil { return emptyConfig , err } signRequest , err := config . GetBool ( " " ) if err != nil { return emptyConfig , err } signedResponse , err := config . GetBool ( " " ) if err != nil { return emptyConfig , err } deflatEncodedResponse , err := config . GetBool ( " " ) if err != nil { deflatEncodedResponse = false log . Debugf ( " " , err ) } s . BaseConfig = BaseConfig { EntityID : entityId , DisplayName : displayName , Description : description , PublicCert : publicCert , PrivateKey : privateKey , IdpURL : idpURL , IdpPublicCert : idpPublicCert , SignRequest : signRequest , SignedResponse : signedResponse , DeflatEncodedResponse : deflatEncodedResponse , } return s . BaseConfig , nil } 
func build ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { tag := InputValue ( r , " " ) if tag == " " { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } opts , err := prepareToBuild ( r ) if err != nil { return err } if opts . File != nil { defer opts . File . Close ( ) } w . Header ( ) . Set ( " " , " " ) appName := r . URL . Query ( ) . Get ( " " ) var userName string if t . IsAppToken ( ) { if t . GetAppName ( ) != appName && t . GetAppName ( ) != app . InternalAppName { return & tsuruErrors . HTTP { Code : http . StatusUnauthorized , Message : " " } } userName = InputValue ( r , " " ) } else { userName = t . GetUserName ( ) } instance , err := app . GetByName ( appName ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } opts . App = instance opts . BuildTag = tag opts . User = userName opts . GetKind ( ) if t . GetAppName ( ) != app . InternalAppName { canBuild := permission . Check ( t , permission . PermAppBuild , contextsForApp ( instance ) ... ) if ! canBuild { return & tsuruErrors . HTTP { Code : http . StatusForbidden , Message : " " } } } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppBuild , RawOwner : event . Owner { Type : event . OwnerTypeUser , Name : userName } , CustomData : opts , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( instance ) ... ) , AllowedCancel : event . Allowed ( permission . PermAppUpdateEvents , contextsForApp ( instance ) ... ) , Cancelable : true , } ) if err != nil { return err } var imageID string defer func ( ) { evt . DoneCustomData ( err , map [ string ] string { " " : imageID } ) } ( ) opts . Event = evt writer := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer writer . Stop ( ) opts . OutputStream = writer imageID , err = app . Build ( opts ) if err == nil { fmt . Fprintln ( w , imageID ) fmt . Fprintln ( w , " " ) } return err } 
func BuildHealthCheck ( routerName string ) func ( ) error { return func ( ) error { routerConfig , err := config . Get ( " " ) if err != nil { return hc . ErrDisabledComponent } routers , _ := routerConfig . ( map [ interface { } ] interface { } ) checkCount := 0 for ifaceName := range routers { name := ifaceName . ( string ) if name != routerName { namedRouter := routers [ name ] . ( map [ interface { } ] interface { } ) if tp , _ := namedRouter [ " " ] . ( string ) ; tp != routerName { continue } } checkCount ++ err := healthCheck ( name ) if err != nil { return err } } if checkCount == 0 { return hc . ErrDisabledComponent } return nil } } 
func Conn ( ) ( * Storage , error ) { var ( strg Storage err error ) url , dbname := DbConfig ( " " ) strg . Storage , err = storage . Open ( url , dbname ) return & strg , err } 
func ( s * Storage ) Apps ( ) * storage . Collection { nameIndex := mgo . Index { Key : [ ] string { " " } , Unique : true } c := s . Collection ( " " ) c . EnsureIndex ( nameIndex ) return c } 
func ( s * Storage ) PoolsConstraints ( ) * storage . Collection { poolConstraintIndex := mgo . Index { Key : [ ] string { " " , " " } , Unique : true } c := s . Collection ( " " ) c . EnsureIndex ( poolConstraintIndex ) return c } 
func ( s * Storage ) Users ( ) * storage . Collection { emailIndex := mgo . Index { Key : [ ] string { " " } , Unique : true } c := s . Collection ( " " ) c . EnsureIndex ( emailIndex ) return c } 
func ( s * Storage ) SAMLRequests ( ) * storage . Collection { id := mgo . Index { Key : [ ] string { " " } } coll := s . Collection ( " " ) coll . EnsureIndex ( id ) return coll } 
func ( s * LogStorage ) AppLogCollection ( appName string ) * storage . Collection { if appName == " " { return nil } return s . Collection ( " " + appName ) } 
func ( s * LogStorage ) CreateAppLogCollection ( appName string ) ( * storage . Collection , error ) { c := s . AppLogCollection ( appName ) err := c . Create ( & logCappedInfo ) return c , err } 
func ( s * LogStorage ) LogsCollections ( ) ( [ ] * storage . Collection , error ) { var names [ ] struct { Name string } conn , err := Conn ( ) if err != nil { return nil , err } defer conn . Close ( ) err = conn . Apps ( ) . Find ( nil ) . All ( & names ) if err != nil { return nil , err } var colls [ ] * storage . Collection for _ , name := range names { colls = append ( colls , s . Collection ( " " + name . Name ) ) } return colls , nil } 
func ArchiveBuildCmds ( app provision . App , archiveURL string ) [ ] string { return buildCmds ( app , " " , " " , archiveURL ) } 
func ArchiveDeployCmds ( app provision . App , archiveURL string ) [ ] string { return buildCmds ( app , " " , " " , archiveURL ) } 
func DeployCmds ( app provision . App ) [ ] string { uaCmds := unitAgentCmds ( app ) uaCmds = append ( uaCmds , " " ) finalCmd := strings . Join ( uaCmds , " " ) return [ ] string { " " , " " , finalCmd } } 
func runWithAgentCmds ( app provision . App ) ( [ ] string , error ) { runCmd , err := config . GetString ( " " ) if err != nil { runCmd = " " } host , _ := config . GetString ( " " ) token := app . Envs ( ) [ " " ] . Value return [ ] string { " " , host , token , app . GetName ( ) , runCmd } , nil } 
func newApps ( c * TsuruV1Client , namespace string ) * apps { return & apps { client : c . RESTClient ( ) , ns : namespace , } } 
func ( c * apps ) Get ( name string , options meta_v1 . GetOptions ) ( result * v1 . App , err error ) { result = & v1 . App { } err = c . client . Get ( ) . Namespace ( c . ns ) . Resource ( " " ) . Name ( name ) . VersionedParams ( & options , scheme . ParameterCodec ) . Do ( ) . Into ( result ) return } 
func ( c * apps ) List ( opts meta_v1 . ListOptions ) ( result * v1 . AppList , err error ) { result = & v1 . AppList { } err = c . client . Get ( ) . Namespace ( c . ns ) . Resource ( " " ) . VersionedParams ( & opts , scheme . ParameterCodec ) . Do ( ) . Into ( result ) return } 
func ( c * apps ) Create ( app * v1 . App ) ( result * v1 . App , err error ) { result = & v1 . App { } err = c . client . Post ( ) . Namespace ( c . ns ) . Resource ( " " ) . Body ( app ) . Do ( ) . Into ( result ) return } 
func ( c * apps ) Update ( app * v1 . App ) ( result * v1 . App , err error ) { result = & v1 . App { } err = c . client . Put ( ) . Namespace ( c . ns ) . Resource ( " " ) . Name ( app . Name ) . Body ( app ) . Do ( ) . Into ( result ) return } 
func ( c * apps ) Delete ( name string , options * meta_v1 . DeleteOptions ) error { return c . client . Delete ( ) . Namespace ( c . ns ) . Resource ( " " ) . Name ( name ) . Body ( options ) . Do ( ) . Error ( ) } 
func ( c * Container ) Commit ( client provision . BuilderDockerClient , limiter provision . ActionLimiter , writer io . Writer , isDeploy bool ) ( string , error ) { log . Debugf ( " " , c . ID ) repository , tag := image . SplitImageName ( c . BuildingImage ) opts := docker . CommitContainerOptions { Container : c . ID , Repository : repository , Tag : tag } done := limiter . Start ( c . HostAddr ) image , err := client . CommitContainer ( opts ) done ( ) if err != nil { return " " , log . WrapError ( errors . Wrapf ( err , " " , c . ID ) ) } tags := [ ] string { tag } if isDeploy && tag != " " { tags = append ( tags , " " ) err = client . TagImage ( fmt . Sprintf ( " " , repository , tag ) , docker . TagImageOptions { Repo : repository , Tag : " " , Force : true , } ) if err != nil { return " " , log . WrapError ( errors . Wrapf ( err , " " , c . ID ) ) } } imgHistory , err := client . ImageHistory ( c . BuildingImage ) imgSize := " " if err == nil && len ( imgHistory ) > 0 { fullSize := imgHistory [ 0 ] . Size if len ( imgHistory ) > 1 && strings . Contains ( imgHistory [ 1 ] . CreatedBy , " " ) { fullSize += imgHistory [ 1 ] . Size } imgSize = fmt . Sprintf ( " " , float64 ( fullSize ) / 1024 / 1024 ) } fmt . Fprintf ( writer , " \n " , imgSize ) log . Debugf ( " " , image . ID , c . ID ) for _ , tag := range tags { maxTry , _ := config . GetInt ( " " ) if maxTry <= 0 { maxTry = 3 } for i := 0 ; i < maxTry ; i ++ { err = dockercommon . PushImage ( client , repository , tag , dockercommon . RegistryAuthConfig ( repository ) ) if err != nil { fmt . Fprintf ( writer , " \n " , err . Error ( ) ) log . Errorf ( " " , c . BuildingImage , err ) time . Sleep ( time . Second ) continue } break } if err != nil { return " " , log . WrapError ( errors . Wrapf ( err , " " , c . BuildingImage ) ) } } return c . BuildingImage , nil } 
func ParseToken ( header string ) ( string , error ) { s := strings . Split ( header , " " ) var value string if len ( s ) < 3 { value = s [ len ( s ) - 1 ] } if value != " " { return value , nil } return value , ErrInvalidToken } 
func processTags ( tags [ ] string ) [ ] string { if tags == nil { return nil } processedTags := [ ] string { } usedTags := make ( map [ string ] bool ) for _ , tag := range tags { tag = strings . TrimSpace ( tag ) if len ( tag ) > 0 && ! usedTags [ tag ] { processedTags = append ( processedTags , tag ) usedTags [ tag ] = true } } return processedTags } 
func ( s * segregatedScheduler ) aggregateContainersBy ( matcher bson . M ) ( map [ string ] int , error ) { coll := s . provisioner . Collection ( ) defer coll . Close ( ) pipe := coll . Pipe ( [ ] bson . M { matcher , { " " : bson . M { " " : " " , " " : bson . M { " " : 1 } } } , } ) var results [ ] nodeAggregate err := pipe . All ( & results ) if err != nil { return nil , err } countMap := make ( map [ string ] int ) for _ , result := range results { countMap [ result . HostAddr ] = result . Count } return countMap , nil } 
func ( s * segregatedScheduler ) chooseNodeToAdd ( nodes [ ] cluster . Node , contName string , appName , process string ) ( string , error ) { log . Debugf ( " " , contName , nodes ) s . hostMutex . Lock ( ) defer s . hostMutex . Unlock ( ) chosenNode , _ , err := s . minMaxNodes ( nodes , appName , process ) if err != nil { return " " , err } log . Debugf ( " " , contName , chosenNode ) if contName != " " { coll := s . provisioner . Collection ( ) defer coll . Close ( ) err = coll . Update ( bson . M { " " : contName } , bson . M { " " : bson . M { " " : net . URLToHost ( chosenNode ) } } ) } return chosenNode , err } 
func ( s * segregatedScheduler ) chooseContainerToRemove ( nodes [ ] cluster . Node , appName , process string ) ( string , error ) { _ , chosenNode , err := s . minMaxNodes ( nodes , appName , process ) if err != nil { return " " , err } log . Debugf ( " " , chosenNode ) containerID , err := s . getContainerPreferablyFromHost ( chosenNode , appName , process ) if err != nil { return " " , err } return containerID , err } 
func ( s * segregatedScheduler ) minMaxNodes ( nodes [ ] cluster . Node , appName , process string ) ( string , string , error ) { nodesList := make ( node . NodeList , len ( nodes ) ) for i := range nodes { nodesList [ i ] = & clusterNodeWrapper { Node : & nodes [ i ] , prov : s . provisioner } } metaFreqList , _ , err := nodesList . SplitMetadata ( ) if err != nil { log . Debugf ( " " , err ) } hostGroupMap := map [ string ] int { } for i , m := range metaFreqList { for _ , n := range m . Nodes { hostGroupMap [ net . URLToHost ( n . Address ( ) ) ] = i } } hosts , hostsMap := s . nodesToHosts ( nodes ) hostCountMap , err := s . aggregateContainersByHost ( hosts ) if err != nil { return " " , " " , err } appCountMap , err := s . aggregateContainersByHostAppProcess ( hosts , appName , process ) if err != nil { return " " , " " , err } priorityEntries := [ ] map [ string ] int { appGroupCount ( hostGroupMap , appCountMap ) , appCountMap , hostCountMap } var minHost , maxHost string var minScore uint64 = math . MaxUint64 var maxScore uint64 = 0 for _ , host := range hosts { var score uint64 for i , e := range priorityEntries { score += uint64 ( e [ host ] ) << uint ( ( len ( priorityEntries ) - i - 1 ) * ( 64 / len ( priorityEntries ) ) ) } if score < minScore { minScore = score minHost = host } if score >= maxScore { maxScore = score maxHost = host } } return hostsMap [ minHost ] , hostsMap [ maxHost ] , nil } 
func listRouters ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { contexts := permission . ContextsForPermission ( t , permission . PermAppCreate ) var teams [ ] string var global bool contexts : for _ , c := range contexts { switch c . CtxType { case permTypes . CtxGlobal : global = true break contexts case permTypes . CtxTeam : teams = append ( teams , c . Value ) } } routers , err := router . ListWithInfo ( ) if err != nil { return err } filteredRouters := routers if ! global { routersAllowed := make ( map [ string ] struct { } ) filteredRouters = [ ] router . PlanRouter { } pools , err := pool . ListPossiblePools ( teams ) if err != nil { return err } for _ , p := range pools { rs , err := p . GetRouters ( ) if err != nil { return err } for _ , r := range rs { routersAllowed [ r ] = struct { } { } } } for _ , r := range routers { if _ , ok := routersAllowed [ r . Name ] ; ok { filteredRouters = append ( filteredRouters , r ) } } } if len ( filteredRouters ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( filteredRouters ) } 
func addAppRouter ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var appRouter appTypes . AppRouter err = ParseInput ( r , & appRouter ) if err != nil { return err } appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } _ , err = router . Get ( appRouter . Name ) if err != nil { if _ , isNotFound := err . ( * router . ErrRouterNotFound ) ; isNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } allowed := permission . Check ( t , permission . PermAppUpdateRouterAdd , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } p , err := pool . GetPoolByName ( a . Pool ) if err != nil { return err } err = p . ValidateRouters ( [ ] appTypes . AppRouter { appRouter } ) if err != nil { if err == pool . ErrPoolHasNoRouter { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } return err } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateRouterAdd , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return a . AddRouter ( appRouter ) } 
func removeAppRouter ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { appName := r . URL . Query ( ) . Get ( " " ) routerName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateRouterRemove , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateRouterRemove , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = a . RemoveRouter ( routerName ) if _ , isNotFound := err . ( * router . ErrRouterNotFound ) ; isNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } 
func listAppRouters ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { a , err := getAppFromContext ( r . URL . Query ( ) . Get ( " " ) , r ) if err != nil { return err } canRead := permission . Check ( t , permission . PermAppReadRouter , contextsForApp ( & a ) ... , ) if ! canRead { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) routers , err := a . GetRoutersWithAddr ( ) if err != nil { return err } if len ( routers ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } return json . NewEncoder ( w ) . Encode ( routers ) } 
func Get ( name string ) ( Router , error ) { routerType , prefix , err := Type ( name ) if err != nil { return nil , & ErrRouterNotFound { Name : name } } factory , ok := routers [ routerType ] if ! ok { return nil , errors . Errorf ( " " , routerType ) } r , err := factory ( name , prefix ) if err != nil { return nil , err } return r , nil } 
func Default ( ) ( string , error ) { plans , err := List ( ) if err != nil { return " " , err } if len ( plans ) == 0 { return " " , ErrDefaultRouterNotFound } if len ( plans ) == 1 { return plans [ 0 ] . Name , nil } for _ , p := range plans { if p . Default { return p . Name , nil } } return " " , ErrDefaultRouterNotFound } 
func Store ( appName , routerName , kind string ) error { coll , err := collection ( ) if err != nil { return err } defer coll . Close ( ) data := routerAppEntry { App : appName , Router : routerName , Kind : kind , } _ , err = coll . Upsert ( bson . M { " " : appName } , data ) return err } 
func serviceList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { contexts := permission . ContextsForPermission ( t , permission . PermServiceRead ) services , err := provisionReadableServices ( t , contexts ) if err != nil { return err } sInstances , err := service . GetServiceInstancesByServices ( services ) if err != nil { return err } results := make ( [ ] service . ServiceModel , len ( services ) ) for i , s := range services { results [ i ] . Service = s . Name for _ , si := range sInstances { if si . ServiceName == s . Name { results [ i ] . Instances = append ( results [ i ] . Instances , si . Name ) results [ i ] . ServiceInstances = append ( results [ i ] . ServiceInstances , si ) } } } if len ( results ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( results ) } 
func serviceCreate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { s := service . Service { Name : InputValue ( r , " " ) , Username : InputValue ( r , " " ) , Endpoint : map [ string ] string { " " : InputValue ( r , " " ) } , Password : InputValue ( r , " " ) , } team := InputValue ( r , " " ) if team == " " { team , err = permission . TeamForPermission ( t , permission . PermServiceCreate ) if err == permission . ErrTooManyTeams { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } if err != nil { return err } } s . OwnerTeams = [ ] string { team } allowed := permission . Check ( t , permission . PermServiceCreate , permission . Context ( permTypes . CtxTeam , s . OwnerTeams [ 0 ] ) , ) if ! allowed { return permission . ErrUnauthorized } delete ( r . Form , " " ) evt , err := event . New ( & event . Opts { Target : serviceTarget ( s . Name ) , Kind : permission . PermServiceCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceReadEvents , contextsForServiceProvision ( & s ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = service . Create ( s ) if err != nil { if err == service . ErrServiceAlreadyExists { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) } } return err } w . WriteHeader ( http . StatusCreated ) fmt . Fprint ( w , " " ) return nil } 
func serviceUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { d := service . Service { Username : InputValue ( r , " " ) , Endpoint : map [ string ] string { " " : InputValue ( r , " " ) } , Password : InputValue ( r , " " ) , Name : r . URL . Query ( ) . Get ( " " ) , } team := InputValue ( r , " " ) s , err := getService ( d . Name ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceUpdate , contextsForServiceProvision ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } delete ( r . Form , " " ) evt , err := event . New ( & event . Opts { Target : serviceTarget ( s . Name ) , Kind : permission . PermServiceUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceReadEvents , contextsForServiceProvision ( & s ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) s . Endpoint = d . Endpoint s . Password = d . Password s . Username = d . Username if team != " " { s . OwnerTeams = [ ] string { team } } return service . Update ( s ) } 
func serviceDelete ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { s , err := getService ( r . URL . Query ( ) . Get ( " " ) ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceDelete , contextsForServiceProvision ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : serviceTarget ( s . Name ) , Kind : permission . PermServiceDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceReadEvents , contextsForServiceProvision ( & s ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) instances , err := service . GetServiceInstancesByServices ( [ ] service . Service { s } ) if err != nil { return err } if len ( instances ) > 0 { msg := " \n " msg += " " return & errors . HTTP { Code : http . StatusForbidden , Message : msg } } return service . Delete ( s ) } 
func serviceProxy ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { serviceName := r . URL . Query ( ) . Get ( " " ) s , err := getService ( serviceName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceUpdateProxy , contextsForServiceProvision ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } var evt * event . Event if r . Method != http . MethodGet && r . Method != http . MethodHead { evt , err = event . New ( & event . Opts { Target : serviceTarget ( s . Name ) , Kind : permission . PermServiceUpdateProxy , Owner : t , CustomData : append ( event . FormToCustomData ( InputFields ( r ) ) , map [ string ] interface { } { " " : " " , " " : r . Method , } ) , Allowed : event . Allowed ( permission . PermServiceReadEvents , contextsForServiceProvision ( & s ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) } path := r . URL . Query ( ) . Get ( " " ) return service . Proxy ( & s , path , evt , requestIDHeader ( r ) , w , r ) } 
func grantServiceAccess ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { serviceName := r . URL . Query ( ) . Get ( " " ) s , err := getService ( serviceName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceUpdateGrantAccess , contextsForServiceProvision ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } teamName := r . URL . Query ( ) . Get ( " " ) team , err := servicemanager . Team . FindByName ( teamName ) if err != nil { if err == authTypes . ErrTeamNotFound { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } return err } evt , err := event . New ( & event . Opts { Target : serviceTarget ( s . Name ) , Kind : permission . PermServiceUpdateGrantAccess , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceReadEvents , contextsForServiceProvision ( & s ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = s . GrantAccess ( team ) if err != nil { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) } } return service . Update ( s ) } 
func serviceAddDoc ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { serviceName := r . URL . Query ( ) . Get ( " " ) s , err := getService ( serviceName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceUpdateDoc , contextsForServiceProvision ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } s . Doc = InputValue ( r , " " ) evt , err := event . New ( & event . Opts { Target : serviceTarget ( s . Name ) , Kind : permission . PermServiceUpdateDoc , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceReadEvents , contextsForServiceProvision ( & s ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return service . Update ( s ) } 
func NewSimpleClientset ( objects ... runtime . Object ) * Clientset { o := testing . NewObjectTracker ( scheme , codecs . UniversalDecoder ( ) ) for _ , obj := range objects { if err := o . Add ( obj ) ; err != nil { panic ( err ) } } fakePtr := testing . Fake { } fakePtr . AddReactor ( " " , " " , testing . ObjectReaction ( o ) ) fakePtr . AddWatchReactor ( " " , testing . DefaultWatchReactor ( watch . NewFake ( ) , nil ) ) return & Clientset { fakePtr , & fakediscovery . FakeDiscovery { Fake : & fakePtr } } } 
func ( c * Clientset ) TsuruV1 ( ) tsuruv1 . TsuruV1Interface { return & faketsuruv1 . FakeTsuruV1 { Fake : & c . Fake } } 
func ( c * Clientset ) Tsuru ( ) tsuruv1 . TsuruV1Interface { return & faketsuruv1 . FakeTsuruV1 { Fake : & c . Fake } } 
func healthcheck ( w http . ResponseWriter , r * http . Request ) { var checks [ ] string values := r . URL . Query ( ) if values != nil { checks = values [ " " ] } fullHealthcheck ( w , checks ) } 
func NewAppInformer ( client versioned . Interface , namespace string , resyncPeriod time . Duration , indexers cache . Indexers ) cache . SharedIndexInformer { return NewFilteredAppInformer ( client , namespace , resyncPeriod , indexers , nil ) } 
func NewFilteredAppInformer ( client versioned . Interface , namespace string , resyncPeriod time . Duration , indexers cache . Indexers , tweakListOptions internalinterfaces . TweakListOptionsFunc ) cache . SharedIndexInformer { return cache . NewSharedIndexInformer ( & cache . ListWatch { ListFunc : func ( options meta_v1 . ListOptions ) ( runtime . Object , error ) { if tweakListOptions != nil { tweakListOptions ( & options ) } return client . TsuruV1 ( ) . Apps ( namespace ) . List ( options ) } , WatchFunc : func ( options meta_v1 . ListOptions ) ( watch . Interface , error ) { if tweakListOptions != nil { tweakListOptions ( & options ) } return client . TsuruV1 ( ) . Apps ( namespace ) . Watch ( options ) } , } , & tsuru_v1 . App { } , resyncPeriod , indexers , ) } 
func ( c * FakeApps ) Get ( name string , options v1 . GetOptions ) ( result * tsuru_v1 . App , err error ) { obj , err := c . Fake . Invokes ( testing . NewGetAction ( appsResource , c . ns , name ) , & tsuru_v1 . App { } ) if obj == nil { return nil , err } return obj . ( * tsuru_v1 . App ) , err } 
func ( c * FakeApps ) List ( opts v1 . ListOptions ) ( result * tsuru_v1 . AppList , err error ) { obj , err := c . Fake . Invokes ( testing . NewListAction ( appsResource , appsKind , c . ns , opts ) , & tsuru_v1 . AppList { } ) if obj == nil { return nil , err } label , _ , _ := testing . ExtractFromListOptions ( opts ) if label == nil { label = labels . Everything ( ) } list := & tsuru_v1 . AppList { } for _ , item := range obj . ( * tsuru_v1 . AppList ) . Items { if label . Matches ( labels . Set ( item . Labels ) ) { list . Items = append ( list . Items , item ) } } return list , err } 
func ( c * FakeApps ) Watch ( opts v1 . ListOptions ) ( watch . Interface , error ) { return c . Fake . InvokesWatch ( testing . NewWatchAction ( appsResource , c . ns , opts ) ) } 
func ( c * FakeApps ) Create ( app * tsuru_v1 . App ) ( result * tsuru_v1 . App , err error ) { obj , err := c . Fake . Invokes ( testing . NewCreateAction ( appsResource , c . ns , app ) , & tsuru_v1 . App { } ) if obj == nil { return nil , err } return obj . ( * tsuru_v1 . App ) , err } 
func ( c * FakeApps ) Update ( app * tsuru_v1 . App ) ( result * tsuru_v1 . App , err error ) { obj , err := c . Fake . Invokes ( testing . NewUpdateAction ( appsResource , c . ns , app ) , & tsuru_v1 . App { } ) if obj == nil { return nil , err } return obj . ( * tsuru_v1 . App ) , err } 
func ( c * FakeApps ) Delete ( name string , options * v1 . DeleteOptions ) error { _ , err := c . Fake . Invokes ( testing . NewDeleteAction ( appsResource , c . ns , name ) , & tsuru_v1 . App { } ) return err } 
func ( c * FakeApps ) DeleteCollection ( options * v1 . DeleteOptions , listOptions v1 . ListOptions ) error { action := testing . NewDeleteCollectionAction ( appsResource , c . ns , listOptions ) _ , err := c . Fake . Invokes ( action , & tsuru_v1 . AppList { } ) return err } 
func ( c * FakeApps ) Patch ( name string , pt types . PatchType , data [ ] byte , subresources ... string ) ( result * tsuru_v1 . App , err error ) { obj , err := c . Fake . Invokes ( testing . NewPatchSubresourceAction ( appsResource , c . ns , name , data , subresources ... ) , & tsuru_v1 . App { } ) if obj == nil { return nil , err } return obj . ( * tsuru_v1 . App ) , err } 
func NewSharedInformerFactory ( client versioned . Interface , defaultResync time . Duration ) SharedInformerFactory { return NewFilteredSharedInformerFactory ( client , defaultResync , v1 . NamespaceAll , nil ) } 
func NewFilteredSharedInformerFactory ( client versioned . Interface , defaultResync time . Duration , namespace string , tweakListOptions internalinterfaces . TweakListOptionsFunc ) SharedInformerFactory { return & sharedInformerFactory { client : client , namespace : namespace , tweakListOptions : tweakListOptions , defaultResync : defaultResync , informers : make ( map [ reflect . Type ] cache . SharedIndexInformer ) , startedInformers : make ( map [ reflect . Type ] bool ) , } } 
func webhookList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { ctxs := permission . ContextsForPermission ( t , permission . PermWebhookRead , permTypes . CtxTeam ) var teams [ ] string for _ , c := range ctxs { if c . CtxType == permTypes . CtxGlobal { teams = nil break } teams = append ( teams , c . Value ) } webhooks , err := servicemanager . Webhook . List ( teams ) if err != nil { return err } if len ( webhooks ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( webhooks ) } 
func webhookInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { webhookName := r . URL . Query ( ) . Get ( " " ) webhook , err := servicemanager . Webhook . Find ( webhookName ) if err != nil { if err == eventTypes . ErrWebhookNotFound { w . WriteHeader ( http . StatusNotFound ) } return err } ctx := permission . Context ( permTypes . CtxTeam , webhook . TeamOwner ) if ! permission . Check ( t , permission . PermWebhookRead , ctx ) { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( webhook ) } 
func webhookCreate ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { var webhook eventTypes . Webhook err := ParseInput ( r , & webhook ) if err != nil { return err } if webhook . TeamOwner == " " { webhook . TeamOwner , err = autoTeamOwner ( t , permission . PermWebhookCreate ) if err != nil { return err } } ctx := permission . Context ( permTypes . CtxTeam , webhook . TeamOwner ) if ! permission . Check ( t , permission . PermWebhookCreate , ctx ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeWebhook , Value : webhook . Name } , Kind : permission . PermWebhookCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermWebhookReadEvents , ctx ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = servicemanager . Webhook . Create ( webhook ) if err == eventTypes . ErrWebhookAlreadyExists { w . WriteHeader ( http . StatusConflict ) } return err } 
func webhookUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { var webhook eventTypes . Webhook err := ParseInput ( r , & webhook ) if err != nil { return err } webhook . Name = r . URL . Query ( ) . Get ( " " ) ctx := permission . Context ( permTypes . CtxTeam , webhook . TeamOwner ) if ! permission . Check ( t , permission . PermWebhookUpdate , ctx ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeWebhook , Value : webhook . Name } , Kind : permission . PermWebhookUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermWebhookReadEvents , ctx ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = servicemanager . Webhook . Update ( webhook ) if err == eventTypes . ErrWebhookNotFound { w . WriteHeader ( http . StatusNotFound ) } return err } 
func ( b * brokerClient ) Proxy ( path string , evt * event . Event , requestID string , w http . ResponseWriter , r * http . Request ) error { return fmt . Errorf ( " " ) } 
func ( b * brokerClient ) UnbindUnit ( instance * ServiceInstance , app bind . App , unit bind . Unit ) error { return nil } 
func ( s * planService ) Create ( plan appTypes . Plan ) error { if plan . Name == " " { return appTypes . PlanValidationError { Field : " " } } if plan . CpuShare < 2 { return appTypes . ErrLimitOfCpuShare } if plan . Memory > 0 && plan . Memory < 4194304 { return appTypes . ErrLimitOfMemory } return s . storage . Insert ( plan ) } 
func ( s * planService ) Remove ( planName string ) error { return s . storage . Delete ( appTypes . Plan { Name : planName } ) } 
func ( s * planService ) ensureDefault ( ) error { plans , err := s . storage . FindAll ( ) if err != nil { return err } if len ( plans ) > 0 { return nil } configMemory , _ := config . GetInt ( " " ) configSwap , _ := config . GetInt ( " " ) dp := appTypes . Plan { Name : " " , Memory : int64 ( configMemory ) * 1024 * 1024 , Swap : int64 ( configSwap - configMemory ) * 1024 * 1024 , CpuShare : 100 , Default : true , } return s . storage . Insert ( dp ) } 
func DeleteInstance ( si * ServiceInstance , evt * event . Event , requestID string ) error { if len ( si . Apps ) > 0 { return ErrServiceInstanceBound } s , err := Get ( si . ServiceName ) if err != nil { return err } endpoint , err := s . getClient ( " " ) if err == nil { endpoint . Destroy ( si , evt , requestID ) } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) return conn . ServiceInstances ( ) . Remove ( bson . M { " " : si . Name , " " : si . ServiceName } ) } 
func ( si * ServiceInstance ) ToInfo ( ) ( ServiceInstanceWithInfo , error ) { info , err := si . Info ( " " ) if err != nil { info = nil } return ServiceInstanceWithInfo { Id : si . Id , Name : si . Name , Teams : si . Teams , PlanName : si . PlanName , Apps : si . Apps , ServiceName : si . ServiceName , Info : info , TeamOwner : si . TeamOwner , } , nil } 
func ( si * ServiceInstance ) Update ( service Service , updateData ServiceInstance , evt * event . Event , requestID string ) error { err := validateServiceInstanceTeamOwner ( updateData ) if err != nil { return err } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) tags := processTags ( updateData . Tags ) if tags == nil { updateData . Tags = si . Tags } else { updateData . Tags = tags } actions := [ ] * action . Action { & updateServiceInstance , & notifyUpdateServiceInstance } pipeline := action . NewPipeline ( actions ... ) return pipeline . Execute ( service , * si , updateData , evt , requestID ) } 
func ( si * ServiceInstance ) BindApp ( app bind . App , params BindAppParameters , shouldRestart bool , writer io . Writer , evt * event . Event , requestID string ) error { args := bindPipelineArgs { serviceInstance : si , app : app , writer : writer , shouldRestart : shouldRestart , params : params , event : evt , requestID : requestID , } actions := [ ] * action . Action { bindAppDBAction , bindAppEndpointAction , setBoundEnvsAction , bindUnitsAction , } pipeline := action . NewPipeline ( actions ... ) return pipeline . Execute ( & args ) } 
func ( si * ServiceInstance ) BindUnit ( app bind . App , unit bind . Unit ) error { s , err := Get ( si . ServiceName ) if err != nil { return err } endpoint , err := s . getClient ( " " ) if err != nil { return err } conn , err := db . Conn ( ) if err != nil { return err } updateOp := bson . M { " " : bson . M { " " : bson . D ( [ ] bson . DocElem { { Name : " " , Value : app . GetName ( ) } , { Name : " " , Value : unit . GetID ( ) } , { Name : " " , Value : unit . GetIp ( ) } , } ) , } , } err = conn . ServiceInstances ( ) . Update ( bson . M { " " : si . Name , " " : si . ServiceName , " " : bson . M { " " : unit . GetID ( ) } } , updateOp ) conn . Close ( ) if err != nil { if err == mgo . ErrNotFound { return nil } return err } err = endpoint . BindUnit ( si , app , unit ) if err != nil { updateOp = bson . M { " " : bson . M { " " : bson . D ( [ ] bson . DocElem { { Name : " " , Value : app . GetName ( ) } , { Name : " " , Value : unit . GetID ( ) } , { Name : " " , Value : unit . GetIp ( ) } , } ) , } , } rollbackErr := si . updateData ( updateOp ) if rollbackErr != nil { log . Errorf ( " " , rollbackErr ) } return err } return nil } 
func ( si * ServiceInstance ) UnbindApp ( unbindArgs UnbindAppArgs ) error { if si . FindApp ( unbindArgs . App . GetName ( ) ) == - 1 { return ErrAppNotBound } args := bindPipelineArgs { serviceInstance : si , app : unbindArgs . App , writer : unbindArgs . Event , shouldRestart : unbindArgs . Restart , event : unbindArgs . Event , requestID : unbindArgs . RequestID , forceRemove : unbindArgs . ForceRemove , } actions := [ ] * action . Action { & unbindUnits , & unbindAppDB , & unbindAppEndpoint , & removeBoundEnvs , } pipeline := action . NewPipeline ( actions ... ) return pipeline . Execute ( & args ) } 
func ( si * ServiceInstance ) Status ( requestID string ) ( string , error ) { s , err := Get ( si . ServiceName ) if err != nil { return " " , err } endpoint , err := s . getClient ( " " ) if err != nil { return " " , err } return endpoint . Status ( si , requestID ) } 
func ProxyInstance ( instance * ServiceInstance , path string , evt * event . Event , requestID string , w http . ResponseWriter , r * http . Request ) error { service , err := Get ( instance . ServiceName ) if err != nil { return err } endpoint , err := service . getClient ( " " ) if err != nil { return err } prefix := fmt . Sprintf ( " " , instance . GetIdentifier ( ) ) path = strings . Trim ( strings . TrimPrefix ( path + " " , prefix ) , " " ) for _ , reserved := range reservedProxyPaths { if path == reserved && r . Method != " " { return & tsuruErrors . ValidationError { Message : fmt . Sprintf ( " " , r . Method , path ) , } } } return endpoint . Proxy ( fmt . Sprintf ( " " , prefix , path ) , evt , requestID , w , r ) } 
func ( s * QuotaService ) Inc ( appName string , quantity int ) error { quota , err := s . Storage . Get ( appName ) if err != nil { return err } err = s . checkLimit ( quota , quantity ) if err != nil { return err } return s . Storage . Inc ( appName , quantity ) } 
func ( s * QuotaService ) SetLimit ( appName string , limit int ) error { q , err := s . Storage . Get ( appName ) if err != nil { return err } if limit < 0 { limit = - 1 } else if limit < q . InUse { return quota . ErrLimitLowerThanAllocated } return s . Storage . SetLimit ( appName , limit ) } 
func ( s * QuotaService ) Set ( appName string , inUse int ) error { q , err := s . Storage . Get ( appName ) if err != nil { return err } if inUse < 0 { return quota . ErrLessThanZero } if ! q . IsUnlimited ( ) && inUse > q . Limit { return & quota . QuotaExceededError { Requested : uint ( inUse ) , Available : uint ( q . Limit ) , } } return s . Storage . Set ( appName , inUse ) } 
func ( s * QuotaService ) Get ( appName string ) ( * quota . Quota , error ) { return s . Storage . Get ( appName ) } 
func installHostAdd ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermInstallManage ) if ! allowed { return permission . ErrUnauthorized } var host * install . Host err = ParseInput ( r , & host ) if err != nil { return err } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeInstallHost , Value : host . Name } , Kind : permission . PermInstallManage , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermInstallManage ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) var rawDriver map [ string ] interface { } err = json . Unmarshal ( [ ] byte ( r . Form . Get ( " " ) ) , & rawDriver ) if err != nil { return err } host . Driver = rawDriver err = install . AddHost ( host ) if err != nil { return err } w . WriteHeader ( http . StatusCreated ) return nil } 
func installHostInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { allowed := permission . Check ( t , permission . PermInstallManage ) if ! allowed { return permission . ErrUnauthorized } host , err := install . GetHostByName ( r . URL . Query ( ) . Get ( " " ) ) if errNf , ok := err . ( * install . ErrHostNotFound ) ; ok { return & errors . HTTP { Code : http . StatusNotFound , Message : fmt . Sprintf ( " " , errNf . Name ) } } if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( & host ) } 
func installHostList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { allowed := permission . Check ( t , permission . PermInstallManage ) if ! allowed { return permission . ErrUnauthorized } hosts , err := install . ListHosts ( ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( & hosts ) } 
func MigrateUniqueCollection ( ) error { conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) coll := conn . Collection ( " " ) appColl := conn . Apps ( ) var appNames [ ] string err = appColl . Find ( nil ) . Distinct ( " " , & appNames ) if err != nil { return err } _ , err = coll . RemoveAll ( bson . M { " " : bson . M { " " : appNames } , " " : bson . M { " " : appNames } } ) if err != nil { return err } byAppMap , err := allDupEntries ( coll ) if err != nil { return err } var toRemove [ ] bson . ObjectId for appName , appEntries := range byAppMap { toRemoveDups := checkAllDups ( appEntries ) toRemove = append ( toRemove , toRemoveDups ... ) var toRemoveAddrs [ ] bson . ObjectId toRemoveAddrs , err = checkAppAddr ( appColl , appName , appEntries ) if err != nil { return err } toRemove = append ( toRemove , toRemoveAddrs ... ) } _ , err = coll . RemoveAll ( bson . M { " " : bson . M { " " : toRemove } } ) if err != nil { return err } var routerAppNames [ ] string err = coll . Find ( nil ) . Distinct ( " " , & routerAppNames ) if err != nil { return err } var missingApps [ ] string err = appColl . Find ( bson . M { " " : bson . M { " " : routerAppNames } } ) . Distinct ( " " , & missingApps ) if err != nil { return err } for _ , missingEntry := range missingApps { err = coll . Insert ( routerAppEntry { App : missingEntry , Router : missingEntry , } ) if err != nil { return err } } byAppMap , err = allDupEntries ( coll ) if err != nil { return err } if len ( byAppMap ) == 0 { _ , err = collection ( ) return err } errBuf := bytes . NewBuffer ( nil ) fmt . Fprintln ( errBuf , `ERROR: The following entries in 'db.routers' collection have inconsistent duplicated entries that could not be fixed automatically. This could have happened after running app-swap due to a bug in previous tsuru versions. You'll have to manually check if the apps are swapped or not and remove the duplicated entries accordingly:` ) for appName , entries := range byAppMap { fmt . Fprintf ( errBuf , " \n " , appName ) for _ , e := range entries { fmt . Fprintf ( errBuf , " \n " , e ) } } return errors . New ( errBuf . String ( ) ) } 
func RemoveImage ( imageName string ) error { registry , image , tag := parseImage ( imageName ) if registry == " " { registry , _ = config . GetString ( " " ) } if registry == " " { } if image == " " { return errors . Errorf ( " " , imageName ) } r := & dockerRegistry { server : registry } digest , err := r . getDigest ( image , tag ) if err != nil { return errors . Wrapf ( err , " " , r . server , image , tag ) } err = r . removeImage ( image , digest ) if err != nil { return errors . Wrapf ( err , " " , r . server , image , tag , digest ) } return nil } 
func RemoveAppImages ( appName string ) error { registry , _ := config . GetString ( " " ) if registry == " " { } r := & dockerRegistry { server : registry } image := fmt . Sprintf ( " " , appName ) tags , err := r . getImageTags ( image ) if err != nil { return err } multi := tsuruErrors . NewMultiError ( ) for _ , tag := range tags { digest , err := r . getDigest ( image , tag ) if err != nil { multi . Add ( errors . Wrapf ( err , " " , r . server , image , tag ) ) continue } err = r . removeImage ( image , digest ) if err != nil { multi . Add ( errors . Wrapf ( err , " " , r . server , image , tag , digest ) ) if errors . Cause ( err ) == ErrDeleteDisabled { break } } } return multi . ToError ( ) } 
func ( s * platformService ) Create ( opts appTypes . PlatformOptions ) error { p := appTypes . Platform { Name : opts . Name } if err := s . validate ( p ) ; err != nil { return err } err := s . storage . Insert ( p ) if err != nil { return err } opts . ImageName , err = servicemanager . PlatformImage . NewImage ( opts . Name ) if err != nil { return err } err = builder . PlatformAdd ( opts ) if err != nil { if imgErr := servicemanager . PlatformImage . DeleteImages ( opts . Name ) ; imgErr != nil { log . Errorf ( " " , imgErr ) } dbErr := s . storage . Delete ( p ) if dbErr != nil { return tsuruErrors . NewMultiError ( errors . Wrapf ( dbErr , " " ) , errors . Wrapf ( err , " " ) , ) } return err } return servicemanager . PlatformImage . AppendImage ( opts . Name , opts . ImageName ) } 
func ( s * platformService ) List ( enabledOnly bool ) ( [ ] appTypes . Platform , error ) { if enabledOnly { return s . storage . FindEnabled ( ) } return s . storage . FindAll ( ) } 
func ( s * platformService ) FindByName ( name string ) ( * appTypes . Platform , error ) { p , err := s . storage . FindByName ( name ) if err != nil { return nil , appTypes . ErrInvalidPlatform } return p , nil } 
func ( s * platformService ) Update ( opts appTypes . PlatformOptions ) error { if opts . Name == " " { return appTypes . ErrPlatformNameMissing } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) _ , err = s . FindByName ( opts . Name ) if err != nil { return err } if opts . Input != nil { data , err := ioutil . ReadAll ( opts . Input ) if err != nil { return err } if len ( data ) == 0 { return appTypes . ErrMissingFileContent } opts . Data = data opts . ImageName , err = servicemanager . PlatformImage . NewImage ( opts . Name ) if err != nil { return err } err = builder . PlatformUpdate ( opts ) if err != nil { return err } err = servicemanager . PlatformImage . AppendImage ( opts . Name , opts . ImageName ) if err != nil { return err } var apps [ ] App err = conn . Apps ( ) . Find ( bson . M { " " : opts . Name } ) . All ( & apps ) if err != nil { return err } for _ , app := range apps { app . SetUpdatePlatform ( true ) } } if opts . Args [ " " ] != " " { disableBool , err := strconv . ParseBool ( opts . Args [ " " ] ) if err != nil { return err } return s . storage . Update ( appTypes . Platform { Name : opts . Name , Disabled : disableBool } ) } return nil } 
func ( s * platformService ) Remove ( name string ) error { if name == " " { return appTypes . ErrPlatformNameMissing } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) apps , _ := conn . Apps ( ) . Find ( bson . M { " " : name } ) . Count ( ) if apps > 0 { return appTypes . ErrDeletePlatformWithApps } err = builder . PlatformRemove ( name ) if err != nil { log . Errorf ( " " , err ) } images , err := servicemanager . PlatformImage . ListImagesOrDefault ( name ) if err == nil { for _ , img := range images { if regErr := registry . RemoveImage ( img ) ; regErr != nil { log . Errorf ( " " , regErr ) } } } else { log . Errorf ( " " , err ) } err = servicemanager . PlatformImage . DeleteImages ( name ) if err != nil { log . Errorf ( " " , err ) } return s . storage . Delete ( appTypes . Platform { Name : name } ) } 
func ( s * platformService ) Rollback ( opts appTypes . PlatformOptions ) error { if opts . Name == " " { return appTypes . ErrPlatformNameMissing } if opts . ImageName == " " { return appTypes . ErrPlatformImageMissing } _ , err := s . FindByName ( opts . Name ) if err != nil { return err } image , err := servicemanager . PlatformImage . FindImage ( opts . Name , opts . ImageName ) if err != nil { return err } if image == " " { return fmt . Errorf ( " " , opts . ImageName , opts . Name ) } opts . Data = [ ] byte ( " " + image ) opts . ImageName , err = servicemanager . PlatformImage . NewImage ( opts . Name ) if err != nil { return err } err = builder . PlatformUpdate ( opts ) if err != nil { return err } err = servicemanager . PlatformImage . AppendImage ( opts . Name , opts . ImageName ) if err != nil { return err } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) var apps [ ] App err = conn . Apps ( ) . Find ( bson . M { " " : opts . Name } ) . All ( & apps ) if err != nil { return err } for _ , app := range apps { app . SetUpdatePlatform ( true ) } return nil } 
func index ( w http . ResponseWriter , r * http . Request ) error { host , _ := config . GetString ( " " ) userCreate , _ := config . GetBool ( " " ) scheme , _ := config . GetString ( " " ) repoManager , _ := config . GetString ( " " ) data := map [ string ] interface { } { " " : host , " " : userCreate , " " : scheme == " " || scheme == " " , " " : repoManager == " " || repoManager == " " , } template , err := getTemplate ( ) if err != nil { return err } return template . Execute ( w , data ) } 
func GetPoolByName ( name string ) ( * Pool , error ) { conn , err := db . Conn ( ) if err != nil { return nil , err } defer conn . Close ( ) var p Pool err = conn . Pools ( ) . FindId ( name ) . One ( & p ) if err != nil { if err == mgo . ErrNotFound { return nil , ErrPoolNotFound } return nil , err } return & p , nil } 
func remoteShellHandler ( w http . ResponseWriter , r * http . Request ) { ws , err := upgrader . Upgrade ( w , r , nil ) if err != nil { fmt . Fprintf ( w , " " , err ) return } var httpErr * errors . HTTP defer func ( ) { if httpErr != nil { var msg string switch httpErr . Code { case http . StatusUnauthorized : msg = " \n " default : msg = httpErr . Message + " \n " } ws . WriteMessage ( websocket . TextMessage , [ ] byte ( " " + msg ) ) } ws . WriteMessage ( websocket . CloseMessage , websocket . FormatCloseMessage ( websocket . CloseNormalClosure , " " ) ) ws . Close ( ) } ( ) token := context . GetAuthToken ( r ) if token == nil { httpErr = & errors . HTTP { Code : http . StatusUnauthorized , Message : " " , } return } appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { if herr , ok := err . ( * errors . HTTP ) ; ok { httpErr = herr } else { httpErr = & errors . HTTP { Code : http . StatusInternalServerError , Message : err . Error ( ) , } } return } allowed := permission . Check ( token , permission . PermAppRunShell , contextsForApp ( & a ) ... ) if ! allowed { httpErr = permission . ErrUnauthorized return } buf := & optionalWriterCloser { } var term * terminal . Terminal unitID := r . URL . Query ( ) . Get ( " " ) isolated , _ := strconv . ParseBool ( r . URL . Query ( ) . Get ( " " ) ) width , _ := strconv . Atoi ( r . URL . Query ( ) . Get ( " " ) ) height , _ := strconv . Atoi ( r . URL . Query ( ) . Get ( " " ) ) clientTerm := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppRunShell , Owner : token , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , DisableLock : true , } ) if err != nil { httpErr = & errors . HTTP { Code : http . StatusInternalServerError , Message : err . Error ( ) , } return } defer func ( ) { var finalErr error if httpErr != nil { finalErr = httpErr } for term != nil { buf . disableWrite = true var line string line , err = term . ReadLine ( ) if err != nil { break } fmt . Fprintf ( evt , " \n " , line ) } evt . Done ( finalErr ) } ( ) term = terminal . NewTerminal ( buf , " " ) ws . SetReadDeadline ( time . Now ( ) . Add ( pongWait ) ) ws . SetPongHandler ( func ( string ) error { ws . SetReadDeadline ( time . Now ( ) . Add ( pongWait ) ) return nil } ) quit := make ( chan struct { } ) defer close ( quit ) go func ( ) { for { select { case <- quit : return case <- time . After ( pingInterval ) : } ws . WriteControl ( websocket . PingMessage , nil , time . Now ( ) . Add ( 2 * time . Second ) ) } } ( ) conn := & cmdLogger { base : & wsReadWriteCloser { ws } , term : term } opts := provision . ExecOptions { Stdout : conn , Stderr : conn , Stdin : conn , Width : width , Height : height , Units : unitsForShell ( a , unitID , isolated ) , Term : clientTerm , } err = a . Shell ( opts ) if err != nil { httpErr = & errors . HTTP { Code : http . StatusInternalServerError , Message : err . Error ( ) , } } } 
func Manager ( ) RepositoryManager { managerName , err := config . GetString ( " " ) if err != nil { managerName = defaultManager } if _ , ok := managers [ managerName ] ; ! ok { managerName = " " } return managers [ managerName ] } 
func Register ( name string , manager RepositoryManager ) { if managers == nil { managers = make ( map [ string ] RepositoryManager ) } managers [ name ] = manager } 
func ( b * bindSyncer ) start ( ) error { if b . started { return errors . New ( " " ) } if b . appLister == nil { return errors . New ( " " ) } if b . interval == 0 { b . interval = 5 * time . Minute } b . shutdown = make ( chan struct { } , 1 ) b . done = make ( chan struct { } ) b . started = true log . Debugf ( " \n " , b . interval ) go func ( d time . Duration ) { for { select { case <- time . After ( d ) : start := time . Now ( ) log . Debug ( " " ) apps , err := b . appLister ( ) if err != nil { log . Errorf ( " " , err ) syncDuration . Set ( time . Since ( start ) . Seconds ( ) ) break } for _ , a := range apps { err = b . sync ( a ) if err != nil { log . Errorf ( " " , a . GetName ( ) , err ) } if len ( b . shutdown ) > 0 { break } } log . Debugf ( " " , len ( apps ) ) d = b . interval syncDuration . Set ( time . Since ( start ) . Seconds ( ) ) case <- b . shutdown : b . done <- struct { } { } return } } } ( time . Millisecond * 100 ) return nil } 
func ( b * bindSyncer ) Shutdown ( ctx context . Context ) error { if ! b . started { return nil } b . shutdown <- struct { } { } select { case <- b . done : case <- ctx . Done ( ) : } b . started = false return ctx . Err ( ) } 
func GetForProvisioner ( p provision . Provisioner ) ( Builder , error ) { builder , err := get ( p . GetName ( ) ) if err != nil { if _ , ok := p . ( provision . BuilderDeployDockerClient ) ; ok { return get ( " " ) } else if _ , ok := p . ( provision . BuilderDeployKubeClient ) ; ok { return get ( " " ) } } return builder , err } 
func get ( name string ) ( Builder , error ) { b , ok := builders [ name ] if ! ok { return nil , errors . Errorf ( " " , name ) } return b , nil } 
func Registry ( ) ( [ ] Builder , error ) { registry := make ( [ ] Builder , 0 , len ( builders ) ) for _ , b := range builders { registry = append ( registry , b ) } return registry , nil } 
func RegisterQueueTask ( p DockerProvisioner ) error { q , err := queue . Queue ( ) if err != nil { return err } return q . RegisterTask ( & runBs { provisioner : p } ) } 
func healingHistoryHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermHealingRead ) { return permission . ErrUnauthorized } filter := r . URL . Query ( ) . Get ( " " ) if filter != " " && filter != " " && filter != " " { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } history , err := healer . ListHealingHistory ( filter ) if err != nil { return err } if len ( history ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( history ) } 
func ( v * version ) Apps ( ) AppInformer { return & appInformer { factory : v . factory , namespace : v . namespace , tweakListOptions : v . tweakListOptions } } 
func isTerminating ( pod apiv1 . Pod ) bool { return pod . Spec . ActiveDeadlineSeconds != nil && * pod . Spec . ActiveDeadlineSeconds >= int64 ( 0 ) || pod . DeletionTimestamp != nil } 
func dumpGoroutines ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermDebug ) { return permission . ErrUnauthorized } return pprof . Lookup ( " " ) . WriteTo ( w , 2 ) } 
func ( in * App ) DeepCopyInto ( out * App ) { * out = * in out . TypeMeta = in . TypeMeta in . ObjectMeta . DeepCopyInto ( & out . ObjectMeta ) in . Spec . DeepCopyInto ( & out . Spec ) return } 
func ( in * App ) DeepCopy ( ) * App { if in == nil { return nil } out := new ( App ) in . DeepCopyInto ( out ) return out } 
func ( in * App ) DeepCopyObject ( ) runtime . Object { if c := in . DeepCopy ( ) ; c != nil { return c } return nil } 
func ( in * AppList ) DeepCopyInto ( out * AppList ) { * out = * in out . TypeMeta = in . TypeMeta out . ListMeta = in . ListMeta if in . Items != nil { in , out := & in . Items , & out . Items * out = make ( [ ] App , len ( * in ) ) for i := range * in { ( * in ) [ i ] . DeepCopyInto ( & ( * out ) [ i ] ) } } return } 
func ( in * AppList ) DeepCopy ( ) * AppList { if in == nil { return nil } out := new ( AppList ) in . DeepCopyInto ( out ) return out } 
func ( in * AppList ) DeepCopyObject ( ) runtime . Object { if c := in . DeepCopy ( ) ; c != nil { return c } return nil } 
func ( in * AppSpec ) DeepCopyInto ( out * AppSpec ) { * out = * in if in . Deployments != nil { in , out := & in . Deployments , & out . Deployments * out = make ( map [ string ] [ ] string , len ( * in ) ) for key , val := range * in { if val == nil { ( * out ) [ key ] = nil } else { ( * out ) [ key ] = make ( [ ] string , len ( val ) ) copy ( ( * out ) [ key ] , val ) } } } if in . Services != nil { in , out := & in . Services , & out . Services * out = make ( map [ string ] [ ] string , len ( * in ) ) for key , val := range * in { if val == nil { ( * out ) [ key ] = nil } else { ( * out ) [ key ] = make ( [ ] string , len ( val ) ) copy ( ( * out ) [ key ] , val ) } } } return } 
func ( in * AppSpec ) DeepCopy ( ) * AppSpec { if in == nil { return nil } out := new ( AppSpec ) in . DeepCopyInto ( out ) return out } 
func serviceBrokerList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermServiceBrokerRead ) { return permission . ErrUnauthorized } brokers , err := servicemanager . ServiceBroker . List ( ) if err != nil { return err } if len ( brokers ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } return json . NewEncoder ( w ) . Encode ( map [ string ] interface { } { " " : brokers , } ) } 
func serviceBrokerAdd ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermServiceBrokerCreate ) { return permission . ErrUnauthorized } broker , err := decodeServiceBroker ( r ) if err != nil { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeServiceBroker , Value : broker . Name } , Kind : permission . PermServiceBrokerCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceBrokerReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) if err = servicemanager . ServiceBroker . Create ( * broker ) ; err != nil { if err == service . ErrServiceBrokerAlreadyExists { return & errors . HTTP { Code : http . StatusConflict , Message : " " } } return err } w . WriteHeader ( http . StatusCreated ) return nil } 
func serviceBrokerUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermServiceBrokerUpdate ) { return permission . ErrUnauthorized } brokerName := r . URL . Query ( ) . Get ( " " ) if brokerName == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } broker , err := decodeServiceBroker ( r ) if err != nil { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeServiceBroker , Value : broker . Name } , Kind : permission . PermServiceBrokerUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceBrokerReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) if err = servicemanager . ServiceBroker . Update ( brokerName , * broker ) ; err == service . ErrServiceBrokerNotFound { w . WriteHeader ( http . StatusNotFound ) } return err } 
func ( w * LogWriter ) Write ( data [ ] byte ) ( int , error ) { w . finLk . RLock ( ) defer w . finLk . RUnlock ( ) if w . closed { return len ( data ) , nil } if w . msgCh == nil { return len ( data ) , w . write ( data ) } copied := make ( [ ] byte , len ( data ) ) copy ( copied , data ) w . msgCh <- copied return len ( data ) , nil } 
func createCluster ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermClusterCreate ) if ! allowed { return permission . ErrUnauthorized } var provCluster provTypes . Cluster err = ParseInput ( r , & provCluster ) if err != nil { return err } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeCluster , Value : provCluster . Name } , Kind : permission . PermClusterCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermClusterReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) _ , err = servicemanager . Cluster . FindByName ( provCluster . Name ) if err == nil { return & tsuruErrors . HTTP { Code : http . StatusConflict , Message : " " , } } for _ , poolName := range provCluster . Pools { _ , err = pool . GetPoolByName ( poolName ) if err != nil { if err == pool . ErrPoolNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } } streamResponse := strings . HasPrefix ( r . Header . Get ( " " ) , " " ) if streamResponse { w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) } provCluster . Writer = evt err = servicemanager . Cluster . Create ( provCluster ) if err != nil { return errors . WithStack ( err ) } return nil } 
func listClusters ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermClusterRead ) if ! allowed { return permission . ErrUnauthorized } clusters , err := servicemanager . Cluster . List ( ) if err != nil { if err == provTypes . ErrNoCluster { w . WriteHeader ( http . StatusNoContent ) return nil } return err } for i := range clusters { clusters [ i ] . ClientKey = nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( clusters ) } 
func deleteCluster ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermClusterDelete ) if ! allowed { return permission . ErrUnauthorized } clusterName := r . URL . Query ( ) . Get ( " " ) evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeCluster , Value : clusterName } , Kind : permission . PermClusterDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermClusterReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) streamResponse := strings . HasPrefix ( r . Header . Get ( " " ) , " " ) if streamResponse { w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) } err = servicemanager . Cluster . Delete ( provTypes . Cluster { Name : clusterName , Writer : evt } ) if err != nil { if errors . Cause ( err ) == provTypes . ErrClusterNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } return nil } 
func provisionerList ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowed := permission . Check ( t , permission . PermClusterRead ) if ! allowed { return permission . ErrUnauthorized } provs , err := provision . Registry ( ) if err != nil { return err } info := make ( [ ] provisionerInfo , len ( provs ) ) for i , p := range provs { info [ i ] . Name = p . GetName ( ) if clusterProv , ok := p . ( cluster . ClusteredProvisioner ) ; ok { info [ i ] . ClusterHelp = clusterProv . ClusterHelp ( ) } } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( info ) } 
func addNodeHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var params provision . AddNodeOptions err = ParseInput ( r , & params ) if err != nil { return err } if templateName , ok := params . Metadata [ " " ] ; ok { params . Metadata , err = iaas . ExpandTemplate ( templateName , params . Metadata ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } } params . Pool = params . Metadata [ provision . PoolMetadataName ] params . IaaSID = params . Metadata [ provision . IaaSIDMetadataName ] delete ( params . Metadata , provision . IaaSIDMetadataName ) if params . Pool == " " { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " } } if ! permission . Check ( t , permission . PermNodeCreate , permission . Context ( permTypes . CtxPool , params . Pool ) ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeNode } , Kind : permission . PermNodeCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , DisableLock : true , Allowed : event . Allowed ( permission . PermPoolReadEvents , permission . Context ( permTypes . CtxPool , params . Pool ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) p , err := pool . GetPoolByName ( params . Pool ) if err != nil { return err } prov , err := p . GetProvisioner ( ) if err != nil { return err } nodeProv , ok := prov . ( provision . NodeProvisioner ) if ! ok { return provision . ProvisionerNotSupported { Prov : prov , Action : " " } } w . Header ( ) . Set ( " " , " " ) w . WriteHeader ( http . StatusCreated ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 15 * time . Second , " " ) defer keepAliveWriter . Stop ( ) addr , response , err := addNodeForParams ( nodeProv , params ) evt . Target . Value = addr if err != nil { if desc := response [ " " ] ; desc != " " { return errors . Wrapf ( err , " \n " , desc ) } return err } return nil } 
func removeNodeHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { address := r . URL . Query ( ) . Get ( " " ) if address == " " { return errors . Errorf ( " " ) } _ , n , err := node . FindNode ( address ) if err != nil { if err == provision . ErrNodeNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } pool := n . Pool ( ) allowedNodeRemove := permission . Check ( t , permission . PermNodeDelete , permission . Context ( permTypes . CtxPool , pool ) , ) if ! allowedNodeRemove { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeNode , Value : n . Address ( ) } , Kind : permission . PermNodeDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permission . Context ( permTypes . CtxPool , pool ) ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) noRebalance , _ := strconv . ParseBool ( r . URL . Query ( ) . Get ( " " ) ) removeIaaS , _ := strconv . ParseBool ( r . URL . Query ( ) . Get ( " " ) ) return node . RemoveNode ( node . RemoveNodeArgs { Node : n , Rebalance : ! noRebalance , Writer : w , RemoveIaaS : removeIaaS , } ) } 
func listNodesHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { pools , err := permission . ListContextValues ( t , permission . PermNodeRead , false ) if err != nil { return err } provs , err := provision . Registry ( ) if err != nil { return err } provNameMap := map [ string ] string { } var allNodes [ ] provision . NodeSpec for _ , prov := range provs { nodeProv , ok := prov . ( provision . NodeProvisioner ) if ! ok { continue } var nodes [ ] provision . Node nodes , err = nodeProv . ListNodes ( nil ) if err != nil { allNodes = append ( allNodes , provision . NodeSpec { Address : fmt . Sprintf ( " " , prov . GetName ( ) ) , Status : fmt . Sprintf ( " " , err ) , } ) continue } for _ , n := range nodes { provNameMap [ n . Address ( ) ] = prov . GetName ( ) allNodes = append ( allNodes , provision . NodeToSpec ( n ) ) } } if pools != nil { filteredNodes := make ( [ ] provision . NodeSpec , 0 , len ( allNodes ) ) for _ , node := range allNodes { for _ , pool := range pools { if node . Pool == pool { filteredNodes = append ( filteredNodes , node ) break } } } allNodes = filteredNodes } iaases , err := permission . ListContextValues ( t , permission . PermMachineRead , false ) if err != nil { return err } machines , err := iaas . ListMachines ( ) if err != nil { return err } if iaases != nil { filteredMachines := make ( [ ] iaas . Machine , 0 , len ( machines ) ) for _ , machine := range machines { for _ , iaas := range iaases { if machine . Iaas == iaas { filteredMachines = append ( filteredMachines , machine ) break } } } machines = filteredMachines } if len ( allNodes ) == 0 && len ( machines ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } result := apiTypes . ListNodeResponse { Nodes : allNodes , Machines : machines , } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( result ) } 
func updateNodeHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var params provision . UpdateNodeOptions err = ParseInput ( r , & params ) if err != nil { return err } if params . Disable && params . Enable { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } if params . Address == " " { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " } } prov , node , err := node . FindNode ( params . Address ) if err != nil { if err == provision . ErrNodeNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } nodeProv := prov . ( provision . NodeProvisioner ) oldPool := node . Pool ( ) allowedOldPool := permission . Check ( t , permission . PermNodeUpdate , permission . Context ( permTypes . CtxPool , oldPool ) , ) if ! allowedOldPool { return permission . ErrUnauthorized } var ok bool params . Pool , ok = params . Metadata [ provision . PoolMetadataName ] if ok { delete ( params . Metadata , provision . PoolMetadataName ) allowedNewPool := permission . Check ( t , permission . PermNodeUpdate , permission . Context ( permTypes . CtxPool , params . Pool ) , ) if ! allowedNewPool { return permission . ErrUnauthorized } } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeNode , Value : node . Address ( ) } , Kind : permission . PermNodeUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , permission . Context ( permTypes . CtxPool , oldPool ) , permission . Context ( permTypes . CtxPool , params . Pool ) , ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return nodeProv . UpdateNode ( params ) } 
func listUnitsByNode ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { address := r . URL . Query ( ) . Get ( " " ) _ , node , err := node . FindNode ( address ) if err != nil { if err == provision . ErrNodeNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } hasAccess := permission . Check ( t , permission . PermNodeRead , permission . Context ( permTypes . CtxPool , node . Pool ( ) ) ) if ! hasAccess { return permission . ErrUnauthorized } units , err := node . Units ( ) if err != nil { return err } if len ( units ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( units ) } 
func listUnitsByApp ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { appName := r . URL . Query ( ) . Get ( " " ) a , err := app . GetByName ( appName ) if err != nil { if err == appTypes . ErrAppNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } canRead := permission . Check ( t , permission . PermAppRead , contextsForApp ( a ) ... , ) if ! canRead { return permission . ErrUnauthorized } units , err := a . Units ( ) if err != nil { return err } if len ( units ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( units ) } 
func nodeHealingRead ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { pools , err := permission . ListContextValues ( t , permission . PermHealingRead , true ) if err != nil { return err } configMap , err := healer . GetConfig ( ) if err != nil { return err } if len ( pools ) > 0 { allowedPoolSet := map [ string ] struct { } { } for _ , p := range pools { allowedPoolSet [ p ] = struct { } { } } for k := range configMap { if k == " " { continue } if _ , ok := allowedPoolSet [ k ] ; ! ok { delete ( configMap , k ) } } } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( configMap ) } 
func nodeHealingUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { poolName := InputValue ( r , " " ) var ctxs [ ] permTypes . PermissionContext if poolName != " " { ctxs = append ( ctxs , permission . Context ( permTypes . CtxPool , poolName ) ) } if ! permission . Check ( t , permission . PermHealingUpdate , ctxs ... ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : poolName } , Kind : permission . PermHealingUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , DisableLock : true , Allowed : event . Allowed ( permission . PermPoolReadEvents , ctxs ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) var config healer . NodeHealerConfig err = ParseInput ( r , & config ) if err != nil { return err } return healer . UpdateConfig ( poolName , config ) } 
func nodeHealingDelete ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { poolName := r . URL . Query ( ) . Get ( " " ) var ctxs [ ] permTypes . PermissionContext if poolName != " " { ctxs = append ( ctxs , permission . Context ( permTypes . CtxPool , poolName ) ) } if ! permission . Check ( t , permission . PermHealingDelete , ctxs ... ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : poolName } , Kind : permission . PermHealingDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , DisableLock : true , Allowed : event . Allowed ( permission . PermPoolReadEvents , ctxs ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) if len ( r . URL . Query ( ) [ " " ] ) == 0 { return healer . RemoveConfig ( poolName , " " ) } for _ , v := range r . URL . Query ( ) [ " " ] { err := healer . RemoveConfig ( poolName , v ) if err != nil { return err } } return nil } 
func rebalanceNodesHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var params provision . RebalanceNodesOptions err = ParseInput ( r , & params ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } params . Force = true var permContexts [ ] permTypes . PermissionContext var ok bool evtTarget := event . Target { Type : event . TargetTypeGlobal } params . Pool , ok = params . MetadataFilter [ provision . PoolMetadataName ] if ok { delete ( params . MetadataFilter , provision . PoolMetadataName ) permContexts = append ( permContexts , permission . Context ( permTypes . CtxPool , params . Pool ) ) evtTarget = event . Target { Type : event . TargetTypePool , Value : params . Pool } } if ! permission . Check ( t , permission . PermNodeUpdateRebalance , permContexts ... ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : evtTarget , Kind : permission . PermNodeUpdateRebalance , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , DisableLock : true , Allowed : event . Allowed ( permission . PermPoolReadEvents , permContexts ... ) , Cancelable : true , AllowedCancel : event . Allowed ( permission . PermAppUpdateEvents , permContexts ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 15 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) params . Event = evt var provs [ ] provision . Provisioner if params . Pool != " " { var p * pool . Pool var prov provision . Provisioner p , err = pool . GetPoolByName ( params . Pool ) if err != nil { return err } prov , err = p . GetProvisioner ( ) if err != nil { return err } if _ , ok := prov . ( provision . NodeRebalanceProvisioner ) ; ! ok { return provision . ProvisionerNotSupported { Prov : prov , Action : " " } } provs = append ( provs , prov ) } else { provs , err = provision . Registry ( ) if err != nil { return err } } for _ , prov := range provs { rebalanceProv , ok := prov . ( provision . NodeRebalanceProvisioner ) if ! ok { continue } _ , err = rebalanceProv . RebalanceNodes ( params ) if err != nil { return errors . Wrap ( err , " " ) } } fmt . Fprintf ( writer , " \n " ) return nil } 
func infoNodeHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { address := r . URL . Query ( ) . Get ( " " ) if address == " " { return errors . Errorf ( " " ) } _ , node , err := node . FindNode ( address ) if err != nil { if err == provision . ErrNodeNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } hasAccess := permission . Check ( t , permission . PermNodeRead , permission . Context ( permTypes . CtxPool , node . Pool ( ) ) ) if ! hasAccess { return permission . ErrUnauthorized } spec := provision . NodeToSpec ( node ) if spec . IaaSID == " " { var machine iaas . Machine machine , err = iaas . FindMachineByAddress ( address ) if err != nil { if err != iaas . ErrMachineNotFound { return err } } else { spec . IaaSID = machine . Iaas } } nodeStatus , err := healer . HealerInstance . GetNodeStatusData ( node ) if err != nil && err != provision . ErrNodeNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } units , err := node . Units ( ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } response := apiTypes . InfoNodeResponse { Node : spec , Status : nodeStatus , Units : units , } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( response ) } 
func ( s NativeScheme ) ResetPassword ( user * auth . User , resetToken string ) error { if resetToken == " " { return auth . ErrInvalidToken } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) passToken , err := getPasswordToken ( resetToken ) if err != nil { return err } if passToken . UserEmail != user . Email { return auth . ErrInvalidToken } password := generatePassword ( 12 ) user . Password = password hashPassword ( user ) go sendNewPassword ( user , password ) passToken . Used = true conn . PasswordTokens ( ) . UpdateId ( passToken . Token , passToken ) return user . Update ( ) } 
func deploy ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { opts , err := prepareToBuild ( r ) if err != nil { return err } if opts . File != nil { defer opts . File . Close ( ) } commit := InputValue ( r , " " ) w . Header ( ) . Set ( " " , " " ) appName := r . URL . Query ( ) . Get ( " " ) origin := InputValue ( r , " " ) if opts . Image != " " { origin = " " } if origin != " " { if ! app . ValidateOrigin ( origin ) { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } } var userName string if t . IsAppToken ( ) { if t . GetAppName ( ) != appName && t . GetAppName ( ) != app . InternalAppName { return & tsuruErrors . HTTP { Code : http . StatusUnauthorized , Message : " " } } userName = InputValue ( r , " " ) } else { commit = " " userName = t . GetUserName ( ) } instance , err := app . GetByName ( appName ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } message := InputValue ( r , " " ) if commit != " " && message == " " { var messages [ ] string messages , err = repository . Manager ( ) . CommitMessages ( instance . Name , commit , 1 ) if err != nil { return err } if len ( messages ) > 0 { message = messages [ 0 ] } } if origin == " " && commit != " " { origin = " " } opts . App = instance opts . Commit = commit opts . User = userName opts . Origin = origin opts . Message = message opts . GetKind ( ) if t . GetAppName ( ) != app . InternalAppName { canDeploy := permission . Check ( t , permSchemeForDeploy ( opts ) , contextsForApp ( instance ) ... ) if ! canDeploy { return & tsuruErrors . HTTP { Code : http . StatusForbidden , Message : " " } } } var imageID string evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppDeploy , RawOwner : event . Owner { Type : event . OwnerTypeUser , Name : userName } , CustomData : opts , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( instance ) ... ) , AllowedCancel : event . Allowed ( permission . PermAppUpdateEvents , contextsForApp ( instance ) ... ) , Cancelable : true , } ) if err != nil { return err } defer func ( ) { evt . DoneCustomData ( err , map [ string ] string { " " : imageID } ) } ( ) w . Header ( ) . Set ( eventIDHeader , evt . UniqueID . Hex ( ) ) opts . Event = evt writer := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer writer . Stop ( ) opts . OutputStream = writer imageID , err = app . Deploy ( opts ) if err == nil { fmt . Fprintln ( w , " \n " ) } return err } 
func diffDeploy ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { writer := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer writer . Stop ( ) fmt . Fprint ( w , " \n " ) appName := r . URL . Query ( ) . Get ( " " ) diff := InputValue ( r , " " ) instance , err := app . GetByName ( appName ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } if t . GetAppName ( ) != app . InternalAppName { canDiffDeploy := permission . Check ( t , permission . PermAppReadDeploy , contextsForApp ( instance ) ... ) if ! canDiffDeploy { return & tsuruErrors . HTTP { Code : http . StatusForbidden , Message : permission . ErrUnauthorized . Error ( ) } } } evt , err := event . GetRunning ( appTarget ( appName ) , permission . PermAppDeploy . FullName ( ) ) if err != nil { return err } return evt . SetOtherCustomData ( map [ string ] string { " " : diff , } ) } 
func deploysList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { contexts := permission . ContextsForPermission ( t , permission . PermAppReadDeploy ) if len ( contexts ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } filter := appFilterByContext ( contexts , nil ) filter . Name = r . URL . Query ( ) . Get ( " " ) skip := r . URL . Query ( ) . Get ( " " ) limit := r . URL . Query ( ) . Get ( " " ) skipInt , _ := strconv . Atoi ( skip ) limitInt , _ := strconv . Atoi ( limit ) deploys , err := app . ListDeploys ( filter , skipInt , limitInt ) if err != nil { return err } if len ( deploys ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( deploys ) } 
func deployInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { depID := r . URL . Query ( ) . Get ( " " ) deploy , err := app . GetDeploy ( depID ) if err != nil { if err == event . ErrEventNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : " " } } return err } dbApp , err := app . GetByName ( deploy . App ) if err != nil { return err } canGet := permission . Check ( t , permission . PermAppReadDeploy , contextsForApp ( dbApp ) ... ) if ! canGet { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : " " } } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( deploy ) } 
func deployRebuild ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { appName := r . URL . Query ( ) . Get ( " " ) instance , err := app . GetByName ( appName ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : fmt . Sprintf ( " " , appName ) } } origin := InputValue ( r , " " ) if ! app . ValidateOrigin ( origin ) { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } opts := app . DeployOptions { App : instance , OutputStream : writer , User : t . GetUserName ( ) , Origin : origin , Kind : app . DeployRebuild , } canDeploy := permission . Check ( t , permSchemeForDeploy ( opts ) , contextsForApp ( instance ) ... ) if ! canDeploy { return & tsuruErrors . HTTP { Code : http . StatusForbidden , Message : permission . ErrUnauthorized . Error ( ) } } var imageID string evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppDeploy , Owner : t , CustomData : opts , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( instance ) ... ) , AllowedCancel : event . Allowed ( permission . PermAppUpdateEvents , contextsForApp ( instance ) ... ) , Cancelable : true , } ) if err != nil { return err } defer func ( ) { evt . DoneCustomData ( err , map [ string ] string { " " : imageID } ) } ( ) opts . Event = evt imageID , err = app . Deploy ( opts ) if err != nil { writer . Encode ( tsuruIo . SimpleJsonMessage { Error : err . Error ( ) } ) } return nil } 
func deployRollbackUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { appName := r . URL . Query ( ) . Get ( " " ) instance , err := app . GetByName ( appName ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : fmt . Sprintf ( " " , appName ) , } } canUpdateRollback := permission . Check ( t , permission . PermAppUpdateDeployRollback , contextsForApp ( instance ) ... ) if ! canUpdateRollback { return & tsuruErrors . HTTP { Code : http . StatusForbidden , Message : " " , } } img := InputValue ( r , " " ) if img == " " { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } disable := InputValue ( r , " " ) disableRollback , err := strconv . ParseBool ( disable ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : fmt . Sprintf ( " " , disable ) , } } reason := InputValue ( r , " " ) if ( reason == " " ) && ( disableRollback ) { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateDeployRollback , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( instance ) ... ) , AllowedCancel : event . Allowed ( permission . PermAppUpdateEvents , contextsForApp ( instance ) ... ) , Cancelable : false , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = app . RollbackUpdate ( instance . Name , img , reason , disableRollback ) if err != nil { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } return err } 
func BuildHealthCheck ( providerName string ) func ( ) error { return func ( ) error { iaasConfig , err := config . Get ( " " ) if err != nil { return hc . ErrDisabledComponent } iaases , _ := iaasConfig . ( map [ interface { } ] interface { } ) for ifaceName := range iaases { name := ifaceName . ( string ) if name == " " { customIaases := iaases [ name ] . ( map [ interface { } ] interface { } ) for ifaceName := range customIaases { iaas := customIaases [ ifaceName . ( string ) ] . ( map [ interface { } ] interface { } ) if iaas [ " " ] . ( string ) != providerName { continue } name = ifaceName . ( string ) } } else if name != providerName { continue } err := healthCheck ( name ) if err != nil { return err } } return nil } } 
func getBrokeredService ( name string ) ( Service , error ) { catalogName , serviceName , err := splitBrokerService ( name ) if err != nil { return Service { } , err } client , err := newBrokeredServiceClient ( name ) if err != nil { return Service { } , err } s , _ , err := client . getService ( serviceName , catalogName ) return s , err } 
func machinesList ( w http . ResponseWriter , r * http . Request , token auth . Token ) error { machines , err := iaas . ListMachines ( ) if err != nil { return err } contexts := permission . ContextsForPermission ( token , permission . PermMachineRead ) allowedIaaS := map [ string ] struct { } { } for _ , c := range contexts { if c . CtxType == permTypes . CtxGlobal { allowedIaaS = nil break } if c . CtxType == permTypes . CtxIaaS { allowedIaaS [ c . Value ] = struct { } { } } } for i := 0 ; allowedIaaS != nil && i < len ( machines ) ; i ++ { if _ , ok := allowedIaaS [ machines [ i ] . Iaas ] ; ! ok { machines = append ( machines [ : i ] , machines [ i + 1 : ] ... ) i -- } } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( machines ) } 
func machineDestroy ( w http . ResponseWriter , r * http . Request , token auth . Token ) ( err error ) { machineID := r . URL . Query ( ) . Get ( " " ) if machineID == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } m , err := iaas . FindMachineById ( machineID ) if err != nil { if err == iaas . ErrMachineNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : " " } } return err } iaasCtx := permission . Context ( permTypes . CtxIaaS , m . Iaas ) allowed := permission . Check ( token , permission . PermMachineDelete , iaasCtx ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeIaas , Value : m . Iaas } , Kind : permission . PermMachineDelete , Owner : token , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermMachineReadEvents , iaasCtx ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return m . Destroy ( ) } 
func templatesList ( w http . ResponseWriter , r * http . Request , token auth . Token ) error { templates , err := iaas . ListTemplates ( ) if err != nil { return err } contexts := permission . ContextsForPermission ( token , permission . PermMachineTemplateRead ) allowedIaaS := map [ string ] struct { } { } for _ , c := range contexts { if c . CtxType == permTypes . CtxGlobal { allowedIaaS = nil break } if c . CtxType == permTypes . CtxIaaS { allowedIaaS [ c . Value ] = struct { } { } } } for i := 0 ; allowedIaaS != nil && i < len ( templates ) ; i ++ { if _ , ok := allowedIaaS [ templates [ i ] . IaaSName ] ; ! ok { templates = append ( templates [ : i ] , templates [ i + 1 : ] ... ) i -- } } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( templates ) } 
func templateCreate ( w http . ResponseWriter , r * http . Request , token auth . Token ) ( err error ) { var paramTemplate iaas . Template err = ParseInput ( r , & paramTemplate ) if err != nil { return err } iaasCtx := permission . Context ( permTypes . CtxIaaS , paramTemplate . IaaSName ) allowed := permission . Check ( token , permission . PermMachineTemplateCreate , iaasCtx ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeIaas , Value : paramTemplate . IaaSName } , Kind : permission . PermMachineTemplateCreate , Owner : token , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermMachineReadEvents , iaasCtx ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) _ , err = iaas . FindTemplate ( paramTemplate . Name ) if err != nil && err != mgo . ErrNotFound { return err } if err == nil { return & errors . HTTP { Code : http . StatusConflict , Message : fmt . Sprintf ( " \" \" " , paramTemplate . Name ) } } err = paramTemplate . Save ( ) if err != nil { return err } w . WriteHeader ( http . StatusCreated ) return nil } 
func templateDestroy ( w http . ResponseWriter , r * http . Request , token auth . Token ) ( err error ) { templateName := r . URL . Query ( ) . Get ( " " ) t , err := iaas . FindTemplate ( templateName ) if err != nil { if err == mgo . ErrNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : " " } } return err } iaasCtx := permission . Context ( permTypes . CtxIaaS , t . IaaSName ) allowed := permission . Check ( token , permission . PermMachineTemplateDelete , iaasCtx ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeIaas , Value : t . IaaSName } , Kind : permission . PermMachineTemplateDelete , Owner : token , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermMachineReadEvents , iaasCtx ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return iaas . DestroyTemplate ( templateName ) } 
func templateUpdate ( w http . ResponseWriter , r * http . Request , token auth . Token ) ( err error ) { var paramTemplate iaas . Template err = ParseInput ( r , & paramTemplate ) if err != nil { return err } templateName := r . URL . Query ( ) . Get ( " " ) dbTpl , err := iaas . FindTemplate ( templateName ) if err != nil { if err == mgo . ErrNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : " " } } return err } iaasValue := InputValue ( r , " " ) if iaasValue != " " { dbTpl . IaaSName = iaasValue } iaasCtx := permission . Context ( permTypes . CtxIaaS , dbTpl . IaaSName ) allowed := permission . Check ( token , permission . PermMachineTemplateUpdate , iaasCtx ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeIaas , Value : dbTpl . IaaSName } , Kind : permission . PermMachineTemplateUpdate , Owner : token , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermMachineReadEvents , iaasCtx ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return dbTpl . Update ( & paramTemplate ) } 
func ( c * TsuruV1Client ) RESTClient ( ) rest . Interface { if c == nil { return nil } return c . restClient } 
func addKnownTypes ( scheme * runtime . Scheme ) error { scheme . AddKnownTypes ( SchemeGroupVersion , & App { } , & AppList { } , ) scheme . AddKnownTypes ( SchemeGroupVersion , & metav1 . Status { } , ) metav1 . AddToGroupVersion ( scheme , SchemeGroupVersion ) return nil } 
func samlMetadata ( w http . ResponseWriter , r * http . Request ) error { if app . AuthScheme . Name ( ) != " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } page , err := saml . Metadata ( ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) w . Write ( [ ] byte ( page ) ) return nil } 
func samlCallbackLogin ( w http . ResponseWriter , r * http . Request ) error { if app . AuthScheme . Name ( ) != " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } params := map [ string ] string { } content := r . PostFormValue ( " " ) if content == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } params [ " " ] = " " params [ " " ] = content _ , err := scheme . Login ( params ) if err != nil { msg := fmt . Sprintf ( cmd . SamlCallbackFailureMessage ( ) , err . Error ( ) ) fmt . Fprint ( w , msg ) } else { fmt . Fprint ( w , cmd . SamlCallbackSuccessMessage ( ) ) } return nil } 
func volumesList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { contexts := permission . ContextsForPermission ( t , permission . PermVolumeRead ) if len ( contexts ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } volumes , err := volume . ListByFilter ( volumeFilterByContext ( contexts ) ) if err != nil { return err } if len ( volumes ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( volumes ) } 
func volumeInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { v , err := volume . Load ( r . URL . Query ( ) . Get ( " " ) ) if err != nil { if err == volume . ErrVolumeNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } canRead := permission . Check ( t , permission . PermVolumeRead , contextsForVolume ( v ) ... ) if ! canRead { return permission . ErrUnauthorized } _ , err = v . LoadBinds ( ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( & v ) } 
func volumeCreate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var inputVolume volume . Volume err = ParseInput ( r , & inputVolume ) if err != nil { return err } inputVolume . Plan . Opts = nil inputVolume . Status = " " canCreate := permission . Check ( t , permission . PermVolumeCreate , permission . Context ( permTypes . CtxTeam , inputVolume . TeamOwner ) , permission . Context ( permTypes . CtxPool , inputVolume . Pool ) , ) if ! canCreate { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeVolume , Value : inputVolume . Name } , Kind : permission . PermVolumeCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermVolumeReadEvents , contextsForVolume ( & inputVolume ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) _ , err = volume . Load ( inputVolume . Name ) if err == nil { return & errors . HTTP { Code : http . StatusConflict , Message : " " } } err = inputVolume . Create ( ) if err != nil { return err } w . WriteHeader ( http . StatusCreated ) return nil } 
func volumeUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var inputVolume volume . Volume err = ParseInput ( r , & inputVolume ) if err != nil { return err } inputVolume . Plan . Opts = nil inputVolume . Status = " " inputVolume . Name = r . URL . Query ( ) . Get ( " " ) dbVolume , err := volume . Load ( inputVolume . Name ) if err != nil { if err == volume . ErrVolumeNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } canUpdate := permission . Check ( t , permission . PermVolumeUpdate , contextsForVolume ( dbVolume ) ... ) if ! canUpdate { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeVolume , Value : inputVolume . Name } , Kind : permission . PermVolumeUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermVolumeReadEvents , contextsForVolume ( dbVolume ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return inputVolume . Update ( ) } 
func volumePlansList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { contexts := permission . ContextsForPermission ( t , permission . PermVolumeCreate ) if len ( contexts ) == 0 { return permission . ErrUnauthorized } plansProvisioners , err := volume . ListPlans ( ) if err != nil { return err } if len ( plansProvisioners ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( plansProvisioners ) } 
func volumeDelete ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { volumeName := r . URL . Query ( ) . Get ( " " ) dbVolume , err := volume . Load ( volumeName ) if err != nil { if err == volume . ErrVolumeNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } canDelete := permission . Check ( t , permission . PermVolumeDelete , contextsForVolume ( dbVolume ) ... ) if ! canDelete { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeVolume , Value : volumeName } , Kind : permission . PermVolumeDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermVolumeReadEvents , contextsForVolume ( dbVolume ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return dbVolume . Delete ( ) } 
func volumeBind ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { var bindInfo struct { App string MountPoint string ReadOnly bool NoRestart bool } err := ParseInput ( r , & bindInfo ) if err != nil { return err } dbVolume , err := volume . Load ( r . URL . Query ( ) . Get ( " " ) ) if err != nil { if err == volume . ErrVolumeNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } canBindVolume := permission . Check ( t , permission . PermVolumeUpdateBind , contextsForVolume ( dbVolume ) ... ) if ! canBindVolume { return permission . ErrUnauthorized } a , err := getAppFromContext ( bindInfo . App , r ) if err != nil { return err } canBindApp := permission . Check ( t , permission . PermAppUpdateBindVolume , contextsForApp ( & a ) ... ) if ! canBindApp { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeVolume , Value : dbVolume . Name } , Kind : permission . PermVolumeUpdateBind , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermVolumeReadEvents , contextsForVolume ( dbVolume ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = dbVolume . BindApp ( bindInfo . App , bindInfo . MountPoint , bindInfo . ReadOnly ) if err != nil || bindInfo . NoRestart { if err == volume . ErrVolumeAlreadyBound { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) } } return err } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) return a . Restart ( " " , evt ) } 
func autoScaleGetConfig ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { allowedGetConfig := permission . Check ( t , permission . PermNodeAutoscaleRead ) if ! allowedGetConfig { return permission . ErrUnauthorized } config , err := autoscale . CurrentConfig ( ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( config ) } 
func autoScaleListRules ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { allowedListRule := permission . Check ( t , permission . PermNodeAutoscaleRead ) if ! allowedListRule { return permission . ErrUnauthorized } rules , err := autoscale . ListRules ( ) if err != nil { return err } if len ( rules ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } return json . NewEncoder ( w ) . Encode ( & rules ) } 
func autoScaleSetRule ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowedSetRule := permission . Check ( t , permission . PermNodeAutoscaleUpdate ) if ! allowedSetRule { return permission . ErrUnauthorized } var rule autoscale . Rule err = ParseInput ( r , & rule ) if err != nil { return err } var ctxs [ ] permTypes . PermissionContext if rule . MetadataFilter != " " { ctxs = append ( ctxs , permission . Context ( permTypes . CtxPool , rule . MetadataFilter ) ) } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : rule . MetadataFilter } , Kind : permission . PermNodeAutoscaleUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , ctxs ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) return rule . Update ( ) } 
func autoScaleDeleteRule ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { allowedDeleteRule := permission . Check ( t , permission . PermNodeAutoscale ) if ! allowedDeleteRule { return permission . ErrUnauthorized } rulePool := r . URL . Query ( ) . Get ( " " ) var ctxs [ ] permTypes . PermissionContext if rulePool != " " { ctxs = append ( ctxs , permission . Context ( permTypes . CtxPool , rulePool ) ) } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool , Value : rulePool } , Kind : permission . PermNodeAutoscaleDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , ctxs ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = autoscale . DeleteRule ( rulePool ) if err == mgo . ErrNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : " " } } return nil } 
func autoScaleHistoryHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if ! permission . Check ( t , permission . PermNodeAutoscale ) { return permission . ErrUnauthorized } skip , _ := strconv . Atoi ( r . URL . Query ( ) . Get ( " " ) ) limit , _ := strconv . Atoi ( r . URL . Query ( ) . Get ( " " ) ) history , err := autoscale . ListAutoScaleEvents ( skip , limit ) if err != nil { return err } if len ( history ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( & history ) } 
func autoScaleRunHandler ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { if ! permission . Check ( t , permission . PermNodeAutoscaleUpdateRun ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypePool } , Kind : permission . PermNodeAutoscaleUpdateRun , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , DisableLock : true , Allowed : event . Allowed ( permission . PermPoolReadEvents ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) w . WriteHeader ( http . StatusOK ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 15 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) , } return autoscale . RunOnce ( writer ) } 
func createServiceInstance ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { serviceName := r . URL . Query ( ) . Get ( " " ) srv , err := getService ( serviceName ) if err != nil { return err } instance := service . ServiceInstance { ServiceName : serviceName , err = ParseInput ( r , & instance ) if err != nil { return err } tags , _ := InputValues ( r , " " ) instance . Tags = append ( instance . Tags , tags ... ) var teamOwner string if instance . TeamOwner == " " { teamOwner , err = permission . TeamForPermission ( t , permission . PermServiceInstanceCreate ) if err != nil { return err } instance . TeamOwner = teamOwner } allowed := permission . Check ( t , permission . PermServiceInstanceCreate , permission . Context ( permTypes . CtxTeam , instance . TeamOwner ) , ) if ! allowed { return permission . ErrUnauthorized } if srv . IsRestricted { allowed := permission . Check ( t , permission . PermServiceRead , contextsForService ( & srv ) ... , ) if ! allowed { return permission . ErrUnauthorized } } evt , err := event . New ( & event . Opts { Target : serviceInstanceTarget ( serviceName , instance . Name ) , Kind : permission . PermServiceInstanceCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceInstanceReadEvents , contextsForServiceInstance ( & instance , srv . Name ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) requestID := requestIDHeader ( r ) err = service . CreateServiceInstance ( instance , & srv , evt , requestID ) if err == service . ErrInstanceNameAlreadyExists { return & tsuruErrors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) , } } if err == service . ErrInvalidInstanceName { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } if err == nil { w . WriteHeader ( http . StatusCreated ) } return err } 
func updateServiceInstance ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { serviceName := r . URL . Query ( ) . Get ( " " ) instanceName := r . URL . Query ( ) . Get ( " " ) updateData := struct { Description string Plan string TeamOwner string Tags [ ] string } { } err = ParseInput ( r , & updateData ) if err != nil { return err } tags , _ := InputValues ( r , " " ) updateData . Tags = append ( updateData . Tags , tags ... ) srv , err := getService ( serviceName ) if err != nil { return err } si , err := getServiceInstanceOrError ( serviceName , instanceName ) if err != nil { return err } var wantedPerms [ ] * permission . PermissionScheme if updateData . Description != " " { wantedPerms = append ( wantedPerms , permission . PermServiceInstanceUpdateDescription ) si . Description = updateData . Description } if updateData . TeamOwner != " " { wantedPerms = append ( wantedPerms , permission . PermServiceInstanceUpdateTeamowner ) si . TeamOwner = updateData . TeamOwner } if updateData . Tags != nil { wantedPerms = append ( wantedPerms , permission . PermServiceInstanceUpdateTags ) si . Tags = updateData . Tags } if updateData . Plan != " " { wantedPerms = append ( wantedPerms , permission . PermServiceInstanceUpdatePlan ) si . PlanName = updateData . Plan } if len ( wantedPerms ) == 0 { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : " " , } } for _ , perm := range wantedPerms { allowed := permission . Check ( t , perm , contextsForServiceInstance ( si , serviceName ) ... , ) if ! allowed { return permission . ErrUnauthorized } } evt , err := event . New ( & event . Opts { Target : serviceInstanceTarget ( serviceName , instanceName ) , Kind : permission . PermServiceInstanceUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceInstanceReadEvents , contextsForServiceInstance ( si , serviceName ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) requestID := requestIDHeader ( r ) return si . Update ( srv , * si , evt , requestID ) } 
func removeServiceInstance ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { unbindAll := r . URL . Query ( ) . Get ( " " ) serviceName := r . URL . Query ( ) . Get ( " " ) instanceName := r . URL . Query ( ) . Get ( " " ) serviceInstance , err := getServiceInstanceOrError ( serviceName , instanceName ) if err != nil { return err } keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } w . Header ( ) . Set ( " " , " " ) allowed := permission . Check ( t , permission . PermServiceInstanceDelete , contextsForServiceInstance ( serviceInstance , serviceName ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : serviceInstanceTarget ( serviceName , instanceName ) , Kind : permission . PermServiceInstanceDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceInstanceReadEvents , contextsForServiceInstance ( serviceInstance , serviceName ) ... ) , } ) if err != nil { return err } evt . SetLogWriter ( writer ) defer func ( ) { evt . Done ( err ) } ( ) requestID := requestIDHeader ( r ) unbindAllBool , _ := strconv . ParseBool ( unbindAll ) if unbindAllBool { if len ( serviceInstance . Apps ) > 0 { for _ , appName := range serviceInstance . Apps { _ , app , instErr := getServiceInstance ( serviceInstance . ServiceName , serviceInstance . Name , appName ) if instErr != nil { return instErr } fmt . Fprintf ( evt , " \n " , app . GetName ( ) ) instErr = serviceInstance . UnbindApp ( service . UnbindAppArgs { App : app , Restart : true , ForceRemove : false , Event : evt , RequestID : requestID , } ) if instErr != nil { return instErr } fmt . Fprintf ( evt , " \n \n " , serviceInstance . Name , app . GetName ( ) ) } serviceInstance , err = getServiceInstanceOrError ( serviceName , instanceName ) if err != nil { return err } } } err = service . DeleteInstance ( serviceInstance , evt , requestID ) if err != nil { if err == service . ErrServiceInstanceBound { return & tsuruErrors . HTTP { Message : errors . Wrapf ( err , `Applications bound to the service "%s": "%s"` + " \n " , instanceName , strings . Join ( serviceInstance . Apps , " " ) ) . Error ( ) , Code : http . StatusBadRequest , } } return err } evt . Write ( [ ] byte ( " \n " ) ) return nil } 
func serviceInstances ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { appName := r . URL . Query ( ) . Get ( " " ) contexts := permission . ContextsForPermission ( t , permission . PermServiceInstanceRead ) instances , err := readableInstances ( t , contexts , appName , " " ) if err != nil { return err } contexts = permission . ContextsForPermission ( t , permission . PermServiceRead ) services , err := readableServices ( t , contexts ) if err != nil { return err } servicesMap := map [ string ] * service . ServiceModel { } for _ , s := range services { if _ , in := servicesMap [ s . Name ] ; ! in { servicesMap [ s . Name ] = & service . ServiceModel { Service : s . Name , Instances : [ ] string { } , } } } for _ , instance := range instances { entry := servicesMap [ instance . ServiceName ] if entry == nil { continue } entry . Instances = append ( entry . Instances , instance . Name ) entry . Plans = append ( entry . Plans , instance . PlanName ) entry . ServiceInstances = append ( entry . ServiceInstances , instance ) } result := [ ] service . ServiceModel { } for _ , name := range sortedServiceNames ( servicesMap ) { entry := servicesMap [ name ] result = append ( result , * entry ) } if len ( result ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( result ) } 
func serviceInstanceStatus ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { instanceName := r . URL . Query ( ) . Get ( " " ) serviceName := r . URL . Query ( ) . Get ( " " ) serviceInstance , err := getServiceInstanceOrError ( serviceName , instanceName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceInstanceReadStatus , contextsForServiceInstance ( serviceInstance , serviceName ) ... , ) if ! allowed { return permission . ErrUnauthorized } var b string requestID := requestIDHeader ( r ) if b , err = serviceInstance . Status ( requestID ) ; err != nil { return errors . Wrap ( err , " " ) } _ , err = fmt . Fprintf ( w , `Service instance "%s" is %s` , instanceName , b ) return err } 
func serviceInstance ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { instanceName := r . URL . Query ( ) . Get ( " " ) serviceName := r . URL . Query ( ) . Get ( " " ) svc , err := getService ( serviceName ) if err != nil { return err } serviceInstance , err := getServiceInstanceOrError ( serviceName , instanceName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceInstanceRead , contextsForServiceInstance ( serviceInstance , serviceName ) ... , ) if ! allowed { return permission . ErrUnauthorized } requestID := requestIDHeader ( r ) info , err := serviceInstance . Info ( requestID ) if err != nil { return err } plan , err := service . GetPlanByServiceAndPlanName ( svc , serviceInstance . PlanName , requestID ) if err != nil { return err } sInfo := serviceInstanceInfo { Apps : serviceInstance . Apps , Teams : serviceInstance . Teams , TeamOwner : serviceInstance . TeamOwner , Description : serviceInstance . Description , PlanName : plan . Name , PlanDescription : plan . Description , CustomInfo : info , Tags : serviceInstance . Tags , } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( sInfo ) } 
func serviceInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { serviceName := r . URL . Query ( ) . Get ( " " ) _ , err := getService ( serviceName ) if err != nil { return err } contexts := permission . ContextsForPermission ( t , permission . PermServiceInstanceRead ) instances , err := readableInstances ( t , contexts , " " , serviceName ) if err != nil { return err } var result [ ] service . ServiceInstanceWithInfo for _ , instance := range instances { infoData , err := instance . ToInfo ( ) if err != nil { return err } result = append ( result , infoData ) } return json . NewEncoder ( w ) . Encode ( result ) } 
func serviceDoc ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { serviceName := r . URL . Query ( ) . Get ( " " ) s , err := getService ( serviceName ) if err != nil { return err } if s . IsRestricted { allowed := permission . Check ( t , permission . PermServiceReadDoc , contextsForService ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } } w . Write ( [ ] byte ( s . Doc ) ) return nil } 
func servicePlans ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { serviceName := r . URL . Query ( ) . Get ( " " ) s , err := getService ( serviceName ) if err != nil { return err } if s . IsRestricted { allowed := permission . Check ( t , permission . PermServiceReadPlans , contextsForService ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } } requestID := requestIDHeader ( r ) plans , err := service . GetPlansByService ( s , requestID ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( plans ) } 
func serviceInstanceProxy ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { serviceName := r . URL . Query ( ) . Get ( " " ) instanceName := r . URL . Query ( ) . Get ( " " ) serviceInstance , err := getServiceInstanceOrError ( serviceName , instanceName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceInstanceUpdateProxy , contextsForServiceInstance ( serviceInstance , serviceName ) ... , ) if ! allowed { return permission . ErrUnauthorized } path := r . URL . Query ( ) . Get ( " " ) var evt * event . Event if r . Method != http . MethodGet && r . Method != http . MethodHead { evt , err = event . New ( & event . Opts { Target : serviceInstanceTarget ( serviceName , instanceName ) , Kind : permission . PermServiceInstanceUpdateProxy , Owner : t , CustomData : append ( event . FormToCustomData ( InputFields ( r ) ) , map [ string ] interface { } { " " : " " , " " : r . Method , } ) , Allowed : event . Allowed ( permission . PermServiceInstanceReadEvents , contextsForServiceInstance ( serviceInstance , serviceName ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) } return service . ProxyInstance ( serviceInstance , path , evt , requestIDHeader ( r ) , w , r ) } 
func serviceInstanceGrantTeam ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { instanceName := r . URL . Query ( ) . Get ( " " ) serviceName := r . URL . Query ( ) . Get ( " " ) serviceInstance , err := getServiceInstanceOrError ( serviceName , instanceName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceInstanceUpdateGrant , contextsForServiceInstance ( serviceInstance , serviceName ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : serviceInstanceTarget ( serviceName , instanceName ) , Kind : permission . PermServiceInstanceUpdateGrant , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermServiceInstanceReadEvents , contextsForServiceInstance ( serviceInstance , serviceName ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) teamName := r . URL . Query ( ) . Get ( " " ) return serviceInstance . Grant ( teamName ) } 
func Register ( s Shutdownable ) { lock . Lock ( ) defer lock . Unlock ( ) registered = append ( registered , s ) } 
func Do ( ctx context . Context , w io . Writer ) error { lock . Lock ( ) defer lock . Unlock ( ) done := make ( chan bool ) wg := sync . WaitGroup { } for _ , h := range registered { wg . Add ( 1 ) go func ( h Shutdownable ) { defer wg . Done ( ) var name string if _ , ok := h . ( fmt . Stringer ) ; ok { name = fmt . Sprintf ( " " , h ) } else { name = fmt . Sprintf ( " " , h ) } fmt . Fprintf ( w , " \n " , name ) err := h . Shutdown ( ctx ) if err != nil { fmt . Fprintf ( w , " " , name , err ) return } fmt . Fprintf ( w , " \n " , name ) } ( h ) } go func ( ) { wg . Wait ( ) close ( done ) } ( ) select { case <- ctx . Done ( ) : return ctx . Err ( ) case <- done : } return nil } 
func ( s * platformImageService ) ListImagesOrDefault ( platformName string ) ( [ ] string , error ) { imgs , err := s . ListImages ( platformName ) if err != nil && err == imageTypes . ErrPlatformImageNotFound { return [ ] string { platformBasicImageName ( platformName ) } , nil } return imgs , err } 
func ( c * endpointClient ) Info ( instance * ServiceInstance , requestID string ) ( [ ] map [ string ] string , error ) { log . Debugf ( " " , instance . Name , instance . ServiceName ) url := " " + instance . GetIdentifier ( ) resp , err := c . issueRequest ( url , " " , nil , requestID ) if err != nil { return nil , err } defer resp . Body . Close ( ) if resp . StatusCode != http . StatusOK { return nil , nil } result := [ ] map [ string ] string { } err = c . jsonFromResponse ( resp , & result ) if err != nil { return nil , err } return result , nil } 
func ( c * endpointClient ) Plans ( requestID string ) ( [ ] Plan , error ) { url := " " resp , err := c . issueRequest ( url , " " , nil , requestID ) if err != nil { return nil , err } defer resp . Body . Close ( ) if resp . StatusCode != http . StatusOK { return nil , nil } result := [ ] Plan { } err = c . jsonFromResponse ( resp , & result ) if err != nil { return nil , err } return result , nil } 
func ( c * endpointClient ) Proxy ( path string , evt * event . Event , requestID string , w http . ResponseWriter , r * http . Request ) error { rawurl := strings . TrimRight ( c . endpoint , " " ) + " " + strings . Trim ( path , " " ) url , err := url . Parse ( rawurl ) if err != nil { log . Errorf ( " " , rawurl , err ) return err } director := func ( req * http . Request ) { if evt != nil { req . Header . Set ( " " , evt . Owner . Name ) req . Header . Set ( " " , evt . UniqueID . Hex ( ) ) } requestIDHeader , err := config . GetString ( " " ) if err == nil && requestID != " " && requestIDHeader != " " { req . Header . Set ( requestIDHeader , requestID ) } req . SetBasicAuth ( c . username , c . password ) req . Host = url . Host req . URL = url } proxy := & httputil . ReverseProxy { Director : director } proxy . ServeHTTP ( w , r ) return nil } 
func MigrateAppsCRDs ( ) error { config . Set ( " " , false ) defer config . Unset ( " " ) prov := kubernetes . GetProvisioner ( ) pools , err := pool . ListAllPools ( ) if err != nil { return errors . Wrap ( err , " " ) } var kubePools [ ] string for _ , p := range pools { if p . Provisioner == prov . GetName ( ) { kubePools = append ( kubePools , p . Name ) } } apps , err := app . List ( & app . Filter { Pools : kubePools } ) if err != nil { return errors . Wrap ( err , " " ) } multiErr := tsuruerrors . NewMultiError ( ) for _ , a := range apps { errProv := prov . Provision ( & a ) if errProv != nil { multiErr . Add ( errProv ) } } return multiErr . ToError ( ) } 
func Register ( name string , fn MigrateFunc ) error { return register ( name , false , fn ) } 
func RegisterOptional ( name string , fn MigrateFunc ) error { return register ( name , true , fn ) } 
func Run ( args RunArgs ) error { if args . Name != " " { return runOptional ( args ) } if args . Force { return ErrCannotForceMandatory } return run ( args ) } 
func ( app * App ) Units ( ) ( [ ] provision . Unit , error ) { prov , err := app . getProvisioner ( ) if err != nil { return [ ] provision . Unit { } , err } units , err := prov . Units ( app ) if units == nil { } return units , err } 
func ( app * App ) MarshalJSON ( ) ( [ ] byte , error ) { repo , _ := repository . Manager ( ) . GetRepository ( app . Name ) result := make ( map [ string ] interface { } ) result [ " " ] = app . Name result [ " " ] = app . Platform if version := app . GetPlatformVersion ( ) ; version != " " { result [ " " ] = fmt . Sprintf ( " " , app . Platform , version ) } result [ " " ] = app . Teams units , err := app . Units ( ) result [ " " ] = units var errMsgs [ ] string if err != nil { errMsgs = append ( errMsgs , fmt . Sprintf ( " " , err ) ) } result [ " " ] = repo . ReadWriteURL plan := map [ string ] interface { } { " " : app . Plan . Name , " " : app . Plan . Memory , " " : app . Plan . Swap , " " : app . Plan . CpuShare , } routers , err := app . GetRoutersWithAddr ( ) if err != nil { errMsgs = append ( errMsgs , fmt . Sprintf ( " " , err ) ) } if len ( routers ) > 0 { result [ " " ] = routers [ 0 ] . Address plan [ " " ] = routers [ 0 ] . Name result [ " " ] = routers [ 0 ] . Name result [ " " ] = routers [ 0 ] . Opts } result [ " " ] = app . CName result [ " " ] = app . Owner result [ " " ] = app . Pool result [ " " ] = app . Description result [ " " ] = app . Deploys result [ " " ] = app . TeamOwner result [ " " ] = plan result [ " " ] = app . Lock result [ " " ] = app . Tags result [ " " ] = routers if len ( errMsgs ) > 0 { result [ " " ] = strings . Join ( errMsgs , " \n " ) } return json . Marshal ( & result ) } 
func AcquireApplicationLock ( appName string , owner string , reason string ) ( bool , error ) { return AcquireApplicationLockWait ( appName , owner , reason , 0 ) } 
func AcquireApplicationLockWait ( appName string , owner string , reason string , timeout time . Duration ) ( bool , error ) { timeoutChan := time . After ( timeout ) for { appLock := appTypes . AppLock { Locked : true , Reason : reason , Owner : owner , AcquireDate : time . Now ( ) . In ( time . UTC ) , } conn , err := db . Conn ( ) if err != nil { return false , err } err = conn . Apps ( ) . Update ( bson . M { " " : appName , " " : bson . M { " " : [ ] interface { } { false , nil } } } , bson . M { " " : bson . M { " " : appLock } } ) conn . Close ( ) if err == nil { return true , nil } if err != mgo . ErrNotFound { return false , err } select { case <- timeoutChan : return false , nil case <- time . After ( 300 * time . Millisecond ) : } } } 
func ReleaseApplicationLock ( appName string ) { var err error retries := 3 for i := 0 ; i < retries ; i ++ { err = releaseApplicationLockOnce ( appName ) if err == nil { return } time . Sleep ( time . Second * time . Duration ( i + 1 ) ) } log . Error ( err ) } 
func GetByName ( name string ) ( * App , error ) { var app App conn , err := db . Conn ( ) if err != nil { return nil , err } defer conn . Close ( ) err = conn . Apps ( ) . Find ( bson . M { " " : name } ) . One ( & app ) if err == mgo . ErrNotFound { return nil , appTypes . ErrAppNotFound } return & app , err } 
func CreateApp ( app * App , user * auth . User ) error { if _ , err := GetByName ( app . GetName ( ) ) ; err != appTypes . ErrAppNotFound { if err != nil { return errors . WithMessage ( err , " " ) } return & appTypes . AppCreationError { Err : ErrAppAlreadyExists , App : app . GetName ( ) } } var plan * appTypes . Plan var err error if app . Plan . Name == " " { plan , err = servicemanager . Plan . DefaultPlan ( ) } else { plan , err = servicemanager . Plan . FindByName ( app . Plan . Name ) } if err != nil { return err } app . Plan = * plan err = app . SetPool ( ) if err != nil { return err } err = app . configureCreateRouters ( ) if err != nil { return err } app . Teams = [ ] string { app . TeamOwner } app . Owner = user . Email app . Tags = processTags ( app . Tags ) if app . Platform != " " { app . Platform , app . PlatformVersion , err = getPlatformNameAndVersion ( app . Platform ) if err != nil { return err } } err = app . validateNew ( ) if err != nil { return err } actions := [ ] * action . Action { & reserveUserApp , & insertApp , & createAppToken , & exportEnvironmentsAction , & createRepository , & provisionApp , & addRouterBackend , } pipeline := action . NewPipeline ( actions ... ) err = pipeline . Execute ( app , user ) if err != nil { return & appTypes . AppCreationError { App : app . Name , Err : err } } return nil } 
func ( app * App ) Update ( updateData App , w io . Writer ) ( err error ) { description := updateData . Description planName := updateData . Plan . Name poolName := updateData . Pool teamOwner := updateData . TeamOwner platform := updateData . Platform tags := processTags ( updateData . Tags ) oldApp := * app if description != " " { app . Description = description } if poolName != " " { app . Pool = poolName app . provisioner = nil _ , err = app . getPoolForApp ( app . Pool ) if err != nil { return err } } newProv , err := app . getProvisioner ( ) if err != nil { return err } oldProv , err := oldApp . getProvisioner ( ) if err != nil { return err } if planName != " " { plan , errFind := servicemanager . Plan . FindByName ( planName ) if errFind != nil { return errFind } app . Plan = * plan } if teamOwner != " " { team , errTeam := servicemanager . Team . FindByName ( teamOwner ) if errTeam != nil { return errTeam } app . TeamOwner = team . Name defer func ( ) { if err == nil { app . Grant ( team ) } } ( ) } if tags != nil { app . Tags = tags } if platform != " " { var p , v string p , v , err = getPlatformNameAndVersion ( platform ) if err != nil { return err } if app . Platform != p || app . PlatformVersion != v { app . UpdatePlatform = true } app . Platform = p app . PlatformVersion = v } if updateData . UpdatePlatform { app . UpdatePlatform = true } err = app . validate ( ) if err != nil { return err } actions := [ ] * action . Action { & saveApp , } if newProv . GetName ( ) == oldProv . GetName ( ) { actions = append ( actions , & updateAppProvisioner ) } if newProv . GetName ( ) != oldProv . GetName ( ) { defer func ( ) { rebuild . RoutesRebuildOrEnqueue ( app . Name ) } ( ) err = validateVolumes ( app ) if err != nil { return err } actions = append ( actions , & provisionAppNewProvisioner , & provisionAppAddUnits , & destroyAppOldProvisioner ) } else if app . Plan != oldApp . Plan { actions = append ( actions , & restartApp ) } return action . NewPipeline ( actions ... ) . Execute ( app , & oldApp , w ) } 
func ( app * App ) unbind ( evt * event . Event , requestID string ) error { instances , err := service . GetServiceInstancesBoundToApp ( app . Name ) if err != nil { return err } var msg string var addMsg = func ( instanceName string , reason error ) { if msg == " " { msg = " \n " } msg += fmt . Sprintf ( " " , instanceName , reason . Error ( ) ) } for _ , instance := range instances { err = instance . UnbindApp ( service . UnbindAppArgs { App : app , Restart : false , ForceRemove : true , Event : evt , RequestID : requestID , } ) if err != nil { addMsg ( instance . Name , err ) } } if msg != " " { return errors . New ( msg ) } return nil } 
func Delete ( app * App , evt * event . Event , requestID string ) error { w := evt isSwapped , swappedWith , err := router . IsSwapped ( app . GetName ( ) ) if err != nil { return errors . Wrap ( err , " " ) } if isSwapped { return errors . Errorf ( " " , swappedWith ) } appName := app . Name fmt . Fprintf ( w , " \n " , appName ) var hasErrors bool defer func ( ) { var problems string if hasErrors { problems = " " } fmt . Fprintf ( w , " \n " , problems ) } ( ) logErr := func ( msg string , err error ) { msg = fmt . Sprintf ( " " , msg , err ) fmt . Fprintf ( w , " \n " , msg ) log . Errorf ( " " , appName , msg ) hasErrors = true } prov , err := app . getProvisioner ( ) if err != nil { return err } err = prov . Destroy ( app ) if err != nil { logErr ( " " , err ) } err = registry . RemoveAppImages ( appName ) if err != nil { log . Errorf ( " " , appName , err ) } if cleanProv , ok := prov . ( provision . CleanImageProvisioner ) ; ok { var imgs [ ] string imgs , err = image . ListAppImages ( appName ) if err != nil { log . Errorf ( " " , appName , err ) } var imgsBuild [ ] string imgsBuild , err = image . ListAppBuilderImages ( appName ) if err != nil { log . Errorf ( " " , appName , err ) } for _ , img := range append ( imgs , imgsBuild ... ) { err = cleanProv . CleanImage ( appName , img ) if err != nil { log . Errorf ( " " , appName , err ) } } } err = image . DeleteAllAppImageNames ( appName ) if err != nil { log . Errorf ( " " , appName , err ) } err = app . unbind ( evt , requestID ) if err != nil { logErr ( " " , err ) } routers := app . GetRouters ( ) for _ , appRouter := range routers { var r router . Router r , err = router . Get ( appRouter . Name ) if err == nil { err = r . RemoveBackend ( app . Name ) } if err != nil { logErr ( " " , err ) } } err = router . Remove ( app . Name ) if err != nil { logErr ( " " , err ) } err = app . unbindVolumes ( ) if err != nil { logErr ( " " , err ) } err = repository . Manager ( ) . RemoveRepository ( appName ) if err != nil { logErr ( " " , err ) } token := app . Env [ " " ] . Value err = AuthScheme . AppLogout ( token ) if err != nil { logErr ( " " , err ) } owner , err := auth . GetUserByEmail ( app . Owner ) if err == nil { err = servicemanager . UserQuota . Inc ( owner . Email , - 1 ) } if err != nil { logErr ( " " , err ) } logConn , err := db . LogConn ( ) if err == nil { defer logConn . Close ( ) err = logConn . AppLogCollection ( appName ) . DropCollection ( ) } if err != nil { logErr ( " " , err ) } conn , err := db . Conn ( ) if err == nil { defer conn . Close ( ) err = conn . Apps ( ) . Remove ( bson . M { " " : appName } ) } if err != nil { logErr ( " " , err ) } err = event . MarkAsRemoved ( event . Target { Type : event . TargetTypeApp , Value : appName } ) if err != nil { logErr ( " " , err ) } return nil } 
func ( app * App ) AddUnits ( n uint , process string , w io . Writer ) error { if n == 0 { return errors . New ( " " ) } units , err := app . Units ( ) if err != nil { return err } for _ , u := range units { if ( u . Status == provision . StatusAsleep ) || ( u . Status == provision . StatusStopped ) { return errors . New ( " " ) } } w = app . withLogWriter ( w ) err = action . NewPipeline ( & reserveUnitsToAdd , & provisionAddUnits , ) . Execute ( app , n , w , process ) rebuild . RoutesRebuildOrEnqueue ( app . Name ) quotaErr := app . fixQuota ( ) if err != nil { return err } return quotaErr } 
func ( app * App ) RemoveUnits ( n uint , process string , w io . Writer ) error { prov , err := app . getProvisioner ( ) if err != nil { return err } w = app . withLogWriter ( w ) err = prov . RemoveUnits ( app , n , process , w ) rebuild . RoutesRebuildOrEnqueue ( app . Name ) quotaErr := app . fixQuota ( ) if err != nil { return err } return quotaErr } 
func ( app * App ) SetUnitStatus ( unitName string , status provision . Status ) error { units , err := app . Units ( ) if err != nil { return err } for _ , unit := range units { if strings . HasPrefix ( unit . ID , unitName ) { prov , err := app . getProvisioner ( ) if err != nil { return err } unitProv , ok := prov . ( provision . UnitStatusProvisioner ) if ! ok { return nil } return unitProv . SetUnitStatus ( unit , status ) } } return & provision . UnitNotFoundError { ID : unitName } } 
func UpdateNodeStatus ( nodeData provision . NodeStatusData ) ( [ ] UpdateUnitsResult , error ) { node , findNodeErr := findNodeForNodeData ( nodeData ) var nodeAddresses [ ] string if findNodeErr == nil { nodeAddresses = [ ] string { node . Address ( ) } } else { nodeAddresses = nodeData . Addrs } if healer . HealerInstance != nil { err := healer . HealerInstance . UpdateNodeData ( nodeAddresses , nodeData . Checks ) if err != nil { log . Errorf ( " " , err ) } } if findNodeErr == provision . ErrNodeNotFound { counterNodesNotFound . Inc ( ) log . Errorf ( " " , nodeData ) result := make ( [ ] UpdateUnitsResult , len ( nodeData . Units ) ) for i , unitData := range nodeData . Units { result [ i ] = UpdateUnitsResult { ID : unitData . ID , Found : false } } return result , nil } if findNodeErr != nil { return nil , findNodeErr } unitProv , ok := node . Provisioner ( ) . ( provision . UnitStatusProvisioner ) if ! ok { return [ ] UpdateUnitsResult { } , nil } result := make ( [ ] UpdateUnitsResult , len ( nodeData . Units ) ) for i , unitData := range nodeData . Units { unit := provision . Unit { ID : unitData . ID , Name : unitData . Name } err := unitProv . SetUnitStatus ( unit , unitData . Status ) _ , isNotFound := err . ( * provision . UnitNotFoundError ) if err != nil && ! isNotFound { return nil , err } result [ i ] = UpdateUnitsResult { ID : unitData . ID , Found : ! isNotFound } } return result , nil } 
func ( app * App ) available ( ) bool { units , err := app . Units ( ) if err != nil { return false } for _ , unit := range units { if unit . Available ( ) { return true } } return false } 
func ( app * App ) Grant ( team * authTypes . Team ) error { if _ , found := app . findTeam ( team ) ; found { return ErrAlreadyHaveAccess } app . Teams = append ( app . Teams , team . Name ) conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) err = conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : team . Name } } ) if err != nil { return err } users , err := auth . ListUsersWithPermissions ( permission . Permission { Scheme : permission . PermAppDeploy , Context : permission . Context ( permTypes . CtxTeam , team . Name ) , } ) if err != nil { conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : team . Name } } ) return err } for _ , user := range users { err = repository . Manager ( ) . GrantAccess ( app . Name , user . Email ) if err != nil { conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : team . Name } } ) return err } } return nil } 
func ( app * App ) Revoke ( team * authTypes . Team ) error { if len ( app . Teams ) == 1 { return ErrCannotOrphanApp } index , found := app . findTeam ( team ) if ! found { return ErrNoAccess } last := len ( app . Teams ) - 1 app . Teams [ index ] = app . Teams [ last ] app . Teams = app . Teams [ : last ] conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) err = conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : team . Name } } ) if err != nil { return err } users , err := auth . ListUsersWithPermissions ( permission . Permission { Scheme : permission . PermAppDeploy , Context : permission . Context ( permTypes . CtxTeam , team . Name ) , } ) if err != nil { conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : team . Name } } ) return err } for _ , user := range users { perms , err := user . Permissions ( ) if err != nil { conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : team . Name } } ) return err } canDeploy := permission . CheckFromPermList ( perms , permission . PermAppDeploy , append ( permission . Contexts ( permTypes . CtxTeam , app . Teams ) , permission . Context ( permTypes . CtxApp , app . Name ) , permission . Context ( permTypes . CtxPool , app . Pool ) , ) ... , ) if canDeploy { continue } err = repository . Manager ( ) . RevokeAccess ( app . Name , user . Email ) if err != nil { conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : team . Name } } ) return err } } return nil } 
func ( app * App ) GetTeams ( ) [ ] authTypes . Team { t , _ := servicemanager . Team . FindByNames ( app . Teams ) return t } 
func ( app * App ) setEnv ( env bind . EnvVar ) { if app . Env == nil { app . Env = make ( map [ string ] bind . EnvVar ) } app . Env [ env . Name ] = env if env . Public { app . Log ( fmt . Sprintf ( " " , env . Name , env . Value ) , " " , " " ) } } 
func ( app * App ) getEnv ( name string ) ( bind . EnvVar , error ) { if env , ok := app . Env [ name ] ; ok { return env , nil } return bind . EnvVar { } , errors . New ( " " ) } 
func ( app * App ) validateNew ( ) error { if app . Name == InternalAppName || ! validation . ValidateName ( app . Name ) { msg := " " + " " + " " return & tsuruErrors . ValidationError { Message : msg } } return app . validate ( ) } 
func ( app * App ) validate ( ) error { err := app . validatePool ( ) if err != nil { return err } return app . validatePlan ( ) } 
func ( app * App ) InstanceEnvs ( serviceName , instanceName string ) map [ string ] bind . EnvVar { envs := make ( map [ string ] bind . EnvVar ) for _ , env := range app . ServiceEnvs { if env . ServiceName == serviceName && env . InstanceName == instanceName { envs [ env . Name ] = env . EnvVar } } return envs } 
func ( app * App ) Run ( cmd string , w io . Writer , args provision . RunArgs ) error { if ! args . Isolated && ! app . available ( ) { return errors . New ( " " ) } app . Log ( fmt . Sprintf ( " " , cmd ) , " " , " " ) logWriter := LogWriter { App : app , Source : " " } logWriter . Async ( ) defer logWriter . Close ( ) return app . run ( cmd , io . MultiWriter ( w , & logWriter ) , args ) } 
func ( app * App ) GetUnits ( ) ( [ ] bind . Unit , error ) { provUnits , err := app . Units ( ) if err != nil { return nil , err } units := make ( [ ] bind . Unit , len ( provUnits ) ) for i := range provUnits { units [ i ] = & provUnits [ i ] } return units , nil } 
func ( app * App ) GetUUID ( ) ( string , error ) { if app . UUID != " " { return app . UUID , nil } uuidV4 , err := uuid . NewV4 ( ) if err != nil { return " " , errors . WithMessage ( err , " " ) } conn , err := db . Conn ( ) if err != nil { return " " , err } defer conn . Close ( ) err = conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : uuidV4 . String ( ) } } ) if err != nil { return " " , err } app . UUID = uuidV4 . String ( ) return app . UUID , nil } 
func ( app * App ) Envs ( ) map [ string ] bind . EnvVar { mergedEnvs := make ( map [ string ] bind . EnvVar , len ( app . Env ) + len ( app . ServiceEnvs ) + 1 ) for _ , e := range app . Env { mergedEnvs [ e . Name ] = e } for _ , e := range app . ServiceEnvs { mergedEnvs [ e . Name ] = e . EnvVar } mergedEnvs [ TsuruServicesEnvVar ] = serviceEnvsFromEnvVars ( app . ServiceEnvs ) return mergedEnvs } 
func ( app * App ) SetEnvs ( setEnvs bind . SetEnvArgs ) error { if len ( setEnvs . Envs ) == 0 { return nil } for _ , env := range setEnvs . Envs { err := validateEnv ( env . Name ) if err != nil { return err } } if setEnvs . Writer != nil { fmt . Fprintf ( setEnvs . Writer , " \n " , len ( setEnvs . Envs ) ) } for _ , env := range setEnvs . Envs { app . setEnv ( env ) } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) err = conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : app . Env } } ) if err != nil { return err } if setEnvs . ShouldRestart { return app . restartIfUnits ( setEnvs . Writer ) } return nil } 
func ( app * App ) UnsetEnvs ( unsetEnvs bind . UnsetEnvArgs ) error { if len ( unsetEnvs . VariableNames ) == 0 { return nil } if unsetEnvs . Writer != nil { fmt . Fprintf ( unsetEnvs . Writer , " \n " , len ( unsetEnvs . VariableNames ) ) } for _ , name := range unsetEnvs . VariableNames { delete ( app . Env , name ) } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) err = conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : app . Env } } ) if err != nil { return err } if unsetEnvs . ShouldRestart { return app . restartIfUnits ( unsetEnvs . Writer ) } return nil } 
func ( app * App ) AddCName ( cnames ... string ) error { actions := [ ] * action . Action { & validateNewCNames , & setNewCNamesToProvisioner , & saveCNames , & updateApp , } err := action . NewPipeline ( actions ... ) . Execute ( app , cnames ) rebuild . RoutesRebuildOrEnqueue ( app . Name ) return err } 
func ( app * App ) Log ( message , source , unit string ) error { messages := strings . Split ( message , " \n " ) logs := make ( [ ] interface { } , 0 , len ( messages ) ) for _ , msg := range messages { if msg != " " { l := Applog { Date : time . Now ( ) . In ( time . UTC ) , Message : msg , Source : source , AppName : app . Name , Unit : unit , } logs = append ( logs , l ) } } if len ( logs ) > 0 { conn , err := db . LogConn ( ) if err != nil { return err } defer conn . Close ( ) return conn . AppLogCollection ( app . Name ) . Insert ( logs ... ) } return nil } 
func ( app * App ) LastLogs ( lines int , filterLog Applog ) ( [ ] Applog , error ) { return app . lastLogs ( lines , filterLog , false ) } 
func List ( filter * Filter ) ( [ ] App , error ) { apps := [ ] App { } query := filter . Query ( ) conn , err := db . Conn ( ) if err != nil { return nil , err } err = conn . Apps ( ) . Find ( query ) . All ( & apps ) conn . Close ( ) if err != nil { return nil , err } if filter != nil && len ( filter . Statuses ) > 0 { appsProvisionerMap := make ( map [ string ] [ ] provision . App ) var prov provision . Provisioner for i := range apps { a := & apps [ i ] prov , err = a . getProvisioner ( ) if err != nil { return nil , err } appsProvisionerMap [ prov . GetName ( ) ] = append ( appsProvisionerMap [ prov . GetName ( ) ] , a ) } var provisionApps [ ] provision . App for provName , apps := range appsProvisionerMap { prov , err = provision . Get ( provName ) if err != nil { return nil , err } if filterProv , ok := prov . ( provision . AppFilterProvisioner ) ; ok { apps , err = filterProv . FilterAppsByUnitStatus ( apps , filter . Statuses ) if err != nil { return nil , err } } provisionApps = append ( provisionApps , apps ... ) } for i := range provisionApps { apps [ i ] = * ( provisionApps [ i ] . ( * App ) ) } apps = apps [ : len ( provisionApps ) ] } err = loadCachedAddrsInApps ( apps ) if err != nil { return nil , err } return apps , nil } 
func Swap ( app1 , app2 * App , cnameOnly bool ) error { a1Routers := app1 . GetRouters ( ) a2Routers := app2 . GetRouters ( ) if len ( a1Routers ) != 1 || len ( a2Routers ) != 1 { return errors . New ( " " ) } r1 , err := router . Get ( a1Routers [ 0 ] . Name ) if err != nil { return err } r2 , err := router . Get ( a2Routers [ 0 ] . Name ) if err != nil { return err } defer func ( app1 , app2 * App ) { rebuild . RoutesRebuildOrEnqueue ( app1 . Name ) rebuild . RoutesRebuildOrEnqueue ( app2 . Name ) app1 . GetRoutersWithAddr ( ) app2 . GetRoutersWithAddr ( ) } ( app1 , app2 ) err = r1 . Swap ( app1 . Name , app2 . Name , cnameOnly ) if err != nil { return err } conn , err := db . Conn ( ) if err != nil { return err } defer conn . Close ( ) app1 . CName , app2 . CName = app2 . CName , app1 . CName updateCName := func ( app * App , r router . Router ) error { return conn . Apps ( ) . Update ( bson . M { " " : app . Name } , bson . M { " " : bson . M { " " : app . CName } } , ) } err = updateCName ( app1 , r1 ) if err != nil { return err } return updateCName ( app2 , r2 ) } 
func ( app * App ) Start ( w io . Writer , process string ) error { w = app . withLogWriter ( w ) msg := fmt . Sprintf ( " \n " , process ) if process == " " { msg = fmt . Sprintf ( " \n " , app . Name ) } fmt . Fprintf ( w , " \n " , msg ) prov , err := app . getProvisioner ( ) if err != nil { return err } err = prov . Start ( app , process ) if err != nil { log . Errorf ( " " , app . Name , err ) return err } rebuild . RoutesRebuildOrEnqueue ( app . Name ) return err } 
func GetDbDriver ( name string ) ( * DbDriver , error ) { driver , ok := dbDrivers [ name ] if ! ok { return nil , errors . Errorf ( " " , name ) } return & driver , nil } 
func GetCurrentDbDriver ( ) ( * DbDriver , error ) { driverLock . RLock ( ) if currentDbDriver != nil { driverLock . RUnlock ( ) return currentDbDriver , nil } driverLock . RUnlock ( ) driverLock . Lock ( ) defer driverLock . Unlock ( ) if currentDbDriver != nil { return currentDbDriver , nil } dbDriverName , err := config . GetString ( " " ) if err != nil || dbDriverName == " " { dbDriverName = DefaultDbDriverName } currentDbDriver , err = GetDbDriver ( dbDriverName ) if err != nil { return nil , err } return currentDbDriver , nil } 
func info ( w http . ResponseWriter , r * http . Request ) error { data := map [ string ] string { } data [ " " ] = Version w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( data ) } 
func Proxy ( service * Service , path string , evt * event . Event , requestID string , w http . ResponseWriter , r * http . Request ) error { endpoint , err := service . getClient ( " " ) if err != nil { return err } return endpoint . Proxy ( path , evt , requestID , w , r ) } 
func appDelete ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { a , err := getAppFromContext ( r . URL . Query ( ) . Get ( " " ) , r ) if err != nil { return err } canDelete := permission . Check ( t , permission . PermAppDelete , contextsForApp ( & a ) ... , ) if ! canDelete { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( a . Name ) , Kind : permission . PermAppDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) w . Header ( ) . Set ( " " , " " ) return app . Delete ( & a , evt , requestIDHeader ( r ) ) } 
func appList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { filter := & app . Filter { } if name := r . URL . Query ( ) . Get ( " " ) ; name != " " { filter . NameMatches = name } if platform := r . URL . Query ( ) . Get ( " " ) ; platform != " " { filter . Platform = platform } if teamOwner := r . URL . Query ( ) . Get ( " " ) ; teamOwner != " " { filter . TeamOwner = teamOwner } if owner := r . URL . Query ( ) . Get ( " " ) ; owner != " " { filter . UserOwner = owner } if pool := r . URL . Query ( ) . Get ( " " ) ; pool != " " { filter . Pool = pool } locked , _ := strconv . ParseBool ( r . URL . Query ( ) . Get ( " " ) ) if locked { filter . Locked = true } if status , ok := r . URL . Query ( ) [ " " ] ; ok { filter . Statuses = status } if tags , ok := r . URL . Query ( ) [ " " ] ; ok { filter . Tags = tags } contexts := permission . ContextsForPermission ( t , permission . PermAppRead ) if len ( contexts ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } apps , err := app . List ( appFilterByContext ( contexts , filter ) ) if err != nil { return err } if len ( apps ) == 0 { w . WriteHeader ( http . StatusNoContent ) return nil } simple , _ := strconv . ParseBool ( r . URL . Query ( ) . Get ( " " ) ) w . Header ( ) . Set ( " " , " " ) miniApps := make ( [ ] miniApp , len ( apps ) ) if simple { for i , ap := range apps { ur := app . AppUnitsResponse { Units : nil , Err : nil } miniApps [ i ] , err = minifyApp ( ap , ur ) if err != nil { return err } } return json . NewEncoder ( w ) . Encode ( miniApps ) } appUnits , err := app . Units ( apps ) if err != nil { return err } for i , app := range apps { miniApps [ i ] , err = minifyApp ( app , appUnits [ app . Name ] ) if err != nil { return err } } return json . NewEncoder ( w ) . Encode ( miniApps ) } 
func appInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { a , err := getAppFromContext ( r . URL . Query ( ) . Get ( " " ) , r ) if err != nil { return err } canRead := permission . Check ( t , permission . PermAppRead , contextsForApp ( & a ) ... , ) if ! canRead { return permission . ErrUnauthorized } err = a . FillInternalAddresses ( r . Context ( ) ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( & a ) } 
func createApp ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var ia inputApp err = ParseInput ( r , & ia ) if err != nil { return err } a := app . App { TeamOwner : ia . TeamOwner , Platform : ia . Platform , Plan : appTypes . Plan { Name : ia . Plan } , Name : ia . Name , Description : ia . Description , Pool : ia . Pool , RouterOpts : ia . RouterOpts , Router : ia . Router , Tags : ia . Tags , Quota : quota . UnlimitedQuota , } tags , _ := InputValues ( r , " " ) a . Tags = append ( a . Tags , tags ... ) if a . TeamOwner == " " { a . TeamOwner , err = autoTeamOwner ( t , permission . PermAppCreate ) if err != nil { return err } } canCreate := permission . Check ( t , permission . PermAppCreate , permission . Context ( permTypes . CtxTeam , a . TeamOwner ) , ) if ! canCreate { return permission . ErrUnauthorized } u , err := auth . ConvertNewUser ( t . User ( ) ) if err != nil { return err } if a . Platform != " " { repo , _ := image . SplitImageName ( a . Platform ) platform , errPlat := servicemanager . Platform . FindByName ( repo ) if errPlat != nil { return errPlat } if platform . Disabled { canUsePlat := permission . Check ( t , permission . PermPlatformUpdate ) || permission . Check ( t , permission . PermPlatformCreate ) if ! canUsePlat { return & errors . HTTP { Code : http . StatusBadRequest , Message : appTypes . ErrInvalidPlatform . Error ( ) } } } } evt , err := event . New ( & event . Opts { Target : appTarget ( a . Name ) , Kind : permission . PermAppCreate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = app . CreateApp ( & a , u ) if err != nil { log . Errorf ( " " , err ) if _ , ok := err . ( appTypes . NoTeamsError ) ; ok { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } if e , ok := err . ( * appTypes . AppCreationError ) ; ok { if e . Err == app . ErrAppAlreadyExists { return & errors . HTTP { Code : http . StatusConflict , Message : e . Error ( ) } } if _ , ok := e . Err . ( * quota . QuotaExceededError ) ; ok { return & errors . HTTP { Code : http . StatusForbidden , Message : " " , } } } if err == appTypes . ErrInvalidPlatform { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } return err } repo , err := repository . Manager ( ) . GetRepository ( a . Name ) if err != nil { return err } msg := map [ string ] interface { } { " " : " " , " " : repo . ReadWriteURL , } addrs , err := a . GetAddresses ( ) if err != nil { return err } if len ( addrs ) > 0 { msg [ " " ] = addrs [ 0 ] } jsonMsg , err := json . Marshal ( msg ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) w . WriteHeader ( http . StatusCreated ) w . Write ( jsonMsg ) return nil } 
func updateApp ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var ia inputApp err = ParseInput ( r , & ia ) if err != nil { return err } imageReset , _ := strconv . ParseBool ( InputValue ( r , " " ) ) updateData := app . App { TeamOwner : ia . TeamOwner , Plan : appTypes . Plan { Name : ia . Plan } , Pool : ia . Pool , Description : ia . Description , Router : ia . Router , Tags : ia . Tags , Platform : InputValue ( r , " " ) , UpdatePlatform : imageReset , RouterOpts : ia . RouterOpts , } tags , _ := InputValues ( r , " " ) updateData . Tags = append ( updateData . Tags , tags ... ) appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } var wantedPerms [ ] * permission . PermissionScheme if updateData . Router != " " || len ( updateData . RouterOpts ) > 0 { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } if updateData . Description != " " { wantedPerms = append ( wantedPerms , permission . PermAppUpdateDescription ) } if len ( updateData . Tags ) > 0 { wantedPerms = append ( wantedPerms , permission . PermAppUpdateTags ) } if updateData . Plan . Name != " " { wantedPerms = append ( wantedPerms , permission . PermAppUpdatePlan ) } if updateData . Pool != " " { wantedPerms = append ( wantedPerms , permission . PermAppUpdatePool ) } if updateData . TeamOwner != " " { wantedPerms = append ( wantedPerms , permission . PermAppUpdateTeamowner ) } if updateData . Platform != " " { repo , _ := image . SplitImageName ( updateData . Platform ) platform , errPlat := servicemanager . Platform . FindByName ( repo ) if errPlat != nil { return errPlat } if platform . Disabled { canUsePlat := permission . Check ( t , permission . PermPlatformUpdate ) || permission . Check ( t , permission . PermPlatformCreate ) if ! canUsePlat { return & errors . HTTP { Code : http . StatusBadRequest , Message : appTypes . ErrInvalidPlatform . Error ( ) } } } wantedPerms = append ( wantedPerms , permission . PermAppUpdatePlatform ) updateData . UpdatePlatform = true } if updateData . UpdatePlatform { wantedPerms = append ( wantedPerms , permission . PermAppUpdateImageReset ) } if len ( wantedPerms ) == 0 { msg := " " return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } for _ , perm := range wantedPerms { allowed := permission . Check ( t , perm , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) w . Header ( ) . Set ( " " , " " ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) err = a . Update ( updateData , evt ) if err == appTypes . ErrPlanNotFound { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } if _ , ok := err . ( * router . ErrRouterNotFound ) ; ok { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } return err } 
func setUnitStatus ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { unitName := r . URL . Query ( ) . Get ( " " ) if unitName == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " , } } postStatus := InputValue ( r , " " ) status , err := provision . ParseStatus ( postStatus ) if err != nil { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } appName := r . URL . Query ( ) . Get ( " " ) a , err := app . GetByName ( appName ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } allowed := permission . Check ( t , permission . PermAppUpdateUnitStatus , contextsForApp ( a ) ... , ) if ! allowed { return permission . ErrUnauthorized } err = a . SetUnitStatus ( unitName , status ) if _ , ok := err . ( * provision . UnitNotFoundError ) ; ok { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } 
func setNodeStatus ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { if t . GetAppName ( ) != app . InternalAppName { return & errors . HTTP { Code : http . StatusForbidden , Message : " " } } var hostInput provision . NodeStatusData err := ParseInput ( r , & hostInput ) if err != nil { return err } result , err := app . UpdateNodeStatus ( hostInput ) if err != nil { if err == provision . ErrNodeNotFound { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } w . Header ( ) . Add ( " " , " " ) return json . NewEncoder ( w ) . Encode ( result ) } 
func grantAppAccess ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { appName := r . URL . Query ( ) . Get ( " " ) teamName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateGrant , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateGrant , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) team , err := servicemanager . Team . FindByName ( teamName ) if err != nil { return & errors . HTTP { Code : http . StatusNotFound , Message : " " } } err = a . Grant ( team ) if err == app . ErrAlreadyHaveAccess { return & errors . HTTP { Code : http . StatusConflict , Message : err . Error ( ) } } return err } 
func revokeAppAccess ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { appName := r . URL . Query ( ) . Get ( " " ) teamName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateRevoke , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateRevoke , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) team , err := servicemanager . Team . FindByName ( teamName ) if err != nil || team == nil { return & errors . HTTP { Code : http . StatusNotFound , Message : " " } } if len ( a . Teams ) == 1 { msg := " " return & errors . HTTP { Code : http . StatusForbidden , Message : msg } } err = a . Revoke ( team ) switch err { case app . ErrNoAccess : return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } case app . ErrCannotOrphanApp : return & errors . HTTP { Code : http . StatusForbidden , Message : err . Error ( ) } default : return err } } 
func runCommand ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { msg := " " command := InputValue ( r , " " ) if len ( command ) < 1 { return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } appName := r . URL . Query ( ) . Get ( " " ) once := InputValue ( r , " " ) isolated := InputValue ( r , " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppRun , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppRun , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) onceBool , _ := strconv . ParseBool ( once ) isolatedBool , _ := strconv . ParseBool ( isolated ) args := provision . RunArgs { Once : onceBool , Isolated : isolatedBool } return a . Run ( command , evt , args ) } 
func getEnv ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { var variables [ ] string if envs , ok := r . URL . Query ( ) [ " " ] ; ok { variables = envs } appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } if ! t . IsAppToken ( ) { allowed := permission . Check ( t , permission . PermAppReadEnv , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } } return writeEnvVars ( w , & a , variables ... ) } 
func setEnv ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var e apiTypes . Envs err = ParseInput ( r , & e ) if err != nil { return err } if len ( e . Envs ) == 0 { msg := " " return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateEnvSet , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } var toExclude [ ] string if e . Private { for i := 0 ; i < len ( e . Envs ) ; i ++ { toExclude = append ( toExclude , fmt . Sprintf ( " " , i ) ) } } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateEnvSet , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r , toExclude ... ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) envs := map [ string ] string { } variables := [ ] bind . EnvVar { } for _ , v := range e . Envs { envs [ v . Name ] = v . Value variables = append ( variables , bind . EnvVar { Name : v . Name , Value : v . Value , Public : ! e . Private } ) } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) err = a . SetEnvs ( bind . SetEnvArgs { Envs : variables , ShouldRestart : ! e . NoRestart , Writer : evt , } ) if v , ok := err . ( * errors . ValidationError ) ; ok { return & errors . HTTP { Code : http . StatusBadRequest , Message : v . Message } } return err } 
func unsetEnv ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { msg := " " if InputValue ( r , " " ) == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } var variables [ ] string if envs , ok := InputValues ( r , " " ) ; ok { variables = envs } else { return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateEnvUnset , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateEnvUnset , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) noRestart , _ := strconv . ParseBool ( InputValue ( r , " " ) ) return a . UnsetEnvs ( bind . UnsetEnvArgs { VariableNames : variables , ShouldRestart : ! noRestart , Writer : evt , } ) } 
func setCName ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { cNameMsg := " " cnames , _ := InputValues ( r , " " ) if len ( cnames ) == 0 { return & errors . HTTP { Code : http . StatusBadRequest , Message : cNameMsg } } appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateCnameAdd , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateCnameAdd , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) if err = a . AddCName ( cnames ... ) ; err == nil { return nil } if err . Error ( ) == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } return err } 
func appLog ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { var err error var lines int if l := r . URL . Query ( ) . Get ( " " ) ; l != " " { lines , err = strconv . Atoi ( l ) if err != nil { msg := `Parameter "lines" must be an integer.` return & errors . HTTP { Code : http . StatusBadRequest , Message : msg } } } else { return & errors . HTTP { Code : http . StatusBadRequest , Message : `Parameter "lines" is mandatory.` } } w . Header ( ) . Set ( " " , " " ) source := r . URL . Query ( ) . Get ( " " ) unit := r . URL . Query ( ) . Get ( " " ) follow := r . URL . Query ( ) . Get ( " " ) appName := r . URL . Query ( ) . Get ( " " ) filterLog := app . Applog { Source : source , Unit : unit } a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppReadLog , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } logs , err := a . LastLogs ( lines , filterLog ) if err != nil { return err } encoder := json . NewEncoder ( w ) err = encoder . Encode ( logs ) if err != nil { return err } if follow != " " { return nil } closeChan := r . Context ( ) . Done ( ) l , err := app . NewLogListener ( & a , filterLog ) if err != nil { return err } logTracker . add ( l ) defer func ( ) { logTracker . remove ( l ) l . Close ( ) } ( ) logChan := l . ListenChan ( ) for { var logMsg app . Applog var chOpen bool select { case <- closeChan : return nil case logMsg , chOpen = <- logChan : } if ! chOpen { return nil } err := encoder . Encode ( [ ] app . Applog { logMsg } ) if err != nil { break } } return nil } 
func bindServiceInstance ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { instanceName := r . URL . Query ( ) . Get ( " " ) appName := r . URL . Query ( ) . Get ( " " ) serviceName := r . URL . Query ( ) . Get ( " " ) req := struct { NoRestart bool Parameters service . BindAppParameters } { } err = ParseInput ( r , & req ) if err != nil { return err } instance , a , err := getServiceInstance ( serviceName , instanceName , appName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceInstanceUpdateBind , append ( permission . Contexts ( permTypes . CtxTeam , instance . Teams ) , permission . Context ( permTypes . CtxServiceInstance , instance . Name ) , ) ... , ) if ! allowed { return permission . ErrUnauthorized } allowed = permission . Check ( t , permission . PermAppUpdateBind , contextsForApp ( a ) ... , ) if ! allowed { return permission . ErrUnauthorized } err = a . ValidateService ( serviceName ) if err != nil { if err == pool . ErrPoolHasNoService { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } return err } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateBind , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) err = instance . BindApp ( a , req . Parameters , ! req . NoRestart , evt , evt , requestIDHeader ( r ) ) if err != nil { status , errStatus := instance . Status ( requestIDHeader ( r ) ) if errStatus != nil { return fmt . Errorf ( " " , err , errStatus ) } return fmt . Errorf ( " " , err , instanceName , status ) } fmt . Fprintf ( writer , " \n \n " , instanceName , appName ) envs := a . InstanceEnvs ( serviceName , instanceName ) if len ( envs ) > 0 { fmt . Fprintf ( writer , " \n \n " ) for k := range envs { fmt . Fprintf ( writer , " \n " , k ) } fmt . Fprintf ( writer , " \n " , app . TsuruServicesEnvVar ) } return nil } 
func unbindServiceInstance ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { instanceName , appName , serviceName := r . URL . Query ( ) . Get ( " " ) , r . URL . Query ( ) . Get ( " " ) , r . URL . Query ( ) . Get ( " " ) noRestart , _ := strconv . ParseBool ( InputValue ( r , " " ) ) force , _ := strconv . ParseBool ( InputValue ( r , " " ) ) instance , a , err := getServiceInstance ( serviceName , instanceName , appName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermServiceInstanceUpdateUnbind , append ( permission . Contexts ( permTypes . CtxTeam , instance . Teams ) , permission . Context ( permTypes . CtxServiceInstance , instance . Name ) , ) ... , ) if ! allowed { return permission . ErrUnauthorized } allowed = permission . Check ( t , permission . PermAppUpdateUnbind , contextsForApp ( a ) ... , ) if ! allowed { return permission . ErrUnauthorized } if force { s , errGet := service . Get ( instance . ServiceName ) if errGet != nil { return errGet } allowed = permission . Check ( t , permission . PermServiceUpdate , contextsForServiceProvision ( & s ) ... , ) if ! allowed { return permission . ErrUnauthorized } } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateUnbind , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) err = instance . UnbindApp ( service . UnbindAppArgs { App : a , Restart : ! noRestart , ForceRemove : force , Event : evt , RequestID : requestIDHeader ( r ) , } ) if err != nil { return err } fmt . Fprintf ( evt , " \n \n " , instanceName , appName ) return nil } 
func restart ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { process := InputValue ( r , " " ) appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateRestart , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateRestart , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) return a . Restart ( process , evt ) } 
func sleep ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { process := InputValue ( r , " " ) appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } proxy := InputValue ( r , " " ) if proxy == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } proxyURL , err := url . Parse ( proxy ) if err != nil { log . Errorf ( " " , proxy ) return err } allowed := permission . Check ( t , permission . PermAppUpdateSleep , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppUpdateSleep , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 30 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) return a . Sleep ( evt , process , proxyURL ) } 
func addLog ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { a , err := app . GetByName ( r . URL . Query ( ) . Get ( " " ) ) if err != nil { return err } if t . GetAppName ( ) != app . InternalAppName { allowed := permission . Check ( t , permission . PermAppUpdateLog , contextsForApp ( a ) ... , ) if ! allowed { return permission . ErrUnauthorized } } logs , _ := InputValues ( r , " " ) source := InputValue ( r , " " ) if source == " " { source = " " } unit := InputValue ( r , " " ) for _ , log := range logs { err := a . Log ( log , source , unit ) if err != nil { return err } } return nil } 
func swap ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { app1Name := InputValue ( r , " " ) app2Name := InputValue ( r , " " ) forceSwap := InputValue ( r , " " ) cnameOnly , _ := strconv . ParseBool ( InputValue ( r , " " ) ) if forceSwap == " " { forceSwap = " " } locked1 , err := app . AcquireApplicationLockWait ( app1Name , t . GetUserName ( ) , " " , lockWaitDuration ) if err != nil { return err } defer app . ReleaseApplicationLock ( app1Name ) locked2 , err := app . AcquireApplicationLockWait ( app2Name , t . GetUserName ( ) , " " , lockWaitDuration ) if err != nil { return err } defer app . ReleaseApplicationLock ( app2Name ) app1 , err := getApp ( app1Name ) if err != nil { return err } if ! locked1 { return & errors . HTTP { Code : http . StatusConflict , Message : fmt . Sprintf ( " " , app1 . Name , & app1 . Lock ) } } app2 , err := getApp ( app2Name ) if err != nil { return err } if ! locked2 { return & errors . HTTP { Code : http . StatusConflict , Message : fmt . Sprintf ( " " , app2 . Name , & app2 . Lock ) } } allowed1 := permission . Check ( t , permission . PermAppUpdateSwap , contextsForApp ( app1 ) ... , ) allowed2 := permission . Check ( t , permission . PermAppUpdateSwap , contextsForApp ( app2 ) ... , ) if ! allowed1 || ! allowed2 { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( app1Name ) , ExtraTargets : [ ] event . ExtraTarget { { Target : appTarget ( app2Name ) , Lock : true } , } , Kind : permission . PermAppUpdateSwap , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( app1 ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) } app1Units , err := app1 . Units ( ) if err != nil { return err } app2Units , err := app2 . Units ( ) if err != nil { return err } if len ( app1Units ) != len ( app2Units ) { return & errors . HTTP { Code : http . StatusPreconditionFailed , Message : " " , } } } return app . Swap ( app1 , app2 , cnameOnly ) } 
func forceDeleteLock ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { appName := r . URL . Query ( ) . Get ( " " ) a , err := getAppFromContext ( appName , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppAdminUnlock , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : appTarget ( appName ) , Kind : permission . PermAppAdminUnlock , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) app . ReleaseApplicationLock ( a . Name ) return nil } 
func registerUnit ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { appName := r . URL . Query ( ) . Get ( " " ) a , err := app . GetByName ( appName ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateUnitRegister , contextsForApp ( a ) ... , ) if ! allowed { return permission . ErrUnauthorized } if isDeployAgentUA ( r ) && r . Header . Get ( " " ) == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : msgError } } defer r . Body . Close ( ) data , err := ioutil . ReadAll ( r . Body ) if err != nil { return err } val , err := url . ParseQuery ( string ( data ) ) if err != nil { return err } hostname := val . Get ( " " ) var customData map [ string ] interface { } rawCustomData := val . Get ( " " ) if rawCustomData != " " { err = json . Unmarshal ( [ ] byte ( rawCustomData ) , & customData ) if err != nil { return err } } err = a . RegisterUnit ( hostname , customData ) if err != nil { if err , ok := err . ( * provision . UnitNotFoundError ) ; ok { return & errors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) } } return err } return writeEnvVars ( w , a ) } 
func appMetricEnvs ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { a , err := getAppFromContext ( r . URL . Query ( ) . Get ( " " ) , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppReadMetric , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) metricMap , err := a . MetricEnvs ( ) if err != nil { return err } return json . NewEncoder ( w ) . Encode ( metricMap ) } 
func appRebuildRoutes ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { a , err := getAppFromContext ( r . URL . Query ( ) . Get ( " " ) , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppAdminRoutes , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } dry , _ := strconv . ParseBool ( InputValue ( r , " " ) ) evt , err := event . New ( & event . Opts { Target : appTarget ( a . Name ) , Kind : permission . PermAppAdminRoutes , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } result := map [ string ] rebuild . RebuildRoutesResult { } defer func ( ) { evt . DoneCustomData ( err , result ) } ( ) w . Header ( ) . Set ( " " , " " ) result , err = rebuild . RebuildRoutes ( & a , dry ) if err != nil { return err } return json . NewEncoder ( w ) . Encode ( & result ) } 
func setCertificate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { a , err := getAppFromContext ( r . URL . Query ( ) . Get ( " " ) , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppUpdateCertificateSet , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } cname := InputValue ( r , " " ) certificate := InputValue ( r , " " ) key := InputValue ( r , " " ) if cname == " " { return & errors . HTTP { Code : http . StatusBadRequest , Message : " " } } evt , err := event . New ( & event . Opts { Target : appTarget ( a . Name ) , Kind : permission . PermAppUpdateCertificateSet , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r , " " ) ) , Allowed : event . Allowed ( permission . PermAppReadEvents , contextsForApp ( & a ) ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = a . SetCertificate ( cname , certificate , key ) if err != nil { return & errors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) } } return nil } 
func listCertificates ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { a , err := getAppFromContext ( r . URL . Query ( ) . Get ( " " ) , r ) if err != nil { return err } allowed := permission . Check ( t , permission . PermAppReadCertificate , contextsForApp ( & a ) ... , ) if ! allowed { return permission . ErrUnauthorized } w . Header ( ) . Set ( " " , " " ) result , err := a . GetCertificates ( ) if err != nil { return err } return json . NewEncoder ( w ) . Encode ( & result ) } 
func NewForConfig ( c * rest . Config ) ( * Clientset , error ) { configShallowCopy := * c if configShallowCopy . RateLimiter == nil && configShallowCopy . QPS > 0 { configShallowCopy . RateLimiter = flowcontrol . NewTokenBucketRateLimiter ( configShallowCopy . QPS , configShallowCopy . Burst ) } var cs Clientset var err error cs . tsuruV1 , err = tsuruv1 . NewForConfig ( & configShallowCopy ) if err != nil { return nil , err } cs . DiscoveryClient , err = discovery . NewDiscoveryClientForConfig ( & configShallowCopy ) if err != nil { glog . Errorf ( " " , err ) return nil , err } return & cs , nil } 
func NewForConfigOrDie ( c * rest . Config ) * Clientset { var cs Clientset cs . tsuruV1 = tsuruv1 . NewForConfigOrDie ( c ) cs . DiscoveryClient = discovery . NewDiscoveryClientForConfigOrDie ( c ) return & cs } 
func New ( c rest . Interface ) * Clientset { var cs Clientset cs . tsuruV1 = tsuruv1 . New ( c ) cs . DiscoveryClient = discovery . NewDiscoveryClient ( c ) return & cs } 
func nodeContainerList ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { pools , err := permission . ListContextValues ( t , permission . PermNodecontainerRead , true ) if err != nil { return err } lst , err := nodecontainer . AllNodeContainers ( ) if err != nil { return err } if pools != nil { poolMap := map [ string ] struct { } { } for _ , p := range pools { poolMap [ p ] = struct { } { } } for i , entry := range lst { for poolName := range entry . ConfigPools { if poolName == " " { continue } if _ , ok := poolMap [ poolName ] ; ! ok { delete ( entry . ConfigPools , poolName ) } } lst [ i ] = entry } } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( lst ) } 
func nodeContainerInfo ( w http . ResponseWriter , r * http . Request , t auth . Token ) error { pools , err := permission . ListContextValues ( t , permission . PermNodecontainerRead , true ) if err != nil { return err } name := r . URL . Query ( ) . Get ( " " ) configMap , err := nodecontainer . LoadNodeContainersForPools ( name ) if err != nil { if err == nodecontainer . ErrNodeContainerNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } return err } if pools != nil { poolMap := map [ string ] struct { } { } for _ , p := range pools { poolMap [ p ] = struct { } { } } for poolName := range configMap { if poolName == " " { continue } if _ , ok := poolMap [ poolName ] ; ! ok { delete ( configMap , poolName ) } } } w . Header ( ) . Set ( " " , " " ) return json . NewEncoder ( w ) . Encode ( configMap ) } 
func nodeContainerUpdate ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { var config nodecontainer . NodeContainerConfig err = ParseInput ( r , & config ) if err != nil { return err } poolName := InputValue ( r , " " ) var ctxs [ ] permTypes . PermissionContext if poolName != " " { ctxs = append ( ctxs , permission . Context ( permTypes . CtxPool , poolName ) ) } if ! permission . Check ( t , permission . PermNodecontainerUpdate , ctxs ... ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeNodeContainer , Value : config . Name } , Kind : permission . PermNodecontainerUpdate , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , ctxs ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) config . Name = r . URL . Query ( ) . Get ( " " ) err = nodecontainer . UpdateContainer ( poolName , & config ) if err != nil { if err == nodecontainer . ErrNodeContainerNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : err . Error ( ) , } } if _ , ok := err . ( nodecontainer . ValidationErr ) ; ok { return & tsuruErrors . HTTP { Code : http . StatusBadRequest , Message : err . Error ( ) , } } return err } return nil } 
func nodeContainerDelete ( w http . ResponseWriter , r * http . Request , t auth . Token ) ( err error ) { name := r . URL . Query ( ) . Get ( " " ) poolName := r . URL . Query ( ) . Get ( " " ) kill , _ := strconv . ParseBool ( r . URL . Query ( ) . Get ( " " ) ) var ctxs [ ] permTypes . PermissionContext if poolName != " " { ctxs = append ( ctxs , permission . Context ( permTypes . CtxPool , poolName ) ) } if ! permission . Check ( t , permission . PermNodecontainerDelete , ctxs ... ) { return permission . ErrUnauthorized } evt , err := event . New ( & event . Opts { Target : event . Target { Type : event . TargetTypeNodeContainer , Value : name } , Kind : permission . PermNodecontainerDelete , Owner : t , CustomData : event . FormToCustomData ( InputFields ( r ) ) , Allowed : event . Allowed ( permission . PermPoolReadEvents , ctxs ... ) , } ) if err != nil { return err } defer func ( ) { evt . Done ( err ) } ( ) err = nodecontainer . RemoveContainer ( poolName , name ) if err == nodecontainer . ErrNodeContainerNotFound { return & tsuruErrors . HTTP { Code : http . StatusNotFound , Message : fmt . Sprintf ( " " , name , poolName ) , } } if err != nil || ! kill { return err } provs , err := provision . Registry ( ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) keepAliveWriter := tsuruIo . NewKeepAliveWriter ( w , 15 * time . Second , " " ) defer keepAliveWriter . Stop ( ) writer := & tsuruIo . SimpleJsonMessageEncoderWriter { Encoder : json . NewEncoder ( keepAliveWriter ) } evt . SetLogWriter ( writer ) var allErrors [ ] string for _ , prov := range provs { ncProv , ok := prov . ( provision . NodeContainerProvisioner ) if ! ok { continue } err = ncProv . RemoveNodeContainer ( name , poolName , evt ) if err != nil { allErrors = append ( allErrors , err . Error ( ) ) } } if len ( allErrors ) > 0 { return errors . Errorf ( " " , strings . Join ( allErrors , " " ) ) } return nil } 
func ( p * dockerProvisioner ) GetAppFromUnitID ( unitID string ) ( provision . App , error ) { cnt , err := p . GetContainer ( unitID ) if err != nil { return nil , err } a , err := app . GetByName ( cnt . AppName ) if err != nil { return nil , err } return a , nil } 
func ValidateLength ( value string , min , max int ) bool { l := len ( value ) if min > 0 && l < min { return false } if max > 0 && l > max { return false } return true } 
func NewPipeline ( actions ... * Action ) * Pipeline { for i , action := range actions { newAction := & Action { Name : action . Name , Forward : action . Forward , Backward : action . Backward , MinParams : action . MinParams , OnError : action . OnError , } newActions [ i ] = newAction } return & Pipeline { actions : newActions } } 
func ( p * Pipeline ) Result ( ) Result { action := p . actions [ len ( p . actions ) - 1 ] action . rMutex . Lock ( ) defer action . rMutex . Unlock ( ) return action . result } 
func ( p * Pipeline ) Execute ( params ... interface { } ) ( err error ) { var r Result if len ( p . actions ) == 0 { return ErrPipelineNoActions } fwCtx := FWContext { Params : params } var i int var a * Action defer func ( ) { if r := recover ( ) ; r != nil { log . Errorf ( " " , a . Name , r ) err = fmt . Errorf ( " " , a . Name , r ) if a . OnError != nil { a . OnError ( fwCtx , err ) } p . rollback ( i - 1 , params ) } } ( ) for i , a = range p . actions { log . Debugf ( " " , a . Name ) if a . Forward == nil { err = ErrPipelineForwardMissing } else if len ( fwCtx . Params ) < a . MinParams { err = ErrPipelineFewParameters } else { r , err = a . Forward ( fwCtx ) a . rMutex . Lock ( ) a . result = r a . rMutex . Unlock ( ) fwCtx . Previous = r } if err != nil { log . Errorf ( " " , a . Name , err ) if a . OnError != nil { a . OnError ( fwCtx , err ) } p . rollback ( i - 1 , params ) return err } } return nil } 
func deepMap ( dst , src reflect . Value , visited map [ uintptr ] * visit , depth int , config * Config ) ( err error ) { overwrite := config . Overwrite if dst . CanAddr ( ) { addr := dst . UnsafeAddr ( ) h := 17 * addr seen := visited [ h ] typ := dst . Type ( ) for p := seen ; p != nil ; p = p . next { if p . ptr == addr && p . typ == typ { return nil } } } zeroValue := reflect . Value { } switch dst . Kind ( ) { case reflect . Map : dstMap := dst . Interface ( ) . ( map [ string ] interface { } ) for i , n := 0 , src . NumField ( ) ; i < n ; i ++ { srcType := src . Type ( ) field := srcType . Field ( i ) if ! isExported ( field ) { continue } fieldName := field . Name fieldName = changeInitialCase ( fieldName , unicode . ToLower ) if v , ok := dstMap [ fieldName ] ; ! ok || ( isEmptyValue ( reflect . ValueOf ( v ) ) || overwrite ) { dstMap [ fieldName ] = src . Field ( i ) . Interface ( ) } } case reflect . Ptr : if dst . IsNil ( ) { v := reflect . New ( dst . Type ( ) . Elem ( ) ) dst . Set ( v ) } dst = dst . Elem ( ) fallthrough case reflect . Struct : srcMap := src . Interface ( ) . ( map [ string ] interface { } ) for key := range srcMap { config . overwriteWithEmptyValue = true srcValue := srcMap [ key ] fieldName := changeInitialCase ( key , unicode . ToUpper ) dstElement := dst . FieldByName ( fieldName ) if dstElement == zeroValue { } srcElement := reflect . ValueOf ( srcValue ) dstKind := dstElement . Kind ( ) srcKind := srcElement . Kind ( ) if srcKind == reflect . Ptr && dstKind != reflect . Ptr { srcElement = srcElement . Elem ( ) srcKind = reflect . TypeOf ( srcElement . Interface ( ) ) . Kind ( ) } else if dstKind == reflect . Ptr { srcElement = reflect . ValueOf ( srcPtr ) srcKind = reflect . Ptr } } if ! srcElement . IsValid ( ) { continue } if srcKind == dstKind { if err = deepMerge ( dstElement , srcElement , visited , depth + 1 , config ) ; err != nil { return } } else if dstKind == reflect . Interface && dstElement . Kind ( ) == reflect . Interface { if err = deepMerge ( dstElement , srcElement , visited , depth + 1 , config ) ; err != nil { return } } else if srcKind == reflect . Map { if err = deepMap ( dstElement , srcElement , visited , depth + 1 , config ) ; err != nil { return } } else { return fmt . Errorf ( " " , fieldName , srcKind , dstKind ) } } } return } 
func Map ( dst , src interface { } , opts ... func ( * Config ) ) error { return _map ( dst , src , opts ... ) } 
func MapWithOverwrite ( dst , src interface { } , opts ... func ( * Config ) ) error { return _map ( dst , src , append ( opts , WithOverride ) ... ) } 
func deepMerge ( dst , src reflect . Value , visited map [ uintptr ] * visit , depth int , config * Config ) ( err error ) { overwrite := config . Overwrite typeCheck := config . TypeCheck overwriteWithEmptySrc := config . overwriteWithEmptyValue config . overwriteWithEmptyValue = false if ! src . IsValid ( ) { return } if dst . CanAddr ( ) { addr := dst . UnsafeAddr ( ) h := 17 * addr seen := visited [ h ] typ := dst . Type ( ) for p := seen ; p != nil ; p = p . next { if p . ptr == addr && p . typ == typ { return nil } } } if config . Transformers != nil && ! isEmptyValue ( dst ) { if fn := config . Transformers . Transformer ( dst . Type ( ) ) ; fn != nil { err = fn ( dst , src ) return } } switch dst . Kind ( ) { case reflect . Struct : if hasExportedField ( dst ) { for i , n := 0 , dst . NumField ( ) ; i < n ; i ++ { if err = deepMerge ( dst . Field ( i ) , src . Field ( i ) , visited , depth + 1 , config ) ; err != nil { return } } } else { if dst . CanSet ( ) && ( ! isEmptyValue ( src ) || overwriteWithEmptySrc ) && ( overwrite || isEmptyValue ( dst ) ) { dst . Set ( src ) } } case reflect . Map : if dst . IsNil ( ) && ! src . IsNil ( ) { dst . Set ( reflect . MakeMap ( dst . Type ( ) ) ) } for _ , key := range src . MapKeys ( ) { srcElement := src . MapIndex ( key ) if ! srcElement . IsValid ( ) { continue } dstElement := dst . MapIndex ( key ) switch srcElement . Kind ( ) { case reflect . Chan , reflect . Func , reflect . Map , reflect . Interface , reflect . Slice : if srcElement . IsNil ( ) { continue } fallthrough default : if ! srcElement . CanInterface ( ) { continue } switch reflect . TypeOf ( srcElement . Interface ( ) ) . Kind ( ) { case reflect . Struct : fallthrough case reflect . Ptr : fallthrough case reflect . Map : srcMapElm := srcElement dstMapElm := dstElement if srcMapElm . CanInterface ( ) { srcMapElm = reflect . ValueOf ( srcMapElm . Interface ( ) ) if dstMapElm . IsValid ( ) { dstMapElm = reflect . ValueOf ( dstMapElm . Interface ( ) ) } } if err = deepMerge ( dstMapElm , srcMapElm , visited , depth + 1 , config ) ; err != nil { return } case reflect . Slice : srcSlice := reflect . ValueOf ( srcElement . Interface ( ) ) var dstSlice reflect . Value if ! dstElement . IsValid ( ) || dstElement . IsNil ( ) { dstSlice = reflect . MakeSlice ( srcSlice . Type ( ) , 0 , srcSlice . Len ( ) ) } else { dstSlice = reflect . ValueOf ( dstElement . Interface ( ) ) } if ( ! isEmptyValue ( src ) || overwriteWithEmptySrc ) && ( overwrite || isEmptyValue ( dst ) ) && ! config . AppendSlice { if typeCheck && srcSlice . Type ( ) != dstSlice . Type ( ) { return fmt . Errorf ( " " , srcSlice . Type ( ) , dstSlice . Type ( ) ) } dstSlice = srcSlice } else if config . AppendSlice { if srcSlice . Type ( ) != dstSlice . Type ( ) { return fmt . Errorf ( " " , srcSlice . Type ( ) , dstSlice . Type ( ) ) } dstSlice = reflect . AppendSlice ( dstSlice , srcSlice ) } dst . SetMapIndex ( key , dstSlice ) } } if dstElement . IsValid ( ) && ! isEmptyValue ( dstElement ) && ( reflect . TypeOf ( srcElement . Interface ( ) ) . Kind ( ) == reflect . Map || reflect . TypeOf ( srcElement . Interface ( ) ) . Kind ( ) == reflect . Slice ) { continue } if srcElement . IsValid ( ) && ( overwrite || ( ! dstElement . IsValid ( ) || isEmptyValue ( dstElement ) ) ) { if dst . IsNil ( ) { dst . Set ( reflect . MakeMap ( dst . Type ( ) ) ) } dst . SetMapIndex ( key , srcElement ) } } case reflect . Slice : if ! dst . CanSet ( ) { break } if ( ! isEmptyValue ( src ) || overwriteWithEmptySrc ) && ( overwrite || isEmptyValue ( dst ) ) && ! config . AppendSlice { dst . Set ( src ) } else if config . AppendSlice { if src . Type ( ) != dst . Type ( ) { return fmt . Errorf ( " " , src . Type ( ) , dst . Type ( ) ) } dst . Set ( reflect . AppendSlice ( dst , src ) ) } case reflect . Ptr : fallthrough case reflect . Interface : if src . IsNil ( ) { break } if dst . Kind ( ) != reflect . Ptr && src . Type ( ) . AssignableTo ( dst . Type ( ) ) { if dst . IsNil ( ) || overwrite { if dst . CanSet ( ) && ( overwrite || isEmptyValue ( dst ) ) { dst . Set ( src ) } } break } if src . Kind ( ) != reflect . Interface { if dst . IsNil ( ) || overwrite { if dst . CanSet ( ) && ( overwrite || isEmptyValue ( dst ) ) { dst . Set ( src ) } } else if src . Kind ( ) == reflect . Ptr { if err = deepMerge ( dst . Elem ( ) , src . Elem ( ) , visited , depth + 1 , config ) ; err != nil { return } } else if dst . Elem ( ) . Type ( ) == src . Type ( ) { if err = deepMerge ( dst . Elem ( ) , src , visited , depth + 1 , config ) ; err != nil { return } } else { return ErrDifferentArgumentsTypes } break } if dst . IsNil ( ) || overwrite { if dst . CanSet ( ) && ( overwrite || isEmptyValue ( dst ) ) { dst . Set ( src ) } } else if err = deepMerge ( dst . Elem ( ) , src . Elem ( ) , visited , depth + 1 , config ) ; err != nil { return } default : if dst . CanSet ( ) && ( ! isEmptyValue ( src ) || overwriteWithEmptySrc ) && ( overwrite || isEmptyValue ( dst ) ) { dst . Set ( src ) } } return } 
func Merge ( dst , src interface { } , opts ... func ( * Config ) ) error { return merge ( dst , src , opts ... ) } 
func MergeWithOverwrite ( dst , src interface { } , opts ... func ( * Config ) ) error { return merge ( dst , src , append ( opts , WithOverride ) ... ) } 
func ( r * Request ) DecodeJsonPayload ( v interface { } ) error { content , err := ioutil . ReadAll ( r . Body ) r . Body . Close ( ) if err != nil { return err } if len ( content ) == 0 { return ErrJsonPayloadEmpty } err = json . Unmarshal ( content , v ) if err != nil { return err } return nil } 
func ( r * Request ) BaseUrl ( ) * url . URL { scheme := r . URL . Scheme if scheme == " " { scheme = " " } } host := r . Host if len ( host ) > 0 && host [ len ( host ) - 1 ] == '/' { host = host [ : len ( host ) - 1 ] } return & url . URL { Scheme : scheme , Host : host , } } 
func ( r * Request ) UrlFor ( path string , queryParams map [ string ] [ ] string ) * url . URL { baseUrl := r . BaseUrl ( ) baseUrl . Path = path if queryParams != nil { query := url . Values { } for k , v := range queryParams { for _ , vv := range v { query . Add ( k , vv ) } } baseUrl . RawQuery = query . Encode ( ) } return baseUrl } 
func ( r * Request ) GetCorsInfo ( ) * CorsInfo { origin := r . Header . Get ( " " ) var originUrl * url . URL var isCors bool if origin == " " { isCors = false } else if origin == " " { isCors = true } else { var err error originUrl , err = url . ParseRequestURI ( origin ) isCors = err == nil && r . Host != originUrl . Host } reqMethod := r . Header . Get ( " " ) reqHeaders := [ ] string { } rawReqHeaders := r . Header [ http . CanonicalHeaderKey ( " " ) ] for _ , rawReqHeader := range rawReqHeaders { if len ( rawReqHeader ) == 0 { continue } } } isPreflight := isCors && r . Method == " " && reqMethod != " " return & CorsInfo { IsCors : isCors , IsPreflight : isPreflight , Origin : origin , OriginUrl : originUrl , AccessControlRequestMethod : strings . ToUpper ( reqMethod ) , AccessControlRequestHeaders : reqHeaders , } } 
func ( mw * CorsMiddleware ) MiddlewareFunc ( handler HandlerFunc ) HandlerFunc { normedMethods := [ ] string { } for _ , allowedMethod := range mw . AllowedMethods { normed := strings . ToUpper ( allowedMethod ) mw . allowedMethods [ normed ] = true normedMethods = append ( normedMethods , normed ) } mw . allowedMethodsCsv = strings . Join ( normedMethods , " " ) mw . allowedHeaders = map [ string ] bool { } normedHeaders := [ ] string { } for _ , allowedHeader := range mw . AllowedHeaders { normed := http . CanonicalHeaderKey ( allowedHeader ) mw . allowedHeaders [ normed ] = true normedHeaders = append ( normedHeaders , normed ) } mw . allowedHeadersCsv = strings . Join ( normedHeaders , " " ) return func ( writer ResponseWriter , request * Request ) { corsInfo := request . GetCorsInfo ( ) return } return } return } if corsInfo . IsPreflight { return } return } } writer . Header ( ) . Set ( " " , mw . allowedMethodsCsv ) writer . Header ( ) . Set ( " " , mw . allowedHeadersCsv ) writer . Header ( ) . Set ( " " , corsInfo . Origin ) if mw . AccessControlAllowCredentials == true { writer . Header ( ) . Set ( " " , " " ) } writer . Header ( ) . Set ( " " , strconv . Itoa ( mw . AccessControlMaxAge ) ) writer . WriteHeader ( http . StatusOK ) return } } writer . Header ( ) . Set ( " " , corsInfo . Origin ) if mw . AccessControlAllowCredentials == true { writer . Header ( ) . Set ( " " , " " ) } return } } 
func ( mw * RecorderMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { return func ( w ResponseWriter , r * Request ) { writer := & recorderResponseWriter { w , 0 , false , 0 } r . Env [ " " ] = writer . statusCode r . Env [ " " ] = writer . bytesWritten } } 
func ( w * recorderResponseWriter ) WriteHeader ( code int ) { w . ResponseWriter . WriteHeader ( code ) if w . wroteHeader { return } w . statusCode = code w . wroteHeader = true } 
func ( w * recorderResponseWriter ) WriteJson ( v interface { } ) error { b , err := w . EncodeJson ( v ) if err != nil { return err } _ , err = w . Write ( b ) if err != nil { return err } return nil } 
func ( w * recorderResponseWriter ) CloseNotify ( ) <- chan bool { notifier := w . ResponseWriter . ( http . CloseNotifier ) return notifier . CloseNotify ( ) } 
func ( w * recorderResponseWriter ) Write ( b [ ] byte ) ( int , error ) { if ! w . wroteHeader { w . WriteHeader ( http . StatusOK ) } writer := w . ResponseWriter . ( http . ResponseWriter ) written , err := writer . Write ( b ) w . bytesWritten += int64 ( written ) return written , err } 
func MakeRouter ( routes ... * Route ) ( App , error ) { r := & router { Routes : routes , } err := r . start ( ) if err != nil { return nil , err } return r , nil } 
func ( rt * router ) AppFunc ( ) HandlerFunc { return func ( writer ResponseWriter , request * Request ) { if route == nil { if pathMatched { return } return } handler ( writer , request ) } } 
func escapedPath ( urlObj * url . URL ) string { return parts [ 0 ] } 
func escapedPathExp ( pathExp string ) ( string , error ) { } if pathExp [ 0 ] != '/' { return " " , errors . New ( " " ) } if strings . Contains ( pathExp , " " ) { return " " , errors . New ( " " ) } urlObj , err := url . Parse ( pathExp ) if err != nil { return " " , err } pathExp = postEscape . Replace ( pathExp ) return pathExp , nil } 
func ( rt * router ) start ( ) error { rt . trie = trie . New ( ) rt . index = map [ * Route ] int { } for i , route := range rt . Routes { if err != nil { return err } if err != nil { return err } } if rt . disableTrieCompression == false { rt . trie . Compress ( ) } return nil } 
func ( rt * router ) ofFirstDefinedRoute ( matches [ ] * trie . Match ) * trie . Match { minIndex := - 1 var bestMatch * trie . Match for _ , result := range matches { route := result . Route . ( * Route ) routeIndex := rt . index [ route ] if minIndex == - 1 || routeIndex < minIndex { minIndex = routeIndex bestMatch = result } } return bestMatch } 
func ( rt * router ) findRouteFromURL ( httpMethod string , urlObj * url . URL ) ( * Route , map [ string ] string , bool ) { } if len ( matches ) == 1 { } return result . Route . ( * Route ) , result . Params , pathMatched } 
func ( rt * router ) findRoute ( httpMethod , urlStr string ) ( * Route , map [ string ] string , bool , error ) { if err != nil { return nil , nil , false , err } route , params , pathMatched := rt . findRouteFromURL ( httpMethod , urlObj ) return route , params , pathMatched , nil } 
func ( mw * ContentTypeCheckerMiddleware ) MiddlewareFunc ( handler HandlerFunc ) HandlerFunc { return func ( w ResponseWriter , r * Request ) { mediatype , params , _ := mime . ParseMediaType ( r . Header . Get ( " " ) ) charset , ok := params [ " " ] if ! ok { charset = " " } return } } } 
func Error ( w ResponseWriter , error string , code int ) { w . WriteHeader ( code ) err := w . WriteJson ( map [ string ] string { ErrorFieldName : error } ) if err != nil { panic ( err ) } } 
func ( w * responseWriter ) CloseNotify ( ) <- chan bool { notifier := w . ResponseWriter . ( http . CloseNotifier ) return notifier . CloseNotify ( ) } 
func ( mw * AccessLogApacheMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { } } mw . convertFormat ( ) return func ( w ResponseWriter , r * Request ) { util := & accessLogUtil { w , r } mw . Logger . Print ( mw . executeTextTemplate ( util ) ) } } 
func ( mw * AccessLogApacheMiddleware ) convertFormat ( ) { tmplText := apacheAdapter . Replace ( string ( mw . Format ) ) funcMap := template . FuncMap { " " : func ( value string ) string { if value == " " { return " " } return value } , " " : func ( value int64 ) string { if value == 0 { return " " } return fmt . Sprintf ( " " , value ) } , " " : func ( dur * time . Duration ) string { if dur != nil { return fmt . Sprintf ( " " , dur . Nanoseconds ( ) / 1000 ) } return " " } , " " : func ( statusCode int ) string { if statusCode >= 400 && statusCode < 500 { return " " } else if statusCode >= 500 { return " " } return " " } , } var err error mw . textTemplate , err = template . New ( " " ) . Funcs ( funcMap ) . Parse ( tmplText ) if err != nil { panic ( err ) } } 
func ( mw * AccessLogApacheMiddleware ) executeTextTemplate ( util * accessLogUtil ) string { buf := bytes . NewBufferString ( " " ) err := mw . textTemplate . Execute ( buf , util ) if err != nil { panic ( err ) } return buf . String ( ) } 
func ( u * accessLogUtil ) RemoteUser ( ) string { if u . R . Env [ " " ] != nil { return u . R . Env [ " " ] . ( string ) } return " " } 
func ( u * accessLogUtil ) ApacheQueryString ( ) string { if u . R . URL . RawQuery != " " { return " " + u . R . URL . RawQuery } return " " } 
func ( u * accessLogUtil ) StartTime ( ) * time . Time { if u . R . Env [ " " ] != nil { return u . R . Env [ " " ] . ( * time . Time ) } return nil } 
func ( u * accessLogUtil ) ApacheRemoteAddr ( ) string { remoteAddr := u . R . RemoteAddr if remoteAddr != " " { if ip , _ , err := net . SplitHostPort ( remoteAddr ) ; err == nil { return ip } } return " " } 
func ( u * accessLogUtil ) StatusCode ( ) int { if u . R . Env [ " " ] != nil { return u . R . Env [ " " ] . ( int ) } return 0 } 
func ( u * accessLogUtil ) ResponseTime ( ) * time . Duration { if u . R . Env [ " " ] != nil { return u . R . Env [ " " ] . ( * time . Duration ) } return nil } 
func ( u * accessLogUtil ) BytesWritten ( ) int64 { if u . R . Env [ " " ] != nil { return u . R . Env [ " " ] . ( int64 ) } return 0 } 
func ( mw * JsonIndentMiddleware ) MiddlewareFunc ( handler HandlerFunc ) HandlerFunc { if mw . Indent == " " { mw . Indent = " " } return func ( w ResponseWriter , r * Request ) { writer := & jsonIndentResponseWriter { w , false , mw . Prefix , mw . Indent } } } 
func ( w * jsonIndentResponseWriter ) EncodeJson ( v interface { } ) ( [ ] byte , error ) { b , err := json . MarshalIndent ( v , w . prefix , w . indent ) if err != nil { return nil , err } return b , nil } 
func ( w * jsonIndentResponseWriter ) WriteHeader ( code int ) { w . ResponseWriter . WriteHeader ( code ) w . wroteHeader = true } 
func ( w * jsonIndentResponseWriter ) CloseNotify ( ) <- chan bool { notifier := w . ResponseWriter . ( http . CloseNotifier ) return notifier . CloseNotify ( ) } 
func ( w * jsonIndentResponseWriter ) Write ( b [ ] byte ) ( int , error ) { if ! w . wroteHeader { w . WriteHeader ( http . StatusOK ) } writer := w . ResponseWriter . ( http . ResponseWriter ) return writer . Write ( b ) } 
func ( route * Route ) MakePath ( pathParams map [ string ] string ) string { path := route . PathExp for paramName , paramValue := range pathParams { paramPlaceholder := " " + paramName relaxedPlaceholder := " " + paramName splatPlaceholder := " " + paramName r := strings . NewReplacer ( paramPlaceholder , paramValue , splatPlaceholder , paramValue , relaxedPlaceholder , paramValue ) path = r . Replace ( path ) } return path } 
func Head ( pathExp string , handlerFunc HandlerFunc ) * Route { return & Route { HttpMethod : " " , PathExp : pathExp , Func : handlerFunc , } } 
func ( mw * RecoverMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { } return func ( w ResponseWriter , r * Request ) { mw . logError ( message ) } else { Error ( w , " " , http . StatusInternalServerError ) } } } ( ) } } 
func WrapMiddlewares ( middlewares [ ] Middleware , handler HandlerFunc ) HandlerFunc { wrapped := handler for i := len ( middlewares ) - 1 ; i >= 0 ; i -- { wrapped = middlewares [ i ] . MiddlewareFunc ( wrapped ) } return wrapped } 
func adapterFunc ( handler HandlerFunc ) http . HandlerFunc { return func ( origWriter http . ResponseWriter , origRequest * http . Request ) { writer := & responseWriter { origWriter , false , } } } 
func ( mw * TimerMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { return func ( w ResponseWriter , r * Request ) { start := time . Now ( ) r . Env [ " " ] = & start end := time . Now ( ) elapsed := end . Sub ( start ) r . Env [ " " ] = & elapsed } } 
func ( mw * GzipMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { return func ( w ResponseWriter , r * Request ) { defer func ( ) { } } ( ) } } 
func ( w * gzipResponseWriter ) WriteHeader ( code int ) { if w . canGzip { w . Header ( ) . Set ( " " , " " ) } w . ResponseWriter . WriteHeader ( code ) w . wroteHeader = true } 
func ( w * gzipResponseWriter ) CloseNotify ( ) <- chan bool { notifier := w . ResponseWriter . ( http . CloseNotifier ) return notifier . CloseNotify ( ) } 
func ( w * gzipResponseWriter ) Hijack ( ) ( net . Conn , * bufio . ReadWriter , error ) { hijacker := w . ResponseWriter . ( http . Hijacker ) return hijacker . Hijack ( ) } 
func ( w * gzipResponseWriter ) Write ( b [ ] byte ) ( int , error ) { if ! w . wroteHeader { w . WriteHeader ( http . StatusOK ) } writer := w . ResponseWriter . ( http . ResponseWriter ) if w . canGzip { } count , errW := w . gzipWriter . Write ( b ) errF := w . gzipWriter . Flush ( ) if errW != nil { return count , errW } if errF != nil { return count , errF } return count , nil } return writer . Write ( b ) } 
func ( mw * AuthBasicMiddleware ) MiddlewareFunc ( handler HandlerFunc ) HandlerFunc { if mw . Realm == " " { log . Fatal ( " " ) } if mw . Authenticator == nil { log . Fatal ( " " ) } if mw . Authorizator == nil { mw . Authorizator = func ( userId string , request * Request ) bool { return true } } return func ( writer ResponseWriter , request * Request ) { authHeader := request . Header . Get ( " " ) if authHeader == " " { mw . unauthorized ( writer ) return } providedUserId , providedPassword , err := mw . decodeBasicAuthHeader ( authHeader ) if err != nil { Error ( writer , " " , http . StatusBadRequest ) return } if ! mw . Authenticator ( providedUserId , providedPassword ) { mw . unauthorized ( writer ) return } if ! mw . Authorizator ( providedUserId , request ) { mw . unauthorized ( writer ) return } request . Env [ " " ] = providedUserId handler ( writer , request ) } } 
func ( mw * IfMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { if mw . Condition == nil { log . Fatal ( " " ) } var ifTrueHandler HandlerFunc if mw . IfTrue != nil { ifTrueHandler = mw . IfTrue . MiddlewareFunc ( h ) } else { ifTrueHandler = h } var ifFalseHandler HandlerFunc if mw . IfFalse != nil { ifFalseHandler = mw . IfFalse . MiddlewareFunc ( h ) } else { ifFalseHandler = h } return func ( w ResponseWriter , r * Request ) { if mw . Condition ( r ) { ifTrueHandler ( w , r ) } else { ifFalseHandler ( w , r ) } } } 
func ( n * node ) printDebug ( level int ) { level ++ n . SplatChild . printDebug ( level ) } n . ParamChild . printDebug ( level ) } n . RelaxedChild . printDebug ( level ) } node . printDebug ( level ) } } 
func ( t * Trie ) AddRoute ( httpMethod , pathExp string , route interface { } ) error { return t . root . addRoute ( httpMethod , pathExp , route , [ ] string { } ) } 
func ( t * Trie ) printDebug ( ) { fmt . Print ( " \n " ) t . root . printDebug ( 0 ) fmt . Print ( " \n " ) } 
func ( t * Trie ) FindRoutes ( httpMethod , path string ) [ ] * Match { context := newFindContext ( ) matches := [ ] * Match { } context . matchFunc = func ( httpMethod , path string , node * node ) { if node . HttpMethodToRoute [ httpMethod ] != nil { } } t . root . find ( httpMethod , path , context ) return matches } 
func ( t * Trie ) FindRoutesAndPathMatched ( httpMethod , path string ) ( [ ] * Match , bool ) { context := newFindContext ( ) pathMatched := false matches := [ ] * Match { } context . matchFunc = func ( httpMethod , path string , node * node ) { pathMatched = true if node . HttpMethodToRoute [ httpMethod ] != nil { } } t . root . find ( httpMethod , path , context ) return matches , pathMatched } 
func ( t * Trie ) FindRoutesForPath ( path string ) [ ] * Match { context := newFindContext ( ) matches := [ ] * Match { } context . matchFunc = func ( httpMethod , path string , node * node ) { params := context . paramsAsMap ( ) for _ , route := range node . HttpMethodToRoute { matches = append ( matches , & Match { Route : route , Params : params , } , ) } } t . root . find ( " " , path , context ) return matches } 
func ( api * Api ) Use ( middlewares ... Middleware ) { api . stack = append ( api . stack , middlewares ... ) } 
func ( api * Api ) MakeHandler ( ) http . Handler { var appFunc HandlerFunc if api . app != nil { appFunc = api . app . AppFunc ( ) } else { appFunc = func ( w ResponseWriter , r * Request ) { } } return http . HandlerFunc ( adapterFunc ( WrapMiddlewares ( api . stack , appFunc ) , ) , ) } 
func ( mw * PoweredByMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { poweredBy := xPoweredByDefault if mw . XPoweredBy != " " { poweredBy = mw . XPoweredBy } return func ( w ResponseWriter , r * Request ) { w . Header ( ) . Add ( " " , poweredBy ) } } 
func ( mw * StatusMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { mw . start = time . Now ( ) mw . pid = os . Getpid ( ) mw . responseCounts = map [ string ] int { } mw . totalResponseTime = time . Time { } return func ( w ResponseWriter , r * Request ) { if r . Env [ " " ] == nil { log . Fatal ( " \" \" " + " " ) } statusCode := r . Env [ " " ] . ( int ) if r . Env [ " " ] == nil { log . Fatal ( " \" \" " + " " ) } responseTime := r . Env [ " " ] . ( * time . Duration ) mw . lock . Lock ( ) mw . responseCounts [ fmt . Sprintf ( " " , statusCode ) ] ++ mw . totalResponseTime = mw . totalResponseTime . Add ( * responseTime ) mw . lock . Unlock ( ) } } 
func ( mw * StatusMiddleware ) GetStatus ( ) * Status { mw . lock . RLock ( ) now := time . Now ( ) uptime := now . Sub ( mw . start ) totalCount := 0 for _ , count := range mw . responseCounts { totalCount += count } totalResponseTime := mw . totalResponseTime . Sub ( time . Time { } ) averageResponseTime := time . Duration ( 0 ) if totalCount > 0 { avgNs := int64 ( totalResponseTime ) / int64 ( totalCount ) averageResponseTime = time . Duration ( avgNs ) } status := & Status { Pid : mw . pid , UpTime : uptime . String ( ) , UpTimeSec : uptime . Seconds ( ) , Time : now . String ( ) , TimeUnix : now . Unix ( ) , StatusCodeCount : mw . responseCounts , TotalCount : totalCount , TotalResponseTime : totalResponseTime . String ( ) , TotalResponseTimeSec : totalResponseTime . Seconds ( ) , AverageResponseTime : averageResponseTime . String ( ) , AverageResponseTimeSec : averageResponseTime . Seconds ( ) , } mw . lock . RUnlock ( ) return status } 
func ( mw * JsonpMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { if mw . CallbackNameKey == " " { mw . CallbackNameKey = " " } return func ( w ResponseWriter , r * Request ) { callbackName := r . URL . Query ( ) . Get ( mw . CallbackNameKey ) } else { } } } 
func ( w * jsonpResponseWriter ) WriteHeader ( code int ) { w . Header ( ) . Set ( " " , " " ) w . ResponseWriter . WriteHeader ( code ) w . wroteHeader = true } 
func ( w * jsonpResponseWriter ) WriteJson ( v interface { } ) error { b , err := w . EncodeJson ( v ) if err != nil { return err } w . Header ( ) . Set ( " " , " " ) w . Write ( [ ] byte ( " " + w . callbackName + " " ) ) w . Write ( b ) w . Write ( [ ] byte ( " " ) ) return nil } 
func ( w * jsonpResponseWriter ) Flush ( ) { if ! w . wroteHeader { w . WriteHeader ( http . StatusOK ) } flusher := w . ResponseWriter . ( http . Flusher ) flusher . Flush ( ) } 
func ( w * jsonpResponseWriter ) CloseNotify ( ) <- chan bool { notifier := w . ResponseWriter . ( http . CloseNotifier ) return notifier . CloseNotify ( ) } 
func ( mw * AccessLogJsonMiddleware ) MiddlewareFunc ( h HandlerFunc ) HandlerFunc { } return func ( w ResponseWriter , r * Request ) { mw . Logger . Printf ( " " , makeAccessLogJsonRecord ( r ) . asJson ( ) ) } } 
func ( s * S3 ) Init ( ) error { if s . Bucket == " " { return errors . New ( " " ) } else if s . Key == " " { return errors . New ( " " ) } if s . Region == " " { s . Region = " " } creds := credentials . AnonymousCredentials if s . Access != " " { creds = credentials . NewStaticCredentials ( s . Access , s . Secret , " " ) } else if os . Getenv ( " " ) != " " { creds = credentials . NewEnvCredentials ( ) } config := & aws . Config { Credentials : creds , Region : & s . Region , } s . client = s3 . New ( session . New ( config ) ) } return nil } 
func ( s * S3 ) Fetch ( ) ( io . Reader , error ) { } s . delay = true if err != nil { return nil , fmt . Errorf ( " " , err ) } if s . lastETag == * head . ETag { return nil , nil } s . lastETag = * head . ETag if err != nil { return nil , fmt . Errorf ( " " , err ) } } } 
func Run ( c Config ) { err := runErr ( & c ) if err != nil { if c . Required { log . Fatalf ( " " , err ) } else if c . Debug || ! c . NoWarn { log . Printf ( " " , err ) } c . Program ( DisabledState ) return } os . Exit ( 0 ) } 
func sanityCheck ( ) bool { return true } return true } return false } 
func prog ( state overseer . State ) { fmt . Printf ( " \n " , BuildID , state . ID ) http . Handle ( " " , http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { d , _ := time . ParseDuration ( r . URL . Query ( ) . Get ( " " ) ) time . Sleep ( d ) fmt . Fprintf ( w , " \n " , BuildID , state . ID ) } ) ) http . Serve ( state . Listener , nil ) fmt . Printf ( " \n " , BuildID , state . ID ) } 
func main ( ) { overseer . Run ( overseer . Config { Program : prog , Address : " " , Fetcher : & fetcher . File { Path : " " } , Debug : false , } 
func ( l * overseerListener ) release ( timeout time . Duration ) { go func ( ) { l . wg . Wait ( ) waited <- true } ( ) go func ( ) { select { case <- time . After ( timeout ) : close ( l . closeByForce ) case <- waited : } ( ) } 
func ( mp * master ) fetchLoop ( ) { min := mp . Config . MinFetchInterval time . Sleep ( min ) for { t0 := time . Now ( ) mp . fetch ( ) if diff < min { delay := min - diff } } } 
func ( mp * master ) forkLoop ( ) error { } } } 
func ( h * Github ) Init ( ) error { } if h . Repo == " " { return fmt . Errorf ( " " ) } if h . Asset == nil { h . Asset = h . defaultAsset } h . releaseURL = " " + h . User + " " + h . Repo + " " if h . Interval == 0 { h . Interval = 5 * time . Minute } else if h . Interval < 1 * time . Minute { log . Printf ( " " ) } return nil } 
func ( h * Github ) Fetch ( ) ( io . Reader , error ) { } h . delay = true if err != nil { return nil , fmt . Errorf ( " " , err ) } if resp . StatusCode != http . StatusOK { resp . Body . Close ( ) return nil , fmt . Errorf ( " " , resp . StatusCode ) } if err := json . NewDecoder ( resp . Body ) . Decode ( & h . latestRelease ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } resp . Body . Close ( ) for _ , a := range h . latestRelease . Assets { if h . Asset ( a . Name ) { assetURL = a . URL break } } if assetURL == " " { return nil , fmt . Errorf ( " " , h . latestRelease . TagName ) } resp , err = http . DefaultTransport . RoundTrip ( req ) if err != nil { return nil , fmt . Errorf ( " " , err ) } resp . Body . Close ( ) if resp . StatusCode != http . StatusFound { return nil , fmt . Errorf ( " " , resp . StatusCode ) } s3URL := resp . Header . Get ( " " ) if err != nil { return nil , fmt . Errorf ( " " , err ) } req . Header . Set ( " " , " " ) resp , err = http . DefaultTransport . RoundTrip ( req ) if err != nil { return nil , fmt . Errorf ( " " , err ) } resp . Body . Close ( ) if resp . StatusCode != http . StatusPartialContent { return nil , fmt . Errorf ( " " , resp . StatusCode ) } etag := resp . Header . Get ( " " ) if etag != " " && h . lastETag == etag { return nil , nil } if err != nil { return nil , fmt . Errorf ( " " , err ) } if resp . StatusCode != http . StatusOK { resp . Body . Close ( ) return nil , fmt . Errorf ( " " , resp . StatusCode ) } h . lastETag = etag } return resp . Body , nil } 
func ( f * File ) Init ( ) error { if f . Path == " " { return fmt . Errorf ( " " ) } if f . Interval < 1 * time . Second { f . Interval = 1 * time . Second } if err := f . updateHash ( ) ; err != nil { return err } return nil } 
func ( f * File ) Fetch ( ) ( io . Reader , error ) { } f . delay = true lastHash := f . hash if err := f . updateHash ( ) ; err != nil { return nil , err } } if err != nil { return nil , err } const total = int ( 5 * time . Second / rate ) attempt := 1 for { if attempt == total { file . Close ( ) return nil , errors . New ( " " ) } attempt ++ return nil , err } } lastHash = f . hash } return file , nil } 
func ( h * HTTP ) Init ( ) error { } h . lasts = map [ string ] string { } if h . Interval == 0 { h . Interval = 5 * time . Minute } if h . CheckHeaders == nil { h . CheckHeaders = defaultHTTPCheckHeaders } return nil } 
func ( h * HTTP ) Fetch ( ) ( io . Reader , error ) { } h . delay = true if err != nil { return nil , fmt . Errorf ( " " , err ) } resp . Body . Close ( ) if resp . StatusCode != http . StatusOK { return nil , fmt . Errorf ( " " , resp . StatusCode ) } for _ , header := range h . CheckHeaders { if curr := resp . Header . Get ( header ) ; curr != " " { if last , ok := h . lasts [ header ] ; ok && last == curr { matches ++ } h . lasts [ header ] = curr total ++ } } if matches == total { return nil , nil } if err != nil { return nil , fmt . Errorf ( " " , err ) } if resp . StatusCode != http . StatusOK { return nil , fmt . Errorf ( " " , resp . StatusCode ) } } } 
func NewConfig ( ) * Config { c := & Config { Config : * sarama . NewConfig ( ) , } c . Group . PartitionStrategy = StrategyRange c . Group . Offsets . Retry . Max = 3 c . Group . Offsets . Synchronization . DwellTime = c . Consumer . MaxProcessingTime c . Group . Session . Timeout = 30 * time . Second c . Group . Heartbeat . Interval = 3 * time . Second c . Config . Version = minVersion return c } 
func ( c * Config ) Validate ( ) error { if c . Group . Heartbeat . Interval % time . Millisecond != 0 { sarama . Logger . Println ( " " ) } if c . Group . Session . Timeout % time . Millisecond != 0 { sarama . Logger . Println ( " " ) } if c . Group . PartitionStrategy != StrategyRange && c . Group . PartitionStrategy != StrategyRoundRobin { sarama . Logger . Println ( " " ) } if ! c . Version . IsAtLeast ( minVersion ) { sarama . Logger . Println ( " " ) c . Version = minVersion } if err := c . Config . Validate ( ) ; err != nil { return err } case c . Group . Offsets . Synchronization . DwellTime <= 0 : return sarama . ConfigurationError ( " " ) case c . Group . Offsets . Synchronization . DwellTime > 10 * time . Minute : return sarama . ConfigurationError ( " " ) case c . Group . Heartbeat . Interval <= 0 : return sarama . ConfigurationError ( " " ) case c . Group . Session . Timeout <= 0 : return sarama . ConfigurationError ( " " ) case ! c . Metadata . Full && c . Group . Topics . Whitelist != nil : return sarama . ConfigurationError ( " " ) case ! c . Metadata . Full && c . Group . Topics . Blacklist != nil : return sarama . ConfigurationError ( " " ) } } return nil } 
func NewClient ( addrs [ ] string , config * Config ) ( * Client , error ) { if config == nil { config = NewConfig ( ) } if err := config . Validate ( ) ; err != nil { return nil , err } client , err := sarama . NewClient ( addrs , & config . Config ) if err != nil { return nil , err } return & Client { Client : client , config : * config } , nil } 
func ( c * partitionConsumer ) AsyncClose ( ) { c . closeOnce . Do ( func ( ) { c . closeErr = c . PartitionConsumer . Close ( ) close ( c . dying ) } ) } 
func ( c * partitionConsumer ) Close ( ) error { c . AsyncClose ( ) <- c . dead return c . closeErr } 
func ( c * partitionConsumer ) MarkOffset ( offset int64 , metadata string ) { c . mu . Lock ( ) if next := offset + 1 ; next > c . state . Info . Offset { c . state . Info . Offset = next c . state . Info . Metadata = metadata c . state . Dirty = true } c . mu . Unlock ( ) } 
func NewConsumer ( addrs [ ] string , groupID string , topics [ ] string , config * Config ) ( * Consumer , error ) { client , err := NewClient ( addrs , config ) if err != nil { return nil , err } consumer , err := NewConsumerFromClient ( client , groupID , topics ) if err != nil { return nil , err } consumer . ownClient = true return consumer , nil } 
func NewConsumerFromClient ( client * Client , groupID string , topics [ ] string ) ( * Consumer , error ) { if ! client . claim ( ) { return nil , errClientInUse } consumer , err := sarama . NewConsumerFromClient ( client . Client ) if err != nil { client . release ( ) return nil , err } sort . Strings ( topics ) c := & Consumer { client : client , consumer : consumer , subs : newPartitionMap ( ) , groupID : groupID , coreTopics : topics , dying : make ( chan none ) , dead : make ( chan none ) , messages : make ( chan * sarama . ConsumerMessage ) , errors : make ( chan error , client . config . ChannelBufferSize ) , partitions : make ( chan PartitionConsumer , 1 ) , notifications : make ( chan * Notification ) , } if err := c . client . RefreshCoordinator ( groupID ) ; err != nil { client . release ( ) return nil , err } go c . mainLoop ( ) return c , nil } 
func ( c * Consumer ) MarkPartitionOffset ( topic string , partition int32 , offset int64 , metadata string ) { if sub := c . subs . Fetch ( topic , partition ) ; sub != nil { sub . MarkOffset ( offset , metadata ) } } 
func ( c * Consumer ) MarkOffsets ( s * OffsetStash ) { s . mu . Lock ( ) defer s . mu . Unlock ( ) for tp , info := range s . offsets { if sub := c . subs . Fetch ( tp . Topic , tp . Partition ) ; sub != nil { sub . MarkOffset ( info . Offset , info . Metadata ) } delete ( s . offsets , tp ) } } 
func ( c * Consumer ) ResetOffset ( msg * sarama . ConsumerMessage , metadata string ) { if sub := c . subs . Fetch ( msg . Topic , msg . Partition ) ; sub != nil { sub . ResetOffset ( msg . Offset , metadata ) } } 
func ( c * Consumer ) ResetPartitionOffset ( topic string , partition int32 , offset int64 , metadata string ) { sub := c . subs . Fetch ( topic , partition ) if sub != nil { sub . ResetOffset ( offset , metadata ) } } 
func ( c * Consumer ) CommitOffsets ( ) error { c . commitMu . Lock ( ) defer c . commitMu . Unlock ( ) memberID , generationID := c . membership ( ) req := & sarama . OffsetCommitRequest { Version : 2 , ConsumerGroup : c . groupID , ConsumerGroupGeneration : generationID , ConsumerID : memberID , RetentionTime : - 1 , } if ns := c . client . config . Consumer . Offsets . Retention ; ns != 0 { req . RetentionTime = int64 ( ns / time . Millisecond ) } snap := c . subs . Snapshot ( ) dirty := false for tp , state := range snap { if state . Dirty { dirty = true req . AddBlock ( tp . Topic , tp . Partition , state . Info . Offset , 0 , state . Info . Metadata ) } } if ! dirty { return nil } broker , err := c . client . Coordinator ( c . groupID ) if err != nil { c . closeCoordinator ( broker , err ) return err } resp , err := broker . CommitOffset ( req ) if err != nil { c . closeCoordinator ( broker , err ) return err } for topic , errs := range resp . Errors { for partition , kerr := range errs { if kerr != sarama . ErrNoError { err = kerr } else if state , ok := snap [ topicPartition { topic , partition } ] ; ok { if sub := c . subs . Fetch ( topic , partition ) ; sub != nil { sub . markCommitted ( state . Info . Offset ) } } } } return err } 
func ( c * Consumer ) Close ( ) ( err error ) { c . closeOnce . Do ( func ( ) { close ( c . dying ) <- c . dead if e := c . release ( ) ; e != nil { err = e } if e := c . consumer . Close ( ) ; e != nil { err = e } close ( c . messages ) close ( c . errors ) if e := c . leaveGroup ( ) ; e != nil { err = e } close ( c . partitions ) close ( c . notifications ) for range c . errors { } for p := range c . partitions { _ = p . Close ( ) } for range c . notifications { } c . client . release ( ) if c . ownClient { if e := c . client . Close ( ) ; e != nil { err = e } } } ) return } 
func ( c * Consumer ) hbLoop ( stopped <- chan none ) { ticker := time . NewTicker ( c . client . config . Group . Heartbeat . Interval ) defer ticker . Stop ( ) for { select { case <- ticker . C : switch err := c . heartbeat ( ) ; err { case nil , sarama . ErrNoError : case sarama . ErrNotCoordinatorForConsumer , sarama . ErrRebalanceInProgress : return default : c . handleError ( & Error { Ctx : " " , error : err } ) return } case <- stopped : return case <- c . dying : return } } } 
func ( c * Consumer ) twLoop ( stopped <- chan none ) { ticker := time . NewTicker ( c . client . config . Metadata . RefreshFrequency / 2 ) defer ticker . Stop ( ) for { select { case <- ticker . C : topics , err := c . client . Topics ( ) if err != nil { c . handleError ( & Error { Ctx : " " , error : err } ) return } for _ , topic := range topics { if ! c . isKnownCoreTopic ( topic ) && ! c . isKnownExtraTopic ( topic ) && c . isPotentialExtraTopic ( topic ) { return } } case <- stopped : return case <- c . dying : return } } } 
func ( c * Consumer ) cmLoop ( stopped <- chan none ) { ticker := time . NewTicker ( c . client . config . Consumer . Offsets . CommitInterval ) defer ticker . Stop ( ) for { select { case <- ticker . C : if err := c . commitOffsetsWithRetry ( c . client . config . Group . Offsets . Retry . Max ) ; err != nil { c . handleError ( & Error { Ctx : " " , error : err } ) return } case <- stopped : return case <- c . dying : return } } } 
func ( c * Consumer ) release ( ) ( err error ) { defer timeout . Stop ( ) select { case <- c . dying : case <- timeout . C : } } return } 
func ( c * Consumer ) heartbeat ( ) error { broker , err := c . client . Coordinator ( c . groupID ) if err != nil { c . closeCoordinator ( broker , err ) return err } memberID , generationID := c . membership ( ) resp , err := broker . Heartbeat ( & sarama . HeartbeatRequest { GroupId : c . groupID , MemberId : memberID , GenerationId : generationID , } ) if err != nil { c . closeCoordinator ( broker , err ) return err } return resp . Err } 
func ( c * Consumer ) rebalance ( ) ( map [ string ] [ ] int32 , error ) { memberID , _ := c . membership ( ) sarama . Logger . Printf ( " \n " , memberID ) allTopics , err := c . client . Topics ( ) if err != nil { return nil , err } c . extraTopics = c . selectExtraTopics ( allTopics ) sort . Strings ( c . extraTopics ) switch { case err == sarama . ErrUnknownMemberId : c . membershipMu . Lock ( ) c . memberID = " " c . membershipMu . Unlock ( ) return nil , err case err != nil : return nil , err } switch { case err == sarama . ErrRebalanceInProgress : return nil , err case err != nil : _ = c . leaveGroup ( ) return nil , err } return subs , nil } 
func ( c * Consumer ) subscribe ( tomb * loopTomb , subs map [ string ] [ ] int32 ) error { if err != nil { _ = c . leaveGroup ( ) return err } var wg sync . WaitGroup for topic , partitions := range subs { for _ , partition := range partitions { wg . Add ( 1 ) info := offsets [ topic ] [ partition ] go func ( topic string , partition int32 ) { if e := c . createConsumer ( tomb , topic , partition , info ) ; e != nil { mu . Lock ( ) err = e mu . Unlock ( ) } wg . Done ( ) } ( topic , partition ) } } wg . Wait ( ) if err != nil { _ = c . release ( ) _ = c . leaveGroup ( ) } return err } 
func ( c * Consumer ) joinGroup ( ) ( * balancer , error ) { memberID , _ := c . membership ( ) req := & sarama . JoinGroupRequest { GroupId : c . groupID , MemberId : memberID , SessionTimeout : int32 ( c . client . config . Group . Session . Timeout / time . Millisecond ) , ProtocolType : " " , } meta := & sarama . ConsumerGroupMemberMetadata { Version : 1 , Topics : append ( c . coreTopics , c . extraTopics ... ) , UserData : c . client . config . Group . Member . UserData , } err := req . AddGroupProtocolMetadata ( string ( StrategyRange ) , meta ) if err != nil { return nil , err } err = req . AddGroupProtocolMetadata ( string ( StrategyRoundRobin ) , meta ) if err != nil { return nil , err } broker , err := c . client . Coordinator ( c . groupID ) if err != nil { c . closeCoordinator ( broker , err ) return nil , err } resp , err := broker . JoinGroup ( req ) if err != nil { c . closeCoordinator ( broker , err ) return nil , err } else if resp . Err != sarama . ErrNoError { c . closeCoordinator ( broker , resp . Err ) return nil , resp . Err } var strategy * balancer if resp . LeaderId == resp . MemberId { members , err := resp . GetMembers ( ) if err != nil { return nil , err } strategy , err = newBalancerFromMeta ( c . client , Strategy ( resp . GroupProtocol ) , members ) if err != nil { return nil , err } } c . membershipMu . Lock ( ) c . memberID = resp . MemberId c . generationID = resp . GenerationId c . membershipMu . Unlock ( ) return strategy , nil } 
func ( c * Consumer ) syncGroup ( strategy * balancer ) ( map [ string ] [ ] int32 , error ) { memberID , generationID := c . membership ( ) req := & sarama . SyncGroupRequest { GroupId : c . groupID , MemberId : memberID , GenerationId : generationID , } if strategy != nil { for memberID , topics := range strategy . Perform ( ) { if err := req . AddGroupAssignmentMember ( memberID , & sarama . ConsumerGroupMemberAssignment { Topics : topics , } ) ; err != nil { return nil , err } } } broker , err := c . client . Coordinator ( c . groupID ) if err != nil { c . closeCoordinator ( broker , err ) return nil , err } resp , err := broker . SyncGroup ( req ) if err != nil { c . closeCoordinator ( broker , err ) return nil , err } else if resp . Err != sarama . ErrNoError { c . closeCoordinator ( broker , resp . Err ) return nil , resp . Err } } if err != nil { return nil , err } } return members . Topics , nil } 
func ( c * Consumer ) fetchOffsets ( subs map [ string ] [ ] int32 ) ( map [ string ] map [ int32 ] offsetInfo , error ) { offsets := make ( map [ string ] map [ int32 ] offsetInfo , len ( subs ) ) req := & sarama . OffsetFetchRequest { Version : 1 , ConsumerGroup : c . groupID , } for topic , partitions := range subs { offsets [ topic ] = make ( map [ int32 ] offsetInfo , len ( partitions ) ) for _ , partition := range partitions { offsets [ topic ] [ partition ] = offsetInfo { Offset : - 1 } req . AddPartition ( topic , partition ) } } broker , err := c . client . Coordinator ( c . groupID ) if err != nil { c . closeCoordinator ( broker , err ) return nil , err } resp , err := broker . FetchOffset ( req ) if err != nil { c . closeCoordinator ( broker , err ) return nil , err } for topic , partitions := range subs { for _ , partition := range partitions { block := resp . GetBlock ( topic , partition ) if block == nil { return nil , sarama . ErrIncompleteResponse } if block . Err == sarama . ErrNoError { offsets [ topic ] [ partition ] = offsetInfo { Offset : block . Offset , Metadata : block . Metadata } } else { return nil , block . Err } } } return offsets , nil } 
func ( c * Consumer ) leaveGroup ( ) error { broker , err := c . client . Coordinator ( c . groupID ) if err != nil { c . closeCoordinator ( broker , err ) return err } memberID , _ := c . membership ( ) if _ , err = broker . LeaveGroup ( & sarama . LeaveGroupRequest { GroupId : c . groupID , MemberId : memberID , } ) ; err != nil { c . closeCoordinator ( broker , err ) } return err } 
func ( s * OffsetStash ) MarkOffset ( msg * sarama . ConsumerMessage , metadata string ) { s . MarkPartitionOffset ( msg . Topic , msg . Partition , msg . Offset , metadata ) } 
func ( s * OffsetStash ) MarkPartitionOffset ( topic string , partition int32 , offset int64 , metadata string ) { s . mu . Lock ( ) defer s . mu . Unlock ( ) key := topicPartition { Topic : topic , Partition : partition } if info := s . offsets [ key ] ; offset >= info . Offset { info . Offset = offset info . Metadata = metadata s . offsets [ key ] = info } } 
func ( s * OffsetStash ) ResetOffset ( msg * sarama . ConsumerMessage , metadata string ) { s . ResetPartitionOffset ( msg . Topic , msg . Partition , msg . Offset , metadata ) } 
func ( s * OffsetStash ) Offsets ( ) map [ string ] int64 { s . mu . Lock ( ) defer s . mu . Unlock ( ) res := make ( map [ string ] int64 , len ( s . offsets ) ) for tp , info := range s . offsets { res [ tp . String ( ) ] = info . Offset } return res } 
func ( r * InstanceGroup ) Actual ( immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) if r . CachedActual != nil { logger . Debug ( " " ) return immutable , r . CachedActual , nil } newResource := & InstanceGroup { Shared : Shared { Name : r . Name , CloudID : r . ServerPool . Identifier , } , } project , err := Sdk . Service . Projects . Get ( immutable . ProviderConfig ( ) . CloudId ) . Do ( ) if err != nil && project != nil { instances , err := Sdk . Service . Instances . List ( immutable . ProviderConfig ( ) . CloudId , immutable . ProviderConfig ( ) . Location ) . Do ( ) if err != nil { return nil , nil , err } count := len ( instances . Items ) if count > 0 { newResource . Count = count instance := instances . Items [ 0 ] newResource . Name = instance . Name newResource . CloudID = string ( instance . Id ) newResource . Size = instance . Kind newResource . Image = r . Image newResource . Location = instance . Zone } } newResource . BootstrapScripts = r . ServerPool . BootstrapScripts newResource . SSHFingerprint = immutable . ProviderConfig ( ) . SSH . PublicKeyFingerprint newResource . Name = r . Name r . CachedActual = newResource return immutable , newResource , nil } 
func ( r * InstanceGroup ) Expected ( immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) if r . CachedExpected != nil { logger . Debug ( " " ) return immutable , r . CachedExpected , nil } expected := & InstanceGroup { Shared : Shared { Name : r . Name , CloudID : r . ServerPool . Identifier , } , Size : r . ServerPool . Size , Location : immutable . ProviderConfig ( ) . Location , Image : r . ServerPool . Image , Count : r . ServerPool . MaxCount , SSHFingerprint : immutable . ProviderConfig ( ) . SSH . PublicKeyFingerprint , BootstrapScripts : r . ServerPool . BootstrapScripts , } r . CachedExpected = expected return immutable , expected , nil } 
func ( r * InstanceGroup ) Apply ( actual , expected cloud . Resource , immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) applyResource := expected . ( * InstanceGroup ) isEqual , err := compare . IsEqual ( actual . ( * InstanceGroup ) , expected . ( * InstanceGroup ) ) if err != nil { return nil , nil , err } if isEqual { return immutable , applyResource , nil } masterIPPrivate := " " masterIPPublic := " " if r . ServerPool . Type == cluster . ServerPoolTypeNode { found := false for i := 0 ; i < MasterIPAttempts ; i ++ { masterTag := " " machineConfigs := immutable . MachineProviderConfigs ( ) for _ , machineConfig := range machineConfigs { serverPool := machineConfig . ServerPool if serverPool . Type == cluster . ServerPoolTypeMaster { masterTag = serverPool . Name } } if masterTag == " " { return nil , nil , fmt . Errorf ( " " ) } instanceGroupManager , err := Sdk . Service . InstanceGroupManagers . ListManagedInstances ( immutable . ProviderConfig ( ) . CloudId , expected . ( * InstanceGroup ) . Location , strings . ToLower ( masterTag ) ) . Do ( ) if err != nil { return nil , nil , err } if err != nil || len ( instanceGroupManager . ManagedInstances ) == 0 { logger . Debug ( " " , err ) time . Sleep ( time . Duration ( MasterIPSleepSecondsPerAttempt ) * time . Second ) continue } parts := strings . Split ( instanceGroupManager . ManagedInstances [ 0 ] . Instance , " " ) instance , err := Sdk . Service . Instances . Get ( immutable . ProviderConfig ( ) . CloudId , expected . ( * InstanceGroup ) . Location , parts [ len ( parts ) - 1 ] ) . Do ( ) if err != nil { logger . Debug ( " " , err ) time . Sleep ( time . Duration ( MasterIPSleepSecondsPerAttempt ) * time . Second ) continue } for _ , networkInterface := range instance . NetworkInterfaces { if networkInterface . Name == " " { masterIPPrivate = networkInterface . NetworkIP for _ , accessConfigs := range networkInterface . AccessConfigs { masterIPPublic = accessConfigs . NatIP } } } if masterIPPublic == " " { logger . Debug ( " " ) time . Sleep ( time . Duration ( MasterIPSleepSecondsPerAttempt ) * time . Second ) continue } found = true providerConfig := immutable . ProviderConfig ( ) providerConfig . Values . ItemMap [ " " ] = fmt . Sprintf ( " " , masterIPPrivate , immutable . ProviderConfig ( ) . KubernetesAPI . Port ) immutable . SetProviderConfig ( providerConfig ) break } if ! found { return nil , nil , fmt . Errorf ( " " ) } } providerConfig := immutable . ProviderConfig ( ) providerConfig . Values . ItemMap [ " " ] = immutable . ProviderConfig ( ) . KubernetesAPI . Port immutable . SetProviderConfig ( providerConfig ) scripts , err := script . BuildBootstrapScript ( r . ServerPool . BootstrapScripts , immutable ) if err != nil { return nil , nil , err } finalScripts := string ( scripts ) if err != nil { return nil , nil , err } tags := [ ] string { } if r . ServerPool . Type == cluster . ServerPoolTypeMaster { if immutable . ProviderConfig ( ) . KubernetesAPI . Port == " " { tags = append ( tags , " " ) } if immutable . ProviderConfig ( ) . KubernetesAPI . Port == " " { tags = append ( tags , " " ) } tags = append ( tags , " " ) } if r . ServerPool . Type == cluster . ServerPoolTypeNode { tags = append ( tags , " " ) } prefix := " " + immutable . ProviderConfig ( ) . CloudId imageURL := " " + expected . ( * InstanceGroup ) . Image templateInstance , err := Sdk . Service . InstanceTemplates . Get ( immutable . ProviderConfig ( ) . CloudId , strings . ToLower ( expected . ( * InstanceGroup ) . Name ) ) . Do ( ) if err != nil { sshPublicKeyValue := fmt . Sprintf ( " " , immutable . ProviderConfig ( ) . SSH . User , string ( immutable . ProviderConfig ( ) . SSH . PublicKeyData ) ) templateInstance = & compute . InstanceTemplate { Name : strings . ToLower ( expected . ( * InstanceGroup ) . Name ) , Properties : & compute . InstanceProperties { MachineType : expected . ( * InstanceGroup ) . Size , Disks : [ ] * compute . AttachedDisk { { AutoDelete : true , Boot : true , Type : " " , InitializeParams : & compute . AttachedDiskInitializeParams { SourceImage : imageURL , } , } , } , NetworkInterfaces : [ ] * compute . NetworkInterface { { AccessConfigs : [ ] * compute . AccessConfig { { Type : " " , Name : " " , } , } , Network : prefix + " " , } , } , ServiceAccounts : [ ] * compute . ServiceAccount { { Email : " " , Scopes : [ ] string { compute . DevstorageFullControlScope , compute . ComputeScope , } , } , } , Metadata : & compute . Metadata { Kind : " " , Items : [ ] * compute . MetadataItems { { Key : " " , Value : & sshPublicKeyValue , } , { Key : " " , Value : & finalScripts , } , } , } , Tags : & compute . Tags { Items : tags , } , } , } _ , err = Sdk . Service . InstanceTemplates . Insert ( immutable . ProviderConfig ( ) . CloudId , templateInstance ) . Do ( ) if err != nil { return nil , nil , err } } _ , err = Sdk . Service . InstanceGroupManagers . Get ( immutable . ProviderConfig ( ) . CloudId , expected . ( * InstanceGroup ) . Location , strings . ToLower ( expected . ( * InstanceGroup ) . Name ) ) . Do ( ) if err != nil { instanceGroupManager := & compute . InstanceGroupManager { Name : templateInstance . Name , BaseInstanceName : templateInstance . Name , InstanceTemplate : prefix + " " + templateInstance . Name , TargetSize : int64 ( expected . ( * InstanceGroup ) . Count ) , } for i := 0 ; i < MasterIPAttempts ; i ++ { logger . Debug ( " " ) _ , err = Sdk . Service . InstanceGroupManagers . Insert ( immutable . ProviderConfig ( ) . CloudId , expected . ( * InstanceGroup ) . Location , instanceGroupManager ) . Do ( ) if err == nil { break } logger . Debug ( " " ) time . Sleep ( time . Duration ( MasterIPSleepSecondsPerAttempt ) * time . Second ) } logger . Success ( " " , templateInstance . Name ) } newResource := & InstanceGroup { Shared : Shared { Name : r . ServerPool . Name , providerConfig = immutable . ProviderConfig ( ) providerConfig . KubernetesAPI . Endpoint = masterIPPublic immutable . SetProviderConfig ( providerConfig ) renderedCluster , err := r . immutableRender ( newResource , immutable ) if err != nil { return nil , nil , err } return renderedCluster , newResource , nil } 
func ( r * InstanceGroup ) Delete ( actual cloud . Resource , immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) deleteResource := actual . ( * InstanceGroup ) if deleteResource . Name == " " { return nil , nil , fmt . Errorf ( " " , deleteResource . Name ) } logger . Success ( " " , r . ServerPool . Name ) _ , err := Sdk . Service . InstanceGroupManagers . Get ( immutable . ProviderConfig ( ) . CloudId , immutable . ProviderConfig ( ) . Location , strings . ToLower ( r . ServerPool . Name ) ) . Do ( ) if err == nil { _ , err := Sdk . Service . InstanceGroupManagers . Delete ( immutable . ProviderConfig ( ) . CloudId , immutable . ProviderConfig ( ) . Location , strings . ToLower ( r . ServerPool . Name ) ) . Do ( ) if err != nil { return nil , nil , err } } _ , err = Sdk . Service . InstanceTemplates . Get ( immutable . ProviderConfig ( ) . CloudId , strings . ToLower ( r . ServerPool . Name ) ) . Do ( ) if err == nil { err := r . retryDeleteInstanceTemplate ( immutable ) if err != nil { return nil , nil , err } } providerConfig . KubernetesAPI . Endpoint = " " immutable . SetProviderConfig ( providerConfig ) renderedCluster , err := r . immutableRender ( actual , immutable ) if err != nil { return nil , nil , err } return renderedCluster , actual , nil } 
func GetReconciler ( known * cluster . Cluster , runtimeParameters * RuntimeParameters ) ( reconciler cloud . Reconciler , err error ) { switch known . ProviderConfig ( ) . Cloud { case cluster . CloudGoogle : sdk , err := googleSDK . NewSdk ( ) if err != nil { return nil , err } gr . Sdk = sdk return cloud . NewAtomicReconciler ( known , compute . NewGoogleComputeModel ( known ) ) , nil case cluster . CloudDigitalOcean : sdk , err := godoSdk . NewSdk ( ) if err != nil { return nil , err } dr . Sdk = sdk return cloud . NewAtomicReconciler ( known , droplet . NewDigitalOceanDropletModel ( known ) ) , nil case cluster . CloudAmazon : awsProfile := " " if runtimeParameters != nil { awsProfile = runtimeParameters . AwsProfile } sdk , err := awsSdkGo . NewSdk ( known . ProviderConfig ( ) . Location , awsProfile ) if err != nil { return nil , err } ar . Sdk = sdk return cloud . NewAtomicReconciler ( known , awspub . NewAmazonPublicModel ( known ) ) , nil case cluster . CloudAzure : sdk , err := azureSDK . NewSdk ( ) if err != nil { return nil , err } azr . Sdk = sdk return cloud . NewAtomicReconciler ( known , azpub . NewAzurePublicModel ( known ) ) , nil case cluster . CloudOVH : sdk , err := openstackSdk . NewSdk ( known . ProviderConfig ( ) . Location ) if err != nil { return nil , err } osr . Sdk = sdk return cloud . NewAtomicReconciler ( known , osovh . NewOvhPublicModel ( known ) ) , nil case cluster . CloudPacket : sdk , err := packetSDK . NewSdk ( ) if err != nil { return nil , err } packetr . Sdk = sdk return cloud . NewAtomicReconciler ( known , packetpub . NewPacketPublicModel ( known ) ) , nil case cluster . CloudECS : sdk , err := openstackSdk . NewSdk ( known . ProviderConfig ( ) . Location ) if err != nil { return nil , err } osr . Sdk = sdk return cloud . NewAtomicReconciler ( known , osecs . NewEcsPublicModel ( known ) ) , nil default : return nil , fmt . Errorf ( " " , known . ProviderConfig ( ) . Cloud ) } } 
func GetVersion ( ) * Version { return & Version { Version : KubicornVersion , GitCommit : GitSha , BuildDate : time . Now ( ) . UTC ( ) . String ( ) , GoVersion : runtime . Version ( ) , GOOS : runtime . GOOS , GOArch : runtime . GOARCH , } } 
func GetVersionJSON ( ) string { verBytes , err := json . Marshal ( GetVersion ( ) ) if err != nil { logger . Critical ( " " , err ) } return string ( verBytes ) } 
func ( r * ResourceGroup ) Actual ( immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) newResource := & ResourceGroup { Shared : Shared { Name : r . Name , Tags : r . Tags , Identifier : immutable . ProviderConfig ( ) . GroupIdentifier , } , Location : r . Location , } if r . Identifier != " " { group , err := Sdk . ResourceGroup . Get ( immutable . Name ) if err != nil { return nil , nil , err } newResource . Location = * group . Location newResource . Name = * group . Name newResource . Identifier = * group . ID } newCluster := r . immutableRender ( newResource , immutable ) return newCluster , newResource , nil } 
func ( r * ResourceGroup ) Expected ( immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) newResource := & ResourceGroup { Shared : Shared { Name : immutable . Name , Tags : r . Tags , Identifier : immutable . ProviderConfig ( ) . GroupIdentifier , } , Location : immutable . ProviderConfig ( ) . Location , } newCluster := r . immutableRender ( newResource , immutable ) return newCluster , newResource , nil } 
func CreateCmd ( ) * cobra . Command { var co = & cli . CreateOptions { } var createCmd = & cobra . Command { Use : " " , Short : " " , Long : `Use this command to create a Kubicorn API model in a defined state store. This command will create a cluster API model as a YAML manifest in a state store. Once the API model has been created, a user can optionally change the model to their liking. After a model is defined and configured properly, the user can then apply the model.` , Run : func ( cmd * cobra . Command , args [ ] string ) { switch len ( args ) { case 0 : co . Name = viper . GetString ( keyKubicornName ) if co . Name == " " { co . Name = namer . RandomName ( ) } case 1 : co . Name = args [ 0 ] default : logger . Critical ( " " ) os . Exit ( 1 ) } if err := RunCreate ( co ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := createCmd . Flags ( ) bindCommonStateStoreFlags ( & co . StateStoreOptions , fs ) bindCommonAwsFlags ( & co . AwsOptions , fs ) fs . StringVarP ( & co . Profile , keyProfile , " " , viper . GetString ( keyProfile ) , descProfile ) fs . StringVarP ( & co . CloudID , keyCloudID , " " , viper . GetString ( keyCloudID ) , descCloudID ) fs . StringVar ( & co . KubeConfigLocalFile , keyKubeConfigLocalFile , viper . GetString ( keyKubeConfigLocalFile ) , descKubeConfigLocalFile ) fs . StringArrayVarP ( & co . Set , keySet , " " , viper . GetStringSlice ( keySet ) , descSet ) fs . StringArrayVarP ( & co . MasterSet , keyMasterSet , " " , viper . GetStringSlice ( keyMasterSet ) , descMasterSet ) fs . StringArrayVarP ( & co . NodeSet , keyNodeSet , " " , viper . GetStringSlice ( keyNodeSet ) , descNodeSet ) fs . StringVarP ( & co . GitRemote , keyGitConfig , " " , viper . GetString ( keyGitConfig ) , descGitConfig ) fs . StringArrayVar ( & co . AwsOptions . PolicyAttachments , keyPolicyAttachments , co . AwsOptions . PolicyAttachments , descPolicyAttachments ) flagApplyAnnotations ( createCmd , " " , " " ) flagApplyAnnotations ( createCmd , " " , " " ) createCmd . SetUsageTemplate ( cli . UsageTemplate ) return createCmd } 
func RunCreate ( options * cli . CreateOptions ) error { var newCluster * cluster . Cluster if _ , ok := cli . ProfileMapIndexed [ options . Profile ] ; ok { newCluster = cli . ProfileMapIndexed [ options . Profile ] . ProfileFunc ( name ) } else { return fmt . Errorf ( " " , options . Profile ) } if options . KubeConfigLocalFile != " " { if newCluster . Annotations == nil { newCluster . Annotations = make ( map [ string ] string ) } newCluster . Annotations [ kubeconfig . ClusterAnnotationKubeconfigLocalFile ] = options . KubeConfigLocalFile } if len ( options . Set ) > 0 { if len ( parts ) == 1 { continue } providerConfig := newCluster . ProviderConfig ( ) err := cli . SwalkerWrite ( strings . Title ( parts [ 0 ] ) , providerConfig , parts [ 1 ] ) if err != nil { } newCluster . SetProviderConfig ( providerConfig ) } } if len ( options . MasterSet ) > 0 { if len ( parts ) == 1 { continue } for i , ms := range newCluster . MachineSets { isMaster := false for _ , role := range ms . Spec . Template . Spec . Roles { if role == v1alpha1 . MasterRole { isMaster = true break } } if ! isMaster { continue } pcStr := ms . Spec . Template . Spec . ProviderConfig providerConfig := & cluster . MachineProviderConfig { } json . Unmarshal ( [ ] byte ( pcStr ) , providerConfig ) err := cli . SwalkerWrite ( strings . Title ( parts [ 0 ] ) , providerConfig , parts [ 1 ] ) if err != nil { } if err != nil { logger . Critical ( " " , err ) return err } str := string ( bytes ) newCluster . MachineSets [ i ] . Spec . Template . Spec . ProviderConfig = str } } } if len ( options . NodeSet ) > 0 { if len ( parts ) == 1 { continue } for i , ms := range newCluster . MachineSets { isNode := false for _ , role := range ms . Spec . Template . Spec . Roles { if role == v1alpha1 . NodeRole { isNode = true break } } if ! isNode { continue } pcStr := ms . Spec . Template . Spec . ProviderConfig providerConfig := & cluster . MachineProviderConfig { } json . Unmarshal ( [ ] byte ( pcStr ) , providerConfig ) err := cli . SwalkerWrite ( strings . Title ( parts [ 0 ] ) , providerConfig , parts [ 1 ] ) if err != nil { } if err != nil { logger . Critical ( " " , err ) return err } str := string ( bytes ) newCluster . MachineSets [ i ] . Spec . Template . Spec . ProviderConfig = str } } } if len ( options . AwsOptions . PolicyAttachments ) > 0 { for i , ms := range newCluster . MachineSets { pcStr := ms . Spec . Template . Spec . ProviderConfig providerConfig := & cluster . MachineProviderConfig { } if err := json . Unmarshal ( [ ] byte ( pcStr ) , providerConfig ) ; err != nil { logger . Critical ( " " , err ) return err } if providerConfig . ServerPool != nil && providerConfig . ServerPool . InstanceProfile != nil && providerConfig . ServerPool . InstanceProfile . Role != nil { providerConfig . ServerPool . InstanceProfile . Role . PolicyAttachments = options . AwsOptions . PolicyAttachments } if err != nil { logger . Critical ( " " , err ) return err } str := string ( bytes ) newCluster . MachineSets [ i ] . Spec . Template . Spec . ProviderConfig = str } } if newCluster . ProviderConfig ( ) . Cloud == cluster . CloudGoogle && options . CloudID == " " { return fmt . Errorf ( " " ) } providerConfig := newCluster . ProviderConfig ( ) providerConfig . CloudId = options . CloudID newCluster . SetProviderConfig ( providerConfig ) if err != nil { return err } else if stateStore . Exists ( ) { return fmt . Errorf ( " " , name , options . StateStorePath + " " + name ) } if err != nil { return fmt . Errorf ( " " , err ) } logger . Always ( " " , options . StateStorePath , name , name ) return nil } 
func NewCentosCluster ( name string ) * cluster . Cluster { controlPlaneProviderConfig := & cluster . ControlPlaneProviderConfig { Cloud : cluster . CloudAmazon , Location : " " , SSH : & cluster . SSH { PublicKeyPath : " " , User : " " , } , KubernetesAPI : & cluster . KubernetesAPI { Port : " " , } , Network : & cluster . Network { Type : cluster . NetworkTypePublic , CIDR : " " , InternetGW : & cluster . InternetGW { } , } , Values : & cluster . Values { ItemMap : map [ string ] string { " " : kubeadm . GetRandomToken ( ) , } , } , } machineSetsProviderConfigs := [ ] * cluster . MachineProviderConfig { { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeMaster , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , MinCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , InstanceProfile : & cluster . IAMInstanceProfile { Name : fmt . Sprintf ( " " , name ) , Role : & cluster . IAMRole { Name : fmt . Sprintf ( " " , name ) , Policies : [ ] * cluster . IAMPolicy { { Name : " " , Document : `{ "Version": "2012-10-17", "Statement": [ { "Effect": "Allow", "Action": [ "ec2:*", "elasticloadbalancing:*", "ecr:GetAuthorizationToken", "ecr:BatchCheckLayerAvailability", "ecr:GetDownloadUrlForLayer", "ecr:GetRepositoryPolicy", "ecr:DescribeRepositories", "ecr:ListImages", "ecr:BatchGetImage", "autoscaling:DescribeAutoScalingGroups", "autoscaling:UpdateAutoScalingGroup" ], "Resource": "*" } ] }` , } , } , } , } , Subnets : [ ] * cluster . Subnet { { Name : fmt . Sprintf ( " " , name ) , CIDR : " " , Zone : " " , } , } , Firewalls : [ ] * cluster . Firewall { { Name : fmt . Sprintf ( " " , name , uuid . TimeOrderedUUID ( ) ) , IngressRules : [ ] * cluster . IngressRule { { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , } , } , } , } , } , { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeNode , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , MinCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , InstanceProfile : & cluster . IAMInstanceProfile { Name : fmt . Sprintf ( " " , name ) , Role : & cluster . IAMRole { Name : fmt . Sprintf ( " " , name ) , Policies : [ ] * cluster . IAMPolicy { { Name : " " , Document : `{ "Version": "2012-10-17", "Statement": [ { "Effect": "Allow", "Action": [ "ec2:Describe*", "ec2:AttachVolume", "ec2:DetachVolume", "ecr:GetAuthorizationToken", "ecr:BatchCheckLayerAvailability", "ecr:GetDownloadUrlForLayer", "ecr:GetRepositoryPolicy", "ecr:DescribeRepositories", "ecr:ListImages", "ecr:BatchGetImage", "autoscaling:DescribeAutoScalingGroups", "autoscaling:UpdateAutoScalingGroup" ], "Resource": "*" } ] }` , } , } , } , } , Subnets : [ ] * cluster . Subnet { { Name : fmt . Sprintf ( " " , name ) , CIDR : " " , Zone : " " , } , } , Firewalls : [ ] * cluster . Firewall { { Name : fmt . Sprintf ( " " , name , uuid . TimeOrderedUUID ( ) ) , IngressRules : [ ] * cluster . IngressRule { { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , } , } , } , } , } , } c := cluster . NewCluster ( name ) c . SetProviderConfig ( controlPlaneProviderConfig ) c . NewMachineSetsFromProviderConfigs ( machineSetsProviderConfigs ) return c } 
func ( m * Model ) Resources ( ) map [ int ] cloud . Resource { if len ( m . cachedResources ) > 0 { return m . cachedResources } r := make ( map [ int ] cloud . Resource ) i := 0 i ++ machineConfigs := m . known . MachineProviderConfigs ( ) for _ , machineConfig := range machineConfigs { serverPool := machineConfig . ServerPool i ++ } for _ , machineConfig := range machineConfigs { serverPool := machineConfig . ServerPool for _ , firewall := range serverPool . Firewalls { for _ , rule := range firewall . IngressRules { var src * resources . Sources if _ , _ , err := net . ParseCIDR ( rule . IngressSource ) ; err == nil { src = & resources . Sources { Addresses : [ ] string { rule . IngressSource } , } } else if ip := net . ParseIP ( rule . IngressSource ) ; ip != nil { src = & resources . Sources { Addresses : [ ] string { rule . IngressSource } , } } else { src = & resources . Sources { Tags : [ ] string { rule . IngressSource } , } } InboundRule := resources . InboundRule { Protocol : rule . IngressProtocol , PortRange : rule . IngressToPort , Source : src , } f . InboundRules = append ( f . InboundRules , InboundRule ) } for _ , rule := range firewall . EgressRules { var dest * resources . Destinations if _ , _ , err := net . ParseCIDR ( rule . EgressDestination ) ; err == nil { dest = & resources . Destinations { Addresses : [ ] string { rule . EgressDestination } , } } else if ip := net . ParseIP ( rule . EgressDestination ) ; ip != nil { dest = & resources . Destinations { Addresses : [ ] string { rule . EgressDestination } , } } else { dest = & resources . Destinations { Tags : [ ] string { rule . EgressDestination } , } } OutboundRule := resources . OutboundRule { Protocol : rule . EgressProtocol , PortRange : rule . EgressToPort , Destinations : dest , } f . OutboundRules = append ( f . OutboundRules , OutboundRule ) } r [ i ] = f i ++ } } m . cachedResources = r return m . cachedResources } 
func NewControllerUbuntuCluster ( name string ) * cluster . Cluster { controlPlaneProviderConfig := & cluster . ControlPlaneProviderConfig { Cloud : cluster . CloudDigitalOcean , Location : " " , SSH : & cluster . SSH { PublicKeyPath : " " , User : " " , } , KubernetesAPI : & cluster . KubernetesAPI { Port : " " , } , Values : & cluster . Values { ItemMap : map [ string ] string { " " : kubeadm . GetRandomToken ( ) , } , } , } machineSetsProviderConfigs := [ ] * cluster . MachineProviderConfig { { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeMaster , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , MinCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , Firewalls : [ ] * cluster . Firewall { { Name : fmt . Sprintf ( " " , name ) , IngressRules : [ ] * cluster . IngressRule { { IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : fmt . Sprintf ( " " , name ) , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : fmt . Sprintf ( " " , name ) , IngressProtocol : " " , } , } , EgressRules : [ ] * cluster . EgressRule { { EgressToPort : " " , deployment := & appsv1beta2 . Deployment { ObjectMeta : metav1 . ObjectMeta { Name : " " , } , Spec : appsv1beta2 . DeploymentSpec { Replicas : ptrconvenient . Int32Ptr ( 1 ) , Selector : & metav1 . LabelSelector { MatchLabels : map [ string ] string { " " : " " , } , } , Template : apiv1 . PodTemplateSpec { ObjectMeta : metav1 . ObjectMeta { Labels : map [ string ] string { " " : " " , } , } , Spec : apiv1 . PodSpec { Containers : [ ] apiv1 . Container { { Name : " " , Image : " " , c := cluster . NewCluster ( name ) c . SetProviderConfig ( controlPlaneProviderConfig ) c . NewMachineSetsFromProviderConfigs ( machineSetsProviderConfigs ) cpms . Spec . Replicas = ptrconvenient . Int32Ptr ( 3 ) c . MachineSets [ 1 ] = cpms secret := & apiv1 . Secret { ObjectMeta : metav1 . ObjectMeta { Name : " " , Namespace : " " , } , StringData : map [ string ] string { " " : string ( os . Getenv ( " " ) ) } , } c . APITokenSecret = secret return c } 
func ReadFromResource ( r string ) ( string , error ) { env := os . Getenv ( " " ) if devMode != " " { logger . Info ( " " , r ) return readFromFS ( r ) } switch { logger . Info ( " " , gitHubUrl ) url , err := url . ParseRequestURI ( gitHubUrl ) if err != nil { return " " , err } return readFromHTTP ( url ) logger . Info ( " " , url ) if err != nil { return " " , err } return readFromHTTP ( url ) return readFromFS ( r ) } } 
func SwalkerWrite ( exp string , obj interface { } , value string ) error { v , err := swalker . Read ( exp , obj ) if err != nil { return err } rv := reflect . ValueOf ( v ) switch rv . Kind ( ) { case reflect . Int : i , err := strconv . ParseInt ( value , 10 , 0 ) if err != nil { return err } return swalker . Write ( exp , obj , int ( i ) ) case reflect . Int8 : i , err := strconv . ParseInt ( value , 10 , 8 ) if err != nil { return err } return swalker . Write ( exp , obj , int8 ( i ) ) case reflect . Int16 : i , err := strconv . ParseInt ( value , 10 , 16 ) if err != nil { return err } return swalker . Write ( exp , obj , int16 ( i ) ) case reflect . Int32 : i , err := strconv . ParseInt ( value , 10 , 32 ) if err != nil { return err } return swalker . Write ( exp , obj , int32 ( i ) ) case reflect . Int64 : i , err := strconv . ParseInt ( value , 10 , 64 ) if err != nil { return err } return swalker . Write ( exp , obj , i ) case reflect . Uint : i , err := strconv . ParseUint ( value , 10 , 0 ) if err != nil { return err } return swalker . Write ( exp , obj , uint ( i ) ) case reflect . Uint8 : i , err := strconv . ParseUint ( value , 10 , 8 ) if err != nil { return err } return swalker . Write ( exp , obj , uint8 ( i ) ) case reflect . Uint16 : i , err := strconv . ParseUint ( value , 10 , 16 ) if err != nil { return err } return swalker . Write ( exp , obj , uint16 ( i ) ) case reflect . Uint32 : i , err := strconv . ParseUint ( value , 10 , 32 ) if err != nil { return err } return swalker . Write ( exp , obj , uint32 ( i ) ) case reflect . Uint64 : i , err := strconv . ParseUint ( value , 10 , 64 ) if err != nil { return err } return swalker . Write ( exp , obj , i ) case reflect . Bool : b , err := strconv . ParseBool ( value ) if err != nil { return err } return swalker . Write ( exp , obj , b ) } return swalker . Write ( exp , obj , value ) } 
func NewCentosCluster ( name string ) * cluster . Cluster { controlPlaneProviderConfig := & cluster . ControlPlaneProviderConfig { Cloud : cluster . CloudDigitalOcean , Location : " " , SSH : & cluster . SSH { PublicKeyPath : " " , User : " " , } , KubernetesAPI : & cluster . KubernetesAPI { Port : " " , } , Values : & cluster . Values { ItemMap : map [ string ] string { " " : kubeadm . GetRandomToken ( ) , } , } , } machineSetsProviderConfigs := [ ] * cluster . MachineProviderConfig { { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeMaster , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , Firewalls : [ ] * cluster . Firewall { { Name : fmt . Sprintf ( " " , name ) , IngressRules : [ ] * cluster . IngressRule { { IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : fmt . Sprintf ( " " , name ) , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : fmt . Sprintf ( " " , name ) , IngressProtocol : " " , } , } , EgressRules : [ ] * cluster . EgressRule { { EgressToPort : " " , c := cluster . NewCluster ( name ) c . SetProviderConfig ( controlPlaneProviderConfig ) c . NewMachineSetsFromProviderConfigs ( machineSetsProviderConfigs ) secret := & apiv1 . Secret { ObjectMeta : metav1 . ObjectMeta { Name : " " , Namespace : " " , } , StringData : map [ string ] string { " " : string ( os . Getenv ( " " ) ) } , } c . APITokenSecret = secret return c } 
func NewSdk ( ) ( * Sdk , error ) { sdk := & Sdk { } apiToken := getToken ( ) if apiToken == " " { return nil , fmt . Errorf ( " " ) } sdk . Client = packngo . NewClient ( " " , apiToken , nil ) return sdk , nil } 
func NewUbuntuCluster ( name string ) * cluster . Cluster { controlPlaneProviderConfig := & cluster . ControlPlaneProviderConfig { Cloud : cluster . CloudAzure , Location : " " , SSH : & cluster . SSH { PublicKeyPath : " " , User : " " , } , KubernetesAPI : & cluster . KubernetesAPI { Port : " " , } , Values : & cluster . Values { ItemMap : map [ string ] string { " " : kubeadm . GetRandomToken ( ) , } , } , } machineSetsProviderConfigs := [ ] * cluster . MachineProviderConfig { { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeMaster , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { } , Firewalls : [ ] * cluster . Firewall { { Name : fmt . Sprintf ( " " , name ) , IngressRules : [ ] * cluster . IngressRule { { IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , } , EgressRules : [ ] * cluster . EgressRule { { EgressToPort : " " , c := cluster . NewCluster ( name ) c . SetProviderConfig ( controlPlaneProviderConfig ) c . NewMachineSetsFromProviderConfigs ( machineSetsProviderConfigs ) return c } 
func ( c * Cluster ) ProviderConfig ( ) * ControlPlaneProviderConfig { providerConfig := & ControlPlaneProviderConfig { } err := json . Unmarshal ( [ ] byte ( raw ) , providerConfig ) if err != nil { logger . Critical ( " " , err ) } return providerConfig } 
func ( c * Cluster ) SetProviderConfig ( config * ControlPlaneProviderConfig ) error { bytes , err := json . Marshal ( config ) if err != nil { logger . Critical ( " " , err ) return err } str := string ( bytes ) c . ClusterAPI . Spec . ProviderConfig = str return nil } 
func ( c * Cluster ) MachineProviderConfigs ( ) [ ] * MachineProviderConfig { var providerConfigs [ ] * MachineProviderConfig for _ , machineSet := range c . MachineSets { raw := machineSet . Spec . Template . Spec . ProviderConfig providerConfig := & MachineProviderConfig { } err := json . Unmarshal ( [ ] byte ( raw ) , providerConfig ) if err != nil { logger . Critical ( " " , err ) } providerConfigs = append ( providerConfigs , providerConfig ) } return providerConfigs } 
func ( c * Cluster ) SetMachineProviderConfigs ( providerConfigs [ ] * MachineProviderConfig ) { for _ , providerConfig := range providerConfigs { name := providerConfig . ServerPool . Name found := false for _ , machineSet := range c . MachineSets { if machineSet . Name == name { if err != nil { logger . Critical ( " " ) continue } str := string ( bytes ) machineSet . Spec . Template . Spec . ProviderConfig = str found = true } } } } } 
func NewCluster ( name string ) * Cluster { return & Cluster { Name : name , ClusterAPI : & clusterv1 . Cluster { ObjectMeta : metav1 . ObjectMeta { Name : name , } , Spec : clusterv1 . ClusterSpec { } , } , ControlPlane : & clusterv1 . MachineSet { } , } } 
func DeployControllerCmd ( ) * cobra . Command { var dco = & cli . DeployControllerOptions { } var deployControllerCmd = & cobra . Command { Use : " " , Short : " " , Long : `Use this command to deploy a controller for a given cluster. As long as a controller is defined, this will create the deployment and the namespace.` , Run : func ( cmd * cobra . Command , args [ ] string ) { switch len ( args ) { case 0 : dco . Name = viper . GetString ( keyKubicornName ) case 1 : dco . Name = args [ 0 ] default : logger . Critical ( " " ) os . Exit ( 1 ) } if err := runDeployController ( dco ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := deployControllerCmd . Flags ( ) bindCommonStateStoreFlags ( & dco . StateStoreOptions , fs ) bindCommonAwsFlags ( & dco . AwsOptions , fs ) fs . StringVar ( & dco . GitRemote , keyGitConfig , viper . GetString ( keyGitConfig ) , descGitConfig ) return deployControllerCmd } 
func NewRetrier ( retries , sleepSeconds int , retryable Retryable ) * Retrier { return & Retrier { retries : retries , sleepSeconds : sleepSeconds , retryable : retryable , } } 
func ( r * Retrier ) RunRetry ( ) error { go sigHandler . Register ( ) finish := make ( chan bool , 1 ) go func ( ) { select { case <- finish : return case <- time . After ( 10 * time . Second ) : return default : for { if sigHandler . GetState ( ) != 0 { logger . Critical ( " " ) os . Exit ( 1 ) } } } } ( ) for i := 0 ; i < r . retries ; i ++ { err := r . retryable . Try ( ) if err != nil { logger . Info ( " " , err ) time . Sleep ( time . Duration ( r . sleepSeconds ) * time . Second ) continue } finish <- true return nil } finish <- true return fmt . Errorf ( " " , r . retries , r . sleepSeconds ) } 
func MustGenerateRandomBytes ( length int ) [ ] byte { res , err := GenerateRandomBytes ( length ) if err != nil { panic ( " " ) } return res } 
func GenerateRandomBytes ( length int ) ( [ ] byte , error ) { b := make ( [ ] byte , length ) _ , err := rand . Read ( b ) return b , err } 
func GenerateRandomInt ( min , max int ) int { return int ( GenerateRandomInt64 ( int64 ( min ) , int64 ( max ) ) ) } 
func GenerateRandomInt64 ( min , max int64 ) int64 { upper := max - min nBig , err := rand . Int ( rand . Reader , big . NewInt ( upper ) ) if err != nil { panic ( err ) } return nBig . Int64 ( ) + min } 
func ExplainCmd ( ) * cobra . Command { var exo = & cli . ExplainOptions { } var cmd = & cobra . Command { Use : " " , Short : " " , Long : `Output expected and actual state of the given cluster` , Run : func ( cmd * cobra . Command , args [ ] string ) { switch len ( args ) { case 0 : exo . Name = viper . GetString ( keyKubicornName ) case 1 : exo . Name = args [ 0 ] default : logger . Critical ( " " ) os . Exit ( 1 ) } if err := runExplain ( exo ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := cmd . Flags ( ) bindCommonStateStoreFlags ( & exo . StateStoreOptions , fs ) bindCommonAwsFlags ( & exo . AwsOptions , fs ) fs . StringVarP ( & exo . Output , keyOutput , " " , viper . GetString ( keyOutput ) , descOutput ) fs . StringVar ( & exo . GitRemote , keyGitConfig , viper . GetString ( keyGitConfig ) , descGitConfig ) return cmd } 
func TimeOrderedUUID ( ) string { unixTime := uint32 ( time . Now ( ) . UTC ( ) . Unix ( ) ) return fmt . Sprintf ( " " , unixTime , rand . MustGenerateRandomBytes ( 2 ) , rand . MustGenerateRandomBytes ( 2 ) , rand . MustGenerateRandomBytes ( 2 ) , rand . MustGenerateRandomBytes ( 2 ) , rand . MustGenerateRandomBytes ( 4 ) ) } 
func GetConfigCmd ( ) * cobra . Command { var cro = & cli . GetConfigOptions { } var getConfigCmd = & cobra . Command { Use : " " , Short : " " , Long : `Use this command to pull a kubeconfig file from a cluster so you can use kubectl. This command will attempt to find a cluster, and append a local kubeconfig file with a kubeconfig ` , Run : func ( cmd * cobra . Command , args [ ] string ) { switch len ( args ) { case 0 : cro . Name = viper . GetString ( keyKubicornName ) case 1 : cro . Name = args [ 0 ] default : logger . Critical ( " " ) os . Exit ( 1 ) } if err := runGetConfig ( cro ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := getConfigCmd . Flags ( ) bindCommonStateStoreFlags ( & cro . StateStoreOptions , fs ) bindCommonAwsFlags ( & cro . AwsOptions , fs ) fs . StringVar ( & cro . GitRemote , keyGitConfig , viper . GetString ( keyGitConfig ) , descGitConfig ) return getConfigCmd } 
func PromptCmd ( ) * cobra . Command { return & cobra . Command { Use : " " , Short : " " , Long : `Use this command to use the Kubicron API via a shell prompt. This command will open a prompt using go-prompt (with auto-completion) to allow you to run commands interactively from the shell. Currently this doesn't work on Windows systems.` , Run : func ( cmd * cobra . Command , args [ ] string ) { logger . Critical ( " " ) os . Exit ( 1 ) } , } } 
func RunAnnotated ( task Task , description string , symbol string , options ... interface { } ) error { doneCh := make ( chan bool ) errCh := make ( chan error ) l := logger . Log t := DefaultTicker for _ , o := range options { if value , ok := o . ( logger . Logger ) ; ok { l = value } else if value , ok := o . ( * time . Ticker ) ; ok { t = value } } go func ( ) { errCh <- task ( ) } ( ) l ( description ) logActivity ( symbol , l , t , doneCh ) err := <- errCh doneCh <- true return err } 
func logActivity ( symbol string , logger logger . Logger , ticker * time . Ticker , quitCh <- chan bool ) { go func ( ) { for { select { case <- ticker . C : logger ( symbol ) case <- quitCh : ticker . Stop ( ) return } } } ( ) } 
func ListCmd ( ) * cobra . Command { var lo = & cli . ListOptions { } var cmd = & cobra . Command { Use : " " , Short : " " , Long : `List the states available in the _state directory` , Run : func ( cmd * cobra . Command , args [ ] string ) { if err := runList ( lo ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := cmd . Flags ( ) bindCommonStateStoreFlags ( & lo . StateStoreOptions , fs ) bindCommonAwsFlags ( & lo . AwsOptions , fs ) fs . BoolVarP ( & noHeaders , keyNoHeaders , " " , viper . GetBool ( keyNoHeaders ) , desNoHeaders ) return cmd } 
func NewUbuntuCluster ( name string ) * cluster . Cluster { controlPlaneProviderConfig := & cluster . ControlPlaneProviderConfig { Cloud : cluster . CloudPacket , Project : & cluster . Project { Name : fmt . Sprintf ( " " , name ) , } , Location : " " , SSH : & cluster . SSH { PublicKeyPath : " " , User : " " , } , KubernetesAPI : & cluster . KubernetesAPI { Port : " " , } , Values : & cluster . Values { ItemMap : map [ string ] string { " " : kubeadm . GetRandomToken ( ) , } , } , } machineSetsProviderConfigs := [ ] * cluster . MachineProviderConfig { { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeMaster , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , MinCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , } , } , { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeNode , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , MinCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , } , } , } c := cluster . NewCluster ( name ) c . SetProviderConfig ( controlPlaneProviderConfig ) c . NewMachineSetsFromProviderConfigs ( machineSetsProviderConfigs ) return c } 
func NewControllerUbuntuCluster ( name string ) * cluster . Cluster { controlPlaneProviderConfig := & cluster . ControlPlaneProviderConfig { Cloud : cluster . CloudAmazon , Location : " " , SSH : & cluster . SSH { PublicKeyPath : " " , User : " " , } , KubernetesAPI : & cluster . KubernetesAPI { Port : " " , } , Network : & cluster . Network { Type : cluster . NetworkTypePublic , CIDR : " " , InternetGW : & cluster . InternetGW { } , } , Values : & cluster . Values { ItemMap : map [ string ] string { " " : kubeadm . GetRandomToken ( ) , } , } , } machineSetsProviderConfigs := [ ] * cluster . MachineProviderConfig { { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeMaster , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , MinCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , InstanceProfile : & cluster . IAMInstanceProfile { Name : fmt . Sprintf ( " " , name ) , Role : & cluster . IAMRole { Name : fmt . Sprintf ( " " , name ) , Policies : [ ] * cluster . IAMPolicy { { Name : " " , Document : `{ "Version": "2012-10-17", "Statement": [ { "Effect": "Allow", "Action": [ "ec2:*", "elasticloadbalancing:*", "ecr:GetAuthorizationToken", "ecr:BatchCheckLayerAvailability", "ecr:GetDownloadUrlForLayer", "ecr:GetRepositoryPolicy", "ecr:DescribeRepositories", "ecr:ListImages", "ecr:BatchGetImage", "autoscaling:DescribeAutoScalingGroups", "autoscaling:UpdateAutoScalingGroup" ], "Resource": "*" } ] }` , } , } , } , } , Subnets : [ ] * cluster . Subnet { { Name : fmt . Sprintf ( " " , name ) , CIDR : " " , Zone : " " , } , } , AwsConfiguration : & cluster . AwsConfiguration { } , Firewalls : [ ] * cluster . Firewall { { Name : fmt . Sprintf ( " " , name , uuid . TimeOrderedUUID ( ) ) , IngressRules : [ ] * cluster . IngressRule { { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , } , } , } , } , } , { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeNode , Name : fmt . Sprintf ( " " , name ) , MaxCount : 1 , MinCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , InstanceProfile : & cluster . IAMInstanceProfile { Name : fmt . Sprintf ( " " , name ) , Role : & cluster . IAMRole { Name : fmt . Sprintf ( " " , name ) , Policies : [ ] * cluster . IAMPolicy { { Name : " " , Document : `{ "Version": "2012-10-17", "Statement": [ { "Effect": "Allow", "Action": [ "ec2:Describe*", "ec2:AttachVolume", "ec2:DetachVolume", "ecr:GetAuthorizationToken", "ecr:BatchCheckLayerAvailability", "ecr:GetDownloadUrlForLayer", "ecr:GetRepositoryPolicy", "ecr:DescribeRepositories", "ecr:ListImages", "ecr:BatchGetImage", "autoscaling:DescribeAutoScalingGroups", "autoscaling:UpdateAutoScalingGroup" ], "Resource": "*" } ] }` , } , } , } , } , Subnets : [ ] * cluster . Subnet { { Name : fmt . Sprintf ( " " , name ) , CIDR : " " , Zone : " " , } , } , AwsConfiguration : & cluster . AwsConfiguration { } , Firewalls : [ ] * cluster . Firewall { { Name : fmt . Sprintf ( " " , name , uuid . TimeOrderedUUID ( ) ) , IngressRules : [ ] * cluster . IngressRule { { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , } , } , } , } , } , } deployment := & appsv1beta2 . Deployment { ObjectMeta : metav1 . ObjectMeta { Name : " " , } , Spec : appsv1beta2 . DeploymentSpec { Replicas : ptrconvenient . Int32Ptr ( 1 ) , Selector : & metav1 . LabelSelector { MatchLabels : map [ string ] string { " " : " " , } , } , Template : apiv1 . PodTemplateSpec { ObjectMeta : metav1 . ObjectMeta { Labels : map [ string ] string { " " : " " , } , } , Spec : apiv1 . PodSpec { Containers : [ ] apiv1 . Container { { Name : " " , Image : " " , c := cluster . NewCluster ( name ) c . SetProviderConfig ( controlPlaneProviderConfig ) c . NewMachineSetsFromProviderConfigs ( machineSetsProviderConfigs ) cpms . Spec . Replicas = ptrconvenient . Int32Ptr ( 3 ) c . MachineSets [ 1 ] = cpms return c } 
func NewSdk ( region string ) ( * Sdk , error ) { sdk := & Sdk { } authOpts , err := openstack . AuthOptionsFromEnv ( ) if err != nil { return nil , err } client , err := openstack . AuthenticatedClient ( authOpts ) if err != nil { return nil , err } } } } return sdk , nil } 
func EditCmd ( ) * cobra . Command { var eo = & cli . EditOptions { } var editCmd = & cobra . Command { Use : " " , Short : " " , Long : `Use this command to edit a state.` , Run : func ( cmd * cobra . Command , args [ ] string ) { switch len ( args ) { case 0 : eo . Name = viper . GetString ( keyKubicornName ) case 1 : eo . Name = args [ 0 ] default : logger . Critical ( " " ) os . Exit ( 1 ) } if err := runEdit ( eo ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := editCmd . Flags ( ) bindCommonStateStoreFlags ( & eo . StateStoreOptions , fs ) bindCommonAwsFlags ( & eo . AwsOptions , fs ) fs . StringVarP ( & eo . Editor , keyEditor , " " , viper . GetString ( keyEditor ) , descEditor ) fs . StringVar ( & eo . GitRemote , keyGitConfig , viper . GetString ( keyGitConfig ) , descGitConfig ) return editCmd } 
func ( k * Keyring ) RemoveKey ( key ssh . PublicKey ) error { return k . Agent . Remove ( key ) } 
func ( k * Keyring ) RemoveKeyUsingFile ( pubkey string ) error { p , err := ioutil . ReadFile ( pubkey ) if err != nil { return err } key , _ , _ , _ , _ := ssh . ParseAuthorizedKey ( p ) if err != nil { return err } return k . RemoveKey ( key ) } 
func ( r * Firewall ) Actual ( immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) newResource := defaultFirewallStruct ( ) if err != nil { return nil , nil , fmt . Errorf ( " " ) } for _ , firewall := range firewalls { if firewall . Name == r . Name { if err != nil { return nil , nil , fmt . Errorf ( " " , err ) } if err := json . Unmarshal ( firewallBytes , newResource ) ; err != nil { return nil , nil , fmt . Errorf ( " " , err ) } } } for i := 0 ; i < len ( newResource . InboundRules ) ; i ++ { if newResource . InboundRules [ i ] . PortRange == " " { newResource . InboundRules [ i ] . PortRange = " " } } } } newCluster := r . immutableRender ( newResource , immutable ) return newCluster , newResource , nil } 
func ( r * Firewall ) Expected ( immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) newResource := & Firewall { Shared : Shared { Name : r . Name , CloudID : r . ServerPool . Identifier , } , InboundRules : r . InboundRules , OutboundRules : r . OutboundRules , DropletIDs : r . DropletIDs , Tags : r . Tags , FirewallID : r . FirewallID , Status : r . Status , Created : r . Created , } return newCluster , newResource , nil } 
func ( r * Firewall ) Apply ( actual , expected cloud . Resource , immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) expectedResource := expected . ( * Firewall ) actualResource := actual . ( * Firewall ) isEqual , err := compare . IsEqual ( actualResource , expectedResource ) if err != nil { return nil , nil , err } if isEqual { return immutable , expected , nil } firewallRequest := godo . FirewallRequest { Name : expectedResource . Name , InboundRules : convertInRuleType ( expectedResource . InboundRules ) , OutboundRules : convertOutRuleType ( expectedResource . OutboundRules ) , DropletIDs : expectedResource . DropletIDs , Tags : expectedResource . Tags , } for _ , machineProviderConfig := range machineProviderConfigs { for i := 0 ; i <= TagsGetAttempts ; i ++ { active := true droplets , _ , err := Sdk . Client . Droplets . ListByTag ( context . TODO ( ) , machineProviderConfig . ServerPool . Name , & godo . ListOptions { } ) if err != nil { logger . Debug ( " " , err ) time . Sleep ( time . Duration ( TagsGetTimeout ) * time . Second ) continue } if len ( droplets ) == 0 { continue } for _ , d := range droplets { if d . Status != " " { active = false break } } if ! active { logger . Debug ( " " ) time . Sleep ( time . Duration ( TagsGetTimeout ) * time . Second ) continue } break } } firewall , _ , err := Sdk . Client . Firewalls . Create ( context . TODO ( ) , & firewallRequest ) if err != nil { return nil , nil , fmt . Errorf ( " " , err ) } logger . Success ( " " , firewall . ID ) newResource := & Firewall { Shared : Shared { CloudID : firewall . ID , Name : r . Name , Tags : r . Tags , } , DropletIDs : r . DropletIDs , FirewallID : firewall . ID , InboundRules : r . InboundRules , OutboundRules : r . OutboundRules , Created : r . Created , } newCluster := r . immutableRender ( newResource , immutable ) return newCluster , newResource , nil } 
func ( r * Firewall ) Delete ( actual cloud . Resource , immutable * cluster . Cluster ) ( * cluster . Cluster , cloud . Resource , error ) { logger . Debug ( " " ) deleteResource , ok := actual . ( * Firewall ) if ! ok { return nil , nil , fmt . Errorf ( " " ) } if deleteResource . Name == " " { return immutable , nil , nil return nil , nil , fmt . Errorf ( " " , deleteResource . Name ) } if _ , err := Sdk . Client . Firewalls . Delete ( context . TODO ( ) , deleteResource . FirewallID ) ; err != nil { return nil , nil , fmt . Errorf ( " " , deleteResource . Name , err ) } logger . Success ( " " , deleteResource . FirewallID ) newResource := & Firewall { Shared : Shared { Name : r . Name , Tags : r . Tags , } , InboundRules : r . InboundRules , OutboundRules : r . OutboundRules , Created : r . Created , } newCluster := r . immutableRender ( newResource , immutable ) return newCluster , newResource , nil } 
func DeleteCmd ( ) * cobra . Command { var do = & cli . DeleteOptions { } var deleteCmd = & cobra . Command { Use : " " , Short : " " , Long : `Use this command to delete cloud resources. This command will attempt to build the resource graph based on an API model. Once the graph is built, the delete will attempt to delete the resources from the cloud. After the delete is complete, the state store will be left in tact and could potentially be applied later. To delete the resource AND the API model in the state store, use --purge.` , Run : func ( cmd * cobra . Command , args [ ] string ) { switch len ( args ) { case 0 : do . Name = viper . GetString ( keyKubicornName ) case 1 : do . Name = args [ 0 ] default : logger . Critical ( " " ) os . Exit ( 1 ) } if err := runDelete ( do ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := deleteCmd . Flags ( ) bindCommonStateStoreFlags ( & do . StateStoreOptions , fs ) bindCommonAwsFlags ( & do . AwsOptions , fs ) fs . StringVar ( & do . AwsProfile , keyAwsProfile , viper . GetString ( keyAwsProfile ) , descAwsProfile ) fs . StringVar ( & do . GitRemote , keyGitConfig , viper . GetString ( keyGitConfig ) , descGitConfig ) fs . BoolVarP ( & do . Purge , keyPurge , " " , viper . GetBool ( keyPurge ) , descPurge ) return deleteCmd } 
func ( options Options ) NewStateStore ( ) ( state . ClusterStorer , error ) { var stateStore state . ClusterStorer switch options . StateStore { case " " : logger . Info ( " " ) stateStore = fs . NewFileSystemStore ( & fs . FileSystemStoreOptions { BasePath : options . StateStorePath , ClusterName : options . Name , } ) case " " : logger . Info ( " " ) stateStore = crd . NewCRDStore ( & crd . CRDStoreOptions { BasePath : options . StateStorePath , ClusterName : options . Name , } ) case " " : logger . Info ( " " ) if options . GitRemote == " " { return nil , errors . New ( " " ) } user , _ := gg . Global ( " " ) email , _ := gg . Email ( ) stateStore = git . NewJSONGitStore ( & git . JSONGitStoreOptions { BasePath : options . StateStorePath , ClusterName : options . Name , CommitConfig : & git . JSONGitCommitConfig { Name : user , Email : email , Remote : options . GitRemote , } , } ) case " " : logger . Info ( " " ) stateStore = jsonfs . NewJSONFileSystemStore ( & jsonfs . JSONFileSystemStoreOptions { BasePath : options . StateStorePath , ClusterName : options . Name , } ) case " " : logger . Info ( " " ) client , err := minio . New ( options . BucketEndpointURL , options . S3AccessKey , options . S3SecretKey , options . BucketSSL ) if err != nil { return nil , err } stateStore = s3 . NewJSONFS3Store ( & s3 . JSONS3StoreOptions { BasePath : options . StateStorePath , ClusterName : options . Name , Client : client , BucketOptions : & s3 . S3BucketOptions { EndpointURL : options . BucketEndpointURL , BucketName : options . BucketName , } , } ) default : return nil , fmt . Errorf ( " " , options . Name , options . StateStore ) } return stateStore , nil } 
func ( git * JSONGitStore ) Commit ( c * cluster . Cluster ) error { if c == nil { return fmt . Errorf ( " " ) } bytes , err := json . Marshal ( c ) if err != nil { return err } if err != nil { return err } _ , err = r . Commits ( ) if err != nil { return err } return nil } 
func ApplyCmd ( ) * cobra . Command { var ao = & cli . ApplyOptions { } var applyCmd = & cobra . Command { Use : " " , Short : " " , Long : `Use this command to apply an API model in a cloud. This command will attempt to find an API model in a defined state store, and then apply any changes needed directly to a cloud. The apply will run once, and ultimately time out if something goes wrong.` , Run : func ( cmd * cobra . Command , args [ ] string ) { switch len ( args ) { case 0 : ao . Name = viper . GetString ( keyKubicornName ) case 1 : ao . Name = args [ 0 ] default : logger . Critical ( " " ) os . Exit ( 1 ) } if err := runApply ( ao ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } fs := applyCmd . Flags ( ) bindCommonStateStoreFlags ( & ao . StateStoreOptions , fs ) bindCommonAwsFlags ( & ao . AwsOptions , fs ) fs . StringArrayVarP ( & ao . Set , keyKubicornSet , " " , viper . GetStringSlice ( keyKubicornSet ) , descSet ) fs . StringVar ( & ao . AwsProfile , keyAwsProfile , viper . GetString ( keyAwsProfile ) , descAwsProfile ) fs . StringVar ( & ao . GitRemote , keyGitConfig , viper . GetString ( keyGitConfig ) , descGitConfig ) return applyCmd } 
func getGitHubUrl ( bootstrapScript string ) string { } 
func PromptCmd ( ) * cobra . Command { var promptCmd = & cobra . Command { Use : " " , Short : " " , Long : `Use this command to use the Kubicron API via a shell prompt. This command will open a prompt using go-prompt (with auto-completion) to allow you to run commands interactively from the shell. Currently this doesn't work on Windows systems` , Run : func ( cmd * cobra . Command , args [ ] string ) { if len ( args ) > 0 { logger . Critical ( " " ) os . Exit ( 1 ) } if err := runPrompt ( ) ; err != nil { logger . Critical ( err . Error ( ) ) os . Exit ( 1 ) } } , } initializePrompt ( ) return promptCmd } 
func ExpandPath ( path string ) string { switch path { case " " : wd , err := os . Getwd ( ) if err != nil { logger . Critical ( " " , err ) return " " } path = wd case " " : homeVar := os . Getenv ( " " ) if homeVar == " " { homeUser , err := user . Current ( ) if err != nil { logger . Critical ( " " , err ) return " " } path = homeUser . HomeDir } } return path } 
func CompletionCmd ( ) * cobra . Command { return & cobra . Command { Use : " " , Short : " " , Long : `completion is used to output completion code for bash and zsh shells. Before using completion features, you have to source completion code from your .profile. This is done by adding following line to one of above files: source <(kubicorn completion SHELL) Valid arguments for SHELL are: "bash" and "zsh". Notes: 1) zsh completions requires zsh 5.2 or newer. 2) macOS users have to install bash-completion framework to utilize completion features. This can be done using homebrew: brew install bash-completion Once installed, you must load bash_completion by adding following line to your .profile or .bashrc/.zshrc: source $(brew --prefix)/etc/bash_completion` , RunE : func ( cmd * cobra . Command , args [ ] string ) error { if logger . Fabulous { cmd . SetOutput ( logger . FabulousWriter ) } if viper . GetString ( keyTrueColor ) != " " { cmd . SetOutput ( logger . FabulousWriter ) } switch len ( args ) { case 0 : return fmt . Errorf ( " " ) default : switch args [ 0 ] { case " " : return runBashGeneration ( ) case " " : return runZshGeneration ( ) default : return fmt . Errorf ( " " ) } } } , } } 
func AdoptCmd ( ) * cobra . Command { return & cobra . Command { Use : " " , Short : " " , Long : `Use this command to audit and adopt a Kubernetes cluster into a Kubicorn state store. This command will query cloud resources and attempt to build a representation of the cluster in the Kubicorn API model. Once the cluster has been adopted, a user can manage and scale their Kubernetes cluster with Kubicorn.` , Run : func ( cmd * cobra . Command , args [ ] string ) { fmt . Println ( " " ) } , } } 
func StrEnvDef ( env string , def string ) string { val := os . Getenv ( env ) if val == " " { return def } return val } 
func IntEnvDef ( env string , def int ) int { val := os . Getenv ( env ) if val == " " { return def } ival , err := strconv . Atoi ( val ) if err != nil { return def } return ival } 
func BoolEnvDef ( env string , def bool ) bool { val := os . Getenv ( env ) if val == " " { return def } b , err := strconv . ParseBool ( val ) if err != nil { return def } return b } 
func readFromFS ( sourcePath string ) ( string , error ) { if homeDir == " " { return " " , fmt . Errorf ( " " ) } sourcePath = filepath . Join ( homeDir , sourcePath [ 1 : ] ) } bytes , err := ioutil . ReadFile ( sourcePath ) if err != nil { return " " , err } return string ( bytes ) , nil } 
func VersionCmd ( ) * cobra . Command { return & cobra . Command { Use : " " , Short : " " , Long : `Use this command to check the version of Kubicorn. This command will return the version of the Kubicorn binary.` , Run : func ( cmd * cobra . Command , args [ ] string ) { fmt . Printf ( " \n " , version . GetVersionJSON ( ) ) } , } } 
func NewSignalHandler ( timeoutSeconds int ) * Handler { signals := make ( chan os . Signal ) signal . Notify ( signals , os . Interrupt , os . Kill ) return & Handler { timeoutSeconds : timeoutSeconds , signals : signals , signalReceived : 0 , } } 
func ( h * Handler ) Register ( ) { go func ( ) { h . timer = time . NewTimer ( time . Duration ( h . timeoutSeconds ) * time . Second ) for { select { case s := <- h . signals : switch { case s == os . Interrupt : if h . signalReceived == 0 { h . signalReceived = 1 logger . Debug ( " " ) continue } h . signalReceived = signalTerminate debug . PrintStack ( ) os . Exit ( 130 ) break case s == syscall . SIGQUIT : h . signalReceived = signalAbort break case s == syscall . SIGTERM : h . signalReceived = signalTerminate os . Exit ( 3 ) break } case <- h . timer . C : os . Exit ( 4 ) break } } } ( ) } 
func NewSdk ( ) ( * Sdk , error ) { sdk := & Sdk { } client , err := google . DefaultClient ( context . TODO ( ) , compute . ComputeScope ) if err != nil { return nil , err } service , err := compute . New ( client ) if err != nil { return nil , err } sdk . Service = service return sdk , nil } 
func NewUbuntuCluster ( name string ) * cluster . Cluster { var ( masterName = fmt . Sprintf ( " " , name ) nodeName = fmt . Sprintf ( " " , name ) ) controlPlaneProviderConfig := & cluster . ControlPlaneProviderConfig { Cloud : cluster . CloudECS , Location : " " , SSH : & cluster . SSH { PublicKeyPath : " " , User : " " , } , Values : & cluster . Values { ItemMap : map [ string ] string { " " : kubeadm . GetRandomToken ( ) , } , } , KubernetesAPI : & cluster . KubernetesAPI { Port : " " , } , Network : & cluster . Network { Type : cluster . NetworkTypePublic , InternetGW : & cluster . InternetGW { Name : " " , } , } , } machineSetsProviderConfigs := [ ] * cluster . MachineProviderConfig { { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeMaster , Name : masterName , MaxCount : 1 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , Subnets : [ ] * cluster . Subnet { { Name : " " , CIDR : " " , } , } , Firewalls : [ ] * cluster . Firewall { { Name : masterName , IngressRules : [ ] * cluster . IngressRule { { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressSource : " " , } , } , } , } , } , } , { ServerPool : & cluster . ServerPool { Type : cluster . ServerPoolTypeNode , Name : nodeName , MaxCount : 2 , Image : " " , Size : " " , BootstrapScripts : [ ] string { " " , } , Firewalls : [ ] * cluster . Firewall { { Name : nodeName , IngressRules : [ ] * cluster . IngressRule { { IngressFromPort : " " , IngressToPort : " " , IngressSource : " " , IngressProtocol : " " , } , { IngressSource : " " , } , } , } , } , } , } , } c := cluster . NewCluster ( name ) c . SetProviderConfig ( controlPlaneProviderConfig ) c . NewMachineSetsFromProviderConfigs ( machineSetsProviderConfigs ) return c } 
func readFromHTTP ( targetURL * url . URL ) ( string , error ) { var client http . Client resp , err := client . Get ( targetURL . String ( ) ) if err != nil { return " " , err } defer resp . Body . Close ( ) if resp . StatusCode == http . StatusOK { bytes , err := ioutil . ReadAll ( resp . Body ) if err != nil { return " " , err } return string ( bytes ) , nil } return " " , fmt . Errorf ( " " , targetURL . String ( ) ) } 
func ( now * Now ) BeginningOfHour ( ) time . Time { y , m , d := now . Date ( ) return time . Date ( y , m , d , now . Time . Hour ( ) , 0 , 0 , 0 , now . Time . Location ( ) ) } 
func ( now * Now ) BeginningOfDay ( ) time . Time { y , m , d := now . Date ( ) return time . Date ( y , m , d , 0 , 0 , 0 , 0 , now . Time . Location ( ) ) } 
func ( now * Now ) BeginningOfWeek ( ) time . Time { t := now . BeginningOfDay ( ) weekday := int ( t . Weekday ( ) ) if WeekStartDay != time . Sunday { weekStartDayInt := int ( WeekStartDay ) if weekday < weekStartDayInt { weekday = weekday + 7 - weekStartDayInt } else { weekday = weekday - weekStartDayInt } } return t . AddDate ( 0 , 0 , - weekday ) } 
func ( now * Now ) BeginningOfMonth ( ) time . Time { y , m , _ := now . Date ( ) return time . Date ( y , m , 1 , 0 , 0 , 0 , 0 , now . Location ( ) ) } 
func ( now * Now ) BeginningOfQuarter ( ) time . Time { month := now . BeginningOfMonth ( ) offset := ( int ( month . Month ( ) ) - 1 ) % 3 return month . AddDate ( 0 , - offset , 0 ) } 
func ( now * Now ) BeginningOfYear ( ) time . Time { y , _ , _ := now . Date ( ) return time . Date ( y , time . January , 1 , 0 , 0 , 0 , 0 , now . Location ( ) ) } 
func ( now * Now ) EndOfMinute ( ) time . Time { return now . BeginningOfMinute ( ) . Add ( time . Minute - time . Nanosecond ) } 
func ( now * Now ) EndOfHour ( ) time . Time { return now . BeginningOfHour ( ) . Add ( time . Hour - time . Nanosecond ) } 
func ( now * Now ) EndOfDay ( ) time . Time { y , m , d := now . Date ( ) return time . Date ( y , m , d , 23 , 59 , 59 , int ( time . Second - time . Nanosecond ) , now . Location ( ) ) } 
func ( now * Now ) EndOfWeek ( ) time . Time { return now . BeginningOfWeek ( ) . AddDate ( 0 , 0 , 7 ) . Add ( - time . Nanosecond ) } 
func ( now * Now ) EndOfMonth ( ) time . Time { return now . BeginningOfMonth ( ) . AddDate ( 0 , 1 , 0 ) . Add ( - time . Nanosecond ) } 
func ( now * Now ) EndOfQuarter ( ) time . Time { return now . BeginningOfQuarter ( ) . AddDate ( 0 , 3 , 0 ) . Add ( - time . Nanosecond ) } 
func ( now * Now ) EndOfYear ( ) time . Time { return now . BeginningOfYear ( ) . AddDate ( 1 , 0 , 0 ) . Add ( - time . Nanosecond ) } 
func ( now * Now ) Sunday ( ) time . Time { t := now . BeginningOfDay ( ) weekday := int ( t . Weekday ( ) ) if weekday == 0 { return t } return t . AddDate ( 0 , 0 , ( 7 - weekday ) ) } 
func ( now * Now ) Parse ( strs ... string ) ( t time . Time , err error ) { var ( setCurrentTime bool parseTime [ ] int currentTime = [ ] int { now . Nanosecond ( ) , now . Second ( ) , now . Minute ( ) , now . Hour ( ) , now . Day ( ) , int ( now . Month ( ) ) , now . Year ( ) } currentLocation = now . Location ( ) onlyTimeInStr = true ) for _ , str := range strs { hasTimeInStr := hasTimeRegexp . MatchString ( str ) onlyTimeInStr = hasTimeInStr && onlyTimeInStr && onlyTimeRegexp . MatchString ( str ) if t , err = parseWithFormat ( str ) ; err == nil { location := t . Location ( ) if location . String ( ) == " " { location = currentLocation } parseTime = [ ] int { t . Nanosecond ( ) , t . Second ( ) , t . Minute ( ) , t . Hour ( ) , t . Day ( ) , int ( t . Month ( ) ) , t . Year ( ) } for i , v := range parseTime { } } } else { setCurrentTime = true } continue } } } t = time . Date ( parseTime [ 6 ] , time . Month ( parseTime [ 5 ] ) , parseTime [ 4 ] , parseTime [ 3 ] , parseTime [ 2 ] , parseTime [ 1 ] , parseTime [ 0 ] , location ) currentTime = [ ] int { t . Nanosecond ( ) , t . Second ( ) , t . Minute ( ) , t . Hour ( ) , t . Day ( ) , int ( t . Month ( ) ) , t . Year ( ) } } } return } 
func ( now * Now ) MustParse ( strs ... string ) ( t time . Time ) { t , err := now . Parse ( strs ... ) if err != nil { panic ( err ) } return t } 
func ( now * Now ) Between ( begin , end string ) bool { beginTime := now . MustParse ( begin ) endTime := now . MustParse ( end ) return now . After ( beginTime ) && now . Before ( endTime ) } 
func Parse ( strs ... string ) ( time . Time , error ) { return New ( time . Now ( ) ) . Parse ( strs ... ) } 
func ParseInLocation ( loc * time . Location , strs ... string ) ( time . Time , error ) { return New ( time . Now ( ) . In ( loc ) ) . Parse ( strs ... ) } 
func MustParse ( strs ... string ) time . Time { return New ( time . Now ( ) ) . MustParse ( strs ... ) } 
func MustParseInLocation ( loc * time . Location , strs ... string ) time . Time { return New ( time . Now ( ) . In ( loc ) ) . MustParse ( strs ... ) } 
func Between ( time1 , time2 string ) bool { return New ( time . Now ( ) ) . Between ( time1 , time2 ) } 
func ( b * MemoryBackend ) Log ( level Level , calldepth int , rec * Record ) error { var size int32 n := & node { Record : rec } np := unsafe . Pointer ( n ) swapped := atomic . CompareAndSwapPointer ( & b . tail , tailp , np , ) if swapped == true { if tailp == nil { b . head = np } else { ( * node ) ( tailp ) . next = n } size = atomic . AddInt32 ( & b . size , 1 ) break } } head := ( * node ) ( b . head ) if head . next == nil { break } swapped := atomic . CompareAndSwapPointer ( & b . head , headp , unsafe . Pointer ( head . next ) , ) if swapped == true { atomic . AddInt32 ( & b . size , - 1 ) break } } } return nil } 
func NewChannelMemoryBackend ( size int ) * ChannelMemoryBackend { backend := & ChannelMemoryBackend { maxSize : size , incoming : make ( chan * Record , 1024 ) , events : make ( chan event ) , } backend . Start ( ) return backend } 
func ( b * ChannelMemoryBackend ) Start ( ) { b . mu . Lock ( ) defer b . mu . Unlock ( ) b . stopWg . Add ( 1 ) go b . process ( ) } } 
func ( b * ChannelMemoryBackend ) Flush ( ) { b . flushWg . Add ( 1 ) b . events <- eventFlush b . flushWg . Wait ( ) } 
func ( b * ChannelMemoryBackend ) Stop ( ) { b . mu . Lock ( ) if b . running == true { b . running = false b . events <- eventStop } b . mu . Unlock ( ) b . stopWg . Wait ( ) } 
func ( b * ChannelMemoryBackend ) Log ( level Level , calldepth int , rec * Record ) error { b . incoming <- rec return nil } 
func ( r * Record ) Formatted ( calldepth int ) string { if r . formatted == " " { var buf bytes . Buffer r . formatter . Format ( calldepth + 1 , r , & buf ) r . formatted = buf . String ( ) } return r . formatted } 
func ( r * Record ) Message ( ) string { if r . message == nil { } } var buf bytes . Buffer if r . fmt != nil { fmt . Fprintf ( & buf , * r . fmt , r . Args ... ) } else { buf . Truncate ( buf . Len ( ) - 1 ) } msg := buf . String ( ) r . message = & msg } return * r . message } 
func ( l * Logger ) SetBackend ( backend LeveledBackend ) { l . backend = backend l . haveBackend = true } 
func MustGetLogger ( module string ) * Logger { logger , err := GetLogger ( module ) if err != nil { panic ( " " + module + " " + err . Error ( ) ) } return logger } 
func Reset ( ) { b := SetBackend ( NewLogBackend ( os . Stderr , " " , log . LstdFlags ) ) b . SetLevel ( DEBUG , " " ) SetFormatter ( DefaultFormatter ) timeNow = time . Now } 
func ( l * Logger ) IsEnabledFor ( level Level ) bool { return defaultBackend . IsEnabledFor ( level , l . Module ) } 
func ( l * Logger ) Fatal ( args ... interface { } ) { l . log ( CRITICAL , nil , args ... ) os . Exit ( 1 ) } 
func ( l * Logger ) Fatalf ( format string , args ... interface { } ) { l . log ( CRITICAL , & format , args ... ) os . Exit ( 1 ) } 
func ( l * Logger ) Panic ( args ... interface { } ) { l . log ( CRITICAL , nil , args ... ) panic ( fmt . Sprint ( args ... ) ) } 
func ( l * Logger ) Panicf ( format string , args ... interface { } ) { l . log ( CRITICAL , & format , args ... ) panic ( fmt . Sprintf ( format , args ... ) ) } 
func ( l * Logger ) Criticalf ( format string , args ... interface { } ) { l . log ( CRITICAL , & format , args ... ) } 
func ( l * Logger ) Warningf ( format string , args ... interface { } ) { l . log ( WARNING , & format , args ... ) } 
func ( l * Logger ) Noticef ( format string , args ... interface { } ) { l . log ( NOTICE , & format , args ... ) } 
func ( l * Logger ) Infof ( format string , args ... interface { } ) { l . log ( INFO , & format , args ... ) } 
func NewLogBackend ( out io . Writer , prefix string , flag int ) * LogBackend { b := & LogBackend { Logger : log . New ( out , prefix , flag ) } } return b } 
func setConsoleTextAttribute ( f file , attribute uint16 ) bool { ok , _ , _ := setConsoleTextAttributeProc . Call ( f . Fd ( ) , uintptr ( attribute ) , 0 ) return ok != 0 } 
func SetFormatter ( f Formatter ) { formatter . Lock ( ) defer formatter . Unlock ( ) formatter . def = f } 
func NewStringFormatter ( format string ) ( Formatter , error ) { var fmter = & stringFormatter { } if matches == nil { return nil , errors . New ( " " + format ) } for _ , m := range matches { start , end := m [ 0 ] , m [ 1 ] if start > prev { fmter . add ( fmtVerbStatic , format [ prev : start ] ) } name := format [ m [ 2 ] : m [ 3 ] ] verb := getFmtVerbByName ( name ) if verb == fmtVerbUnknown { return nil , errors . New ( " " + name ) } if m [ 4 ] != - 1 { layout = format [ m [ 4 ] : m [ 5 ] ] } if verb != fmtVerbTime && verb != fmtVerbLevelColor && verb != fmtVerbCallpath { layout = " " + layout } fmter . add ( verb , layout ) prev = end } end := format [ prev : ] if end != " " { fmter . add ( fmtVerbStatic , end ) } if err != nil { panic ( err ) } testFmt := " " r := & Record { ID : 12345 , Time : t , Module : " " , Args : [ ] interface { } { " " } , fmt : & testFmt , } if err := fmter . Format ( 0 , r , & bytes . Buffer { } ) ; err != nil { return nil , err } return fmter , nil } 
func MustStringFormatter ( format string ) Formatter { f , err := NewStringFormatter ( format ) if err != nil { panic ( " " + err . Error ( ) ) } return f } 
func formatFuncName ( v fmtVerb , f string ) string { i := strings . LastIndex ( f , " " ) j := strings . Index ( f [ i + 1 : ] , " " ) if j < 1 { return " " } pkg , fun := f [ : i + j + 1 ] , f [ i + j + 2 : ] switch v { case fmtVerbLongpkg : return pkg case fmtVerbShortpkg : return path . Base ( pkg ) case fmtVerbLongfunc : return fun case fmtVerbShortfunc : i = strings . LastIndex ( fun , " " ) return fun [ i + 1 : ] } panic ( " " ) } 
func ( bf * backendFormatter ) Log ( level Level , calldepth int , r * Record ) error { r2 . formatter = bf . f return bf . b . Log ( level , calldepth + 1 , & r2 ) } 
func LogLevel ( level string ) ( Level , error ) { for i , name := range levelNames { if strings . EqualFold ( name , level ) { return Level ( i ) , nil } } return ERROR , ErrInvalidLogLevel } 
func AddModuleLevel ( backend Backend ) LeveledBackend { var leveled LeveledBackend var ok bool if leveled , ok = backend . ( LeveledBackend ) ; ! ok { leveled = & moduleLeveled { levels : make ( map [ string ] Level ) , backend : backend , } } return leveled } 
func ( l * moduleLeveled ) GetLevel ( module string ) Level { level , exists := l . levels [ module ] if exists == false { level , exists = l . levels [ " " ] } } return level } 
func ( l * moduleLeveled ) SetLevel ( level Level , module string ) { l . levels [ module ] = level } 
func ( l * moduleLeveled ) IsEnabledFor ( level Level , module string ) bool { return level <= l . GetLevel ( module ) } 
func MultiLogger ( backends ... Backend ) LeveledBackend { var leveledBackends [ ] LeveledBackend for _ , backend := range backends { leveledBackends = append ( leveledBackends , AddModuleLevel ( backend ) ) } return & multiLogger { leveledBackends } } 
func ( b * multiLogger ) Log ( level Level , calldepth int , rec * Record ) ( err error ) { for _ , backend := range b . backends { if backend . IsEnabledFor ( level , rec . Module ) { if e := backend . Log ( level , calldepth + 1 , & r2 ) ; e != nil { err = e } } } return } 
func ( b * multiLogger ) GetLevel ( module string ) Level { var level Level for _ , backend := range b . backends { if backendLevel := backend . GetLevel ( module ) ; backendLevel > level { level = backendLevel } } return level } 
func ( b * multiLogger ) SetLevel ( level Level , module string ) { for _ , backend := range b . backends { backend . SetLevel ( level , module ) } } 
func ( b * multiLogger ) IsEnabledFor ( level Level , module string ) bool { for _ , backend := range b . backends { if backend . IsEnabledFor ( level , module ) { return true } } return false } 
func NewLogBackend ( out io . Writer , prefix string , flag int ) * LogBackend { return & LogBackend { Logger : log . New ( out , prefix , flag ) } } 
func ( b * LogBackend ) Log ( level Level , calldepth int , rec * Record ) error { if b . Color { col := colors [ level ] if len ( b . ColorConfig ) > int ( level ) && b . ColorConfig [ level ] != " " { col = b . ColorConfig [ level ] } buf := & bytes . Buffer { } buf . Write ( [ ] byte ( col ) ) buf . Write ( [ ] byte ( rec . Formatted ( calldepth + 1 ) ) ) buf . Write ( [ ] byte ( " \033 " ) ) } return b . Logger . Output ( calldepth + 2 , rec . Formatted ( calldepth + 1 ) ) } 
func ConvertColors ( colors [ ] int , bold bool ) [ ] string { converted := [ ] string { } for _ , i := range colors { if bold { converted = append ( converted , ColorSeqBold ( color ( i ) ) ) } else { converted = append ( converted , ColorSeq ( color ( i ) ) ) } } return converted } 
func NewSyslogBackend ( prefix string ) ( b * SyslogBackend , err error ) { var w * syslog . Writer w , err = syslog . New ( syslog . LOG_CRIT , prefix ) return & SyslogBackend { w } , err } 
func NewSyslogBackendPriority ( prefix string , priority syslog . Priority ) ( b * SyslogBackend , err error ) { var w * syslog . Writer w , err = syslog . New ( priority , prefix ) return & SyslogBackend { w } , err } 
func ( b * SyslogBackend ) Log ( level Level , calldepth int , rec * Record ) error { line := rec . Formatted ( calldepth + 1 ) switch level { case CRITICAL : return b . Writer . Crit ( line ) case ERROR : return b . Writer . Err ( line ) case WARNING : return b . Writer . Warning ( line ) case NOTICE : return b . Writer . Notice ( line ) case INFO : return b . Writer . Info ( line ) case DEBUG : return b . Writer . Debug ( line ) default : } panic ( " " ) } 
func SetBackend ( backends ... Backend ) LeveledBackend { var backend Backend if len ( backends ) == 1 { backend = backends [ 0 ] } else { backend = MultiLogger ( backends ... ) } defaultBackend = AddModuleLevel ( backend ) return defaultBackend } 
func NewCommander ( topLevelFlags * flag . FlagSet , name string ) * Commander { cdr := & Commander { topFlags : topLevelFlags , name : name , Output : os . Stdout , Error : os . Stderr , } topLevelFlags . Usage = func ( ) { cdr . explain ( cdr . Error ) } return cdr } 
func ( cdr * Commander ) Register ( cmd Command , group string ) { for _ , g := range cdr . commands { if g . name == group { g . commands = append ( g . commands , cmd ) return } } cdr . commands = append ( cdr . commands , & commandGroup { name : group , commands : [ ] Command { cmd } , } ) } 
func ( cdr * Commander ) ImportantFlag ( name string ) { cdr . important = append ( cdr . important , name ) } 
func ( cdr * Commander ) Execute ( ctx context . Context , args ... interface { } ) ExitStatus { if cdr . topFlags . NArg ( ) < 1 { cdr . topFlags . Usage ( ) return ExitUsageError } name := cdr . topFlags . Arg ( 0 ) for _ , group := range cdr . commands { for _ , cmd := range group . commands { if name != cmd . Name ( ) { continue } f := flag . NewFlagSet ( name , flag . ContinueOnError ) f . Usage = func ( ) { explain ( cdr . Error , cmd ) } cmd . SetFlags ( f ) if f . Parse ( cdr . topFlags . Args ( ) [ 1 : ] ) != nil { return ExitUsageError } return cmd . Execute ( ctx , f , args ... ) } } return ExitUsageError } 
func ( cdr * Commander ) explain ( w io . Writer ) { fmt . Fprintf ( w , " \n \n " , cdr . name ) sort . Sort ( byGroupName ( cdr . commands ) ) for _ , group := range cdr . commands { explainGroup ( w , group ) } if cdr . topFlags == nil { fmt . Fprintln ( w , " \n " ) return } if len ( cdr . important ) == 0 { fmt . Fprintf ( w , " \n \" \" \n " , cdr . name ) return } fmt . Fprintf ( w , " \n \" \" \n " , cdr . name ) for _ , name := range cdr . important { f := cdr . topFlags . Lookup ( name ) if f == nil { panic ( fmt . Sprintf ( " " , name ) ) } fmt . Fprintf ( w , " \n " , f . Name , f . DefValue , f . Usage ) } } 
func explainGroup ( w io . Writer , group * commandGroup ) { if len ( group . commands ) == 0 { return } if group . name == " " { fmt . Fprintf ( w , " \n " ) } else { fmt . Fprintf ( w , " \n " , group . name ) } sort . Sort ( group ) aliases := make ( map [ string ] [ ] string ) for _ , cmd := range group . commands { if alias , ok := cmd . ( * aliaser ) ; ok { root := dealias ( alias ) . Name ( ) if _ , ok := aliases [ root ] ; ! ok { aliases [ root ] = [ ] string { } } aliases [ root ] = append ( aliases [ root ] , alias . Name ( ) ) } } for _ , cmd := range group . commands { if _ , ok := cmd . ( * aliaser ) ; ok { continue } name := cmd . Name ( ) names := [ ] string { name } if a , ok := aliases [ name ] ; ok { names = append ( names , a ... ) } fmt . Fprintf ( w , " \t \n " , strings . Join ( names , " " ) , cmd . Synopsis ( ) ) } fmt . Fprintln ( w ) } 
func explain ( w io . Writer , cmd Command ) { fmt . Fprintf ( w , " " , cmd . Usage ( ) ) subflags := flag . NewFlagSet ( cmd . Name ( ) , flag . PanicOnError ) subflags . SetOutput ( w ) cmd . SetFlags ( subflags ) subflags . PrintDefaults ( ) } 
func dealias ( cmd Command ) Command { if alias , ok := cmd . ( * aliaser ) ; ok { return dealias ( alias . Command ) } return cmd } 
func Execute ( ctx context . Context , args ... interface { } ) ExitStatus { return DefaultCommander . Execute ( ctx , args ... ) } 
func ( c * ConfigFile ) read ( reader io . Reader ) ( err error ) { buf := bufio . NewReader ( reader ) if err == nil && len ( mask ) >= 3 && mask [ 0 ] == 239 && mask [ 1 ] == 187 && mask [ 2 ] == 191 { buf . Read ( mask ) } count := 1 var comments string line = strings . TrimSpace ( line ) lineLengh := len ( line ) if err != nil { if err != io . EOF { return err } } } case line [ 0 ] == '#' || line [ 0 ] == ';' : } else { comments += LineBreak + line } continue case line [ 0 ] == '[' && line [ lineLengh - 1 ] == ']' : comments = " " } continue case section == " " : default : keyQuote string key string valQuote string value string ) } else { keyQuote = `"` } } else if line [ 0 ] == '`' { keyQuote = " " } if keyQuote != " " { qLen := len ( keyQuote ) pos := strings . Index ( line [ qLen : ] , keyQuote ) if pos == - 1 { return readError { ERR_COULD_NOT_PARSE , line } } pos = pos + qLen i = strings . IndexAny ( line [ pos : ] , " " ) if i <= 0 { return readError { ERR_COULD_NOT_PARSE , line } } i = i + pos key = line [ qLen : pos ] // } else { i = strings . IndexAny ( line , " " ) if i <= 0 { return readError { ERR_COULD_NOT_PARSE , line } } key = strings . TrimSpace ( line [ 0 : i ] ) } //[SWH|+]; // Check if it needs auto increment. if key == " " { key = " " + fmt . Sprint ( count ) count ++ } //[SWH|+]: lineRight := strings . TrimSpace ( line [ i + 1 : ] ) lineRightLength := len ( lineRight ) firstChar := " " if lineRightLength >= 2 { firstChar = lineRight [ 0 : 1 ] } if firstChar == " " { valQuote = " " } else if lineRightLength >= 6 && lineRight [ 0 : 3 ] == `"""` { valQuote = `"""` } if valQuote != " " { qLen := len ( valQuote ) pos := strings . LastIndex ( lineRight [ qLen : ] , valQuote ) if pos == - 1 { return readError { ERR_COULD_NOT_PARSE , line } } pos = pos + qLen value = lineRight [ qLen : pos ] } else { value = strings . TrimSpace ( lineRight [ 0 : ] ) } //[SWH|+]; c . SetValue ( section , key , value ) // Set key comments and empty if it has comments. if len ( comments ) > 0 { c . SetKeyComments ( section , key , comments ) comments = " " } } } } return nil } 
func LoadFromData ( data [ ] byte ) ( c * ConfigFile , err error ) { if err = os . MkdirAll ( path . Dir ( tmpName ) , os . ModePerm ) ; err != nil { return nil , err } if err = ioutil . WriteFile ( tmpName , data , 0655 ) ; err != nil { return nil , err } c = newConfigFile ( [ ] string { tmpName } ) err = c . read ( bytes . NewBuffer ( data ) ) return c , err } 
func LoadFromReader ( in io . Reader ) ( c * ConfigFile , err error ) { c = newConfigFile ( [ ] string { " " } ) err = c . read ( in ) return c , err } 
func ( c * ConfigFile ) ReloadData ( in io . Reader ) ( err error ) { var cfg * ConfigFile if len ( c . fileNames ) != 1 { return fmt . Errorf ( " " ) } cfg , err = LoadFromReader ( in ) if err == nil { * c = * cfg } return err } 
func ( c * ConfigFile ) AppendFiles ( files ... string ) error { if len ( c . fileNames ) == 1 && c . fileNames [ 0 ] == " " { return fmt . Errorf ( " " ) } c . fileNames = append ( c . fileNames , files ... ) return c . Reload ( ) } 
func ( c * ConfigFile ) GetKeyList ( section string ) [ ] string { } if c . BlockMode { c . lock . RLock ( ) defer c . lock . RUnlock ( ) } } for _ , key := range c . keyList [ section ] { if key != " " { list = append ( list , key ) } } return list } 
func SaveConfigData ( c * ConfigFile , out io . Writer ) ( err error ) { equalSign := " " if PrettyFormat { equalSign = " " } buf := bytes . NewBuffer ( nil ) for _ , section := range c . sectionList { } } if section != DEFAULT_SECTION { } } for _ , key := range c . keyList [ section ] { if key != " " { } } keyName := key } } else { keyName = `"` + keyName + `"` } } else { keyName = " " + keyName + " " } } value := c . data [ section ] [ key ] } else { value = `"` + value + `"` } } } } } } } if _ , err := buf . WriteTo ( out ) ; err != nil { return err } return nil } 
func SaveConfigFile ( c * ConfigFile , filename string ) ( err error ) { if f , err = os . Create ( filename ) ; err != nil { return err } if err := SaveConfigData ( c , f ) ; err != nil { return err } return f . Close ( ) } 
func ( s * selectable ) Find ( selector string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . CSS , selector ) . Single ( ) ) } 
func ( s * selectable ) FindByXPath ( selector string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . XPath , selector ) . Single ( ) ) } 
func ( s * selectable ) FindByLink ( text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Link , text ) . Single ( ) ) } 
func ( s * selectable ) FindByLabel ( text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Label , text ) . Single ( ) ) } 
func ( s * selectable ) FindByButton ( text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Button , text ) . Single ( ) ) } 
func ( s * selectable ) FindByName ( name string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Name , name ) . Single ( ) ) } 
func ( s * selectable ) FindByClass ( text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Class , text ) . Single ( ) ) } 
func ( s * selectable ) FindByID ( id string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . ID , id ) . Single ( ) ) } 
func ( s * selectable ) First ( selector string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . CSS , selector ) . At ( 0 ) ) } 
func ( s * selectable ) FirstByXPath ( selector string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . XPath , selector ) . At ( 0 ) ) } 
func ( s * selectable ) FirstByLink ( text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Link , text ) . At ( 0 ) ) } 
func ( s * selectable ) FirstByLabel ( text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Label , text ) . At ( 0 ) ) } 
func ( s * selectable ) FirstByButton ( text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Button , text ) . At ( 0 ) ) } 
func ( s * selectable ) FirstByName ( name string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Name , name ) . At ( 0 ) ) } 
func ( s * selectable ) All ( selector string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . CSS , selector ) ) } 
func ( s * selectable ) AllByXPath ( selector string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . XPath , selector ) ) } 
func ( s * selectable ) AllByLink ( text string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . Link , text ) ) } 
func ( s * selectable ) AllByLabel ( text string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . Label , text ) ) } 
func ( s * selectable ) AllByButton ( text string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . Button , text ) ) } 
func ( s * selectable ) AllByName ( name string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . Name , name ) ) } 
func ( s * selectable ) AllByClass ( text string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . Class , text ) ) } 
func ( s * selectable ) AllByID ( text string ) * MultiSelection { return newMultiSelection ( s . session , s . selectors . Append ( target . ID , text ) ) } 
func ( s * selectable ) FindForAppium ( selectorType string , text string ) * Selection { return newSelection ( s . session , s . selectors . Append ( target . Class , text ) . At ( 0 ) ) } 
func Timeout ( seconds int ) Option { return func ( c * config ) { c . Timeout = time . Duration ( seconds ) * time . Second } } 
func ChromeOptions ( opt string , value interface { } ) Option { return func ( c * config ) { if c . ChromeOptions == nil { c . ChromeOptions = make ( map [ string ] interface { } ) } c . ChromeOptions [ opt ] = value } } 
func HTTPClient ( client * http . Client ) Option { return func ( c * config ) { c . HTTPClient = client } } 
func NewPage ( url string , options ... Option ) ( * Page , error ) { pageOptions := config { } . Merge ( options ) session , err := api . OpenWithClient ( url , pageOptions . Capabilities ( ) , pageOptions . HTTPClient ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return newPage ( session ) , nil } 
func JoinPage ( url string , options ... Option ) * Page { pageOptions := config { } . Merge ( options ) session := api . NewWithClient ( url , pageOptions . HTTPClient ) return newPage ( session ) } 
func ( p * Page ) Destroy ( ) error { if err := p . session . Delete ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) Reset ( ) error { p . ConfirmPopup ( ) url , err := p . URL ( ) if err != nil { return err } if url == " " { return nil } if err := p . ClearCookies ( ) ; err != nil { return err } if err := p . session . DeleteLocalStorage ( ) ; err != nil { if err := p . RunScript ( " " , nil , nil ) ; err != nil { return err } } if err := p . session . DeleteSessionStorage ( ) ; err != nil { if err := p . RunScript ( " " , nil , nil ) ; err != nil { return err } } return p . Navigate ( " " ) } 
func ( p * Page ) Navigate ( url string ) error { if err := p . session . SetURL ( url ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) GetCookies ( ) ( [ ] * http . Cookie , error ) { apiCookies , err := p . session . GetCookies ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } cookies := [ ] * http . Cookie { } for _ , apiCookie := range apiCookies { expSeconds := int64 ( apiCookie . Expiry ) expNano := int64 ( apiCookie . Expiry - float64 ( expSeconds ) ) * 1000000000 cookie := & http . Cookie { Name : apiCookie . Name , Value : apiCookie . Value , Path : apiCookie . Path , Domain : apiCookie . Domain , Secure : apiCookie . Secure , HttpOnly : apiCookie . HTTPOnly , Expires : time . Unix ( expSeconds , expNano ) , } cookies = append ( cookies , cookie ) } return cookies , nil } 
func ( p * Page ) SetCookie ( cookie * http . Cookie ) error { if cookie == nil { return errors . New ( " " ) } var expiry int64 if ! cookie . Expires . IsZero ( ) { expiry = cookie . Expires . Unix ( ) } apiCookie := & api . Cookie { Name : cookie . Name , Value : cookie . Value , Path : cookie . Path , Domain : cookie . Domain , Secure : cookie . Secure , HTTPOnly : cookie . HttpOnly , Expiry : float64 ( expiry ) , } if err := p . session . SetCookie ( apiCookie ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) DeleteCookie ( name string ) error { if err := p . session . DeleteCookie ( name ) ; err != nil { return fmt . Errorf ( " " , name , err ) } return nil } 
func ( p * Page ) ClearCookies ( ) error { if err := p . session . DeleteCookies ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) URL ( ) ( string , error ) { url , err := p . session . GetURL ( ) if err != nil { return " " , fmt . Errorf ( " " , err ) } return url , nil } 
func ( p * Page ) Size ( width , height int ) error { window , err := p . session . GetWindow ( ) if err != nil { return fmt . Errorf ( " " , err ) } if err := window . SetSize ( width , height ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) Screenshot ( filename string ) error { absFilePath , err := filepath . Abs ( filename ) if err != nil { return fmt . Errorf ( " " , err ) } screenshot , err := p . session . GetScreenshot ( ) if err != nil { return fmt . Errorf ( " " , err ) } if err := ioutil . WriteFile ( absFilePath , screenshot , 0666 ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) Title ( ) ( string , error ) { title , err := p . session . GetTitle ( ) if err != nil { return " " , fmt . Errorf ( " " , err ) } return title , nil } 
func ( p * Page ) HTML ( ) ( string , error ) { html , err := p . session . GetSource ( ) if err != nil { return " " , fmt . Errorf ( " " , err ) } return html , nil } 
func ( p * Page ) RunScript ( body string , arguments map [ string ] interface { } , result interface { } ) error { var ( keys [ ] string values [ ] interface { } ) for key , value := range arguments { keys = append ( keys , key ) values = append ( values , value ) } argumentList := strings . Join ( keys , " " ) cleanBody := fmt . Sprintf ( " " , argumentList , body ) if err := p . session . Execute ( cleanBody , values , result ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) PopupText ( ) ( string , error ) { text , err := p . session . GetAlertText ( ) if err != nil { return " " , fmt . Errorf ( " " , err ) } return text , nil } 
func ( p * Page ) EnterPopupText ( text string ) error { if err := p . session . SetAlertText ( text ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) ConfirmPopup ( ) error { if err := p . session . AcceptAlert ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) CancelPopup ( ) error { if err := p . session . DismissAlert ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) SwitchToParentFrame ( ) error { if err := p . session . FrameParent ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) SwitchToRootFrame ( ) error { if err := p . session . Frame ( nil ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) SwitchToWindow ( name string ) error { if err := p . session . SetWindowByName ( name ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) NextWindow ( ) error { windows , err := p . session . GetWindows ( ) if err != nil { return fmt . Errorf ( " " , err ) } var windowIDs [ ] string for _ , window := range windows { windowIDs = append ( windowIDs , window . ID ) } activeWindow , err := p . session . GetWindow ( ) if err != nil { return fmt . Errorf ( " " , err ) } for position , windowID := range windowIDs { if windowID == activeWindow . ID { activeWindow . ID = windowIDs [ ( position + 1 ) % len ( windowIDs ) ] break } } if err := p . session . SetWindow ( activeWindow ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) CloseWindow ( ) error { if err := p . session . DeleteWindow ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) WindowCount ( ) ( int , error ) { windows , err := p . session . GetWindows ( ) if err != nil { return 0 , fmt . Errorf ( " " , err ) } return len ( windows ) , nil } 
func ( p * Page ) LogTypes ( ) ( [ ] string , error ) { types , err := p . session . GetLogTypes ( ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return types , nil } 
func ( p * Page ) ReadNewLogs ( logType string ) ( [ ] Log , error ) { if p . logs == nil { p . logs = map [ string ] [ ] Log { } } clientLogs , err := p . session . NewLogs ( logType ) if err != nil { return nil , fmt . Errorf ( " " , err ) } messageMatcher := regexp . MustCompile ( `^(?s:(.+))\s\(([^)]*:\w*)\)$` ) var logs [ ] Log for _ , clientLog := range clientLogs { matches := messageMatcher . FindStringSubmatch ( clientLog . Message ) message , location := clientLog . Message , " " if len ( matches ) > 2 { message , location = matches [ 1 ] , matches [ 2 ] } log := Log { message , location , clientLog . Level , msToTime ( clientLog . Timestamp ) } logs = append ( logs , log ) } p . logs [ logType ] = append ( p . logs [ logType ] , logs ... ) return logs , nil } 
func ( p * Page ) ReadAllLogs ( logType string ) ( [ ] Log , error ) { if _ , err := p . ReadNewLogs ( logType ) ; err != nil { return nil , err } return append ( [ ] Log ( nil ) , p . logs [ logType ] ... ) , nil } 
func ( p * Page ) MoveMouseBy ( xOffset , yOffset int ) error { if err := p . session . MoveTo ( nil , api . XYOffset { X : xOffset , Y : yOffset } ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) DoubleClick ( ) error { if err := p . session . DoubleClick ( ) ; err != nil { return fmt . Errorf ( " " , err ) } return nil } 
func ( p * Page ) Click ( event Click , button Button ) error { var err error switch event { case SingleClick : err = p . session . Click ( api . Button ( button ) ) case HoldClick : err = p . session . ButtonDown ( api . Button ( button ) ) case ReleaseClick : err = p . session . ButtonUp ( api . Button ( button ) ) default : err = errors . New ( " " ) } if err != nil { return fmt . Errorf ( " " , event , button , err ) } return nil } 
func ( p * Page ) SetImplicitWait ( timeout int ) error { return p . session . SetImplicitWait ( timeout ) } 
func ( p * Page ) SetPageLoad ( timeout int ) error { return p . session . SetPageLoad ( timeout ) } 
func ( p * Page ) SetScriptTimeout ( timeout int ) error { return p . session . SetScriptTimeout ( timeout ) } 
func NewWebDriver ( url string , command [ ] string , options ... Option ) * WebDriver { apiWebDriver := api . NewWebDriver ( url , command ) defaultOptions := config { Timeout : apiWebDriver . Timeout } . Merge ( options ) apiWebDriver . Timeout = defaultOptions . Timeout apiWebDriver . Debug = defaultOptions . Debug apiWebDriver . HTTPClient = defaultOptions . HTTPClient return & WebDriver { apiWebDriver , defaultOptions } } 
func ( w * WebDriver ) NewPage ( options ... Option ) ( * Page , error ) { newOptions := w . defaultOptions . Merge ( options ) session , err := w . Open ( newOptions . Capabilities ( ) ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return newPage ( session ) , nil } 
func ( s * Selection ) Click ( ) error { return s . forEachElement ( func ( selectedElement element . Element ) error { if err := selectedElement . Click ( ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } ) } 
func ( s * Selection ) DoubleClick ( ) error { return s . forEachElement ( func ( selectedElement element . Element ) error { if err := s . session . MoveTo ( selectedElement . ( * api . Element ) , nil ) ; err != nil { return fmt . Errorf ( " " , s , err ) } if err := s . session . DoubleClick ( ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } ) } 
func ( s * Selection ) Fill ( text string ) error { return s . forEachElement ( func ( selectedElement element . Element ) error { if err := selectedElement . Clear ( ) ; err != nil { return fmt . Errorf ( " " , s , err ) } if err := selectedElement . Value ( text ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } ) } 
func ( s * Selection ) UploadFile ( filename string ) error { absFilePath , err := filepath . Abs ( filename ) if err != nil { return fmt . Errorf ( " " , err ) } return s . forEachElement ( func ( selectedElement element . Element ) error { tagName , err := selectedElement . GetName ( ) if err != nil { return fmt . Errorf ( " " , s , err ) } if tagName != " " { return fmt . Errorf ( " " , s ) } inputType , err := selectedElement . GetAttribute ( " " ) if err != nil { return fmt . Errorf ( " " , s , err ) } if inputType != " " { return fmt . Errorf ( " " , s ) } if err := selectedElement . Value ( absFilePath ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } ) } 
func ( s * Selection ) Select ( text string ) error { return s . forEachElement ( func ( selectedElement element . Element ) error { optionXPath := fmt . Sprintf ( `./option[normalize-space()="%s"]` , text ) optionToSelect := target . Selector { Type : target . XPath , Value : optionXPath } options , err := selectedElement . GetElements ( optionToSelect . API ( ) ) if err != nil { return fmt . Errorf ( " " , s , err ) } if len ( options ) == 0 { return fmt . Errorf ( `no options with text "%s" found for %s` , text , s ) } for _ , option := range options { if err := option . Click ( ) ; err != nil { return fmt . Errorf ( `failed to click on option with text "%s" for %s: %s` , text , s , err ) } } return nil } ) } 
func ( s * Selection ) Tap ( event Tap ) error { var touchFunc func ( * api . Element ) error switch event { case SingleTap : touchFunc = s . session . TouchClick case DoubleTap : touchFunc = s . session . TouchDoubleClick case LongTap : touchFunc = s . session . TouchLongClick default : return fmt . Errorf ( " " , event , s ) } return s . forEachElement ( func ( selectedElement element . Element ) error { if err := touchFunc ( selectedElement . ( * api . Element ) ) ; err != nil { return fmt . Errorf ( " " , event , s , err ) } return nil } ) } 
func ( s * Selection ) Touch ( event Touch ) error { var touchFunc func ( x , y int ) error switch event { case HoldFinger : touchFunc = s . session . TouchDown case ReleaseFinger : touchFunc = s . session . TouchUp case MoveFinger : touchFunc = s . session . TouchMove default : return fmt . Errorf ( " " , event , s ) } return s . forEachElement ( func ( selectedElement element . Element ) error { x , y , err := selectedElement . GetLocation ( ) if err != nil { return fmt . Errorf ( " " , s , err ) } if err := touchFunc ( x , y ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } ) } 
func ( s * Selection ) FlickFinger ( xOffset , yOffset int , speed uint ) error { selectedElement , err := s . elements . GetExactlyOne ( ) if err != nil { return fmt . Errorf ( " " , s , err ) } if err := s . session . TouchFlick ( selectedElement . ( * api . Element ) , api . XYOffset { X : xOffset , Y : yOffset } , api . ScalarSpeed ( speed ) ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } 
func ( s * Selection ) ScrollFinger ( xOffset , yOffset int ) error { selectedElement , err := s . elements . GetExactlyOne ( ) if err != nil { return fmt . Errorf ( " " , s , err ) } if err := s . session . TouchScroll ( selectedElement . ( * api . Element ) , api . XYOffset { X : xOffset , Y : yOffset } ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } 
func ( s * MultiSelection ) At ( index int ) * Selection { return newSelection ( s . session , s . selectors . At ( index ) ) } 
func NewCapabilities ( features ... string ) Capabilities { c := Capabilities { } for _ , feature := range features { c . With ( feature ) } return c } 
func ( c Capabilities ) With ( feature string ) Capabilities { c [ feature ] = true return c } 
func ( c Capabilities ) Without ( feature string ) Capabilities { c [ feature ] = false return c } 
func ( c Capabilities ) JSON ( ) ( string , error ) { capabilitiesJSON , err := json . Marshal ( c ) return string ( capabilitiesJSON ) , err } 
func HaveTitle ( title string ) types . GomegaMatcher { return & internal . ValueMatcher { Method : " " , Property : " " , Expected : title } } 
func HaveURL ( url string ) types . GomegaMatcher { return & internal . ValueMatcher { Method : " " , Property : " " , Expected : url } } 
func HavePopupText ( text string ) types . GomegaMatcher { return & internal . ValueMatcher { Method : " " , Property : " " , Expected : text } } 
func HaveLoggedError ( messages ... string ) types . GomegaMatcher { return & internal . LogMatcher { ExpectedMessages : messages , Levels : [ ] string { " " , " " } , Name : " " , Type : " " , } } 
func ( s * Selection ) Text ( ) ( string , error ) { selectedElement , err := s . elements . GetExactlyOne ( ) if err != nil { return " " , fmt . Errorf ( " " , s , err ) } text , err := selectedElement . GetText ( ) if err != nil { return " " , fmt . Errorf ( " " , s , err ) } return text , nil } 
func ( s * Selection ) Active ( ) ( bool , error ) { selectedElement , err := s . elements . GetExactlyOne ( ) if err != nil { return false , fmt . Errorf ( " " , s , err ) } activeElement , err := s . session . GetActiveElement ( ) if err != nil { return false , fmt . Errorf ( " " , err ) } equal , err := selectedElement . IsEqualTo ( activeElement ) if err != nil { return false , fmt . Errorf ( " " , err ) } return equal , nil } 
func ( s * Selection ) Attribute ( attribute string ) ( string , error ) { return s . hasProperty ( element . Element . GetAttribute , attribute , " " ) } 
func ( s * Selection ) CSS ( property string ) ( string , error ) { return s . hasProperty ( element . Element . GetCSS , property , " " ) } 
func ( s * Selection ) Selected ( ) ( bool , error ) { return s . hasState ( element . Element . IsSelected , " " ) } 
func ( s * Selection ) Visible ( ) ( bool , error ) { return s . hasState ( element . Element . IsDisplayed , " " ) } 
func ( s * Selection ) Enabled ( ) ( bool , error ) { return s . hasState ( element . Element . IsEnabled , " " ) } 
func HaveCount ( count int ) types . GomegaMatcher { return & internal . ValueMatcher { Method : " " , Property : " " , Expected : count } } 
func HaveAttribute ( attribute string , value string ) types . GomegaMatcher { return & internal . HaveAttributeMatcher { ExpectedAttribute : attribute , ExpectedValue : value } } 
func HaveCSS ( property string , value string ) types . GomegaMatcher { return & internal . HaveCSSMatcher { ExpectedProperty : property , ExpectedValue : value } } 
func PhantomJS ( options ... Option ) * WebDriver { command := [ ] string { " " , " " } defaultOptions := config { } . Merge ( options ) if ! defaultOptions . RejectInvalidSSL { command = append ( command , " " ) } return NewWebDriver ( " " , command , options ... ) } 
func EdgeDriver ( options ... Option ) * WebDriver { var binaryName string if runtime . GOOS == " " { binaryName = " " } else { return nil } command := [ ] string { binaryName , " " } } 
func Selendroid ( jarFile string , options ... Option ) * WebDriver { absJARPath , err := filepath . Abs ( jarFile ) if err != nil { return nil } command := [ ] string { " " , " " , absJARPath , " " , " " , } options = append ( [ ] Option { Timeout ( 90 ) , Browser ( " " ) } , options ... ) return NewWebDriver ( " " , command , options ... ) } 
func SauceLabs ( name , platform , browser , version , username , accessKey string , options ... Option ) ( * Page , error ) { url := fmt . Sprintf ( " " , username , accessKey ) capabilities := NewCapabilities ( ) . Browser ( browser ) . Platform ( platform ) . Version ( version ) capabilities [ " " ] = name return NewPage ( url , append ( [ ] Option { Desired ( capabilities ) } , options ... ) ... ) } 
func GeckoDriver ( options ... Option ) * WebDriver { var binaryName string if runtime . GOOS == " " { binaryName = " " } else { binaryName = " " } command := [ ] string { binaryName , " " } return NewWebDriver ( " " , command , options ... ) } 
func ( s * Selection ) SwitchToFrame ( ) error { selectedElement , err := s . elements . GetExactlyOne ( ) if err != nil { return fmt . Errorf ( " " , s , err ) } if err := s . session . Frame ( selectedElement . ( * api . Element ) ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } 
func ( s * Selection ) Elements ( ) ( [ ] * api . Element , error ) { elements , err := s . elements . Get ( ) if err != nil { return nil , err } apiElements := [ ] * api . Element { } for _ , selectedElement := range elements { apiElements = append ( apiElements , selectedElement . ( * api . Element ) ) } return apiElements , nil } 
func ( s * Selection ) Count ( ) ( int , error ) { elements , err := s . elements . Get ( ) if err != nil { return 0 , fmt . Errorf ( " " , s , err ) } return len ( elements ) , nil } 
func ( s * Selection ) EqualsElement ( other interface { } ) ( bool , error ) { otherSelection , ok := other . ( * Selection ) if ! ok { multiSelection , ok := other . ( * MultiSelection ) if ! ok { return false , fmt . Errorf ( " " ) } otherSelection = & multiSelection . Selection } selectedElement , err := s . elements . GetExactlyOne ( ) if err != nil { return false , fmt . Errorf ( " " , s , err ) } otherElement , err := otherSelection . elements . GetExactlyOne ( ) if err != nil { return false , fmt . Errorf ( " " , other , err ) } equal , err := selectedElement . IsEqualTo ( otherElement . ( * api . Element ) ) if err != nil { return false , fmt . Errorf ( " " , s , other , err ) } return equal , nil } 
func ( s * Selection ) MouseToElement ( ) error { selectedElement , err := s . elements . GetExactlyOne ( ) if err != nil { return fmt . Errorf ( " " , s , err ) } if err := s . session . MoveTo ( selectedElement . ( * api . Element ) , nil ) ; err != nil { return fmt . Errorf ( " " , s , err ) } return nil } 
func ( v * VerifyRequest ) Validate ( ) error { v . Args = [ ] string { } if len ( v . PactURLs ) != 0 { v . Args = append ( v . Args , v . PactURLs ... ) } if len ( v . PactURLs ) == 0 && v . BrokerURL == " " { return fmt . Errorf ( " " ) } if len ( v . CustomProviderHeaders ) != 0 { for _ , header := range v . CustomProviderHeaders { v . Args = append ( v . Args , " " , header ) } } v . Args = append ( v . Args , " " , " " ) if v . ProviderBaseURL != " " { v . Args = append ( v . Args , " " , v . ProviderBaseURL ) } else { return fmt . Errorf ( " " ) } if v . ProviderStatesSetupURL != " " { v . Args = append ( v . Args , " " , v . ProviderStatesSetupURL ) } if v . BrokerUsername != " " { v . Args = append ( v . Args , " " , v . BrokerUsername ) } if v . BrokerPassword != " " { v . Args = append ( v . Args , " " , v . BrokerPassword ) } if v . BrokerURL != " " && ( ( v . BrokerUsername == " " && v . BrokerPassword != " " ) || ( v . BrokerUsername != " " && v . BrokerPassword == " " ) ) { return errors . New ( " " ) } if v . BrokerURL != " " { v . Args = append ( v . Args , " " , v . BrokerURL ) } if v . BrokerToken != " " { v . Args = append ( v . Args , " " , v . BrokerToken ) } if v . ProviderVersion != " " { v . Args = append ( v . Args , " " , v . ProviderVersion ) } if v . Provider != " " { v . Args = append ( v . Args , " " , v . Provider ) } if v . PublishVerificationResults { v . Args = append ( v . Args , " " , " " ) } if v . Verbose { log . Println ( " " ) } return nil } 
func loggingMiddleware ( next http . Handler ) http . Handler { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { log . Printf ( " \n " , r . RemoteAddr , r . RequestURI ) next . ServeHTTP ( w , r ) } ) } 
func chainHandlers ( mw ... Middleware ) Middleware { return func ( final http . Handler ) http . Handler { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { last := final for i := len ( mw ) - 1 ; i >= 0 ; i -- { last = mw [ i ] ( last ) } last . ServeHTTP ( w , r ) } ) } } 
func HTTPReverseProxy ( options Options ) ( int , error ) { port := options . ProxyPort var err error proxy := httputil . NewSingleHostReverseProxy ( & url . URL { Scheme : options . TargetScheme , Host : options . TargetAddress , } ) if port == 0 { port , err = utils . GetFreePort ( ) if err != nil { log . Println ( " " , err ) return 0 , err } } wrapper := chainHandlers ( append ( options . Middleware , loggingMiddleware ) ... ) log . Println ( " " , port ) go http . ListenAndServe ( fmt . Sprintf ( " " , port ) , wrapper ( proxy ) ) return port , nil } 
func ( i * Installer ) CheckInstallation ( ) error { for binary , versionRange := range versionMap { log . Println ( " " , binary , " " , versionRange ) version , err := i . GetVersionForBinary ( binary ) if err != nil { return err } if err = i . CheckVersion ( binary , version ) ; err != nil { return err } } return nil } 
func ( i * Installer ) CheckVersion ( binary , version string ) error { log . Println ( " " , binary , " " , version ) v , err := goversion . NewVersion ( version ) if err != nil { log . Println ( " " , err ) return err } versionRange , ok := versionMap [ binary ] if ! ok { return fmt . Errorf ( " " , binary ) } log . Println ( " " , v , " " , versionRange ) constraints , err := goversion . NewConstraint ( versionRange ) if constraints . Check ( v ) { log . Println ( " " , v , " " , v , constraints ) return nil } return fmt . Errorf ( " " , version , binary , versionRange ) } 
func ( i * Installer ) GetVersionForBinary ( binary string ) ( version string , err error ) { log . Println ( " " , binary ) content , err := i . commander . Output ( binary , " " ) elements := strings . Split ( strings . TrimSpace ( string ( content ) ) , " \n " ) version = strings . TrimSpace ( elements [ len ( elements ) - 1 ] ) return version , err } 
func ( c * Client ) getUser ( id string ) ( * ex . User , error ) { u := fmt . Sprintf ( " " , c . Host , id ) req , err := http . NewRequest ( " " , u , nil ) req . Header . Set ( " " , c . token ) res , err := http . DefaultClient . Do ( req ) if res . StatusCode != 200 || err != nil { return nil , fmt . Errorf ( " " ) } data , err := ioutil . ReadAll ( res . Body ) if err != nil { return nil , err } var response ex . User err = json . Unmarshal ( data , & response ) if err != nil { return nil , err } return & response , err } 
func ( c * Client ) login ( username string , password string ) ( * ex . User , error ) { loginRequest := fmt . Sprintf ( ` { "username":"%s", "password": "%s" }` , username , password ) res , err := http . Post ( fmt . Sprintf ( " " , c . Host ) , " " , bytes . NewReader ( [ ] byte ( loginRequest ) ) ) if res . StatusCode != 200 || err != nil { return nil , fmt . Errorf ( " " ) } data , err := ioutil . ReadAll ( res . Body ) if err != nil { return nil , err } var response loginResponse err = json . Unmarshal ( data , & response ) if err != nil { return nil , err } return & response . User , err } 
func ( c * Client ) loginHandler ( w http . ResponseWriter , r * http . Request ) { username := r . FormValue ( " " ) password := r . FormValue ( " " ) user , err := c . login ( username , password ) if err == nil && user != nil { c . user = user c . err = nil http . Redirect ( w , r , " " , http . StatusFound ) return } c . err = fmt . Errorf ( " " ) http . Redirect ( w , r , " " , http . StatusFound ) return } 
func ( c * Client ) logoutHandler ( w http . ResponseWriter , r * http . Request ) { c . user = nil c . err = nil http . Redirect ( w , r , " " , http . StatusFound ) return } 
func ( c * Client ) viewHandler ( w http . ResponseWriter , r * http . Request ) { data := templateData { User : c . user , Error : c . err , } renderTemplate ( w , " " , data ) } 
func ( c * Client ) Run ( ) { http . HandleFunc ( " " , c . loginHandler ) http . HandleFunc ( " " , c . logoutHandler ) http . HandleFunc ( " " , c . viewHandler ) fmt . Println ( " " ) http . ListenAndServe ( " " , nil ) } 
func ( i * Interaction ) Given ( state string ) * Interaction { i . State = state return i } 
func ( i * Interaction ) UponReceiving ( description string ) * Interaction { i . Description = description return i } 
func ( i * Interaction ) WithRequest ( request Request ) * Interaction { i . Request = request } return i } 
func ( i * Interaction ) WillRespondWith ( response Response ) * Interaction { i . Response = response return i } 
func isJSONFormattedObject ( stringOrObject interface { } ) bool { switch content := stringOrObject . ( type ) { case [ ] byte : case string : var obj interface { } err := json . Unmarshal ( [ ] byte ( content ) , & obj ) if err != nil { return false } } } return false } 
func ( u * UserRepository ) ByUsername ( username string ) ( * User , error ) { if user , ok := u . Users [ username ] ; ok { return user , nil } return nil , ErrNotFound } 
func ( u * UserRepository ) ByID ( ID int ) ( * User , error ) { for _ , user := range u . Users { if user . ID == ID { return user , nil } } return nil , ErrNotFound } 
func IsAuthenticated ( h http . HandlerFunc ) http . HandlerFunc { return func ( w http . ResponseWriter , r * http . Request ) { if r . Header . Get ( " " ) == fmt . Sprintf ( " " , getAuthToken ( ) ) { h . ServeHTTP ( w , r ) } else { w . Header ( ) . Set ( " " , " " ) w . WriteHeader ( http . StatusUnauthorized ) } } } 
func UserLogin ( w http . ResponseWriter , r * http . Request ) { var login types . LoginRequest w . Header ( ) . Set ( " " , " " ) w . Header ( ) . Set ( " " , " " ) body , err := ioutil . ReadAll ( r . Body ) defer r . Body . Close ( ) if err != nil { w . WriteHeader ( http . StatusServiceUnavailable ) return } err = json . Unmarshal ( body , & login ) if err != nil { w . WriteHeader ( http . StatusServiceUnavailable ) return } user , err := userRepository . ByUsername ( login . Username ) if err != nil { w . WriteHeader ( http . StatusNotFound ) } else if user . Username != login . Username || user . Password != login . Password { w . WriteHeader ( http . StatusUnauthorized ) } else { w . Header ( ) . Set ( " " , getAuthToken ( ) ) w . WriteHeader ( http . StatusOK ) res := types . LoginResponse { User : user } resBody , _ := json . Marshal ( res ) w . Write ( resBody ) } } 
func GetUser ( w http . ResponseWriter , r * http . Request ) { w . Header ( ) . Set ( " " , " " ) w . Header ( ) . Set ( " " , " " ) id , _ := strconv . Atoi ( a [ len ( a ) - 1 ] ) user , err := userRepository . ByID ( id ) if err != nil { w . WriteHeader ( http . StatusNotFound ) } else { w . WriteHeader ( http . StatusOK ) resBody , _ := json . Marshal ( user ) w . Write ( resBody ) } } 
func newClient ( MockServiceManager client . Service , verificationServiceManager client . Service , messageServiceManager client . Service , publishServiceManager client . Service ) * PactClient { MockServiceManager . Setup ( ) verificationServiceManager . Setup ( ) messageServiceManager . Setup ( ) publishServiceManager . Setup ( ) return & PactClient { pactMockSvcManager : MockServiceManager , verificationSvcManager : verificationServiceManager , messageSvcManager : messageServiceManager , publishSvcManager : publishServiceManager , TimeoutDuration : 10 * time . Second , } } 
func NewClient ( ) * PactClient { return newClient ( & client . MockService { } , & client . VerificationService { } , & client . MessageService { } , & client . PublishService { } ) } 
func ( p * PactClient ) StartServer ( args [ ] string , port int ) * types . MockServer { log . Println ( " " , args , " " , port ) args = append ( args , [ ] string { " " , strconv . Itoa ( port ) } ... ) svc := p . pactMockSvcManager . NewService ( args ) cmd := svc . Start ( ) waitForPort ( port , p . getNetworkInterface ( ) , p . Address , p . TimeoutDuration , fmt . Sprintf ( `Timed out waiting for Mock Server to start on port %d - are you sure it's running?` , port ) ) return & types . MockServer { Pid : cmd . Process . Pid , Port : port , } } 
func ( p * PactClient ) ListServers ( ) [ ] * types . MockServer { log . Println ( " " ) var servers [ ] * types . MockServer for port , s := range p . pactMockSvcManager . List ( ) { servers = append ( servers , & types . MockServer { Pid : s . Process . Pid , Port : port , } ) } return servers } 
func ( p * PactClient ) StopServer ( server * types . MockServer ) ( * types . MockServer , error ) { log . Println ( " " ) return server , server . Error } 
func ( p * PactClient ) RemoveAllServers ( server * types . MockServer ) [ ] * types . MockServer { log . Println ( " " ) for _ , s := range p . verificationSvcManager . List ( ) { if s != nil { p . pactMockSvcManager . Stop ( s . Process . Pid ) } } return nil } 
func ( p * PactClient ) VerifyProvider ( request types . VerifyRequest ) ( types . ProviderVerifierResponse , error ) { log . Println ( " " ) var response types . ProviderVerifierResponse if err != nil { return response , err } address := getAddress ( request . ProviderBaseURL ) port := getPort ( request . ProviderBaseURL ) waitForPort ( port , p . getNetworkInterface ( ) , address , p . TimeoutDuration , fmt . Sprintf ( `Timed out waiting for Provider API to start on port %d - are you sure it's running?` , port ) ) cmd := svc . Command ( ) stdOutPipe , err := cmd . StdoutPipe ( ) if err != nil { return response , err } stdErrPipe , err := cmd . StderrPipe ( ) if err != nil { return response , err } err = cmd . Start ( ) if err != nil { return response , err } stdOut , err := ioutil . ReadAll ( stdOutPipe ) if err != nil { return response , err } stdErr , err := ioutil . ReadAll ( stdErrPipe ) if err != nil { return response , err } err = cmd . Wait ( ) var verification types . ProviderVerifierResponse for _ , v := range verifications { v = strings . TrimSpace ( v ) response . Examples = append ( response . Examples , verification . Examples ... ) if dErr != nil { err = dErr } } } if err == nil { return response , err } return response , fmt . Errorf ( " \n \n \n \n \n \n " , err , stdErr , stdOut ) } 
func ( p * PactClient ) UpdateMessagePact ( request types . PactMessageRequest ) error { log . Println ( " " ) if err != nil { return err } svc := p . messageSvcManager . NewService ( request . Args ) cmd := svc . Command ( ) stdOutPipe , err := cmd . StdoutPipe ( ) if err != nil { return err } stdErrPipe , err := cmd . StderrPipe ( ) if err != nil { return err } err = cmd . Start ( ) if err != nil { return err } stdOut , err := ioutil . ReadAll ( stdOutPipe ) if err != nil { return err } stdErr , err := ioutil . ReadAll ( stdErrPipe ) if err != nil { return err } err = cmd . Wait ( ) if err == nil { return nil } return fmt . Errorf ( " \n \n \n \n \n \n " , err , stdErr , stdOut ) } 
func ( p * PactClient ) PublishPacts ( request types . PublishRequest ) error { svc := p . publishSvcManager . NewService ( request . Args ) log . Println ( " " ) cmd := svc . Start ( ) log . Println ( " " ) err := cmd . Wait ( ) log . Println ( " " , err ) return err } 
func ( p * PactClient ) ReifyMessage ( request * types . PactReificationRequest ) ( res * types . ReificationResponse , err error ) { log . Println ( " " ) var responseObject interface { } res = & types . ReificationResponse { Response : responseObject , } if err != nil { return } svc := p . messageSvcManager . NewService ( request . Args ) cmd := svc . Command ( ) stdOutPipe , err := cmd . StdoutPipe ( ) if err != nil { return } stdErrPipe , err := cmd . StderrPipe ( ) if err != nil { return } err = cmd . Start ( ) if err != nil { return } stdOut , err := ioutil . ReadAll ( stdOutPipe ) if err != nil { return } stdErr , err := ioutil . ReadAll ( stdErrPipe ) if err != nil { return } err = cmd . Wait ( ) res . ResponseRaw = stdOut decoder := json . NewDecoder ( bytes . NewReader ( stdOut ) ) dErr := decoder . Decode ( & res . Response ) if dErr == nil { return } if err == nil { err = dErr } if err == nil { return } err = fmt . Errorf ( " \n \n \n \n \n \n " , err , stdErr , stdOut ) return } 
func getPort ( rawURL string ) int { parsedURL , err := url . Parse ( rawURL ) if err == nil { splitHost := strings . Split ( parsedURL . Host , " " ) if len ( splitHost ) == 2 { port , err := strconv . Atoi ( splitHost [ 1 ] ) if err == nil { return port } } if parsedURL . Scheme == " " { return 443 } return 80 } return - 1 } 
func getAddress ( rawURL string ) string { parsedURL , err := url . Parse ( rawURL ) if err != nil { return " " } splitHost := strings . Split ( parsedURL . Host , " " ) return splitHost [ 0 ] } 
func sanitiseRubyResponse ( response string ) string { log . Println ( " " , response ) r := regexp . MustCompile ( " \\ " ) s := r . ReplaceAllString ( response , " " ) r = regexp . MustCompile ( " " ) s = r . ReplaceAllString ( s , " " ) r = regexp . MustCompile ( " \\ " ) s = r . ReplaceAllString ( s , " \n " ) return s } 
func ( s * ServiceMock ) Stop ( pid int ) ( bool , error ) { s . ServiceStopCount ++ return s . ServiceStopResult , s . ServiceStopError } 
func ( s * ServiceMock ) Start ( ) * exec . Cmd { s . ServiceStartCount ++ cmd := s . ExecFunc ( ) cmd . Start ( ) if s . processes == nil { s . processes = make ( map [ int ] * exec . Cmd ) } s . processes [ cmd . Process . Pid ] = cmd return cmd } 
func ( v * PublishService ) NewService ( args [ ] string ) Service { log . Printf ( " \n " , args ) v . Args = [ ] string { " " , } v . Args = append ( v . Args , args ... ) v . Cmd = getPublisherCommandPath ( ) return v } 
func ( v * MessageService ) NewService ( args [ ] string ) Service { v . Args = args log . Printf ( " \n " , v . Args ) v . Cmd = " " return v } 
func ( m * PactReificationRequest ) Validate ( ) error { m . Args = [ ] string { } body , err := json . Marshal ( m . Message ) if err != nil { return err } m . Args = append ( m . Args , [ ] string { " " , string ( body ) , } ... ) return nil } 
func ( p * Publisher ) Publish ( request types . PublishRequest ) error { log . Println ( " " ) if p . pactClient == nil { c := NewClient ( ) p . pactClient = c } err := request . Validate ( ) if err != nil { return err } return p . pactClient . PublishPacts ( request ) } 
func ( p * PublishRequest ) Validate ( ) error { p . Args = [ ] string { } if len ( p . PactURLs ) != 0 { p . Args = append ( p . Args , p . PactURLs ... ) } else { return fmt . Errorf ( " " ) } if p . BrokerUsername != " " { p . Args = append ( p . Args , " " , p . BrokerUsername ) } if p . BrokerPassword != " " { p . Args = append ( p . Args , " " , p . BrokerPassword ) } if p . PactBroker != " " && ( ( p . BrokerUsername == " " && p . BrokerPassword != " " ) || ( p . BrokerUsername != " " && p . BrokerPassword == " " ) ) { return errors . New ( " " ) } if p . PactBroker == " " { return fmt . Errorf ( " " ) } p . Args = append ( p . Args , " " , p . PactBroker ) if p . BrokerToken != " " { p . Args = append ( p . Args , " " , p . BrokerToken ) } if p . ConsumerVersion == " " { return fmt . Errorf ( " " ) } p . Args = append ( p . Args , " " , p . ConsumerVersion ) if len ( p . Tags ) > 0 { for _ , t := range p . Tags { p . Args = append ( p . Args , " " , t ) } } if p . Verbose { p . Args = append ( p . Args , " " ) } return nil } 
func ( v * VerifyMessageRequest ) Validate ( ) error { v . Args = [ ] string { } if len ( v . PactURLs ) != 0 { v . Args = append ( v . Args , v . PactURLs ... ) } else { return fmt . Errorf ( " " ) } v . Args = append ( v . Args , " " , " " ) if v . BrokerUsername != " " { v . Args = append ( v . Args , " " , v . BrokerUsername ) } if v . BrokerPassword != " " { v . Args = append ( v . Args , " " , v . BrokerPassword ) } if v . ProviderVersion != " " { v . Args = append ( v . Args , " " , v . ProviderVersion ) } if v . PublishVerificationResults { v . Args = append ( v . Args , " " , " " ) } return nil } 
func FindPortInRange ( s string ) ( int , error ) { for _ , p := range ports { i , err := strconv . Atoi ( p ) if err != nil { return 0 , err } err = checkPort ( i ) if err != nil { continue } return i , nil } return 0 , errors . New ( " " ) } if len ( ports ) != 2 { return 0 , errors . New ( " " ) } lower , err := strconv . Atoi ( ports [ 0 ] ) if err != nil { return 0 , err } upper , err := strconv . Atoi ( ports [ 1 ] ) if err != nil { return 0 , err } if upper < lower { return 0 , errors . New ( " " ) } for i := lower ; i <= upper ; i ++ { err = checkPort ( i ) if err != nil { continue } return i , nil } return 0 , errors . New ( " " ) } 
func EachLike ( content interface { } , minRequired int ) Matcher { return eachLike { Contents : content , Min : minRequired , } } 
func Term ( generate string , matcher string ) Matcher { return term { Data : termData { Generate : generate , Matcher : termMatcher { Type : " " , O : 0 , Regex : matcher , } , } , } } 
func ( m * MapMatcher ) UnmarshalJSON ( bytes [ ] byte ) ( err error ) { sk := make ( map [ string ] string ) err = json . Unmarshal ( bytes , & sk ) if err != nil { return } * m = make ( map [ string ] Matcher ) for k , v := range sk { ( * m ) [ k ] = String ( v ) } return } 
func objectToString ( obj interface { } ) string { switch content := obj . ( type ) { case string : return content default : jsonString , err := json . Marshal ( obj ) if err != nil { log . Println ( " " , err . Error ( ) ) return " " } return string ( jsonString ) } } 
func match ( srcType reflect . Type , params params ) Matcher { switch kind := srcType . Kind ( ) ; kind { case reflect . Ptr : return match ( srcType . Elem ( ) , params ) case reflect . Slice , reflect . Array : return EachLike ( match ( srcType . Elem ( ) , getDefaults ( ) ) , params . slice . min ) case reflect . Struct : result := StructMatcher { } for i := 0 ; i < srcType . NumField ( ) ; i ++ { field := srcType . Field ( i ) result [ field . Tag . Get ( " " ) ] = match ( field . Type , pluckParams ( field . Type , field . Tag . Get ( " " ) ) ) } return result case reflect . String : if params . str . regEx != " " { return Term ( params . str . example , params . str . regEx ) } if params . str . example != " " { return Like ( params . str . example ) } return Like ( " " ) case reflect . Bool : return Like ( true ) case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 , reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 : return Like ( 1 ) case reflect . Float32 , reflect . Float64 : return Like ( 1.1 ) default : panic ( fmt . Sprintf ( " " , srcType ) ) } } 
func pluckParams ( srcType reflect . Type , pactTag string ) params { params := getDefaults ( ) if pactTag == " " { return params } switch kind := srcType . Kind ( ) ; kind { case reflect . Slice : if _ , err := fmt . Sscanf ( pactTag , " " , & params . slice . min ) ; err != nil { triggerInvalidPactTagPanic ( pactTag , err ) } case reflect . String : fullRegex , _ := regexp . Compile ( `regex=(.*)$` ) exampleRegex , _ := regexp . Compile ( `^example=(.*)` ) if fullRegex . Match ( [ ] byte ( pactTag ) ) { components := strings . Split ( pactTag , " " ) if len ( components [ 1 ] ) == 0 { triggerInvalidPactTagPanic ( pactTag , fmt . Errorf ( " " ) ) } if _ , err := fmt . Sscanf ( components [ 0 ] , " " , & params . str . example ) ; err != nil { triggerInvalidPactTagPanic ( pactTag , err ) } params . str . regEx = strings . Replace ( components [ 1 ] , `\` , `\\` , - 1 ) } else if exampleRegex . Match ( [ ] byte ( pactTag ) ) { components := strings . Split ( pactTag , " " ) if len ( components ) != 2 || strings . TrimSpace ( components [ 1 ] ) == " " { triggerInvalidPactTagPanic ( pactTag , fmt . Errorf ( " " ) ) } params . str . example = components [ 1 ] } } return params } 
func ( p * Pact ) AddMessage ( ) * Message { log . Println ( " " ) m := & Message { } p . MessageInteractions = append ( p . MessageInteractions , m ) return m } 
func ( p * Pact ) AddInteraction ( ) * Interaction { p . Setup ( true ) log . Println ( " " ) i := & Interaction { } p . Interactions = append ( p . Interactions , i ) return i } 
func ( p * Pact ) Setup ( startMockServer bool ) * Pact { p . setupLogging ( ) log . Println ( " " ) dir , _ := os . Getwd ( ) if p . Network == " " { p . Network = " " } if ! p . toolValidityCheck && ! ( p . DisableToolValidityCheck || os . Getenv ( " " ) != " " ) { checkCliCompatibility ( ) p . toolValidityCheck = true } if p . Host == " " { p . Host = " " } if p . LogDir == " " { p . LogDir = fmt . Sprintf ( filepath . Join ( dir , " " ) ) } if p . PactDir == " " { p . PactDir = fmt . Sprintf ( filepath . Join ( dir , " " ) ) } if p . SpecificationVersion == 0 { p . SpecificationVersion = 2 } if p . ClientTimeout == 0 { p . ClientTimeout = 10 * time . Second } if p . pactClient == nil { c := NewClient ( ) c . TimeoutDuration = p . ClientTimeout p . pactClient = c } if p . PactFileWriteMode == " " { p . PactFileWriteMode = " " } var perr error if p . AllowedMockServerPorts != " " { port , perr = utils . FindPortInRange ( p . AllowedMockServerPorts ) } else { port , perr = utils . GetFreePort ( ) } if perr != nil { log . Println ( " " ) } if p . Server == nil && startMockServer { log . Println ( " " , port ) args := [ ] string { " " , fmt . Sprintf ( " " , p . SpecificationVersion ) , " " , filepath . FromSlash ( p . PactDir ) , " " , filepath . FromSlash ( p . LogDir + " " + " " ) , " " , p . Consumer , " " , p . Provider , " " , p . PactFileWriteMode , } p . Server = p . pactClient . StartServer ( args , port ) } return p } 
func ( p * Pact ) setupLogging ( ) { if p . logFilter == nil { if p . LogLevel == " " { p . LogLevel = " " } p . logFilter = & logutils . LevelFilter { Levels : [ ] logutils . LogLevel { " " , " " , " " , " " } , MinLevel : logutils . LogLevel ( p . LogLevel ) , Writer : os . Stderr , } log . SetOutput ( p . logFilter ) } log . Println ( " " ) } 
func ( p * Pact ) Teardown ( ) * Pact { log . Println ( " " ) if p . Server != nil { server , err := p . pactClient . StopServer ( p . Server ) if err != nil { log . Println ( " " , err ) } p . Server = server } return p } 
func ( p * Pact ) Verify ( integrationTest func ( ) error ) error { p . Setup ( true ) log . Println ( " " ) } mockServer := & MockService { BaseURL : fmt . Sprintf ( " " , p . Host , p . Server . Port ) , Consumer : p . Consumer , Provider : p . Provider , } for _ , interaction := range p . Interactions { err := mockServer . AddInteraction ( interaction ) if err != nil { return err } } if err != nil { return err } if err != nil { return err } return mockServer . DeleteInteractions ( ) } 
func ( p * Pact ) WritePact ( ) error { p . Setup ( true ) log . Println ( " " ) mockServer := MockService { BaseURL : fmt . Sprintf ( " " , p . Host , p . Server . Port ) , Consumer : p . Consumer , Provider : p . Provider , PactFileWriteMode : p . PactFileWriteMode , } err := mockServer . WritePact ( ) if err != nil { return err } return nil } 
func ( p * Pact ) VerifyProviderRaw ( request types . VerifyRequest ) ( types . ProviderVerifierResponse , error ) { p . Setup ( false ) var res types . ProviderVerifierResponse u , err := url . Parse ( request . ProviderBaseURL ) if err != nil { return res , err } m := [ ] proxy . Middleware { } if request . BeforeEach != nil { m = append ( m , BeforeEachMiddleware ( request . BeforeEach ) ) } if request . AfterEach != nil { m = append ( m , AfterEachMiddleware ( request . AfterEach ) ) } if len ( request . StateHandlers ) > 0 { m = append ( m , stateHandlerMiddleware ( request . StateHandlers ) ) } if request . RequestFilter != nil { m = append ( m , request . RequestFilter ) } if request . ProviderStatesSetupURL == " " { setupURL = fmt . Sprintf ( " " , u . Scheme , port ) } if request . Provider == " " { verificationRequest . Provider = p . Provider } portErr := waitForPort ( port , " " , " " , p . ClientTimeout , fmt . Sprintf ( `Timed out waiting for http verification proxy on port %d - check for errors` , port ) ) if portErr != nil { log . Fatal ( " " , err ) return res , portErr } log . Println ( " " ) return p . pactClient . VerifyProvider ( verificationRequest ) } 
func ( p * Pact ) VerifyProvider ( t * testing . T , request types . VerifyRequest ) ( types . ProviderVerifierResponse , error ) { res , err := p . VerifyProviderRaw ( request ) for _ , example := range res . Examples { t . Run ( example . Description , func ( st * testing . T ) { st . Log ( example . FullDescription ) if example . Status != " " { t . Errorf ( " \n \n " , example . FullDescription , example . Exception . Message ) } } ) } return res , err } 
func AfterEachMiddleware ( AfterEach types . Hook ) proxy . Middleware { return func ( next http . Handler ) http . Handler { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { next . ServeHTTP ( w , r ) if r . URL . Path != " " { log . Println ( " " ) err := AfterEach ( ) if err != nil { log . Println ( " " , err ) w . WriteHeader ( http . StatusInternalServerError ) } } } ) } } 
func stateHandlerMiddleware ( stateHandlers types . StateHandlers ) proxy . Middleware { return func ( next http . Handler ) http . Handler { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { if r . URL . Path == " " { var s * types . ProviderState decoder := json . NewDecoder ( r . Body ) decoder . Decode ( & s ) if ! stateFound { log . Printf ( " " , state ) } else { w . WriteHeader ( http . StatusInternalServerError ) return } } } w . WriteHeader ( http . StatusOK ) return } log . Println ( " " , r . RequestURI ) } ) } } 
func ( p * Pact ) VerifyMessageProvider ( t * testing . T , request VerifyMessageRequest ) ( res types . ProviderVerifierResponse , err error ) { res , err = p . VerifyMessageProviderRaw ( request ) for _ , example := range res . Examples { t . Run ( example . Description , func ( st * testing . T ) { st . Log ( example . FullDescription ) if example . Status != " " { st . Errorf ( " \n " , example . Exception . Message ) st . Error ( " " ) } } ) } return } 
func ( p * Pact ) VerifyMessageProviderRaw ( request VerifyMessageRequest ) ( types . ProviderVerifierResponse , error ) { p . Setup ( false ) response := types . ProviderVerifierResponse { } port , err := utils . GetFreePort ( ) if err != nil { return response , fmt . Errorf ( " " , err ) } mux . HandleFunc ( " " , messageVerificationHandler ( request . MessageHandlers , request . StateHandlers ) ) ln , err := net . Listen ( " " , fmt . Sprintf ( " " , port ) ) if err != nil { log . Fatal ( err ) } defer ln . Close ( ) log . Printf ( " " , port , ln . Addr ( ) ) go http . Serve ( ln , mux ) portErr := waitForPort ( port , " " , " " , p . ClientTimeout , fmt . Sprintf ( `Timed out waiting for pact proxy on port %d - check for errors` , port ) ) if portErr != nil { log . Fatal ( " " , err ) return response , portErr } log . Println ( " " ) return p . pactClient . VerifyProvider ( verificationRequest ) } 
func ( p * Pact ) VerifyMessageConsumerRaw ( message * Message , handler MessageConsumer ) error { log . Printf ( " " ) p . Setup ( false ) if err != nil { return fmt . Errorf ( " " , err ) } t := reflect . TypeOf ( message . Type ) if t != nil && t . Name ( ) != " " { log . Println ( " " , t . Name ( ) ) err = json . Unmarshal ( reified . ResponseRaw , & message . Type ) if err != nil { return fmt . Errorf ( " " , t . Name ( ) , err ) } } err = handler ( generatedMessage ) if err != nil { return err } } 
func ( p * Pact ) VerifyMessageConsumer ( t * testing . T , message * Message , handler MessageConsumer ) error { err := p . VerifyMessageConsumerRaw ( message , handler ) if err != nil { t . Errorf ( " " , err ) } return err } 
func ( p * mockClient ) StartServer ( args [ ] string , port int ) * types . MockServer { return p . MockServer } 
func ( p * mockClient ) StopServer ( server * types . MockServer ) ( * types . MockServer , error ) { return p . StopServerResponse , p . StopServerError } 
func ( p * mockClient ) RemoveAllServers ( server * types . MockServer ) [ ] * types . MockServer { return p . RemoveAllServersResponse } 
func ( p * mockClient ) VerifyProvider ( request types . VerifyRequest ) ( types . ProviderVerifierResponse , error ) { return p . VerifyProviderResponse , p . VerifyProviderError } 
func ( p * mockClient ) ReifyMessage ( request * types . PactReificationRequest ) ( res * types . ReificationResponse , err error ) { return p . ReifyMessageResponse , p . ReifyMessageError } 
func ( m * MockService ) NewService ( args [ ] string ) Service { m . Args = [ ] string { " " , } m . Args = append ( m . Args , args ... ) m . Cmd = getMockServiceCommandPath ( ) return m } 
func ( s * ServiceManager ) Setup ( ) { log . Println ( " " ) s . commandCreatedChan = make ( chan * exec . Cmd ) s . commandCompleteChan = make ( chan * exec . Cmd ) s . processMap = processMap { processes : make ( map [ int ] * exec . Cmd ) } go s . removeServiceMonitor ( ) } 
func ( s * ServiceManager ) addServiceMonitor ( ) { log . Println ( " " ) for { select { case p := <- s . commandCreatedChan : if p != nil && p . Process != nil { s . processMap . Set ( p . Process . Pid , p ) } } } } 
func ( s * ServiceManager ) removeServiceMonitor ( ) { log . Println ( " " ) var p * exec . Cmd for { select { case p = <- s . commandCompleteChan : if p != nil && p . Process != nil { p . Process . Signal ( os . Interrupt ) s . processMap . Delete ( p . Process . Pid ) } } } } 
func ( s * ServiceManager ) Stop ( pid int ) ( bool , error ) { log . Println ( " " , pid ) cmd := s . processMap . Get ( pid ) } ( ) done := make ( chan error , 1 ) go func ( ) { done <- cmd . Wait ( ) } ( ) select { case <- time . After ( 3 * time . Second ) : if err = cmd . Process . Kill ( ) ; err != nil { log . Println ( " " , pid ) return false , err } case err = <- done : if err != nil { log . Println ( " " , err ) return false , err } } return true , nil } 
func ( s * ServiceManager ) List ( ) map [ int ] * exec . Cmd { log . Println ( " " ) return s . processMap . processes } 
func ( s * ServiceManager ) Command ( ) * exec . Cmd { cmd := exec . Command ( s . Cmd , s . Args ... ) env := os . Environ ( ) env = append ( env , s . Env ... ) cmd . Env = env return cmd } 
func ( s * ServiceManager ) Start ( ) * exec . Cmd { log . Println ( " " ) cmd := exec . Command ( s . Cmd , s . Args ... ) env := os . Environ ( ) env = append ( env , s . Env ... ) cmd . Env = env cmdReader , err := cmd . StdoutPipe ( ) if err != nil { log . Printf ( " \n " , err . Error ( ) ) } cmdReaderErr , err := cmd . StderrPipe ( ) if err != nil { log . Printf ( " \n " , err . Error ( ) ) } scanner := bufio . NewScanner ( cmdReader ) go func ( ) { for scanner . Scan ( ) { log . Printf ( " \n " , scanner . Text ( ) ) } } ( ) scanner2 := bufio . NewScanner ( cmdReaderErr ) go func ( ) { for scanner2 . Scan ( ) { log . Printf ( " \n " , scanner2 . Text ( ) ) } } ( ) err = cmd . Start ( ) if err != nil { log . Println ( " " , err . Error ( ) ) } return cmd } 
func ( m * MockService ) call ( method string , url string , content interface { } ) error { body , err := json . Marshal ( content ) if err != nil { fmt . Println ( err ) return err } client := & http . Client { } var req * http . Request if method == " " { req , err = http . NewRequest ( method , url , bytes . NewReader ( body ) ) } else { req , err = http . NewRequest ( method , url , nil ) } if err != nil { return err } req . Header . Set ( " " , " " ) req . Header . Set ( " " , " " ) res , err := client . Do ( req ) if err != nil { return err } responseBody , err := ioutil . ReadAll ( res . Body ) res . Body . Close ( ) if res . StatusCode < 200 || res . StatusCode >= 300 { return errors . New ( string ( responseBody ) ) } return err } 
func ( m * MockService ) DeleteInteractions ( ) error { log . Println ( " " ) url := fmt . Sprintf ( " " , m . BaseURL ) return m . call ( " " , url , nil ) } 
func ( m * MockService ) AddInteraction ( interaction * Interaction ) error { log . Println ( " " ) url := fmt . Sprintf ( " " , m . BaseURL ) return m . call ( " " , url , interaction ) } 
func ( m * MockService ) WritePact ( ) error { log . Println ( " " ) if m . Consumer == " " || m . Provider == " " { return errors . New ( " " ) } if m . PactFileWriteMode == " " { m . PactFileWriteMode = " " } pact := map [ string ] interface { } { " " : map [ string ] string { " " : m . Consumer , } , " " : map [ string ] string { " " : m . Provider , } , " " : m . PactFileWriteMode , } url := fmt . Sprintf ( " " , m . BaseURL ) return m . call ( " " , url , pact ) } 
func ( p * Message ) Given ( state string ) * Message { p . States = [ ] State { State { Name : state } } return p } 
func ( p * Message ) ExpectsToReceive ( description string ) * Message { p . Description = description return p } 
func ( p * Message ) WithMetadata ( metadata MapMatcher ) * Message { p . Metadata = metadata return p } 
func ( p * Message ) AsType ( t interface { } ) * Message { fmt . Println ( " " , reflect . TypeOf ( t ) ) p . Type = t return p } 
func IsAuthenticated ( ) gin . HandlerFunc { return func ( c * gin . Context ) { fmt . Println ( c . GetHeader ( " " ) ) if c . GetHeader ( " " ) == fmt . Sprintf ( " " , getAuthToken ( ) ) { c . Next ( ) } else { c . JSON ( http . StatusUnauthorized , gin . H { " " : " " } ) } } } 
func UserLogin ( c * gin . Context ) { c . Header ( " " , " " ) var json Login if c . BindJSON ( & json ) == nil { user , err := userRepository . ByUsername ( json . User ) if err != nil { c . JSON ( http . StatusNotFound , gin . H { " " : " " } ) } else if user . Username != json . User || user . Password != json . Password { c . JSON ( http . StatusUnauthorized , gin . H { " " : " " } ) } else { c . Header ( " " , getAuthToken ( ) ) c . JSON ( http . StatusOK , types . LoginResponse { User : user } ) } } } 
func GetUser ( c * gin . Context ) { fmt . Println ( " " ) c . Header ( " " , " " ) id , _ := strconv . Atoi ( c . Param ( " " ) ) user , err := userRepository . ByID ( id ) if err != nil { c . JSON ( http . StatusNotFound , gin . H { " " : " " } ) } else { c . JSON ( http . StatusOK , user ) } } 
func ( m * PactMessageRequest ) Validate ( ) error { m . Args = [ ] string { } body , err := json . Marshal ( m . Message ) if err != nil { return err } m . Args = append ( m . Args , [ ] string { " " , string ( body ) , " " , m . Consumer , " " , m . Provider , " " , m . PactDir , " " , " " , } ... ) return nil } 
func ( v * VerificationService ) NewService ( args [ ] string ) Service { log . Printf ( " \n " , args ) v . Args = args v . Cmd = getVerifierCommandPath ( ) v . Env = append ( os . Environ ( ) , `PACT_INTERACTION_RERUN_COMMAND="To re-run this specific test, set the following environment variables and run your test again: PACT_DESCRIPTION=\"<PACT_DESCRIPTION>\" PACT_PROVIDER_STATE=\"<PACT_PROVIDER_STATE>\""` ) return v } 
func ( s * S3 ) Region ( ) string { region := os . Getenv ( " " ) switch s . Domain { case " " , " " : return " " case " " : if region == " " { panic ( " " ) } return region default : regions := regionMatcher . FindStringSubmatch ( s . Domain ) if len ( regions ) < 2 { if region == " " { panic ( " " ) } return region } return regions [ 1 ] } } 
func New ( domain string , keys Keys ) * S3 { if domain == " " { domain = DefaultDomain } return & S3 { domain , keys } } 
func ( s * S3 ) Bucket ( name string ) * Bucket { return & Bucket { S3 : s , Name : name , Config : DefaultConfig , } } 
func ( b * Bucket ) GetReader ( path string , c * Config ) ( r io . ReadCloser , h http . Header , err error ) { if path == " " { return nil , nil , errors . New ( " " ) } if c == nil { c = b . conf ( ) } u , err := b . url ( path , c ) if err != nil { return nil , nil , err } return newGetter ( * u , c , b ) } 
func ( b * Bucket ) PutWriter ( path string , h http . Header , c * Config ) ( w io . WriteCloser , err error ) { if c == nil { c = b . conf ( ) } u , err := b . url ( path , c ) if err != nil { return nil , err } return newPutter ( * u , h , c , b ) } 
func ( b * Bucket ) url ( bPath string , c * Config ) ( * url . URL , error ) { if err != nil { return nil , err } var vals url . Values if v := purl . Query ( ) . Get ( versionParam ) ; v != " " { vals = make ( url . Values ) vals . Add ( versionParam , v ) bPath = strings . Split ( bPath , " " ) [ 0 ] } } else { return & url . URL { Scheme : c . Scheme , Path : path . Clean ( fmt . Sprintf ( " " , bPath ) ) , Host : path . Clean ( fmt . Sprintf ( " " , b . Name , b . S3 . Domain ) ) , RawQuery : vals . Encode ( ) , } , nil } } 
func ( b * Bucket ) Delete ( path string ) error { if err := b . delete ( path ) ; err != nil { return err } } } logger . Printf ( " \n " , path , b . Name ) return nil } 
func SetLogger ( out io . Writer , prefix string , flag int , debug bool ) { logger = internalLogger { log . New ( out , prefix , flag ) , debug , } } 
func init ( ) { logger = internalLogger { log . New ( ioutil . Discard , " " , log . LstdFlags ) , false , } } 
func InstanceKeys ( ) ( keys Keys , err error ) { rolePath := " " var creds mdCreds if err != nil { return } defer checkClose ( resp . Body , err ) if resp . StatusCode != 200 { err = newRespError ( resp ) return } role , err := ioutil . ReadAll ( resp . Body ) if err != nil { return } if err != nil { return } defer checkClose ( resp . Body , err ) if resp . StatusCode != 200 { err = newRespError ( resp ) return } metadata , err := ioutil . ReadAll ( resp . Body ) if err != nil { return } if err = json . Unmarshal ( [ ] byte ( metadata ) , & creds ) ; err != nil { return } keys = Keys { AccessKey : creds . AccessKeyID , SecretKey : creds . SecretAccessKey , SecurityToken : creds . Token , } return } 
func EnvKeys ( ) ( keys Keys , err error ) { keys = Keys { AccessKey : os . Getenv ( " " ) , SecretKey : os . Getenv ( " " ) , SecurityToken : os . Getenv ( " " ) , } if keys . AccessKey == " " || keys . SecretKey == " " { err = fmt . Errorf ( " " ) } return } 
func ClientWithTimeout ( timeout time . Duration ) * http . Client { transport := & http . Transport { Proxy : http . ProxyFromEnvironment , Dial : func ( netw , addr string ) ( net . Conn , error ) { c , err := net . DialTimeout ( netw , addr , timeout ) if err != nil { return nil , err } if tc , ok := c . ( * net . TCPConn ) ; ok { tc . SetKeepAlive ( true ) tc . SetKeepAlivePeriod ( timeout ) } return & deadlineConn { timeout , c } , nil } , ResponseHeaderTimeout : timeout , MaxIdleConnsPerHost : 10 , } return & http . Client { Transport : transport } } 
func ( b * Bucket ) Sign ( req * http . Request ) { if req . Header == nil { req . Header = http . Header { } } if b . S3 . Keys . SecurityToken != " " { req . Header . Set ( " " , b . S3 . Keys . SecurityToken ) } req . Header . Set ( " " , " " ) s := & signer { Time : time . Now ( ) , Request : req , Region : b . S3 . Region ( ) , Keys : b . S3 . Keys , } s . sign ( ) } 
func getAWSKeys ( ) ( keys s3gof3r . Keys , err error ) { keys , err = s3gof3r . EnvKeys ( ) if err == nil { return } keys , err = s3gof3r . InstanceKeys ( ) if err == nil { return } err = errors . New ( " " ) return } 
func homeDir ( ) ( string , error ) { if h := os . Getenv ( " " ) ; h != " " { return h , nil } h , err := exec . Command ( " " , " " , " " ) . Output ( ) if err == nil && len ( h ) > 0 { return strings . TrimSpace ( string ( h ) ) , nil } return " " , fmt . Errorf ( " " ) } 
func ACL ( h http . Header , acl string ) http . Header { if acl != " " { h . Set ( " " , acl ) } return h } 
func newPutter ( url url . URL , h http . Header , c * Config , b * Bucket ) ( p * putter , err error ) { p = new ( putter ) p . url = url p . c , p . b = new ( Config ) , new ( Bucket ) * p . c , * p . b = * c , * b p . c . Concurrency = max ( c . Concurrency , 1 ) p . c . NTry = max ( c . NTry , 1 ) p . bufsz = max64 ( minPartSize , c . PartSize ) resp , err := p . retryRequest ( " " , url . String ( ) + " " , nil , h ) if err != nil { return nil , err } defer checkClose ( resp . Body , err ) if resp . StatusCode != 200 { return nil , newRespError ( resp ) } err = xml . NewDecoder ( resp . Body ) . Decode ( p ) if err != nil { return nil , err } p . ch = make ( chan * part ) for i := 0 ; i < p . c . Concurrency ; i ++ { go p . worker ( ) } p . md5OfParts = md5 . New ( ) p . md5 = md5 . New ( ) p . sp = bufferPool ( p . bufsz ) return p , nil } 
func ( p * putter ) retryPutPart ( part * part ) { defer p . wg . Done ( ) var err error for i := 0 ; i < p . c . NTry ; i ++ { err = p . putPart ( part ) if err == nil { p . sp . give <- part . b part . b = nil return } logger . debugPrintf ( " " , i , part . PartNumber , err ) time . Sleep ( time . Duration ( math . Exp2 ( float64 ( i ) ) ) * 100 * time . Millisecond ) } p . err = err } 
func ( p * putter ) putPart ( part * part ) error { v := url . Values { } v . Set ( " " , strconv . Itoa ( part . PartNumber ) ) v . Set ( " " , p . UploadID ) if _ , err := part . r . Seek ( 0 , 0 ) ; err != nil { } req , err := http . NewRequest ( " " , p . url . String ( ) + " " + v . Encode ( ) , part . r ) if err != nil { return err } req . ContentLength = part . len req . Header . Set ( md5Header , part . md5 ) req . Header . Set ( sha256Header , part . sha256 ) p . b . Sign ( req ) resp , err := p . c . Client . Do ( req ) if err != nil { return err } defer checkClose ( resp . Body , err ) if resp . StatusCode != 200 { return newRespError ( resp ) } s := resp . Header . Get ( " " ) if len ( s ) < 2 { return fmt . Errorf ( " " , s ) } s = s [ 1 : len ( s ) - 1 ] if part . ETag != s { return fmt . Errorf ( " " , s , p . ETag ) } return nil } 
func ( p * putter ) abort ( ) { v := url . Values { } v . Set ( " " , p . UploadID ) s := p . url . String ( ) + " " + v . Encode ( ) resp , err := p . retryRequest ( " " , s , nil , nil ) if err != nil { logger . Printf ( " \n " , err ) return } defer checkClose ( resp . Body , err ) if resp . StatusCode != 204 { logger . Printf ( " " , newRespError ( resp ) ) } return } 
func ( p * putter ) hashContent ( r io . ReadSeeker ) ( string , string , string , error ) { m := md5 . New ( ) s := sha256 . New ( ) mw := io . MultiWriter ( m , s , p . md5 ) if _ , err := io . Copy ( mw , r ) ; err != nil { return " " , " " , " " , err } md5Sum := m . Sum ( nil ) shaSum := hex . EncodeToString ( s . Sum ( nil ) ) etag := hex . EncodeToString ( md5Sum ) } return base64 . StdEncoding . EncodeToString ( md5Sum ) , shaSum , etag , nil } 
func ( p * putter ) putMd5 ( ) ( err error ) { calcMd5 := fmt . Sprintf ( " " , p . md5 . Sum ( nil ) ) md5Reader := strings . NewReader ( calcMd5 ) md5Path := fmt . Sprint ( " " , p . url . Path , " " ) md5Url , err := p . b . url ( md5Path , p . c ) if err != nil { return err } logger . debugPrintln ( " " , calcMd5 ) logger . debugPrintln ( " " , md5Path ) r , err := http . NewRequest ( " " , md5Url . String ( ) , md5Reader ) if err != nil { return } p . b . Sign ( r ) resp , err := p . c . Client . Do ( r ) if err != nil { return } defer checkClose ( resp . Body , err ) if resp . StatusCode != 200 { return newRespError ( resp ) } return } 
func growPartSize ( partIndex int , partSize , putsz int64 ) bool { return ( maxObjSize - putsz ) / ( maxNPart - int64 ( partIndex ) ) > partSize } 
func gatherInfo ( prefix string , spec interface { } ) ( [ ] varInfo , error ) { s := reflect . ValueOf ( spec ) if s . Kind ( ) != reflect . Ptr { return nil , ErrInvalidSpecification } s = s . Elem ( ) if s . Kind ( ) != reflect . Struct { return nil , ErrInvalidSpecification } typeOfSpec := s . Type ( ) for i := 0 ; i < s . NumField ( ) ; i ++ { f := s . Field ( i ) ftype := typeOfSpec . Field ( i ) if ! f . CanSet ( ) || isTrue ( ftype . Tag . Get ( " " ) ) { continue } for f . Kind ( ) == reflect . Ptr { if f . IsNil ( ) { if f . Type ( ) . Elem ( ) . Kind ( ) != reflect . Struct { } } f = f . Elem ( ) } if len ( words ) > 0 { var name [ ] string for _ , words := range words { name = append ( name , words [ 0 ] ) } info . Key = strings . Join ( name , " " ) } } if info . Alt != " " { info . Key = info . Alt } if prefix != " " { info . Key = fmt . Sprintf ( " " , prefix , info . Key ) } info . Key = strings . ToUpper ( info . Key ) infos = append ( infos , info ) if f . Kind ( ) == reflect . Struct { if ! ftype . Anonymous { innerPrefix = info . Key } embeddedPtr := f . Addr ( ) . Interface ( ) embeddedInfos , err := gatherInfo ( innerPrefix , embeddedPtr ) if err != nil { return nil , err } infos = append ( infos [ : len ( infos ) - 1 ] , embeddedInfos ... ) continue } } } return infos , nil } 
func CheckDisallowed ( prefix string , spec interface { } ) error { infos , err := gatherInfo ( prefix , spec ) if err != nil { return err } vars := make ( map [ string ] struct { } ) for _ , info := range infos { vars [ info . Key ] = struct { } { } } if prefix != " " { prefix = strings . ToUpper ( prefix ) + " " } for _ , env := range os . Environ ( ) { if ! strings . HasPrefix ( env , prefix ) { continue } v := strings . SplitN ( env , " " , 2 ) [ 0 ] if _ , found := vars [ v ] ; ! found { return fmt . Errorf ( " " , v ) } } return nil } 
func Process ( prefix string , spec interface { } ) error { infos , err := gatherInfo ( prefix , spec ) for _ , info := range infos { if ! ok && info . Alt != " " { value , ok = lookupEnv ( info . Alt ) } def := info . Tags . Get ( " " ) if def != " " && ! ok { value = def } req := info . Tags . Get ( " " ) if ! ok && def == " " { if isTrue ( req ) { return fmt . Errorf ( " " , info . Key ) } continue } err = processField ( value , info . Field ) if err != nil { return & ParseError { KeyName : info . Key , FieldName : info . Name , TypeName : info . Field . Type ( ) . String ( ) , Value : value , Err : err , } } } return err } 
func MustProcess ( prefix string , spec interface { } ) { if err := Process ( prefix , spec ) ; err != nil { panic ( err ) } } 
func toTypeDescription ( t reflect . Type ) string { switch t . Kind ( ) { case reflect . Array , reflect . Slice : return fmt . Sprintf ( " " , toTypeDescription ( t . Elem ( ) ) ) case reflect . Map : return fmt . Sprintf ( " " , toTypeDescription ( t . Key ( ) ) , toTypeDescription ( t . Elem ( ) ) , ) case reflect . Ptr : return toTypeDescription ( t . Elem ( ) ) case reflect . Struct : if implementsInterface ( t ) && t . Name ( ) != " " { return t . Name ( ) } return " " case reflect . String : name := t . Name ( ) if name != " " && name != " " { return name } return " " case reflect . Bool : name := t . Name ( ) if name != " " && name != " " { return name } return " " case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 : name := t . Name ( ) if name != " " && ! strings . HasPrefix ( name , " " ) { return name } return " " case reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 : name := t . Name ( ) if name != " " && ! strings . HasPrefix ( name , " " ) { return name } return " " case reflect . Float32 , reflect . Float64 : name := t . Name ( ) if name != " " && ! strings . HasPrefix ( name , " " ) { return name } return " " } return fmt . Sprintf ( " " , t ) } 
func Usage ( prefix string , spec interface { } ) error { err := Usagef ( prefix , spec , tabs , DefaultTableFormat ) tabs . Flush ( ) return err } 
func Usagef ( prefix string , spec interface { } , out io . Writer , format string ) error { if req != " " { reqB , err := strconv . ParseBool ( req ) if err != nil { return " " , err } if reqB { req = " " } } return req , nil } , } tmpl , err := template . New ( " " ) . Funcs ( functions ) . Parse ( format ) if err != nil { return err } return Usaget ( prefix , spec , out , tmpl ) } 
func Usaget ( prefix string , spec interface { } , out io . Writer , tmpl * template . Template ) error { if err != nil { return err } return tmpl . Execute ( out , infos ) } 
func ( t * Time ) Scan ( value interface { } ) error { var err error switch x := value . ( type ) { case time . Time : t . Time = x case nil : t . Valid = false return nil default : err = fmt . Errorf ( " " , value , value ) } t . Valid = err == nil return err } 
func ( t Time ) Value ( ) ( driver . Value , error ) { if ! t . Valid { return nil , nil } return t . Time , nil } 
func NewTime ( t time . Time , valid bool ) Time { return Time { Time : t , Valid : valid , } } 
func TimeFromPtr ( t * time . Time ) Time { if t == nil { return NewTime ( time . Time { } , false ) } return NewTime ( * t , true ) } 
func ( t Time ) ValueOrZero ( ) time . Time { if ! t . Valid { return time . Time { } } return t . Time } 
func ( t Time ) MarshalJSON ( ) ( [ ] byte , error ) { if ! t . Valid { return [ ] byte ( " " ) , nil } return t . Time . MarshalJSON ( ) } 
func ( t * Time ) UnmarshalJSON ( data [ ] byte ) error { var err error var v interface { } if err = json . Unmarshal ( data , & v ) ; err != nil { return err } switch x := v . ( type ) { case string : err = t . Time . UnmarshalJSON ( data ) case map [ string ] interface { } : ti , tiOK := x [ " " ] . ( string ) valid , validOK := x [ " " ] . ( bool ) if ! tiOK || ! validOK { return fmt . Errorf ( `json: unmarshalling object into Go value of type null.Time requires key "Time" to be of type string and key "Valid" to be of type bool; found %T and %T, respectively` , x [ " " ] , x [ " " ] ) } err = t . Time . UnmarshalText ( [ ] byte ( ti ) ) t . Valid = valid return err case nil : t . Valid = false return nil default : err = fmt . Errorf ( " " , reflect . TypeOf ( v ) . Name ( ) ) } t . Valid = err == nil return err } 
func ( t * Time ) SetValid ( v time . Time ) { t . Time = v t . Valid = true } 
func ( t Time ) Ptr ( ) * time . Time { if ! t . Valid { return nil } return & t . Time } 
func NewBool ( b bool , valid bool ) Bool { return Bool { NullBool : sql . NullBool { Bool : b , Valid : valid , } , } } 
func BoolFromPtr ( b * bool ) Bool { if b == nil { return NewBool ( false , false ) } return NewBool ( * b , true ) } 
func ( b * Bool ) UnmarshalJSON ( data [ ] byte ) error { var err error var v interface { } if err = json . Unmarshal ( data , & v ) ; err != nil { return err } switch x := v . ( type ) { case bool : b . Bool = x case map [ string ] interface { } : err = json . Unmarshal ( data , & b . NullBool ) case nil : b . Valid = false return nil default : err = fmt . Errorf ( " " , reflect . TypeOf ( v ) . Name ( ) ) } b . Valid = err == nil return err } 
func ( b * Bool ) UnmarshalText ( text [ ] byte ) error { str := string ( text ) switch str { case " " , " " : b . Valid = false return nil case " " : b . Bool = true case " " : b . Bool = false default : b . Valid = false return errors . New ( " " + str ) } b . Valid = true return nil } 
func ( b Bool ) MarshalJSON ( ) ( [ ] byte , error ) { if ! b . Valid { return [ ] byte ( " " ) , nil } if ! b . Bool { return [ ] byte ( " " ) , nil } return [ ] byte ( " " ) , nil } 
func ( b * Bool ) SetValid ( v bool ) { b . Bool = v b . Valid = true } 
func NewString ( s string , valid bool ) String { return String { NullString : sql . NullString { String : s , Valid : valid , } , } } 
func ( s * String ) UnmarshalJSON ( data [ ] byte ) error { var err error var v interface { } if err = json . Unmarshal ( data , & v ) ; err != nil { return err } switch x := v . ( type ) { case string : s . String = x case map [ string ] interface { } : err = json . Unmarshal ( data , & s . NullString ) case nil : s . Valid = false return nil default : err = fmt . Errorf ( " " , reflect . TypeOf ( v ) . Name ( ) ) } s . Valid = ( err == nil ) && ( s . String != " " ) return err } 
func ( s String ) MarshalText ( ) ( [ ] byte , error ) { if ! s . Valid { return [ ] byte { } , nil } return [ ] byte ( s . String ) , nil } 
func ( s * String ) UnmarshalText ( text [ ] byte ) error { s . String = string ( text ) s . Valid = s . String != " " return nil } 
func ( s * String ) SetValid ( v string ) { s . String = v s . Valid = true } 
func StringFromPtr ( s * string ) String { if s == nil { return NewString ( " " , false ) } return NewString ( * s , true ) } 
func ( s String ) MarshalJSON ( ) ( [ ] byte , error ) { if ! s . Valid { return [ ] byte ( " " ) , nil } return json . Marshal ( s . String ) } 
func NewInt ( i int64 , valid bool ) Int { return Int { NullInt64 : sql . NullInt64 { Int64 : i , Valid : valid , } , } } 
func IntFromPtr ( i * int64 ) Int { if i == nil { return NewInt ( 0 , false ) } n := NewInt ( * i , true ) return n } 
func ( i * Int ) UnmarshalJSON ( data [ ] byte ) error { var err error var v interface { } if err = json . Unmarshal ( data , & v ) ; err != nil { return err } switch x := v . ( type ) { case float64 : case string : str := string ( x ) if len ( str ) == 0 { i . Valid = false return nil } i . Int64 , err = strconv . ParseInt ( str , 10 , 64 ) case map [ string ] interface { } : err = json . Unmarshal ( data , & i . NullInt64 ) case nil : i . Valid = false return nil default : err = fmt . Errorf ( " " , reflect . TypeOf ( v ) . Name ( ) ) } i . Valid = ( err == nil ) && ( i . Int64 != 0 ) return err } 
func ( i Int ) MarshalText ( ) ( [ ] byte , error ) { n := i . Int64 if ! i . Valid { n = 0 } return [ ] byte ( strconv . FormatInt ( n , 10 ) ) , nil } 
func ( i * Int ) SetValid ( n int64 ) { i . Int64 = n i . Valid = true } 
func ( i * Int ) UnmarshalText ( text [ ] byte ) error { str := string ( text ) if str == " " || str == " " { i . Valid = false return nil } var err error i . Int64 , err = strconv . ParseInt ( string ( text ) , 10 , 64 ) i . Valid = err == nil return err } 
func ( b Bool ) MarshalText ( ) ( [ ] byte , error ) { if ! b . Valid || ! b . Bool { return [ ] byte ( " " ) , nil } return [ ] byte ( " " ) , nil } 
func ( f * Float ) SetValid ( v float64 ) { f . Float64 = v f . Valid = true } 
func TimeFromPtr ( t * time . Time ) Time { if t == nil { return NewTime ( time . Time { } , false ) } return TimeFrom ( * t ) } 
func ( t Time ) MarshalJSON ( ) ( [ ] byte , error ) { if ! t . Valid { return ( time . Time { } ) . MarshalJSON ( ) } return t . Time . MarshalJSON ( ) } 
func ( f * Float ) UnmarshalJSON ( data [ ] byte ) error { var err error var v interface { } if err = json . Unmarshal ( data , & v ) ; err != nil { return err } switch x := v . ( type ) { case float64 : f . Float64 = float64 ( x ) case string : str := string ( x ) if len ( str ) == 0 { f . Valid = false return nil } f . Float64 , err = strconv . ParseFloat ( str , 64 ) case map [ string ] interface { } : err = json . Unmarshal ( data , & f . NullFloat64 ) case nil : f . Valid = false return nil default : err = fmt . Errorf ( " " , reflect . TypeOf ( v ) . Name ( ) ) } f . Valid = err == nil return err } 
func ( f * Float ) UnmarshalText ( text [ ] byte ) error { str := string ( text ) if str == " " || str == " " { f . Valid = false return nil } var err error f . Float64 , err = strconv . ParseFloat ( string ( text ) , 64 ) f . Valid = err == nil return err } 
func ( f Float ) MarshalJSON ( ) ( [ ] byte , error ) { if ! f . Valid { return [ ] byte ( " " ) , nil } if math . IsInf ( f . Float64 , 0 ) || math . IsNaN ( f . Float64 ) { return nil , & json . UnsupportedValueError { Value : reflect . ValueOf ( f . Float64 ) , Str : strconv . FormatFloat ( f . Float64 , 'g' , - 1 , 64 ) , } } return [ ] byte ( strconv . FormatFloat ( f . Float64 , 'f' , - 1 , 64 ) ) , nil } 
func newGossipChannel ( channelName string , ourself * localPeer , r * routes , g Gossiper , logger Logger ) * gossipChannel { return & gossipChannel { name : channelName , ourself : ourself , routes : r , gossiper : g , logger : logger , } } 
func ( c * gossipChannel ) GossipUnicast ( dstPeerName PeerName , msg [ ] byte ) error { return c . relayUnicast ( dstPeerName , gobEncode ( c . name , c . ourself . Name , dstPeerName , msg ) ) } 
func ( c * gossipChannel ) GossipBroadcast ( update GossipData ) { c . relayBroadcast ( c . ourself . Name , update ) } 
func ( c * gossipChannel ) Send ( data GossipData ) { c . relay ( c . ourself . Name , data ) } 
func ( c * gossipChannel ) SendDown ( conn Connection , data GossipData ) { c . senderFor ( conn ) . Send ( data ) } 
func gobEncode ( items ... interface { } ) [ ] byte { buf := new ( bytes . Buffer ) enc := gob . NewEncoder ( buf ) for _ , i := range items { if err := enc . Encode ( i ) ; err != nil { panic ( err ) } } return buf . Bytes ( ) } 
func newTokenBucket ( capacity int64 , tokenInterval time . Duration ) * tokenBucket { tb := tokenBucket { capacity : capacity , tokenInterval : tokenInterval , refillDuration : tokenInterval * time . Duration ( capacity ) } tb . earliestUnspentToken = tb . capacityToken ( ) return & tb } 
func ( tb * tokenBucket ) wait ( ) { if tb . earliestUnspentToken . Before ( capacityToken ) { tb . earliestUnspentToken = capacityToken } } 
func ( tb * tokenBucket ) capacityToken ( ) time . Time { return time . Now ( ) . Add ( - tb . refillDuration ) . Truncate ( tb . tokenInterval ) } 
func PrefixRangeEnd ( prefix [ ] byte ) [ ] byte { copy ( end , prefix ) for i := len ( end ) - 1 ; i >= 0 ; i -- { if end [ i ] < 0xff { end [ i ] = end [ i ] + 1 end = end [ : i + 1 ] return end } } } 
func newLocalPeer ( name PeerName , nickName string , router * Router ) * localPeer { actionChan := make ( chan localPeerAction , ChannelSize ) peer := & localPeer { Peer : newPeer ( name , nickName , randomPeerUID ( ) , 0 , randomPeerShortID ( ) ) , router : router , actionChan : actionChan , } go peer . actorLoop ( actionChan ) return peer } 
func ( peer * localPeer ) getConnections ( ) connectionSet { connections := make ( connectionSet ) peer . RLock ( ) defer peer . RUnlock ( ) for _ , conn := range peer . connections { connections [ conn ] = struct { } { } } return connections } 
func ( peer * localPeer ) ConnectionTo ( name PeerName ) ( Connection , bool ) { peer . RLock ( ) defer peer . RUnlock ( ) conn , found := peer . connections [ name ] return conn , found } 
func ( peer * localPeer ) ConnectionsTo ( names [ ] PeerName ) [ ] Connection { if len ( names ) == 0 { return nil } conns := make ( [ ] Connection , 0 , len ( names ) ) peer . RLock ( ) defer peer . RUnlock ( ) for _ , name := range names { conn , found := peer . connections [ name ] } } return conns } 
func ( peer * localPeer ) createConnection ( localAddr string , peerAddr string , acceptNewPeer bool , logger Logger ) error { if err := peer . checkConnectionLimit ( ) ; err != nil { return err } localTCPAddr , err := net . ResolveTCPAddr ( " " , localAddr ) if err != nil { return err } remoteTCPAddr , err := net . ResolveTCPAddr ( " " , peerAddr ) if err != nil { return err } tcpConn , err := net . DialTCP ( " " , localTCPAddr , remoteTCPAddr ) if err != nil { return err } connRemote := newRemoteConnection ( peer . Peer , nil , peerAddr , true , false ) startLocalConnection ( connRemote , tcpConn , peer . router , acceptNewPeer , logger ) return nil } 
func ( peer * localPeer ) doAddConnection ( conn ourConnection , isRestartedPeer bool ) error { resultChan := make ( chan error ) peer . actionChan <- func ( ) { resultChan <- peer . handleAddConnection ( conn , isRestartedPeer ) } return <- resultChan } 
func ( peer * localPeer ) doConnectionEstablished ( conn ourConnection ) { peer . actionChan <- func ( ) { peer . handleConnectionEstablished ( conn ) } } 
func ( peer * localPeer ) doDeleteConnection ( conn ourConnection ) { resultChan := make ( chan interface { } ) peer . actionChan <- func ( ) { peer . handleDeleteConnection ( conn ) resultChan <- nil } <- resultChan } 
func ( peer * localPeer ) actorLoop ( actionChan <- chan localPeerAction ) { gossipTimer := time . Tick ( gossipInterval ) for { select { case action := <- actionChan : action ( ) case <- gossipTimer : peer . router . sendAllGossip ( ) } } } 
func ( peer * localPeer ) broadcastPeerUpdate ( peers ... * Peer ) { } } 
func startLocalConnection ( connRemote * remoteConnection , tcpConn * net . TCPConn , router * Router , acceptNewPeer bool , logger Logger ) { if connRemote . local != router . Ourself . Peer { panic ( " " ) } errorChan := make ( chan error , 1 ) finished := make ( chan struct { } ) conn := & LocalConnection { remoteConnection : * connRemote , conn . senders = newGossipSenders ( conn , finished ) go conn . run ( errorChan , finished , acceptNewPeer ) } 
func ( conn * LocalConnection ) SendProtocolMsg ( m protocolMsg ) error { if err := conn . sendProtocolMsg ( m ) ; err != nil { conn . shutdown ( err ) return err } return nil } 
func ( conn * LocalConnection ) shutdown ( err error ) { } select { case conn . errorChan <- err : default : } } 
func ( conn * LocalConnection ) run ( errorChan <- chan error , finished chan <- struct { } , acceptNewPeer bool ) { var err error defer func ( ) { conn . teardown ( err ) } ( ) defer close ( finished ) if err = conn . tcpConn . SetLinger ( 0 ) ; err != nil { return } intro , err := protocolIntroParams { MinVersion : conn . router . ProtocolMinVersion , MaxVersion : ProtocolMaxVersion , Features : conn . makeFeatures ( ) , Conn : conn . tcpConn , Password : conn . router . Password , Outbound : conn . outbound , } . doIntro ( ) if err != nil { return } conn . sessionKey = intro . SessionKey conn . tcpSender = intro . Sender conn . version = intro . Version remote , err := conn . parseFeatures ( intro . Features ) if err != nil { return } if err = conn . registerRemote ( remote , acceptNewPeer ) ; err != nil { return } isRestartedPeer := conn . Remote ( ) . UID != remote . UID conn . logf ( " " , conn . version ) if conn . untrusted ( ) { sessionKey = conn . sessionKey } params := OverlayConnectionParams { RemotePeer : conn . remote , LocalAddr : conn . tcpConn . LocalAddr ( ) . ( * net . TCPAddr ) , RemoteAddr : conn . tcpConn . RemoteAddr ( ) . ( * net . TCPAddr ) , Outbound : conn . outbound , ConnUID : conn . uid , SessionKey : sessionKey , SendControlMessage : conn . sendOverlayControlMessage , Features : intro . Features , } if conn . OverlayConn , err = conn . router . Overlay . PrepareConnection ( params ) ; err != nil { return } } conn . router . ConnectionMaker . connectionCreated ( conn ) go conn . receiveTCP ( intro . Receiver ) } 
func ( conn * LocalConnection ) sendSimpleProtocolMsg ( tag protocolTag ) error { return conn . sendProtocolMsg ( protocolMsg { tag : tag } ) } 
func NewStatus ( router * Router ) * Status { return & Status { Protocol : Protocol , ProtocolMinVersion : int ( router . ProtocolMinVersion ) , ProtocolMaxVersion : ProtocolMaxVersion , Encryption : router . usingPassword ( ) , PeerDiscovery : router . PeerDiscovery , Name : router . Ourself . Name . String ( ) , NickName : router . Ourself . NickName , Port : router . Port , Peers : makePeerStatusSlice ( router . Peers ) , UnicastRoutes : makeUnicastRouteStatusSlice ( router . Routes ) , BroadcastRoutes : makeBroadcastRouteStatusSlice ( router . Routes ) , Connections : makeLocalConnectionStatusSlice ( router . ConnectionMaker ) , TerminationCount : router . ConnectionMaker . terminationCount , Targets : router . ConnectionMaker . Targets ( false ) , OverlayDiagnostics : router . Overlay . Diagnostics ( ) , TrustedSubnets : makeTrustedSubnetsSlice ( router . TrustedSubnets ) , } } 
func makePeerStatusSlice ( peers * Peers ) [ ] PeerStatus { var slice [ ] PeerStatus peers . forEach ( func ( peer * Peer ) { var connections [ ] connectionStatus if peer == peers . ourself . Peer { for conn := range peers . ourself . getConnections ( ) { connections = append ( connections , makeConnectionStatus ( conn ) ) } } else { } } slice = append ( slice , PeerStatus { peer . Name . String ( ) , peer . NickName , peer . UID , peer . ShortID , peer . Version , connections , } ) } ) return slice } 
func makeUnicastRouteStatusSlice ( r * routes ) [ ] unicastRouteStatus { r . RLock ( ) defer r . RUnlock ( ) var slice [ ] unicastRouteStatus for dest , via := range r . unicast { slice = append ( slice , unicastRouteStatus { dest . String ( ) , via . String ( ) } ) } return slice } 
func makeBroadcastRouteStatusSlice ( r * routes ) [ ] broadcastRouteStatus { r . RLock ( ) defer r . RUnlock ( ) var slice [ ] broadcastRouteStatus for source , via := range r . broadcast { var hops [ ] string for _ , hop := range via { hops = append ( hops , hop . String ( ) ) } slice = append ( slice , broadcastRouteStatus { source . String ( ) , hops } ) } return slice } 
func makeLocalConnectionStatusSlice ( cm * connectionMaker ) [ ] LocalConnectionStatus { resultChan := make ( chan [ ] LocalConnectionStatus ) cm . actionChan <- func ( ) bool { var slice [ ] LocalConnectionStatus for conn := range cm . connections { state := " " if conn . isEstablished ( ) { state = " " } lc , _ := conn . ( * LocalConnection ) attrs := lc . OverlayConn . Attrs ( ) name , ok := attrs [ " " ] if ! ok { name = " " } info := fmt . Sprintf ( " " , name , conn . Remote ( ) ) if lc . router . usingPassword ( ) { if lc . untrusted ( ) { info = fmt . Sprintf ( " " , " " , info ) if attrs != nil { attrs [ " " ] = true } } else { info = fmt . Sprintf ( " " , " " , info ) } } slice = append ( slice , LocalConnectionStatus { conn . remoteTCPAddress ( ) , conn . isOutbound ( ) , state , info , attrs } ) } for address , target := range cm . targets { add := func ( state , info string ) { slice = append ( slice , LocalConnectionStatus { address , true , state , info , nil } ) } switch target . state { case targetWaiting : until := " " if ! target . tryAfter . IsZero ( ) { until = target . tryAfter . String ( ) } if target . lastError == nil { } else { add ( " " , target . lastError . Error ( ) + " " + until ) } case targetAttempting : if target . lastError == nil { add ( " " , " " ) } else { add ( " " , target . lastError . Error ( ) ) } case targetConnected : case targetSuspended : } } resultChan <- slice return false } return <- resultChan } 
func makeTrustedSubnetsSlice ( trustedSubnets [ ] * net . IPNet ) [ ] string { trustedSubnetStrs := [ ] string { } for _ , trustedSubnet := range trustedSubnets { trustedSubnetStrs = append ( trustedSubnetStrs , trustedSubnet . String ( ) ) } return trustedSubnetStrs } 
func ( s * etcdStore ) Range ( ctx context . Context , req * etcdserverpb . RangeRequest ) ( * etcdserverpb . RangeResponse , error ) { ireq := etcdserverpb . InternalRaftRequest { ID : <- s . idgen , Range : req } msgc , errc , err := s . proposeInternalRaftRequest ( ireq ) if err != nil { return nil , err } select { case <- ctx . Done ( ) : s . cancelInternalRaftRequest ( ireq ) return nil , ctx . Err ( ) case msg := <- msgc : return msg . ( * etcdserverpb . RangeResponse ) , nil case err := <- errc : return nil , err case <- s . quitc : return nil , errStopped } } 
func ( s * etcdStore ) Put ( ctx context . Context , req * etcdserverpb . PutRequest ) ( * etcdserverpb . PutResponse , error ) { ireq := etcdserverpb . InternalRaftRequest { ID : <- s . idgen , Put : req } msgc , errc , err := s . proposeInternalRaftRequest ( ireq ) if err != nil { return nil , err } select { case <- ctx . Done ( ) : s . cancelInternalRaftRequest ( ireq ) return nil , ctx . Err ( ) case msg := <- msgc : return msg . ( * etcdserverpb . PutResponse ) , nil case err := <- errc : return nil , err case <- s . quitc : return nil , errStopped } } 
func ( s * etcdStore ) DeleteRange ( ctx context . Context , req * etcdserverpb . DeleteRangeRequest ) ( * etcdserverpb . DeleteRangeResponse , error ) { ireq := etcdserverpb . InternalRaftRequest { ID : <- s . idgen , DeleteRange : req } msgc , errc , err := s . proposeInternalRaftRequest ( ireq ) if err != nil { return nil , err } select { case <- ctx . Done ( ) : s . cancelInternalRaftRequest ( ireq ) return nil , ctx . Err ( ) case msg := <- msgc : return msg . ( * etcdserverpb . DeleteRangeResponse ) , nil case err := <- errc : return nil , err case <- s . quitc : return nil , errStopped } } 
func ( s * etcdStore ) Txn ( ctx context . Context , req * etcdserverpb . TxnRequest ) ( * etcdserverpb . TxnResponse , error ) { ireq := etcdserverpb . InternalRaftRequest { ID : <- s . idgen , Txn : req } msgc , errc , err := s . proposeInternalRaftRequest ( ireq ) if err != nil { return nil , err } select { case <- ctx . Done ( ) : s . cancelInternalRaftRequest ( ireq ) return nil , ctx . Err ( ) case msg := <- msgc : return msg . ( * etcdserverpb . TxnResponse ) , nil case err := <- errc : return nil , err case <- s . quitc : return nil , errStopped } } 
func ( s * etcdStore ) Compact ( ctx context . Context , req * etcdserverpb . CompactionRequest ) ( * etcdserverpb . CompactionResponse , error ) { } 
func ( s * etcdStore ) proposeInternalRaftRequest ( req etcdserverpb . InternalRaftRequest ) ( <- chan proto . Message , <- chan error , error ) { data , err := req . Marshal ( ) if err != nil { return nil , nil , err } if len ( data ) > maxRequestBytes { return nil , nil , errTooBig } msgc , errc , err := s . registerPending ( req . ID ) if err != nil { return nil , nil , err } s . proposalc <- data return msgc , errc , nil } 
func ( s * etcdStore ) applyInternalRaftRequest ( req etcdserverpb . InternalRaftRequest ) ( proto . Message , error ) { switch { case req . Range != nil : return applyRange ( noTxn , s . kv , req . Range ) case req . Put != nil : return applyPut ( noTxn , s . kv , s . lessor , req . Put ) case req . DeleteRange != nil : return applyDeleteRange ( noTxn , s . kv , req . DeleteRange ) case req . Txn != nil : return applyTransaction ( s . kv , s . lessor , req . Txn ) case req . Compaction != nil : return applyCompaction ( s . kv , req . Compaction ) case req . LeaseGrant != nil : return applyLeaseGrant ( s . lessor , req . LeaseGrant ) case req . LeaseRevoke != nil : return applyLeaseRevoke ( s . lessor , req . LeaseRevoke ) default : return nil , fmt . Errorf ( " " ) } } 
func applyCompare ( kv mvcc . KV , c * etcdserverpb . Compare ) ( int64 , bool ) { ckvs , rev , err := kv . Range ( c . Key , nil , 1 , 0 ) if err != nil { if err == mvcc . ErrTxnIDMismatch { panic ( " " ) } return rev , false } var ckv mvccpb . KeyValue if len ( ckvs ) != 0 { ckv = ckvs [ 0 ] } else { } } switch c . Target { case etcdserverpb . Compare_VALUE : tv , _ := c . TargetUnion . ( * etcdserverpb . Compare_Value ) if tv != nil { result = bytes . Compare ( ckv . Value , tv . Value ) } case etcdserverpb . Compare_CREATE : tv , _ := c . TargetUnion . ( * etcdserverpb . Compare_CreateRevision ) if tv != nil { result = compareInt64 ( ckv . CreateRevision , tv . CreateRevision ) } case etcdserverpb . Compare_MOD : tv , _ := c . TargetUnion . ( * etcdserverpb . Compare_ModRevision ) if tv != nil { result = compareInt64 ( ckv . ModRevision , tv . ModRevision ) } case etcdserverpb . Compare_VERSION : tv , _ := c . TargetUnion . ( * etcdserverpb . Compare_Version ) if tv != nil { result = compareInt64 ( ckv . Version , tv . Version ) } } switch c . Result { case etcdserverpb . Compare_EQUAL : if result != 0 { return rev , false } case etcdserverpb . Compare_GREATER : if result != 1 { return rev , false } case etcdserverpb . Compare_LESS : if result != - 1 { return rev , false } } return rev , true } 
func ( peers * Peers ) Descriptions ( ) [ ] PeerDescription { peers . RLock ( ) defer peers . RUnlock ( ) descriptions := make ( [ ] PeerDescription , 0 , len ( peers . byName ) ) for _ , peer := range peers . byName { descriptions = append ( descriptions , PeerDescription { Name : peer . Name , NickName : peer . peerSummary . NickName , UID : peer . UID , Self : peer . Name == peers . ourself . Name , NumConnections : len ( peer . connections ) , } ) } return descriptions } 
func ( peers * Peers ) OnGC ( callback func ( * Peer ) ) { peers . Lock ( ) defer peers . Unlock ( ) } 
func ( peers * Peers ) OnInvalidateShortIDs ( callback func ( ) ) { peers . Lock ( ) defer peers . Unlock ( ) } 
func ( peers * Peers ) chooseShortID ( ) ( PeerShortID , bool ) { rng := rand . New ( rand . NewSource ( int64 ( randUint64 ( ) ) ) ) if peers . byShortID [ shortID ] . peer == nil { return shortID , true } } for _ , entry := range peers . byShortID { if entry . peer != nil { available -- } } if available == 0 { } n := rng . Intn ( available ) var i PeerShortID for { if peers . byShortID [ i ] . peer == nil { if n == 0 { return i , true } n -- } i ++ } } 
func ( peers * Peers ) fetchWithDefault ( peer * Peer ) * Peer { peers . Lock ( ) var pending peersPendingNotifications defer peers . unlockAndNotify ( & pending ) if existingPeer , found := peers . byName [ peer . Name ] ; found { existingPeer . localRefCount ++ return existingPeer } peers . byName [ peer . Name ] = peer peers . addByShortID ( peer , & pending ) peer . localRefCount ++ return peer } 
func ( peers * Peers ) Fetch ( name PeerName ) * Peer { peers . RLock ( ) defer peers . RUnlock ( ) return peers . byName [ name ] } 
func ( peers * Peers ) fetchAndAddRef ( name PeerName ) * Peer { peers . Lock ( ) defer peers . Unlock ( ) peer := peers . byName [ name ] if peer != nil { peer . localRefCount ++ } return peer } 
func ( peers * Peers ) FetchByShortID ( shortID PeerShortID ) * Peer { peers . RLock ( ) defer peers . RUnlock ( ) return peers . byShortID [ shortID ] . peer } 
func ( peers * Peers ) dereference ( peer * Peer ) { peers . Lock ( ) defer peers . Unlock ( ) peer . localRefCount -- } 
func ( peers * Peers ) applyUpdate ( update [ ] byte ) ( peerNameSet , peerNameSet , error ) { peers . Lock ( ) var pending peersPendingNotifications defer peers . unlockAndNotify ( & pending ) newPeers , decodedUpdate , decodedConns , err := peers . decodeUpdate ( update ) if err != nil { return nil , nil , err } peers . addByShortID ( newPeer , & pending ) } peers . garbageCollect ( & pending ) for _ , peerRemoved := range pending . removed { delete ( newUpdate , peerRemoved . Name ) } updateNames := make ( peerNameSet ) for _ , peer := range decodedUpdate { updateNames [ peer . Name ] = struct { } { } } return updateNames , newUpdate , nil } 
func ( peers * Peers ) GarbageCollect ( ) { peers . Lock ( ) var pending peersPendingNotifications defer peers . unlockAndNotify ( & pending ) peers . garbageCollect ( & pending ) } 
func newRoutes ( ourself * localPeer , peers * Peers ) * routes { recalculate := make ( chan * struct { } , 1 ) wait := make ( chan chan struct { } ) action := make ( chan func ( ) ) r := & routes { ourself : ourself , peers : peers , unicast : unicastRoutes { ourself . Name : UnknownPeerName } , unicastAll : unicastRoutes { ourself . Name : UnknownPeerName } , broadcast : broadcastRoutes { ourself . Name : [ ] PeerName { } } , broadcastAll : broadcastRoutes { ourself . Name : [ ] PeerName { } } , recalc : recalculate , wait : wait , action : action , } go r . run ( recalculate , wait , action ) return r } 
func ( r * routes ) OnChange ( callback func ( ) ) { r . Lock ( ) defer r . Unlock ( ) r . onChange = append ( r . onChange , callback ) } 
func ( r * routes ) Unicast ( name PeerName ) ( PeerName , bool ) { r . RLock ( ) defer r . RUnlock ( ) hop , found := r . unicast [ name ] return hop , found } 
func ( r * routes ) UnicastAll ( name PeerName ) ( PeerName , bool ) { r . RLock ( ) defer r . RUnlock ( ) hop , found := r . unicastAll [ name ] return hop , found } 
func ( r * routes ) Broadcast ( name PeerName ) [ ] PeerName { return r . lookupOrCalculate ( name , & r . broadcast , true ) } 
func ( r * routes ) BroadcastAll ( name PeerName ) [ ] PeerName { return r . lookupOrCalculate ( name , & r . broadcastAll , false ) } 
func ( r * routes ) randomNeighbours ( except PeerName ) [ ] PeerName { destinations := make ( peerNameSet ) r . RLock ( ) defer r . RUnlock ( ) count := int ( math . Log2 ( float64 ( len ( r . unicastAll ) ) ) ) if len ( destinations ) >= count { break } } } res := make ( [ ] PeerName , 0 , len ( destinations ) ) for dst := range destinations { res = append ( res , dst ) } return res } 
func ( r * routes ) calculateUnicast ( establishedAndSymmetric bool ) unicastRoutes { _ , unicast := r . ourself . routes ( nil , establishedAndSymmetric ) return unicast } 
func ( r * routes ) calculateBroadcast ( name PeerName , establishedAndSymmetric bool ) [ ] PeerName { hops := [ ] PeerName { } peer , found := r . peers . byName [ name ] if ! found { return hops } if found , reached := peer . routes ( r . ourself . Peer , establishedAndSymmetric ) ; found { r . ourself . forEachConnectedPeer ( establishedAndSymmetric , reached , func ( remotePeer * Peer ) { hops = append ( hops , remotePeer . Name ) } ) } return hops } 
func NewPeer ( name mesh . PeerName , uid mesh . PeerUID , logger mesh . Logger ) * Peer { p := & Peer { name : name , uid : uid , gossip : nil , go p . loop ( ) return p } 
func ( p * Peer ) Register ( gossip mesh . Gossip ) { p . actions <- func ( ) { p . gossip = gossip } } 
func ( p * Peer ) ReadFrom ( b [ ] byte ) ( n int , remote net . Addr , err error ) { c := make ( chan struct { } ) p . actions <- func ( ) { go func ( ) { select { case pkt := <- p . recv : n = copy ( b , pkt . Buf ) remote = MeshAddr { PeerName : pkt . SrcName , PeerUID : pkt . SrcUID } if n < len ( pkt . Buf ) { err = ErrShortRead } case <- p . quit : err = ErrPeerClosed } } ( ) } <- c return n , remote , err } 
func ( p * Peer ) WriteTo ( b [ ] byte , dst net . Addr ) ( n int , err error ) { c := make ( chan struct { } ) p . actions <- func ( ) { defer close ( c ) if p . gossip == nil { err = ErrGossipNotRegistered return } meshAddr , ok := dst . ( MeshAddr ) if ! ok { err = ErrNotMeshAddr return } pkt := pkt { SrcName : p . name , SrcUID : p . uid , Buf : b } if meshAddr . PeerName == p . name { p . recv <- pkt return } n = len ( buf ) err = p . gossip . GossipUnicast ( meshAddr . PeerName , buf ) } <- c return n , err } 
func ( p * Peer ) LocalAddr ( ) net . Addr { return MeshAddr { PeerName : p . name , PeerUID : p . uid } } 
func ( p * Peer ) OnGossip ( buf [ ] byte ) ( delta mesh . GossipData , err error ) { return pktSlice { makePkt ( buf ) } , nil } 
func ( p * Peer ) OnGossipBroadcast ( _ mesh . PeerName , buf [ ] byte ) ( received mesh . GossipData , err error ) { pkt := makePkt ( buf ) p . recv <- pkt return pktSlice { pkt } , nil } 
func ( p * Peer ) OnGossipUnicast ( _ mesh . PeerName , buf [ ] byte ) error { pkt := makePkt ( buf ) p . recv <- pkt return nil } 
func GRPCServer ( s Server , options ... grpc . ServerOption ) * grpc . Server { srv := grpc . NewServer ( options ... ) } 
func NewServer ( router * mesh . Router , peer * meshconn . Peer , minPeerCount int , terminatec <- chan struct { } , terminatedc chan <- error , logger mesh . Logger , ) Server { c := make ( chan Server ) go serverManager ( router , peer , minPeerCount , terminatec , terminatedc , logger , c ) return <- c } 
func NewDefaultServer ( minPeerCount int , terminatec <- chan struct { } , terminatedc chan <- error , logger mesh . Logger , ) Server { var ( peerName = mustPeerName ( ) nickName = mustHostname ( ) host = " " port = 6379 password = " " channel = " " ) router := mesh . NewRouter ( mesh . Config { Host : host , Port : port , ProtocolMinVersion : mesh . ProtocolMinVersion , Password : [ ] byte ( password ) , ConnLimit : 64 , PeerDiscovery : true , TrustedSubnets : [ ] * net . IPNet { } , } , peerName , nickName , mesh . NullOverlay { } , logger ) gossip := router . NewGossip ( channel , peer ) peer . Register ( gossip ) return NewServer ( router , peer , minPeerCount , terminatec , terminatedc , logger ) } 
func PeerNameFromUserInput ( userInput string ) ( PeerName , error ) { return PeerNameFromBin ( nameByteAry [ : NameSize ] ) , nil } 
func PeerNameFromString ( nameStr string ) ( PeerName , error ) { if _ , err := hex . DecodeString ( nameStr ) ; err != nil { return UnknownPeerName , err } return PeerName ( nameStr ) , nil } 
func ( name PeerName ) bytes ( ) [ ] byte { res , err := hex . DecodeString ( string ( name ) ) if err != nil { panic ( " " + name ) } return res } 
func PeerNameFromString ( nameStr string ) ( PeerName , error ) { var a , b , c , d , e , f uint64 match := func ( format string , args ... interface { } ) bool { a , b , c , d , e , f = 0 , 0 , 0 , 0 , 0 , 0 n , err := fmt . Sscanf ( nameStr + " \000 " , format + " \000 " , args ... ) return err == nil && n == len ( args ) } switch { case match ( " " , & a , & b , & c , & d , & e , & f ) : case match ( " " , & c , & d , & e , & f ) : case match ( " " , & a , & d , & e , & f ) : case match ( " " , & a , & b , & e , & f ) : case match ( " " , & a , & b , & c , & f ) : case match ( " " , & a , & b , & c , & d ) : case match ( " " , & d , & e , & f ) : case match ( " " , & a , & e , & f ) : case match ( " " , & a , & b , & f ) : case match ( " " , & a , & b , & c ) : case match ( " " , & e , & f ) : case match ( " " , & a , & f ) : case match ( " " , & a , & b ) : case match ( " " , & f ) : case match ( " " , & a ) : default : return UnknownPeerName , fmt . Errorf ( " " , nameStr ) } return PeerName ( a << 40 | b << 32 | c << 24 | d << 16 | e << 8 | f ) , nil } 
func NewRouter ( config Config , name PeerName , nickName string , overlay Overlay , logger Logger ) ( * Router , error ) { router := & Router { Config : config , gossipChannels : make ( gossipChannels ) } if overlay == nil { overlay = NullOverlay { } } router . Overlay = overlay router . Ourself = newLocalPeer ( name , nickName , router ) router . Peers = newPeers ( router . Ourself ) router . Peers . OnGC ( func ( peer * Peer ) { logger . Printf ( " " , peer ) } ) router . Routes = newRoutes ( router . Ourself , router . Peers ) router . ConnectionMaker = newConnectionMaker ( router . Ourself , router . Peers , net . JoinHostPort ( router . Host , " " ) , router . Port , router . PeerDiscovery , logger ) router . logger = logger gossip , err := router . NewGossip ( " " , router ) if err != nil { return nil , err } router . topologyGossip = gossip router . acceptLimiter = newTokenBucket ( acceptMaxTokens , acceptTokenDelay ) return router , nil } 
func ( router * Router ) NewGossip ( channelName string , g Gossiper ) ( Gossip , error ) { channel := newGossipChannel ( channelName , router . Ourself , router . Routes , g , router . logger ) router . gossipLock . Lock ( ) defer router . gossipLock . Unlock ( ) if _ , found := router . gossipChannels [ channelName ] ; found { return nil , fmt . Errorf ( " " , channelName ) } router . gossipChannels [ channelName ] = channel return channel , nil } 
func ( router * Router ) sendAllGossip ( ) { for channel := range router . gossipChannelSet ( ) { if gossip := channel . gossiper . Gossip ( ) ; gossip != nil { channel . Send ( gossip ) } } } 
func ( router * Router ) sendAllGossipDown ( conn Connection ) { for channel := range router . gossipChannelSet ( ) { if gossip := channel . gossiper . Gossip ( ) ; gossip != nil { channel . SendDown ( conn , gossip ) } } } 
func ( router * Router ) sendPendingGossip ( ) bool { sentSomething := false for conn := range router . Ourself . getConnections ( ) { sentSomething = conn . ( gossipConnection ) . gossipSenders ( ) . Flush ( ) || sentSomething } return sentSomething } 
func ( router * Router ) broadcastTopologyUpdate ( update [ ] * Peer ) { names := make ( peerNameSet ) for _ , p := range update { names [ p . Name ] = struct { } { } } router . topologyGossip . GossipBroadcast ( & topologyGossipData { peers : router . Peers , update : names } ) } 
func ( router * Router ) OnGossipUnicast ( sender PeerName , msg [ ] byte ) error { return fmt . Errorf ( " " , msg ) } 
func ( router * Router ) OnGossipBroadcast ( _ PeerName , update [ ] byte ) ( GossipData , error ) { origUpdate , _ , err := router . applyTopologyUpdate ( update ) if err != nil || len ( origUpdate ) == 0 { return nil , err } return & topologyGossipData { peers : router . Peers , update : origUpdate } , nil } 
func ( router * Router ) Gossip ( ) GossipData { return & topologyGossipData { peers : router . Peers , update : router . Peers . names ( ) } } 
func ( router * Router ) OnGossip ( update [ ] byte ) ( GossipData , error ) { _ , newUpdate , err := router . applyTopologyUpdate ( update ) if err != nil || len ( newUpdate ) == 0 { return nil , err } return & topologyGossipData { peers : router . Peers , update : newUpdate } , nil } 
func ( d * topologyGossipData ) Merge ( other GossipData ) GossipData { names := make ( peerNameSet ) for name := range d . update { names [ name ] = struct { } { } } for name := range other . ( * topologyGossipData ) . update { names [ name ] = struct { } { } } return & topologyGossipData { peers : d . peers , update : names } } 
func ( d * topologyGossipData ) Encode ( ) [ ] [ ] byte { return [ ] [ ] byte { d . peers . encodePeers ( d . update ) } } 
func newState ( self mesh . PeerName ) * state { return & state { set : map [ mesh . PeerName ] int { } , self : self , } } 
func ( st * state ) Encode ( ) [ ] [ ] byte { st . mtx . RLock ( ) defer st . mtx . RUnlock ( ) var buf bytes . Buffer if err := gob . NewEncoder ( & buf ) . Encode ( st . set ) ; err != nil { panic ( err ) } return [ ] [ ] byte { buf . Bytes ( ) } } 
func ( st * state ) Merge ( other mesh . GossipData ) ( complete mesh . GossipData ) { return st . mergeComplete ( other . ( * state ) . copy ( ) . set ) } 
func ( st * state ) mergeReceived ( set map [ mesh . PeerName ] int ) ( received mesh . GossipData ) { st . mtx . Lock ( ) defer st . mtx . Unlock ( ) for peer , v := range set { if v <= st . set [ peer ] { delete ( set , peer ) continue } st . set [ peer ] = v } return & state { set : set , } 
func ( st * state ) mergeDelta ( set map [ mesh . PeerName ] int ) ( delta mesh . GossipData ) { st . mtx . Lock ( ) defer st . mtx . Unlock ( ) for peer , v := range set { if v <= st . set [ peer ] { delete ( set , peer ) continue } st . set [ peer ] = v } if len ( set ) <= 0 { return nil } return & state { set : set , } 
func ( st * state ) mergeComplete ( set map [ mesh . PeerName ] int ) ( complete mesh . GossipData ) { st . mtx . Lock ( ) defer st . mtx . Unlock ( ) for peer , v := range set { if v > st . set [ peer ] { st . set [ peer ] = v } } return & state { set : st . set , } 
func ( * surrogateGossiper ) OnGossipBroadcast ( _ PeerName , update [ ] byte ) ( GossipData , error ) { return newSurrogateGossipData ( update ) , nil } 
func ( s * surrogateGossiper ) OnGossip ( update [ ] byte ) ( GossipData , error ) { hash := fnv . New64a ( ) _ , _ = hash . Write ( update ) updateHash := hash . Sum64 ( ) s . Lock ( ) defer s . Unlock ( ) for _ , p := range s . prevUpdates { if updateHash == p . hash && bytes . Equal ( update , p . update ) { return nil , nil } } deleteBefore := updateTime . Add ( - gossipInterval ) keepFrom := len ( s . prevUpdates ) for i , p := range s . prevUpdates { if p . t . After ( deleteBefore ) { keepFrom = i break } } s . prevUpdates = append ( s . prevUpdates [ keepFrom : ] , prevUpdate { update , updateHash , updateTime } ) return newSurrogateGossipData ( update ) , nil } 
func ( d * surrogateGossipData ) Merge ( other GossipData ) GossipData { o := other . ( * surrogateGossipData ) messages := make ( [ ] [ ] byte , 0 , len ( d . messages ) + len ( o . messages ) ) messages = append ( messages , d . messages ... ) messages = append ( messages , o . messages ... ) return & surrogateGossipData { messages : messages } } 
func generateKeyPair ( ) ( publicKey , privateKey * [ 32 ] byte , err error ) { return box . GenerateKey ( rand . Reader ) } 
func formSessionKey ( remotePublicKey , localPrivateKey * [ 32 ] byte , secretKey [ ] byte ) * [ 32 ] byte { var sharedKey [ 32 ] byte box . Precompute ( & sharedKey , remotePublicKey , localPrivateKey ) sharedKeySlice := sharedKey [ : ] sharedKeySlice = append ( sharedKeySlice , secretKey ... ) sessionKey := sha256 . Sum256 ( sharedKeySlice ) return & sessionKey } 
func newTCPCryptoState ( sessionKey * [ 32 ] byte , outbound bool ) * tcpCryptoState { s := & tcpCryptoState { sessionKey : sessionKey } if outbound { s . nonce [ 0 ] |= ( 1 << 7 ) } s . nonce [ 0 ] |= ( 1 << 6 ) return s } 
func ( sender * gobTCPSender ) Send ( msg [ ] byte ) error { return sender . encoder . Encode ( msg ) } 
func ( sender * lengthPrefixTCPSender ) Send ( msg [ ] byte ) error { l := len ( msg ) if l > maxTCPMsgSize { return fmt . Errorf ( " " , l , maxTCPMsgSize ) } binary . BigEndian . PutUint32 ( prefixedMsg , uint32 ( l ) ) copy ( prefixedMsg [ 4 : ] , msg ) _ , err := sender . writer . Write ( prefixedMsg ) return err } 
func ( sender * encryptedTCPSender ) Send ( msg [ ] byte ) error { sender . Lock ( ) defer sender . Unlock ( ) encodedMsg := secretbox . Seal ( nil , msg , & sender . state . nonce , sender . state . sessionKey ) sender . state . advance ( ) return sender . sender . Send ( encodedMsg ) } 
func ( receiver * gobTCPReceiver ) Receive ( ) ( [ ] byte , error ) { var msg [ ] byte err := receiver . decoder . Decode ( & msg ) return msg , err } 
func ( receiver * lengthPrefixTCPReceiver ) Receive ( ) ( [ ] byte , error ) { lenPrefix := make ( [ ] byte , 4 ) if _ , err := io . ReadFull ( receiver . reader , lenPrefix ) ; err != nil { return nil , err } l := binary . BigEndian . Uint32 ( lenPrefix ) if l > maxTCPMsgSize { return nil , fmt . Errorf ( " " , l , maxTCPMsgSize ) } msg := make ( [ ] byte , l ) _ , err := io . ReadFull ( receiver . reader , msg ) return msg , err } 
func ( receiver * encryptedTCPReceiver ) Receive ( ) ( [ ] byte , error ) { msg , err := receiver . receiver . Receive ( ) if err != nil { return nil , err } decodedMsg , success := secretbox . Open ( nil , msg , & receiver . state . nonce , receiver . state . sessionKey ) if ! success { return nil , fmt . Errorf ( " " ) } receiver . state . advance ( ) return decodedMsg , nil } 
func newPeer ( self mesh . PeerName , logger * log . Logger ) * peer { actions := make ( chan func ( ) ) p := & peer { st : newState ( self ) , send : nil , go p . loop ( actions ) return p } 
func ( p * peer ) incr ( ) ( result int ) { c := make ( chan struct { } ) p . actions <- func ( ) { defer close ( c ) st := p . st . incr ( ) if p . send != nil { p . send . GossipBroadcast ( st ) } else { p . logger . Printf ( " " ) } result = st . get ( ) } <- c return result } 
func ( p * peer ) Gossip ( ) ( complete mesh . GossipData ) { complete = p . st . copy ( ) p . logger . Printf ( " " , complete . ( * state ) . set ) return complete } 
func ( p * peer ) OnGossip ( buf [ ] byte ) ( delta mesh . GossipData , err error ) { var set map [ mesh . PeerName ] int if err := gob . NewDecoder ( bytes . NewReader ( buf ) ) . Decode ( & set ) ; err != nil { return nil , err } delta = p . st . mergeDelta ( set ) if delta == nil { p . logger . Printf ( " " , set , delta ) } else { p . logger . Printf ( " " , set , delta . ( * state ) . set ) } return delta , nil } 
func ( p * peer ) OnGossipBroadcast ( src mesh . PeerName , buf [ ] byte ) ( received mesh . GossipData , err error ) { var set map [ mesh . PeerName ] int if err := gob . NewDecoder ( bytes . NewReader ( buf ) ) . Decode ( & set ) ; err != nil { return nil , err } received = p . st . mergeReceived ( set ) if received == nil { p . logger . Printf ( " " , src , set , received ) } else { p . logger . Printf ( " " , src , set , received . ( * state ) . set ) } return received , nil } 
func ( p * peer ) OnGossipUnicast ( src mesh . PeerName , buf [ ] byte ) error { var set map [ mesh . PeerName ] int if err := gob . NewDecoder ( bytes . NewReader ( buf ) ) . Decode ( & set ) ; err != nil { return err } complete := p . st . mergeComplete ( set ) p . logger . Printf ( " " , src , set , complete ) return nil } 
func makeRaftPeer ( addr net . Addr ) raft . Peer { return raft . Peer { ID : uint64 ( addr . ( meshconn . MeshAddr ) . PeerUID ) , Context : nil , } 
func ( peer * Peer ) String ( ) string { return fmt . Sprint ( peer . Name , " " , peer . NickName , " " ) } 
func ( peer * Peer ) routes ( stopAt * Peer , establishedAndSymmetric bool ) ( bool , map [ PeerName ] PeerName ) { routes := make ( unicastRoutes ) routes [ peer . Name ] = UnknownPeerName nextWorklist := [ ] * Peer { peer } for len ( nextWorklist ) > 0 { worklist := nextWorklist sort . Sort ( listOfPeers ( worklist ) ) nextWorklist = [ ] * Peer { } for _ , curPeer := range worklist { if curPeer == stopAt { return true , routes } curPeer . forEachConnectedPeer ( establishedAndSymmetric , routes , func ( remotePeer * Peer ) { nextWorklist = append ( nextWorklist , remotePeer ) remoteName := remotePeer . Name } else { routes [ remoteName ] = routes [ curPeer . Name ] } } ) } } return false , routes } 
func ( peer * Peer ) forEachConnectedPeer ( establishedAndSymmetric bool , exclude map [ PeerName ] PeerName , f func ( * Peer ) ) { for remoteName , conn := range peer . connections { if establishedAndSymmetric && ! conn . isEstablished ( ) { continue } if _ , found := exclude [ remoteName ] ; found { continue } remotePeer := conn . Remote ( ) if remoteConn , found := remotePeer . connections [ peer . Name ] ; ! establishedAndSymmetric || ( found && remoteConn . isEstablished ( ) ) { f ( remotePeer ) } } } 
func parsePeerUID ( s string ) ( PeerUID , error ) { uid , err := strconv . ParseUint ( s , 10 , 64 ) return PeerUID ( uid ) , err } 
func ( lop listOfPeers ) Swap ( i , j int ) { lop [ i ] , lop [ j ] = lop [ j ] , lop [ i ] } 
func ( lop listOfPeers ) Less ( i , j int ) bool { return lop [ i ] . Name < lop [ j ] . Name } 
func ( params protocolIntroParams ) doIntro ( ) ( res protocolIntroResults , err error ) { if err = params . Conn . SetDeadline ( time . Now ( ) . Add ( headerTimeout ) ) ; err != nil { return } if res . Version , err = params . exchangeProtocolHeader ( ) ; err != nil { return } var pubKey , privKey * [ 32 ] byte if params . Password != nil { if pubKey , privKey , err = generateKeyPair ( ) ; err != nil { return } } if err = params . Conn . SetWriteDeadline ( time . Time { } ) ; err != nil { return } if err = params . Conn . SetReadDeadline ( time . Now ( ) . Add ( tcpHeartbeat * 2 ) ) ; err != nil { return } switch res . Version { case 1 : err = res . doIntroV1 ( params , pubKey , privKey ) case 2 : err = res . doIntroV2 ( params , pubKey , privKey ) default : panic ( " " ) } return } 
func ( res * protocolIntroResults ) doIntroV1 ( params protocolIntroParams , pubKey , privKey * [ 32 ] byte ) error { features := filterV1Features ( params . Features ) if pubKey != nil { features [ " " ] = hex . EncodeToString ( pubKey [ : ] ) } enc := gob . NewEncoder ( params . Conn ) dec := gob . NewDecoder ( params . Conn ) go func ( ) { encodeDone <- enc . Encode ( features ) } ( ) if err := dec . Decode ( & res . Features ) ; err != nil { return err } if err := <- encodeDone ; err != nil { return err } res . Sender = newGobTCPSender ( enc ) res . Receiver = newGobTCPReceiver ( dec ) if pubKey == nil { if _ , present := res . Features [ " " ] ; present { return errExpectedNoCrypto } } else { remotePubKeyStr , ok := res . Features [ " " ] if ! ok { return errExpectedCrypto } remotePubKey , err := hex . DecodeString ( remotePubKeyStr ) if err != nil { return err } res . setupCrypto ( params , remotePubKey , privKey ) } res . Features = filterV1Features ( res . Features ) return nil } 
func filterV1Features ( intro map [ string ] string ) map [ string ] string { safe := make ( map [ string ] string ) for _ , k := range protocolV1Features { if val , ok := intro [ k ] ; ok { safe [ k ] = val } } return safe } 
func ( res * protocolIntroResults ) doIntroV2 ( params protocolIntroParams , pubKey , privKey * [ 32 ] byte ) error { if pubKey == nil { wbuf = [ ] byte { 0 } } else { wbuf = make ( [ ] byte , 1 + len ( * pubKey ) ) wbuf [ 0 ] = 1 copy ( wbuf [ 1 : ] , ( * pubKey ) [ : ] ) } go func ( ) { _ , err := params . Conn . Write ( wbuf ) writeDone <- err } ( ) rbuf := make ( [ ] byte , 1 ) if _ , err := io . ReadFull ( params . Conn , rbuf ) ; err != nil { return err } switch rbuf [ 0 ] { case 0 : if pubKey != nil { return errExpectedCrypto } res . Sender = newLengthPrefixTCPSender ( params . Conn ) res . Receiver = newLengthPrefixTCPReceiver ( params . Conn ) case 1 : if pubKey == nil { return errExpectedNoCrypto } rbuf = make ( [ ] byte , len ( pubKey ) ) if _ , err := io . ReadFull ( params . Conn , rbuf ) ; err != nil { return err } res . Sender = newLengthPrefixTCPSender ( params . Conn ) res . Receiver = newLengthPrefixTCPReceiver ( params . Conn ) res . setupCrypto ( params , rbuf , privKey ) default : return fmt . Errorf ( " " , rbuf [ 0 ] ) } if err := <- writeDone ; err != nil { return err } if err := gob . NewEncoder ( buf ) . Encode ( & params . Features ) ; err != nil { writeDone <- err return } writeDone <- res . Sender . Send ( buf . Bytes ( ) ) } ( ) rbuf , err := res . Receiver . Receive ( ) if err != nil { return err } if err := gob . NewDecoder ( bytes . NewReader ( rbuf ) ) . Decode ( & res . Features ) ; err != nil { return err } if err := <- writeDone ; err != nil { return err } return nil } 
func newConnectionMaker ( ourself * localPeer , peers * Peers , localAddr string , port int , discovery bool , logger Logger ) * connectionMaker { actionChan := make ( chan connectionMakerAction , ChannelSize ) cm := & connectionMaker { ourself : ourself , peers : peers , localAddr : localAddr , port : port , discovery : discovery , directPeers : peerAddrs { } , targets : make ( map [ string ] * target ) , connections : make ( map [ Connection ] struct { } ) , actionChan : actionChan , logger : logger , } go cm . queryLoop ( actionChan ) return cm } 
func ( cm * connectionMaker ) InitiateConnections ( peers [ ] string , replace bool ) [ ] error { errors := [ ] error { } addrs := peerAddrs { } for _ , peer := range peers { host , port , err := net . SplitHostPort ( peer ) if err != nil { host = peer port = " " } if host == " " || ! isAlnum ( port ) { errors = append ( errors , fmt . Errorf ( " " , peer ) ) } else if addr , err := net . ResolveTCPAddr ( " " , fmt . Sprintf ( " " , host , port ) ) ; err != nil { errors = append ( errors , err ) } else { addrs [ peer ] = addr } } cm . actionChan <- func ( ) bool { if replace { cm . directPeers = peerAddrs { } } for peer , addr := range addrs { cm . directPeers [ peer ] = addr } } return true } return errors } 
func ( cm * connectionMaker ) ForgetConnections ( peers [ ] string ) { cm . actionChan <- func ( ) bool { for _ , peer := range peers { delete ( cm . directPeers , peer ) } return true } } 
func ( cm * connectionMaker ) Targets ( activeOnly bool ) [ ] string { resultChan := make ( chan [ ] string ) cm . actionChan <- func ( ) bool { var slice [ ] string for peer , addr := range cm . directPeers { if activeOnly { if target , ok := cm . targets [ cm . completeAddr ( * addr ) ] ; ok && target . tryAfter . IsZero ( ) { continue } } slice = append ( slice , peer ) } resultChan <- slice return false } return <- resultChan } 
func ( cm * connectionMaker ) connectionAborted ( address string , err error ) { cm . actionChan <- func ( ) bool { target := cm . targets [ address ] target . state = targetWaiting target . lastError = err target . nextTryLater ( ) return true } } 
func ( cm * connectionMaker ) connectionCreated ( conn Connection ) { cm . actionChan <- func ( ) bool { cm . connections [ conn ] = struct { } { } if conn . isOutbound ( ) { target := cm . targets [ conn . remoteTCPAddress ( ) ] target . state = targetConnected } return false } } 
func ( cm * connectionMaker ) connectionTerminated ( conn Connection , err error ) { cm . actionChan <- func ( ) bool { if err != errConnectToSelf { cm . terminationCount ++ } delete ( cm . connections , conn ) if conn . isOutbound ( ) { target := cm . targets [ conn . remoteTCPAddress ( ) ] target . state = targetWaiting target . lastError = err _ , peerNameCollision := err . ( * peerNameCollisionError ) switch { case peerNameCollision || err == errConnectToSelf : target . nextTryNever ( ) case time . Now ( ) . After ( target . tryAfter . Add ( resetAfter ) ) : target . nextTryNow ( ) default : target . nextTryLater ( ) } } return true } } 
func ( t * target ) nextTryLater ( ) { t . tryAfter = time . Now ( ) . Add ( t . tryInterval / 2 + time . Duration ( rand . Int63n ( int64 ( t . tryInterval ) ) ) ) t . tryInterval = t . tryInterval * 3 / 2 if t . tryInterval > maxInterval { t . tryInterval = maxInterval } } 
func newGossipSender ( makeMsg func ( msg [ ] byte ) protocolMsg , makeBroadcastMsg func ( srcName PeerName , msg [ ] byte ) protocolMsg , sender protocolSender , stop <- chan struct { } , ) * gossipSender { more := make ( chan struct { } , 1 ) flush := make ( chan chan <- bool ) s := & gossipSender { makeMsg : makeMsg , makeBroadcastMsg : makeBroadcastMsg , sender : sender , broadcasts : make ( map [ PeerName ] GossipData ) , more : more , flush : flush , } go s . run ( stop , more , flush ) return s } 
func ( s * gossipSender ) Send ( data GossipData ) { s . Lock ( ) defer s . Unlock ( ) if s . empty ( ) { defer s . prod ( ) } if s . gossip == nil { s . gossip = data } else { s . gossip = s . gossip . Merge ( data ) } } 
func ( s * gossipSender ) Broadcast ( srcName PeerName , data GossipData ) { s . Lock ( ) defer s . Unlock ( ) if s . empty ( ) { defer s . prod ( ) } d , found := s . broadcasts [ srcName ] if ! found { s . broadcasts [ srcName ] = data } else { s . broadcasts [ srcName ] = d . Merge ( data ) } } 
func ( s * gossipSender ) Flush ( ) bool { ch := make ( chan bool ) s . flush <- ch return <- ch } 
func newGossipSenders ( sender protocolSender , stop <- chan struct { } ) * gossipSenders { return & gossipSenders { sender : sender , stop : stop , senders : make ( map [ string ] * gossipSender ) , } } 
func ( gs * gossipSenders ) Sender ( channelName string , makeGossipSender func ( sender protocolSender , stop <- chan struct { } ) * gossipSender ) * gossipSender { gs . Lock ( ) defer gs . Unlock ( ) s , found := gs . senders [ channelName ] if ! found { s = makeGossipSender ( gs . sender , gs . stop ) gs . senders [ channelName ] = s } return s } 
func ( gs * gossipSenders ) Flush ( ) bool { sent := false gs . Lock ( ) defer gs . Unlock ( ) for _ , sender := range gs . senders { sent = sender . Flush ( ) || sent } return sent } 
func findMainPath ( ) string { pc := make ( [ ] uintptr , 100 ) n := runtime . Callers ( 2 , pc ) frames := runtime . CallersFrames ( pc [ : n ] ) for { frame , more := frames . Next ( ) } if ! more { break } } return " " } 
func Create ( c context . Context , clientID string ) ( token string , err error ) { req := & pb . CreateChannelRequest { ApplicationKey : & clientID , } resp := & pb . CreateChannelResponse { } err = internal . Call ( c , service , " " , req , resp ) token = resp . GetToken ( ) return token , remapError ( err ) } 
func Send ( c context . Context , clientID , message string ) error { req := & pb . SendMessageRequest { ApplicationKey : & clientID , Message : & message , } resp := & basepb . VoidProto { } return remapError ( internal . Call ( c , service , " " , req , resp ) ) } 
func SendJSON ( c context . Context , clientID string , value interface { } ) error { m , err := json . Marshal ( value ) if err != nil { return err } return Send ( c , clientID , string ( m ) ) } 
func remapError ( err error ) error { if e , ok := err . ( * internal . APIError ) ; ok { if e . Service == " " { e . Service = " " } } return err } 
func FullyQualifiedAppID ( ctx netcontext . Context ) string { if id , ok := ctx . Value ( & appIDOverrideKey ) . ( string ) ; ok { return id } return fullyQualifiedAppID ( ctx ) } 
func NamespacedContext ( ctx netcontext . Context , namespace string ) netcontext . Context { return withNamespace ( ctx , namespace ) } 
func protoToItem ( p * pb . MemcacheGetResponse_Item ) * Item { return & Item { Key : string ( p . Key ) , Value : p . Value , Flags : p . GetFlags ( ) , casID : p . GetCasId ( ) , } } 
func singleError ( err error ) error { if me , ok := err . ( appengine . MultiError ) ; ok { return me [ 0 ] } return err } 
func Get ( c context . Context , key string ) ( * Item , error ) { m , err := GetMulti ( c , [ ] string { key } ) if err != nil { return nil , err } if _ , ok := m [ key ] ; ! ok { return nil , ErrCacheMiss } return m [ key ] , nil } 
func GetMulti ( c context . Context , key [ ] string ) ( map [ string ] * Item , error ) { if len ( key ) == 0 { return nil , nil } keyAsBytes := make ( [ ] [ ] byte , len ( key ) ) for i , k := range key { keyAsBytes [ i ] = [ ] byte ( k ) } req := & pb . MemcacheGetRequest { Key : keyAsBytes , ForCas : proto . Bool ( true ) , } res := & pb . MemcacheGetResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } m := make ( map [ string ] * Item , len ( res . Item ) ) for _ , p := range res . Item { t := protoToItem ( p ) m [ t . Key ] = t } return m , nil } 
func Delete ( c context . Context , key string ) error { return singleError ( DeleteMulti ( c , [ ] string { key } ) ) } 
func DeleteMulti ( c context . Context , key [ ] string ) error { if len ( key ) == 0 { return nil } req := & pb . MemcacheDeleteRequest { Item : make ( [ ] * pb . MemcacheDeleteRequest_Item , len ( key ) ) , } for i , k := range key { req . Item [ i ] = & pb . MemcacheDeleteRequest_Item { Key : [ ] byte ( k ) } } res := & pb . MemcacheDeleteResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } if len ( res . DeleteStatus ) != len ( key ) { return ErrServerError } me , any := make ( appengine . MultiError , len ( key ) ) , false for i , s := range res . DeleteStatus { switch s { case pb . MemcacheDeleteResponse_DELETED : any = true default : me [ i ] = ErrServerError any = true } } if any { return me } return nil } 
func Increment ( c context . Context , key string , delta int64 , initialValue uint64 ) ( newValue uint64 , err error ) { return incr ( c , key , delta , & initialValue ) } 
func IncrementExisting ( c context . Context , key string , delta int64 ) ( newValue uint64 , err error ) { return incr ( c , key , delta , nil ) } 
func set ( c context . Context , item [ ] * Item , value [ ] [ ] byte , policy pb . MemcacheSetRequest_SetPolicy ) error { if len ( item ) == 0 { return nil } req := & pb . MemcacheSetRequest { Item : make ( [ ] * pb . MemcacheSetRequest_Item , len ( item ) ) , } for i , t := range item { p := & pb . MemcacheSetRequest_Item { Key : [ ] byte ( t . Key ) , } if value == nil { p . Value = t . Value } else { p . Value = value [ i ] } if t . Flags != 0 { p . Flags = proto . Uint32 ( t . Flags ) } if t . Expiration != 0 { } else if t . Expiration >= thirtyYears { p . ExpirationTime = proto . Uint32 ( uint32 ( time . Now ( ) . Unix ( ) ) + uint32 ( t . Expiration / time . Second ) ) } else { p . ExpirationTime = proto . Uint32 ( uint32 ( t . Expiration / time . Second ) ) } } if t . casID != 0 { p . CasId = proto . Uint64 ( t . casID ) p . ForCas = proto . Bool ( true ) } p . SetPolicy = policy . Enum ( ) req . Item [ i ] = p } res := & pb . MemcacheSetResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } if len ( res . SetStatus ) != len ( item ) { return ErrServerError } me , any := make ( appengine . MultiError , len ( item ) ) , false for i , st := range res . SetStatus { var err error switch st { case pb . MemcacheSetResponse_STORED : case pb . MemcacheSetResponse_EXISTS : err = ErrCASConflict default : err = ErrServerError } if err != nil { me [ i ] = err any = true } } if any { return me } return nil } 
func Set ( c context . Context , item * Item ) error { return singleError ( set ( c , [ ] * Item { item } , nil , pb . MemcacheSetRequest_SET ) ) } 
func SetMulti ( c context . Context , item [ ] * Item ) error { return set ( c , item , nil , pb . MemcacheSetRequest_SET ) } 
func Add ( c context . Context , item * Item ) error { return singleError ( set ( c , [ ] * Item { item } , nil , pb . MemcacheSetRequest_ADD ) ) } 
func AddMulti ( c context . Context , item [ ] * Item ) error { return set ( c , item , nil , pb . MemcacheSetRequest_ADD ) } 
func CompareAndSwap ( c context . Context , item * Item ) error { return singleError ( set ( c , [ ] * Item { item } , nil , pb . MemcacheSetRequest_CAS ) ) } 
func CompareAndSwapMulti ( c context . Context , item [ ] * Item ) error { return set ( c , item , nil , pb . MemcacheSetRequest_CAS ) } 
func ( cd Codec ) Get ( c context . Context , key string , v interface { } ) ( * Item , error ) { i , err := Get ( c , key ) if err != nil { return nil , err } if err := cd . Unmarshal ( i . Value , v ) ; err != nil { return nil , err } return i , nil } 
func ( cd Codec ) Set ( c context . Context , item * Item ) error { return singleError ( cd . set ( c , [ ] * Item { item } , pb . MemcacheSetRequest_SET ) ) } 
func ( cd Codec ) SetMulti ( c context . Context , items [ ] * Item ) error { return cd . set ( c , items , pb . MemcacheSetRequest_SET ) } 
func ( cd Codec ) Add ( c context . Context , item * Item ) error { return singleError ( cd . set ( c , [ ] * Item { item } , pb . MemcacheSetRequest_ADD ) ) } 
func ( cd Codec ) AddMulti ( c context . Context , items [ ] * Item ) error { return cd . set ( c , items , pb . MemcacheSetRequest_ADD ) } 
func ( cd Codec ) CompareAndSwap ( c context . Context , item * Item ) error { return singleError ( cd . set ( c , [ ] * Item { item } , pb . MemcacheSetRequest_CAS ) ) } 
func ( cd Codec ) CompareAndSwapMulti ( c context . Context , items [ ] * Item ) error { return cd . set ( c , items , pb . MemcacheSetRequest_CAS ) } 
func Stats ( c context . Context ) ( * Statistics , error ) { req := & pb . MemcacheStatsRequest { } res := & pb . MemcacheStatsResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } if res . Stats == nil { return nil , ErrNoStats } return & Statistics { Hits : * res . Stats . Hits , Misses : * res . Stats . Misses , ByteHits : * res . Stats . ByteHits , Items : * res . Stats . Items , Bytes : * res . Stats . Bytes , Oldest : int64 ( * res . Stats . OldestItemAge ) , } , nil } 
func Flush ( c context . Context ) error { req := & pb . MemcacheFlushRequest { } res := & pb . MemcacheFlushResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func init ( ) { http . HandleFunc ( " " , handleBackground ) sc := make ( chan send ) rc := make ( chan recv ) sendc , recvc = sc , rc go matchmaker ( sc , rc ) } 
func RunInBackground ( c context . Context , f func ( c context . Context ) ) error { req := & pb . StartBackgroundRequestRequest { } res := & pb . StartBackgroundRequestResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } sendc <- send { res . GetRequestId ( ) , f } return nil } 
func List ( c context . Context ) ( [ ] string , error ) { req := & pb . GetModulesRequest { } res := & pb . GetModulesResponse { } err := internal . Call ( c , " " , " " , req , res ) return res . Module , err } 
func NumInstances ( c context . Context , module , version string ) ( int , error ) { req := & pb . GetNumInstancesRequest { } if module != " " { req . Module = & module } if version != " " { req . Version = & version } res := & pb . GetNumInstancesResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return 0 , err } return int ( * res . Instances ) , nil } 
func SetNumInstances ( c context . Context , module , version string , instances int ) error { req := & pb . SetNumInstancesRequest { } if module != " " { req . Module = & module } if version != " " { req . Version = & version } req . Instances = proto . Int64 ( int64 ( instances ) ) res := & pb . SetNumInstancesResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func Versions ( c context . Context , module string ) ( [ ] string , error ) { req := & pb . GetVersionsRequest { } if module != " " { req . Module = & module } res := & pb . GetVersionsResponse { } err := internal . Call ( c , " " , " " , req , res ) return res . GetVersion ( ) , err } 
func DefaultVersion ( c context . Context , module string ) ( string , error ) { req := & pb . GetDefaultVersionRequest { } if module != " " { req . Module = & module } res := & pb . GetDefaultVersionResponse { } err := internal . Call ( c , " " , " " , req , res ) return res . GetVersion ( ) , err } 
func Start ( c context . Context , module , version string ) error { req := & pb . StartModuleRequest { } if module != " " { req . Module = & module } if version != " " { req . Version = & version } res := & pb . StartModuleResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func Stop ( c context . Context , module , version string ) error { req := & pb . StopModuleRequest { } if module != " " { req . Module = & module } if version != " " { req . Version = & version } res := & pb . StopModuleResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func ( q * Query ) Ancestor ( ancestor * Key ) * Query { q = q . clone ( ) if ancestor == nil { q . err = errors . New ( " " ) return q } q . ancestor = ancestor return q } 
func ( q * Query ) EventualConsistency ( ) * Query { q = q . clone ( ) q . eventual = true return q } 
func ( q * Query ) Filter ( filterStr string , value interface { } ) * Query { q = q . clone ( ) filterStr = strings . TrimSpace ( filterStr ) if len ( filterStr ) < 1 { q . err = errors . New ( " " + filterStr ) return q } f := filter { FieldName : strings . TrimRight ( filterStr , " " ) , Value : value , } switch op := strings . TrimSpace ( filterStr [ len ( f . FieldName ) : ] ) ; op { case " " : f . Op = lessEq case " " : f . Op = greaterEq case " " : f . Op = lessThan case " " : f . Op = greaterThan case " " : f . Op = equal default : q . err = fmt . Errorf ( " " , op , filterStr ) return q } q . filter = append ( q . filter , f ) return q } 
func ( q * Query ) Order ( fieldName string ) * Query { q = q . clone ( ) fieldName = strings . TrimSpace ( fieldName ) o := order { Direction : ascending , FieldName : fieldName , } if strings . HasPrefix ( fieldName , " " ) { o . Direction = descending o . FieldName = strings . TrimSpace ( fieldName [ 1 : ] ) } else if strings . HasPrefix ( fieldName , " " ) { q . err = fmt . Errorf ( " " , fieldName ) return q } if len ( o . FieldName ) == 0 { q . err = errors . New ( " " ) return q } q . order = append ( q . order , o ) return q } 
func ( q * Query ) Project ( fieldNames ... string ) * Query { q = q . clone ( ) q . projection = append ( [ ] string ( nil ) , fieldNames ... ) return q } 
func ( q * Query ) Distinct ( ) * Query { q = q . clone ( ) q . distinct = true return q } 
func ( q * Query ) DistinctOn ( fieldNames ... string ) * Query { q = q . clone ( ) q . distinctOn = fieldNames return q } 
func ( q * Query ) KeysOnly ( ) * Query { q = q . clone ( ) q . keysOnly = true return q } 
func ( q * Query ) Limit ( limit int ) * Query { q = q . clone ( ) if limit < math . MinInt32 || limit > math . MaxInt32 { q . err = errors . New ( " " ) return q } q . limit = int32 ( limit ) return q } 
func ( q * Query ) Offset ( offset int ) * Query { q = q . clone ( ) if offset < 0 { q . err = errors . New ( " " ) return q } if offset > math . MaxInt32 { q . err = errors . New ( " " ) return q } q . offset = int32 ( offset ) return q } 
func ( q * Query ) BatchSize ( size int ) * Query { q = q . clone ( ) if size <= 0 || size > math . MaxInt32 { q . err = errors . New ( " " ) return q } q . count = int32 ( size ) return q } 
func ( q * Query ) Start ( c Cursor ) * Query { q = q . clone ( ) if c . cc == nil { q . err = errors . New ( " " ) return q } q . start = c . cc return q } 
func ( q * Query ) End ( c Cursor ) * Query { q = q . clone ( ) if c . cc == nil { q . err = errors . New ( " " ) return q } q . end = c . cc return q } 
func ( q * Query ) toProto ( dst * pb . Query , appID string ) error { if len ( q . projection ) != 0 && q . keysOnly { return errors . New ( " " ) } if len ( q . distinctOn ) != 0 && q . distinct { return errors . New ( " " ) } dst . Reset ( ) dst . App = proto . String ( appID ) if q . kind != " " { dst . Kind = proto . String ( q . kind ) } if q . ancestor != nil { dst . Ancestor = keyToProto ( appID , q . ancestor ) if q . eventual { dst . Strong = proto . Bool ( false ) } } if q . projection != nil { dst . PropertyName = q . projection if len ( q . distinctOn ) != 0 { dst . GroupByPropertyName = q . distinctOn } if q . distinct { dst . GroupByPropertyName = q . projection } } if q . keysOnly { dst . KeysOnly = proto . Bool ( true ) dst . RequirePerfectPlan = proto . Bool ( true ) } for _ , qf := range q . filter { if qf . FieldName == " " { return errors . New ( " " ) } p , errStr := valueToProto ( appID , qf . FieldName , reflect . ValueOf ( qf . Value ) , false ) if errStr != " " { return errors . New ( " " + errStr ) } xf := & pb . Query_Filter { Op : operatorToProto [ qf . Op ] , Property : [ ] * pb . Property { p } , } if xf . Op == nil { return errors . New ( " " ) } dst . Filter = append ( dst . Filter , xf ) } for _ , qo := range q . order { if qo . FieldName == " " { return errors . New ( " " ) } xo := & pb . Query_Order { Property : proto . String ( qo . FieldName ) , Direction : sortDirectionToProto [ qo . Direction ] , } if xo . Direction == nil { return errors . New ( " " ) } dst . Order = append ( dst . Order , xo ) } if q . limit >= 0 { dst . Limit = proto . Int32 ( q . limit ) } if q . offset != 0 { dst . Offset = proto . Int32 ( q . offset ) } if q . count != 0 { dst . Count = proto . Int32 ( q . count ) } dst . CompiledCursor = q . start dst . EndCompiledCursor = q . end dst . Compile = proto . Bool ( true ) return nil } 
func ( q * Query ) Count ( c context . Context ) ( int , error ) { } newQ . keysOnly = len ( newQ . projection ) == 0 newQ . limit = 0 if q . limit < 0 { } else { newQ . offset = q . offset + q . limit if newQ . offset < 0 { } } req := & pb . Query { } if err := newQ . toProto ( req , internal . FullyQualifiedAppID ( c ) ) ; err != nil { return 0 , err } res := & pb . QueryResult { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return 0 , err } for { } n += res . GetSkippedResults ( ) if ! res . GetMoreResults ( ) { break } if err := callNext ( c , res , newQ . offset - n , q . count ) ; err != nil { return 0 , err } } n -= q . offset if n < 0 { } return int ( n ) , nil } 
func callNext ( c context . Context , res * pb . QueryResult , offset , count int32 ) error { if res . Cursor == nil { return errors . New ( " " ) } req := & pb . NextRequest { Cursor : res . Cursor , } if count >= 0 { req . Count = proto . Int32 ( count ) } if offset != 0 { req . Offset = proto . Int32 ( offset ) } if res . CompiledCursor != nil { req . Compile = proto . Bool ( true ) } res . Reset ( ) return internal . Call ( c , " " , " " , req , res ) } 
func ( q * Query ) GetAll ( c context . Context , dst interface { } ) ( [ ] * Key , error ) { var ( dv reflect . Value mat multiArgType elemType reflect . Type errFieldMismatch error ) if ! q . keysOnly { dv = reflect . ValueOf ( dst ) if dv . Kind ( ) != reflect . Ptr || dv . IsNil ( ) { return nil , ErrInvalidEntityType } dv = dv . Elem ( ) mat , elemType = checkMultiArg ( dv ) if mat == multiArgTypeInvalid || mat == multiArgTypeInterface { return nil , ErrInvalidEntityType } } var keys [ ] * Key for t := q . Run ( c ) ; ; { k , e , err := t . next ( ) if err == Done { break } if err != nil { return keys , err } if ! q . keysOnly { ev := reflect . New ( elemType ) if elemType . Kind ( ) == reflect . Map { ev . Elem ( ) . Set ( x ) } if err = loadEntity ( ev . Interface ( ) , e ) ; err != nil { if _ , ok := err . ( * ErrFieldMismatch ) ; ok { } else { return keys , err } } if mat != multiArgTypeStructPtr { ev = ev . Elem ( ) } dv . Set ( reflect . Append ( dv , ev ) ) } keys = append ( keys , k ) } return keys , errFieldMismatch } 
func ( q * Query ) Run ( c context . Context ) * Iterator { if q . err != nil { return & Iterator { err : q . err } } t := & Iterator { c : c , limit : q . limit , count : q . count , q : q , prevCC : q . start , } var req pb . Query if err := q . toProto ( & req , internal . FullyQualifiedAppID ( c ) ) ; err != nil { t . err = err return t } if err := internal . Call ( c , " " , " " , & req , & t . res ) ; err != nil { t . err = err return t } offset := q . offset - t . res . GetSkippedResults ( ) var count int32 if t . count > 0 && ( t . limit < 0 || t . count < t . limit ) { count = t . count } else { count = t . limit } for offset > 0 && t . res . GetMoreResults ( ) { t . prevCC = t . res . CompiledCursor if err := callNext ( t . c , & t . res , offset , count ) ; err != nil { t . err = err break } skip := t . res . GetSkippedResults ( ) if skip < 0 { t . err = errors . New ( " " ) break } offset -= skip } if offset < 0 { t . err = errors . New ( " " ) } return t } 
func ( t * Iterator ) Next ( dst interface { } ) ( * Key , error ) { k , e , err := t . next ( ) if err != nil { return nil , err } if dst != nil && ! t . q . keysOnly { err = loadEntity ( dst , e ) } return k , err } 
func ( t * Iterator ) Cursor ( ) ( Cursor , error ) { if t . err != nil && t . err != Done { return Cursor { } , t . err } if t . i == 0 && skipped == 0 { if t . prevCC == nil { } return Cursor { t . prevCC } , nil } if t . i == len ( t . res . Result ) { return Cursor { t . res . CompiledCursor } , nil } q . start = t . prevCC q . offset = skipped + int32 ( t . i ) q . limit = 0 q . keysOnly = len ( q . projection ) == 0 t1 := q . Run ( t . c ) _ , _ , err := t1 . next ( ) if err != Done { if err == nil { err = fmt . Errorf ( " " ) } return Cursor { } , err } return Cursor { t1 . res . CompiledCursor } , nil } 
func ( c Cursor ) String ( ) string { if c . cc == nil { return " " } b , err := proto . Marshal ( c . cc ) if err != nil { } return strings . TrimRight ( base64 . URLEncoding . EncodeToString ( b ) , " " ) } 
func DecodeCursor ( s string ) ( Cursor , error ) { if s == " " { return Cursor { & zeroCC } , nil } if n := len ( s ) % 4 ; n != 0 { s += strings . Repeat ( " " , 4 - n ) } b , err := base64 . URLEncoding . DecodeString ( s ) if err != nil { return Cursor { } , err } cc := & pb . CompiledCursor { } if err := proto . Unmarshal ( b , cc ) ; err != nil { return Cursor { } , err } return Cursor { cc } , nil } 
func valueToProto ( defaultAppID , name string , v reflect . Value , multiple bool ) ( p * pb . Property , errStr string ) { var ( pv pb . PropertyValue unsupported bool ) switch v . Kind ( ) { case reflect . Invalid : case reflect . Bool : pv . BooleanValue = proto . Bool ( v . Bool ( ) ) case reflect . String : pv . StringValue = proto . String ( v . String ( ) ) case reflect . Float32 , reflect . Float64 : pv . DoubleValue = proto . Float64 ( v . Float ( ) ) case reflect . Ptr : if k , ok := v . Interface ( ) . ( * Key ) ; ok { if k != nil { pv . Referencevalue = keyToReferenceValue ( defaultAppID , k ) } } else { unsupported = true } case reflect . Struct : switch t := v . Interface ( ) . ( type ) { case time . Time : if t . Before ( minTime ) || t . After ( maxTime ) { return nil , " " } pv . Int64Value = proto . Int64 ( toUnixMicro ( t ) ) case appengine . GeoPoint : if ! t . Valid ( ) { return nil , " " } default : unsupported = true } case reflect . Slice : if b , ok := v . Interface ( ) . ( [ ] byte ) ; ok { pv . StringValue = proto . String ( string ( b ) ) } else { } default : unsupported = true } if unsupported { return nil , " " + v . Type ( ) . String ( ) } p = & pb . Property { Name : proto . String ( name ) , Value : & pv , Multiple : proto . Bool ( multiple ) , } if v . IsValid ( ) { switch v . Interface ( ) . ( type ) { case [ ] byte : p . Meaning = pb . Property_BLOB . Enum ( ) case ByteString : p . Meaning = pb . Property_BYTESTRING . Enum ( ) case appengine . BlobKey : p . Meaning = pb . Property_BLOBKEY . Enum ( ) case time . Time : p . Meaning = pb . Property_GD_WHEN . Enum ( ) case appengine . GeoPoint : p . Meaning = pb . Property_GEORSS_POINT . Enum ( ) } } return p , " " } 
func saveEntity ( defaultAppID string , key * Key , src interface { } ) ( * pb . EntityProto , error ) { var err error var props [ ] Property if e , ok := src . ( PropertyLoadSaver ) ; ok { props , err = e . Save ( ) } else { props , err = SaveStruct ( src ) } if err != nil { return nil , err } return propertiesToProto ( defaultAppID , key , props ) } 
func ( l * FieldList ) Load ( f [ ] Field , _ * DocumentMetadata ) error { * l = append ( * l , f ... ) return nil } 
func ( m * AppOverride ) GetNumMemcachegBackends ( ) int32 { if m != nil && m . NumMemcachegBackends != nil { return * m . NumMemcachegBackends } return 0 } 
func ( m * AppOverride ) GetIgnoreShardlock ( ) bool { if m != nil && m . IgnoreShardlock != nil { return * m . IgnoreShardlock } return false } 
func ( m * AppOverride ) GetMemcachePoolHint ( ) string { if m != nil && m . MemcachePoolHint != nil { return * m . MemcachePoolHint } return " " } 
func Namespace ( c context . Context , namespace string ) ( context . Context , error ) { if ! validNamespace . MatchString ( namespace ) { return nil , fmt . Errorf ( " " , namespace , validNamespace ) } return internal . NamespacedContext ( c , namespace ) , nil } 
func ( cfg * TypeConfig ) typeof ( name string ) string { if cfg . Var != nil { if t := cfg . Var [ name ] ; t != " " { return t } } if cfg . Func != nil { if t := cfg . Func [ name ] ; t != " " { return " " + t } } return " " } 
func ( typ * Type ) dot ( cfg * TypeConfig , name string ) string { if typ . Field != nil { if t := typ . Field [ name ] ; t != " " { return t } } if typ . Method != nil { if t := typ . Method [ name ] ; t != " " { return t } } for _ , e := range typ . Embed { etyp := cfg . Type [ e ] if etyp != nil { if t := etyp . dot ( cfg , name ) ; t != " " { return t } } } return " " } 
func typecheck ( cfg * TypeConfig , f * ast . File ) ( typeof map [ interface { } ] string , assign map [ string ] [ ] interface { } ) { typeof = make ( map [ interface { } ] string ) assign = make ( map [ string ] [ ] interface { } ) cfg1 := & TypeConfig { } * cfg1 = * cfg copied := false if ! ok { continue } typecheck1 ( cfg , fn . Type , typeof , assign ) t := typeof [ fn . Type ] if fn . Recv != nil { if ! isType ( rcvr ) { if len ( fn . Recv . List ) != 1 { continue } rcvr = mkType ( gofmt ( fn . Recv . List [ 0 ] . Type ) ) typeof [ fn . Recv . List [ 0 ] . Type ] = rcvr } rcvr = getType ( rcvr ) if rcvr != " " && rcvr [ 0 ] == '*' { rcvr = rcvr [ 1 : ] } typeof [ rcvr + " " + fn . Name . Name ] = t } else { if isType ( t ) { t = getType ( t ) } else { t = gofmt ( fn . Type ) } typeof [ fn . Name ] = t } } if ok { for _ , s := range d . Specs { switch s := s . ( type ) { case * ast . TypeSpec : if cfg1 . Type [ s . Name . Name ] != nil { break } if ! copied { copied = true for k , v := range cfg . Type { cfg1 . Type [ k ] = v } } t := & Type { Field : map [ string ] string { } } cfg1 . Type [ s . Name . Name ] = t switch st := s . Type . ( type ) { case * ast . StructType : for _ , f := range st . Fields . List { for _ , n := range f . Names { t . Field [ n . Name ] = gofmt ( f . Type ) } } case * ast . ArrayType , * ast . StarExpr , * ast . MapType : t . Def = gofmt ( st ) } } } } } typecheck1 ( cfg1 , f , typeof , assign ) return typeof , assign } 
func typecheck1 ( cfg * TypeConfig , f interface { } , typeof map [ interface { } ] string , assign map [ string ] [ ] interface { } ) { } return } typeof [ n ] = typ } } } return } } if len ( lhs ) == 1 && len ( rhs ) == 2 { } else if len ( lhs ) == 2 && len ( rhs ) == 1 { } if typeof [ y ] != " " { set ( x , typeof [ y ] , isDecl ) } else { set ( y , typeof [ x ] , false ) } } } expand := func ( s string ) string { typ := cfg . Type [ s ] if typ != nil && typ . Def != " " { return typ . Def } return s } before := func ( n interface { } ) { case * ast . FuncLit : curfn = append ( curfn , n . Type ) } } } if false && reflect . TypeOf ( n ) . Kind ( ) == reflect . Ptr { fmt . Fprintf ( os . Stderr , " \n " , pos , gofmt ( n ) , t ) } } ( ) } switch n := n . ( type ) { case * ast . FuncDecl , * ast . FuncLit : case * ast . FuncType : typeof [ n ] = mkType ( joinFunc ( split ( typeof [ n . Params ] ) , split ( typeof [ n . Results ] ) ) ) case * ast . FieldList : for _ , field := range n . List { if t != " " { t += " " } t += typeof [ field ] } typeof [ n ] = t case * ast . Field : t := typeof [ n . Type ] if ! isType ( t ) { typeof [ n . Type ] = t } t = getType ( t ) if len ( n . Names ) == 0 { all = t } else { for _ , id := range n . Names { if all != " " { all += " " } all += t typeof [ id . Obj ] = t typeof [ id ] = t } } typeof [ n ] = all case * ast . ValueSpec : if ! isType ( t ) { t = mkType ( gofmt ( n . Type ) ) typeof [ n . Type ] = t } t = getType ( t ) for _ , id := range n . Names { set ( id , t , true ) } } case * ast . AssignStmt : typecheckAssign ( n . Lhs , n . Rhs , n . Tok == token . DEFINE ) case * ast . Ident : } case * ast . SelectorExpr : if t := typeof [ n . X ] ; t != " " { if strings . HasPrefix ( t , " " ) { t = t [ 1 : ] } if typ := cfg . Type [ t ] ; typ != nil { if t := typ . dot ( cfg , name ) ; t != " " { typeof [ n ] = t return } } tt := typeof [ t + " " + name ] if isType ( tt ) { typeof [ n ] = getType ( tt ) return } } if cfg . Type [ str ] != nil { typeof [ n ] = mkType ( str ) return } if t := cfg . typeof ( x . Name + " " + name ) ; t != " " { typeof [ n ] = t return } } case * ast . CallExpr : return } return } in , out := splitFunc ( t ) if in == nil && out == nil { return } typeof [ n ] = join ( out ) for i , arg := range n . Args { if i >= len ( in ) { break } if typeof [ arg ] == " " { typeof [ arg ] = in [ i ] } } case * ast . TypeAssertExpr : return } } else { typeof [ n ] = gofmt ( n . Type ) } case * ast . SliceExpr : case * ast . IndexExpr : if strings . HasPrefix ( t , " " ) || strings . HasPrefix ( t , " " ) { } } case * ast . StarExpr : if isType ( t ) { typeof [ n ] = " " + getType ( t ) } else if strings . HasPrefix ( t , " " ) { typeof [ n ] = t [ len ( " " ) : ] } case * ast . UnaryExpr : if t != " " && n . Op == token . AND { typeof [ n ] = " " + t } case * ast . CompositeLit : case * ast . ParenExpr : case * ast . RangeStmt : t := expand ( typeof [ n . X ] ) if t == " " { return } var key , value string if t == " " { key , value = " " , " " } else if strings . HasPrefix ( t , " " ) { key = " " if i := strings . Index ( t , " " ) ; i >= 0 { value = t [ i + 1 : ] } } else if strings . HasPrefix ( t , " " ) { if i := strings . Index ( t , " " ) ; i >= 0 { key , value = t [ 4 : i ] , t [ i + 1 : ] } } changed := false if n . Key != nil && key != " " { changed = true set ( n . Key , key , n . Tok == token . DEFINE ) } if n . Value != nil && value != " " { changed = true set ( n . Value , value , n . Tok == token . DEFINE ) } } case * ast . TypeSwitchStmt : if ! ok { return } varx , ok := as . Lhs [ 0 ] . ( * ast . Ident ) if ! ok { return } t := typeof [ varx ] for _ , cas := range n . Body . List { cas := cas . ( * ast . CaseClause ) if len ( cas . List ) == 1 { typeof [ varx ] = tt typeof [ varx . Obj ] = tt typecheck1 ( cfg , cas . Body , typeof , assign ) } } } typeof [ varx . Obj ] = t case * ast . ReturnStmt : if len ( curfn ) == 0 { } f := curfn [ len ( curfn ) - 1 ] res := n . Results if f . Results != nil { t := split ( typeof [ f . Results ] ) for i := 0 ; i < len ( res ) && i < len ( t ) ; i ++ { set ( res [ i ] , t [ i ] , false ) } } } } walkBeforeAfter ( f , before , after ) } 
func splitFunc ( s string ) ( in , out [ ] string ) { if ! strings . HasPrefix ( s , " " ) { return nil , nil } i := len ( " " ) nparen := 0 for j := i ; j < len ( s ) ; j ++ { switch s [ j ] { case '(' : nparen ++ case ')' : nparen -- if nparen < 0 { if len ( out ) >= 2 && out [ 0 ] == '(' && out [ len ( out ) - 1 ] == ')' { out = out [ 1 : len ( out ) - 1 ] } return split ( s [ i : j ] ) , split ( out ) } } } return nil , nil } 
func joinFunc ( in , out [ ] string ) string { outs := " " if len ( out ) == 1 { outs = " " + out [ 0 ] } else if len ( out ) > 1 { outs = " " + join ( out ) + " " } return " " + join ( in ) + " " + outs } 
func split ( s string ) [ ] string { out := [ ] string { } i := 0 nparen := 0 for j := 0 ; j < len ( s ) ; j ++ { switch s [ j ] { case ' ' : if i == j { i ++ } case '(' : nparen ++ case ')' : nparen -- if nparen < 0 { } case ',' : if nparen == 0 { if i < j { out = append ( out , s [ i : j ] ) } i = j + 1 } } } if nparen != 0 { } if i < len ( s ) { out = append ( out , s [ i : ] ) } return out } 
func Enabled ( ctx context . Context , api , capability string ) bool { req := & pb . IsEnabledRequest { Package : & api , Capability : [ ] string { capability } , } res := & pb . IsEnabledResponse { } if err := internal . Call ( ctx , " " , " " , req , res ) ; err != nil { log . Warningf ( ctx , " " , err ) return false } switch * res . SummaryStatus { case pb . IsEnabledResponse_ENABLED , pb . IsEnabledResponse_SCHEDULED_FUTURE , pb . IsEnabledResponse_SCHEDULED_NOW : return true case pb . IsEnabledResponse_UNKNOWN : log . Errorf ( ctx , " " , api , capability ) return false default : return false } } 
func ( l * PropertyList ) Load ( p [ ] Property ) error { * l = append ( * l , p ... ) return nil } 
func validPropertyName ( name string ) bool { if name == " " { return false } for _ , s := range strings . Split ( name , " " ) { if s == " " { return false } first := true for _ , c := range s { if first { first = false if c != '_' && ! unicode . IsLetter ( c ) { return false } } else { if c != '_' && ! unicode . IsLetter ( c ) && ! unicode . IsDigit ( c ) { return false } } } } return true } 
func getStructCodec ( t reflect . Type ) ( * structCodec , error ) { structCodecsMutex . Lock ( ) defer structCodecsMutex . Unlock ( ) return getStructCodecLocked ( t ) } 
func getStructCodecLocked ( t reflect . Type ) ( ret * structCodec , retErr error ) { c , ok := structCodecs [ t ] if ok { return c , nil } c = & structCodec { fields : make ( map [ string ] fieldCodec ) , defer func ( ) { if retErr != nil { delete ( structCodecs , t ) } } ( ) for i := 0 ; i < t . NumField ( ) ; i ++ { f := t . Field ( i ) } tags := strings . Split ( f . Tag . Get ( " " ) , " " ) name := tags [ 0 ] opts := make ( map [ string ] bool ) for _ , t := range tags [ 1 : ] { opts [ t ] = true } switch { case name == " " : if ! f . Anonymous { name = f . Name } case name == " " : continue case name == " " : if f . Type != typeOfKeyPtr { return nil , fmt . Errorf ( " " , t ) } c . keyField = i case ! validPropertyName ( name ) : return nil , fmt . Errorf ( " " , name ) } substructType , fIsSlice := reflect . Type ( nil ) , false switch f . Type . Kind ( ) { case reflect . Struct : substructType = f . Type case reflect . Slice : if f . Type . Elem ( ) . Kind ( ) == reflect . Struct { substructType = f . Type . Elem ( ) } fIsSlice = f . Type != typeOfByteSlice c . hasSlice = c . hasSlice || fIsSlice } var sub * structCodec if substructType != nil && substructType != typeOfTime && substructType != typeOfGeoPoint { var err error sub , err = getStructCodecLocked ( substructType ) if err != nil { return nil , err } if ! sub . complete { return nil , fmt . Errorf ( " " , f . Name ) } if fIsSlice && sub . hasSlice { return nil , fmt . Errorf ( " " , f . Name ) } c . hasSlice = c . hasSlice || sub . hasSlice } if _ , ok := c . fields [ subname ] ; ok { return nil , fmt . Errorf ( " " , subname ) } c . fields [ subname ] = fieldCodec { path : append ( [ ] int { i } , subfield . path ... ) , noIndex : subfield . noIndex || opts [ " " ] , omitEmpty : subfield . omitEmpty , structCodec : subfield . structCodec , } } continue } } if _ , ok := c . fields [ name ] ; ok { return nil , fmt . Errorf ( " " , name ) } c . fields [ name ] = fieldCodec { path : [ ] int { i } , noIndex : opts [ " " ] , omitEmpty : opts [ " " ] , structCodec : sub , } } c . complete = true return c , nil } 
func LoadStruct ( dst interface { } , p [ ] Property ) error { x , err := newStructPLS ( dst ) if err != nil { return err } return x . Load ( p ) } 
func SaveStruct ( src interface { } ) ( [ ] Property , error ) { x , err := newStructPLS ( src ) if err != nil { return nil , err } return x . Save ( ) } 
func ServingURL ( c context . Context , key appengine . BlobKey , opts * ServingURLOptions ) ( * url . URL , error ) { req := & pb . ImagesGetUrlBaseRequest { BlobKey : ( * string ) ( & key ) , } if opts != nil && opts . Secure { req . CreateSecureUrl = & opts . Secure } res := & pb . ImagesGetUrlBaseResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } if opts != nil && opts . Size > 0 { u += fmt . Sprintf ( " " , opts . Size ) if opts . Crop { u += " " } } return url . Parse ( u ) } 
func DeleteServingURL ( c context . Context , key appengine . BlobKey ) error { req := & pb . ImagesDeleteUrlBaseRequest { BlobKey : ( * string ) ( & key ) , } res := & pb . ImagesDeleteUrlBaseResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func CurrentOAuth ( c context . Context , scopes ... string ) ( * User , error ) { req := & pb . GetOAuthUserRequest { } if len ( scopes ) != 1 || scopes [ 0 ] != " " { } res := & pb . GetOAuthUserResponse { } err := internal . Call ( c , " " , " " , req , res ) if err != nil { return nil , err } return & User { Email : * res . Email , AuthDomain : * res . AuthDomain , Admin : res . GetIsAdmin ( ) , ID : * res . UserId , ClientID : res . GetClientId ( ) , } , nil } 
func OAuthConsumerKey ( c context . Context ) ( string , error ) { req := & pb . CheckOAuthSignatureRequest { } res := & pb . CheckOAuthSignatureResponse { } err := internal . Call ( c , " " , " " , req , res ) if err != nil { return " " , err } return * res . OauthConsumerKey , err } 
func appID ( fullAppID string ) string { _ , dom , dis := parseFullAppID ( fullAppID ) if dom != " " { return dom + " " + dis } return dis } 
func ( u * User ) String ( ) string { if u . AuthDomain != " " && strings . HasSuffix ( u . Email , " " + u . AuthDomain ) { return u . Email [ : len ( u . Email ) - len ( " " + u . AuthDomain ) ] } if u . FederatedIdentity != " " { return u . FederatedIdentity } return u . Email } 
func LoginURL ( c context . Context , dest string ) ( string , error ) { return LoginURLFederated ( c , dest , " " ) } 
func LoginURLFederated ( c context . Context , dest , identity string ) ( string , error ) { req := & pb . CreateLoginURLRequest { DestinationUrl : proto . String ( dest ) , } if identity != " " { req . FederatedIdentity = proto . String ( identity ) } res := & pb . CreateLoginURLResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return " " , err } return * res . LoginUrl , nil } 
func LogoutURL ( c context . Context , dest string ) ( string , error ) { req := & pb . CreateLogoutURLRequest { DestinationUrl : proto . String ( dest ) , } res := & pb . CreateLogoutURLResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return " " , err } return * res . LogoutUrl , nil } 
func mapPackage ( s string ) string { if stutterPackage { s += " " + path . Base ( s ) } return newPackageBase + s } 
func insertContext ( f * ast . File , call * ast . CallExpr , ctx * ast . Ident ) { if ctx == nil { } else { } call . Args = append ( [ ] ast . Expr { ctx } , call . Args ... ) } 
func NewClient ( host string , client * http . Client ) ( * Client , error ) { * wrapClient = * client t := client . Transport if t == nil { t = http . DefaultTransport } wrapClient . Transport = & headerAddingRoundTripper { t } url := url . URL { Scheme : " " , Host : host , Path : " " , } if host == " " || strings . HasPrefix ( host , " " ) { url . Scheme = " " } u := url . String ( ) appID , err := getAppID ( wrapClient , u ) if err != nil { return nil , fmt . Errorf ( " " , err ) } return & Client { hc : wrapClient , url : u , appID : appID , } , nil } 
func ( c * Client ) NewContext ( parent context . Context ) context . Context { ctx := internal . WithCallOverride ( parent , c . call ) ctx = internal . WithLogOverride ( ctx , c . logf ) ctx = internal . WithAppIDOverride ( ctx , c . appID ) return ctx } 
func NewRemoteContext ( host string , client * http . Client ) ( context . Context , error ) { c , err := NewClient ( host , client ) if err != nil { return nil , err } return c . NewContext ( context . Background ( ) ) , nil } 
func Debugf ( ctx context . Context , format string , args ... interface { } ) { internal . Logf ( ctx , 0 , format , args ... ) } 
func guestbookKey ( ctx context . Context ) * datastore . Key { } 
func ( opt * RetryOptions ) toRetryParameters ( ) * pb . TaskQueueRetryParameters { params := & pb . TaskQueueRetryParameters { } if opt . RetryLimit > 0 { params . RetryLimit = proto . Int32 ( opt . RetryLimit ) } if opt . AgeLimit > 0 { params . AgeLimitSec = proto . Int64 ( int64 ( opt . AgeLimit . Seconds ( ) ) ) } if opt . MinBackoff > 0 { params . MinBackoffSec = proto . Float64 ( opt . MinBackoff . Seconds ( ) ) } if opt . MaxBackoff > 0 { params . MaxBackoffSec = proto . Float64 ( opt . MaxBackoff . Seconds ( ) ) } if opt . MaxDoublings > 0 || ( opt . MaxDoublings == 0 && opt . ApplyZeroMaxDoublings ) { params . MaxDoublings = proto . Int32 ( opt . MaxDoublings ) } return params } 
func NewPOSTTask ( path string , params url . Values ) * Task { h := make ( http . Header ) h . Set ( " " , " " ) return & Task { Path : path , Payload : [ ] byte ( params . Encode ( ) ) , Header : h , Method : " " , } } 
func ParseRequestHeaders ( h http . Header ) * RequestHeaders { ret := & RequestHeaders { QueueName : h . Get ( " " ) , TaskName : h . Get ( " " ) , } ret . TaskRetryCount , _ = strconv . ParseInt ( h . Get ( " " ) , 10 , 64 ) ret . TaskExecutionCount , _ = strconv . ParseInt ( h . Get ( " " ) , 10 , 64 ) etaSecs , _ := strconv . ParseInt ( h . Get ( " " ) , 10 , 64 ) if etaSecs != 0 { ret . TaskETA = time . Unix ( etaSecs , 0 ) } ret . TaskPreviousResponse , _ = strconv . Atoi ( h . Get ( " " ) ) ret . TaskRetryReason = h . Get ( " " ) if h . Get ( " " ) != " " { ret . FailFast = true } return ret } 
func Add ( c context . Context , task * Task , queueName string ) ( * Task , error ) { req , err := newAddReq ( c , task , queueName ) if err != nil { return nil , err } res := & pb . TaskQueueAddResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { apiErr , ok := err . ( * internal . APIError ) if ok && alreadyAddedErrors [ pb . TaskQueueServiceError_ErrorCode ( apiErr . Code ) ] { return nil , ErrTaskAlreadyAdded } return nil , err } resultTask := * task resultTask . Method = task . method ( ) if task . Name == " " { resultTask . Name = string ( res . ChosenTaskName ) } return & resultTask , nil } 
func AddMulti ( c context . Context , tasks [ ] * Task , queueName string ) ( [ ] * Task , error ) { req := & pb . TaskQueueBulkAddRequest { AddRequest : make ( [ ] * pb . TaskQueueAddRequest , len ( tasks ) ) , } me , any := make ( appengine . MultiError , len ( tasks ) ) , false for i , t := range tasks { req . AddRequest [ i ] , me [ i ] = newAddReq ( c , t , queueName ) any = any || me [ i ] != nil } if any { return nil , me } res := & pb . TaskQueueBulkAddResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } if len ( res . Taskresult ) != len ( tasks ) { return nil , errors . New ( " " ) } tasksOut := make ( [ ] * Task , len ( tasks ) ) for i , tr := range res . Taskresult { tasksOut [ i ] = new ( Task ) * tasksOut [ i ] = * tasks [ i ] tasksOut [ i ] . Method = tasksOut [ i ] . method ( ) if tasksOut [ i ] . Name == " " { tasksOut [ i ] . Name = string ( tr . ChosenTaskName ) } if * tr . Result != pb . TaskQueueServiceError_OK { if alreadyAddedErrors [ * tr . Result ] { me [ i ] = ErrTaskAlreadyAdded } else { me [ i ] = & internal . APIError { Service : " " , Code : int32 ( * tr . Result ) , } } any = true } } if any { return tasksOut , me } return tasksOut , nil } 
func Delete ( c context . Context , task * Task , queueName string ) error { err := DeleteMulti ( c , [ ] * Task { task } , queueName ) if me , ok := err . ( appengine . MultiError ) ; ok { return me [ 0 ] } return err } 
func DeleteMulti ( c context . Context , tasks [ ] * Task , queueName string ) error { taskNames := make ( [ ] [ ] byte , len ( tasks ) ) for i , t := range tasks { taskNames [ i ] = [ ] byte ( t . Name ) } if queueName == " " { queueName = " " } req := & pb . TaskQueueDeleteRequest { QueueName : [ ] byte ( queueName ) , TaskName : taskNames , } res := & pb . TaskQueueDeleteResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } if a , b := len ( req . TaskName ) , len ( res . Result ) ; a != b { return fmt . Errorf ( " " , a , b ) } me , any := make ( appengine . MultiError , len ( res . Result ) ) , false for i , ec := range res . Result { if ec != pb . TaskQueueServiceError_OK { me [ i ] = & internal . APIError { Service : " " , Code : int32 ( ec ) , } any = true } } if any { return me } return nil } 
func Lease ( c context . Context , maxTasks int , queueName string , leaseTime int ) ( [ ] * Task , error ) { return lease ( c , maxTasks , queueName , leaseTime , false , nil ) } 
func LeaseByTag ( c context . Context , maxTasks int , queueName string , leaseTime int , tag string ) ( [ ] * Task , error ) { return lease ( c , maxTasks , queueName , leaseTime , true , [ ] byte ( tag ) ) } 
func Purge ( c context . Context , queueName string ) error { if queueName == " " { queueName = " " } req := & pb . TaskQueuePurgeQueueRequest { QueueName : [ ] byte ( queueName ) , } res := & pb . TaskQueuePurgeQueueResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func ModifyLease ( c context . Context , task * Task , queueName string , leaseTime int ) error { if queueName == " " { queueName = " " } req := & pb . TaskQueueModifyTaskLeaseRequest { QueueName : [ ] byte ( queueName ) , TaskName : [ ] byte ( task . Name ) , EtaUsec : proto . Int64 ( task . ETA . UnixNano ( ) / 1e3 ) , res := & pb . TaskQueueModifyTaskLeaseResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } task . ETA = time . Unix ( 0 , * res . UpdatedEtaUsec * 1e3 ) return nil } 
func QueueStats ( c context . Context , queueNames [ ] string ) ( [ ] QueueStatistics , error ) { req := & pb . TaskQueueFetchQueueStatsRequest { QueueName : make ( [ ] [ ] byte , len ( queueNames ) ) , } for i , q := range queueNames { if q == " " { q = " " } req . QueueName [ i ] = [ ] byte ( q ) } res := & pb . TaskQueueFetchQueueStatsResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } qs := make ( [ ] QueueStatistics , len ( res . Queuestats ) ) for i , qsg := range res . Queuestats { qs [ i ] = QueueStatistics { Tasks : int ( * qsg . NumTasks ) , } if eta := * qsg . OldestEtaUsec ; eta > - 1 { qs [ i ] . OldestETA = time . Unix ( 0 , eta * 1e3 ) } if si := qsg . ScannerInfo ; si != nil { qs [ i ] . Executed1Minute = int ( * si . ExecutedLastMinute ) qs [ i ] . InFlight = int ( si . GetRequestsInFlight ( ) ) qs [ i ] . EnforcedRate = si . GetEnforcedRate ( ) } } return qs , nil } 
func IsTimeoutError ( err error ) bool { if err == context . DeadlineExceeded { return true } if t , ok := err . ( interface { IsTimeout ( ) bool } ) ; ok { return t . IsTimeout ( ) } return false } 
func fileKey ( file string ) ( string , error ) { if ! internal . IsSecondGen ( ) || internal . MainPath == " " { return file , nil } } for _ , s := range [ ] string { filepath . Join ( " " , " " ) + s , s + " " + s , filepath . Join ( build . Default . GOPATH , " " ) + s } { if idx := strings . Index ( file , s ) ; idx > 0 { return file [ idx + len ( s ) : ] , nil } } if idx := strings . Index ( file , m ) ; idx > 0 { file = file [ idx + len ( m ) : ] } else { return file , fmt . Errorf ( " " , file ) } return modVersionPat . ReplaceAllString ( file , " " ) , nil } 
func Func ( key string , i interface { } ) * Function { f := & Function { fv : reflect . ValueOf ( i ) } fk , err := fileKey ( file ) if err != nil { } f . key = fk + " " + key t := f . fv . Type ( ) if t . Kind ( ) != reflect . Func { f . err = errors . New ( " " ) return f } if t . NumIn ( ) == 0 || ! isContext ( t . In ( 0 ) ) { f . err = errFirstArg return f } } gob . Register ( reflect . Zero ( t . In ( i ) ) . Interface ( ) ) } if old := funcs [ f . key ] ; old != nil { old . err = fmt . Errorf ( " " , key , file ) } funcs [ f . key ] = f return f } 
func ( f * Function ) Task ( args ... interface { } ) ( * taskqueue . Task , error ) { if f . err != nil { return nil , fmt . Errorf ( " " , f . err ) } nArgs := len ( args ) + 1 ft := f . fv . Type ( ) minArgs := ft . NumIn ( ) if ft . IsVariadic ( ) { minArgs -- } if nArgs < minArgs { return nil , fmt . Errorf ( " " , nArgs , minArgs ) } if ! ft . IsVariadic ( ) && nArgs > minArgs { return nil , fmt . Errorf ( " " , nArgs , minArgs ) } var dt reflect . Type if i < minArgs { } else { } } return nil , fmt . Errorf ( " " , i , dt ) } switch at . Kind ( ) { case reflect . Chan , reflect . Func , reflect . Interface , reflect . Map , reflect . Ptr , reflect . Slice : av := reflect . ValueOf ( args [ i - 1 ] ) if av . IsNil ( ) { } } if ! at . AssignableTo ( dt ) { return nil , fmt . Errorf ( " " , i , at , dt ) } } inv := invocation { Key : f . key , Args : args , } buf := new ( bytes . Buffer ) if err := gob . NewEncoder ( buf ) . Encode ( inv ) ; err != nil { return nil , fmt . Errorf ( " " , err ) } return & taskqueue . Task { Path : path , Payload : buf . Bytes ( ) , } , nil } 
func RequestHeaders ( c context . Context ) ( * taskqueue . RequestHeaders , error ) { if ret , ok := c . Value ( headersContextKey ) . ( * taskqueue . RequestHeaders ) ; ok { return ret , nil } return nil , errOutsideDelayFunc } 
func WithContext ( parent context . Context , req * http . Request ) context . Context { return internal . WithContext ( parent , req ) } 
func ( g GeoPoint ) Valid ( ) bool { return - 90 <= g . Lat && g . Lat <= 90 && - 180 <= g . Lng && g . Lng <= 180 } 
func WithAPICallFunc ( ctx context . Context , f APICallFunc ) context . Context { return internal . WithCallOverride ( ctx , internal . CallOverrideFunc ( f ) ) } 
func APICall ( ctx context . Context , service , method string , in , out proto . Message ) error { return internal . Call ( ctx , service , method , in , out ) } 
func ModuleHostname ( c context . Context , module , version , instance string ) ( string , error ) { req := & modpb . GetHostnameRequest { } if module != " " { req . Module = & module } if version != " " { req . Version = & version } if instance != " " { req . Instance = & instance } res := & modpb . GetHostnameResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return " " , err } return * res . Hostname , nil } 
func AccessToken ( c context . Context , scopes ... string ) ( token string , expiry time . Time , err error ) { req := & pb . GetAccessTokenRequest { Scope : scopes } res := & pb . GetAccessTokenResponse { } err = internal . Call ( c , " " , " " , req , res ) if err != nil { return " " , time . Time { } , err } return res . GetAccessToken ( ) , time . Unix ( res . GetExpirationTime ( ) , 0 ) , nil } 
func PublicCertificates ( c context . Context ) ( [ ] Certificate , error ) { req := & pb . GetPublicCertificateForAppRequest { } res := & pb . GetPublicCertificateForAppResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } var cs [ ] Certificate for _ , pc := range res . PublicCertificateList { cs = append ( cs , Certificate { KeyName : pc . GetKeyName ( ) , Data : [ ] byte ( pc . GetX509CertificatePem ( ) ) , } ) } return cs , nil } 
func ServiceAccount ( c context . Context ) ( string , error ) { req := & pb . GetServiceAccountNameRequest { } res := & pb . GetServiceAccountNameResponse { } err := internal . Call ( c , " " , " " , req , res ) if err != nil { return " " , err } return res . GetServiceAccountName ( ) , err } 
func SignBytes ( c context . Context , bytes [ ] byte ) ( keyName string , signature [ ] byte , err error ) { req := & pb . SignForAppRequest { BytesToSign : bytes } res := & pb . SignForAppResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return " " , nil , err } return res . GetKeyName ( ) , res . GetSignatureBytes ( ) , nil } 
func ( r * reader ) fetch ( off int64 ) error { req := & blobpb . FetchDataRequest { BlobKey : proto . String ( string ( r . blobKey ) ) , StartIndex : proto . Int64 ( off ) , EndIndex : proto . Int64 ( off + readBufferSize - 1 ) , res := & blobpb . FetchDataResponse { } if err := internal . Call ( r . c , " " , " " , req , res ) ; err != nil { return err } if len ( res . Data ) == 0 { return io . EOF } r . buf , r . r , r . off = res . Data , 0 , off return nil } 
func ( r * reader ) seek ( off int64 ) ( int64 , error ) { delta := off - r . off if delta >= 0 && delta < int64 ( len ( r . buf ) ) { r . r = int ( delta ) return off , nil } r . buf , r . r , r . off = nil , 0 , off return off , nil } 
func keyToProto ( defaultAppID string , k * Key ) * pb . Reference { appID := k . appID if appID == " " { appID = defaultAppID } n := 0 for i := k ; i != nil ; i = i . parent { n ++ } e := make ( [ ] * pb . Path_Element , n ) for i := k ; i != nil ; i = i . parent { n -- e [ n ] = & pb . Path_Element { Type : & i . kind , } } else if i . intID != 0 { e [ n ] . Id = & i . intID } } var namespace * string if k . namespace != " " { namespace = proto . String ( k . namespace ) } return & pb . Reference { App : proto . String ( appID ) , NameSpace : namespace , Path : & pb . Path { Element : e , } , } } 
func multiKeyToProto ( appID string , key [ ] * Key ) [ ] * pb . Reference { ret := make ( [ ] * pb . Reference , len ( key ) ) for i , k := range key { ret [ i ] = keyToProto ( appID , k ) } return ret } 
func multiValid ( key [ ] * Key ) error { invalid := false for _ , k := range key { if ! k . valid ( ) { invalid = true break } } if ! invalid { return nil } err := make ( appengine . MultiError , len ( key ) ) for i , k := range key { if ! k . valid ( ) { err [ i ] = ErrInvalidKey } } return err } 
func referenceValueToKey ( r * pb . PropertyValue_ReferenceValue ) ( k * Key , err error ) { appID := r . GetApp ( ) namespace := r . GetNameSpace ( ) for _ , e := range r . Pathelement { k = & Key { kind : e . GetType ( ) , stringID : e . GetName ( ) , intID : e . GetId ( ) , parent : k , appID : appID , namespace : namespace , } if ! k . valid ( ) { return nil , ErrInvalidKey } } return } 
func keyToReferenceValue ( defaultAppID string , k * Key ) * pb . PropertyValue_ReferenceValue { ref := keyToProto ( defaultAppID , k ) pe := make ( [ ] * pb . PropertyValue_ReferenceValue_PathElement , len ( ref . Path . Element ) ) for i , e := range ref . Path . Element { pe [ i ] = & pb . PropertyValue_ReferenceValue_PathElement { Type : e . Type , Id : e . Id , Name : e . Name , } } return & pb . PropertyValue_ReferenceValue { App : ref . App , NameSpace : ref . NameSpace , Pathelement : pe , } } 
func checkMultiArg ( v reflect . Value ) ( m multiArgType , elemType reflect . Type ) { if v . Kind ( ) != reflect . Slice { return multiArgTypeInvalid , nil } if v . Type ( ) == typeOfPropertyList { return multiArgTypeInvalid , nil } elemType = v . Type ( ) . Elem ( ) if reflect . PtrTo ( elemType ) . Implements ( typeOfPropertyLoadSaver ) { return multiArgTypePropertyLoadSaver , elemType } switch elemType . Kind ( ) { case reflect . Struct : return multiArgTypeStruct , elemType case reflect . Interface : return multiArgTypeInterface , elemType case reflect . Ptr : elemType = elemType . Elem ( ) if elemType . Kind ( ) == reflect . Struct { return multiArgTypeStructPtr , elemType } } return multiArgTypeInvalid , nil } 
func GetMulti ( c context . Context , key [ ] * Key , dst interface { } ) error { v := reflect . ValueOf ( dst ) multiArgType , _ := checkMultiArg ( v ) if multiArgType == multiArgTypeInvalid { return errors . New ( " " ) } if len ( key ) != v . Len ( ) { return errors . New ( " " ) } if len ( key ) == 0 { return nil } if err := multiValid ( key ) ; err != nil { return err } req := & pb . GetRequest { Key : multiKeyToProto ( internal . FullyQualifiedAppID ( c ) , key ) , } res := & pb . GetResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } if len ( key ) != len ( res . Entity ) { return errors . New ( " " ) } multiErr , any := make ( appengine . MultiError , len ( key ) ) , false for i , e := range res . Entity { if e . Entity == nil { multiErr [ i ] = ErrNoSuchEntity } else { elem := v . Index ( i ) if multiArgType == multiArgTypePropertyLoadSaver || multiArgType == multiArgTypeStruct { elem = elem . Addr ( ) } if multiArgType == multiArgTypeStructPtr && elem . IsNil ( ) { elem . Set ( reflect . New ( elem . Type ( ) . Elem ( ) ) ) } multiErr [ i ] = loadEntity ( elem . Interface ( ) , e . Entity ) } if multiErr [ i ] != nil { any = true } } if any { return multiErr } return nil } 
func Put ( c context . Context , key * Key , src interface { } ) ( * Key , error ) { k , err := PutMulti ( c , [ ] * Key { key } , [ ] interface { } { src } ) if err != nil { if me , ok := err . ( appengine . MultiError ) ; ok { return nil , me [ 0 ] } return nil , err } return k [ 0 ] , nil } 
func PutMulti ( c context . Context , key [ ] * Key , src interface { } ) ( [ ] * Key , error ) { v := reflect . ValueOf ( src ) multiArgType , _ := checkMultiArg ( v ) if multiArgType == multiArgTypeInvalid { return nil , errors . New ( " " ) } if len ( key ) != v . Len ( ) { return nil , errors . New ( " " ) } if len ( key ) == 0 { return nil , nil } appID := internal . FullyQualifiedAppID ( c ) if err := multiValid ( key ) ; err != nil { return nil , err } req := & pb . PutRequest { } for i := range key { elem := v . Index ( i ) if multiArgType == multiArgTypePropertyLoadSaver || multiArgType == multiArgTypeStruct { elem = elem . Addr ( ) } sProto , err := saveEntity ( appID , key [ i ] , elem . Interface ( ) ) if err != nil { return nil , err } req . Entity = append ( req . Entity , sProto ) } res := & pb . PutResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } if len ( key ) != len ( res . Key ) { return nil , errors . New ( " " ) } ret := make ( [ ] * Key , len ( key ) ) for i := range ret { var err error ret [ i ] , err = protoToKey ( res . Key [ i ] ) if err != nil || ret [ i ] . Incomplete ( ) { return nil , errors . New ( " " ) } } return ret , nil } 
func Delete ( c context . Context , key * Key ) error { err := DeleteMulti ( c , [ ] * Key { key } ) if me , ok := err . ( appengine . MultiError ) ; ok { return me [ 0 ] } return err } 
func DeleteMulti ( c context . Context , key [ ] * Key ) error { if len ( key ) == 0 { return nil } if err := multiValid ( key ) ; err != nil { return err } req := & pb . DeleteRequest { Key : multiKeyToProto ( internal . FullyQualifiedAppID ( c ) , key ) , } res := & pb . DeleteResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func Client ( ctx context . Context ) * http . Client { return & http . Client { Transport : & Transport { Context : ctx , } , } } 
func urlString ( u * url . URL ) string { if u . Opaque == " " || strings . HasPrefix ( u . Opaque , " " ) { return u . String ( ) } aux := * u aux . Opaque = " " + aux . Host + aux . Opaque return aux . String ( ) } 
func ( t * Transport ) RoundTrip ( req * http . Request ) ( res * http . Response , err error ) { methNum , ok := pb . URLFetchRequest_RequestMethod_value [ req . Method ] if ! ok { return nil , fmt . Errorf ( " " , req . Method ) } method := pb . URLFetchRequest_RequestMethod ( methNum ) freq := & pb . URLFetchRequest { Method : & method , Url : proto . String ( urlString ( req . URL ) ) , FollowRedirects : proto . Bool ( false ) , if deadline , ok := t . Context . Deadline ( ) ; ok { freq . Deadline = proto . Float64 ( deadline . Sub ( time . Now ( ) ) . Seconds ( ) ) } for k , vals := range req . Header { for _ , val := range vals { freq . Header = append ( freq . Header , & pb . URLFetchRequest_Header { Key : proto . String ( k ) , Value : proto . String ( val ) , } ) } } if methodAcceptsRequestBody [ req . Method ] && req . Body != nil { } : freq . Payload = b . Bytes ( ) default : freq . Payload , err = ioutil . ReadAll ( req . Body ) if err != nil { return nil , err } } } fres := & pb . URLFetchResponse { } if err := internal . Call ( t . Context , " " , " " , freq , fres ) ; err != nil { return nil , err } res = & http . Response { } res . StatusCode = int ( * fres . StatusCode ) res . Status = fmt . Sprintf ( " " , res . StatusCode , statusCodeToText ( res . StatusCode ) ) res . Header = make ( http . Header ) res . Request = req res . ProtoMinor = 1 res . Proto = " " res . Close = true for _ , h := range fres . Header { hkey := http . CanonicalHeaderKey ( * h . Key ) hval := * h . Value if hkey == " " { } continue } res . Header . Add ( hkey , hval ) } if req . Method != " " { res . ContentLength = int64 ( len ( fres . Content ) ) } truncated := fres . GetContentWasTruncated ( ) res . Body = & bodyReader { content : fres . Content , truncated : truncated } return } 
func deploy ( ) error { vlogf ( " " , flag . Args ( ) ) cmd := exec . Command ( flag . Arg ( 0 ) , flag . Args ( ) [ 1 : ] ... ) cmd . Stdin , cmd . Stdout , cmd . Stderr = os . Stdin , os . Stdout , os . Stderr if err := cmd . Run ( ) ; err != nil { return fmt . Errorf ( " " , strings . Join ( flag . Args ( ) , " " ) , err ) } return nil } 
func ( qr * Result ) Next ( ) ( * Record , error ) { if qr . err != nil { return nil , qr . err } if len ( qr . logs ) > 0 { lr := qr . logs [ 0 ] qr . logs = qr . logs [ 1 : ] return lr , nil } if qr . request . Offset == nil && qr . resultsSeen { return nil , Done } if err := qr . run ( ) ; err != nil { } return qr . Next ( ) } 
func protoToAppLogs ( logLines [ ] * pb . LogLine ) [ ] AppLog { appLogs := make ( [ ] AppLog , len ( logLines ) ) for i , line := range logLines { appLogs [ i ] = AppLog { Time : time . Unix ( 0 , * line . Time * 1e3 ) , Level : int ( * line . Level ) , Message : * line . LogMessage , } } return appLogs } 
func protoToRecord ( rl * pb . RequestLog ) * Record { offset , err := proto . Marshal ( rl . Offset ) if err != nil { offset = nil } return & Record { AppID : * rl . AppId , ModuleID : rl . GetModuleId ( ) , VersionID : * rl . VersionId , RequestID : rl . RequestId , Offset : offset , IP : * rl . Ip , Nickname : rl . GetNickname ( ) , AppEngineRelease : string ( rl . GetAppEngineRelease ( ) ) , StartTime : time . Unix ( 0 , * rl . StartTime * 1e3 ) , EndTime : time . Unix ( 0 , * rl . EndTime * 1e3 ) , Latency : time . Duration ( * rl . Latency ) * time . Microsecond , MCycles : * rl . Mcycles , Method : * rl . Method , Resource : * rl . Resource , HTTPVersion : * rl . HttpVersion , Status : * rl . Status , ResponseSize : * rl . ResponseSize , Referrer : rl . GetReferrer ( ) , UserAgent : rl . GetUserAgent ( ) , URLMapEntry : * rl . UrlMapEntry , Combined : * rl . Combined , Host : rl . GetHost ( ) , Cost : rl . GetCost ( ) , TaskQueueName : rl . GetTaskQueueName ( ) , TaskName : rl . GetTaskName ( ) , WasLoadingRequest : rl . GetWasLoadingRequest ( ) , PendingTime : time . Duration ( rl . GetPendingTime ( ) ) * time . Microsecond , Finished : rl . GetFinished ( ) , AppLogs : protoToAppLogs ( rl . Line ) , InstanceID : string ( rl . GetCloneKey ( ) ) , } } 
func ( params * Query ) Run ( c context . Context ) * Result { req , err := makeRequest ( params , internal . FullyQualifiedAppID ( c ) , appengine . VersionID ( c ) ) return & Result { context : c , request : req , err : err , } } 
func ( r * Result ) run ( ) error { res := & pb . LogReadResponse { } if err := internal . Call ( r . context , " " , " " , r . request , res ) ; err != nil { return err } r . logs = make ( [ ] * Record , len ( res . Log ) ) r . request . Offset = res . Offset r . resultsSeen = true for i , log := range res . Log { r . logs [ i ] = protoToRecord ( log ) } return nil } 
func Current ( c context . Context ) * User { h := internal . IncomingHeaders ( c ) u := & User { Email : h . Get ( " " ) , AuthDomain : h . Get ( " " ) , ID : h . Get ( " " ) , Admin : h . Get ( " " ) == " " , FederatedIdentity : h . Get ( " " ) , FederatedProvider : h . Get ( " " ) , } if u . Email == " " && u . FederatedIdentity == " " { return nil } return u } 
func IsAdmin ( c context . Context ) bool { h := internal . IncomingHeaders ( c ) return h . Get ( " " ) == " " } 
func isErrFieldMismatch ( err error ) bool { _ , ok := err . ( * datastore . ErrFieldMismatch ) return ok } 
func Stat ( c context . Context , blobKey appengine . BlobKey ) ( * BlobInfo , error ) { c , _ = appengine . Namespace ( c , " " ) dskey := datastore . NewKey ( c , blobInfoKind , string ( blobKey ) , 0 , nil ) bi := & BlobInfo { BlobKey : blobKey , } if err := datastore . Get ( c , dskey , bi ) ; err != nil && ! isErrFieldMismatch ( err ) { return nil , err } return bi , nil } 
func Send ( response http . ResponseWriter , blobKey appengine . BlobKey ) { hdr := response . Header ( ) hdr . Set ( " " , string ( blobKey ) ) if hdr . Get ( " " ) == " " { } } 
func UploadURL ( c context . Context , successPath string , opts * UploadURLOptions ) ( * url . URL , error ) { req := & blobpb . CreateUploadURLRequest { SuccessPath : proto . String ( successPath ) , } if opts != nil { if n := opts . MaxUploadBytes ; n != 0 { req . MaxUploadSizeBytes = & n } if n := opts . MaxUploadBytesPerBlob ; n != 0 { req . MaxUploadSizePerBlobBytes = & n } if s := opts . StorageBucket ; s != " " { req . GsBucketName = & s } } res := & blobpb . CreateUploadURLResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } return url . Parse ( * res . Url ) } 
func Delete ( c context . Context , blobKey appengine . BlobKey ) error { return DeleteMulti ( c , [ ] appengine . BlobKey { blobKey } ) } 
func DeleteMulti ( c context . Context , blobKey [ ] appengine . BlobKey ) error { s := make ( [ ] string , len ( blobKey ) ) for i , b := range blobKey { s [ i ] = string ( b ) } req := & blobpb . DeleteBlobRequest { BlobKey : s , } res := & basepb . VoidProto { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } return nil } 
func ParseUpload ( req * http . Request ) ( blobs map [ string ] [ ] * BlobInfo , other url . Values , err error ) { _ , params , err := mime . ParseMediaType ( req . Header . Get ( " " ) ) if err != nil { return nil , nil , err } boundary := params [ " " ] if boundary == " " { return nil , nil , errorf ( " " ) } blobs = make ( map [ string ] [ ] * BlobInfo ) other = make ( url . Values ) mreader := multipart . NewReader ( io . MultiReader ( req . Body , strings . NewReader ( " \r \n \r \n " ) ) , boundary ) for { part , perr := mreader . NextPart ( ) if perr == io . EOF { break } if perr != nil { return nil , nil , errorf ( " " , boundary , len ( boundary ) , perr ) } bi := & BlobInfo { } ctype , params , err := mime . ParseMediaType ( part . Header . Get ( " " ) ) if err != nil { return nil , nil , err } bi . Filename = params [ " " ] formKey := params [ " " ] ctype , params , err = mime . ParseMediaType ( part . Header . Get ( " " ) ) if err != nil { return nil , nil , err } bi . BlobKey = appengine . BlobKey ( params [ " " ] ) charset := params [ " " ] if ctype != " " || bi . BlobKey == " " { if formKey != " " { slurp , serr := ioutil . ReadAll ( part ) if serr != nil { return nil , nil , errorf ( " " , formKey ) } if err == nil && ctype == " " { slurp , serr = ioutil . ReadAll ( base64 . NewDecoder ( base64 . StdEncoding , bytes . NewReader ( slurp ) ) ) if serr != nil { return nil , nil , errorf ( " " , ctype , formKey ) } } if err != nil { return nil , nil , errorf ( " " , charset ) } slurp , err = encoding . NewDecoder ( ) . Bytes ( slurp ) if err != nil { return nil , nil , errorf ( " " , charset ) } } other [ formKey ] = append ( other [ formKey ] , string ( slurp ) ) } continue } header , mimeerr := tp . ReadMIMEHeader ( ) if mimeerr != nil { return nil , nil , mimeerr } bi . Size , err = strconv . ParseInt ( header . Get ( " " ) , 10 , 64 ) if err != nil { return nil , nil , err } bi . ContentType = header . Get ( " " ) if createDate == " " { return nil , nil , errorf ( " " ) } bi . CreationTime , err = time . Parse ( " " , createDate ) if err != nil { return nil , nil , errorf ( " " , err ) } if hdr := header . Get ( " " ) ; hdr != " " { md5 , err := base64 . URLEncoding . DecodeString ( hdr ) if err != nil { return nil , nil , errorf ( " " , hdr , err ) } bi . MD5 = string ( md5 ) } blobs [ formKey ] = append ( blobs [ formKey ] , bi ) } return } 
func NewReader ( c context . Context , blobKey appengine . BlobKey ) Reader { return openBlob ( c , blobKey ) } 
func BlobKeyForFile ( c context . Context , filename string ) ( appengine . BlobKey , error ) { req := & blobpb . CreateEncodedGoogleStorageKeyRequest { Filename : & filename , } res := & blobpb . CreateEncodedGoogleStorageKeyResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return " " , err } return appengine . BlobKey ( * res . BlobKey ) , nil } 
func Handle ( f func ( c context . Context , m * Message ) ) { http . HandleFunc ( " " , func ( _ http . ResponseWriter , r * http . Request ) { f ( appengine . NewContext ( r ) , & Message { Sender : r . FormValue ( " " ) , To : [ ] string { r . FormValue ( " " ) } , Body : r . FormValue ( " " ) , } ) } ) } 
func ( m * Message ) Send ( c context . Context ) error { req := & pb . XmppMessageRequest { Jid : m . To , Body : & m . Body , RawXml : & m . RawXML , } if m . Type != " " && m . Type != " " { req . Type = & m . Type } if m . Sender != " " { req . FromJid = & m . Sender } res := & pb . XmppMessageResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } if len ( res . Status ) != len ( req . Jid ) { return fmt . Errorf ( " " , len ( req . Jid ) , len ( res . Status ) ) } me , any := make ( appengine . MultiError , len ( req . Jid ) ) , false for i , st := range res . Status { if st != pb . XmppMessageResponse_NO_ERROR { me [ i ] = errors . New ( st . String ( ) ) any = true } } if any { return me } return nil } 
func Invite ( c context . Context , to , from string ) error { req := & pb . XmppInviteRequest { Jid : & to , } if from != " " { req . FromJid = & from } res := & pb . XmppInviteResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func ( p * Presence ) Send ( c context . Context ) error { req := & pb . XmppSendPresenceRequest { Jid : & p . To , } if p . State != " " { req . Show = & p . State } if p . Type != " " { req . Type = & p . Type } if p . Sender != " " { req . FromJid = & p . Sender } if p . Status != " " { req . Status = & p . Status } res := & pb . XmppSendPresenceResponse { } return internal . Call ( c , " " , " " , req , res ) } 
func GetPresence ( c context . Context , to string , from string ) ( string , error ) { req := & pb . PresenceRequest { Jid : & to , } if from != " " { req . FromJid = & from } res := & pb . PresenceResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return " " , err } if ! * res . IsAvailable || res . Presence == nil { return " " , ErrPresenceUnavailable } presence , ok := presenceMap [ * res . Presence ] if ok { return presence , nil } return " " , fmt . Errorf ( " " , * res . Presence ) } 
func GetPresenceMulti ( c context . Context , to [ ] string , from string ) ( [ ] string , error ) { req := & pb . BulkPresenceRequest { Jid : to , } if from != " " { req . FromJid = & from } res := & pb . BulkPresenceResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } presences := make ( [ ] string , 0 , len ( res . PresenceResponse ) ) errs := appengine . MultiError { } addResult := func ( presence string , err error ) { presences = append ( presences , presence ) errs = append ( errs , err ) } anyErr := false for _ , subres := range res . PresenceResponse { if ! subres . GetValid ( ) { anyErr = true addResult ( " " , ErrInvalidJID ) continue } if ! * subres . IsAvailable || subres . Presence == nil { anyErr = true addResult ( " " , ErrPresenceUnavailable ) continue } presence , ok := presenceMap [ * subres . Presence ] if ok { addResult ( presence , nil ) } else { anyErr = true addResult ( " " , fmt . Errorf ( " " , * subres . Presence ) ) } } if anyErr { return presences , errs } return presences , nil } 
func Dial ( ctx context . Context , protocol , addr string ) ( * Conn , error ) { conn , err := net . Dial ( protocol , addr ) if err != nil { return nil , err } return & Conn { conn } , nil } 
func DialTimeout ( ctx context . Context , protocol , addr string , timeout time . Duration ) ( * Conn , error ) { conn , err := net . DialTimeout ( protocol , addr , timeout ) if err != nil { return nil , err } return & Conn { conn } , nil } 
func LookupIP ( ctx context . Context , host string ) ( addrs [ ] net . IP , err error ) { return net . LookupIP ( host ) } 
func newStructFLS ( p interface { } ) ( FieldLoadSaver , error ) { v := reflect . ValueOf ( p ) if v . Kind ( ) != reflect . Ptr || v . IsNil ( ) || v . Elem ( ) . Kind ( ) != reflect . Struct { return nil , ErrInvalidDocumentType } codec , err := loadCodec ( v . Elem ( ) . Type ( ) ) if err != nil { return nil , err } return structFLS { v . Elem ( ) , codec } , nil } 
func SaveStruct ( src interface { } ) ( [ ] Field , error ) { f , _ , err := saveStructWithMeta ( src ) return f , err } 
func Namespaces ( ctx context . Context ) ( [ ] string , error ) { keys , err := q . GetAll ( ctx , nil ) if err != nil { return nil , err } } 
func Kinds ( ctx context . Context ) ( [ ] string , error ) { keys , err := q . GetAll ( ctx , nil ) if err != nil { return nil , err } return keyNames ( keys ) , nil } 
func keyNames ( keys [ ] * Key ) [ ] string { n := make ( [ ] string , 0 , len ( keys ) ) for _ , k := range keys { n = append ( n , k . StringID ( ) ) } return n } 
func KindProperties ( ctx context . Context , kind string ) ( map [ string ] [ ] string , error ) { q := NewQuery ( propertyKind ) . Ancestor ( kindKey ) propMap := map [ string ] [ ] string { } props := [ ] struct { Repr [ ] string `datastore:"property_representation"` } { } keys , err := q . GetAll ( ctx , & props ) if err != nil { return nil , err } for i , p := range props { propMap [ keys [ i ] . StringID ( ) ] = p . Repr } return propMap , nil } 
func mustGetMetadata ( key string ) [ ] byte { b , err := getMetadata ( key ) if err != nil { panic ( fmt . Sprintf ( " " , key , err ) ) } return b } 
func RunInTransaction ( c context . Context , f func ( tc context . Context ) error , opts * TransactionOptions ) error { xg := false if opts != nil { xg = opts . XG } readOnly := false if opts != nil { readOnly = opts . ReadOnly } attempts := 3 if opts != nil && opts . Attempts > 0 { attempts = opts . Attempts } var t * pb . Transaction var err error for i := 0 ; i < attempts ; i ++ { if t , err = internal . RunTransactionOnce ( c , f , xg , readOnly , t ) ; err != internal . ErrConcurrentTransaction { return err } } return ErrConcurrentTransaction } 
func walkBeforeAfter ( x interface { } , before , after func ( interface { } ) ) { before ( x ) switch n := x . ( type ) { default : panic ( fmt . Errorf ( " " , x ) ) case nil : case * ast . Expr : walkBeforeAfter ( * n , before , after ) case * ast . Spec : walkBeforeAfter ( * n , before , after ) case * ast . Stmt : walkBeforeAfter ( * n , before , after ) case * * ast . CallExpr : walkBeforeAfter ( * n , before , after ) case * * ast . FieldList : walkBeforeAfter ( * n , before , after ) case * * ast . FuncType : walkBeforeAfter ( * n , before , after ) case * * ast . Ident : walkBeforeAfter ( * n , before , after ) case * * ast . BasicLit : walkBeforeAfter ( * n , before , after ) case * [ ] ast . Expr : walkBeforeAfter ( * n , before , after ) case * [ ] * ast . File : walkBeforeAfter ( * n , before , after ) case * [ ] * ast . Ident : walkBeforeAfter ( * n , before , after ) case * [ ] ast . Spec : walkBeforeAfter ( * n , before , after ) case * [ ] ast . Stmt : walkBeforeAfter ( * n , before , after ) walkBeforeAfter ( & n . Type , before , after ) walkBeforeAfter ( & n . Tag , before , after ) case * ast . FieldList : for _ , field := range n . List { walkBeforeAfter ( field , before , after ) } case * ast . BadExpr : case * ast . Ident : case * ast . Ellipsis : walkBeforeAfter ( & n . Elt , before , after ) case * ast . BasicLit : case * ast . FuncLit : walkBeforeAfter ( & n . Type , before , after ) walkBeforeAfter ( & n . Body , before , after ) case * ast . CompositeLit : walkBeforeAfter ( & n . Type , before , after ) walkBeforeAfter ( & n . Elts , before , after ) case * ast . ParenExpr : walkBeforeAfter ( & n . X , before , after ) case * ast . SelectorExpr : walkBeforeAfter ( & n . X , before , after ) case * ast . IndexExpr : walkBeforeAfter ( & n . X , before , after ) walkBeforeAfter ( & n . Index , before , after ) case * ast . SliceExpr : walkBeforeAfter ( & n . X , before , after ) if n . Low != nil { walkBeforeAfter ( & n . Low , before , after ) } if n . High != nil { walkBeforeAfter ( & n . High , before , after ) } case * ast . TypeAssertExpr : walkBeforeAfter ( & n . X , before , after ) walkBeforeAfter ( & n . Type , before , after ) case * ast . CallExpr : walkBeforeAfter ( & n . Fun , before , after ) walkBeforeAfter ( & n . Args , before , after ) case * ast . StarExpr : walkBeforeAfter ( & n . X , before , after ) case * ast . UnaryExpr : walkBeforeAfter ( & n . X , before , after ) case * ast . BinaryExpr : walkBeforeAfter ( & n . X , before , after ) walkBeforeAfter ( & n . Y , before , after ) case * ast . KeyValueExpr : walkBeforeAfter ( & n . Key , before , after ) walkBeforeAfter ( & n . Value , before , after ) case * ast . ArrayType : walkBeforeAfter ( & n . Len , before , after ) walkBeforeAfter ( & n . Elt , before , after ) case * ast . StructType : walkBeforeAfter ( & n . Fields , before , after ) case * ast . FuncType : walkBeforeAfter ( & n . Params , before , after ) if n . Results != nil { walkBeforeAfter ( & n . Results , before , after ) } case * ast . InterfaceType : walkBeforeAfter ( & n . Methods , before , after ) case * ast . MapType : walkBeforeAfter ( & n . Key , before , after ) walkBeforeAfter ( & n . Value , before , after ) case * ast . ChanType : walkBeforeAfter ( & n . Value , before , after ) case * ast . BadStmt : case * ast . DeclStmt : walkBeforeAfter ( & n . Decl , before , after ) case * ast . EmptyStmt : case * ast . LabeledStmt : walkBeforeAfter ( & n . Stmt , before , after ) case * ast . ExprStmt : walkBeforeAfter ( & n . X , before , after ) case * ast . SendStmt : walkBeforeAfter ( & n . Chan , before , after ) walkBeforeAfter ( & n . Value , before , after ) case * ast . IncDecStmt : walkBeforeAfter ( & n . X , before , after ) case * ast . AssignStmt : walkBeforeAfter ( & n . Lhs , before , after ) walkBeforeAfter ( & n . Rhs , before , after ) case * ast . GoStmt : walkBeforeAfter ( & n . Call , before , after ) case * ast . DeferStmt : walkBeforeAfter ( & n . Call , before , after ) case * ast . ReturnStmt : walkBeforeAfter ( & n . Results , before , after ) case * ast . BranchStmt : case * ast . BlockStmt : walkBeforeAfter ( & n . List , before , after ) case * ast . IfStmt : walkBeforeAfter ( & n . Init , before , after ) walkBeforeAfter ( & n . Cond , before , after ) walkBeforeAfter ( & n . Body , before , after ) walkBeforeAfter ( & n . Else , before , after ) case * ast . CaseClause : walkBeforeAfter ( & n . List , before , after ) walkBeforeAfter ( & n . Body , before , after ) case * ast . SwitchStmt : walkBeforeAfter ( & n . Init , before , after ) walkBeforeAfter ( & n . Tag , before , after ) walkBeforeAfter ( & n . Body , before , after ) case * ast . TypeSwitchStmt : walkBeforeAfter ( & n . Init , before , after ) walkBeforeAfter ( & n . Assign , before , after ) walkBeforeAfter ( & n . Body , before , after ) case * ast . CommClause : walkBeforeAfter ( & n . Comm , before , after ) walkBeforeAfter ( & n . Body , before , after ) case * ast . SelectStmt : walkBeforeAfter ( & n . Body , before , after ) case * ast . ForStmt : walkBeforeAfter ( & n . Init , before , after ) walkBeforeAfter ( & n . Cond , before , after ) walkBeforeAfter ( & n . Post , before , after ) walkBeforeAfter ( & n . Body , before , after ) case * ast . RangeStmt : walkBeforeAfter ( & n . Key , before , after ) walkBeforeAfter ( & n . Value , before , after ) walkBeforeAfter ( & n . X , before , after ) walkBeforeAfter ( & n . Body , before , after ) case * ast . ImportSpec : case * ast . ValueSpec : walkBeforeAfter ( & n . Type , before , after ) walkBeforeAfter ( & n . Values , before , after ) walkBeforeAfter ( & n . Names , before , after ) case * ast . TypeSpec : walkBeforeAfter ( & n . Type , before , after ) case * ast . BadDecl : case * ast . GenDecl : walkBeforeAfter ( & n . Specs , before , after ) case * ast . FuncDecl : if n . Recv != nil { walkBeforeAfter ( & n . Recv , before , after ) } walkBeforeAfter ( & n . Type , before , after ) if n . Body != nil { walkBeforeAfter ( & n . Body , before , after ) } case * ast . File : walkBeforeAfter ( & n . Decls , before , after ) case * ast . Package : walkBeforeAfter ( & n . Files , before , after ) case [ ] * ast . File : for i := range n { walkBeforeAfter ( & n [ i ] , before , after ) } case [ ] ast . Decl : for i := range n { walkBeforeAfter ( & n [ i ] , before , after ) } case [ ] ast . Expr : for i := range n { walkBeforeAfter ( & n [ i ] , before , after ) } case [ ] * ast . Ident : for i := range n { walkBeforeAfter ( & n [ i ] , before , after ) } case [ ] ast . Stmt : for i := range n { walkBeforeAfter ( & n [ i ] , before , after ) } case [ ] ast . Spec : for i := range n { walkBeforeAfter ( & n [ i ] , before , after ) } } after ( x ) } 
func imports ( f * ast . File , path string ) bool { return importSpec ( f , path ) != nil } 
func importSpec ( f * ast . File , path string ) * ast . ImportSpec { for _ , s := range f . Imports { if importPath ( s ) == path { return s } } return nil } 
func declImports ( gen * ast . GenDecl , path string ) bool { if gen . Tok != token . IMPORT { return false } for _ , spec := range gen . Specs { impspec := spec . ( * ast . ImportSpec ) if importPath ( impspec ) == path { return true } } return false } 
func isPkgDot ( t ast . Expr , pkg , name string ) bool { sel , ok := t . ( * ast . SelectorExpr ) return ok && isTopName ( sel . X , pkg ) && sel . Sel . String ( ) == name } 
func isPtrPkgDot ( t ast . Expr , pkg , name string ) bool { ptr , ok := t . ( * ast . StarExpr ) return ok && isPkgDot ( ptr . X , pkg , name ) } 
func isTopName ( n ast . Expr , name string ) bool { id , ok := n . ( * ast . Ident ) return ok && id . Name == name && id . Obj == nil } 
func isName ( n ast . Expr , name string ) bool { id , ok := n . ( * ast . Ident ) return ok && id . String ( ) == name } 
func isCall ( t ast . Expr , pkg , name string ) bool { call , ok := t . ( * ast . CallExpr ) return ok && isPkgDot ( call . Fun , pkg , name ) } 
func isIdent ( n interface { } ) * ast . Ident { id , _ := n . ( * ast . Ident ) return id } 
func refersTo ( n ast . Node , x * ast . Ident ) bool { id , ok := n . ( * ast . Ident ) } 
func isEmptyString ( n ast . Expr ) bool { lit , ok := n . ( * ast . BasicLit ) return ok && lit . Kind == token . STRING && len ( lit . Value ) == 2 } 
func countUses ( x * ast . Ident , scope [ ] ast . Stmt ) int { count := 0 ff := func ( n interface { } ) { if n , ok := n . ( ast . Node ) ; ok && refersTo ( n , x ) { count ++ } } for _ , n := range scope { walk ( n , ff ) } return count } 
func rewriteUses ( x * ast . Ident , f , fnot func ( token . Pos ) ast . Expr , scope [ ] ast . Stmt ) { var lastF ast . Expr ff := func ( n interface { } ) { ptr , ok := n . ( * ast . Expr ) if ! ok { return } nn := * ptr if ok && not . Op == token . NOT && not . X == lastF { * ptr = fnot ( nn . Pos ( ) ) return } if refersTo ( nn , x ) { lastF = f ( nn . Pos ( ) ) * ptr = lastF } } for _ , n := range scope { walk ( n , ff ) } } 
func assignsTo ( x * ast . Ident , scope [ ] ast . Stmt ) bool { assigned := false ff := func ( n interface { } ) { if assigned { return } switch n := n . ( type ) { case * ast . UnaryExpr : return } case * ast . AssignStmt : for _ , l := range n . Lhs { if refersTo ( l , x ) { assigned = true return } } } } for _ , n := range scope { if assigned { break } walk ( n , ff ) } return assigned } 
func newPkgDot ( pos token . Pos , pkg , name string ) ast . Expr { return & ast . SelectorExpr { X : & ast . Ident { NamePos : pos , Name : pkg , } , Sel : & ast . Ident { NamePos : pos , Name : name , } , } } 
func renameTop ( f * ast . File , old , new string ) bool { var fixed bool fixed = true } } else { _ , thisName := path . Split ( importPath ( s ) ) if thisName == old { s . Name = ast . NewIdent ( new ) fixed = true } } } d . Name . Obj . Name = new fixed = true } case * ast . GenDecl : for _ , s := range d . Specs { switch s := s . ( type ) { case * ast . TypeSpec : if s . Name . Name == old { s . Name . Name = new s . Name . Obj . Name = new fixed = true } case * ast . ValueSpec : for _ , n := range s . Names { if n . Name == old { n . Name = new n . Obj . Name = new fixed = true } } } } } } if ok && isTopName ( id , old ) { id . Name = new fixed = true } if ok && id . Obj != nil && id . Name == old && id . Obj . Name == new { id . Name = id . Obj . Name fixed = true } } ) return fixed } 
func matchLen ( x , y string ) int { i := 0 for i < len ( x ) && i < len ( y ) && x [ i ] == y [ i ] { i ++ } return i } 
func deleteImport ( f * ast . File , path string ) ( deleted bool ) { oldImport := importSpec ( f , path ) if ! ok || gen . Tok != token . IMPORT { continue } for j , spec := range gen . Specs { impspec := spec . ( * ast . ImportSpec ) if oldImport != impspec { continue } copy ( gen . Specs [ j : ] , gen . Specs [ j + 1 : ] ) gen . Specs = gen . Specs [ : len ( gen . Specs ) - 1 ] f . Decls = f . Decls [ : len ( f . Decls ) - 1 ] } else if len ( gen . Specs ) == 1 { gen . Lparen = token . NoPos } if j > 0 { } break } } f . Imports = f . Imports [ : len ( f . Imports ) - 1 ] break } } return } 
func rewriteImport ( f * ast . File , oldPath , newPath string ) ( rewrote bool ) { for _ , imp := range f . Imports { if importPath ( imp ) == oldPath { rewrote = true imp . Path . Value = strconv . Quote ( newPath ) } } return } 
func fromContext ( ctx netcontext . Context ) * context { c , _ := ctx . Value ( & contextKey ) . ( * context ) return c } 
func DefaultTicket ( ) string { defaultTicketOnce . Do ( func ( ) { if IsDevAppServer ( ) { defaultTicket = " " + defaultTicketSuffix return } appID := partitionlessAppID ( ) escAppID := strings . Replace ( strings . Replace ( appID , " " , " " , - 1 ) , " " , " " , - 1 ) majVersion := VersionID ( nil ) if i := strings . Index ( majVersion , " " ) ; i > 0 { majVersion = majVersion [ : i ] } defaultTicket = fmt . Sprintf ( " " , escAppID , ModuleName ( nil ) , majVersion , InstanceID ( ) ) } ) return defaultTicket } 
func ( c * context ) flushLog ( force bool ) ( flushed bool ) { c . pendingLogs . Lock ( ) for ; n < len ( c . pendingLogs . lines ) ; n ++ { ll := c . pendingLogs . lines [ n ] if nb > rem { break } rem -= nb } lines := c . pendingLogs . lines [ : n ] c . pendingLogs . lines = c . pendingLogs . lines [ n : ] c . pendingLogs . Unlock ( ) if len ( lines ) == 0 && ! force { } rescueLogs := false defer func ( ) { if rescueLogs { c . pendingLogs . Lock ( ) c . pendingLogs . lines = append ( lines , c . pendingLogs . lines ... ) c . pendingLogs . Unlock ( ) } } ( ) buf , err := proto . Marshal ( & logpb . UserAppLogGroup { LogLine : lines , } ) if err != nil { log . Printf ( " " , err ) rescueLogs = true return false } req := & logpb . FlushRequest { Logs : buf , } res := & basepb . VoidProto { } c . pendingLogs . Lock ( ) c . pendingLogs . flushes ++ c . pendingLogs . Unlock ( ) if err := Call ( toContext ( c ) , " " , " " , req , res ) ; err != nil { log . Printf ( " " , err ) rescueLogs = true return false } return true } 
func Dial ( ctx context . Context , protocol , addr string ) ( * Conn , error ) { return DialTimeout ( ctx , protocol , addr , 0 ) } 
func DialTimeout ( ctx context . Context , protocol , addr string , timeout time . Duration ) ( * Conn , error ) { dialCtx := ctx if timeout > 0 { var cancel context . CancelFunc dialCtx , cancel = context . WithTimeout ( ctx , timeout ) defer cancel ( ) } host , portStr , err := net . SplitHostPort ( addr ) if err != nil { return nil , err } port , err := strconv . Atoi ( portStr ) if err != nil { return nil , fmt . Errorf ( " " , portStr , err ) } var prot pb . CreateSocketRequest_SocketProtocol switch protocol { case " " : prot = pb . CreateSocketRequest_TCP case " " : prot = pb . CreateSocketRequest_UDP default : return nil , fmt . Errorf ( " " , protocol ) } packedAddrs , resolved , err := resolve ( dialCtx , ipFamilies , host ) if err != nil { return nil , fmt . Errorf ( " " , host , err ) } if len ( packedAddrs ) == 0 { return nil , fmt . Errorf ( " " , host ) } packedAddr := packedAddrs [ 0 ] fam := pb . CreateSocketRequest_IPv4 if len ( packedAddr ) == net . IPv6len { fam = pb . CreateSocketRequest_IPv6 } req := & pb . CreateSocketRequest { Family : fam . Enum ( ) , Protocol : prot . Enum ( ) , RemoteIp : & pb . AddressPort { Port : proto . Int32 ( int32 ( port ) ) , PackedAddress : packedAddr , } , } if resolved { req . RemoteIp . HostnameHint = & host } res := & pb . CreateSocketReply { } if err := internal . Call ( dialCtx , " " , " " , req , res ) ; err != nil { return nil , err } return & Conn { ctx : ctx , desc : res . GetSocketDescriptor ( ) , prot : prot , local : res . ProxyExternalIp , remote : req . RemoteIp , } , nil } 
func LookupIP ( ctx context . Context , host string ) ( addrs [ ] net . IP , err error ) { packedAddrs , _ , err := resolve ( ctx , ipFamilies , host ) if err != nil { return nil , fmt . Errorf ( " " , host , err ) } addrs = make ( [ ] net . IP , len ( packedAddrs ) ) for i , pa := range packedAddrs { addrs [ i ] = net . IP ( pa ) } return addrs , nil } 
func withDeadline ( parent context . Context , deadline time . Time ) ( context . Context , context . CancelFunc ) { if deadline . IsZero ( ) { return parent , func ( ) { } } return context . WithDeadline ( parent , deadline ) } 
func ( cn * Conn ) KeepAlive ( ) error { req := & pb . GetSocketNameRequest { SocketDescriptor : & cn . desc , } res := & pb . GetSocketNameReply { } return internal . Call ( cn . ctx , " " , " " , req , res ) } 
func RegisterTransactionSetter ( f interface { } ) { v := reflect . ValueOf ( f ) transactionSetters [ v . Type ( ) . In ( 0 ) ] = v } 
func applyTransaction ( pb proto . Message , t * pb . Transaction ) { v := reflect . ValueOf ( pb ) if f , ok := transactionSetters [ v . Type ( ) ] ; ok { f . Call ( [ ] reflect . Value { v , reflect . ValueOf ( t ) } ) } } 
func analyze ( tags [ ] string ) ( * app , error ) { ctxt := buildContext ( tags ) hasMain , appFiles , err := checkMain ( ctxt ) if err != nil { return nil , err } gopath := filepath . SplitList ( ctxt . GOPATH ) im , err := imports ( ctxt , * rootDir , gopath ) return & app { hasMain : hasMain , appFiles : appFiles , imports : im , } , err } 
func buildContext ( tags [ ] string ) * build . Context { return & build . Context { GOARCH : build . Default . GOARCH , GOOS : build . Default . GOOS , GOROOT : build . Default . GOROOT , GOPATH : build . Default . GOPATH , Compiler : build . Default . Compiler , BuildTags : append ( build . Default . BuildTags , tags ... ) , } } 
func ( s * app ) bundle ( tarFile string ) ( err error ) { var out io . Writer if tarFile == " " { out = os . Stdout } else { f , err := os . Create ( tarFile ) if err != nil { return err } defer func ( ) { if cerr := f . Close ( ) ; err == nil { err = cerr } } ( ) out = f } tw := tar . NewWriter ( out ) for srcDir , importName := range s . imports { dstDir := " " + importName if err = copyTree ( tw , dstDir , srcDir ) ; err != nil { return fmt . Errorf ( " " , srcDir , dstDir , err ) } } if err := copyTree ( tw , " " , * rootDir ) ; err != nil { return fmt . Errorf ( " " , err ) } if ! s . hasMain { if err := synthesizeMain ( tw , s . appFiles ) ; err != nil { return fmt . Errorf ( " " , err ) } } if err := tw . Close ( ) ; err != nil { return fmt . Errorf ( " " , tarFile , err ) } return nil } 
func synthesizeMain ( tw * tar . Writer , appFiles [ ] string ) error { appMap := make ( map [ string ] bool ) for _ , f := range appFiles { appMap [ f ] = true } var f string for i := 0 ; i < 100 ; i ++ { f = fmt . Sprintf ( " " , i ) if ! appMap [ filepath . Join ( * rootDir , f ) ] { break } } if appMap [ filepath . Join ( * rootDir , f ) ] { return fmt . Errorf ( " " , f ) } hdr := & tar . Header { Name : f , Mode : 0644 , Size : int64 ( len ( newMain ) ) , } if err := tw . WriteHeader ( hdr ) ; err != nil { return fmt . Errorf ( " " , f , err ) } if _ , err := tw . Write ( [ ] byte ( newMain ) ) ; err != nil { return fmt . Errorf ( " " , f , err ) } return nil } 
func imports ( ctxt * build . Context , srcDir string , gopath [ ] string ) ( map [ string ] string , error ) { pkg , err := ctxt . ImportDir ( srcDir , 0 ) if err != nil { return nil , fmt . Errorf ( " " , err ) } for _ , v := range pkg . Imports { if ! strings . Contains ( v , " " ) { continue } src , err := findInGopath ( v , gopath ) if err != nil { return nil , fmt . Errorf ( " " , v , gopath , err ) } result [ src ] = v im , err := imports ( ctxt , src , gopath ) if err != nil { return nil , fmt . Errorf ( " " , src , err ) } for k , v := range im { result [ k ] = v } } return result , nil } 
func findInGopath ( dir string , gopath [ ] string ) ( string , error ) { for _ , v := range gopath { dst := filepath . Join ( v , " " , dir ) if _ , err := os . Stat ( dst ) ; err == nil { return dst , nil } } return " " , fmt . Errorf ( " " , dir , gopath ) } 
func copyTree ( tw * tar . Writer , dstDir , srcDir string ) error { entries , err := ioutil . ReadDir ( srcDir ) if err != nil { return fmt . Errorf ( " " , srcDir , err ) } for _ , entry := range entries { n := entry . Name ( ) if skipFiles [ n ] { continue } s := filepath . Join ( srcDir , n ) d := filepath . Join ( dstDir , n ) if entry . IsDir ( ) { if err := copyTree ( tw , d , s ) ; err != nil { return fmt . Errorf ( " " , s , d , err ) } continue } if err := copyFile ( tw , d , s ) ; err != nil { return fmt . Errorf ( " " , s , d , err ) } } return nil } 
func copyFile ( tw * tar . Writer , dst , src string ) error { s , err := os . Open ( src ) if err != nil { return fmt . Errorf ( " " , src , err ) } defer s . Close ( ) fi , err := s . Stat ( ) if err != nil { return fmt . Errorf ( " " , src , err ) } hdr , err := tar . FileInfoHeader ( fi , dst ) if err != nil { return fmt . Errorf ( " " , dst , err ) } hdr . Name = dst if err := tw . WriteHeader ( hdr ) ; err != nil { return fmt . Errorf ( " " , dst , err ) } _ , err = io . Copy ( tw , s ) if err != nil { return fmt . Errorf ( " " , src , dst , err ) } return nil } 
func checkMain ( ctxt * build . Context ) ( bool , [ ] string , error ) { pkg , err := ctxt . ImportDir ( * rootDir , 0 ) if err != nil { return false , nil , fmt . Errorf ( " " , err ) } if ! pkg . IsCommand ( ) { errorf ( " \" \" \n " , pkg . Name ) } var appFiles [ ] string for _ , f := range pkg . GoFiles { n := filepath . Join ( * rootDir , f ) appFiles = append ( appFiles , n ) if hasMain , err = readFile ( n ) ; err != nil { return false , nil , fmt . Errorf ( " " , n , err ) } } return hasMain , appFiles , nil } 
func isMain ( f * ast . FuncDecl ) bool { ft := f . Type return f . Name . Name == " " && f . Recv == nil && ft . Params . NumFields ( ) == 0 && ft . Results . NumFields ( ) == 0 } 
func readFile ( filename string ) ( hasMain bool , err error ) { var src [ ] byte src , err = ioutil . ReadFile ( filename ) if err != nil { return } fset := token . NewFileSet ( ) file , err := parser . ParseFile ( fset , filename , src , 0 ) for _ , decl := range file . Decls { funcDecl , ok := decl . ( * ast . FuncDecl ) if ! ok { continue } if ! isMain ( funcDecl ) { continue } hasMain = true break } return } 
func setVal ( v reflect . Value , pValue interface { } ) string { switch v . Kind ( ) { case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 : x , ok := pValue . ( int64 ) if ! ok && pValue != nil { return typeMismatchReason ( pValue , v ) } if v . OverflowInt ( x ) { return fmt . Sprintf ( " " , x , v . Type ( ) ) } v . SetInt ( x ) case reflect . Bool : x , ok := pValue . ( bool ) if ! ok && pValue != nil { return typeMismatchReason ( pValue , v ) } v . SetBool ( x ) case reflect . String : switch x := pValue . ( type ) { case appengine . BlobKey : v . SetString ( string ( x ) ) case ByteString : v . SetString ( string ( x ) ) case string : v . SetString ( x ) default : if pValue != nil { return typeMismatchReason ( pValue , v ) } } case reflect . Float32 , reflect . Float64 : x , ok := pValue . ( float64 ) if ! ok && pValue != nil { return typeMismatchReason ( pValue , v ) } if v . OverflowFloat ( x ) { return fmt . Sprintf ( " " , x , v . Type ( ) ) } v . SetFloat ( x ) case reflect . Ptr : x , ok := pValue . ( * Key ) if ! ok && pValue != nil { return typeMismatchReason ( pValue , v ) } if _ , ok := v . Interface ( ) . ( * Key ) ; ! ok { return typeMismatchReason ( pValue , v ) } v . Set ( reflect . ValueOf ( x ) ) case reflect . Struct : switch v . Type ( ) { case typeOfTime : x , ok := pValue . ( time . Time ) if ! ok && pValue != nil { return typeMismatchReason ( pValue , v ) } v . Set ( reflect . ValueOf ( x ) ) case typeOfGeoPoint : x , ok := pValue . ( appengine . GeoPoint ) if ! ok && pValue != nil { return typeMismatchReason ( pValue , v ) } v . Set ( reflect . ValueOf ( x ) ) default : ent , ok := pValue . ( * Entity ) if ! ok { return typeMismatchReason ( pValue , v ) } if err != nil { return err . Error ( ) } } err = pls . Load ( ent . Properties ) if err != nil { return err . Error ( ) } } case reflect . Slice : x , ok := pValue . ( [ ] byte ) if ! ok { if y , yok := pValue . ( ByteString ) ; yok { x , ok = [ ] byte ( y ) , true } } if ! ok && pValue != nil { return typeMismatchReason ( pValue , v ) } if v . Type ( ) . Elem ( ) . Kind ( ) != reflect . Uint8 { return typeMismatchReason ( pValue , v ) } v . SetBytes ( x ) default : return typeMismatchReason ( pValue , v ) } return " " } 
func initField ( val reflect . Value , index [ ] int ) reflect . Value { for _ , i := range index [ : len ( index ) - 1 ] { val = val . Field ( i ) if val . Kind ( ) == reflect . Ptr { if val . IsNil ( ) { val . Set ( reflect . New ( val . Type ( ) . Elem ( ) ) ) } val = val . Elem ( ) } } return val . Field ( index [ len ( index ) - 1 ] ) } 
func loadEntity ( dst interface { } , src * pb . EntityProto ) ( err error ) { ent , err := protoToEntity ( src ) if err != nil { return err } if e , ok := dst . ( PropertyLoadSaver ) ; ok { return e . Load ( ent . Properties ) } return LoadStruct ( dst , ent . Properties ) } 
func validIndexNameOrDocID ( s string ) bool { if strings . HasPrefix ( s , " " ) { return false } for _ , c := range s { if c < 0x21 || 0x7f <= c { return false } } return true } 
func Open ( name string ) ( * Index , error ) { if ! validIndexNameOrDocID ( name ) { return nil , fmt . Errorf ( " " , name ) } return & Index { spec : pb . IndexSpec { Name : & name , } , } , nil } 
func ( x * Index ) Put ( c context . Context , id string , src interface { } ) ( string , error ) { ids , err := x . PutMulti ( c , [ ] string { id } , [ ] interface { } { src } ) if err != nil { return " " , err } return ids [ 0 ] , nil } 
func ( x * Index ) PutMulti ( c context . Context , ids [ ] string , srcs [ ] interface { } ) ( [ ] string , error ) { if len ( ids ) != 0 && len ( srcs ) != len ( ids ) { return nil , fmt . Errorf ( " " ) } if len ( srcs ) > maxDocumentsPerPutDelete { return nil , ErrTooManyDocuments } docs := make ( [ ] * pb . Document , len ( srcs ) ) for i , s := range srcs { var err error docs [ i ] , err = saveDoc ( s ) if err != nil { return nil , err } if len ( ids ) != 0 && ids [ i ] != " " { if ! validIndexNameOrDocID ( ids [ i ] ) { return nil , fmt . Errorf ( " " , ids [ i ] ) } docs [ i ] . Id = proto . String ( ids [ i ] ) } } req := & pb . IndexDocumentRequest { Params : & pb . IndexDocumentParams { Document : docs , IndexSpec : & spec , } , } res := & pb . IndexDocumentResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return nil , err } multiErr , hasErr := make ( appengine . MultiError , len ( res . Status ) ) , false for i , s := range res . Status { if s . GetCode ( ) != pb . SearchServiceError_OK { multiErr [ i ] = fmt . Errorf ( " " , s . GetCode ( ) , s . GetErrorDetail ( ) ) hasErr = true } } if hasErr { return res . DocId , multiErr } if len ( res . Status ) != len ( docs ) || len ( res . DocId ) != len ( docs ) { return nil , fmt . Errorf ( " " , len ( res . Status ) , len ( res . DocId ) , len ( docs ) ) } return res . DocId , nil } 
func ( x * Index ) Get ( c context . Context , id string , dst interface { } ) error { if id == " " || ! validIndexNameOrDocID ( id ) { return fmt . Errorf ( " " , id ) } req := & pb . ListDocumentsRequest { Params : & pb . ListDocumentsParams { IndexSpec : & x . spec , StartDocId : proto . String ( id ) , Limit : proto . Int32 ( 1 ) , } , } res := & pb . ListDocumentsResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } if res . Status == nil || res . Status . GetCode ( ) != pb . SearchServiceError_OK { return fmt . Errorf ( " " , res . Status . GetCode ( ) , res . Status . GetErrorDetail ( ) ) } if len ( res . Document ) != 1 || res . Document [ 0 ] . GetId ( ) != id { return ErrNoSuchDocument } return loadDoc ( dst , res . Document [ 0 ] , nil ) } 
func ( x * Index ) Delete ( c context . Context , id string ) error { return x . DeleteMulti ( c , [ ] string { id } ) } 
func ( x * Index ) DeleteMulti ( c context . Context , ids [ ] string ) error { if len ( ids ) > maxDocumentsPerPutDelete { return ErrTooManyDocuments } req := & pb . DeleteDocumentRequest { Params : & pb . DeleteDocumentParams { DocId : ids , IndexSpec : & x . spec , } , } res := & pb . DeleteDocumentResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } if len ( res . Status ) != len ( ids ) { return fmt . Errorf ( " " , len ( res . Status ) , len ( ids ) ) } multiErr , hasErr := make ( appengine . MultiError , len ( ids ) ) , false for i , s := range res . Status { if s . GetCode ( ) != pb . SearchServiceError_OK { multiErr [ i ] = fmt . Errorf ( " " , s . GetCode ( ) , s . GetErrorDetail ( ) ) hasErr = true } } if hasErr { return multiErr } return nil } 
func ( x * Index ) Search ( c context . Context , query string , opts * SearchOptions ) * Iterator { t := & Iterator { c : c , index : x , searchQuery : query , more : moreSearch , } if opts != nil { if opts . Cursor != " " { if opts . Offset != 0 { return errIter ( " " ) } t . searchCursor = proto . String ( string ( opts . Cursor ) ) } t . limit = opts . Limit t . fields = opts . Fields t . idsOnly = opts . IDsOnly t . sort = opts . Sort t . exprs = opts . Expressions t . refinements = opts . Refinements t . facetOpts = opts . Facets t . searchOffset = opts . Offset t . countAccuracy = opts . CountAccuracy } return t } 
func ( t * Iterator ) fetchMore ( ) { if t . err == nil && len ( t . listRes ) + len ( t . searchRes ) == 0 && t . more != nil { t . err = t . more ( t ) } } 
func ( t * Iterator ) Next ( dst interface { } ) ( string , error ) { t . fetchMore ( ) if t . err != nil { return " " , t . err } var doc * pb . Document var exprs [ ] * pb . Field switch { case len ( t . listRes ) != 0 : doc = t . listRes [ 0 ] t . listRes = t . listRes [ 1 : ] case len ( t . searchRes ) != 0 : doc = t . searchRes [ 0 ] . Document exprs = t . searchRes [ 0 ] . Expression t . searchCursor = t . searchRes [ 0 ] . Cursor t . searchRes = t . searchRes [ 1 : ] default : return " " , Done } if doc == nil { return " " , errors . New ( " " ) } if ! t . idsOnly && dst != nil { if err := loadDoc ( dst , doc , exprs ) ; err != nil { return " " , err } } return doc . GetId ( ) , nil } 
func ( t * Iterator ) Cursor ( ) Cursor { if t . searchCursor == nil { return " " } return Cursor ( * t . searchCursor ) } 
func ( t * Iterator ) Facets ( ) ( [ ] [ ] FacetResult , error ) { t . fetchMore ( ) if t . err != nil && t . err != Done { return nil , t . err } var facets [ ] [ ] FacetResult for _ , f := range t . facetRes { fres := make ( [ ] FacetResult , 0 , len ( f . Value ) ) for _ , v := range f . Value { ref := v . Refinement facet := FacetResult { Facet : Facet { Name : ref . GetName ( ) } , Count : int ( v . GetCount ( ) ) , } if ref . Value != nil { facet . Value = Atom ( * ref . Value ) } else { facet . Value = protoToRange ( ref . Range ) } fres = append ( fres , facet ) } facets = append ( facets , fres ) } return facets , nil } 
func saveDoc ( src interface { } ) ( * pb . Document , error ) { var err error var fields [ ] Field var meta * DocumentMetadata switch x := src . ( type ) { case FieldLoadSaver : fields , meta , err = x . Save ( ) default : fields , meta , err = saveStructWithMeta ( src ) } if err != nil { return nil , err } fieldsProto , err := fieldsToProto ( fields ) if err != nil { return nil , err } d := & pb . Document { Field : fieldsProto , OrderId : proto . Int32 ( int32 ( time . Since ( orderIDEpoch ) . Seconds ( ) ) ) , OrderIdSource : pb . Document_DEFAULTED . Enum ( ) , } if meta != nil { if meta . Rank != 0 { if ! validDocRank ( meta . Rank ) { return nil , fmt . Errorf ( " " , meta . Rank ) } * d . OrderId = int32 ( meta . Rank ) d . OrderIdSource = pb . Document_SUPPLIED . Enum ( ) } if len ( meta . Facets ) > 0 { facets , err := facetsToProto ( meta . Facets ) if err != nil { return nil , err } d . Facet = facets } } return d , nil } 
func loadDoc ( dst interface { } , src * pb . Document , exprs [ ] * pb . Field ) ( err error ) { fields , err := protoToFields ( src . Field ) if err != nil { return err } facets , err := protoToFacets ( src . Facet ) if err != nil { return err } if len ( exprs ) > 0 { exprFields , err := protoToFields ( exprs ) if err != nil { return err } } fields = append ( fields , exprFields ... ) } meta := & DocumentMetadata { Rank : int ( src . GetOrderId ( ) ) , Facets : facets , } switch x := dst . ( type ) { case FieldLoadSaver : return x . Load ( fields , meta ) default : return loadStructWithMeta ( dst , fields , meta ) } } 
func DefaultBucketName ( c context . Context ) ( string , error ) { req := & aipb . GetDefaultGcsBucketNameRequest { } res := & aipb . GetDefaultGcsBucketNameResponse { } err := internal . Call ( c , " " , " " , req , res ) if err != nil { return " " , fmt . Errorf ( " " , res ) } return res . GetDefaultGcsBucketName ( ) , nil } 
func ( k * Key ) valid ( ) bool { if k == nil { return false } for ; k != nil ; k = k . parent { if k . kind == " " || k . appID == " " { return false } if k . stringID != " " && k . intID != 0 { return false } if k . parent != nil { if k . parent . Incomplete ( ) { return false } if k . parent . appID != k . appID || k . parent . namespace != k . namespace { return false } } } return true } 
func ( k * Key ) Equal ( o * Key ) bool { for k != nil && o != nil { if k . kind != o . kind || k . stringID != o . stringID || k . intID != o . intID || k . appID != o . appID || k . namespace != o . namespace { return false } k , o = k . parent , o . parent } return k == o } 
func ( k * Key ) root ( ) * Key { for k . parent != nil { k = k . parent } return k } 
func ( k * Key ) marshal ( b * bytes . Buffer ) { if k . parent != nil { k . parent . marshal ( b ) } b . WriteByte ( '/' ) b . WriteString ( k . kind ) b . WriteByte ( ',' ) if k . stringID != " " { b . WriteString ( k . stringID ) } else { b . WriteString ( strconv . FormatInt ( k . intID , 10 ) ) } } 
func ( k * Key ) String ( ) string { if k == nil { return " " } b := bytes . NewBuffer ( make ( [ ] byte , 0 , 512 ) ) k . marshal ( b ) return b . String ( ) } 
func ( k * Key ) Encode ( ) string { ref := keyToProto ( " " , k ) b , err := proto . Marshal ( ref ) if err != nil { panic ( err ) } } 
func DecodeKey ( encoded string ) ( * Key , error ) { } b , err := base64 . URLEncoding . DecodeString ( encoded ) if err != nil { return nil , err } ref := new ( pb . Reference ) if err := proto . Unmarshal ( b , ref ) ; err != nil { return nil , err } return protoToKey ( ref ) } 
func NewIncompleteKey ( c context . Context , kind string , parent * Key ) * Key { return NewKey ( c , kind , " " , 0 , parent ) } 
func NewKey ( c context . Context , kind , stringID string , intID int64 , parent * Key ) * Key { if parent != nil { namespace = parent . namespace } else { namespace = internal . NamespaceFromContext ( c ) } return & Key { kind : kind , stringID : stringID , intID : intID , parent : parent , appID : internal . FullyQualifiedAppID ( c ) , namespace : namespace , } } 
func AllocateIDs ( c context . Context , kind string , parent * Key , n int ) ( low , high int64 , err error ) { if kind == " " { return 0 , 0 , errors . New ( " " ) } if n < 0 { return 0 , 0 , fmt . Errorf ( " " , n ) } if n == 0 { return 0 , 0 , nil } req := & pb . AllocateIdsRequest { ModelKey : keyToProto ( " " , NewIncompleteKey ( c , kind , parent ) ) , Size : proto . Int64 ( int64 ( n ) ) , } res := & pb . AllocateIdsResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return 0 , 0 , err } high = res . GetEnd ( ) + 1 if low + int64 ( n ) != high { return 0 , 0 , fmt . Errorf ( " " , n ) } return low , high , nil } 
func AllocateIDRange ( c context . Context , kind string , parent * Key , start , end int64 ) ( err error ) { if kind == " " { return errors . New ( " " ) } if start < 1 || end < 1 { return errors . New ( " " ) } if start > end { return errors . New ( " " ) } req := & pb . AllocateIdsRequest { ModelKey : keyToProto ( " " , NewIncompleteKey ( c , kind , parent ) ) , Max : proto . Int64 ( end ) , } res := & pb . AllocateIdsResponse { } if err := internal . Call ( c , " " , " " , req , res ) ; err != nil { return err } keys , err := q . GetAll ( c , nil ) if err != nil { return err } if len ( keys ) != 0 { return & KeyRangeCollisionError { start : start , end : end } } } return nil } 
func ( m * IndexDocumentParams ) GetFreshness ( ) IndexDocumentParams_Freshness { if m != nil && m . Freshness != nil { return * m . Freshness } return Default_IndexDocumentParams_Freshness } 
func IsOverQuota ( err error ) bool { callErr , ok := err . ( * internal . CallError ) return ok && callErr . Code == 4 } 
func fromContext ( ctx netcontext . Context ) appengine . Context { c , _ := ctx . Value ( & contextKey ) . ( appengine . Context ) return c } 
func ClassicContextFromContext ( ctx netcontext . Context ) ( appengine . Context , error ) { c := fromContext ( ctx ) if c == nil { return nil , errNotAppEngineContext } return c , nil } 
func Send ( c context . Context , msg * Message ) error { return send ( c , " " , msg ) } 
func SendToAdmins ( c context . Context , msg * Message ) error { return send ( c , " " , msg ) } 
func Parse ( r io . Reader , pkgName string ) ( * Report , error ) { reader := bufio . NewReader ( r ) report := & Report { make ( [ ] Package , 0 ) } if err != nil && err == io . EOF { break } else if err != nil { return nil , err } line := string ( l ) if strings . HasPrefix ( line , " " ) { tests = append ( tests , & Test { Name : cur , Result : FAIL , Output : make ( [ ] string , 0 ) , } ) seenSummary = false } else if matches := regexBenchmark . FindStringSubmatch ( line ) ; len ( matches ) == 6 { bytes , _ := strconv . Atoi ( matches [ 4 ] ) allocs , _ := strconv . Atoi ( matches [ 5 ] ) benchmarks = append ( benchmarks , & Benchmark { Name : matches [ 1 ] , Duration : parseNanoseconds ( matches [ 3 ] ) , Bytes : bytes , Allocs : allocs , } ) } else if strings . HasPrefix ( line , " " ) { continue } else if strings . HasPrefix ( line , " " ) { cur = strings . TrimSpace ( line [ 8 : ] ) continue } else if matches := regexResult . FindStringSubmatch ( line ) ; len ( matches ) == 6 { if matches [ 5 ] != " " { coveragePct = matches [ 5 ] } if strings . HasSuffix ( matches [ 4 ] , " " ) { } else if matches [ 1 ] == " " && len ( tests ) == 0 && len ( buffers [ cur ] ) > 0 { buffers [ cur ] = buffers [ cur ] [ 0 : 0 ] } buffers [ cur ] = buffers [ cur ] [ 0 : 0 ] tests = make ( [ ] * Test , 0 ) benchmarks = make ( [ ] * Benchmark , 0 ) coveragePct = " " cur = " " testsTime = 0 } else if matches := regexStatus . FindStringSubmatch ( line ) ; len ( matches ) == 4 { cur = matches [ 2 ] test := findTest ( tests , cur ) if test == nil { continue } } else if matches [ 1 ] == " " { test . Result = SKIP } else { test . Result = FAIL } if matches := regexIndent . FindStringSubmatch ( line ) ; len ( matches ) == 2 { test . SubtestIndent = matches [ 1 ] } test . Output = buffers [ cur ] test . Name = matches [ 2 ] test . Duration = parseSeconds ( matches [ 3 ] ) testsTime += test . Duration test . Time = int ( test . Duration / time . Millisecond ) } else if matches := regexCoverage . FindStringSubmatch ( line ) ; len ( matches ) == 2 { coveragePct = matches [ 1 ] } else if matches := regexOutput . FindStringSubmatch ( line ) ; capturedPackage == " " && len ( matches ) == 3 { if test == nil { continue } test . Output = append ( test . Output , matches [ 2 ] ) } else if strings . HasPrefix ( line , " " ) { } else if capturedPackage != " " { } else if regexSummary . MatchString ( line ) { } else if ! seenSummary { if test != nil { if strings . HasPrefix ( line , test . SubtestIndent + " " ) { test . Output = append ( test . Output , strings . TrimPrefix ( line , test . SubtestIndent + " " ) ) } } } } if len ( tests ) > 0 { } return report , nil } 
func ( r * Report ) Failures ( ) int { count := 0 for _ , p := range r . Packages { for _ , t := range p . Tests { if t . Result == FAIL { count ++ } } } return count } 
func JUnitReportXML ( report * parser . Report , noXMLHeader bool , goVersion string , w io . Writer ) error { suites := JUnitTestSuites { } ts := JUnitTestSuite { Tests : len ( pkg . Tests ) + len ( pkg . Benchmarks ) , Failures : 0 , Time : formatTime ( pkg . Duration ) , Name : pkg . Name , Properties : [ ] JUnitProperty { } , TestCases : [ ] JUnitTestCase { } , } classname := pkg . Name if idx := strings . LastIndex ( classname , " " ) ; idx > - 1 && idx < len ( pkg . Name ) { classname = pkg . Name [ idx + 1 : ] } } ts . Properties = append ( ts . Properties , JUnitProperty { " " , goVersion } ) if pkg . CoveragePct != " " { ts . Properties = append ( ts . Properties , JUnitProperty { " " , pkg . CoveragePct } ) } if test . Result == parser . FAIL { ts . Failures ++ testCase . Failure = & JUnitFailure { Message : " " , Type : " " , Contents : strings . Join ( test . Output , " \n " ) , } } if test . Result == parser . SKIP { testCase . SkipMessage = & JUnitSkipMessage { strings . Join ( test . Output , " \n " ) } } ts . TestCases = append ( ts . TestCases , testCase ) } ts . TestCases = append ( ts . TestCases , benchmarkCase ) } suites . Suites = append ( suites . Suites , ts ) } if err != nil { return err } writer := bufio . NewWriter ( w ) if ! noXMLHeader { writer . WriteString ( xml . Header ) } writer . Write ( bytes ) writer . WriteByte ( '\n' ) writer . Flush ( ) return nil } 
func ( cdc * Codec ) decodeReflectBinary ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions , bare bool ) ( n int , err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if info . Type . Kind ( ) == reflect . Interface && rv . Kind ( ) == reflect . Ptr { panic ( " " ) } if printLog { spew . Printf ( " \n " , bz , info , rv . Interface ( ) , rv . Type ( ) , fopts ) defer func ( ) { fmt . Printf ( " \n " , n , err ) } ( ) } var _n int rv . Set ( newPtr ) } rv = rv . Elem ( ) } rinfo , err = cdc . getTypeInfo_wlock ( info . AminoUnmarshalReprType ) if err != nil { return } _n , err = cdc . decodeReflectBinary ( bz , rinfo , rrv , fopts , bare ) if slide ( & bz , & n , _n ) && err != nil { return } uwouts := uwrm . Call ( [ ] reflect . Value { rrv } ) erri := uwouts [ 0 ] . Interface ( ) if erri != nil { err = erri . ( error ) } return } switch info . Type . Kind ( ) { n += _n return case reflect . Array : ert := info . Type . Elem ( ) if ert . Kind ( ) == reflect . Uint8 { _n , err = cdc . decodeReflectBinaryByteArray ( bz , info , rv , fopts ) n += _n } else { _n , err = cdc . decodeReflectBinaryArray ( bz , info , rv , fopts , bare ) n += _n } return case reflect . Slice : ert := info . Type . Elem ( ) if ert . Kind ( ) == reflect . Uint8 { _n , err = cdc . decodeReflectBinaryByteSlice ( bz , info , rv , fopts ) n += _n } else { _n , err = cdc . decodeReflectBinarySlice ( bz , info , rv , fopts , bare ) n += _n } return case reflect . Struct : _n , err = cdc . decodeReflectBinaryStruct ( bz , info , rv , fopts , bare ) n += _n return if fopts . BinFixed64 { num , _n , err = DecodeInt64 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetInt ( num ) } else { var u64 uint64 u64 , _n , err = DecodeUvarint ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetInt ( int64 ( u64 ) ) } return case reflect . Int32 : if fopts . BinFixed32 { var num int32 num , _n , err = DecodeInt32 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetInt ( int64 ( num ) ) } else { var num uint64 num , _n , err = DecodeUvarint ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } if int64 ( num ) > math . MaxInt32 || int64 ( num ) < math . MinInt32 { err = ErrOverflowInt return } rv . SetInt ( int64 ( num ) ) } return case reflect . Int16 : var num int16 num , _n , err = DecodeInt16 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetInt ( int64 ( num ) ) return case reflect . Int8 : var num int8 num , _n , err = DecodeInt8 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetInt ( int64 ( num ) ) return case reflect . Int : var num uint64 num , _n , err = DecodeUvarint ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } if int64 ( num ) > int64 ( maxInt ) || int64 ( num ) < int64 ( minInt ) { err = ErrOverflowInt return } rv . SetInt ( int64 ( num ) ) return if fopts . BinFixed64 { num , _n , err = DecodeUint64 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetUint ( num ) } else { num , _n , err = DecodeUvarint ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetUint ( num ) } return case reflect . Uint32 : if fopts . BinFixed32 { var num uint32 num , _n , err = DecodeUint32 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetUint ( uint64 ( num ) ) } else { var num uint64 num , _n , err = DecodeUvarint ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetUint ( uint64 ( num ) ) } return case reflect . Uint16 : var num uint16 num , _n , err = DecodeUint16 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetUint ( uint64 ( num ) ) return case reflect . Uint8 : var num uint8 num , _n , err = DecodeUint8 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetUint ( uint64 ( num ) ) return case reflect . Uint : var num uint64 num , _n , err = DecodeUvarint ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetUint ( num ) return b , _n , err = DecodeBool ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetBool ( b ) return case reflect . Float64 : var f float64 if ! fopts . Unsafe { err = errors . New ( " \" \" " ) return } f , _n , err = DecodeFloat64 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetFloat ( f ) return case reflect . Float32 : var f float32 if ! fopts . Unsafe { err = errors . New ( " \" \" " ) return } f , _n , err = DecodeFloat32 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetFloat ( float64 ( f ) ) return case reflect . String : var str string str , _n , err = DecodeString ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . SetString ( str ) return default : panic ( fmt . Sprintf ( " " , info . Type . Kind ( ) ) ) } } 
func ( cdc * Codec ) decodeReflectBinaryInterface ( bz [ ] byte , iinfo * TypeInfo , rv reflect . Value , fopts FieldOptions , bare bool ) ( n int , err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } if ! rv . IsNil ( ) { return } if ! bare { buf , _n , err = DecodeByteSlice ( bz ) if slide ( & bz , nil , _n ) && err != nil { return } bz = buf } if slide ( & bz , & n , _n ) && err != nil { return } if hasDisamb { cinfo , err = cdc . getTypeInfoFromDisfix_rlock ( toDisfix ( disamb , prefix ) ) } else if hasPrefix { cinfo , err = cdc . getTypeInfoFromPrefix_rlock ( iinfo , prefix ) } else { err = errors . New ( " " ) } if err != nil { return } if slide ( & bz , & n , _n ) && err != nil { rv . Set ( irvSet ) return } return } return } 
func ( cdc * Codec ) decodeReflectBinaryByteArray ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( n int , err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } ert := info . Type . Elem ( ) if ert . Kind ( ) != reflect . Uint8 { panic ( " " ) } length := info . Type . Len ( ) if len ( bz ) < length { return 0 , fmt . Errorf ( " " , length ) } byteslice , _n , err = DecodeByteSlice ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } if len ( byteslice ) != length { err = fmt . Errorf ( " " , length , len ( byteslice ) ) return } return } 
func ( cdc * Codec ) decodeReflectBinaryArray ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions , bare bool ) ( n int , err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } ert := info . Type . Elem ( ) if ert . Kind ( ) == reflect . Uint8 { panic ( " " ) } length := info . Type . Len ( ) einfo , err := cdc . getTypeInfo_wlock ( ert ) if err != nil { return } if ! bare { buf , _n , err = DecodeByteSlice ( bz ) if slide ( & bz , nil , _n ) && err != nil { return } bz = buf } if typ3 != Typ3_ByteLength { _n , err = cdc . decodeReflectBinary ( bz , einfo , erv , fopts , false ) if slide ( & bz , & n , _n ) && err != nil { err = fmt . Errorf ( " " , err ) return } if isDefault { erv . Set ( reflect . Zero ( erv . Type ( ) ) ) continue } } } return } } else { fnum , typ , _n , err = decodeFieldNumberAndTyp3 ( bz ) return } if typ != Typ3_ByteLength { err = errors . New ( fmt . Sprintf ( " " , Typ3_ByteLength , typ ) ) return } if slide ( & bz , & n , _n ) && err != nil { return } erv . Set ( defaultValue ( erv . Type ( ) ) ) continue } efopts . BinFieldNum = 1 _n , err = cdc . decodeReflectBinary ( bz , einfo , erv , efopts , false ) if slide ( & bz , & n , _n ) && err != nil { err = fmt . Errorf ( " " , err ) return } } fnum , _ , _ , err = decodeFieldNumberAndTyp3 ( bz ) if err != nil { return } if fnum <= fopts . BinFieldNum { err = fmt . Errorf ( " " , fnum , fopts . BinFieldNum ) return } } } return } 
func ( cdc * Codec ) decodeReflectBinaryStruct ( bz [ ] byte , info * TypeInfo , rv reflect . Value , _ FieldOptions , bare bool ) ( n int , err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } _n := 0 buf , _n , err = DecodeByteSlice ( bz ) if slide ( & bz , nil , _n ) && err != nil { return } bz = buf } switch info . Type { case timeType : t , _n , err = DecodeTime ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } rv . Set ( reflect . ValueOf ( t ) ) default : var finfo * TypeInfo finfo , err = cdc . getTypeInfo_wlock ( field . Type ) if err != nil { return } continue } if field . UnpackedList { if slide ( & bz , & n , _n ) && err != nil { return } } else { fnum , typ , _n , err = decodeFieldNumberAndTyp3 ( bz ) if field . BinFieldNum < fnum { continue if fnum <= lastFieldNum { err = fmt . Errorf ( " \n " , fnum , lastFieldNum , bz ) return } lastFieldNum = fnum if slide ( & bz , & n , _n ) && err != nil { return } return } typWanted := typeToTyp3 ( finfo . Type , field . FieldOptions ) if typ != typWanted { err = errors . New ( fmt . Sprintf ( " " , typWanted , fnum , info . Type , typ ) ) return } if slide ( & bz , & n , _n ) && err != nil { return } } } var typ3 Typ3 for len ( bz ) > 0 { fnum , typ3 , _n , err = decodeFieldNumberAndTyp3 ( bz ) if slide ( & bz , & n , _n ) && err != nil { return } if fnum <= lastFieldNum { err = fmt . Errorf ( " \n " , fnum , lastFieldNum , bz ) return } lastFieldNum = fnum _n , err = consumeAny ( typ3 , bz ) if slide ( & bz , & n , _n ) && err != nil { return } } } return } 
func consumeAny ( typ3 Typ3 , bz [ ] byte ) ( n int , err error ) { var _n int switch typ3 { case Typ3_Varint : _ , _n , err = DecodeVarint ( bz ) case Typ3_8Byte : _ , _n , err = DecodeInt64 ( bz ) case Typ3_ByteLength : _ , _n , err = DecodeByteSlice ( bz ) case Typ3_4Byte : _ , _n , err = DecodeInt32 ( bz ) default : err = fmt . Errorf ( " " , typ3 ) return } if err != nil { } slide ( & bz , & n , _n ) return } 
func decodeFieldNumberAndTyp3 ( bz [ ] byte ) ( num uint32 , typ Typ3 , n int , err error ) { value64 , n , err = DecodeUvarint ( bz ) if err != nil { return } num64 = value64 >> 3 if num64 > ( 1 << 29 - 1 ) { err = fmt . Errorf ( " " , num64 ) return } num = uint32 ( num64 ) return } 
func checkTyp3 ( rt reflect . Type , typ Typ3 , fopts FieldOptions ) ( err error ) { typWanted := typeToTyp3 ( rt , fopts ) if typ != typWanted { err = fmt . Errorf ( " " , typWanted , typ ) } return } 
func decodeTyp3 ( bz [ ] byte ) ( typ Typ3 , n int , err error ) { if len ( bz ) == 0 { err = fmt . Errorf ( " " ) return } if bz [ 0 ] & 0xF8 != 0 { err = fmt . Errorf ( " " , Typ3 ( bz [ 0 ] ) . String ( ) ) return } typ = Typ3 ( bz [ 0 ] ) n = 1 return } 
func decodeNumNilBytes ( bz [ ] byte ) ( numNil int64 , n int , err error ) { if len ( bz ) == 0 { err = errors . New ( " " ) return } if bz [ 0 ] == 0x00 { numNil , n = 0 , 1 return } if bz [ 0 ] == 0x01 { numNil , n = 1 , 1 return } n , err = 0 , fmt . Errorf ( " " , bz [ 0 ] ) return } 
func NewPrefixBytes ( prefixBytes [ ] byte ) PrefixBytes { pb := PrefixBytes { } copy ( pb [ : ] , prefixBytes ) return pb } 
func ( cdc * Codec ) RegisterInterface ( ptr interface { } , iopts * InterfaceOptions ) { cdc . assertNotSealed ( ) if rt . Kind ( ) != reflect . Interface { panic ( fmt . Sprintf ( " " , rt ) ) } defer cdc . mtx . Unlock ( ) cdc . collectImplementers_nolock ( info ) err := cdc . checkConflictsInPrio_nolock ( info ) if err != nil { panic ( err ) } cdc . setTypeInfo_nolock ( info ) } ( ) } 
func ( cdc * Codec ) RegisterConcrete ( o interface { } , name string , copts * ConcreteOptions ) { cdc . assertNotSealed ( ) var pointerPreferred bool if rt . Kind ( ) == reflect . Interface { panic ( fmt . Sprintf ( " " , rt ) ) } if rt . Kind ( ) == reflect . Ptr { rt = rt . Elem ( ) if rt . Kind ( ) == reflect . Ptr { } if rt . Kind ( ) == reflect . Interface { } pointerPreferred = true } defer cdc . mtx . Unlock ( ) cdc . addCheckConflictsWithConcrete_nolock ( info ) cdc . setTypeInfo_nolock ( info ) } ( ) } 
func ( cdc * Codec ) PrintTypes ( out io . Writer ) error { cdc . mtx . RLock ( ) defer cdc . mtx . RUnlock ( ) } if _ , err := io . WriteString ( out , " \n " ) ; err != nil { return err } } if _ , err := io . WriteString ( out , " " ) ; err != nil { return err } if _ , err := io . WriteString ( out , i . Name ) ; err != nil { return err } if _ , err := io . WriteString ( out , " " ) ; err != nil { return err } if _ , err := io . WriteString ( out , fmt . Sprintf ( " " , i . Prefix ) ) ; err != nil { return err } if _ , err := io . WriteString ( out , " " ) ; err != nil { return err } if _ , err := io . WriteString ( out , getLengthStr ( i ) ) ; err != nil { return err } if _ , err := io . WriteString ( out , " " ) ; err != nil { return err } } } 
func getLengthStr ( info * TypeInfo ) string { switch info . Type . Kind ( ) { case reflect . Array , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 , reflect . Float32 , reflect . Float64 , reflect . Complex64 , reflect . Complex128 : s := info . Type . Size ( ) return fmt . Sprintf ( " " , s ) default : return " " } } 
func ( cdc * Codec ) getTypeInfoFromPrefix_rlock ( iinfo * TypeInfo , pb PrefixBytes ) ( info * TypeInfo , err error ) { infos , ok := iinfo . Implementers [ pb ] if ! ok { err = fmt . Errorf ( " " , pb ) cdc . mtx . RUnlock ( ) return } if len ( infos ) > 1 { err = fmt . Errorf ( " " , pb , infos [ 0 ] . Type , infos [ 1 ] . Type ) cdc . mtx . RUnlock ( ) return } info = infos [ 0 ] cdc . mtx . RUnlock ( ) return } 
func ( cdc * Codec ) newTypeInfoUnregistered ( rt reflect . Type ) * TypeInfo { if rt . Kind ( ) == reflect . Ptr { panic ( " " ) } if rt . Kind ( ) == reflect . Interface { panic ( " " ) } var info = new ( TypeInfo ) info . Type = rt info . PtrToType = reflect . PtrTo ( rt ) info . ZeroValue = reflect . Zero ( rt ) info . ZeroProto = reflect . Zero ( rt ) . Interface ( ) if rt . Kind ( ) == reflect . Struct { info . StructInfo = cdc . parseStructInfo ( rt ) } if rm , ok := rt . MethodByName ( " " ) ; ok { info . ConcreteInfo . IsAminoMarshaler = true info . ConcreteInfo . AminoMarshalReprType = marshalAminoReprType ( rm ) } if rm , ok := reflect . PtrTo ( rt ) . MethodByName ( " " ) ; ok { info . ConcreteInfo . IsAminoUnmarshaler = true info . ConcreteInfo . AminoUnmarshalReprType = unmarshalAminoReprType ( rm ) } return info } 
func ( cdc * Codec ) collectImplementers_nolock ( info * TypeInfo ) { for _ , cinfo := range cdc . concreteInfos { if cinfo . PtrToType . Implements ( info . Type ) { info . Implementers [ cinfo . Prefix ] = append ( info . Implementers [ cinfo . Prefix ] , cinfo ) } } } 
func ( cdc * Codec ) checkConflictsInPrio_nolock ( iinfo * TypeInfo ) error { for _ , cinfos := range iinfo . Implementers { if len ( cinfos ) < 2 { continue } for _ , cinfo := range cinfos { var inPrio = false for _ , disfix := range iinfo . InterfaceInfo . Priority { if cinfo . GetDisfix ( ) == disfix { inPrio = true } } if ! inPrio { return fmt . Errorf ( " " , cinfo . Type , len ( cinfos ) , iinfo . Type ) } } } return nil } 
func ( ti TypeInfo ) String ( ) string { buf := new ( bytes . Buffer ) buf . Write ( [ ] byte ( " " ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " " , ti . Type ) ) ) if ti . Type . Kind ( ) == reflect . Interface { buf . Write ( [ ] byte ( fmt . Sprintf ( " " , ti . Priority ) ) ) buf . Write ( [ ] byte ( " " ) ) for pb , cinfos := range ti . Implementers { buf . Write ( [ ] byte ( fmt . Sprintf ( " \" \" " , pb ) ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " " , cinfos ) ) ) } buf . Write ( [ ] byte ( " " ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " " , ti . InterfaceOptions . Priority ) ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " " , ti . InterfaceOptions . AlwaysDisambiguate ) ) ) } if ti . Type . Kind ( ) != reflect . Interface { if ti . ConcreteInfo . Registered { buf . Write ( [ ] byte ( " " ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " " , ti . PointerPreferred ) ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " \" \" " , ti . Name ) ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " \" \" " , ti . Disamb ) ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " \" \" " , ti . Prefix ) ) ) } else { buf . Write ( [ ] byte ( " " ) ) } buf . Write ( [ ] byte ( fmt . Sprintf ( " \" \" " , ti . AminoMarshalReprType ) ) ) buf . Write ( [ ] byte ( fmt . Sprintf ( " \" \" " , ti . AminoUnmarshalReprType ) ) ) if ti . Type . Kind ( ) == reflect . Struct { buf . Write ( [ ] byte ( fmt . Sprintf ( " " , ti . Fields ) ) ) } } buf . Write ( [ ] byte ( " " ) ) return buf . String ( ) } 
func isExported ( field reflect . StructField ) bool { } for _ , c := range field . Name { first = c break } } } 
func ( cdc * Codec ) encodeReflectBinary ( w io . Writer , info * TypeInfo , rv reflect . Value , fopts FieldOptions , bare bool ) ( err error ) { if rv . Kind ( ) == reflect . Ptr { panic ( " " ) } if ! rv . IsValid ( ) { panic ( " " ) } if printLog { spew . Printf ( " \n " , info , rv . Interface ( ) , rv . Type ( ) , fopts ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } rrv , err = toReprObject ( rv ) if err != nil { return } rinfo , err = cdc . getTypeInfo_wlock ( info . AminoMarshalReprType ) if err != nil { return } return } switch info . Type . Kind ( ) { case reflect . Array : if info . Type . Elem ( ) . Kind ( ) == reflect . Uint8 { err = cdc . encodeReflectBinaryByteArray ( w , info , rv , fopts ) } else { err = cdc . encodeReflectBinaryList ( w , info , rv , fopts , bare ) } case reflect . Slice : if info . Type . Elem ( ) . Kind ( ) == reflect . Uint8 { err = cdc . encodeReflectBinaryByteSlice ( w , info , rv , fopts ) } else { err = cdc . encodeReflectBinaryList ( w , info , rv , fopts , bare ) } case reflect . Struct : err = cdc . encodeReflectBinaryStruct ( w , info , rv , fopts , bare ) } else { err = EncodeUvarint ( w , uint64 ( rv . Int ( ) ) ) } case reflect . Int32 : if fopts . BinFixed32 { err = EncodeInt32 ( w , int32 ( rv . Int ( ) ) ) } else { err = EncodeUvarint ( w , uint64 ( rv . Int ( ) ) ) } case reflect . Int16 : err = EncodeInt16 ( w , int16 ( rv . Int ( ) ) ) case reflect . Int8 : err = EncodeInt8 ( w , int8 ( rv . Int ( ) ) ) case reflect . Int : err = EncodeUvarint ( w , uint64 ( rv . Int ( ) ) ) } else { err = EncodeUvarint ( w , rv . Uint ( ) ) } case reflect . Uint32 : if fopts . BinFixed32 { err = EncodeUint32 ( w , uint32 ( rv . Uint ( ) ) ) } else { err = EncodeUvarint ( w , rv . Uint ( ) ) } case reflect . Uint16 : err = EncodeUint16 ( w , uint16 ( rv . Uint ( ) ) ) case reflect . Uint8 : err = EncodeUint8 ( w , uint8 ( rv . Uint ( ) ) ) case reflect . Uint : err = EncodeUvarint ( w , rv . Uint ( ) ) case reflect . Float64 : if ! fopts . Unsafe { err = errors . New ( " \" \" " ) return } err = EncodeFloat64 ( w , rv . Float ( ) ) case reflect . Float32 : if ! fopts . Unsafe { err = errors . New ( " \" \" " ) return } err = EncodeFloat32 ( w , float32 ( rv . Float ( ) ) ) case reflect . String : err = EncodeString ( w , rv . String ( ) ) } return } 
func ( cdc * Codec ) encodeReflectBinaryByteSlice ( w io . Writer , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } ert := info . Type . Elem ( ) if ert . Kind ( ) != reflect . Uint8 { panic ( " " ) } err = EncodeByteSlice ( w , byteslice ) return } 
func encodeFieldNumberAndTyp3 ( w io . Writer , num uint32 , typ Typ3 ) ( err error ) { if ( typ & 0xF8 ) != 0 { panic ( fmt . Sprintf ( " " , typ ) ) } if num < 0 || num > ( 1 << 29 - 1 ) { panic ( fmt . Sprintf ( " " , num ) ) } n := binary . PutUvarint ( buf [ : ] , value64 ) _ , err = w . Write ( buf [ 0 : n ] ) return } 
func ( cdc * Codec ) decodeReflectJSON ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if info . Type . Kind ( ) == reflect . Interface && rv . Kind ( ) == reflect . Ptr { panic ( " " ) } if printLog { spew . Printf ( " \n " , bz , info , rv . Interface ( ) , rv . Type ( ) , fopts ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } return } rv . Set ( newPtr ) } rv = rv . Elem ( ) } return } } else { err = fmt . Errorf ( " " , bz ) return } } return } rinfo , err = cdc . getTypeInfo_wlock ( info . AminoUnmarshalReprType ) if err != nil { return } err = cdc . decodeReflectJSON ( bz , rinfo , rrv , fopts ) if err != nil { return } uwouts := uwrm . Call ( [ ] reflect . Value { rrv } ) erri := uwouts [ 0 ] . Interface ( ) if erri != nil { err = erri . ( error ) } return } switch ikind := info . Type . Kind ( ) ; ikind { case reflect . Array : err = cdc . decodeReflectJSONArray ( bz , info , rv , fopts ) case reflect . Slice : err = cdc . decodeReflectJSONSlice ( bz , info , rv , fopts ) case reflect . Struct : err = cdc . decodeReflectJSONStruct ( bz , info , rv , fopts ) case reflect . Map : err = cdc . decodeReflectJSONMap ( bz , info , rv , fopts ) case reflect . Uint64 , reflect . Uint : if bz [ 0 ] != '"' || bz [ len ( bz ) - 1 ] != '"' { err = fmt . Errorf ( " " , string ( bz ) ) if err != nil { return } } bz = bz [ 1 : len ( bz ) - 1 ] fallthrough case reflect . Int32 , reflect . Int16 , reflect . Int8 , reflect . Uint32 , reflect . Uint16 , reflect . Uint8 : err = invokeStdlibJSONUnmarshal ( bz , rv , fopts ) } fallthrough case reflect . Bool , reflect . String : err = invokeStdlibJSONUnmarshal ( bz , rv , fopts ) } return } 
func ( cdc * Codec ) decodeReflectJSONInterface ( bz [ ] byte , iinfo * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } if ! rv . IsNil ( ) { } if err != nil { return } cinfo , err = cdc . getTypeInfoFromName_rlock ( name ) if err != nil { return } if err != nil { rv . Set ( irvSet ) return } return } 
func ( cdc * Codec ) decodeReflectJSONArray ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } ert := info . Type . Elem ( ) length := info . Type . Len ( ) switch ert . Kind ( ) { case reflect . Uint8 : err = json . Unmarshal ( bz , & buf ) if err != nil { return } if len ( buf ) != length { err = fmt . Errorf ( " " , len ( buf ) , length ) } reflect . Copy ( rv , reflect . ValueOf ( buf ) ) return default : einfo , err = cdc . getTypeInfo_wlock ( ert ) if err != nil { return } if err = json . Unmarshal ( bz , & rawSlice ) ; err != nil { return } if len ( rawSlice ) != length { err = fmt . Errorf ( " " , len ( rawSlice ) , length ) return } ebz := rawSlice [ i ] err = cdc . decodeReflectJSON ( ebz , einfo , erv , fopts ) if err != nil { return } } return } } 
func ( cdc * Codec ) decodeReflectJSONSlice ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } var ert = info . Type . Elem ( ) switch ert . Kind ( ) { case reflect . Uint8 : if err != nil { return } if rv . Len ( ) == 0 { } else { return default : einfo , err = cdc . getTypeInfo_wlock ( ert ) if err != nil { return } if err = json . Unmarshal ( bz , & rawSlice ) ; err != nil { return } if length == 0 { rv . Set ( info . ZeroValue ) return } var srv = reflect . MakeSlice ( esrt , length , length ) for i := 0 ; i < length ; i ++ { erv := srv . Index ( i ) ebz := rawSlice [ i ] err = cdc . decodeReflectJSON ( ebz , einfo , erv , fopts ) if err != nil { return } } return } } 
func ( cdc * Codec ) decodeReflectJSONStruct ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } err = json . Unmarshal ( bz , & rawMap ) if err != nil { return } for _ , field := range info . Fields { var finfo * TypeInfo finfo , err = cdc . getTypeInfo_wlock ( field . Type ) if err != nil { return } if len ( valueBytes ) == 0 { continue } if err != nil { return } } return nil } 
func ( cdc * Codec ) decodeReflectJSONMap ( bz [ ] byte , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if ! rv . CanAddr ( ) { panic ( " " ) } if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } err = json . Unmarshal ( bz , & rawMap ) if err != nil { return } var krt = rv . Type ( ) . Key ( ) if krt . Kind ( ) != reflect . String { err = fmt . Errorf ( " " ) return } var vinfo * TypeInfo vinfo , err = cdc . getTypeInfo_wlock ( rv . Type ( ) . Elem ( ) ) if err != nil { return } var mrv = reflect . MakeMapWithSize ( rv . Type ( ) , len ( rawMap ) ) for key , valueBytes := range rawMap { if err != nil { return } krv . SetString ( key ) mrv . SetMapIndex ( krv , vrv ) } rv . Set ( mrv ) return nil } 
func decodeInterfaceJSON ( bz [ ] byte ) ( name string , data [ ] byte , err error ) { dfw := new ( disfixWrapper ) err = json . Unmarshal ( bz , dfw ) if err != nil { err = fmt . Errorf ( " " , err ) return } return } name = dfw . Name return } data = dfw . Data return } 
func getTypeFromPointer ( ptr interface { } ) reflect . Type { rt := reflect . TypeOf ( ptr ) if rt . Kind ( ) != reflect . Ptr { panic ( fmt . Sprintf ( " " , rt ) ) } return rt . Elem ( ) } 
func slide ( bz * [ ] byte , n * int , _n int ) bool { if _n < 0 || _n > len ( * bz ) { panic ( fmt . Sprintf ( " " , len ( * bz ) , _n ) ) } * bz = ( * bz ) [ _n : ] if n != nil { * n += _n } return true } 
func derefPointers ( rv reflect . Value ) ( drv reflect . Value , isPtr bool , isNilPtr bool ) { for rv . Kind ( ) == reflect . Ptr { isPtr = true if rv . IsNil ( ) { isNilPtr = true return } rv = rv . Elem ( ) } drv = rv return } 
func derefPointersZero ( rv reflect . Value ) ( drv reflect . Value , isPtr bool , isNilPtr bool ) { for rv . Kind ( ) == reflect . Ptr { isPtr = true if rv . IsNil ( ) { isNilPtr = true rt := rv . Type ( ) . Elem ( ) for rt . Kind ( ) == reflect . Ptr { rt = rt . Elem ( ) } drv = reflect . New ( rt ) . Elem ( ) return } rv = rv . Elem ( ) } drv = rv return } 
func isDefaultValue ( rv reflect . Value ) ( erv reflect . Value , isDefaultValue bool ) { rv , _ , isNilPtr := derefPointers ( rv ) if isNilPtr { return rv , true } else { switch rv . Kind ( ) { case reflect . Bool : return rv , rv . Bool ( ) == false case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 : return rv , rv . Int ( ) == 0 case reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 : return rv , rv . Uint ( ) == 0 case reflect . String : return rv , rv . Len ( ) == 0 case reflect . Chan , reflect . Map , reflect . Slice : return rv , rv . IsNil ( ) || rv . Len ( ) == 0 case reflect . Func , reflect . Interface : return rv , rv . IsNil ( ) default : return rv , false } } } 
func defaultValue ( rt reflect . Type ) ( rv reflect . Value ) { switch rt . Kind ( ) { case reflect . Ptr : for rt_ . Kind ( ) == reflect . Ptr { rt_ = rt_ . Elem ( ) } switch rt_ { case timeType : rt_ , rv_ := rt , rv for rt_ . Kind ( ) == reflect . Ptr { newPtr := reflect . New ( rt_ . Elem ( ) ) rv_ . Set ( newPtr ) rt_ = rt_ . Elem ( ) rv_ = rv_ . Elem ( ) } return rv } case reflect . Struct : switch rt { case timeType : rv . Set ( reflect . ValueOf ( zeroTime ) ) return rv } } } 
func constructConcreteType ( cinfo * TypeInfo ) ( crv , irvSet reflect . Value ) { crv = cPtrRv . Elem ( ) irvSet = cPtrRv } else { crv = reflect . New ( cinfo . Type ) . Elem ( ) irvSet = crv } return } 
func typeToTyp3 ( rt reflect . Type , opts FieldOptions ) Typ3 { switch rt . Kind ( ) { case reflect . Interface : return Typ3_ByteLength case reflect . Array , reflect . Slice : return Typ3_ByteLength case reflect . String : return Typ3_ByteLength case reflect . Struct , reflect . Map : return Typ3_ByteLength case reflect . Int64 , reflect . Uint64 : if opts . BinFixed64 { return Typ3_8Byte } else { return Typ3_Varint } case reflect . Int32 , reflect . Uint32 : if opts . BinFixed32 { return Typ3_4Byte } else { return Typ3_Varint } case reflect . Int16 , reflect . Int8 , reflect . Int , reflect . Uint16 , reflect . Uint8 , reflect . Uint , reflect . Bool : return Typ3_Varint case reflect . Float64 : return Typ3_8Byte case reflect . Float32 : return Typ3_4Byte default : panic ( fmt . Sprintf ( " " , rt ) ) } } 
func slide ( bzPtr * [ ] byte , n * int , _n int ) bool { if len ( * bzPtr ) < _n { panic ( " " ) } * bzPtr = ( * bzPtr ) [ _n : ] * n += _n return true } 
func ( cdc * Codec ) encodeReflectJSON ( w io . Writer , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if ! rv . IsValid ( ) { panic ( " " ) } if printLog { spew . Printf ( " \n " , info , rv . Interface ( ) , rv . Type ( ) , fopts ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } rv , _ , isNilPtr = derefPointers ( rv ) return } rv = reflect . ValueOf ( ct ) } return } } else if rv . Type ( ) . Implements ( jsonMarshalerType ) { err = invokeMarshalJSON ( w , rv ) return } rrv , err = toReprObject ( rv ) if err != nil { return } rinfo , err = cdc . getTypeInfo_wlock ( info . AminoMarshalReprType ) if err != nil { return } return } switch info . Type . Kind ( ) { case reflect . Array , reflect . Slice : return cdc . encodeReflectJSONList ( w , info , rv , fopts ) case reflect . Struct : return cdc . encodeReflectJSONStruct ( w , info , rv , fopts ) case reflect . Map : return cdc . encodeReflectJSONMap ( w , info , rv , fopts ) return case reflect . Uint64 , reflect . Uint : _ , err = fmt . Fprintf ( w , `"%d"` , rv . Uint ( ) ) return case reflect . Int32 , reflect . Int16 , reflect . Int8 , reflect . Uint32 , reflect . Uint16 , reflect . Uint8 : return invokeStdlibJSONMarshal ( w , rv . Interface ( ) ) } fallthrough case reflect . Bool , reflect . String : return invokeStdlibJSONMarshal ( w , rv . Interface ( ) ) } } 
func ( cdc * Codec ) encodeReflectJSONMap ( w io . Writer , info * TypeInfo , rv reflect . Value , fopts FieldOptions ) ( err error ) { if printLog { fmt . Println ( " " ) defer func ( ) { fmt . Printf ( " \n " , err ) } ( ) } if err != nil { return } } } ( ) return } var writeComma = false for _ , krv := range rv . MapKeys ( ) { if err != nil { return } writeComma = false } if err != nil { return } if err != nil { return } } else { var vinfo * TypeInfo vinfo , err = cdc . getTypeInfo_wlock ( vrv . Type ( ) ) if err != nil { return } err = cdc . encodeReflectJSON ( w , vinfo , vrv , fopts ) } if err != nil { return } writeComma = true } return } 
func invokeMarshalJSON ( w io . Writer , rv reflect . Value ) error { blob , err := rv . Interface ( ) . ( json . Marshaler ) . MarshalJSON ( ) if err != nil { return err } _ , err = w . Write ( blob ) return err } 
func isEmpty ( rv reflect . Value , zrv reflect . Value ) bool { if ! rv . IsValid ( ) { return true } if reflect . DeepEqual ( rv . Interface ( ) , zrv . Interface ( ) ) { return true } switch rv . Kind ( ) { case reflect . Slice , reflect . Array , reflect . String : if rv . Len ( ) == 0 { return true } } return false } 
func EncodeInt8 ( w io . Writer , i int8 ) ( err error ) { return EncodeVarint ( w , int64 ( i ) ) } 
func EncodeByte ( w io . Writer , b byte ) ( err error ) { return EncodeUvarint ( w , uint64 ( b ) ) } 
func EncodeUvarint ( w io . Writer , u uint64 ) ( err error ) { var buf [ 10 ] byte n := binary . PutUvarint ( buf [ : ] , u ) _ , err = w . Write ( buf [ 0 : n ] ) return } 
func EncodeBool ( w io . Writer , b bool ) ( err error ) { if b { err = EncodeUint8 ( w , 1 ) } else { err = EncodeUint8 ( w , 0 ) } return } 
func EncodeFloat32 ( w io . Writer , f float32 ) ( err error ) { return EncodeUint32 ( w , math . Float32bits ( f ) ) } 
func EncodeFloat64 ( w io . Writer , f float64 ) ( err error ) { return EncodeUint64 ( w , math . Float64bits ( f ) ) } 
func EncodeTime ( w io . Writer , t time . Time ) ( err error ) { s := t . Unix ( ) } err = encodeFieldNumberAndTyp3 ( w , 1 , Typ3_Varint ) if err != nil { return } err = EncodeUvarint ( w , uint64 ( s ) ) if err != nil { return } } ns := int32 ( t . Nanosecond ( ) ) } err = encodeFieldNumberAndTyp3 ( w , 2 , Typ3_Varint ) if err != nil { return } err = EncodeUvarint ( w , uint64 ( ns ) ) if err != nil { return } } return } 
func DecodeInt8 ( bz [ ] byte ) ( i int8 , n int , err error ) { var i64 = int64 ( 0 ) i64 , n , err = DecodeVarint ( bz ) if err != nil { return } if i64 < int64 ( math . MinInt8 ) || i64 > int64 ( math . MaxInt8 ) { err = errors . New ( " " ) return } i = int8 ( i64 ) return } 
func DecodeByte ( bz [ ] byte ) ( b byte , n int , err error ) { return DecodeUint8 ( bz ) } 
func DecodeBool ( bz [ ] byte ) ( b bool , n int , err error ) { const size int = 1 if len ( bz ) < size { err = errors . New ( " " ) return } switch bz [ 0 ] { case 0 : b = false case 1 : b = true default : err = errors . New ( " " ) } n = size return } 
func DecodeFloat32 ( bz [ ] byte ) ( f float32 , n int , err error ) { const size int = 4 if len ( bz ) < size { err = errors . New ( " " ) return } i := binary . LittleEndian . Uint32 ( bz [ : size ] ) f = math . Float32frombits ( i ) n = size return } 
func DecodeFloat64 ( bz [ ] byte ) ( f float64 , n int , err error ) { const size int = 8 if len ( bz ) < size { err = errors . New ( " " ) return } i := binary . LittleEndian . Uint64 ( bz [ : size ] ) f = math . Float64frombits ( i ) n = size return } 
func DecodeTime ( bz [ ] byte ) ( t time . Time , n int , err error ) { var nsec int32 if len ( bz ) > 0 { sec , n , err = decodeSeconds ( & bz ) if err != nil { return } } if len ( bz ) > 0 { nsec , err = decodeNanos ( & bz , & n ) if err != nil { return } } return } 
func DeepCopy ( o interface { } ) ( r interface { } ) { if o == nil { return nil } src := reflect . ValueOf ( o ) dst := reflect . New ( src . Type ( ) ) . Elem ( ) deepCopy ( src , dst ) return dst . Interface ( ) } 
func callDeepCopy ( src , dst reflect . Value ) bool { dc := src . MethodByName ( " " ) if ! dc . IsValid ( ) { return false } if dc . Type ( ) . NumIn ( ) != 0 { return false } if dc . Type ( ) . NumOut ( ) != 1 { return false } otype := dc . Type ( ) . Out ( 0 ) if dst . Kind ( ) == reflect . Ptr && dst . Type ( ) . Elem ( ) == otype { cpy := reflect . New ( dst . Type ( ) . Elem ( ) ) out := dc . Call ( nil ) [ 0 ] cpy . Elem ( ) . Set ( out ) dst . Set ( cpy ) return true } if dst . Type ( ) == otype { out := dc . Call ( nil ) [ 0 ] dst . Set ( out ) return true } return false } 
func callAminoCopy ( src , dst reflect . Value ) bool { if src . Type ( ) != dst . Type ( ) { panic ( " " ) } if src . Kind ( ) == reflect . Ptr { cpy := reflect . New ( src . Type ( ) . Elem ( ) ) dst . Set ( cpy ) } else if src . CanAddr ( ) { if ! dst . CanAddr ( ) { panic ( " " ) } src = src . Addr ( ) dst = dst . Addr ( ) } else { return false } if ! canAminoCopy ( src ) { return false } cpy := reflect . New ( src . Type ( ) . Elem ( ) ) dst . Set ( cpy ) ma := src . MethodByName ( " " ) ua := dst . MethodByName ( " " ) outs := ma . Call ( nil ) repr , err := outs [ 0 ] , outs [ 1 ] if ! err . IsNil ( ) { panic ( err . Interface ( ) ) } outs = ua . Call ( [ ] reflect . Value { repr } ) err = outs [ 0 ] if ! err . IsNil ( ) { panic ( err . Interface ( ) ) } return true } 
func ( cdc * Codec ) MarshalBinaryLengthPrefixed ( o interface { } ) ( [ ] byte , error ) { if err != nil { return nil , err } if err != nil { return nil , err } if err != nil { return nil , err } return buf . Bytes ( ) , nil } 
func ( cdc * Codec ) MarshalBinaryLengthPrefixedWriter ( w io . Writer , o interface { } ) ( n int64 , err error ) { var bz , _n = [ ] byte ( nil ) , int ( 0 ) bz , err = cdc . MarshalBinaryLengthPrefixed ( o ) if err != nil { return 0 , err } _n , err = w . Write ( bz ) n = int64 ( _n ) return } 
func ( cdc * Codec ) MustMarshalBinaryLengthPrefixed ( o interface { } ) [ ] byte { bz , err := cdc . MarshalBinaryLengthPrefixed ( o ) if err != nil { panic ( err ) } return bz } 
func ( cdc * Codec ) MarshalBinaryBare ( o interface { } ) ( [ ] byte , error ) { if isNilPtr { } buf := new ( bytes . Buffer ) rt := rv . Type ( ) info , err := cdc . getTypeInfo_wlock ( rt ) if err != nil { return nil , err } err = cdc . encodeReflectBinary ( buf , info , rv , FieldOptions { BinFieldNum : 1 } , true ) if err != nil { return nil , err } bz = buf . Bytes ( ) bz = append ( pb , bz ... ) } return bz , nil } 
func ( cdc * Codec ) MustMarshalBinaryBare ( o interface { } ) [ ] byte { bz , err := cdc . MarshalBinaryBare ( o ) if err != nil { panic ( err ) } return bz } 
func ( cdc * Codec ) UnmarshalBinaryLengthPrefixed ( bz [ ] byte , ptr interface { } ) error { if len ( bz ) == 0 { return errors . New ( " " ) } if n < 0 { return fmt . Errorf ( " " , n ) } if u64 > uint64 ( len ( bz ) - n ) { return fmt . Errorf ( " " , u64 , len ( bz ) - n ) } else if u64 < uint64 ( len ( bz ) - n ) { return fmt . Errorf ( " " , u64 , len ( bz ) - n ) } bz = bz [ n : ] } 
func ( cdc * Codec ) UnmarshalBinaryLengthPrefixedReader ( r io . Reader , ptr interface { } , maxSize int64 ) ( n int64 , err error ) { if maxSize < 0 { panic ( " " ) } var buf [ binary . MaxVarintLen64 ] byte for i := 0 ; i < len ( buf ) ; i ++ { _ , err = r . Read ( buf [ i : i + 1 ] ) if err != nil { return } n += 1 if buf [ i ] & 0x80 == 0 { break } if n >= maxSize { err = fmt . Errorf ( " " , maxSize ) } } u64 , _ := binary . Uvarint ( buf [ : ] ) if err != nil { return } if maxSize > 0 { if uint64 ( maxSize ) < u64 { err = fmt . Errorf ( " " , maxSize , u64 ) return } if ( maxSize - n ) < int64 ( u64 ) { err = fmt . Errorf ( " " , maxSize , n , u64 ) return } } l = int64 ( u64 ) if l < 0 { err = fmt . Errorf ( " " ) } _ , err = io . ReadFull ( r , bz ) if err != nil { return } n += l return } 
func ( cdc * Codec ) MustUnmarshalBinaryLengthPrefixed ( bz [ ] byte , ptr interface { } ) { err := cdc . UnmarshalBinaryLengthPrefixed ( bz , ptr ) if err != nil { panic ( err ) } } 
func ( cdc * Codec ) UnmarshalBinaryBare ( bz [ ] byte , ptr interface { } ) error { rv := reflect . ValueOf ( ptr ) if rv . Kind ( ) != reflect . Ptr { panic ( " " ) } rv = rv . Elem ( ) rt := rv . Type ( ) info , err := cdc . getTypeInfo_wlock ( rt ) if err != nil { return err } if len ( bz ) < 4 { return fmt . Errorf ( " " , pb , bz ) } else if ! bytes . Equal ( bz [ : 4 ] , pb ) { return fmt . Errorf ( " " , pb , bz [ : 4 ] ) } bz = bz [ 4 : ] } if err != nil { return fmt . Errorf ( " " , info . Type , n , err , bz ) } if n != len ( bz ) { return fmt . Errorf ( " " , info . Type , len ( bz ) , n , bz ) } return nil } 
func ( cdc * Codec ) MustUnmarshalBinaryBare ( bz [ ] byte , ptr interface { } ) { err := cdc . UnmarshalBinaryBare ( bz , ptr ) if err != nil { panic ( err ) } } 
func ( cdc * Codec ) MustMarshalJSON ( o interface { } ) [ ] byte { bz , err := cdc . MarshalJSON ( o ) if err != nil { panic ( err ) } return bz } 
func ( cdc * Codec ) MustUnmarshalJSON ( bz [ ] byte , ptr interface { } ) { if err := cdc . UnmarshalJSON ( bz , ptr ) ; err != nil { panic ( err ) } } 
func ( cdc * Codec ) MarshalJSONIndent ( o interface { } , prefix , indent string ) ( [ ] byte , error ) { bz , err := cdc . MarshalJSON ( o ) if err != nil { return nil , err } var out bytes . Buffer err = json . Indent ( & out , bz , prefix , indent ) if err != nil { return nil , err } return out . Bytes ( ) , nil } 
func DialTo ( addr string ) ( * Conn , error ) { const network = " " if " " == addr { addr = " " } conn , err := net . Dial ( network , addr ) if nil != err { return nil , err } dataReader := newDataReader ( conn ) dataWriter := newDataWriter ( conn ) clientConn := Conn { conn : conn , dataReader : dataReader , dataWriter : dataWriter , } return & clientConn , nil } 
func DialToTLS ( addr string , tlsConfig * tls . Config ) ( * Conn , error ) { const network = " " if " " == addr { addr = " " } conn , err := tls . Dial ( network , addr , tlsConfig ) if nil != err { return nil , err } dataReader := newDataReader ( conn ) dataWriter := newDataWriter ( conn ) clientConn := Conn { conn : conn , dataReader : dataReader , dataWriter : dataWriter , } return & clientConn , nil } 
func ( clientConn * Conn ) Read ( p [ ] byte ) ( n int , err error ) { return clientConn . dataReader . Read ( p ) } 
func ( clientConn * Conn ) Write ( p [ ] byte ) ( n int , err error ) { return clientConn . dataWriter . Write ( p ) } 
func newDataReader ( r io . Reader ) * internalDataReader { buffered := bufio . NewReader ( r ) reader := internalDataReader { wrapped : r , buffered : buffered , } return & reader } 
func ( r * internalDataReader ) Read ( data [ ] byte ) ( n int , err error ) { const IAC = 255 const SB = 250 const SE = 240 const WILL = 251 const WONT = 252 const DO = 253 const DONT = 254 p := data for len ( p ) > 0 { var b byte b , err = r . buffered . ReadByte ( ) if nil != err { return n , err } if IAC == b { var peeked [ ] byte peeked , err = r . buffered . Peek ( 1 ) if nil != err { return n , err } switch peeked [ 0 ] { case WILL , WONT , DO , DONT : _ , err = r . buffered . Discard ( 2 ) if nil != err { return n , err } case IAC : p [ 0 ] = IAC n ++ p = p [ 1 : ] _ , err = r . buffered . Discard ( 1 ) if nil != err { return n , err } case SB : for { var b2 byte b2 , err = r . buffered . ReadByte ( ) if nil != err { return n , err } if IAC == b2 { peeked , err = r . buffered . Peek ( 1 ) if nil != err { return n , err } if IAC == peeked [ 0 ] { _ , err = r . buffered . Discard ( 1 ) if nil != err { return n , err } } if SE == peeked [ 0 ] { _ , err = r . buffered . Discard ( 1 ) if nil != err { return n , err } break } } } case SE : _ , err = r . buffered . Discard ( 1 ) if nil != err { return n , err } default : return n , err } } else { p [ 0 ] = b n ++ p = p [ 1 : ] } } return n , nil } 
func ListenAndServeTLS ( addr string , certFile string , keyFile string , handler Handler ) error { server := & Server { Addr : addr , Handler : handler } return server . ListenAndServeTLS ( certFile , keyFile ) } 
func ( server * Server ) ListenAndServeTLS ( certFile string , keyFile string ) error { addr := server . Addr if " " == addr { addr = " " } listener , err := net . Listen ( " " , addr ) if nil != err { return err } if nil == server . TLSConfig { tlsConfig = & tls . Config { } } else { tlsConfig = & tls . Config { Rand : server . TLSConfig . Rand , Time : server . TLSConfig . Time , Certificates : server . TLSConfig . Certificates , NameToCertificate : server . TLSConfig . NameToCertificate , GetCertificate : server . TLSConfig . GetCertificate , RootCAs : server . TLSConfig . RootCAs , NextProtos : server . TLSConfig . NextProtos , ServerName : server . TLSConfig . ServerName , ClientAuth : server . TLSConfig . ClientAuth , ClientCAs : server . TLSConfig . ClientCAs , InsecureSkipVerify : server . TLSConfig . InsecureSkipVerify , CipherSuites : server . TLSConfig . CipherSuites , PreferServerCipherSuites : server . TLSConfig . PreferServerCipherSuites , SessionTicketsDisabled : server . TLSConfig . SessionTicketsDisabled , SessionTicketKey : server . TLSConfig . SessionTicketKey , ClientSessionCache : server . TLSConfig . ClientSessionCache , MinVersion : server . TLSConfig . MinVersion , MaxVersion : server . TLSConfig . MaxVersion , CurvePreferences : server . TLSConfig . CurvePreferences , } } tlsConfigHasCertificate := len ( tlsConfig . Certificates ) > 0 || nil != tlsConfig . GetCertificate if " " == certFile || " " == keyFile || ! tlsConfigHasCertificate { tlsConfig . Certificates = make ( [ ] tls . Certificate , 1 ) var err error tlsConfig . Certificates [ 0 ] , err = tls . LoadX509KeyPair ( certFile , keyFile ) if nil != err { return err } } tlsListener := tls . NewListener ( listener , tlsConfig ) return server . Serve ( tlsListener ) } 
func newDataWriter ( w io . Writer ) * internalDataWriter { writer := internalDataWriter { wrapped : w , } return & writer } 
func ( w * internalDataWriter ) Write ( data [ ] byte ) ( n int , err error ) { var n64 int64 n64 , err = w . write64 ( data ) n = int ( n64 ) if int64 ( n ) != n64 { panic ( errOverflow ) } return n , err } 
func ( fn ProducerFunc ) Produce ( ctx telnet . Context , name string , args ... string ) Handler { return fn ( ctx , name , args ... ) } 
func PromoteHandlerFunc ( fn HandlerFunc , args ... string ) Handler { stdin , stdinPipe := io . Pipe ( ) stdoutPipe , stdout := io . Pipe ( ) stderrPipe , stderr := io . Pipe ( ) argsCopy := make ( [ ] string , len ( args ) ) for i , datum := range args { argsCopy [ i ] = datum } handler := internalPromotedHandlerFunc { err : nil , fn : fn , stdin : stdin , stdout : stdout , stderr : stderr , stdinPipe : stdinPipe , stdoutPipe : stdoutPipe , stderrPipe : stderrPipe , args : argsCopy , } return & handler } 
func Serve ( listener net . Listener , handler Handler ) error { server := & Server { Handler : handler } return server . Serve ( listener ) } 
func ( server * Server ) ListenAndServe ( ) error { addr := server . Addr if " " == addr { addr = " " } listener , err := net . Listen ( " " , addr ) if nil != err { return err } return server . Serve ( listener ) } 
func ( server * Server ) Serve ( listener net . Listener ) error { defer listener . Close ( ) logger := server . logger ( ) handler := server . Handler if nil == handler { handler = EchoHandler } for { conn , err := listener . Accept ( ) if err != nil { } logger . Debugf ( " " , conn . RemoteAddr ( ) ) logger . Debugf ( " " , conn . RemoteAddr ( ) ) } } 
func ( p * Parser ) Fail ( msg string ) { p . WriteUsage ( os . Stderr ) fmt . Fprintln ( os . Stderr , " " , msg ) os . Exit ( - 1 ) } 
func ( p * Parser ) WriteUsage ( w io . Writer ) { var positionals , options [ ] * spec for _ , spec := range p . specs { if spec . positional { positionals = append ( positionals , spec ) } else { options = append ( options , spec ) } } if p . version != " " { fmt . Fprintln ( w , p . version ) } fmt . Fprintf ( w , " " , p . config . Program ) if ! spec . required { fmt . Fprint ( w , " " ) } fmt . Fprint ( w , synopsis ( spec , " " + spec . long ) ) if ! spec . required { fmt . Fprint ( w , " " ) } } up := strings . ToUpper ( spec . long ) if spec . multiple { if ! spec . required { fmt . Fprint ( w , " " ) } fmt . Fprintf ( w , " " , up , up ) if ! spec . required { fmt . Fprint ( w , " " ) } } else { fmt . Fprint ( w , up ) } } fmt . Fprint ( w , " \n " ) } 
func ( p * Parser ) WriteHelp ( w io . Writer ) { var positionals , options [ ] * spec for _ , spec := range p . specs { if spec . positional { positionals = append ( positionals , spec ) } else { options = append ( options , spec ) } } if p . description != " " { fmt . Fprintln ( w , p . description ) } p . WriteUsage ( w ) for _ , spec := range positionals { left := " " + strings . ToUpper ( spec . long ) fmt . Fprint ( w , left ) if spec . help != " " { if len ( left ) + 2 < colWidth { fmt . Fprint ( w , strings . Repeat ( " " , colWidth - len ( left ) ) ) } else { fmt . Fprint ( w , " \n " + strings . Repeat ( " " , colWidth ) ) } fmt . Fprint ( w , spec . help ) } fmt . Fprint ( w , " \n " ) } } for _ , spec := range options { printOption ( w , spec ) } if p . version != " " { printOption ( w , & spec { boolean : true , long : " " , help : " " } ) } } 
func MustParse ( dest ... interface { } ) * Parser { p , err := NewParser ( Config { } , dest ... ) if err != nil { fmt . Println ( err ) os . Exit ( - 1 ) } err = p . Parse ( flags ( ) ) if err == ErrHelp { p . WriteHelp ( os . Stdout ) os . Exit ( 0 ) } if err == ErrVersion { fmt . Println ( p . version ) os . Exit ( 0 ) } if err != nil { p . Fail ( err . Error ( ) ) } return p } 
func Parse ( dest ... interface { } ) error { p , err := NewParser ( Config { } , dest ... ) if err != nil { return err } return p . Parse ( flags ( ) ) } 
func walkFields ( v reflect . Value , visit func ( field reflect . StructField , val reflect . Value , owner reflect . Type ) bool ) { t := v . Type ( ) for i := 0 ; i < t . NumField ( ) ; i ++ { field := t . Field ( i ) val := v . Field ( i ) expand := visit ( field , val , t ) if expand && field . Type . Kind ( ) == reflect . Struct { walkFields ( val , visit ) } } } 
func NewParser ( config Config , dests ... interface { } ) ( * Parser , error ) { p := Parser { config : config , } for _ , dest := range dests { if dest , ok := dest . ( Versioned ) ; ok { p . version = dest . Version ( ) } if dest , ok := dest . ( Described ) ; ok { p . description = dest . Description ( ) } v := reflect . ValueOf ( dest ) if v . Kind ( ) != reflect . Ptr { panic ( fmt . Sprintf ( " " , v . Type ( ) ) ) } v = v . Elem ( ) if v . Kind ( ) != reflect . Struct { panic ( fmt . Sprintf ( " " , dest ) ) } var errs [ ] string walkFields ( v , func ( field reflect . StructField , val reflect . Value , t reflect . Type ) bool { if tag == " " { return false } } spec := spec { long : strings . ToLower ( field . Name ) , dest : val , } help , exists := field . Tag . Lookup ( " " ) if exists { spec . help = help } parseable , spec . boolean , spec . multiple = canParse ( field . Type ) if ! parseable { errs = append ( errs , fmt . Sprintf ( " " , t . Name ( ) , field . Name , field . Type . String ( ) ) ) return false } var value string if pos := strings . Index ( key , " " ) ; pos != - 1 { value = key [ pos + 1 : ] key = key [ : pos ] } switch { case strings . HasPrefix ( key , " " ) : errs = append ( errs , fmt . Sprintf ( " " , t . Name ( ) , field . Name ) ) case strings . HasPrefix ( key , " " ) : spec . long = key [ 2 : ] case strings . HasPrefix ( key , " " ) : if len ( key ) != 2 { errs = append ( errs , fmt . Sprintf ( " " , t . Name ( ) , field . Name ) ) return false } spec . short = key [ 1 : ] case key == " " : spec . required = true case key == " " : spec . positional = true case key == " " : spec . separate = true case key == " " : case key == " " : } else { spec . env = strings . ToUpper ( field . Name ) } default : errs = append ( errs , fmt . Sprintf ( " " , key , tag ) ) return false } } } p . specs = append ( p . specs , & spec ) } ) if len ( errs ) > 0 { return nil , errors . New ( strings . Join ( errs , " \n " ) ) } } if p . config . Program == " " { p . config . Program = " " if len ( os . Args ) > 0 { p . config . Program = filepath . Base ( os . Args [ 0 ] ) } } return & p , nil } 
func ( p * Parser ) Parse ( args [ ] string ) error { } if arg == " " { return ErrVersion } if arg == " " { break } } } 
func process ( specs [ ] * spec , args [ ] string ) error { for _ , spec := range specs { if spec . positional { continue } if spec . long != " " { optionMap [ spec . long ] = spec } if spec . short != " " { optionMap [ spec . short ] = spec } } } value , found := os . LookupEnv ( spec . env ) if ! found { continue } if spec . multiple { if err != nil { return fmt . Errorf ( " " , spec . env , err , ) } if err = setSlice ( spec . dest , values , ! spec . separate ) ; err != nil { return fmt . Errorf ( " " , spec . env , err , ) } } else { if err := scalar . ParseValue ( spec . dest , value ) ; err != nil { return fmt . Errorf ( " " , spec . env , err ) } } wasPresent [ spec ] = true } var positionals [ ] string if arg == " " { allpositional = true continue } if ! isFlag ( arg ) || allpositional { positionals = append ( positionals , arg ) continue } opt := strings . TrimLeft ( arg , " " ) if pos := strings . Index ( opt , " " ) ; pos != - 1 { value = opt [ pos + 1 : ] opt = opt [ : pos ] } if ! ok { return fmt . Errorf ( " " , arg ) } wasPresent [ spec ] = true if value == " " { for i + 1 < len ( args ) && ! isFlag ( args [ i + 1 ] ) { values = append ( values , args [ i + 1 ] ) i ++ if spec . separate { break } } } else { values = append ( values , value ) } err := setSlice ( spec . dest , values , ! spec . separate ) if err != nil { return fmt . Errorf ( " " , arg , err ) } continue } } } if ! nextIsNumeric ( spec . dest . Type ( ) , args [ i + 1 ] ) && isFlag ( args [ i + 1 ] ) { return fmt . Errorf ( " " , arg ) } value = args [ i + 1 ] i ++ } err := scalar . ParseValue ( spec . dest , value ) if err != nil { return fmt . Errorf ( " " , arg , err ) } } } if len ( positionals ) == 0 { break } wasPresent [ spec ] = true if spec . multiple { err := setSlice ( spec . dest , positionals , true ) if err != nil { return fmt . Errorf ( " " , spec . long , err ) } positionals = nil } else { err := scalar . ParseValue ( spec . dest , positionals [ 0 ] ) if err != nil { return fmt . Errorf ( " " , spec . long , err ) } positionals = positionals [ 1 : ] } } if len ( positionals ) > 0 { return fmt . Errorf ( " " , positionals [ 0 ] ) } if ! spec . positional { name = " " + spec . long } return fmt . Errorf ( " " , name ) } } return nil } 
func isFlag ( s string ) bool { return strings . HasPrefix ( s , " " ) && strings . TrimLeft ( s , " " ) != " " } 
func setSlice ( dest reflect . Value , values [ ] string , trunc bool ) error { if ! dest . CanSet ( ) { return fmt . Errorf ( " " ) } var ptr bool elem := dest . Type ( ) . Elem ( ) if elem . Kind ( ) == reflect . Ptr && ! elem . Implements ( textUnmarshalerType ) { ptr = true elem = elem . Elem ( ) } } for _ , s := range values { v := reflect . New ( elem ) if err := scalar . ParseValue ( v . Elem ( ) , s ) ; err != nil { return err } if ! ptr { v = v . Elem ( ) } dest . Set ( reflect . Append ( dest , v ) ) } return nil } 
func canParse ( t reflect . Type ) ( parseable , boolean , multiple bool ) { parseable = scalar . CanParse ( t ) boolean = isBoolean ( t ) if parseable { return } } t = t . Elem ( ) } parseable = scalar . CanParse ( t ) boolean = isBoolean ( t ) if parseable { return } } parseable = scalar . CanParse ( t ) boolean = isBoolean ( t ) if parseable { return } return false , false , false } 
func isBoolean ( t reflect . Type ) bool { switch { case t . Implements ( textUnmarshalerType ) : return false case t . Kind ( ) == reflect . Bool : return true case t . Kind ( ) == reflect . Ptr && t . Elem ( ) . Kind ( ) == reflect . Bool : return true default : return false } } 
func NewFromMap ( m map [ string ] interface { } ) * Tree { t := & Tree { root : & node { } } for k , v := range m { t . Insert ( k , v ) } return t } 
func ( t * Tree ) Insert ( s string , v interface { } ) ( interface { } , bool ) { var parent * node n := t . root search := s for { n . leaf . val = v return old , true } n . leaf = & leafNode { key : s , val : v , } t . size ++ return nil , false } n = n . getEdge ( search [ 0 ] ) parent . addEdge ( e ) t . size ++ return nil , false } if commonPrefix == len ( n . prefix ) { search = search [ commonPrefix : ] continue } child := & node { prefix : search [ : commonPrefix ] , } parent . updateEdge ( search [ 0 ] , child ) n . prefix = n . prefix [ commonPrefix : ] if len ( search ) == 0 { child . leaf = leaf return nil , false } return nil , false } } 
func ( t * Tree ) Delete ( s string ) ( interface { } , bool ) { var parent * node var label byte n := t . root search := s for { } goto DELETE } label = search [ 0 ] n = n . getEdge ( label ) if n == nil { break } } else { break } } return nil , false DELETE : n . leaf = nil t . size -- } } } return leaf . val , true } 
func ( t * Tree ) DeletePrefix ( s string ) int { return t . deletePrefix ( nil , t . root , s ) } 
func ( t * Tree ) deletePrefix ( parent , n * node , prefix string ) int { return false } ) if n . isLeaf ( ) { n . leaf = nil } n . edges = nil } t . size -= subTreeSize return subTreeSize } child := n . getEdge ( label ) if child == nil || ( ! strings . HasPrefix ( child . prefix , prefix ) && ! strings . HasPrefix ( prefix , child . prefix ) ) { return 0 } } else { prefix = prefix [ len ( child . prefix ) : ] } return t . deletePrefix ( n , child , prefix ) } 
func ( t * Tree ) Get ( s string ) ( interface { } , bool ) { n := t . root search := s for { } break } if n == nil { break } } else { break } } return nil , false } 
func ( t * Tree ) LongestPrefix ( s string ) ( string , interface { } , bool ) { var last * leafNode n := t . root search := s for { } } if n == nil { break } } else { break } } if last != nil { return last . key , last . val , true } return " " , nil , false } 
func ( t * Tree ) Minimum ( ) ( string , interface { } , bool ) { n := t . root for { if n . isLeaf ( ) { return n . leaf . key , n . leaf . val , true } if len ( n . edges ) > 0 { n = n . edges [ 0 ] . node } else { break } } return " " , nil , false } 
func ( t * Tree ) WalkPrefix ( prefix string , fn WalkFn ) { n := t . root search := prefix for { return } if n == nil { break } } else if strings . HasPrefix ( n . prefix , search ) { return } else { break } } } 
func ( t * Tree ) WalkPath ( path string , fn WalkFn ) { n := t . root search := path for { } } if n == nil { return } } else { break } } } 
func recursiveWalk ( n * node , fn WalkFn ) bool { } } } return false } 
func ( t * Tree ) ToMap ( ) map [ string ] interface { } { out := make ( map [ string ] interface { } , t . size ) t . Walk ( func ( k string , v interface { } ) bool { out [ k ] = v return false } ) return out } 
func checkip ( ip string ) ( iptype uint32 , ipnum * big . Int , ipindex uint32 ) { iptype = 0 ipnum = big . NewInt ( 0 ) ipnumtmp := big . NewInt ( 0 ) ipindex = 0 ipaddress := net . ParseIP ( ip ) if ipaddress != nil { v4 := ipaddress . To4 ( ) if v4 != nil { iptype = 4 ipnum . SetBytes ( v4 ) } else { v6 := ipaddress . To16 ( ) if v6 != nil { iptype = 6 ipnum . SetBytes ( v6 ) } } } if iptype == 4 { if meta . ipv4indexbaseaddr > 0 { ipnumtmp . Rsh ( ipnum , 16 ) ipnumtmp . Lsh ( ipnumtmp , 3 ) ipindex = uint32 ( ipnumtmp . Add ( ipnumtmp , big . NewInt ( int64 ( meta . ipv4indexbaseaddr ) ) ) . Uint64 ( ) ) } } else if iptype == 6 { if meta . ipv6indexbaseaddr > 0 { ipnumtmp . Rsh ( ipnum , 112 ) ipnumtmp . Lsh ( ipnumtmp , 3 ) ipindex = uint32 ( ipnumtmp . Add ( ipnumtmp , big . NewInt ( int64 ( meta . ipv6indexbaseaddr ) ) ) . Uint64 ( ) ) } } return } 
func readuint8 ( pos int64 ) uint8 { var retval uint8 data := make ( [ ] byte , 1 ) _ , err := f . ReadAt ( data , pos - 1 ) if err != nil { fmt . Println ( " " , err ) } retval = data [ 0 ] return retval } 
func readuint32 ( pos uint32 ) uint32 { pos2 := int64 ( pos ) var retval uint32 data := make ( [ ] byte , 4 ) _ , err := f . ReadAt ( data , pos2 - 1 ) if err != nil { fmt . Println ( " " , err ) } buf := bytes . NewReader ( data ) err = binary . Read ( buf , binary . LittleEndian , & retval ) if err != nil { fmt . Println ( " " , err ) } return retval } 
func readuint128 ( pos uint32 ) * big . Int { pos2 := int64 ( pos ) retval := big . NewInt ( 0 ) data := make ( [ ] byte , 16 ) _ , err := f . ReadAt ( data , pos2 - 1 ) if err != nil { fmt . Println ( " " , err ) } } retval . SetBytes ( data ) return retval } 
func readstr ( pos uint32 ) string { pos2 := int64 ( pos ) var retval string lenbyte := make ( [ ] byte , 1 ) _ , err := f . ReadAt ( lenbyte , pos2 ) if err != nil { fmt . Println ( " " , err ) } strlen := lenbyte [ 0 ] data := make ( [ ] byte , strlen ) _ , err = f . ReadAt ( data , pos2 + 1 ) if err != nil { fmt . Println ( " " , err ) } retval = string ( data [ : strlen ] ) return retval } 
func Open ( dbpath string ) { max_ipv6_range . SetString ( " " , 10 ) var err error f , err = os . Open ( dbpath ) if err != nil { return } meta . databasetype = readuint8 ( 1 ) meta . databasecolumn = readuint8 ( 2 ) meta . databaseyear = readuint8 ( 3 ) meta . databasemonth = readuint8 ( 4 ) meta . databaseday = readuint8 ( 5 ) meta . ipv4databasecount = readuint32 ( 6 ) meta . ipv4databaseaddr = readuint32 ( 10 ) meta . ipv6databasecount = readuint32 ( 14 ) meta . ipv6databaseaddr = readuint32 ( 18 ) meta . ipv4indexbaseaddr = readuint32 ( 22 ) meta . ipv6indexbaseaddr = readuint32 ( 26 ) meta . ipv4columnsize = uint32 ( meta . databasecolumn << 2 ) meta . ipv6columnsize = uint32 ( 16 + ( ( meta . databasecolumn - 1 ) << 2 ) ) dbt := meta . databasetype country_enabled = true } if region_position [ dbt ] != 0 { region_position_offset = uint32 ( region_position [ dbt ] - 1 ) << 2 region_enabled = true } if city_position [ dbt ] != 0 { city_position_offset = uint32 ( city_position [ dbt ] - 1 ) << 2 city_enabled = true } if isp_position [ dbt ] != 0 { isp_position_offset = uint32 ( isp_position [ dbt ] - 1 ) << 2 isp_enabled = true } if domain_position [ dbt ] != 0 { domain_position_offset = uint32 ( domain_position [ dbt ] - 1 ) << 2 domain_enabled = true } if zipcode_position [ dbt ] != 0 { zipcode_position_offset = uint32 ( zipcode_position [ dbt ] - 1 ) << 2 zipcode_enabled = true } if latitude_position [ dbt ] != 0 { latitude_position_offset = uint32 ( latitude_position [ dbt ] - 1 ) << 2 latitude_enabled = true } if longitude_position [ dbt ] != 0 { longitude_position_offset = uint32 ( longitude_position [ dbt ] - 1 ) << 2 longitude_enabled = true } if timezone_position [ dbt ] != 0 { timezone_position_offset = uint32 ( timezone_position [ dbt ] - 1 ) << 2 timezone_enabled = true } if netspeed_position [ dbt ] != 0 { netspeed_position_offset = uint32 ( netspeed_position [ dbt ] - 1 ) << 2 netspeed_enabled = true } if iddcode_position [ dbt ] != 0 { iddcode_position_offset = uint32 ( iddcode_position [ dbt ] - 1 ) << 2 iddcode_enabled = true } if areacode_position [ dbt ] != 0 { areacode_position_offset = uint32 ( areacode_position [ dbt ] - 1 ) << 2 areacode_enabled = true } if weatherstationcode_position [ dbt ] != 0 { weatherstationcode_position_offset = uint32 ( weatherstationcode_position [ dbt ] - 1 ) << 2 weatherstationcode_enabled = true } if weatherstationname_position [ dbt ] != 0 { weatherstationname_position_offset = uint32 ( weatherstationname_position [ dbt ] - 1 ) << 2 weatherstationname_enabled = true } if mcc_position [ dbt ] != 0 { mcc_position_offset = uint32 ( mcc_position [ dbt ] - 1 ) << 2 mcc_enabled = true } if mnc_position [ dbt ] != 0 { mnc_position_offset = uint32 ( mnc_position [ dbt ] - 1 ) << 2 mnc_enabled = true } if mobilebrand_position [ dbt ] != 0 { mobilebrand_position_offset = uint32 ( mobilebrand_position [ dbt ] - 1 ) << 2 mobilebrand_enabled = true } if elevation_position [ dbt ] != 0 { elevation_position_offset = uint32 ( elevation_position [ dbt ] - 1 ) << 2 elevation_enabled = true } if usagetype_position [ dbt ] != 0 { usagetype_position_offset = uint32 ( usagetype_position [ dbt ] - 1 ) << 2 usagetype_enabled = true } metaok = true } 
func loadmessage ( mesg string ) IP2Locationrecord { var x IP2Locationrecord x . Country_short = mesg x . Country_long = mesg x . Region = mesg x . City = mesg x . Isp = mesg x . Domain = mesg x . Zipcode = mesg x . Timezone = mesg x . Netspeed = mesg x . Iddcode = mesg x . Areacode = mesg x . Weatherstationcode = mesg x . Weatherstationname = mesg x . Mcc = mesg x . Mnc = mesg x . Mobilebrand = mesg x . Usagetype = mesg return x } 
func query ( ipaddress string , mode uint32 ) IP2Locationrecord { x := loadmessage ( not_supported ) return x } if iptype == 0 { x = loadmessage ( invalid_address ) return x } var colsize uint32 var baseaddr uint32 var low uint32 var high uint32 var mid uint32 var rowoffset uint32 var rowoffset2 uint32 ipfrom := big . NewInt ( 0 ) ipto := big . NewInt ( 0 ) maxip := big . NewInt ( 0 ) if iptype == 4 { baseaddr = meta . ipv4databaseaddr high = meta . ipv4databasecount maxip = max_ipv4_range colsize = meta . ipv4columnsize } else { baseaddr = meta . ipv6databaseaddr high = meta . ipv6databasecount maxip = max_ipv6_range colsize = meta . ipv6columnsize } high = readuint32 ( ipindex + 4 ) } if ipno . Cmp ( maxip ) >= 0 { ipno = ipno . Sub ( ipno , big . NewInt ( 1 ) ) } for low <= high { mid = ( ( low + high ) >> 1 ) rowoffset = baseaddr + ( mid * colsize ) rowoffset2 = rowoffset + colsize if iptype == 4 { ipfrom = big . NewInt ( int64 ( readuint32 ( rowoffset ) ) ) ipto = big . NewInt ( int64 ( readuint32 ( rowoffset2 ) ) ) } else { ipfrom = readuint128 ( rowoffset ) ipto = readuint128 ( rowoffset2 ) } if ipno . Cmp ( ipfrom ) >= 0 && ipno . Cmp ( ipto ) < 0 { if iptype == 6 { rowoffset = rowoffset + 12 } if mode & countryshort == 1 && country_enabled { x . Country_short = readstr ( readuint32 ( rowoffset + country_position_offset ) ) } if mode & countrylong != 0 && country_enabled { x . Country_long = readstr ( readuint32 ( rowoffset + country_position_offset ) + 3 ) } if mode & region != 0 && region_enabled { x . Region = readstr ( readuint32 ( rowoffset + region_position_offset ) ) } if mode & city != 0 && city_enabled { x . City = readstr ( readuint32 ( rowoffset + city_position_offset ) ) } if mode & isp != 0 && isp_enabled { x . Isp = readstr ( readuint32 ( rowoffset + isp_position_offset ) ) } if mode & latitude != 0 && latitude_enabled { x . Latitude = readfloat ( rowoffset + latitude_position_offset ) } if mode & longitude != 0 && longitude_enabled { x . Longitude = readfloat ( rowoffset + longitude_position_offset ) } if mode & domain != 0 && domain_enabled { x . Domain = readstr ( readuint32 ( rowoffset + domain_position_offset ) ) } if mode & zipcode != 0 && zipcode_enabled { x . Zipcode = readstr ( readuint32 ( rowoffset + zipcode_position_offset ) ) } if mode & timezone != 0 && timezone_enabled { x . Timezone = readstr ( readuint32 ( rowoffset + timezone_position_offset ) ) } if mode & netspeed != 0 && netspeed_enabled { x . Netspeed = readstr ( readuint32 ( rowoffset + netspeed_position_offset ) ) } if mode & iddcode != 0 && iddcode_enabled { x . Iddcode = readstr ( readuint32 ( rowoffset + iddcode_position_offset ) ) } if mode & areacode != 0 && areacode_enabled { x . Areacode = readstr ( readuint32 ( rowoffset + areacode_position_offset ) ) } if mode & weatherstationcode != 0 && weatherstationcode_enabled { x . Weatherstationcode = readstr ( readuint32 ( rowoffset + weatherstationcode_position_offset ) ) } if mode & weatherstationname != 0 && weatherstationname_enabled { x . Weatherstationname = readstr ( readuint32 ( rowoffset + weatherstationname_position_offset ) ) } if mode & mcc != 0 && mcc_enabled { x . Mcc = readstr ( readuint32 ( rowoffset + mcc_position_offset ) ) } if mode & mnc != 0 && mnc_enabled { x . Mnc = readstr ( readuint32 ( rowoffset + mnc_position_offset ) ) } if mode & mobilebrand != 0 && mobilebrand_enabled { x . Mobilebrand = readstr ( readuint32 ( rowoffset + mobilebrand_position_offset ) ) } if mode & elevation != 0 && elevation_enabled { f , _ := strconv . ParseFloat ( readstr ( readuint32 ( rowoffset + elevation_position_offset ) ) , 32 ) x . Elevation = float32 ( f ) } if mode & usagetype != 0 && usagetype_enabled { x . Usagetype = readstr ( readuint32 ( rowoffset + usagetype_position_offset ) ) } return x } else { if ipno . Cmp ( ipfrom ) < 0 { high = mid - 1 } else { low = mid + 1 } } } return x } 
func Printrecord ( x IP2Locationrecord ) { fmt . Printf ( " \n " , x . Country_short ) fmt . Printf ( " \n " , x . Country_long ) fmt . Printf ( " \n " , x . Region ) fmt . Printf ( " \n " , x . City ) fmt . Printf ( " \n " , x . Isp ) fmt . Printf ( " \n " , x . Latitude ) fmt . Printf ( " \n " , x . Longitude ) fmt . Printf ( " \n " , x . Domain ) fmt . Printf ( " \n " , x . Zipcode ) fmt . Printf ( " \n " , x . Timezone ) fmt . Printf ( " \n " , x . Netspeed ) fmt . Printf ( " \n " , x . Iddcode ) fmt . Printf ( " \n " , x . Areacode ) fmt . Printf ( " \n " , x . Weatherstationcode ) fmt . Printf ( " \n " , x . Weatherstationname ) fmt . Printf ( " \n " , x . Mcc ) fmt . Printf ( " \n " , x . Mnc ) fmt . Printf ( " \n " , x . Mobilebrand ) fmt . Printf ( " \n " , x . Elevation ) fmt . Printf ( " \n " , x . Usagetype ) } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { gc . Save ( ) gc . Scale ( 0.5 , 0.5 ) gc . Restore ( ) } 
func Draw ( gc draw2d . GraphicContext ) { gc . SetLineCap ( draw2d . RoundCap ) gc . SetStrokeColor ( color . Black ) gc . MoveTo ( 10.634 , 300.493 ) rCubicCurveTo ( gc , 0.764 , 15.751 , 16.499 , 8.463 , 23.626 , 3.539 ) rCubicCurveTo ( gc , 6.765 , - 4.675 , 8.743 , - 0.789 , 9.337 , - 10.015 ) rCubicCurveTo ( gc , 0.389 , - 6.064 , 1.088 , - 12.128 , 0.744 , - 18.216 ) rCubicCurveTo ( gc , - 10.23 , - 0.927 , - 21.357 , 1.509 , - 29.744 , 7.602 ) gc . CubicCurveTo ( 10.277 , 286.542 , 2.177 , 296.561 , 10.634 , 300.493 ) gc . FillStroke ( ) rCubicCurveTo ( gc , 2.29 , - 0.852 , 4.717 , - 1.457 , 6.271 , - 3.528 ) gc . Stroke ( ) gc . CubicCurveTo ( - 13.3 , 95.897 , 31.536 , 19.189 , 79.956 , 50.74 ) gc . LineTo ( 46.997 , 112.853 ) gc . Close ( ) gc . Stroke ( ) } 
func Rectangle ( path draw2d . PathBuilder , x1 , y1 , x2 , y2 float64 ) { path . MoveTo ( x1 , y1 ) path . LineTo ( x2 , y1 ) path . LineTo ( x2 , y2 ) path . LineTo ( x1 , y2 ) path . Close ( ) } 
func RoundedRectangle ( path draw2d . PathBuilder , x1 , y1 , x2 , y2 , arcWidth , arcHeight float64 ) { arcWidth = arcWidth / 2 arcHeight = arcHeight / 2 path . MoveTo ( x1 , y1 + arcHeight ) path . QuadCurveTo ( x1 , y1 , x1 + arcWidth , y1 ) path . LineTo ( x2 - arcWidth , y1 ) path . QuadCurveTo ( x2 , y1 , x2 , y1 + arcHeight ) path . LineTo ( x2 , y2 - arcHeight ) path . QuadCurveTo ( x2 , y2 , x2 - arcWidth , y2 ) path . LineTo ( x1 + arcWidth , y2 ) path . QuadCurveTo ( x1 , y2 , x1 , y2 - arcHeight ) path . Close ( ) } 
func Ellipse ( path draw2d . PathBuilder , cx , cy , rx , ry float64 ) { path . ArcTo ( cx , cy , rx , ry , 0 , - math . Pi * 2 ) path . Close ( ) } 
func Circle ( path draw2d . PathBuilder , cx , cy , radius float64 ) { path . ArcTo ( cx , cy , radius , radius , 0 , - math . Pi * 2 ) path . Close ( ) } 
func SaveToPdfFile ( filePath string , pdf * gofpdf . Fpdf ) error { return pdf . OutputFileAndClose ( filePath ) } 
func ( p * Path ) MoveTo ( x , y float64 ) { p . appendToPath ( MoveToCmp , x , y ) p . x = x p . y = y } 
func ( p * Path ) CubicCurveTo ( cx1 , cy1 , cx2 , cy2 , x , y float64 ) { if len ( p . Components ) == 0 { } else { p . appendToPath ( CubicCurveToCmp , cx1 , cy1 , cx2 , cy2 , x , y ) } p . x = x p . y = y } 
func ( p * Path ) ArcTo ( cx , cy , rx , ry , startAngle , angle float64 ) { endAngle := startAngle + angle clockWise := true if angle < 0 { clockWise = false } } } else { for startAngle < endAngle { startAngle += math . Pi * 2.0 } } startX := cx + math . Cos ( startAngle ) * rx startY := cy + math . Sin ( startAngle ) * ry if len ( p . Components ) > 0 { p . LineTo ( startX , startY ) } else { p . MoveTo ( startX , startY ) } p . appendToPath ( ArcToCmp , cx , cy , rx , ry , startAngle , angle ) p . x = cx + math . Cos ( endAngle ) * rx p . y = cy + math . Sin ( endAngle ) * ry } 
func ( p * Path ) String ( ) string { s := " " j := 0 for _ , cmd := range p . Components { switch cmd { case MoveToCmp : s += fmt . Sprintf ( " \n " , p . Points [ j ] , p . Points [ j + 1 ] ) j = j + 2 case LineToCmp : s += fmt . Sprintf ( " \n " , p . Points [ j ] , p . Points [ j + 1 ] ) j = j + 2 case QuadCurveToCmp : s += fmt . Sprintf ( " \n " , p . Points [ j ] , p . Points [ j + 1 ] , p . Points [ j + 2 ] , p . Points [ j + 3 ] ) j = j + 4 case CubicCurveToCmp : s += fmt . Sprintf ( " \n " , p . Points [ j ] , p . Points [ j + 1 ] , p . Points [ j + 2 ] , p . Points [ j + 3 ] , p . Points [ j + 4 ] , p . Points [ j + 5 ] ) j = j + 6 case ArcToCmp : s += fmt . Sprintf ( " \n " , p . Points [ j ] , p . Points [ j + 1 ] , p . Points [ j + 2 ] , p . Points [ j + 3 ] , p . Points [ j + 4 ] , p . Points [ j + 5 ] ) j = j + 6 case CloseCmp : s += " \n " } } return s } 
func ( path * Path ) VerticalFlip ( ) * Path { p := path . Copy ( ) j := 0 for _ , cmd := range p . Components { switch cmd { case MoveToCmp , LineToCmp : p . Points [ j + 1 ] = - p . Points [ j + 1 ] j = j + 2 case QuadCurveToCmp : p . Points [ j + 1 ] = - p . Points [ j + 1 ] p . Points [ j + 3 ] = - p . Points [ j + 3 ] j = j + 4 case CubicCurveToCmp : p . Points [ j + 1 ] = - p . Points [ j + 1 ] p . Points [ j + 3 ] = - p . Points [ j + 3 ] p . Points [ j + 5 ] = - p . Points [ j + 5 ] j = j + 6 case ArcToCmp : p . Points [ j + 1 ] = - p . Points [ j + 1 ] p . Points [ j + 3 ] = - p . Points [ j + 3 ] p . Points [ j + 4 ] = - p . Points [ j + 4 ] p . Points [ j + 5 ] = - p . Points [ j + 5 ] j = j + 6 case CloseCmp : } } p . y = - p . y return p } 
func NewGlyphCache ( ) * GlyphCacheImp { glyphs := make ( map [ string ] map [ rune ] * Glyph ) return & GlyphCacheImp { glyphs : glyphs , } } 
func ( glyphCache * GlyphCacheImp ) Fetch ( gc draw2d . GraphicContext , fontName string , chr rune ) * Glyph { if glyphCache . glyphs [ fontName ] == nil { glyphCache . glyphs [ fontName ] = make ( map [ rune ] * Glyph , 60 ) } if glyphCache . glyphs [ fontName ] [ chr ] == nil { glyphCache . glyphs [ fontName ] [ chr ] = renderGlyph ( gc , fontName , chr ) } return glyphCache . glyphs [ fontName ] [ chr ] . Copy ( ) } 
func renderGlyph ( gc draw2d . GraphicContext , fontName string , chr rune ) * Glyph { gc . Save ( ) defer gc . Restore ( ) gc . BeginPath ( ) width := gc . CreateStringPath ( string ( chr ) , 0 , 0 ) path := gc . GetPath ( ) return & Glyph { Path : & path , Width : width , } } 
func ( g * Glyph ) Copy ( ) * Glyph { return & Glyph { Path : g . Path . Copy ( ) , Width : g . Width , } } 
func ( g * Glyph ) Fill ( gc draw2d . GraphicContext , x , y float64 ) float64 { gc . Save ( ) gc . BeginPath ( ) gc . Translate ( x , y ) gc . Fill ( g . Path ) gc . Restore ( ) return g . Width } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { gc . SetFillRule ( draw2d . FillRuleWinding ) gc . Clear ( ) } gc . ClearRect ( 100 , 75 , 197 , 135 ) draw2dkit . Ellipse ( gc , 148.5 , 105 , 35 , 25 ) gc . SetFillColor ( color . RGBA { 0xff , 0xff , 0x44 , 0xff } ) gc . FillStroke ( ) } 
func Draw ( gc draw2d . GraphicContext , x0 , y0 , x1 , y1 float64 ) { gc . LineTo ( x1 , y1 ) gc . Stroke ( ) } 
func optiSprintf ( format string , a ... interface { } ) string { chunks := strings . Split ( format , " " ) newChunks := make ( [ ] string , len ( chunks ) ) for i , chunk := range chunks { if i != 0 { verb := chunk [ 0 ] if verb == 'f' || verb == 'F' { num := a [ i - 1 ] . ( float64 ) p := strconv . Itoa ( getPrec ( num , verb == 'F' ) ) chunk = strings . Replace ( chunk , string ( verb ) , " " + p + " " , 1 ) } } newChunks [ i ] = chunk } format = strings . Join ( newChunks , " " ) return fmt . Sprintf ( format , a ... ) } 
func getPrec ( num float64 , better bool ) int { max := 3 eps := 0.0005 if better { max = 6 eps = 0.0000005 } prec := 0 for math . Mod ( num , 1 ) > eps { num *= 10 eps *= 10 prec ++ } if max < prec { return max } return prec } 
func ( p * Painter ) Paint ( ss [ ] raster . Span , done bool ) { clenrequired := sslen * 8 vlenrequired := sslen * 4 if clenrequired >= ( cap ( p . colors ) - len ( p . colors ) ) { p . Flush ( ) if clenrequired >= cap ( p . colors ) { p . vertices = make ( [ ] int32 , 0 , vlenrequired + ( vlenrequired / 2 ) ) p . colors = make ( [ ] uint8 , 0 , clenrequired + ( clenrequired / 2 ) ) } } vi := len ( p . vertices ) ci := len ( p . colors ) p . vertices = p . vertices [ 0 : vi + vlenrequired ] p . colors = p . colors [ 0 : ci + clenrequired ] var ( colors [ ] uint8 vertices [ ] int32 ) for _ , s := range ss { a := uint8 ( ( s . Alpha * p . ca / M16 ) >> 8 ) colors = p . colors [ ci : ] colors [ 0 ] = p . cr colors [ 1 ] = p . cg colors [ 2 ] = p . cb colors [ 3 ] = a colors [ 4 ] = p . cr colors [ 5 ] = p . cg colors [ 6 ] = p . cb colors [ 7 ] = a ci += 8 vertices = p . vertices [ vi : ] vertices [ 0 ] = int32 ( s . X0 ) vertices [ 1 ] = int32 ( s . Y ) vertices [ 2 ] = int32 ( s . X1 ) vertices [ 3 ] = int32 ( s . Y ) vi += 4 } } 
func ( p * Painter ) SetColor ( c color . Color ) { r , g , b , a := c . RGBA ( ) if a == 0 { p . cr = 0 p . cg = 0 p . cb = 0 p . ca = a } else { p . cr = uint8 ( ( r * M16 / a ) >> 8 ) p . cg = uint8 ( ( g * M16 / a ) >> 8 ) p . cb = uint8 ( ( b * M16 / a ) >> 8 ) p . ca = a } } 
func NewPainter ( ) * Painter { p := new ( Painter ) p . vertices = make ( [ ] int32 , 0 , 1024 ) p . colors = make ( [ ] uint8 , 0 , 1024 ) return p } 
func NewGraphicContext ( width , height int ) * GraphicContext { gc := & GraphicContext { draw2dbase . NewStackGraphicContext ( ) , NewPainter ( ) , raster . NewRasterizer ( width , height ) , raster . NewRasterizer ( width , height ) , draw2d . GetGlobalFontCache ( ) , draw2dbase . NewGlyphCache ( ) , & truetype . GlyphBuf { } , 92 , } return gc } 
func ( gc * GraphicContext ) FillString ( text string ) ( width float64 ) { return gc . FillStringAt ( text , 0 , 0 ) } 
func ( gc * GraphicContext ) FillStringAt ( text string , x , y float64 ) ( width float64 ) { f , err := gc . loadCurrentFont ( ) if err != nil { log . Println ( err ) return 0.0 } startx := x prev , hasPrev := truetype . Index ( 0 ) , false fontName := gc . GetFontName ( ) for _ , r := range text { index := f . Index ( r ) if hasPrev { x += fUnitsToFloat64 ( f . Kern ( fixed . Int26_6 ( gc . Current . Scale ) , prev , index ) ) } glyph := gc . glyphCache . Fetch ( gc , fontName , r ) x += glyph . Fill ( gc , x , y ) prev , hasPrev = index , true } return x - startx } 
func ( gc * GraphicContext ) GetStringBounds ( s string ) ( left , top , right , bottom float64 ) { f , err := gc . loadCurrentFont ( ) if err != nil { log . Println ( err ) return 0 , 0 , 0 , 0 } top , left , bottom , right = 10e6 , 10e6 , - 10e6 , - 10e6 cursor := 0.0 prev , hasPrev := truetype . Index ( 0 ) , false for _ , rune := range s { index := f . Index ( rune ) if hasPrev { cursor += fUnitsToFloat64 ( f . Kern ( fixed . Int26_6 ( gc . Current . Scale ) , prev , index ) ) } if err := gc . glyphBuf . Load ( gc . Current . Font , fixed . Int26_6 ( gc . Current . Scale ) , index , font . HintingNone ) ; err != nil { log . Println ( err ) return 0 , 0 , 0 , 0 } e0 := 0 for _ , e1 := range gc . glyphBuf . Ends { ps := gc . glyphBuf . Points [ e0 : e1 ] for _ , p := range ps { x , y := pointToF64Point ( p ) top = math . Min ( top , y ) bottom = math . Max ( bottom , y ) left = math . Min ( left , x + cursor ) right = math . Max ( right , x + cursor ) } } cursor += fUnitsToFloat64 ( f . HMetric ( fixed . Int26_6 ( gc . Current . Scale ) , index ) . AdvanceWidth ) prev , hasPrev = index , true } return left , top , right , bottom } 
func ( gc * GraphicContext ) StrokeString ( text string ) ( width float64 ) { return gc . StrokeStringAt ( text , 0 , 0 ) } 
func ( gc * GraphicContext ) recalc ( ) { gc . Current . Scale = gc . Current . FontSize * float64 ( gc . DPI ) * ( 64.0 / 72.0 ) } 
func ( gc * GraphicContext ) SetFont ( font * truetype . Font ) { gc . Current . Font = font } 
func ( gc * GraphicContext ) SetFontSize ( fontSize float64 ) { gc . Current . FontSize = fontSize gc . recalc ( ) } 
func ( gc * GraphicContext ) Stroke ( paths ... * draw2d . Path ) { gc . drawPaths ( stroked , paths ... ) gc . Current . Path . Clear ( ) } 
func ( gc * GraphicContext ) Fill ( paths ... * draw2d . Path ) { gc . drawPaths ( filled , paths ... ) gc . Current . Path . Clear ( ) } 
func ( gc * GraphicContext ) FillStroke ( paths ... * draw2d . Path ) { gc . drawPaths ( filled | stroked , paths ... ) gc . Current . Path . Clear ( ) } 
func ( gc * GraphicContext ) FillString ( text string ) ( cursor float64 ) { return gc . FillStringAt ( text , 0 , 0 ) } 
func ( gc * GraphicContext ) FillStringAt ( text string , x , y float64 ) ( cursor float64 ) { return gc . drawString ( text , filled , x , y ) } 
func ( gc * GraphicContext ) StrokeString ( text string ) ( cursor float64 ) { return gc . StrokeStringAt ( text , 0 , 0 ) } 
func ( gc * GraphicContext ) StrokeStringAt ( text string , x , y float64 ) ( cursor float64 ) { return gc . drawString ( text , stroked , x , y ) } 
func ( gc * GraphicContext ) DrawImage ( image image . Image ) { bounds := image . Bounds ( ) svgImage := & Image { Href : imageToSvgHref ( image ) } svgImage . X = float64 ( bounds . Min . X ) svgImage . Y = float64 ( bounds . Min . Y ) svgImage . Width = toSvgLength ( float64 ( bounds . Max . X - bounds . Min . X ) ) svgImage . Height = toSvgLength ( float64 ( bounds . Max . Y - bounds . Min . Y ) ) gc . newGroup ( 0 ) . Image = svgImage } 
func ( gc * GraphicContext ) ClearRect ( x1 , y1 , x2 , y2 int ) { mask := gc . newMask ( x1 , y1 , x2 - x1 , y2 - y1 ) newGroup := & Group { Groups : gc . svg . Groups , Mask : " " + mask . Id + " " , } } 
func ( gc * GraphicContext ) CreateStringPath ( s string , x , y float64 ) ( cursor float64 ) { f , err := gc . loadCurrentFont ( ) if err != nil { log . Println ( err ) return 0.0 } startx := x prev , hasPrev := truetype . Index ( 0 ) , false for _ , rune := range s { index := f . Index ( rune ) if hasPrev { x += fUnitsToFloat64 ( f . Kern ( fixed . Int26_6 ( gc . Current . Scale ) , prev , index ) ) } err := gc . drawGlyph ( index , x , y ) if err != nil { log . Println ( err ) return startx - x } x += fUnitsToFloat64 ( f . HMetric ( fixed . Int26_6 ( gc . Current . Scale ) , index ) . AdvanceWidth ) prev , hasPrev = index , true } return x - startx } 
func ( gc * GraphicContext ) drawPaths ( drawType drawType , paths ... * draw2d . Path ) { group := gc . newGroup ( drawType ) svgPathsDesc := make ( [ ] string , len ( paths ) ) } svgPath . Desc = strings . Join ( svgPathsDesc , " " ) } 
func ( gc * GraphicContext ) drawString ( text string , drawType drawType , x , y float64 ) float64 { switch gc . svg . FontMode { case PathFontMode : w := gc . CreateStringPath ( text , x , y ) gc . drawPaths ( drawType ) gc . Current . Path . Clear ( ) return w case SvgFontMode : gc . embedSvgFont ( text ) } group := gc . newGroup ( drawType ) svgText . FontSize = gc . Current . FontSize svgText . X = x svgText . Y = y svgText . FontFamily = gc . Current . FontData . Name left , _ , right , _ := gc . GetStringBounds ( text ) return right - left } 
func ( gc * GraphicContext ) newGroup ( drawType drawType ) * Group { group := Group { } group . StrokeWidth = toSvgLength ( gc . Current . LineWidth ) group . StrokeLinecap = gc . Current . Cap . String ( ) group . StrokeLinejoin = gc . Current . Join . String ( ) if len ( gc . Current . Dash ) > 0 { group . StrokeDasharray = toSvgArray ( gc . Current . Dash ) group . StrokeDashoffset = toSvgLength ( gc . Current . DashOffset ) } } if drawType & filled == filled { group . Fill = toSvgRGBA ( gc . Current . FillColor ) group . FillRule = toSvgFillRule ( gc . Current . FillRule ) } group . Transform = toSvgTransform ( gc . Current . Tr ) return & group } 
func ( gc * GraphicContext ) newMask ( x , y , width , height int ) * Mask { mask := & Mask { } mask . X = float64 ( x ) mask . Y = float64 ( y ) mask . Width = toSvgLength ( float64 ( width ) ) mask . Height = toSvgLength ( float64 ( height ) ) mask . Id = " " + strconv . Itoa ( len ( gc . svg . Masks ) ) return mask } 
func ( gc * GraphicContext ) embedSvgFont ( text string ) * Font { fontName := gc . Current . FontData . Name gc . loadCurrentFont ( ) for _ , font := range gc . svg . Fonts { if font . Name == fontName { svgFont = font break } } if svgFont == nil { } defer gc . Restore ( ) gc . SetFontSize ( 2048 ) defer gc . SetDPI ( gc . GetDPI ( ) ) gc . SetDPI ( 92 ) filling : for _ , rune := range text { for _ , g := range svgFont . Glyphs { if g . Rune == Rune ( rune ) { continue filling } } glyph := gc . glyphCache . Fetch ( gc , gc . GetFontName ( ) , rune ) svgFont . Glyphs = append ( svgFont . Glyphs , & Glyph { Rune : Rune ( rune ) , Desc : toSvgPathDesc ( glypPath ) , HorizAdvX : glyph . Width , } ) } svgFont . Name = fontName return svgFont } 
func TraceQuad ( t Liner , quad [ ] float64 , flatteningThreshold float64 ) error { if len ( quad ) < 6 { return errors . New ( " " ) } copy ( curves [ 0 : 6 ] , quad [ 0 : 6 ] ) i := 0 var dx , dy , d float64 for i >= 0 { c = curves [ i : ] dx = c [ 4 ] - c [ 0 ] dy = c [ 5 ] - c [ 1 ] d = math . Abs ( ( ( c [ 2 ] - c [ 4 ] ) * dy - ( c [ 3 ] - c [ 5 ] ) * dx ) ) i -= 6 } else { i += 6 } } return nil } 
func ( cs * ContextStack ) GetFontName ( ) string { fontData := cs . FontData return fmt . Sprintf ( " " , fontData . Name , fontData . Family , fontData . Style , cs . FontSize ) } 
func NewStackGraphicContext ( ) * StackGraphicContext { gc := & StackGraphicContext { } gc . Current = new ( ContextStack ) gc . Current . Tr = draw2d . NewIdentityMatrix ( ) gc . Current . Path = new ( draw2d . Path ) gc . Current . LineWidth = 1.0 gc . Current . StrokeColor = image . Black gc . Current . FillColor = image . White gc . Current . Cap = draw2d . RoundCap gc . Current . FillRule = draw2d . FillRuleEvenOdd gc . Current . Join = draw2d . RoundJoin gc . Current . FontSize = 10 gc . Current . FontData = DefaultFontData return gc } 
func NewFolderFontCache ( folder string ) * FolderFontCache { return & FolderFontCache { fonts : make ( map [ string ] * truetype . Font ) , folder : folder , namer : FontFileName , } } 
func ( cache * FolderFontCache ) Load ( fontData FontData ) ( font * truetype . Font , err error ) { if font = cache . fonts [ cache . namer ( fontData ) ] ; font != nil { return font , nil } var data [ ] byte var file = cache . namer ( fontData ) if data , err = ioutil . ReadFile ( filepath . Join ( cache . folder , file ) ) ; err != nil { return } if font , err = truetype . Parse ( data ) ; err != nil { return } cache . fonts [ file ] = font return } 
func ( cache * FolderFontCache ) Store ( fontData FontData , font * truetype . Font ) { cache . fonts [ cache . namer ( fontData ) ] = font } 
func NewSyncFolderFontCache ( folder string ) * SyncFolderFontCache { return & SyncFolderFontCache { fonts : make ( map [ string ] * truetype . Font ) , folder : folder , namer : FontFileName , } } 
func ( cache * SyncFolderFontCache ) Load ( fontData FontData ) ( font * truetype . Font , err error ) { cache . RLock ( ) font = cache . fonts [ cache . namer ( fontData ) ] cache . RUnlock ( ) if font != nil { return font , nil } var data [ ] byte var file = cache . namer ( fontData ) if data , err = ioutil . ReadFile ( filepath . Join ( cache . folder , file ) ) ; err != nil { return } if font , err = truetype . Parse ( data ) ; err != nil { return } cache . Lock ( ) cache . fonts [ file ] = font cache . Unlock ( ) return } 
func ( cache * SyncFolderFontCache ) Store ( fontData FontData , font * truetype . Font ) { cache . Lock ( ) cache . fonts [ cache . namer ( fontData ) ] = font cache . Unlock ( ) } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { gc . SetStrokeColor ( image . Black ) gc . SetFillColor ( image . White ) gc . Save ( ) gc . Rotate ( - 30 * ( math . Pi / 180.0 ) ) Draw ( gc , 48 , 48 , 240 , 72 ) gc . Restore ( ) } 
func Draw ( gc draw2d . GraphicContext , x , y , w , h float64 ) { h23 := ( h * 2 ) / 3 blf := color . RGBA { 0 , 0 , 0 , 0xff } wf := color . RGBA { 0xff , 0xff , 0xff , 0xff } nf := color . RGBA { 0x8B , 0x45 , 0x13 , 0xff } brf := color . RGBA { 0x8B , 0x45 , 0x13 , 0x99 } brb := color . RGBA { 0x8B , 0x45 , 0x13 , 0xBB } gc . CubicCurveTo ( x + w / 4 , y - h / 3 , x + 3 * w / 4 , y - h / 3 , x + w , y + h * 1.002 ) gc . Close ( ) gc . SetFillColor ( brb ) gc . Fill ( ) gc . Fill ( ) gc . SetFillColor ( brf ) gc . Fill ( ) gc . SetFillColor ( nf ) gc . Fill ( ) gc . SetFillColor ( brf ) gc . Fill ( ) gc . SetFillColor ( nf ) gc . Fill ( ) gc . SetFillColor ( wf ) gc . Fill ( ) gc . SetFillColor ( blf ) gc . Fill ( ) gc . SetFillColor ( wf ) gc . Fill ( ) gc . Fill ( ) gc . SetFillColor ( blf ) gc . Fill ( ) gc . SetFillColor ( wf ) gc . Fill ( ) draw2dkit . RoundedRectangle ( gc , x + w / 2 - w / 8 , y + h + h / 2.5 , x + w / 2 - w / 8 + w / 8 , y + h + h / 2.5 + w / 6 , w / 10 , w / 10 ) gc . Fill ( ) gc . Fill ( ) gc . SetFillColor ( nf ) gc . Fill ( ) gc . SetFillColor ( blf ) gc . Fill ( ) } 
func NewPdf ( orientationStr , unitStr , sizeStr string ) * gofpdf . Fpdf { pdf := gofpdf . New ( orientationStr , unitStr , sizeStr , draw2d . GetFontFolder ( ) ) pdf . SetDrawColor ( 0 , 0 , 0 ) pdf . SetFillColor ( 255 , 255 , 255 ) pdf . SetLineCapStyle ( " " ) pdf . SetLineJoinStyle ( " " ) pdf . SetLineWidth ( 1 ) pdf . AddPage ( ) return pdf } 
func rgb ( c color . Color ) ( int , int , int ) { r , g , b , _ := c . RGBA ( ) return int ( float64 ( r ) * c255 ) , int ( float64 ( g ) * c255 ) , int ( float64 ( b ) * c255 ) } 
func clearRect ( gc * GraphicContext , x1 , y1 , x2 , y2 float64 ) { x , y := gc . pdf . GetXY ( ) draw2dkit . Rectangle ( gc , x1 , y1 , x2 , y2 ) gc . Fill ( ) gc . pdf . MoveTo ( x , y ) } 
func NewGraphicContext ( pdf * gofpdf . Fpdf ) * GraphicContext { gc := & GraphicContext { draw2dbase . NewStackGraphicContext ( ) , pdf , DPI } gc . SetDPI ( DPI ) return gc } 
func ( gc * GraphicContext ) DrawImage ( image image . Image ) { name := strconv . Itoa ( int ( imageCount ) ) imageCount ++ tp := " " b := & bytes . Buffer { } png . Encode ( b , image ) gc . pdf . RegisterImageReader ( name , tp , b ) bounds := image . Bounds ( ) x0 , y0 := float64 ( bounds . Min . X ) , float64 ( bounds . Min . Y ) w , h := float64 ( bounds . Dx ( ) ) , float64 ( bounds . Dy ( ) ) gc . pdf . Image ( name , x0 , y0 , w , h , false , tp , 0 , " " ) } 
func ( gc * GraphicContext ) Clear ( ) { width , height := gc . pdf . GetPageSize ( ) clearRect ( gc , 0 , 0 , width , height ) } 
func ( gc * GraphicContext ) ClearRect ( x1 , y1 , x2 , y2 int ) { clearRect ( gc , float64 ( x1 ) , float64 ( y1 ) , float64 ( x2 ) , float64 ( y2 ) ) } 
func ( gc * GraphicContext ) GetStringBounds ( s string ) ( left , top , right , bottom float64 ) { _ , h := gc . pdf . GetFontSize ( ) d := gc . pdf . GetFontDesc ( " " , " " ) if d . Ascent == 0 { } else { top = - float64 ( d . Ascent ) * h / float64 ( d . Ascent - d . Descent ) } return 0 , top , gc . pdf . GetStringWidth ( s ) , top + h } 
func ( gc * GraphicContext ) CreateStringPath ( text string , x , y float64 ) ( cursor float64 ) { w := right - left h := bottom - top gc . pdf . MoveTo ( x - left - margin , y + top ) gc . pdf . CellFormat ( w , h , text , " " , 0 , " " , false , 0 , " " ) return w } 
func ( gc * GraphicContext ) FillStringAt ( text string , x , y float64 ) ( cursor float64 ) { return gc . CreateStringPath ( text , x , y ) } 
func ( gc * GraphicContext ) Stroke ( paths ... * draw2d . Path ) { _ , _ , _ , alphaS := gc . Current . StrokeColor . RGBA ( ) gc . draw ( " " , alphaS , paths ... ) gc . Current . Path . Clear ( ) } 
func ( gc * GraphicContext ) Fill ( paths ... * draw2d . Path ) { style := " " if gc . Current . FillRule != draw2d . FillRuleWinding { style += " " } _ , _ , _ , alphaF := gc . Current . FillColor . RGBA ( ) gc . draw ( style , alphaF , paths ... ) gc . Current . Path . Clear ( ) } 
func ( gc * GraphicContext ) FillStroke ( paths ... * draw2d . Path ) { var rule string if gc . Current . FillRule != draw2d . FillRuleWinding { rule = " " } _ , _ , _ , alphaS := gc . Current . StrokeColor . RGBA ( ) _ , _ , _ , alphaF := gc . Current . FillColor . RGBA ( ) if alphaS == alphaF { gc . draw ( " " + rule , alphaF , paths ... ) } else { gc . draw ( " " + rule , alphaF , paths ... ) gc . draw ( " " , alphaS , paths ... ) } gc . Current . Path . Clear ( ) } 
func ( gc * GraphicContext ) draw ( style string , alpha uint32 , paths ... * draw2d . Path ) { paths = append ( paths , gc . Current . Path ) for _ , p := range paths { ConvertPath ( p , gc . pdf ) } a := float64 ( alpha ) / alphaMax current , blendMode := gc . pdf . GetAlpha ( ) if a != current { gc . pdf . SetAlpha ( a , blendMode ) } gc . pdf . DrawPath ( style ) } 
func ( gc * GraphicContext ) SetStrokeColor ( c color . Color ) { gc . StackGraphicContext . SetStrokeColor ( c ) gc . pdf . SetDrawColor ( rgb ( c ) ) } 
func ( gc * GraphicContext ) SetFillColor ( c color . Color ) { gc . StackGraphicContext . SetFillColor ( c ) gc . pdf . SetFillColor ( rgb ( c ) ) gc . pdf . SetTextColor ( rgb ( c ) ) } 
func ( gc * GraphicContext ) SetFontData ( fontData draw2d . FontData ) { var style string if fontData . Style & draw2d . FontStyleBold != 0 { style += " " } if fontData . Style & draw2d . FontStyleItalic != 0 { style += " " } fn := draw2d . FontFileName ( fontData ) fn = fn [ : len ( fn ) - 4 ] size , _ := gc . pdf . GetFontSize ( ) gc . pdf . AddFont ( fontData . Name , style , fn + " " ) gc . pdf . SetFont ( fontData . Name , style , size ) } 
func ( gc * GraphicContext ) SetFontSize ( fontSize float64 ) { gc . StackGraphicContext . SetFontSize ( fontSize ) gc . recalc ( ) gc . pdf . SetFontSize ( fontSize * gc . Current . Scale ) } 
func ( gc * GraphicContext ) SetLineDash ( Dash [ ] float64 , DashOffset float64 ) { gc . StackGraphicContext . SetLineDash ( Dash , DashOffset ) gc . pdf . SetDashPattern ( Dash , DashOffset ) } 
func ( gc * GraphicContext ) SetLineWidth ( LineWidth float64 ) { gc . StackGraphicContext . SetLineWidth ( LineWidth ) gc . pdf . SetLineWidth ( LineWidth ) } 
func ( gc * GraphicContext ) SetLineCap ( Cap draw2d . LineCap ) { gc . StackGraphicContext . SetLineCap ( Cap ) gc . pdf . SetLineCapStyle ( caps [ Cap ] ) } 
func ( gc * GraphicContext ) SetLineJoin ( Join draw2d . LineJoin ) { gc . StackGraphicContext . SetLineJoin ( Join ) gc . pdf . SetLineJoinStyle ( joins [ Join ] ) } 
func ( gc * GraphicContext ) Scale ( sx , sy float64 ) { gc . StackGraphicContext . Scale ( sx , sy ) gc . pdf . TransformScale ( sx * 100 , sy * 100 , 0 , 0 ) } 
func ( gc * GraphicContext ) Rotate ( angle float64 ) { gc . StackGraphicContext . Rotate ( angle ) gc . pdf . TransformRotate ( - angle * 180 / math . Pi , 0 , 0 ) } 
func ( gc * GraphicContext ) Translate ( tx , ty float64 ) { gc . StackGraphicContext . Translate ( tx , ty ) gc . pdf . TransformTranslate ( tx , ty ) } 
func ( gc * GraphicContext ) Restore ( ) { gc . pdf . TransformEnd ( ) gc . StackGraphicContext . Restore ( ) c := gc . Current gc . SetFontSize ( c . FontSize ) gc . SetStrokeColor ( c . StrokeColor ) gc . SetFillColor ( c . FillColor ) gc . SetFillRule ( c . FillRule ) gc . SetLineJoin ( c . Join ) // c.Path unsupported // c.Font unsupported } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { } 
func Draw ( gc draw2d . GraphicContext , text string ) { gc . FillStroke ( ) gc . SetFontSize ( 14 ) } 
func SaveToPngFile ( filePath string , m image . Image ) error { if err != nil { return err } defer f . Close ( ) if err != nil { return err } err = b . Flush ( ) if err != nil { return err } return nil } 
func LoadFromPngFile ( filePath string ) ( image . Image , error ) { if err != nil { return nil , err } defer f . Close ( ) b := bufio . NewReader ( f ) img , err := png . Decode ( b ) if err != nil { return nil , err } return img , nil } 
func Resource ( folder , filename , ext string ) string { var root string if ext == " " || ext == " " { root = " " } return fmt . Sprintf ( " " , root , folder , filename ) } 
func Output ( name , ext string ) string { var root string if ext == " " || ext == " " { root = " " } return fmt . Sprintf ( " " , root , name , ext ) } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { gc . Save ( ) gc . Scale ( 0.35 , - 0.35 ) gc . Translate ( 70 , - 200 ) gc . Restore ( ) } 
func Draw ( gc draw2d . GraphicContext , filename string ) { if err != nil { panic ( err ) } defer src . Close ( ) bytes , err := ioutil . ReadAll ( src ) reader := strings . NewReader ( string ( bytes ) ) interpreter . Execute ( reader ) } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { } 
func Bubble ( gc draw2d . GraphicContext , x , y , width , height float64 ) { sx , sy := width / 100 , height / 100 gc . MoveTo ( x + sx * 50 , y ) gc . QuadCurveTo ( x , y , x , y + sy * 37.5 ) gc . QuadCurveTo ( x , y + sy * 75 , x + sx * 25 , y + sy * 75 ) gc . QuadCurveTo ( x + sx * 25 , y + sy * 95 , x + sx * 5 , y + sy * 100 ) gc . QuadCurveTo ( x + sx * 35 , y + sy * 95 , x + sx * 40 , y + sy * 75 ) gc . QuadCurveTo ( x + sx * 100 , y + sy * 75 , x + sx * 100 , y + sy * 37.5 ) gc . QuadCurveTo ( x + sx * 100 , y , x + sx * 50 , y ) gc . Stroke ( ) } 
func CurveRectangle ( gc draw2d . GraphicContext , x0 , y0 , rectWidth , rectHeight float64 , stroke , fill color . Color ) { radius := ( rectWidth + rectHeight ) / 4 x1 := x0 + rectWidth y1 := y0 + rectHeight if rectWidth / 2 < radius { if rectHeight / 2 < radius { gc . MoveTo ( x0 , ( y0 + y1 ) / 2 ) gc . CubicCurveTo ( x0 , y0 , x0 , y0 , ( x0 + x1 ) / 2 , y0 ) gc . CubicCurveTo ( x1 , y0 , x1 , y0 , x1 , ( y0 + y1 ) / 2 ) gc . CubicCurveTo ( x1 , y1 , x1 , y1 , ( x1 + x0 ) / 2 , y1 ) gc . CubicCurveTo ( x0 , y1 , x0 , y1 , x0 , ( y0 + y1 ) / 2 ) } else { gc . MoveTo ( x0 , y0 + radius ) gc . CubicCurveTo ( x0 , y0 , x0 , y0 , ( x0 + x1 ) / 2 , y0 ) gc . CubicCurveTo ( x1 , y0 , x1 , y0 , x1 , y0 + radius ) gc . LineTo ( x1 , y1 - radius ) gc . CubicCurveTo ( x1 , y1 , x1 , y1 , ( x1 + x0 ) / 2 , y1 ) gc . CubicCurveTo ( x0 , y1 , x0 , y1 , x0 , y1 - radius ) } } else { if rectHeight / 2 < radius { gc . MoveTo ( x0 , ( y0 + y1 ) / 2 ) gc . CubicCurveTo ( x0 , y0 , x0 , y0 , x0 + radius , y0 ) gc . LineTo ( x1 - radius , y0 ) gc . CubicCurveTo ( x1 , y0 , x1 , y0 , x1 , ( y0 + y1 ) / 2 ) gc . CubicCurveTo ( x1 , y1 , x1 , y1 , x1 - radius , y1 ) gc . LineTo ( x0 + radius , y1 ) gc . CubicCurveTo ( x0 , y1 , x0 , y1 , x0 , ( y0 + y1 ) / 2 ) } else { gc . MoveTo ( x0 , y0 + radius ) gc . CubicCurveTo ( x0 , y0 , x0 , y0 , x0 + radius , y0 ) gc . LineTo ( x1 - radius , y0 ) gc . CubicCurveTo ( x1 , y0 , x1 , y0 , x1 , y0 + radius ) gc . LineTo ( x1 , y1 - radius ) gc . CubicCurveTo ( x1 , y1 , x1 , y1 , x1 - radius , y1 ) gc . LineTo ( x0 + radius , y1 ) gc . CubicCurveTo ( x0 , y1 , x0 , y1 , x0 , y1 - radius ) } } gc . Close ( ) gc . SetStrokeColor ( stroke ) gc . SetFillColor ( fill ) gc . SetLineWidth ( 10.0 ) gc . FillStroke ( ) } 
func Dash ( gc draw2d . GraphicContext , x , y , width , height float64 ) { sx , sy := width / 162 , height / 205 gc . SetStrokeColor ( image . Black ) gc . SetLineDash ( [ ] float64 { height / 10 , height / 50 , height / 50 , height / 50 } , - 50.0 ) gc . SetLineCap ( draw2d . ButtCap ) gc . SetLineJoin ( draw2d . RoundJoin ) gc . SetLineWidth ( height / 50 ) gc . MoveTo ( x + sx * 60.0 , y ) gc . LineTo ( x + sx * 60.0 , y ) gc . LineTo ( x + sx * 162 , y + sy * 205 ) rLineTo ( gc , sx * - 102.4 , 0 ) gc . CubicCurveTo ( x + sx * - 17 , y + sy * 205 , x + sx * - 17 , y + sy * 103 , x + sx * 60.0 , y + sy * 103.0 ) gc . Stroke ( ) gc . SetLineDash ( nil , 0.0 ) } 
func Arc ( gc draw2d . GraphicContext , xc , yc , width , height float64 ) { yc += height / 2 radiusX , radiusY := width / 2 , height / 2 startAngle := 45 * ( math . Pi / 180.0 ) angle := 135 * ( math . Pi / 180.0 ) gc . SetLineWidth ( width / 10 ) gc . SetLineCap ( draw2d . ButtCap ) gc . SetStrokeColor ( image . Black ) gc . MoveTo ( xc + math . Cos ( startAngle ) * radiusX , yc + math . Sin ( startAngle ) * radiusY ) gc . ArcTo ( xc , yc , radiusX , radiusY , startAngle , angle ) gc . Stroke ( ) gc . SetFillColor ( color . NRGBA { 255 , 0x33 , 0x33 , 0x80 } ) gc . SetLineWidth ( width / 20 ) gc . MoveTo ( xc + math . Cos ( startAngle ) * radiusX , yc + math . Sin ( startAngle ) * radiusY ) gc . LineTo ( xc , yc ) gc . LineTo ( xc - radiusX , yc ) gc . Stroke ( ) gc . MoveTo ( xc , yc ) gc . ArcTo ( xc , yc , width / 10.0 , height / 10.0 , 0 , 2 * math . Pi ) gc . Fill ( ) } 
func CubicCurve ( gc draw2d . GraphicContext , x , y , width , height float64 ) { sx , sy := width / 162 , height / 205 x0 , y0 := x , y + sy * 100.0 x1 , y1 := x + sx * 75 , y + sy * 205 x2 , y2 := x + sx * 125 , y x3 , y3 := x + sx * 205 , y + sy * 100 gc . SetStrokeColor ( image . Black ) gc . SetFillColor ( color . NRGBA { 0xAA , 0xAA , 0xAA , 0xFF } ) gc . SetLineWidth ( width / 10 ) gc . MoveTo ( x0 , y0 ) gc . CubicCurveTo ( x1 , y1 , x2 , y2 , x3 , y3 ) gc . Stroke ( ) gc . SetStrokeColor ( color . NRGBA { 0xFF , 0x33 , 0x33 , 0x88 } ) gc . SetLineWidth ( width / 20 ) gc . LineTo ( x1 , y1 ) gc . LineTo ( x2 , y2 ) gc . LineTo ( x3 , y3 ) gc . Stroke ( ) } 
func FillString ( gc draw2d . GraphicContext , x , y , width , height float64 ) { sx , sy := width / 100 , height / 100 gc . Save ( ) gc . SetStrokeColor ( image . Black ) gc . SetLineWidth ( 1 ) draw2dkit . RoundedRectangle ( gc , x + sx * 5 , y + sy * 5 , x + sx * 95 , y + sy * 95 , sx * 10 , sy * 10 ) gc . FillStroke ( ) gc . SetFillColor ( image . Black ) gc . SetFontSize ( height / 6 ) gc . Translate ( x + sx * 6 , y + sy * 52 ) gc . SetFontData ( draw2d . FontData { Name : " " , Family : draw2d . FontFamilyMono , Style : draw2d . FontStyleBold | draw2d . FontStyleItalic , } ) w := gc . FillString ( " " ) gc . Translate ( w + sx , 0 ) left , top , right , bottom := gc . GetStringBounds ( " " ) gc . SetStrokeColor ( color . NRGBA { 255 , 0x33 , 0x33 , 0x80 } ) draw2dkit . Rectangle ( gc , left , top , right , bottom ) gc . SetLineWidth ( height / 50 ) gc . Stroke ( ) gc . SetFillColor ( color . NRGBA { 0x33 , 0x33 , 0xff , 0xff } ) gc . SetStrokeColor ( color . NRGBA { 0x33 , 0x33 , 0xff , 0xff } ) gc . SetLineWidth ( height / 100 ) gc . StrokeString ( " " ) gc . Translate ( - ( w + sx ) , sy * 24 ) w = gc . CreateStringPath ( " " , 0 , 0 ) gc . Fill ( ) gc . Translate ( w + sx , 0 ) gc . CreateStringPath ( " " , 0 , 0 ) path := gc . GetPath ( ) gc . Stroke ( ( & path ) . VerticalFlip ( ) ) gc . Restore ( ) } 
func FillStroke ( gc draw2d . GraphicContext , x , y , width , height float64 ) { sx , sy := width / 210 , height / 215 gc . MoveTo ( x + sx * 113.0 , y ) gc . LineTo ( x + sx * 215.0 , y + sy * 215 ) rLineTo ( gc , sx * - 100 , 0 ) gc . CubicCurveTo ( x + sx * 35 , y + sy * 215 , x + sx * 35 , y + sy * 113 , x + sx * 113.0 , y + sy * 113 ) gc . Close ( ) gc . MoveTo ( x + sx * 50.0 , y ) rLineTo ( gc , sx * 51.2 , sy * 51.2 ) rLineTo ( gc , sx * - 51.2 , sy * 51.2 ) rLineTo ( gc , sx * - 51.2 , sy * - 51.2 ) gc . Close ( ) gc . SetLineWidth ( width / 20.0 ) gc . SetFillColor ( color . NRGBA { 0 , 0 , 0xFF , 0xFF } ) gc . SetStrokeColor ( image . Black ) gc . FillStroke ( ) } 
func FillStyle ( gc draw2d . GraphicContext , x , y , width , height float64 ) { sx , sy := width / 232 , height / 220 gc . SetLineWidth ( width / 40 ) draw2dkit . Rectangle ( gc , x + sx * 0 , y + sy * 12 , x + sx * 232 , y + sy * 70 ) var wheel1 , wheel2 draw2d . Path wheel1 . ArcTo ( x + sx * 52 , y + sy * 70 , sx * 40 , sy * 40 , 0 , 2 * math . Pi ) wheel2 . ArcTo ( x + sx * 180 , y + sy * 70 , sx * 40 , sy * 40 , 0 , - 2 * math . Pi ) gc . SetFillRule ( draw2d . FillRuleEvenOdd ) gc . SetFillColor ( color . NRGBA { 0 , 0xB2 , 0 , 0xFF } ) gc . SetStrokeColor ( image . Black ) gc . FillStroke ( & wheel1 , & wheel2 ) draw2dkit . Rectangle ( gc , x , y + sy * 140 , x + sx * 232 , y + sy * 198 ) wheel1 . Clear ( ) wheel1 . ArcTo ( x + sx * 52 , y + sy * 198 , sx * 40 , sy * 40 , 0 , 2 * math . Pi ) wheel2 . Clear ( ) wheel2 . ArcTo ( x + sx * 180 , y + sy * 198 , sx * 40 , sy * 40 , 0 , - 2 * math . Pi ) gc . SetFillRule ( draw2d . FillRuleWinding ) gc . SetFillColor ( color . NRGBA { 0 , 0 , 0xE5 , 0xFF } ) gc . FillStroke ( & wheel1 , & wheel2 ) } 
func PathTransform ( gc draw2d . GraphicContext , x , y , width , height float64 ) { gc . Save ( ) gc . SetLineWidth ( width / 10 ) gc . Translate ( x + width / 2 , y + height / 2 ) gc . Scale ( 1 , 4 ) gc . ArcTo ( 0 , 0 , width / 8 , height / 8 , 0 , math . Pi * 2 ) gc . Close ( ) gc . Stroke ( ) gc . Restore ( ) } 
func Star ( gc draw2d . GraphicContext , x , y , width , height float64 ) { gc . Save ( ) gc . Translate ( x + width / 2 , y + height / 2 ) gc . SetLineWidth ( width / 40 ) for i := 0.0 ; i < 360 ; i = i + 10 { gc . Rotate ( i * ( math . Pi / 180.0 ) ) gc . MoveTo ( 0 , 0 ) gc . LineTo ( width / 2 , 0 ) gc . Stroke ( ) gc . Restore ( ) } gc . Restore ( ) } 
func Draw ( gc draw2d . GraphicContext , width , height float64 ) { mx , my := width * 0.025 , height * 0.025 dx , dy := ( width - 2 * mx ) / 4 , ( height - 2 * my ) / 3 w , h := dx - 2 * mx , dy - 2 * my x0 , y := 2 * mx , 2 * my x := x0 Bubble ( gc , x , y , w , h ) x += dx CurveRectangle ( gc , x , y , w , h , color . NRGBA { 0x80 , 0 , 0 , 0x80 } , color . NRGBA { 0x80 , 0x80 , 0xFF , 0xFF } ) x += dx Dash ( gc , x , y , w , h ) x += dx Arc ( gc , x , y , w , h ) x = x0 y += dy ArcNegative ( gc , x , y , w , h ) x += dx CubicCurve ( gc , x , y , w , h ) x += dx FillString ( gc , x , y , w , h ) x += dx FillStroke ( gc , x , y , w , h ) x = x0 y += dy FillStyle ( gc , x , y , w , h ) x += dx PathTransform ( gc , x , y , w , h ) x += dx Star ( gc , x , y , w , h ) x += dx gopher2 . Draw ( gc , x , y , w , h / 2 ) } 
func ConvertPath ( path * draw2d . Path , pdf Vectorizer ) { var startX , startY float64 = 0 , 0 i := 0 for _ , cmp := range path . Components { switch cmp { case draw2d . MoveToCmp : startX , startY = path . Points [ i ] , path . Points [ i + 1 ] pdf . MoveTo ( startX , startY ) i += 2 case draw2d . LineToCmp : pdf . LineTo ( path . Points [ i ] , path . Points [ i + 1 ] ) i += 2 case draw2d . QuadCurveToCmp : pdf . CurveTo ( path . Points [ i ] , path . Points [ i + 1 ] , path . Points [ i + 2 ] , path . Points [ i + 3 ] ) i += 4 case draw2d . CubicCurveToCmp : pdf . CurveBezierCubicTo ( path . Points [ i ] , path . Points [ i + 1 ] , path . Points [ i + 2 ] , path . Points [ i + 3 ] , path . Points [ i + 4 ] , path . Points [ i + 5 ] ) i += 6 case draw2d . ArcToCmp : pdf . ArcTo ( path . Points [ i ] , path . Points [ i + 1 ] , path . Points [ i + 2 ] , path . Points [ i + 3 ] , 0 , i += 6 case draw2d . CloseCmp : pdf . LineTo ( startX , startY ) pdf . ClosePath ( ) } } } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { x := 35.0 caps := [ ] draw2d . LineCap { draw2d . ButtCap , draw2d . SquareCap , draw2d . RoundCap } joins := [ ] draw2d . LineJoin { draw2d . BevelJoin , draw2d . MiterJoin , draw2d . RoundJoin } for i := range caps { Draw ( gc , caps [ i ] , joins [ i ] , x , 50 , x , 160 , offset ) x += offset } } 
func Draw ( gc draw2d . GraphicContext , cap draw2d . LineCap , join draw2d . LineJoin , x0 , y0 , x1 , y1 , offset float64 ) { gc . SetLineCap ( cap ) gc . SetLineJoin ( join ) gc . SetLineWidth ( 30.0 ) gc . MoveTo ( x0 , y0 ) gc . LineTo ( ( x0 + x1 ) / 2 + offset , ( y0 + y1 ) / 2 ) gc . LineTo ( x1 , y1 ) gc . Stroke ( ) gc . SetLineWidth ( 2.56 ) gc . MoveTo ( x0 , y0 ) gc . LineTo ( ( x0 + x1 ) / 2 + offset , ( y0 + y1 ) / 2 ) gc . LineTo ( x1 , y1 ) gc . Stroke ( ) } 
func DrawContour ( path draw2d . PathBuilder , ps [ ] truetype . Point , dx , dy float64 ) { if len ( ps ) == 0 { return } startX , startY := pointToF64Point ( ps [ 0 ] ) path . MoveTo ( startX + dx , startY + dy ) q0X , q0Y , on0 := startX , startY , true for _ , p := range ps [ 1 : ] { qX , qY := pointToF64Point ( p ) on := p . Flags & 0x01 != 0 if on { if on0 { path . LineTo ( qX + dx , qY + dy ) } else { path . QuadCurveTo ( q0X + dx , q0Y + dy , qX + dx , qY + dy ) } } else { if on0 { midY := ( q0Y + qY ) / 2 path . QuadCurveTo ( q0X + dx , q0Y + dy , midX + dx , midY + dy ) } } q0X , q0Y , on0 = qX , qY , on } } else { path . QuadCurveTo ( q0X + dx , q0Y + dy , startX + dx , startY + dy ) } } 
func Flatten ( path * draw2d . Path , flattener Flattener , scale float64 ) { i := 0 for _ , cmp := range path . Components { switch cmp { case draw2d . MoveToCmp : x , y = path . Points [ i ] , path . Points [ i + 1 ] startX , startY = x , y if i != 0 { flattener . End ( ) } flattener . MoveTo ( x , y ) i += 2 case draw2d . LineToCmp : x , y = path . Points [ i ] , path . Points [ i + 1 ] flattener . LineTo ( x , y ) flattener . LineJoin ( ) i += 2 case draw2d . QuadCurveToCmp : TraceQuad ( flattener , path . Points [ i - 2 : ] , 0.5 ) x , y = path . Points [ i + 2 ] , path . Points [ i + 3 ] flattener . LineTo ( x , y ) i += 4 case draw2d . CubicCurveToCmp : TraceCubic ( flattener , path . Points [ i - 2 : ] , 0.5 ) x , y = path . Points [ i + 4 ] , path . Points [ i + 5 ] flattener . LineTo ( x , y ) i += 6 case draw2d . ArcToCmp : x , y = TraceArc ( flattener , path . Points [ i ] , path . Points [ i + 1 ] , path . Points [ i + 2 ] , path . Points [ i + 3 ] , path . Points [ i + 4 ] , path . Points [ i + 5 ] , scale ) flattener . LineTo ( x , y ) i += 6 case draw2d . CloseCmp : flattener . LineTo ( startX , startY ) flattener . Close ( ) } } flattener . End ( ) } 
func ( tr1 Matrix ) Equals ( tr2 Matrix ) bool { for i := 0 ; i < 6 ; i = i + 1 { if ! fequals ( tr1 [ i ] , tr2 [ i ] ) { return false } } return true } 
func NewGraphicContext ( img draw . Image ) * GraphicContext { var painter Painter switch selectImage := img . ( type ) { case * image . RGBA : painter = raster . NewRGBAPainter ( selectImage ) default : panic ( " " ) } return NewGraphicContextWithPainter ( img , painter ) } 
func NewGraphicContextWithPainter ( img draw . Image , painter Painter ) * GraphicContext { width , height := img . Bounds ( ) . Dx ( ) , img . Bounds ( ) . Dy ( ) dpi := 92 gc := & GraphicContext { draw2dbase . NewStackGraphicContext ( ) , img , painter , raster . NewRasterizer ( width , height ) , raster . NewRasterizer ( width , height ) , draw2d . GetGlobalFontCache ( ) , draw2dbase . NewGlyphCache ( ) , & truetype . GlyphBuf { } , dpi , } return gc } 
func ( gc * GraphicContext ) Clear ( ) { width , height := gc . img . Bounds ( ) . Dx ( ) , gc . img . Bounds ( ) . Dy ( ) gc . ClearRect ( 0 , 0 , width , height ) } 
func ( gc * GraphicContext ) ClearRect ( x1 , y1 , x2 , y2 int ) { imageColor := image . NewUniform ( gc . Current . FillColor ) draw . Draw ( gc . img , image . Rect ( x1 , y1 , x2 , y2 ) , imageColor , image . ZP , draw . Over ) } 
func DrawImage ( src image . Image , dest draw . Image , tr draw2d . Matrix , op draw . Op , filter ImageFilter ) { var transformer draw . Transformer switch filter { case LinearFilter : transformer = draw . NearestNeighbor case BilinearFilter : transformer = draw . BiLinear case BicubicFilter : transformer = draw . CatmullRom } transformer . Transform ( dest , f64 . Aff3 { tr [ 0 ] , tr [ 1 ] , tr [ 4 ] , tr [ 2 ] , tr [ 3 ] , tr [ 5 ] } , src , src . Bounds ( ) , op , nil ) } 
func ( gc * GraphicContext ) DrawImage ( img image . Image ) { DrawImage ( img , gc . img , gc . Current . Tr , draw . Over , BilinearFilter ) } 
func ( gc * GraphicContext ) Stroke ( paths ... * draw2d . Path ) { paths = append ( paths , gc . Current . Path ) gc . strokeRasterizer . UseNonZeroWinding = true stroker := draw2dbase . NewLineStroker ( gc . Current . Cap , gc . Current . Join , draw2dbase . Transformer { Tr : gc . Current . Tr , Flattener : FtLineBuilder { Adder : gc . strokeRasterizer } } ) stroker . HalfLineWidth = gc . Current . LineWidth / 2 var liner draw2dbase . Flattener if gc . Current . Dash != nil && len ( gc . Current . Dash ) > 0 { liner = draw2dbase . NewDashConverter ( gc . Current . Dash , gc . Current . DashOffset , stroker ) } else { liner = stroker } for _ , p := range paths { draw2dbase . Flatten ( p , liner , gc . Current . Tr . GetScale ( ) ) } gc . paint ( gc . strokeRasterizer , gc . Current . StrokeColor ) } 
func ( gc * GraphicContext ) Fill ( paths ... * draw2d . Path ) { paths = append ( paths , gc . Current . Path ) gc . fillRasterizer . UseNonZeroWinding = gc . Current . FillRule == draw2d . FillRuleWinding flattener := draw2dbase . Transformer { Tr : gc . Current . Tr , Flattener : FtLineBuilder { Adder : gc . fillRasterizer } } for _ , p := range paths { draw2dbase . Flatten ( p , flattener , gc . Current . Tr . GetScale ( ) ) } gc . paint ( gc . fillRasterizer , gc . Current . FillColor ) } 
func ( gc * GraphicContext ) FillStroke ( paths ... * draw2d . Path ) { paths = append ( paths , gc . Current . Path ) gc . fillRasterizer . UseNonZeroWinding = gc . Current . FillRule == draw2d . FillRuleWinding gc . strokeRasterizer . UseNonZeroWinding = true flattener := draw2dbase . Transformer { Tr : gc . Current . Tr , Flattener : FtLineBuilder { Adder : gc . fillRasterizer } } stroker := draw2dbase . NewLineStroker ( gc . Current . Cap , gc . Current . Join , draw2dbase . Transformer { Tr : gc . Current . Tr , Flattener : FtLineBuilder { Adder : gc . strokeRasterizer } } ) stroker . HalfLineWidth = gc . Current . LineWidth / 2 var liner draw2dbase . Flattener if gc . Current . Dash != nil && len ( gc . Current . Dash ) > 0 { liner = draw2dbase . NewDashConverter ( gc . Current . Dash , gc . Current . DashOffset , stroker ) } else { liner = stroker } demux := draw2dbase . DemuxFlattener { Flatteners : [ ] draw2dbase . Flattener { flattener , liner } } for _ , p := range paths { draw2dbase . Flatten ( p , demux , gc . Current . Tr . GetScale ( ) ) } } 
func Main ( gc draw2d . GraphicContext , ext string ) ( string , error ) { } 
func Draw ( gc draw2d . GraphicContext , png string , dw , dh , margin , lineWidth float64 ) error { gc . SetLineWidth ( lineWidth ) gc . FillStroke ( ) if err != nil { return err } gc . Save ( ) gc . Translate ( ( dw - sw * scale ) / 2 , ( dh - sh * scale ) / 2 ) gc . Scale ( scale , scale ) gc . Rotate ( 0.2 ) gc . DrawImage ( source ) gc . Restore ( ) return nil } 
func Draw ( gc draw2d . GraphicContext , x , y float64 ) { gc . SetStrokeColor ( color . RGBA { 0x44 , 0x44 , 0x44 , 0xff } ) gc . SetLineWidth ( 5 ) gc . ArcTo ( x + 80 , y + 70 , 50 , 50 , 180 * ( math . Pi / 180 ) , 180 * ( math . Pi / 180 ) ) gc . Close ( ) gc . FillStroke ( ) gc . MoveTo ( x + 60 , y + 25 ) gc . LineTo ( x + 50 , y + 10 ) gc . MoveTo ( x + 100 , y + 25 ) gc . LineTo ( x + 110 , y + 10 ) gc . Stroke ( ) gc . FillStroke ( ) gc . FillStroke ( ) gc . FillStroke ( ) draw2dkit . Rectangle ( gc , x + 30 , y + 75 , x + 30 + 100 , y + 75 + 80 ) gc . FillStroke ( ) gc . FillStroke ( ) gc . FillStroke ( ) gc . FillStroke ( ) gc . FillStroke ( ) } 
func ChecksumString32S ( s string , seed uint32 ) uint32 { if len ( s ) == 0 { return Checksum32S ( nil , seed ) } ss := ( * reflect . StringHeader ) ( unsafe . Pointer ( & s ) ) return Checksum32S ( ( * [ maxInt32 ] byte ) ( unsafe . Pointer ( ss . Data ) ) [ : len ( s ) : len ( s ) ] , seed ) } 
func ChecksumString64S ( s string , seed uint64 ) uint64 { if len ( s ) == 0 { return Checksum64S ( nil , seed ) } ss := ( * reflect . StringHeader ) ( unsafe . Pointer ( & s ) ) return Checksum64S ( ( * [ maxInt32 ] byte ) ( unsafe . Pointer ( ss . Data ) ) [ : len ( s ) : len ( s ) ] , seed ) } 
func NewS32 ( seed uint32 ) ( xx * XXHash32 ) { xx = & XXHash32 { seed : seed , } xx . Reset ( ) return } 
func ( xx * XXHash32 ) Sum ( in [ ] byte ) [ ] byte { s := xx . Sum32 ( ) return append ( in , byte ( s >> 24 ) , byte ( s >> 16 ) , byte ( s >> 8 ) , byte ( s ) ) } 
func NewS64 ( seed uint64 ) ( xx * XXHash64 ) { xx = & XXHash64 { seed : seed , } xx . Reset ( ) return } 
func ( xx * XXHash64 ) Sum ( in [ ] byte ) [ ] byte { s := xx . Sum64 ( ) return append ( in , byte ( s >> 56 ) , byte ( s >> 48 ) , byte ( s >> 40 ) , byte ( s >> 32 ) , byte ( s >> 24 ) , byte ( s >> 16 ) , byte ( s >> 8 ) , byte ( s ) ) } 
func round64 ( h , v uint64 ) uint64 { h += v * prime64x2 h = rotl64_31 ( h ) h *= prime64x1 return h } 
func Checksum32S ( in [ ] byte , seed uint32 ) ( h uint32 ) { var i int if len ( in ) > 15 { var ( v1 = seed + prime32x1 + prime32x2 v2 = seed + prime32x2 v3 = seed + 0 v4 = seed - prime32x1 ) for ; i < len ( in ) - 15 ; i += 16 { in := in [ i : i + 16 : len ( in ) ] v1 += u32 ( in [ 0 : 4 : len ( in ) ] ) * prime32x2 v1 = rotl32_13 ( v1 ) * prime32x1 v2 += u32 ( in [ 4 : 8 : len ( in ) ] ) * prime32x2 v2 = rotl32_13 ( v2 ) * prime32x1 v3 += u32 ( in [ 8 : 12 : len ( in ) ] ) * prime32x2 v3 = rotl32_13 ( v3 ) * prime32x1 v4 += u32 ( in [ 12 : 16 : len ( in ) ] ) * prime32x2 v4 = rotl32_13 ( v4 ) * prime32x1 } h = rotl32_1 ( v1 ) + rotl32_7 ( v2 ) + rotl32_12 ( v3 ) + rotl32_18 ( v4 ) } else { h = seed + prime32x5 } h += uint32 ( len ( in ) ) for ; i <= len ( in ) - 4 ; i += 4 { in := in [ i : i + 4 : len ( in ) ] h += u32 ( in [ 0 : 4 : len ( in ) ] ) * prime32x3 h = rotl32_17 ( h ) * prime32x4 } for ; i < len ( in ) ; i ++ { h += uint32 ( in [ i ] ) * prime32x5 h = rotl32_11 ( h ) * prime32x1 } h ^= h >> 15 h *= prime32x2 h ^= h >> 13 h *= prime32x3 h ^= h >> 16 return } 
func Checksum64S ( in [ ] byte , seed uint64 ) uint64 { if len ( in ) == 0 && seed == 0 { return 0xef46db3751d8e999 } if len ( in ) > 31 { return checksum64 ( in , seed ) } return checksum64Short ( in , seed ) } 
func GetExecutablePath ( ) ( string , error ) { buf := make ( [ ] uint16 , syscall . MAX_PATH + 1 ) res , _ , err := getModuleFileName . Call ( 0 , uintptr ( unsafe . Pointer ( & buf [ 0 ] ) ) , uintptr ( len ( buf ) ) ) if res == 0 || res >= syscall . MAX_PATH || buf [ 0 ] == 0 || buf [ res - 1 ] == 0 { return " " , fmt . Errorf ( " " , res , err ) } return string ( utf16 . Decode ( buf [ : res ] ) ) , nil } 
func GetExecutablePath ( ) ( string , error ) { exePath , err := Readlink ( " " ) if err != nil { err = fmt . Errorf ( " " , err ) } return filepath . Clean ( exePath ) , err } 
func GetExecutablePath ( ) ( string , error ) { PATH_MAX := 1024 exePath := make ( [ ] byte , PATH_MAX ) exeLen := C . size_t ( len ( exePath ) ) mib [ 1 ] = 14 mib [ 2 ] = 12 mib [ 3 ] = - 1 status , err := C . sysctl ( ( * C . int ) ( unsafe . Pointer ( & mib [ 0 ] ) ) , 4 , unsafe . Pointer ( & exePath [ 0 ] ) , & exeLen , nil , 0 ) if err != nil { return " " , fmt . Errorf ( " " , err ) } } exePathString := string ( exePath [ : exePathStringLen ] ) return filepath . Clean ( exePathString ) , nil } 
func Readlink ( name string ) ( string , error ) { for len := 128 ; ; len *= 2 { b := make ( [ ] byte , len ) n , e := syscall . Readlink ( name , b ) if e != nil { return " " , & os . PathError { " " , name , e } } if n < len { if z := bytes . IndexByte ( b [ : n ] , 0 ) ; z >= 0 { n = z } return string ( b [ : n ] ) , nil } } } 
func GetExecutablePath ( ) ( string , error ) { PATH_MAX := 1024 exePath := make ( [ ] byte , PATH_MAX ) exeLen := C . uint32_t ( len ( exePath ) ) status , err := C . _NSGetExecutablePath ( ( * C . char ) ( unsafe . Pointer ( & exePath [ 0 ] ) ) , & exeLen ) if err != nil { return " " , fmt . Errorf ( " " , err ) } } exePathString := string ( exePath [ : exePathStringLen ] ) return filepath . Clean ( exePathString ) , nil } 
func MakeDaemon ( attrs * DaemonAttr ) ( io . Reader , io . Reader , error ) { stage , advanceStage , resetEnv := getStage ( ) } resetEnv ( ) return nil , nil , err } fileCount := 3 + len ( attrs . Files ) files := make ( [ ] * os . File , fileCount , fileCount + 2 ) if stage == 0 { if err != nil { return fatal ( err ) } files [ 0 ] , files [ 1 ] , files [ 2 ] = nullDev , nullDev , nullDev fd := 3 for _ , fPtr := range attrs . Files { files [ fd ] = * fPtr saveFileName ( fd , ( * fPtr ) . Name ( ) ) fd ++ } } else { files [ 0 ] , files [ 1 ] , files [ 2 ] = os . Stdin , os . Stdout , os . Stderr fd := 3 for _ , fPtr := range attrs . Files { * fPtr = os . NewFile ( uintptr ( fd ) , getFileName ( fd ) ) syscall . CloseOnExec ( fd ) files [ fd ] = * fPtr fd ++ } } if stage < 2 { if err != nil { return fatal ( fmt . Errorf ( " " , err ) ) } } if stage == 1 && attrs . CaptureOutput { files = files [ : fileCount + 2 ] } } } if err := advanceStage ( ) ; err != nil { return fatal ( err ) } dir , _ := os . Getwd ( ) osAttrs := os . ProcAttr { Dir : dir , Env : os . Environ ( ) , Files : files } if stage == 0 { sysattrs := syscall . SysProcAttr { Setsid : true } osAttrs . Sys = & sysattrs } progName := attrs . ProgramName if len ( progName ) == 0 { progName = os . Args [ 0 ] } args := append ( [ ] string { progName } , os . Args [ 1 : ] ... ) proc , err := os . StartProcess ( procName , args , & osAttrs ) if err != nil { return fatal ( fmt . Errorf ( " " , procName , err ) ) } proc . Release ( ) os . Exit ( 0 ) } os . Chdir ( " " ) syscall . Umask ( 0 ) resetEnv ( ) for fd := 3 ; fd < fileCount ; fd ++ { resetFileName ( fd ) } currStage = DaemonStage ( stage ) var stdout , stderr * os . File if attrs . CaptureOutput { stdout = os . NewFile ( uintptr ( fileCount ) , " " ) stderr = os . NewFile ( uintptr ( fileCount + 1 ) , " " ) } return stdout , stderr , nil } 
func Stage ( ) DaemonStage { if currStage == stageUnknown { s , _ , _ := getStage ( ) currStage = DaemonStage ( s ) } return currStage } 
func getStage ( ) ( stage int , advanceStage func ( ) error , resetEnv func ( ) error ) { var origValue string stage = 0 daemonStage := os . Getenv ( stageVar ) stageTag := strings . SplitN ( daemonStage , " " , 2 ) stageInfo := strings . SplitN ( stageTag [ 0 ] , " " , 3 ) if len ( stageInfo ) == 3 { stageStr , tm , check := stageInfo [ 0 ] , stageInfo [ 1 ] , stageInfo [ 2 ] hash := sha1 . New ( ) hash . Write ( [ ] byte ( stageStr + " " + tm + " " ) ) if check != hex . EncodeToString ( hash . Sum ( [ ] byte { } ) ) { } else { stage , _ = strconv . Atoi ( stageStr ) if len ( stageTag ) == 2 { origValue = stageTag [ 1 ] } } } else { origValue = daemonStage } advanceStage = func ( ) error { base := fmt . Sprintf ( " " , stage + 1 , time . Now ( ) . Nanosecond ( ) ) hash := sha1 . New ( ) hash . Write ( [ ] byte ( base ) ) tag := base + hex . EncodeToString ( hash . Sum ( [ ] byte { } ) ) if err := os . Setenv ( stageVar , tag + " " + origValue ) ; err != nil { return fmt . Errorf ( " " , stageVar , err ) } return nil } resetEnv = func ( ) error { return os . Setenv ( stageVar , origValue ) } return stage , advanceStage , resetEnv } 
func New ( ) * Glg { g := & Glg { levelCounter : new ( uint32 ) , buffer : sync . Pool { New : func ( ) interface { } { return bytes . NewBuffer ( make ( [ ] byte , 0 , bufferSize ) ) } , } , } atomic . StoreUint32 ( g . levelCounter , uint32 ( FATAL ) ) for lev , log := range map [ LEVEL ] * logger { log . updateMode ( ) g . logger . Store ( lev , log ) } return g } 
func Get ( ) * Glg { once . Do ( func ( ) { fastime . SetFormat ( timeFormat ) glg = New ( ) } ) return glg } 
func ( g * Glg ) SetMode ( mode MODE ) * Glg { g . logger . Range ( func ( key , val interface { } ) bool { l := val . ( * logger ) l . mode = mode l . updateMode ( ) g . logger . Store ( key . ( LEVEL ) , l ) return true } ) return g } 
func ( g * Glg ) SetLevelMode ( level LEVEL , mode MODE ) * Glg { lev , ok := g . logger . Load ( level ) if ok { l := lev . ( * logger ) l . mode = mode l . updateMode ( ) g . logger . Store ( level , l ) } return g } 
func ( g * Glg ) SetPrefix ( pref string ) * Glg { v , ok := g . logger . Load ( PRINT ) if ok { value := v . ( * logger ) value . tag = pref g . logger . Store ( PRINT , value ) } return g } 
func ( g * Glg ) GetCurrentMode ( level LEVEL ) MODE { l , ok := g . logger . Load ( level ) if ok { return l . ( * logger ) . mode } return NONE } 
func ( g * Glg ) InitWriter ( ) * Glg { g . logger . Range ( func ( key , val interface { } ) bool { l := val . ( * logger ) l . writer = nil l . updateMode ( ) g . logger . Store ( key . ( LEVEL ) , l ) return true } ) return g } 
func ( g * Glg ) SetWriter ( writer io . Writer ) * Glg { if writer == nil { return g } g . logger . Range ( func ( key , val interface { } ) bool { l := val . ( * logger ) l . writer = writer l . updateMode ( ) g . logger . Store ( key . ( LEVEL ) , l ) return true } ) return g } 
func ( g * Glg ) SetLevelColor ( level LEVEL , color func ( string ) string ) * Glg { lev , ok := g . logger . Load ( level ) if ok { l := lev . ( * logger ) l . color = color g . logger . Store ( level , l ) } return g } 
func ( g * Glg ) SetLevelWriter ( level LEVEL , writer io . Writer ) * Glg { if writer == nil { return g } lev , ok := g . logger . Load ( level ) if ok { l := lev . ( * logger ) l . writer = writer l . updateMode ( ) g . logger . Store ( level , l ) } return g } 
func ( g * Glg ) AddStdLevel ( tag string , mode MODE , isColor bool ) * Glg { atomic . AddUint32 ( g . levelCounter , 1 ) lev := LEVEL ( atomic . LoadUint32 ( g . levelCounter ) ) g . levelMap . Store ( tag , lev ) l := & logger { writer : nil , std : os . Stdout , color : Colorless , isColor : isColor , mode : mode , tag : tag , } l . updateMode ( ) g . logger . Store ( lev , l ) return g } 
func ( g * Glg ) EnableColor ( ) * Glg { g . logger . Range ( func ( key , val interface { } ) bool { l := val . ( * logger ) l . isColor = true l . updateMode ( ) g . logger . Store ( key . ( LEVEL ) , l ) return true } ) return g } 
func ( g * Glg ) EnableLevelColor ( lv LEVEL ) * Glg { ins , ok := g . logger . Load ( lv ) if ok { l := ins . ( * logger ) l . isColor = true l . updateMode ( ) g . logger . Store ( lv , l ) } return g } 
func ( g * Glg ) DisableLevelColor ( lv LEVEL ) * Glg { ins , ok := g . logger . Load ( lv ) if ok { l := ins . ( * logger ) l . isColor = false l . updateMode ( ) g . logger . Store ( lv , l ) } return g } 
func ( g * Glg ) RawString ( data [ ] byte ) string { str := * ( * string ) ( unsafe . Pointer ( & data ) ) return str [ strings . Index ( str , sep ) + sepl : len ( str ) - rcl ] } 
func ( g * Glg ) TagStringToLevel ( tag string ) LEVEL { l , ok := g . levelMap . Load ( tag ) if ! ok { return 255 } return l . ( LEVEL ) } 
func FileWriter ( path string , perm os . FileMode ) * os . File { if path == " " { return nil } var err error var file * os . File if _ , err = os . Stat ( path ) ; err != nil { if _ , err = os . Stat ( filepath . Dir ( path ) ) ; err != nil { err = os . MkdirAll ( filepath . Dir ( path ) , perm ) if err != nil { return nil } } file , err = os . Create ( path ) if err != nil { return nil } err = file . Close ( ) if err != nil { return nil } } file , err = os . OpenFile ( path , os . O_APPEND | os . O_CREATE | os . O_WRONLY , perm ) if err != nil { return nil } return file } 
func ( g * Glg ) HTTPLogger ( name string , handler http . Handler ) http . Handler { return g . HTTPLoggerFunc ( name , handler . ServeHTTP ) } 
func ( g * Glg ) HTTPLoggerFunc ( name string , hf http . HandlerFunc ) http . Handler { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { start := fastime . Now ( ) hf ( w , r ) err := g . Logf ( " \t \t \t " , r . Method , r . RequestURI , name , fastime . Now ( ) . Sub ( start ) . String ( ) ) if err != nil { err = g . Error ( err ) if err != nil { fmt . Println ( err ) } } } ) } 
func HTTPLogger ( name string , handler http . Handler ) http . Handler { return glg . HTTPLogger ( name , handler ) } 
func HTTPLoggerFunc ( name string , hf http . HandlerFunc ) http . Handler { return glg . HTTPLoggerFunc ( name , hf ) } 
func ( g * Glg ) Log ( val ... interface { } ) error { return g . out ( LOG , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Logf ( format string , val ... interface { } ) error { return g . out ( LOG , format , val ... ) } 
func ( g * Glg ) LogFunc ( f func ( ) string ) error { if g . isModeEnable ( LOG ) { return g . out ( LOG , " " , f ( ) ) } return nil } 
func Log ( val ... interface { } ) error { return glg . out ( LOG , blankFormat ( len ( val ) ) , val ... ) } 
func Logf ( format string , val ... interface { } ) error { return glg . out ( LOG , format , val ... ) } 
func LogFunc ( f func ( ) string ) error { if isModeEnable ( LOG ) { return glg . out ( LOG , " " , f ( ) ) } return nil } 
func ( g * Glg ) Info ( val ... interface { } ) error { return g . out ( INFO , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Infof ( format string , val ... interface { } ) error { return g . out ( INFO , format , val ... ) } 
func ( g * Glg ) InfoFunc ( f func ( ) string ) error { if g . isModeEnable ( INFO ) { return g . out ( INFO , " " , f ( ) ) } return nil } 
func Info ( val ... interface { } ) error { return glg . out ( INFO , blankFormat ( len ( val ) ) , val ... ) } 
func Infof ( format string , val ... interface { } ) error { return glg . out ( INFO , format , val ... ) } 
func InfoFunc ( f func ( ) string ) error { if isModeEnable ( INFO ) { return glg . out ( INFO , " " , f ( ) ) } return nil } 
func ( g * Glg ) Success ( val ... interface { } ) error { return g . out ( OK , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Successf ( format string , val ... interface { } ) error { return g . out ( OK , format , val ... ) } 
func ( g * Glg ) SuccessFunc ( f func ( ) string ) error { if g . isModeEnable ( OK ) { return g . out ( OK , " " , f ( ) ) } return nil } 
func Success ( val ... interface { } ) error { return glg . out ( OK , blankFormat ( len ( val ) ) , val ... ) } 
func Successf ( format string , val ... interface { } ) error { return glg . out ( OK , format , val ... ) } 
func SuccessFunc ( f func ( ) string ) error { if isModeEnable ( OK ) { return glg . out ( OK , " " , f ( ) ) } return nil } 
func ( g * Glg ) Debug ( val ... interface { } ) error { return g . out ( DEBG , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Debugf ( format string , val ... interface { } ) error { return g . out ( DEBG , format , val ... ) } 
func ( g * Glg ) DebugFunc ( f func ( ) string ) error { if g . isModeEnable ( DEBG ) { return g . out ( DEBG , " " , f ( ) ) } return nil } 
func Debug ( val ... interface { } ) error { return glg . out ( DEBG , blankFormat ( len ( val ) ) , val ... ) } 
func Debugf ( format string , val ... interface { } ) error { return glg . out ( DEBG , format , val ... ) } 
func DebugFunc ( f func ( ) string ) error { if isModeEnable ( DEBG ) { return glg . out ( DEBG , " " , f ( ) ) } return nil } 
func ( g * Glg ) Warn ( val ... interface { } ) error { return g . out ( WARN , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Warnf ( format string , val ... interface { } ) error { return g . out ( WARN , format , val ... ) } 
func ( g * Glg ) WarnFunc ( f func ( ) string ) error { if g . isModeEnable ( WARN ) { return g . out ( WARN , " " , f ( ) ) } return nil } 
func Warn ( val ... interface { } ) error { return glg . out ( WARN , blankFormat ( len ( val ) ) , val ... ) } 
func Warnf ( format string , val ... interface { } ) error { return glg . out ( WARN , format , val ... ) } 
func WarnFunc ( f func ( ) string ) error { if isModeEnable ( WARN ) { return glg . out ( WARN , " " , f ( ) ) } return nil } 
func ( g * Glg ) CustomLog ( level string , val ... interface { } ) error { return g . out ( g . TagStringToLevel ( level ) , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) CustomLogf ( level string , format string , val ... interface { } ) error { return g . out ( g . TagStringToLevel ( level ) , format , val ... ) } 
func ( g * Glg ) CustomLogFunc ( level string , f func ( ) string ) error { lv := g . TagStringToLevel ( level ) if g . isModeEnable ( lv ) { return g . out ( lv , " " , f ( ) ) } return nil } 
func CustomLog ( level string , val ... interface { } ) error { return glg . out ( glg . TagStringToLevel ( level ) , blankFormat ( len ( val ) ) , val ... ) } 
func CustomLogf ( level string , format string , val ... interface { } ) error { return glg . out ( glg . TagStringToLevel ( level ) , format , val ... ) } 
func CustomLogFunc ( level string , f func ( ) string ) error { lv := TagStringToLevel ( level ) if isModeEnable ( lv ) { return glg . out ( lv , " " , f ( ) ) } return nil } 
func ( g * Glg ) Print ( val ... interface { } ) error { return g . out ( PRINT , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Printf ( format string , val ... interface { } ) error { return g . out ( PRINT , format , val ... ) } 
func ( g * Glg ) PrintFunc ( f func ( ) string ) error { if g . isModeEnable ( PRINT ) { return g . out ( PRINT , " " , f ( ) ) } return nil } 
func Print ( val ... interface { } ) error { return glg . out ( PRINT , blankFormat ( len ( val ) ) , val ... ) } 
func Println ( val ... interface { } ) error { return glg . out ( PRINT , blankFormat ( len ( val ) ) , val ... ) } 
func Printf ( format string , val ... interface { } ) error { return glg . out ( PRINT , format , val ... ) } 
func PrintFunc ( f func ( ) string ) error { if isModeEnable ( PRINT ) { return glg . out ( PRINT , " " , f ( ) ) } return nil } 
func ( g * Glg ) Error ( val ... interface { } ) error { return g . out ( ERR , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Errorf ( format string , val ... interface { } ) error { return g . out ( ERR , format , val ... ) } 
func ( g * Glg ) ErrorFunc ( f func ( ) string ) error { if g . isModeEnable ( ERR ) { return g . out ( ERR , " " , f ( ) ) } return nil } 
func Error ( val ... interface { } ) error { return glg . out ( ERR , blankFormat ( len ( val ) ) , val ... ) } 
func Errorf ( format string , val ... interface { } ) error { return glg . out ( ERR , format , val ... ) } 
func ErrorFunc ( f func ( ) string ) error { if isModeEnable ( ERR ) { return glg . out ( ERR , " " , f ( ) ) } return nil } 
func ( g * Glg ) Fail ( val ... interface { } ) error { return g . out ( FAIL , blankFormat ( len ( val ) ) , val ... ) } 
func ( g * Glg ) Failf ( format string , val ... interface { } ) error { return g . out ( FAIL , format , val ... ) } 
func ( g * Glg ) FailFunc ( f func ( ) string ) error { if g . isModeEnable ( FAIL ) { return g . out ( FAIL , " " , f ( ) ) } return nil } 
func Fail ( val ... interface { } ) error { return glg . out ( FAIL , blankFormat ( len ( val ) ) , val ... ) } 
func Failf ( format string , val ... interface { } ) error { return glg . out ( FAIL , format , val ... ) } 
func FailFunc ( f func ( ) string ) error { if isModeEnable ( FAIL ) { return glg . out ( FAIL , " " , f ( ) ) } return nil } 
func ( g * Glg ) Fatal ( val ... interface { } ) { err := g . out ( FATAL , blankFormat ( len ( val ) ) , val ... ) if err != nil { err = g . Error ( err . Error ( ) ) if err != nil { panic ( err ) } } exit ( 1 ) } 
func ( g * Glg ) Fatalf ( format string , val ... interface { } ) { err := g . out ( FATAL , format , val ... ) if err != nil { err = g . Error ( err . Error ( ) ) if err != nil { panic ( err ) } } exit ( 1 ) } 
func ( g * Glg ) isModeEnable ( l LEVEL ) bool { return g . GetCurrentMode ( l ) != NONE } 
func Wrap ( w http . ResponseWriter , hooks Hooks ) http . ResponseWriter { rw := & rw { w : w , h : hooks } _ , i0 := w . ( http . Flusher ) _ , i1 := w . ( http . CloseNotifier ) _ , i2 := w . ( http . Hijacker ) _ , i3 := w . ( io . ReaderFrom ) switch { } { rw } io . ReaderFrom } { rw , rw } http . Hijacker } { rw , rw } http . Hijacker io . ReaderFrom } { rw , rw , rw } http . CloseNotifier } { rw , rw } http . CloseNotifier io . ReaderFrom } { rw , rw , rw } http . CloseNotifier http . Hijacker } { rw , rw , rw } http . CloseNotifier http . Hijacker io . ReaderFrom } { rw , rw , rw , rw } http . Flusher } { rw , rw } http . Flusher io . ReaderFrom } { rw , rw , rw } http . Flusher http . Hijacker } { rw , rw , rw } http . Flusher http . Hijacker io . ReaderFrom } { rw , rw , rw , rw } http . Flusher http . CloseNotifier } { rw , rw , rw } http . Flusher http . CloseNotifier io . ReaderFrom } { rw , rw , rw , rw } http . Flusher http . CloseNotifier http . Hijacker } { rw , rw , rw , rw } http . Flusher http . CloseNotifier http . Hijacker io . ReaderFrom } { rw , rw , rw , rw , rw } } panic ( " " ) } 
func Wrap ( w http . ResponseWriter , hooks Hooks ) http . ResponseWriter { rw := & rw { w : w , h : hooks } _ , i0 := w . ( http . Flusher ) _ , i1 := w . ( http . CloseNotifier ) _ , i2 := w . ( http . Hijacker ) _ , i3 := w . ( io . ReaderFrom ) _ , i4 := w . ( http . Pusher ) switch { } { rw } http . Pusher } { rw , rw } io . ReaderFrom } { rw , rw } io . ReaderFrom http . Pusher } { rw , rw , rw } http . Hijacker } { rw , rw } http . Hijacker http . Pusher } { rw , rw , rw } http . Hijacker io . ReaderFrom } { rw , rw , rw } http . Hijacker io . ReaderFrom http . Pusher } { rw , rw , rw , rw } http . CloseNotifier } { rw , rw } http . CloseNotifier http . Pusher } { rw , rw , rw } http . CloseNotifier io . ReaderFrom } { rw , rw , rw } http . CloseNotifier io . ReaderFrom http . Pusher } { rw , rw , rw , rw } http . CloseNotifier http . Hijacker } { rw , rw , rw } http . CloseNotifier http . Hijacker http . Pusher } { rw , rw , rw , rw } http . CloseNotifier http . Hijacker io . ReaderFrom } { rw , rw , rw , rw } http . CloseNotifier http . Hijacker io . ReaderFrom http . Pusher } { rw , rw , rw , rw , rw } http . Flusher } { rw , rw } http . Flusher http . Pusher } { rw , rw , rw } http . Flusher io . ReaderFrom } { rw , rw , rw } http . Flusher io . ReaderFrom http . Pusher } { rw , rw , rw , rw } http . Flusher http . Hijacker } { rw , rw , rw } http . Flusher http . Hijacker http . Pusher } { rw , rw , rw , rw } http . Flusher http . Hijacker io . ReaderFrom } { rw , rw , rw , rw } http . Flusher http . Hijacker io . ReaderFrom http . Pusher } { rw , rw , rw , rw , rw } http . Flusher http . CloseNotifier } { rw , rw , rw } http . Flusher http . CloseNotifier http . Pusher } { rw , rw , rw , rw } http . Flusher http . CloseNotifier io . ReaderFrom } { rw , rw , rw , rw } http . Flusher http . CloseNotifier io . ReaderFrom http . Pusher } { rw , rw , rw , rw , rw } http . Flusher http . CloseNotifier http . Hijacker } { rw , rw , rw , rw } http . Flusher http . CloseNotifier http . Hijacker http . Pusher } { rw , rw , rw , rw , rw } http . Flusher http . CloseNotifier http . Hijacker io . ReaderFrom } { rw , rw , rw , rw , rw } http . Flusher http . CloseNotifier http . Hijacker io . ReaderFrom http . Pusher } { rw , rw , rw , rw , rw , rw } } panic ( " " ) } 
func CaptureMetrics ( hnd http . Handler , w http . ResponseWriter , r * http . Request ) Metrics { return CaptureMetricsFn ( w , func ( ww http . ResponseWriter ) { hnd . ServeHTTP ( ww , r ) } ) } 
func CaptureMetricsFn ( w http . ResponseWriter , fn func ( http . ResponseWriter ) ) Metrics { var ( start = time . Now ( ) m = Metrics { Code : http . StatusOK } headerWritten bool lock sync . Mutex hooks = Hooks { WriteHeader : func ( next WriteHeaderFunc ) WriteHeaderFunc { return func ( code int ) { next ( code ) lock . Lock ( ) defer lock . Unlock ( ) if ! headerWritten { m . Code = code headerWritten = true } } } , Write : func ( next WriteFunc ) WriteFunc { return func ( p [ ] byte ) ( int , error ) { n , err := next ( p ) lock . Lock ( ) defer lock . Unlock ( ) m . Written += int64 ( n ) headerWritten = true return n , err } } , ReadFrom : func ( next ReadFromFunc ) ReadFromFunc { return func ( src io . Reader ) ( int64 , error ) { n , err := next ( src ) lock . Lock ( ) defer lock . Unlock ( ) headerWritten = true m . Written += n return n , err } } , } ) fn ( Wrap ( w , hooks ) ) m . Duration = time . Since ( start ) return m } 
func ( da * cedar ) get ( key [ ] byte , from , pos int ) * int { for ; pos < len ( key ) ; pos ++ { if value := da . Array [ from ] . Value ; value >= 0 && value != ValueLimit { to := da . follow ( from , 0 ) da . Array [ to ] . Value = value } from = da . follow ( from , key [ pos ] ) } to := from if da . Array [ from ] . Value < 0 { to = da . follow ( from , 0 ) } return & da . Array [ to ] . Value } 
func ( da * cedar ) pushSibling ( from , base int , label byte , hasChild bool ) { c := & da . Ninfos [ from ] . Child keepOrder := * c == 0 if da . Ordered { keepOrder = label > * c } if hasChild && keepOrder { c = & da . Ninfos [ base ^ int ( * c ) ] . Sibling for da . Ordered && * c != 0 && * c < label { c = & da . Ninfos [ base ^ int ( * c ) ] . Sibling } } da . Ninfos [ base ^ int ( label ) ] . Sibling = * c * c = label } 
func ( da * Cedar ) Save ( out io . Writer , dataType string ) error { switch dataType { case " " , " " : dataEecoder := gob . NewEncoder ( out ) return dataEecoder . Encode ( da . cedar ) case " " , " " : dataEecoder := json . NewEncoder ( out ) return dataEecoder . Encode ( da . cedar ) } return ErrInvalidDataType } 
func ( da * Cedar ) SaveToFile ( fileName string , dataType string ) error { file , err := os . OpenFile ( fileName , os . O_CREATE | os . O_WRONLY , 0666 ) if err != nil { return err } defer file . Close ( ) out := bufio . NewWriter ( file ) defer out . Flush ( ) da . Save ( out , dataType ) return nil } 
func ( da * Cedar ) Load ( in io . Reader , dataType string ) error { switch dataType { case " " , " " : dataDecoder := gob . NewDecoder ( in ) return dataDecoder . Decode ( da . cedar ) case " " , " " : dataDecoder := json . NewDecoder ( in ) return dataDecoder . Decode ( da . cedar ) } return ErrInvalidDataType } 
func ( da * Cedar ) LoadFromFile ( fileName string , dataType string ) error { file , err := os . OpenFile ( fileName , os . O_RDONLY , 0600 ) defer file . Close ( ) if err != nil { return err } in := bufio . NewReader ( file ) return da . Load ( in , dataType ) } 
func ( da * Cedar ) Status ( ) ( keys , nodes , size , capacity int ) { for i := 0 ; i < da . Size ; i ++ { n := da . Array [ i ] if n . Check >= 0 { nodes ++ if n . Value >= 0 { keys ++ } } } return keys , nodes , da . Size , da . Capacity } 
func ( da * Cedar ) Jump ( path [ ] byte , from int ) ( to int , err error ) { for _ , b := range path { if da . Array [ from ] . Value >= 0 { return from , ErrNoPath } to = da . Array [ from ] . base ( ) ^ int ( b ) if da . Array [ to ] . Check != from { return from , ErrNoPath } from = to } return to , nil } 
func ( da * Cedar ) Key ( id int ) ( key [ ] byte , err error ) { for id > 0 { from := da . Array [ id ] . Check if from < 0 { return nil , ErrNoPath } if char := byte ( da . Array [ from ] . base ( ) ^ id ) ; char != 0 { key = append ( key , char ) } id = from } if id != 0 || len ( key ) == 0 { return nil , ErrInvalidKey } for i := 0 ; i < len ( key ) / 2 ; i ++ { key [ i ] , key [ len ( key ) - i - 1 ] = key [ len ( key ) - i - 1 ] , key [ i ] } return key , nil } 
func ( da * Cedar ) Value ( id int ) ( value int , err error ) { value = da . Array [ id ] . Value if value >= 0 { return value , nil } to := da . Array [ id ] . base ( ) if da . Array [ to ] . Check == id && da . Array [ to ] . Value >= 0 { return da . Array [ to ] . Value , nil } return 0 , ErrNoValue } 
func ( da * Cedar ) Insert ( key [ ] byte , value int ) error { if value < 0 || value >= ValueLimit { return ErrInvalidValue } p := da . get ( key , 0 , 0 ) * p = value return nil } 
func ( da * Cedar ) Update ( key [ ] byte , value int ) error { p := da . get ( key , 0 , 0 ) return nil } } * p += value return nil } 
func ( da * Cedar ) Delete ( key [ ] byte ) error { if err != nil { return ErrNoPath } if da . Array [ to ] . Value < 0 { base := da . Array [ to ] . base ( ) if da . Array [ base ] . Check == to { to = base } } for to > 0 { from := da . Array [ to ] . Check base := da . Array [ from ] . base ( ) label := byte ( to ^ base ) break } } return nil } 
func ( da * Cedar ) Get ( key [ ] byte ) ( value int , err error ) { to , err := da . Jump ( key , 0 ) if err != nil { return 0 , err } return da . Value ( to ) } 
func ( da * Cedar ) PrefixMatch ( key [ ] byte , num int ) ( ids [ ] int ) { for from , i := 0 , 0 ; i < len ( key ) ; i ++ { to , err := da . Jump ( key [ i : i + 1 ] , from ) if err != nil { break } if _ , err := da . Value ( to ) ; err == nil { ids = append ( ids , to ) num -- if num == 0 { return } } from = to } return } 
func ( da * Cedar ) PrefixPredict ( key [ ] byte , num int ) ( ids [ ] int ) { root , err := da . Jump ( key , 0 ) if err != nil { return } for from , err := da . begin ( root ) ; err == nil ; from , err = da . next ( from , root ) { ids = append ( ids , from ) num -- if num == 0 { return } } return } 
func ( v * Version ) Set ( version string ) error { metadata := splitOff ( & version , " " ) preRelease := PreRelease ( splitOff ( & version , " " ) ) dotParts := strings . SplitN ( version , " " , 3 ) if len ( dotParts ) != 3 { return fmt . Errorf ( " " , version ) } if err := validateIdentifier ( string ( preRelease ) ) ; err != nil { return fmt . Errorf ( " " , err ) } if err := validateIdentifier ( metadata ) ; err != nil { return fmt . Errorf ( " " , err ) } parsed := make ( [ ] int64 , 3 , 3 ) for i , v := range dotParts [ : 3 ] { val , err := strconv . ParseInt ( v , 10 , 64 ) parsed [ i ] = val if err != nil { return err } } v . Metadata = metadata v . PreRelease = preRelease v . Major = parsed [ 0 ] v . Minor = parsed [ 1 ] v . Patch = parsed [ 2 ] return nil } 
func ( v Version ) Compare ( versionB Version ) int { if cmp := recursiveCompare ( v . Slice ( ) , versionB . Slice ( ) ) ; cmp != 0 { return cmp } return preReleaseCompare ( v , versionB ) } 
func ( v Version ) Slice ( ) [ ] int64 { return [ ] int64 { v . Major , v . Minor , v . Patch } } 
func ( v * Version ) BumpMajor ( ) { v . Major += 1 v . Minor = 0 v . Patch = 0 v . PreRelease = PreRelease ( " " ) v . Metadata = " " } 
func ( v * Version ) BumpMinor ( ) { v . Minor += 1 v . Patch = 0 v . PreRelease = PreRelease ( " " ) v . Metadata = " " } 
func ( v * Version ) BumpPatch ( ) { v . Patch += 1 v . PreRelease = PreRelease ( " " ) v . Metadata = " " } 
func validateIdentifier ( id string ) error { if id != " " && ! reIdentifier . MatchString ( id ) { return fmt . Errorf ( " " , id ) } return nil } 
func parse_token ( token string ) ( op string , key string , args interface { } , err error ) { if token == " " { return " " , " " , nil , nil } if token == " " { return " " , " " , nil , nil } bracket_idx := strings . Index ( token , " " ) if bracket_idx < 0 { return " " , token , nil , nil } else { key = token [ : bracket_idx ] tail := token [ bracket_idx : ] if len ( tail ) < 3 { err = fmt . Errorf ( " " , tail ) return } tail = tail [ 1 : len ( tail ) - 1 ] if strings . HasPrefix ( tail , " " ) && strings . HasSuffix ( tail , " " ) { args = strings . Trim ( tail [ 2 : len ( tail ) - 1 ] , " " ) } return } else if strings . Contains ( tail , " " ) { tails := strings . Split ( tail , " " ) if len ( tails ) != 2 { err = fmt . Errorf ( " " , tails ) return } var frm interface { } var to interface { } if frm , err = strconv . Atoi ( strings . Trim ( tails [ 0 ] , " " ) ) ; err != nil { if strings . Trim ( tails [ 0 ] , " " ) == " " { err = nil } frm = nil } if to , err = strconv . Atoi ( strings . Trim ( tails [ 1 ] , " " ) ) ; err != nil { if strings . Trim ( tails [ 1 ] , " " ) == " " { err = nil } to = nil } args = [ 2 ] interface { } { frm , to } return } else if tail == " " { op = " " args = [ 2 ] interface { } { nil , nil } return } else { res := [ ] int { } for _ , x := range strings . Split ( tail , " " ) { if i , err := strconv . Atoi ( strings . Trim ( x , " " ) ) ; err == nil { res = append ( res , i ) } else { return " " , " " , nil , err } } args = res } } return op , key , args , nil } 
func newStream ( bufsize int , replay bool ) * Stream { return & Stream { AutoReplay : replay , subscribers : make ( [ ] * Subscriber , 0 ) , register : make ( chan * Subscriber ) , deregister : make ( chan * Subscriber ) , event : make ( chan * Event , bufsize ) , quit : make ( chan bool ) , Eventlog : make ( EventLog , 0 ) , } } 
func ( str * Stream ) addSubscriber ( eventid string ) * Subscriber { sub := & Subscriber { eventid : eventid , quit : str . deregister , connection : make ( chan * Event , 64 ) , } str . register <- sub return sub } 
func New ( ) * Server { return & Server { BufferSize : DefaultBufferSize , AutoStream : false , AutoReplay : true , Streams : make ( map [ string ] * Stream ) , } } 
func ( s * Server ) Close ( ) { s . mu . Lock ( ) defer s . mu . Unlock ( ) for id := range s . Streams { s . Streams [ id ] . quit <- true delete ( s . Streams , id ) } } 
func ( s * Server ) CreateStream ( id string ) * Stream { s . mu . Lock ( ) defer s . mu . Unlock ( ) if s . Streams [ id ] != nil { return s . Streams [ id ] } str := newStream ( s . BufferSize , s . AutoReplay ) str . run ( ) s . Streams [ id ] = str return str } 
func ( s * Server ) RemoveStream ( id string ) { s . mu . Lock ( ) defer s . mu . Unlock ( ) if s . Streams [ id ] != nil { s . Streams [ id ] . close ( ) delete ( s . Streams , id ) } } 
func ( s * Server ) StreamExists ( id string ) bool { s . mu . Lock ( ) defer s . mu . Unlock ( ) return s . Streams [ id ] != nil } 
func ( s * Server ) Publish ( id string , event * Event ) { s . mu . Lock ( ) defer s . mu . Unlock ( ) if s . Streams [ id ] != nil { s . Streams [ id ] . event <- s . process ( event ) } } 
func NewClient ( url string ) * Client { return & Client { URL : url , Connection : & http . Client { } , Headers : make ( map [ string ] string ) , subscribed : make ( map [ chan * Event ] chan bool ) , } } 
func ( c * Client ) Subscribe ( stream string , handler func ( msg * Event ) ) error { operation := func ( ) error { resp , err := c . request ( stream ) if err != nil { return err } defer resp . Body . Close ( ) reader := NewEventStreamReader ( resp . Body ) for { if err != nil { if err == io . EOF { return nil } } return err } } else { msg . ID = [ ] byte ( c . EventID ) } handler ( msg ) } } } return backoff . Retry ( operation , backoff . NewExponentialBackOff ( ) ) } 
func ( c * Client ) SubscribeChan ( stream string , ch chan * Event ) error { var connected bool errch := make ( chan error ) c . mu . Lock ( ) c . subscribed [ ch ] = make ( chan bool ) c . mu . Unlock ( ) go func ( ) { operation := func ( ) error { resp , err := c . request ( stream ) if err != nil { c . cleanup ( resp , ch ) return err } if resp . StatusCode != 200 { c . cleanup ( resp , ch ) return errors . New ( " " ) } if ! connected { errch <- nil connected = true } reader := NewEventStreamReader ( resp . Body ) for { if err != nil { if err == io . EOF { c . cleanup ( resp , ch ) return nil } } return err } } else { msg . ID = [ ] byte ( c . EventID ) } select { case <- c . subscribed [ ch ] : c . cleanup ( resp , ch ) return nil case ch <- msg : } } } err := backoff . Retry ( operation , backoff . NewExponentialBackOff ( ) ) if err != nil && ! connected { errch <- err } } ( ) err := <- errch close ( errch ) return err } 
func ( c * Client ) SubscribeRaw ( handler func ( msg * Event ) ) error { return c . Subscribe ( " " , handler ) } 
func ( c * Client ) Unsubscribe ( ch chan * Event ) { c . mu . Lock ( ) defer c . mu . Unlock ( ) if c . subscribed [ ch ] != nil { c . subscribed [ ch ] <- true } } 
func NewEventStreamReader ( eventStream io . Reader ) * EventStreamReader { scanner := bufio . NewScanner ( eventStream ) split := func ( data [ ] byte , atEOF bool ) ( int , [ ] byte , error ) { if atEOF && len ( data ) == 0 { return 0 , nil , nil } } if i := bytes . Index ( data , [ ] byte ( " \r \r " ) ) ; i >= 0 { return i + 1 , data [ 0 : i ] , nil } if i := bytes . Index ( data , [ ] byte ( " \n \n " ) ) ; i >= 0 { return i + 1 , data [ 0 : i ] , nil } } } return & EventStreamReader { scanner : scanner , } } 
func ( e * EventStreamReader ) ReadEvent ( ) ( [ ] byte , error ) { if e . scanner . Scan ( ) { event := e . scanner . Bytes ( ) return event , nil } if err := e . scanner . Err ( ) ; err != nil { return nil , err } return nil , io . EOF } 
func ( s * Server ) HTTPHandler ( w http . ResponseWriter , r * http . Request ) { flusher , err := w . ( http . Flusher ) if ! err { http . Error ( w , " " , http . StatusInternalServerError ) return } w . Header ( ) . Set ( " " , " " ) w . Header ( ) . Set ( " " , " " ) w . Header ( ) . Set ( " " , " " ) w . Header ( ) . Set ( " " , " " ) if streamID == " " { http . Error ( w , " " , http . StatusInternalServerError ) return } stream := s . getStream ( streamID ) if stream == nil && ! s . AutoStream { http . Error ( w , " " , http . StatusInternalServerError ) return } else if stream == nil && s . AutoStream { stream = s . CreateStream ( streamID ) } eventid := r . Header . Get ( " " ) if eventid == " " { eventid = " " } defer sub . close ( ) notify := w . ( http . CloseNotifier ) . CloseNotify ( ) go func ( ) { <- notify sub . close ( ) } ( ) } } } fmt . Fprintf ( w , " \n " , ev . ID ) fmt . Fprintf ( w , " \n " , ev . Data ) if len ( ev . Event ) > 0 { fmt . Fprintf ( w , " \n " , ev . Event ) } if len ( ev . Retry ) > 0 { fmt . Fprintf ( w , " \n " , ev . Retry ) } fmt . Fprint ( w , " \n " ) flusher . Flush ( ) } } } 
func ( e * EventLog ) Add ( ev * Event ) { ev . ID = [ ] byte ( e . currentindex ( ) ) ev . timestamp = time . Now ( ) ( * e ) = append ( ( * e ) , ev ) } 
func ( e * EventLog ) Replay ( s * Subscriber ) { for i := 0 ; i < len ( ( * e ) ) ; i ++ { if string ( ( * e ) [ i ] . ID ) >= s . eventid { s . connection <- ( * e ) [ i ] } } } 
func readConfig ( ) ( * userConfig , error ) { b , err := ioutil . ReadFile ( filepath . Join ( configDir , accountFile ) ) if err != nil { return nil , err } uc := & userConfig { } if err := json . Unmarshal ( b , uc ) ; err != nil { return nil , err } if key , err := readKey ( filepath . Join ( configDir , accountKey ) ) ; err == nil { uc . key = key } return uc , nil } 
func writeConfig ( uc * userConfig ) error { b , err := json . MarshalIndent ( uc , " " , " " ) if err != nil { return err } if err := os . MkdirAll ( configDir , 0700 ) ; err != nil { return err } return ioutil . WriteFile ( filepath . Join ( configDir , accountFile ) , b , 0600 ) } 
func readKey ( path string ) ( crypto . Signer , error ) { b , err := ioutil . ReadFile ( path ) if err != nil { return nil , err } d , _ := pem . Decode ( b ) if d == nil { return nil , fmt . Errorf ( " " , path ) } switch d . Type { case rsaPrivateKey : return x509 . ParsePKCS1PrivateKey ( d . Bytes ) case ecPrivateKey : return x509 . ParseECPrivateKey ( d . Bytes ) default : return nil , fmt . Errorf ( " " , d . Type ) } } 
func writeKey ( path string , k * ecdsa . PrivateKey ) error { f , err := os . OpenFile ( path , os . O_WRONLY | os . O_CREATE | os . O_TRUNC , 0600 ) if err != nil { return err } bytes , err := x509 . MarshalECPrivateKey ( k ) if err != nil { return err } b := & pem . Block { Type : ecPrivateKey , Bytes : bytes } if err := pem . Encode ( f , b ) ; err != nil { f . Close ( ) return err } return f . Close ( ) } 
func anyKey ( filename string , gen bool ) ( crypto . Signer , error ) { k , err := readKey ( filename ) if err == nil { return k , nil } if ! os . IsNotExist ( err ) || ! gen { return nil , err } ecKey , err := ecdsa . GenerateKey ( elliptic . P256 ( ) , rand . Reader ) if err != nil { return nil , err } return ecKey , writeKey ( filename , ecKey ) } 
func sameDir ( existing , filename string ) string { return filepath . Join ( filepath . Dir ( existing ) , filename ) } 
func printAccount ( w io . Writer , a * acme . Account , kp string ) { tw := tabwriter . NewWriter ( w , 0 , 8 , 0 , '\t' , 0 ) fmt . Fprintln ( tw , " \t " , a . URI ) fmt . Fprintln ( tw , " \t " , kp ) fmt . Fprintln ( tw , " \t " , strings . Join ( a . Contact , " " ) ) fmt . Fprintln ( tw , " \t " , a . CurrentTerms ) agreed := a . AgreedTerms if a . AgreedTerms == " " { agreed = " " } else if a . AgreedTerms == a . CurrentTerms { agreed = " " } fmt . Fprintln ( tw , " \t " , agreed ) } 
func tmpl ( w io . Writer , text string , data interface { } ) { t := template . New ( " " ) t . Funcs ( template . FuncMap { " " : strings . TrimSpace , " " : capitalize , } ) template . Must ( t . Parse ( text ) ) ew := & errWriter { w : w } err := t . Execute ( ew , data ) if ew . err != nil { } fatalf ( " " , ew . err ) } if err != nil { panic ( err ) } } 
func printUsage ( w io . Writer ) { bw := bufio . NewWriter ( w ) tmpl ( bw , usageTemplate , commands ) bw . Flush ( ) } 
func ( c * command ) Name ( ) string { name := c . UsageLine i := strings . IndexRune ( name , ' ' ) if i >= 0 { name = name [ : i ] } return name } 
func isPrivateAddress ( address string ) ( bool , error ) { ipAddress := net . ParseIP ( address ) if ipAddress == nil { return false , errors . New ( " " ) } for i := range cidrs { if cidrs [ i ] . Contains ( ipAddress ) { return true , nil } } return false , nil } 
func FromRequest ( r * http . Request ) string { xForwardedFor := r . Header . Get ( " " ) } else { remoteIP = r . RemoteAddr } return remoteIP } isPrivate , err := isPrivateAddress ( address ) if ! isPrivate && err == nil { return address } } } 
func ( p * ClearParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandClear , p , nil ) } 
func ( p * DisableParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandDisable , nil , nil ) } 
func ( p * GetDOMStorageItemsParams ) Do ( ctx context . Context ) ( entries [ ] Item , err error ) { err = cdp . Execute ( ctx , CommandGetDOMStorageItems , p , & res ) if err != nil { return nil , err } return res . Entries , nil } 
func RemoveDOMStorageItem ( storageID * StorageID , key string ) * RemoveDOMStorageItemParams { return & RemoveDOMStorageItemParams { StorageID : storageID , Key : key , } } 
func ( p * RemoveDOMStorageItemParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandRemoveDOMStorageItem , p , nil ) } 
func SetDOMStorageItem ( storageID * StorageID , key string , value string ) * SetDOMStorageItemParams { return & SetDOMStorageItemParams { StorageID : storageID , Key : key , Value : value , } } 
func ( p * SetDOMStorageItemParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetDOMStorageItem , p , nil ) } 
func ( v TraceConfig ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TraceConfig ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing ( & r , v ) return r . Error ( ) } 
func ( v StartParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v RequestMemoryDumpReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestMemoryDumpReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing2 ( & r , v ) return r . Error ( ) } 
func ( v RequestMemoryDumpParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestMemoryDumpParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing3 ( & r , v ) return r . Error ( ) } 
func ( v RecordClockSyncMarkerParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RecordClockSyncMarkerParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing4 ( & r , v ) return r . Error ( ) } 
func ( v MemoryDumpConfig ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * MemoryDumpConfig ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing5 ( & r , v ) return r . Error ( ) } 
func ( v GetCategoriesReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetCategoriesReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing6 ( & r , v ) return r . Error ( ) } 
func ( v GetCategoriesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetCategoriesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing7 ( & r , v ) return r . Error ( ) } 
func ( v EventTracingComplete ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventTracingComplete ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing8 ( & r , v ) return r . Error ( ) } 
func ( v EventDataCollected ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventDataCollected ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing9 ( & r , v ) return r . Error ( ) } 
func ( v EventBufferUsage ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventBufferUsage ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing10 ( & r , v ) return r . Error ( ) } 
func ( v EndParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTracing11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EndParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTracing11 ( & r , v ) return r . Error ( ) } 
func DeliverPushMessage ( origin string , registrationID RegistrationID , data string ) * DeliverPushMessageParams { return & DeliverPushMessageParams { Origin : origin , RegistrationID : registrationID , Data : data , } } 
func ( p * DeliverPushMessageParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandDeliverPushMessage , p , nil ) } 
func DispatchSyncEvent ( origin string , registrationID RegistrationID , tag string , lastChance bool ) * DispatchSyncEventParams { return & DispatchSyncEventParams { Origin : origin , RegistrationID : registrationID , Tag : tag , LastChance : lastChance , } } 
func ( p * DispatchSyncEventParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandDispatchSyncEvent , p , nil ) } 
func ( p * InspectWorkerParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandInspectWorker , p , nil ) } 
func ( p * SetForceUpdateOnPageLoadParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetForceUpdateOnPageLoad , p , nil ) } 
func ( p * SkipWaitingParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSkipWaiting , p , nil ) } 
func ( p * StartWorkerParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandStartWorker , p , nil ) } 
func ( p * StopAllWorkersParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandStopAllWorkers , nil , nil ) } 
func ( p * StopWorkerParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandStopWorker , p , nil ) } 
func ( p * UnregisterParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandUnregister , p , nil ) } 
func ( p * UpdateRegistrationParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandUpdateRegistration , p , nil ) } 
func ( p * BindParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandBind , p , nil ) } 
func ( p * UnbindParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandUnbind , p , nil ) } 
func ( v GetEncodedResponseReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoAudits ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetEncodedResponseReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoAudits ( & r , v ) return r . Error ( ) } 
func ( v GetEncodedResponseParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoAudits1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetEncodedResponseParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoAudits1 ( & r , v ) return r . Error ( ) } 
func ( e * ExceptionDetails ) Error ( ) string { } 
func ( t * Timestamp ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { * t = Timestamp ( time . Unix ( 0 , int64 ( in . Float64 ( ) * float64 ( time . Millisecond ) ) ) ) } 
func ( t * Timestamp ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t Type ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * Type ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch Type ( in . String ( ) ) { case TypeObject : * t = TypeObject case TypeFunction : * t = TypeFunction case TypeUndefined : * t = TypeUndefined case TypeString : * t = TypeString case TypeNumber : * t = TypeNumber case TypeBoolean : * t = TypeBoolean case TypeSymbol : * t = TypeSymbol case TypeBigint : * t = TypeBigint case TypeAccessor : * t = TypeAccessor default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * Type ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t Subtype ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * Subtype ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch Subtype ( in . String ( ) ) { case SubtypeArray : * t = SubtypeArray case SubtypeNull : * t = SubtypeNull case SubtypeNode : * t = SubtypeNode case SubtypeRegexp : * t = SubtypeRegexp case SubtypeDate : * t = SubtypeDate case SubtypeMap : * t = SubtypeMap case SubtypeSet : * t = SubtypeSet case SubtypeWeakmap : * t = SubtypeWeakmap case SubtypeWeakset : * t = SubtypeWeakset case SubtypeIterator : * t = SubtypeIterator case SubtypeGenerator : * t = SubtypeGenerator case SubtypeError : * t = SubtypeError case SubtypeProxy : * t = SubtypeProxy case SubtypePromise : * t = SubtypePromise case SubtypeTypedarray : * t = SubtypeTypedarray case SubtypeArraybuffer : * t = SubtypeArraybuffer case SubtypeDataview : * t = SubtypeDataview default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * Subtype ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t APIType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * APIType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch APIType ( in . String ( ) ) { case APITypeLog : * t = APITypeLog case APITypeDebug : * t = APITypeDebug case APITypeInfo : * t = APITypeInfo case APITypeError : * t = APITypeError case APITypeWarning : * t = APITypeWarning case APITypeDir : * t = APITypeDir case APITypeDirxml : * t = APITypeDirxml case APITypeTable : * t = APITypeTable case APITypeTrace : * t = APITypeTrace case APITypeClear : * t = APITypeClear case APITypeStartGroup : * t = APITypeStartGroup case APITypeStartGroupCollapsed : * t = APITypeStartGroupCollapsed case APITypeEndGroup : * t = APITypeEndGroup case APITypeAssert : * t = APITypeAssert case APITypeProfile : * t = APITypeProfile case APITypeProfileEnd : * t = APITypeProfileEnd case APITypeCount : * t = APITypeCount case APITypeTimeEnd : * t = APITypeTimeEnd default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * APIType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( v RequestDatabaseReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestDatabaseReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb ( & r , v ) return r . Error ( ) } 
func ( v RequestDatabaseParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestDatabaseParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb1 ( & r , v ) return r . Error ( ) } 
func ( v RequestDatabaseNamesReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestDatabaseNamesReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb2 ( & r , v ) return r . Error ( ) } 
func ( v RequestDatabaseNamesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestDatabaseNamesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb3 ( & r , v ) return r . Error ( ) } 
func ( v RequestDataReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestDataReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb4 ( & r , v ) return r . Error ( ) } 
func ( v RequestDataParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestDataParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb5 ( & r , v ) return r . Error ( ) } 
func ( v ObjectStoreIndex ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ObjectStoreIndex ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb6 ( & r , v ) return r . Error ( ) } 
func ( v ObjectStore ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ObjectStore ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb7 ( & r , v ) return r . Error ( ) } 
func ( v KeyRange ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * KeyRange ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb8 ( & r , v ) return r . Error ( ) } 
func ( v KeyPath ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * KeyPath ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb9 ( & r , v ) return r . Error ( ) } 
func ( v Key ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Key ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb10 ( & r , v ) return r . Error ( ) } 
func ( v GetMetadataReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetMetadataReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb11 ( & r , v ) return r . Error ( ) } 
func ( v GetMetadataParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetMetadataParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb12 ( & r , v ) return r . Error ( ) } 
func ( v DeleteObjectStoreEntriesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DeleteObjectStoreEntriesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb15 ( & r , v ) return r . Error ( ) } 
func ( v DeleteDatabaseParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DeleteDatabaseParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb16 ( & r , v ) return r . Error ( ) } 
func ( v DatabaseWithObjectStores ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DatabaseWithObjectStores ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb17 ( & r , v ) return r . Error ( ) } 
func ( v * DataEntry ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb18 ( & r , v ) return r . Error ( ) } 
func ( v ClearObjectStoreParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoIndexeddb19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ClearObjectStoreParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoIndexeddb19 ( & r , v ) return r . Error ( ) } 
func ( v ViolationSetting ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLog ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ViolationSetting ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLog ( & r , v ) return r . Error ( ) } 
func ( v StopViolationsReportParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLog1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StopViolationsReportParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLog1 ( & r , v ) return r . Error ( ) } 
func ( v StartViolationsReportParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLog2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StartViolationsReportParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLog2 ( & r , v ) return r . Error ( ) } 
func ( v EventEntryAdded ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLog3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventEntryAdded ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLog3 ( & r , v ) return r . Error ( ) } 
func ( v Entry ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLog4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Entry ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLog4 ( & r , v ) return r . Error ( ) } 
func ( v StickyPositionConstraint ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StickyPositionConstraint ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree ( & r , v ) return r . Error ( ) } 
func ( v SnapshotCommandLogReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SnapshotCommandLogReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree1 ( & r , v ) return r . Error ( ) } 
func ( v SnapshotCommandLogParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SnapshotCommandLogParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree2 ( & r , v ) return r . Error ( ) } 
func ( v ScrollRect ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ScrollRect ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree3 ( & r , v ) return r . Error ( ) } 
func ( v ReplaySnapshotReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ReplaySnapshotReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree4 ( & r , v ) return r . Error ( ) } 
func ( v ReplaySnapshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ReplaySnapshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree5 ( & r , v ) return r . Error ( ) } 
func ( v ReleaseSnapshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ReleaseSnapshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree6 ( & r , v ) return r . Error ( ) } 
func ( v ProfileSnapshotReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ProfileSnapshotReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree7 ( & r , v ) return r . Error ( ) } 
func ( v ProfileSnapshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ProfileSnapshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree8 ( & r , v ) return r . Error ( ) } 
func ( v PictureTile ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PictureTile ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree9 ( & r , v ) return r . Error ( ) } 
func ( v MakeSnapshotReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * MakeSnapshotReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree10 ( & r , v ) return r . Error ( ) } 
func ( v MakeSnapshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * MakeSnapshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree11 ( & r , v ) return r . Error ( ) } 
func ( v LoadSnapshotReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * LoadSnapshotReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree12 ( & r , v ) return r . Error ( ) } 
func ( v LoadSnapshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * LoadSnapshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree13 ( & r , v ) return r . Error ( ) } 
func ( v Layer ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Layer ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree14 ( & r , v ) return r . Error ( ) } 
func ( v EventLayerTreeDidChange ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventLayerTreeDidChange ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree15 ( & r , v ) return r . Error ( ) } 
func ( v EventLayerPainted ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventLayerPainted ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree16 ( & r , v ) return r . Error ( ) } 
func ( v EnableParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v CompositingReasonsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CompositingReasonsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree19 ( & r , v ) return r . Error ( ) } 
func ( v CompositingReasonsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoLayertree20 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CompositingReasonsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoLayertree20 ( & r , v ) return r . Error ( ) } 
func ( t StyleSheetOrigin ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * StyleSheetOrigin ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch StyleSheetOrigin ( in . String ( ) ) { case StyleSheetOriginInjected : * t = StyleSheetOriginInjected case StyleSheetOriginUserAgent : * t = StyleSheetOriginUserAgent case StyleSheetOriginInspector : * t = StyleSheetOriginInspector case StyleSheetOriginRegular : * t = StyleSheetOriginRegular default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * StyleSheetOrigin ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t MediaSource ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * MediaSource ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch MediaSource ( in . String ( ) ) { case MediaSourceMediaRule : * t = MediaSourceMediaRule case MediaSourceImportRule : * t = MediaSourceImportRule case MediaSourceLinkedSheet : * t = MediaSourceLinkedSheet case MediaSourceInlineSheet : * t = MediaSourceInlineSheet default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * MediaSource ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( v TakeHeapSnapshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TakeHeapSnapshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler ( & r , v ) return r . Error ( ) } 
func ( v StopTrackingHeapObjectsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StopTrackingHeapObjectsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler1 ( & r , v ) return r . Error ( ) } 
func ( v StopSamplingReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StopSamplingReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler2 ( & r , v ) return r . Error ( ) } 
func ( v * StopSamplingParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler3 ( & r , v ) return r . Error ( ) } 
func ( v StartTrackingHeapObjectsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StartTrackingHeapObjectsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler4 ( & r , v ) return r . Error ( ) } 
func ( v SamplingHeapProfileSample ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SamplingHeapProfileSample ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler6 ( & r , v ) return r . Error ( ) } 
func ( v SamplingHeapProfileNode ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SamplingHeapProfileNode ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler7 ( & r , v ) return r . Error ( ) } 
func ( v SamplingHeapProfile ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SamplingHeapProfile ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler8 ( & r , v ) return r . Error ( ) } 
func ( v GetSamplingProfileReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetSamplingProfileReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler9 ( & r , v ) return r . Error ( ) } 
func ( v GetSamplingProfileParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetSamplingProfileParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler10 ( & r , v ) return r . Error ( ) } 
func ( v GetObjectByHeapObjectIDReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetObjectByHeapObjectIDReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler11 ( & r , v ) return r . Error ( ) } 
func ( v GetObjectByHeapObjectIDParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetObjectByHeapObjectIDParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler12 ( & r , v ) return r . Error ( ) } 
func ( v GetHeapObjectIDReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetHeapObjectIDReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler13 ( & r , v ) return r . Error ( ) } 
func ( v GetHeapObjectIDParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetHeapObjectIDParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler14 ( & r , v ) return r . Error ( ) } 
func ( v EventResetProfiles ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventResetProfiles ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler15 ( & r , v ) return r . Error ( ) } 
func ( v EventReportHeapSnapshotProgress ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventReportHeapSnapshotProgress ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler16 ( & r , v ) return r . Error ( ) } 
func ( v EventLastSeenObjectID ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventLastSeenObjectID ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler17 ( & r , v ) return r . Error ( ) } 
func ( v EventHeapStatsUpdate ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler18 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventHeapStatsUpdate ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler18 ( & r , v ) return r . Error ( ) } 
func ( v EventAddHeapSnapshotChunk ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventAddHeapSnapshotChunk ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler19 ( & r , v ) return r . Error ( ) } 
func ( v CollectGarbageParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler22 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CollectGarbageParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler22 ( & r , v ) return r . Error ( ) } 
func ( v AddInspectedHeapObjectParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHeapprofiler23 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AddInspectedHeapObjectParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHeapprofiler23 ( & r , v ) return r . Error ( ) } 
func ( p * GetCurrentTimeParams ) Do ( ctx context . Context ) ( currentTime float64 , err error ) { err = cdp . Execute ( ctx , CommandGetCurrentTime , p , & res ) if err != nil { return 0 , err } return res . CurrentTime , nil } 
func ( p * GetPlaybackRateParams ) Do ( ctx context . Context ) ( playbackRate float64 , err error ) { err = cdp . Execute ( ctx , CommandGetPlaybackRate , nil , & res ) if err != nil { return 0 , err } return res . PlaybackRate , nil } 
func ( p * ReleaseAnimationsParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandReleaseAnimations , p , nil ) } 
func ( p * ResolveAnimationParams ) Do ( ctx context . Context ) ( remoteObject * runtime . RemoteObject , err error ) { err = cdp . Execute ( ctx , CommandResolveAnimation , p , & res ) if err != nil { return nil , err } return res . RemoteObject , nil } 
func SeekAnimations ( animations [ ] string , currentTime float64 ) * SeekAnimationsParams { return & SeekAnimationsParams { Animations : animations , CurrentTime : currentTime , } } 
func ( p * SeekAnimationsParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSeekAnimations , p , nil ) } 
func SetPaused ( animations [ ] string , paused bool ) * SetPausedParams { return & SetPausedParams { Animations : animations , Paused : paused , } } 
func ( p * SetPausedParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetPaused , p , nil ) } 
func ( p * SetPlaybackRateParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetPlaybackRate , p , nil ) } 
func SetTiming ( animationID string , duration float64 , delay float64 ) * SetTimingParams { return & SetTimingParams { AnimationID : animationID , Duration : duration , Delay : delay , } } 
func ( p * SetTimingParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetTiming , p , nil ) } 
func ( v empty ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdproto ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * empty ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdproto ( & r , v ) return r . Error ( ) } 
func ( v Message ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdproto1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Message ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdproto1 ( & r , v ) return r . Error ( ) } 
func ( v Error ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdproto2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Error ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdproto2 ( & r , v ) return r . Error ( ) } 
func ( p * GetDOMCountersParams ) Do ( ctx context . Context ) ( documents int64 , nodes int64 , jsEventListeners int64 , err error ) { err = cdp . Execute ( ctx , CommandGetDOMCounters , nil , & res ) if err != nil { return 0 , 0 , 0 , err } return res . Documents , res . Nodes , res . JsEventListeners , nil } 
func ( p * PrepareForLeakDetectionParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandPrepareForLeakDetection , nil , nil ) } 
func ( p * ForciblyPurgeJavaScriptMemoryParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandForciblyPurgeJavaScriptMemory , nil , nil ) } 
func ( p * SetPressureNotificationsSuppressedParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetPressureNotificationsSuppressed , p , nil ) } 
func ( p * SimulatePressureNotificationParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSimulatePressureNotification , p , nil ) } 
func ( p StartSamplingParams ) WithSamplingInterval ( samplingInterval int64 ) * StartSamplingParams { p . SamplingInterval = samplingInterval return & p } 
func ( p StartSamplingParams ) WithSuppressRandomness ( suppressRandomness bool ) * StartSamplingParams { p . SuppressRandomness = suppressRandomness return & p } 
func ( p * StartSamplingParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandStartSampling , p , nil ) } 
func ( p * StopSamplingParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandStopSampling , nil , nil ) } 
func ( p * GetAllTimeSamplingProfileParams ) Do ( ctx context . Context ) ( profile * SamplingProfile , err error ) { err = cdp . Execute ( ctx , CommandGetAllTimeSamplingProfile , nil , & res ) if err != nil { return nil , err } return res . Profile , nil } 
func ( p * GetBrowserSamplingProfileParams ) Do ( ctx context . Context ) ( profile * SamplingProfile , err error ) { err = cdp . Execute ( ctx , CommandGetBrowserSamplingProfile , nil , & res ) if err != nil { return nil , err } return res . Profile , nil } 
func ( p * GetSamplingProfileParams ) Do ( ctx context . Context ) ( profile * SamplingProfile , err error ) { err = cdp . Execute ( ctx , CommandGetSamplingProfile , nil , & res ) if err != nil { return nil , err } return res . Profile , nil } 
func ( t Source ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * Source ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch Source ( in . String ( ) ) { case SourceXML : * t = SourceXML case SourceJavascript : * t = SourceJavascript case SourceNetwork : * t = SourceNetwork case SourceStorage : * t = SourceStorage case SourceAppcache : * t = SourceAppcache case SourceRendering : * t = SourceRendering case SourceSecurity : * t = SourceSecurity case SourceDeprecation : * t = SourceDeprecation case SourceWorker : * t = SourceWorker case SourceViolation : * t = SourceViolation case SourceIntervention : * t = SourceIntervention case SourceRecommendation : * t = SourceRecommendation case SourceOther : * t = SourceOther default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * Source ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t Level ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * Level ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch Level ( in . String ( ) ) { case LevelVerbose : * t = LevelVerbose case LevelInfo : * t = LevelInfo case LevelWarning : * t = LevelWarning case LevelError : * t = LevelError default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * Level ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t Violation ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * Violation ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch Violation ( in . String ( ) ) { case ViolationLongTask : * t = ViolationLongTask case ViolationLongLayout : * t = ViolationLongLayout case ViolationBlockedEvent : * t = ViolationBlockedEvent case ViolationBlockedParser : * t = ViolationBlockedParser case ViolationDiscouragedAPIUse : * t = ViolationDiscouragedAPIUse case ViolationHandler : * t = ViolationHandler case ViolationRecurringHandler : * t = ViolationRecurringHandler default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * Violation ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t WindowState ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * WindowState ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch WindowState ( in . String ( ) ) { case WindowStateNormal : * t = WindowStateNormal case WindowStateMinimized : * t = WindowStateMinimized case WindowStateMaximized : * t = WindowStateMaximized case WindowStateFullscreen : * t = WindowStateFullscreen default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * WindowState ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t PermissionType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * PermissionType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch PermissionType ( in . String ( ) ) { case PermissionTypeAccessibilityEvents : * t = PermissionTypeAccessibilityEvents case PermissionTypeAudioCapture : * t = PermissionTypeAudioCapture case PermissionTypeBackgroundSync : * t = PermissionTypeBackgroundSync case PermissionTypeBackgroundFetch : * t = PermissionTypeBackgroundFetch case PermissionTypeClipboardRead : * t = PermissionTypeClipboardRead case PermissionTypeClipboardWrite : * t = PermissionTypeClipboardWrite case PermissionTypeDurableStorage : * t = PermissionTypeDurableStorage case PermissionTypeFlash : * t = PermissionTypeFlash case PermissionTypeGeolocation : * t = PermissionTypeGeolocation case PermissionTypeMidi : * t = PermissionTypeMidi case PermissionTypeMidiSysex : * t = PermissionTypeMidiSysex case PermissionTypeNotifications : * t = PermissionTypeNotifications case PermissionTypePaymentHandler : * t = PermissionTypePaymentHandler case PermissionTypeProtectedMediaIdentifier : * t = PermissionTypeProtectedMediaIdentifier case PermissionTypeSensors : * t = PermissionTypeSensors case PermissionTypeVideoCapture : * t = PermissionTypeVideoCapture case PermissionTypeIdleDetection : * t = PermissionTypeIdleDetection default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * PermissionType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( p * ClearDeviceOrientationOverrideParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandClearDeviceOrientationOverride , nil , nil ) } 
func SetDeviceOrientationOverride ( alpha float64 , beta float64 , gamma float64 ) * SetDeviceOrientationOverrideParams { return & SetDeviceOrientationOverrideParams { Alpha : alpha , Beta : beta , Gamma : gamma , } } 
func ( p * SetDeviceOrientationOverrideParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetDeviceOrientationOverride , p , nil ) } 
func ( t RequestStage ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * RequestStage ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch RequestStage ( in . String ( ) ) { case RequestStageRequest : * t = RequestStageRequest case RequestStageResponse : * t = RequestStageResponse default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * RequestStage ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t AuthChallengeSource ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * AuthChallengeSource ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch AuthChallengeSource ( in . String ( ) ) { case AuthChallengeSourceServer : * t = AuthChallengeSourceServer case AuthChallengeSourceProxy : * t = AuthChallengeSourceProxy default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * AuthChallengeSource ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t AuthChallengeResponseResponse ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * AuthChallengeResponseResponse ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch AuthChallengeResponseResponse ( in . String ( ) ) { case AuthChallengeResponseResponseDefault : * t = AuthChallengeResponseResponseDefault case AuthChallengeResponseResponseCancelAuth : * t = AuthChallengeResponseResponseCancelAuth case AuthChallengeResponseResponseProvideCredentials : * t = AuthChallengeResponseResponseProvideCredentials default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * AuthChallengeResponseResponse ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t MixedContentType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * MixedContentType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch MixedContentType ( in . String ( ) ) { case MixedContentTypeBlockable : * t = MixedContentTypeBlockable case MixedContentTypeOptionallyBlockable : * t = MixedContentTypeOptionallyBlockable case MixedContentTypeNone : * t = MixedContentTypeNone default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * MixedContentType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t State ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * State ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch State ( in . String ( ) ) { case StateUnknown : * t = StateUnknown case StateNeutral : * t = StateNeutral case StateInsecure : * t = StateInsecure case StateSecure : * t = StateSecure case StateInfo : * t = StateInfo default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * State ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t CertificateErrorAction ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * CertificateErrorAction ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch CertificateErrorAction ( in . String ( ) ) { case CertificateErrorActionContinue : * t = CertificateErrorActionContinue case CertificateErrorActionCancel : * t = CertificateErrorActionCancel default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * CertificateErrorAction ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t * Type ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch Type ( in . String ( ) ) { case TypeAppcache : * t = TypeAppcache case TypeCookies : * t = TypeCookies case TypeFileSystems : * t = TypeFileSystems case TypeIndexeddb : * t = TypeIndexeddb case TypeLocalStorage : * t = TypeLocalStorage case TypeShaderCache : * t = TypeShaderCache case TypeWebsql : * t = TypeWebsql case TypeServiceWorkers : * t = TypeServiceWorkers case TypeCacheStorage : * t = TypeCacheStorage case TypeAll : * t = TypeAll case TypeOther : * t = TypeOther default : in . AddError ( errors . New ( " " ) ) } } 
func ( p * GetRealtimeDataParams ) Do ( ctx context . Context ) ( realtimeData * ContextRealtimeData , err error ) { err = cdp . Execute ( ctx , CommandGetRealtimeData , p , & res ) if err != nil { return nil , err } return res . RealtimeData , nil } 
func ( t ScreenshotParamsFormat ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * ScreenshotParamsFormat ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch ScreenshotParamsFormat ( in . String ( ) ) { case ScreenshotParamsFormatJpeg : * t = ScreenshotParamsFormatJpeg case ScreenshotParamsFormatPng : * t = ScreenshotParamsFormatPng default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * ScreenshotParamsFormat ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( p * StartViolationsReportParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandStartViolationsReport , p , nil ) } 
func ( p * StopViolationsReportParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandStopViolationsReport , nil , nil ) } 
func ( v TakeResponseBodyAsStreamReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TakeResponseBodyAsStreamReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch ( & r , v ) return r . Error ( ) } 
func ( v TakeResponseBodyAsStreamParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TakeResponseBodyAsStreamParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch1 ( & r , v ) return r . Error ( ) } 
func ( v RequestPattern ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RequestPattern ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch2 ( & r , v ) return r . Error ( ) } 
func ( v HeaderEntry ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * HeaderEntry ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch3 ( & r , v ) return r . Error ( ) } 
func ( v GetResponseBodyReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetResponseBodyReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch4 ( & r , v ) return r . Error ( ) } 
func ( v * GetResponseBodyParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch5 ( & r , v ) return r . Error ( ) } 
func ( v FulfillRequestParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FulfillRequestParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch6 ( & r , v ) return r . Error ( ) } 
func ( v FailRequestParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FailRequestParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch7 ( & r , v ) return r . Error ( ) } 
func ( v EventRequestPaused ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventRequestPaused ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch8 ( & r , v ) return r . Error ( ) } 
func ( v EventAuthRequired ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventAuthRequired ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch9 ( & r , v ) return r . Error ( ) } 
func ( v DisableParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v ContinueWithAuthParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ContinueWithAuthParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch12 ( & r , v ) return r . Error ( ) } 
func ( v ContinueRequestParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ContinueRequestParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch13 ( & r , v ) return r . Error ( ) } 
func ( v AuthChallengeResponse ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v AuthChallenge ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoFetch15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AuthChallenge ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoFetch15 ( & r , v ) return r . Error ( ) } 
func ( t GestureType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * GestureType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch GestureType ( in . String ( ) ) { case GestureDefault : * t = GestureDefault case GestureTouch : * t = GestureTouch case GestureMouse : * t = GestureMouse default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * GestureType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t TimeSinceEpoch ) MarshalEasyJSON ( out * jwriter . Writer ) { v := float64 ( time . Time ( t ) . UnixNano ( ) / int64 ( time . Second ) ) out . Buffer . EnsureSpace ( 20 ) out . Buffer . Buf = strconv . AppendFloat ( out . Buffer . Buf , v , 'f' , - 1 , 64 ) } 
func ( t * TimeSinceEpoch ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { * t = TimeSinceEpoch ( time . Unix ( 0 , int64 ( in . Float64 ( ) * float64 ( time . Second ) ) ) ) } 
func ( t * TimeSinceEpoch ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t Modifier ) String ( ) string { switch t { case ModifierNone : return " " case ModifierAlt : return " " case ModifierCtrl : return " " case ModifierMeta : return " " case ModifierShift : return " " } return fmt . Sprintf ( " " , t ) } 
func ( t Modifier ) MarshalEasyJSON ( out * jwriter . Writer ) { out . Int64 ( int64 ( t ) ) } 
func ( t * Modifier ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch Modifier ( in . Int64 ( ) ) { case ModifierNone : * t = ModifierNone case ModifierAlt : * t = ModifierAlt case ModifierCtrl : * t = ModifierCtrl case ModifierMeta : * t = ModifierMeta case ModifierShift : * t = ModifierShift default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * Modifier ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t KeyType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * KeyType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch KeyType ( in . String ( ) ) { case KeyDown : * t = KeyDown case KeyUp : * t = KeyUp case KeyRawDown : * t = KeyRawDown case KeyChar : * t = KeyChar default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * KeyType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t MouseType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * MouseType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch MouseType ( in . String ( ) ) { case MousePressed : * t = MousePressed case MouseReleased : * t = MouseReleased case MouseMoved : * t = MouseMoved case MouseWheel : * t = MouseWheel default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * MouseType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t ButtonType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * ButtonType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch ButtonType ( in . String ( ) ) { case ButtonNone : * t = ButtonNone case ButtonLeft : * t = ButtonLeft case ButtonMiddle : * t = ButtonMiddle case ButtonRight : * t = ButtonRight case ButtonBack : * t = ButtonBack case ButtonForward : * t = ButtonForward default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * ButtonType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t DispatchMouseEventPointerType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * DispatchMouseEventPointerType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch DispatchMouseEventPointerType ( in . String ( ) ) { case Mouse : * t = Mouse case Pen : * t = Pen default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * DispatchMouseEventPointerType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t TouchType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * TouchType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch TouchType ( in . String ( ) ) { case TouchStart : * t = TouchStart case TouchEnd : * t = TouchEnd case TouchMove : * t = TouchMove case TouchCancel : * t = TouchCancel default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * TouchType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t DOMBreakpointType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * DOMBreakpointType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch DOMBreakpointType ( in . String ( ) ) { case DOMBreakpointTypeSubtreeModified : * t = DOMBreakpointTypeSubtreeModified case DOMBreakpointTypeAttributeModified : * t = DOMBreakpointTypeAttributeModified case DOMBreakpointTypeNodeRemoved : * t = DOMBreakpointTypeNodeRemoved default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * DOMBreakpointType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t ScopeType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * ScopeType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch ScopeType ( in . String ( ) ) { case ScopeTypeGlobal : * t = ScopeTypeGlobal case ScopeTypeLocal : * t = ScopeTypeLocal case ScopeTypeWith : * t = ScopeTypeWith case ScopeTypeClosure : * t = ScopeTypeClosure case ScopeTypeCatch : * t = ScopeTypeCatch case ScopeTypeBlock : * t = ScopeTypeBlock case ScopeTypeScript : * t = ScopeTypeScript case ScopeTypeEval : * t = ScopeTypeEval case ScopeTypeModule : * t = ScopeTypeModule default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * ScopeType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t BreakLocationType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * BreakLocationType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch BreakLocationType ( in . String ( ) ) { case BreakLocationTypeDebuggerStatement : * t = BreakLocationTypeDebuggerStatement case BreakLocationTypeCall : * t = BreakLocationTypeCall case BreakLocationTypeReturn : * t = BreakLocationTypeReturn default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * BreakLocationType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t PausedReason ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * PausedReason ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch PausedReason ( in . String ( ) ) { case PausedReasonXHR : * t = PausedReasonXHR case PausedReasonDOM : * t = PausedReasonDOM case PausedReasonEventListener : * t = PausedReasonEventListener case PausedReasonException : * t = PausedReasonException case PausedReasonAssert : * t = PausedReasonAssert case PausedReasonDebugCommand : * t = PausedReasonDebugCommand case PausedReasonPromiseRejection : * t = PausedReasonPromiseRejection case PausedReasonOOM : * t = PausedReasonOOM case PausedReasonOther : * t = PausedReasonOther case PausedReasonAmbiguous : * t = PausedReasonAmbiguous default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * PausedReason ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t ContinueToLocationTargetCallFrames ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * ContinueToLocationTargetCallFrames ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch ContinueToLocationTargetCallFrames ( in . String ( ) ) { case ContinueToLocationTargetCallFramesAny : * t = ContinueToLocationTargetCallFramesAny case ContinueToLocationTargetCallFramesCurrent : * t = ContinueToLocationTargetCallFramesCurrent default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * ContinueToLocationTargetCallFrames ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t ExceptionsState ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * ExceptionsState ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch ExceptionsState ( in . String ( ) ) { case ExceptionsStateNone : * t = ExceptionsStateNone case ExceptionsStateUncaught : * t = ExceptionsStateUncaught case ExceptionsStateAll : * t = ExceptionsStateAll default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * ExceptionsState ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( p GetPartialAXTreeParams ) WithNodeID ( nodeID cdp . NodeID ) * GetPartialAXTreeParams { p . NodeID = nodeID return & p } 
func ( p GetPartialAXTreeParams ) WithBackendNodeID ( backendNodeID cdp . BackendNodeID ) * GetPartialAXTreeParams { p . BackendNodeID = backendNodeID return & p } 
func ( p GetPartialAXTreeParams ) WithObjectID ( objectID runtime . RemoteObjectID ) * GetPartialAXTreeParams { p . ObjectID = objectID return & p } 
func ( p GetPartialAXTreeParams ) WithFetchRelatives ( fetchRelatives bool ) * GetPartialAXTreeParams { p . FetchRelatives = fetchRelatives return & p } 
func ( p * GetPartialAXTreeParams ) Do ( ctx context . Context ) ( nodes [ ] * Node , err error ) { err = cdp . Execute ( ctx , CommandGetPartialAXTree , p , & res ) if err != nil { return nil , err } return res . Nodes , nil } 
func ( p * GetFullAXTreeParams ) Do ( ctx context . Context ) ( nodes [ ] * Node , err error ) { err = cdp . Execute ( ctx , CommandGetFullAXTree , nil , & res ) if err != nil { return nil , err } return res . Nodes , nil } 
func ( v TouchPoint ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TouchPoint ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput ( & r , v ) return r . Error ( ) } 
func ( v SynthesizeTapGestureParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SynthesizeTapGestureParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput1 ( & r , v ) return r . Error ( ) } 
func ( v SynthesizeScrollGestureParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SynthesizeScrollGestureParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput2 ( & r , v ) return r . Error ( ) } 
func ( v SynthesizePinchGestureParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SynthesizePinchGestureParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput3 ( & r , v ) return r . Error ( ) } 
func ( v SetIgnoreInputEventsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetIgnoreInputEventsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput4 ( & r , v ) return r . Error ( ) } 
func ( v InsertTextParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * InsertTextParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput5 ( & r , v ) return r . Error ( ) } 
func ( v EmulateTouchFromMouseEventParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EmulateTouchFromMouseEventParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput6 ( & r , v ) return r . Error ( ) } 
func ( v DispatchTouchEventParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DispatchTouchEventParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput7 ( & r , v ) return r . Error ( ) } 
func ( v DispatchMouseEventParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DispatchMouseEventParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput8 ( & r , v ) return r . Error ( ) } 
func ( v DispatchKeyEventParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInput9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DispatchKeyEventParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInput9 ( & r , v ) return r . Error ( ) } 
func ( p * SetTimeDomainParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandSetTimeDomain , p , nil ) } 
func ( p * GetMetricsParams ) Do ( ctx context . Context ) ( metrics [ ] * Metric , err error ) { err = cdp . Execute ( ctx , CommandGetMetrics , nil , & res ) if err != nil { return nil , err } return res . Metrics , nil } 
func ( p * CompositingReasonsParams ) Do ( ctx context . Context ) ( compositingReasons [ ] string , err error ) { err = cdp . Execute ( ctx , CommandCompositingReasons , p , & res ) if err != nil { return nil , err } return res . CompositingReasons , nil } 
func ( p * LoadSnapshotParams ) Do ( ctx context . Context ) ( snapshotID SnapshotID , err error ) { err = cdp . Execute ( ctx , CommandLoadSnapshot , p , & res ) if err != nil { return " " , err } return res . SnapshotID , nil } 
func ( p * MakeSnapshotParams ) Do ( ctx context . Context ) ( snapshotID SnapshotID , err error ) { err = cdp . Execute ( ctx , CommandMakeSnapshot , p , & res ) if err != nil { return " " , err } return res . SnapshotID , nil } 
func ( p ProfileSnapshotParams ) WithMinRepeatCount ( minRepeatCount int64 ) * ProfileSnapshotParams { p . MinRepeatCount = minRepeatCount return & p } 
func ( p ProfileSnapshotParams ) WithMinDuration ( minDuration float64 ) * ProfileSnapshotParams { p . MinDuration = minDuration return & p } 
func ( p ProfileSnapshotParams ) WithClipRect ( clipRect * dom . Rect ) * ProfileSnapshotParams { p . ClipRect = clipRect return & p } 
func ( p * ProfileSnapshotParams ) Do ( ctx context . Context ) ( timings [ ] PaintProfile , err error ) { err = cdp . Execute ( ctx , CommandProfileSnapshot , p , & res ) if err != nil { return nil , err } return res . Timings , nil } 
func ( p * ReleaseSnapshotParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandReleaseSnapshot , p , nil ) } 
func ( p ReplaySnapshotParams ) WithFromStep ( fromStep int64 ) * ReplaySnapshotParams { p . FromStep = fromStep return & p } 
func ( p ReplaySnapshotParams ) WithToStep ( toStep int64 ) * ReplaySnapshotParams { p . ToStep = toStep return & p } 
func ( p ReplaySnapshotParams ) WithScale ( scale float64 ) * ReplaySnapshotParams { p . Scale = scale return & p } 
func ( p * ReplaySnapshotParams ) Do ( ctx context . Context ) ( dataURL string , err error ) { err = cdp . Execute ( ctx , CommandReplaySnapshot , p , & res ) if err != nil { return " " , err } return res . DataURL , nil } 
func ( p * SnapshotCommandLogParams ) Do ( ctx context . Context ) ( commandLog [ ] easyjson . RawMessage , err error ) { err = cdp . Execute ( ctx , CommandSnapshotCommandLog , p , & res ) if err != nil { return nil , err } return res . CommandLog , nil } 
func ( v WebSocketResponse ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * WebSocketResponse ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork ( & r , v ) return r . Error ( ) } 
func ( v WebSocketRequest ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * WebSocketRequest ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork1 ( & r , v ) return r . Error ( ) } 
func ( v WebSocketFrame ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * WebSocketFrame ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork2 ( & r , v ) return r . Error ( ) } 
func ( v TakeResponseBodyForInterceptionAsStreamReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TakeResponseBodyForInterceptionAsStreamReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork3 ( & r , v ) return r . Error ( ) } 
func ( v TakeResponseBodyForInterceptionAsStreamParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TakeResponseBodyForInterceptionAsStreamParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork4 ( & r , v ) return r . Error ( ) } 
func ( v SignedExchangeSignature ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SignedExchangeSignature ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork5 ( & r , v ) return r . Error ( ) } 
func ( v SignedExchangeInfo ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SignedExchangeInfo ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork6 ( & r , v ) return r . Error ( ) } 
func ( v SignedExchangeHeader ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SignedExchangeHeader ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork7 ( & r , v ) return r . Error ( ) } 
func ( v SignedExchangeError ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SignedExchangeError ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork8 ( & r , v ) return r . Error ( ) } 
func ( v SignedCertificateTimestamp ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SignedCertificateTimestamp ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork9 ( & r , v ) return r . Error ( ) } 
func ( v SetRequestInterceptionParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetRequestInterceptionParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork10 ( & r , v ) return r . Error ( ) } 
func ( v SetExtraHTTPHeadersParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetExtraHTTPHeadersParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork11 ( & r , v ) return r . Error ( ) } 
func ( v SetDataSizeLimitsForTestParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetDataSizeLimitsForTestParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork12 ( & r , v ) return r . Error ( ) } 
func ( v SetCookiesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetCookiesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork13 ( & r , v ) return r . Error ( ) } 
func ( v SetCookieReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetCookieReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork14 ( & r , v ) return r . Error ( ) } 
func ( v SetCookieParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetCookieParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork15 ( & r , v ) return r . Error ( ) } 
func ( v SetCacheDisabledParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetCacheDisabledParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork16 ( & r , v ) return r . Error ( ) } 
func ( v SetBypassServiceWorkerParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBypassServiceWorkerParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork17 ( & r , v ) return r . Error ( ) } 
func ( v SetBlockedURLSParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork18 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBlockedURLSParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork18 ( & r , v ) return r . Error ( ) } 
func ( v SecurityDetails ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SecurityDetails ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork19 ( & r , v ) return r . Error ( ) } 
func ( v SearchInResponseBodyReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork20 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SearchInResponseBodyReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork20 ( & r , v ) return r . Error ( ) } 
func ( v SearchInResponseBodyParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork21 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SearchInResponseBodyParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork21 ( & r , v ) return r . Error ( ) } 
func ( v Response ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork22 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v ResourceTiming ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork23 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ResourceTiming ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork23 ( & r , v ) return r . Error ( ) } 
func ( v Request ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork25 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Request ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork25 ( & r , v ) return r . Error ( ) } 
func ( v ReplayXHRParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork26 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ReplayXHRParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork26 ( & r , v ) return r . Error ( ) } 
func ( v Initiator ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork27 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Initiator ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork27 ( & r , v ) return r . Error ( ) } 
func ( v GetResponseBodyParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork29 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v GetResponseBodyForInterceptionReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork30 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetResponseBodyForInterceptionReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork30 ( & r , v ) return r . Error ( ) } 
func ( v GetResponseBodyForInterceptionParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork31 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetResponseBodyForInterceptionParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork31 ( & r , v ) return r . Error ( ) } 
func ( v GetRequestPostDataReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork32 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetRequestPostDataReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork32 ( & r , v ) return r . Error ( ) } 
func ( v GetRequestPostDataParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork33 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetRequestPostDataParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork33 ( & r , v ) return r . Error ( ) } 
func ( v GetCookiesReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork34 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetCookiesReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork34 ( & r , v ) return r . Error ( ) } 
func ( v GetCookiesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork35 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetCookiesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork35 ( & r , v ) return r . Error ( ) } 
func ( v GetCertificateReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork36 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetCertificateReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork36 ( & r , v ) return r . Error ( ) } 
func ( v GetCertificateParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork37 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetCertificateParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork37 ( & r , v ) return r . Error ( ) } 
func ( v GetAllCookiesReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork38 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetAllCookiesReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork38 ( & r , v ) return r . Error ( ) } 
func ( v GetAllCookiesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork39 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetAllCookiesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork39 ( & r , v ) return r . Error ( ) } 
func ( v EventWebSocketWillSendHandshakeRequest ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork40 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWebSocketWillSendHandshakeRequest ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork40 ( & r , v ) return r . Error ( ) } 
func ( v EventWebSocketHandshakeResponseReceived ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork41 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWebSocketHandshakeResponseReceived ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork41 ( & r , v ) return r . Error ( ) } 
func ( v EventWebSocketFrameSent ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork42 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWebSocketFrameSent ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork42 ( & r , v ) return r . Error ( ) } 
func ( v EventWebSocketFrameReceived ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork43 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWebSocketFrameReceived ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork43 ( & r , v ) return r . Error ( ) } 
func ( v EventWebSocketFrameError ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork44 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWebSocketFrameError ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork44 ( & r , v ) return r . Error ( ) } 
func ( v EventWebSocketCreated ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork45 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWebSocketCreated ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork45 ( & r , v ) return r . Error ( ) } 
func ( v EventWebSocketClosed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork46 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWebSocketClosed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork46 ( & r , v ) return r . Error ( ) } 
func ( v EventSignedExchangeReceived ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork47 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventSignedExchangeReceived ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork47 ( & r , v ) return r . Error ( ) } 
func ( v EventResponseReceived ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork48 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventResponseReceived ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork48 ( & r , v ) return r . Error ( ) } 
func ( v EventResourceChangedPriority ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork49 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventResourceChangedPriority ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork49 ( & r , v ) return r . Error ( ) } 
func ( v EventRequestWillBeSent ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork50 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventRequestWillBeSent ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork50 ( & r , v ) return r . Error ( ) } 
func ( v EventRequestServedFromCache ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork51 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventRequestServedFromCache ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork51 ( & r , v ) return r . Error ( ) } 
func ( v EventRequestIntercepted ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork52 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventRequestIntercepted ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork52 ( & r , v ) return r . Error ( ) } 
func ( v EventLoadingFinished ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork53 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventLoadingFinished ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork53 ( & r , v ) return r . Error ( ) } 
func ( v EventLoadingFailed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork54 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventLoadingFailed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork54 ( & r , v ) return r . Error ( ) } 
func ( v EventEventSourceMessageReceived ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork55 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventEventSourceMessageReceived ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork55 ( & r , v ) return r . Error ( ) } 
func ( v EventDataReceived ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork56 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventDataReceived ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork56 ( & r , v ) return r . Error ( ) } 
func ( v EmulateNetworkConditionsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork58 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EmulateNetworkConditionsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork58 ( & r , v ) return r . Error ( ) } 
func ( v DeleteCookiesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork60 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DeleteCookiesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork60 ( & r , v ) return r . Error ( ) } 
func ( v CookieParam ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork61 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CookieParam ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork61 ( & r , v ) return r . Error ( ) } 
func ( v ContinueInterceptedRequestParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork63 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ContinueInterceptedRequestParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork63 ( & r , v ) return r . Error ( ) } 
func ( v ClearBrowserCookiesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork64 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ClearBrowserCookiesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork64 ( & r , v ) return r . Error ( ) } 
func ( v ClearBrowserCacheParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork65 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ClearBrowserCacheParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork65 ( & r , v ) return r . Error ( ) } 
func ( v CachedResource ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoNetwork66 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CachedResource ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork66 ( & r , v ) return r . Error ( ) } 
func ( v * AuthChallengeResponse ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoNetwork67 ( & r , v ) return r . Error ( ) } 
func ( v TextBoxSnapshot ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TextBoxSnapshot ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot ( & r , v ) return r . Error ( ) } 
func ( v RareStringData ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RareStringData ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot1 ( & r , v ) return r . Error ( ) } 
func ( v RareIntegerData ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RareIntegerData ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot2 ( & r , v ) return r . Error ( ) } 
func ( v RareBooleanData ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RareBooleanData ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot3 ( & r , v ) return r . Error ( ) } 
func ( v NodeTreeSnapshot ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * NodeTreeSnapshot ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot4 ( & r , v ) return r . Error ( ) } 
func ( v NameValue ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * NameValue ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot5 ( & r , v ) return r . Error ( ) } 
func ( v LayoutTreeSnapshot ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * LayoutTreeSnapshot ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot6 ( & r , v ) return r . Error ( ) } 
func ( v LayoutTreeNode ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * LayoutTreeNode ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot7 ( & r , v ) return r . Error ( ) } 
func ( v InlineTextBox ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * InlineTextBox ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot8 ( & r , v ) return r . Error ( ) } 
func ( v DocumentSnapshot ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DocumentSnapshot ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot10 ( & r , v ) return r . Error ( ) } 
func ( v DOMNode ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DOMNode ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot12 ( & r , v ) return r . Error ( ) } 
func ( v ComputedStyle ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDomsnapshot13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ComputedStyle ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot13 ( & r , v ) return r . Error ( ) } 
func ( v * CaptureSnapshotReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDomsnapshot14 ( & r , v ) return r . Error ( ) } 
func ( v StopSamplingParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v StartSamplingParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StartSamplingParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory1 ( & r , v ) return r . Error ( ) } 
func ( v SimulatePressureNotificationParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SimulatePressureNotificationParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory2 ( & r , v ) return r . Error ( ) } 
func ( v SetPressureNotificationsSuppressedParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetPressureNotificationsSuppressedParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory3 ( & r , v ) return r . Error ( ) } 
func ( v SamplingProfileNode ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SamplingProfileNode ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory4 ( & r , v ) return r . Error ( ) } 
func ( v SamplingProfile ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SamplingProfile ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory5 ( & r , v ) return r . Error ( ) } 
func ( v PrepareForLeakDetectionParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PrepareForLeakDetectionParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory6 ( & r , v ) return r . Error ( ) } 
func ( v Module ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Module ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory7 ( & r , v ) return r . Error ( ) } 
func ( v GetDOMCountersReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetDOMCountersReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory10 ( & r , v ) return r . Error ( ) } 
func ( v GetDOMCountersParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetDOMCountersParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory11 ( & r , v ) return r . Error ( ) } 
func ( v GetBrowserSamplingProfileReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetBrowserSamplingProfileReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory12 ( & r , v ) return r . Error ( ) } 
func ( v GetBrowserSamplingProfileParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetBrowserSamplingProfileParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory13 ( & r , v ) return r . Error ( ) } 
func ( v GetAllTimeSamplingProfileReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetAllTimeSamplingProfileReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory14 ( & r , v ) return r . Error ( ) } 
func ( v GetAllTimeSamplingProfileParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetAllTimeSamplingProfileParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory15 ( & r , v ) return r . Error ( ) } 
func ( v ForciblyPurgeJavaScriptMemoryParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoMemory16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ForciblyPurgeJavaScriptMemoryParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoMemory16 ( & r , v ) return r . Error ( ) } 
func ( v TakeCoverageDeltaReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TakeCoverageDeltaReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss1 ( & r , v ) return r . Error ( ) } 
func ( v TakeCoverageDeltaParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * TakeCoverageDeltaParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss2 ( & r , v ) return r . Error ( ) } 
func ( v StyleSheetHeader ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StyleSheetHeader ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss3 ( & r , v ) return r . Error ( ) } 
func ( v StyleDeclarationEdit ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StyleDeclarationEdit ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss4 ( & r , v ) return r . Error ( ) } 
func ( v Style ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Style ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss5 ( & r , v ) return r . Error ( ) } 
func ( v StopRuleUsageTrackingReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StopRuleUsageTrackingReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss6 ( & r , v ) return r . Error ( ) } 
func ( v StopRuleUsageTrackingParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StopRuleUsageTrackingParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss7 ( & r , v ) return r . Error ( ) } 
func ( v StartRuleUsageTrackingParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StartRuleUsageTrackingParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss8 ( & r , v ) return r . Error ( ) } 
func ( v SourceRange ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SourceRange ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss9 ( & r , v ) return r . Error ( ) } 
func ( v ShorthandEntry ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ShorthandEntry ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss10 ( & r , v ) return r . Error ( ) } 
func ( v SetStyleTextsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetStyleTextsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss11 ( & r , v ) return r . Error ( ) } 
func ( v SetStyleTextsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetStyleTextsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss12 ( & r , v ) return r . Error ( ) } 
func ( v SetStyleSheetTextReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetStyleSheetTextReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss13 ( & r , v ) return r . Error ( ) } 
func ( v SetStyleSheetTextParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetStyleSheetTextParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss14 ( & r , v ) return r . Error ( ) } 
func ( v SetRuleSelectorReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetRuleSelectorReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss15 ( & r , v ) return r . Error ( ) } 
func ( v SetRuleSelectorParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetRuleSelectorParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss16 ( & r , v ) return r . Error ( ) } 
func ( v SetMediaTextReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetMediaTextReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss17 ( & r , v ) return r . Error ( ) } 
func ( v SetMediaTextParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss18 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetMediaTextParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss18 ( & r , v ) return r . Error ( ) } 
func ( v SetKeyframeKeyReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetKeyframeKeyReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss19 ( & r , v ) return r . Error ( ) } 
func ( v SetKeyframeKeyParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss20 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetKeyframeKeyParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss20 ( & r , v ) return r . Error ( ) } 
func ( v SetEffectivePropertyValueForNodeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss21 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetEffectivePropertyValueForNodeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss21 ( & r , v ) return r . Error ( ) } 
func ( v SelectorList ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss22 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SelectorList ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss22 ( & r , v ) return r . Error ( ) } 
func ( v RuleUsage ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss23 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RuleUsage ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss23 ( & r , v ) return r . Error ( ) } 
func ( v RuleMatch ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss24 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RuleMatch ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss24 ( & r , v ) return r . Error ( ) } 
func ( v Rule ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss25 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Rule ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss25 ( & r , v ) return r . Error ( ) } 
func ( v PseudoElementMatches ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss26 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PseudoElementMatches ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss26 ( & r , v ) return r . Error ( ) } 
func ( v Property ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss27 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Property ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss27 ( & r , v ) return r . Error ( ) } 
func ( v PlatformFontUsage ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss28 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PlatformFontUsage ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss28 ( & r , v ) return r . Error ( ) } 
func ( v MediaQueryExpression ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss29 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * MediaQueryExpression ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss29 ( & r , v ) return r . Error ( ) } 
func ( v MediaQuery ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss30 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * MediaQuery ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss30 ( & r , v ) return r . Error ( ) } 
func ( v Media ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss31 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Media ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss31 ( & r , v ) return r . Error ( ) } 
func ( v KeyframesRule ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss32 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v KeyframeRule ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss33 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * KeyframeRule ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss33 ( & r , v ) return r . Error ( ) } 
func ( v InheritedStyleEntry ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss34 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * InheritedStyleEntry ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss34 ( & r , v ) return r . Error ( ) } 
func ( v GetStyleSheetTextReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss35 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetStyleSheetTextReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss35 ( & r , v ) return r . Error ( ) } 
func ( v GetStyleSheetTextParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss36 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetStyleSheetTextParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss36 ( & r , v ) return r . Error ( ) } 
func ( v GetPlatformFontsForNodeReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss37 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetPlatformFontsForNodeReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss37 ( & r , v ) return r . Error ( ) } 
func ( v GetPlatformFontsForNodeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss38 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetPlatformFontsForNodeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss38 ( & r , v ) return r . Error ( ) } 
func ( v GetMediaQueriesReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss39 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetMediaQueriesReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss39 ( & r , v ) return r . Error ( ) } 
func ( v GetMediaQueriesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss40 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetMediaQueriesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss40 ( & r , v ) return r . Error ( ) } 
func ( v GetMatchedStylesForNodeReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss41 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetMatchedStylesForNodeReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss41 ( & r , v ) return r . Error ( ) } 
func ( v GetMatchedStylesForNodeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss42 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetMatchedStylesForNodeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss42 ( & r , v ) return r . Error ( ) } 
func ( v GetInlineStylesForNodeReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss43 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetInlineStylesForNodeReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss43 ( & r , v ) return r . Error ( ) } 
func ( v GetInlineStylesForNodeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss44 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetInlineStylesForNodeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss44 ( & r , v ) return r . Error ( ) } 
func ( v GetComputedStyleForNodeReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss45 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetComputedStyleForNodeReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss45 ( & r , v ) return r . Error ( ) } 
func ( v GetComputedStyleForNodeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss46 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetComputedStyleForNodeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss46 ( & r , v ) return r . Error ( ) } 
func ( v GetBackgroundColorsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss47 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetBackgroundColorsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss47 ( & r , v ) return r . Error ( ) } 
func ( v GetBackgroundColorsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss48 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetBackgroundColorsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss48 ( & r , v ) return r . Error ( ) } 
func ( v ForcePseudoStateParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss49 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ForcePseudoStateParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss49 ( & r , v ) return r . Error ( ) } 
func ( v FontFace ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss50 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FontFace ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss50 ( & r , v ) return r . Error ( ) } 
func ( v EventStyleSheetRemoved ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss51 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventStyleSheetRemoved ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss51 ( & r , v ) return r . Error ( ) } 
func ( v EventStyleSheetChanged ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss52 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventStyleSheetChanged ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss52 ( & r , v ) return r . Error ( ) } 
func ( v EventStyleSheetAdded ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss53 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventStyleSheetAdded ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss53 ( & r , v ) return r . Error ( ) } 
func ( v EventMediaQueryResultChanged ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss54 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventMediaQueryResultChanged ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss54 ( & r , v ) return r . Error ( ) } 
func ( v EventFontsUpdated ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss55 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFontsUpdated ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss55 ( & r , v ) return r . Error ( ) } 
func ( v * DisableParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss57 ( & r , v ) return r . Error ( ) } 
func ( v CreateStyleSheetReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss58 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateStyleSheetReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss58 ( & r , v ) return r . Error ( ) } 
func ( v CreateStyleSheetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss59 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateStyleSheetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss59 ( & r , v ) return r . Error ( ) } 
func ( v ComputedProperty ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss60 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ComputedProperty ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss60 ( & r , v ) return r . Error ( ) } 
func ( v CollectClassNamesReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss61 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CollectClassNamesReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss61 ( & r , v ) return r . Error ( ) } 
func ( v CollectClassNamesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss62 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CollectClassNamesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss62 ( & r , v ) return r . Error ( ) } 
func ( v AddRuleReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss63 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AddRuleReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss63 ( & r , v ) return r . Error ( ) } 
func ( v AddRuleParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoCss64 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AddRuleParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoCss64 ( & r , v ) return r . Error ( ) } 
func ( v StepOverParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StepOverParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger ( & r , v ) return r . Error ( ) } 
func ( v StepOutParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StepOutParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger1 ( & r , v ) return r . Error ( ) } 
func ( v StepIntoParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StepIntoParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger2 ( & r , v ) return r . Error ( ) } 
func ( v SetVariableValueParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetVariableValueParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger3 ( & r , v ) return r . Error ( ) } 
func ( v SetSkipAllPausesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetSkipAllPausesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger4 ( & r , v ) return r . Error ( ) } 
func ( v SetScriptSourceReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetScriptSourceReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger5 ( & r , v ) return r . Error ( ) } 
func ( v SetScriptSourceParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetScriptSourceParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger6 ( & r , v ) return r . Error ( ) } 
func ( v SetReturnValueParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetReturnValueParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger7 ( & r , v ) return r . Error ( ) } 
func ( v SetPauseOnExceptionsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetPauseOnExceptionsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger8 ( & r , v ) return r . Error ( ) } 
func ( v SetBreakpointsActiveParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBreakpointsActiveParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger9 ( & r , v ) return r . Error ( ) } 
func ( v SetBreakpointReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBreakpointReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger10 ( & r , v ) return r . Error ( ) } 
func ( v SetBreakpointParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBreakpointParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger11 ( & r , v ) return r . Error ( ) } 
func ( v SetBreakpointOnFunctionCallReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBreakpointOnFunctionCallReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger12 ( & r , v ) return r . Error ( ) } 
func ( v SetBreakpointOnFunctionCallParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBreakpointOnFunctionCallParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger13 ( & r , v ) return r . Error ( ) } 
func ( v SetBreakpointByURLReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBreakpointByURLReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger14 ( & r , v ) return r . Error ( ) } 
func ( v SetBreakpointByURLParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBreakpointByURLParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger15 ( & r , v ) return r . Error ( ) } 
func ( v SetBlackboxedRangesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBlackboxedRangesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger16 ( & r , v ) return r . Error ( ) } 
func ( v SetBlackboxPatternsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBlackboxPatternsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger17 ( & r , v ) return r . Error ( ) } 
func ( v SetAsyncCallStackDepthParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger18 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetAsyncCallStackDepthParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger18 ( & r , v ) return r . Error ( ) } 
func ( v SearchMatch ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SearchMatch ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger19 ( & r , v ) return r . Error ( ) } 
func ( v SearchInContentReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger20 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SearchInContentReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger20 ( & r , v ) return r . Error ( ) } 
func ( v SearchInContentParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger21 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SearchInContentParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger21 ( & r , v ) return r . Error ( ) } 
func ( v ScriptPosition ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger22 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ScriptPosition ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger22 ( & r , v ) return r . Error ( ) } 
func ( v Scope ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger23 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Scope ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger23 ( & r , v ) return r . Error ( ) } 
func ( v ResumeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger24 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ResumeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger24 ( & r , v ) return r . Error ( ) } 
func ( v RestartFrameReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger25 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RestartFrameReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger25 ( & r , v ) return r . Error ( ) } 
func ( v RestartFrameParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger26 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RestartFrameParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger26 ( & r , v ) return r . Error ( ) } 
func ( v RemoveBreakpointParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger27 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RemoveBreakpointParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger27 ( & r , v ) return r . Error ( ) } 
func ( v PauseParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger28 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PauseParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger28 ( & r , v ) return r . Error ( ) } 
func ( v PauseOnAsyncCallParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger29 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PauseOnAsyncCallParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger29 ( & r , v ) return r . Error ( ) } 
func ( v Location ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger30 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Location ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger30 ( & r , v ) return r . Error ( ) } 
func ( v GetStackTraceReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger31 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetStackTraceReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger31 ( & r , v ) return r . Error ( ) } 
func ( v GetStackTraceParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger32 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetStackTraceParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger32 ( & r , v ) return r . Error ( ) } 
func ( v GetScriptSourceReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger33 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetScriptSourceReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger33 ( & r , v ) return r . Error ( ) } 
func ( v GetScriptSourceParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger34 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetScriptSourceParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger34 ( & r , v ) return r . Error ( ) } 
func ( v GetPossibleBreakpointsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger35 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetPossibleBreakpointsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger35 ( & r , v ) return r . Error ( ) } 
func ( v GetPossibleBreakpointsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger36 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetPossibleBreakpointsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger36 ( & r , v ) return r . Error ( ) } 
func ( v EventScriptParsed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger37 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventScriptParsed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger37 ( & r , v ) return r . Error ( ) } 
func ( v EventScriptFailedToParse ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger38 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventScriptFailedToParse ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger38 ( & r , v ) return r . Error ( ) } 
func ( v EventResumed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger39 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventResumed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger39 ( & r , v ) return r . Error ( ) } 
func ( v EventPaused ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger40 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventPaused ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger40 ( & r , v ) return r . Error ( ) } 
func ( v EventBreakpointResolved ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger41 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventBreakpointResolved ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger41 ( & r , v ) return r . Error ( ) } 
func ( v EvaluateOnCallFrameReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger42 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EvaluateOnCallFrameReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger42 ( & r , v ) return r . Error ( ) } 
func ( v EvaluateOnCallFrameParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger43 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EvaluateOnCallFrameParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger43 ( & r , v ) return r . Error ( ) } 
func ( v EnableReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger44 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EnableReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger44 ( & r , v ) return r . Error ( ) } 
func ( v ContinueToLocationParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger47 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ContinueToLocationParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger47 ( & r , v ) return r . Error ( ) } 
func ( v * CallFrame ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger48 ( & r , v ) return r . Error ( ) } 
func ( v BreakLocation ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoDebugger49 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * BreakLocation ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoDebugger49 ( & r , v ) return r . Error ( ) } 
func ( t PressureLevel ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * PressureLevel ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch PressureLevel ( in . String ( ) ) { case PressureLevelModerate : * t = PressureLevelModerate case PressureLevelCritical : * t = PressureLevelCritical default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * PressureLevel ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( v Timings ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Timings ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar ( & r , v ) return r . Error ( ) } 
func ( v * Response ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar1 ( & r , v ) return r . Error ( ) } 
func ( v PostData ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PostData ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar3 ( & r , v ) return r . Error ( ) } 
func ( v Param ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Param ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar4 ( & r , v ) return r . Error ( ) } 
func ( v PageTimings ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PageTimings ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar5 ( & r , v ) return r . Error ( ) } 
func ( v Page ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Page ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar6 ( & r , v ) return r . Error ( ) } 
func ( v NameValuePair ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * NameValuePair ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar7 ( & r , v ) return r . Error ( ) } 
func ( v Log ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Log ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar8 ( & r , v ) return r . Error ( ) } 
func ( v HAR ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * HAR ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar9 ( & r , v ) return r . Error ( ) } 
func ( v Creator ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Creator ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar11 ( & r , v ) return r . Error ( ) } 
func ( v Cookie ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Cookie ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar12 ( & r , v ) return r . Error ( ) } 
func ( v Content ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Content ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar13 ( & r , v ) return r . Error ( ) } 
func ( v CacheData ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CacheData ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoHar14 ( & r , v ) return r . Error ( ) } 
func ( v Cache ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoHar15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v SetVirtualTimePolicyReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetVirtualTimePolicyReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation ( & r , v ) return r . Error ( ) } 
func ( v SetVirtualTimePolicyParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetVirtualTimePolicyParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation1 ( & r , v ) return r . Error ( ) } 
func ( v SetUserAgentOverrideParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetUserAgentOverrideParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation2 ( & r , v ) return r . Error ( ) } 
func ( v SetTouchEmulationEnabledParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetTouchEmulationEnabledParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation3 ( & r , v ) return r . Error ( ) } 
func ( v SetScrollbarsHiddenParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetScrollbarsHiddenParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation4 ( & r , v ) return r . Error ( ) } 
func ( v SetScriptExecutionDisabledParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetScriptExecutionDisabledParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation5 ( & r , v ) return r . Error ( ) } 
func ( v SetPageScaleFactorParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetPageScaleFactorParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation6 ( & r , v ) return r . Error ( ) } 
func ( v SetGeolocationOverrideParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetGeolocationOverrideParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation7 ( & r , v ) return r . Error ( ) } 
func ( v SetFocusEmulationEnabledParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetFocusEmulationEnabledParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation8 ( & r , v ) return r . Error ( ) } 
func ( v SetEmulatedMediaParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetEmulatedMediaParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation9 ( & r , v ) return r . Error ( ) } 
func ( v SetEmitTouchEventsForMouseParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetEmitTouchEventsForMouseParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation10 ( & r , v ) return r . Error ( ) } 
func ( v SetDocumentCookieDisabledParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetDocumentCookieDisabledParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation11 ( & r , v ) return r . Error ( ) } 
func ( v SetDeviceMetricsOverrideParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetDeviceMetricsOverrideParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation12 ( & r , v ) return r . Error ( ) } 
func ( v SetDefaultBackgroundColorOverrideParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetDefaultBackgroundColorOverrideParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation13 ( & r , v ) return r . Error ( ) } 
func ( v SetCPUThrottlingRateParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetCPUThrottlingRateParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation14 ( & r , v ) return r . Error ( ) } 
func ( v ScreenOrientation ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ScreenOrientation ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation15 ( & r , v ) return r . Error ( ) } 
func ( v ResetPageScaleFactorParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ResetPageScaleFactorParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation16 ( & r , v ) return r . Error ( ) } 
func ( v EventVirtualTimeBudgetExpired ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventVirtualTimeBudgetExpired ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation17 ( & r , v ) return r . Error ( ) } 
func ( v ClearGeolocationOverrideParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation18 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ClearGeolocationOverrideParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation18 ( & r , v ) return r . Error ( ) } 
func ( v ClearDeviceMetricsOverrideParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ClearDeviceMetricsOverrideParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation19 ( & r , v ) return r . Error ( ) } 
func ( v CanEmulateReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation20 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CanEmulateReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation20 ( & r , v ) return r . Error ( ) } 
func ( v CanEmulateParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoEmulation21 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CanEmulateParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoEmulation21 ( & r , v ) return r . Error ( ) } 
func ( t * KeyType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch KeyType ( in . String ( ) ) { case KeyTypeNumber : * t = KeyTypeNumber case KeyTypeString : * t = KeyTypeString case KeyTypeDate : * t = KeyTypeDate case KeyTypeArray : * t = KeyTypeArray default : in . AddError ( errors . New ( " " ) ) } } 
func ( t KeyPathType ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * KeyPathType ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch KeyPathType ( in . String ( ) ) { case KeyPathTypeNull : * t = KeyPathTypeNull case KeyPathTypeString : * t = KeyPathTypeString case KeyPathTypeArray : * t = KeyPathTypeArray default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * KeyPathType ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t StreamFormat ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * StreamFormat ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch StreamFormat ( in . String ( ) ) { case StreamFormatJSON : * t = StreamFormatJSON case StreamFormatProto : * t = StreamFormatProto default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * StreamFormat ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t StreamCompression ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * StreamCompression ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch StreamCompression ( in . String ( ) ) { case StreamCompressionNone : * t = StreamCompressionNone case StreamCompressionGzip : * t = StreamCompressionGzip default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * StreamCompression ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t RecordMode ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * RecordMode ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch RecordMode ( in . String ( ) ) { case RecordModeRecordUntilFull : * t = RecordModeRecordUntilFull case RecordModeRecordContinuously : * t = RecordModeRecordContinuously case RecordModeRecordAsMuchAsPossible : * t = RecordModeRecordAsMuchAsPossible case RecordModeEchoToConsole : * t = RecordModeEchoToConsole default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * RecordMode ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ( t TransferMode ) MarshalEasyJSON ( out * jwriter . Writer ) { out . String ( string ( t ) ) } 
func ( t * TransferMode ) UnmarshalEasyJSON ( in * jlexer . Lexer ) { switch TransferMode ( in . String ( ) ) { case TransferModeReportEvents : * t = TransferModeReportEvents case TransferModeReturnAsStream : * t = TransferModeReturnAsStream default : in . AddError ( errors . New ( " " ) ) } } 
func ( t * TransferMode ) UnmarshalJSON ( buf [ ] byte ) error { return easyjson . Unmarshal ( buf , t ) } 
func ClearObjectStore ( securityOrigin string , databaseName string , objectStoreName string ) * ClearObjectStoreParams { return & ClearObjectStoreParams { SecurityOrigin : securityOrigin , DatabaseName : databaseName , ObjectStoreName : objectStoreName , } } 
func ( p * ClearObjectStoreParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandClearObjectStore , p , nil ) } 
func DeleteDatabase ( securityOrigin string , databaseName string ) * DeleteDatabaseParams { return & DeleteDatabaseParams { SecurityOrigin : securityOrigin , DatabaseName : databaseName , } } 
func ( p * DeleteDatabaseParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandDeleteDatabase , p , nil ) } 
func DeleteObjectStoreEntries ( securityOrigin string , databaseName string , objectStoreName string , keyRange * KeyRange ) * DeleteObjectStoreEntriesParams { return & DeleteObjectStoreEntriesParams { SecurityOrigin : securityOrigin , DatabaseName : databaseName , ObjectStoreName : objectStoreName , KeyRange : keyRange , } } 
func ( p * DeleteObjectStoreEntriesParams ) Do ( ctx context . Context ) ( err error ) { return cdp . Execute ( ctx , CommandDeleteObjectStoreEntries , p , nil ) } 
func RequestData ( securityOrigin string , databaseName string , objectStoreName string , indexName string , skipCount int64 , pageSize int64 ) * RequestDataParams { return & RequestDataParams { SecurityOrigin : securityOrigin , DatabaseName : databaseName , ObjectStoreName : objectStoreName , IndexName : indexName , SkipCount : skipCount , PageSize : pageSize , } } 
func ( p RequestDataParams ) WithKeyRange ( keyRange * KeyRange ) * RequestDataParams { p . KeyRange = keyRange return & p } 
func ( p * RequestDataParams ) Do ( ctx context . Context ) ( objectStoreDataEntries [ ] * DataEntry , hasMore bool , err error ) { err = cdp . Execute ( ctx , CommandRequestData , p , & res ) if err != nil { return nil , false , err } return res . ObjectStoreDataEntries , res . HasMore , nil } 
func GetMetadata ( securityOrigin string , databaseName string , objectStoreName string ) * GetMetadataParams { return & GetMetadataParams { SecurityOrigin : securityOrigin , DatabaseName : databaseName , ObjectStoreName : objectStoreName , } } 
func ( p * GetMetadataParams ) Do ( ctx context . Context ) ( entriesCount float64 , keyGeneratorValue float64 , err error ) { err = cdp . Execute ( ctx , CommandGetMetadata , p , & res ) if err != nil { return 0 , 0 , err } return res . EntriesCount , res . KeyGeneratorValue , nil } 
func RequestDatabase ( securityOrigin string , databaseName string ) * RequestDatabaseParams { return & RequestDatabaseParams { SecurityOrigin : securityOrigin , DatabaseName : databaseName , } } 
func ( p * RequestDatabaseParams ) Do ( ctx context . Context ) ( databaseWithObjectStores * DatabaseWithObjectStores , err error ) { err = cdp . Execute ( ctx , CommandRequestDatabase , p , & res ) if err != nil { return nil , err } return res . DatabaseWithObjectStores , nil } 
func ( p * RequestDatabaseNamesParams ) Do ( ctx context . Context ) ( databaseNames [ ] string , err error ) { err = cdp . Execute ( ctx , CommandRequestDatabaseNames , p , & res ) if err != nil { return nil , err } return res . DatabaseNames , nil } 
func ( v EventTargetReloadedAfterCrash ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInspector ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventTargetReloadedAfterCrash ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInspector ( & r , v ) return r . Error ( ) } 
func ( v EventDetached ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoInspector2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventDetached ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInspector2 ( & r , v ) return r . Error ( ) } 
func ( v * EnableParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoInspector3 ( & r , v ) return r . Error ( ) } 
func ( v GetRealtimeDataReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoWebaudio ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetRealtimeDataReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoWebaudio ( & r , v ) return r . Error ( ) } 
func ( v GetRealtimeDataParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoWebaudio1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetRealtimeDataParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoWebaudio1 ( & r , v ) return r . Error ( ) } 
func ( v EventContextDestroyed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoWebaudio2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventContextDestroyed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoWebaudio2 ( & r , v ) return r . Error ( ) } 
func ( v EventContextCreated ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoWebaudio3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventContextCreated ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoWebaudio3 ( & r , v ) return r . Error ( ) } 
func ( v EventContextChanged ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoWebaudio4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventContextChanged ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoWebaudio4 ( & r , v ) return r . Error ( ) } 
func ( v ContextRealtimeData ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoWebaudio7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ContextRealtimeData ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoWebaudio7 ( & r , v ) return r . Error ( ) } 
func ( v BaseAudioContext ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoWebaudio8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * BaseAudioContext ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoWebaudio8 ( & r , v ) return r . Error ( ) } 
func ( v SetRemoteLocationsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetRemoteLocationsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget ( & r , v ) return r . Error ( ) } 
func ( v SetDiscoverTargetsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetDiscoverTargetsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget1 ( & r , v ) return r . Error ( ) } 
func ( v SetAutoAttachParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetAutoAttachParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget2 ( & r , v ) return r . Error ( ) } 
func ( v SendMessageToTargetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SendMessageToTargetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget3 ( & r , v ) return r . Error ( ) } 
func ( v RemoteLocation ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RemoteLocation ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget4 ( & r , v ) return r . Error ( ) } 
func ( v Info ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Info ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget5 ( & r , v ) return r . Error ( ) } 
func ( v GetTargetsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetTargetsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget6 ( & r , v ) return r . Error ( ) } 
func ( v GetTargetsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetTargetsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget7 ( & r , v ) return r . Error ( ) } 
func ( v GetTargetInfoReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetTargetInfoReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget8 ( & r , v ) return r . Error ( ) } 
func ( v GetTargetInfoParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetTargetInfoParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget9 ( & r , v ) return r . Error ( ) } 
func ( v GetBrowserContextsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetBrowserContextsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget10 ( & r , v ) return r . Error ( ) } 
func ( v GetBrowserContextsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetBrowserContextsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget11 ( & r , v ) return r . Error ( ) } 
func ( v ExposeDevToolsProtocolParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ExposeDevToolsProtocolParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget12 ( & r , v ) return r . Error ( ) } 
func ( v EventTargetInfoChanged ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventTargetInfoChanged ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget13 ( & r , v ) return r . Error ( ) } 
func ( v EventTargetDestroyed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventTargetDestroyed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget14 ( & r , v ) return r . Error ( ) } 
func ( v EventTargetCreated ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventTargetCreated ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget15 ( & r , v ) return r . Error ( ) } 
func ( v EventTargetCrashed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventTargetCrashed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget16 ( & r , v ) return r . Error ( ) } 
func ( v EventReceivedMessageFromTarget ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventReceivedMessageFromTarget ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget17 ( & r , v ) return r . Error ( ) } 
func ( v EventDetachedFromTarget ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget18 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventDetachedFromTarget ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget18 ( & r , v ) return r . Error ( ) } 
func ( v EventAttachedToTarget ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventAttachedToTarget ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget19 ( & r , v ) return r . Error ( ) } 
func ( v DisposeBrowserContextParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget20 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DisposeBrowserContextParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget20 ( & r , v ) return r . Error ( ) } 
func ( v DetachFromTargetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget21 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * DetachFromTargetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget21 ( & r , v ) return r . Error ( ) } 
func ( v CreateTargetReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget22 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateTargetReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget22 ( & r , v ) return r . Error ( ) } 
func ( v CreateTargetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget23 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateTargetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget23 ( & r , v ) return r . Error ( ) } 
func ( v CreateBrowserContextReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget24 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateBrowserContextReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget24 ( & r , v ) return r . Error ( ) } 
func ( v CreateBrowserContextParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget25 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateBrowserContextParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget25 ( & r , v ) return r . Error ( ) } 
func ( v CloseTargetReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget26 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CloseTargetReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget26 ( & r , v ) return r . Error ( ) } 
func ( v CloseTargetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget27 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CloseTargetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget27 ( & r , v ) return r . Error ( ) } 
func ( v AttachToTargetReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget28 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AttachToTargetReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget28 ( & r , v ) return r . Error ( ) } 
func ( v AttachToTargetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget29 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AttachToTargetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget29 ( & r , v ) return r . Error ( ) } 
func ( v AttachToBrowserTargetReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget30 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AttachToBrowserTargetReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget30 ( & r , v ) return r . Error ( ) } 
func ( v AttachToBrowserTargetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget31 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AttachToBrowserTargetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget31 ( & r , v ) return r . Error ( ) } 
func ( v ActivateTargetParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoTarget32 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ActivateTargetParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoTarget32 ( & r , v ) return r . Error ( ) } 
func ( v WaitForDebuggerParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * WaitForDebuggerParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage ( & r , v ) return r . Error ( ) } 
func ( v VisualViewport ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage1 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * VisualViewport ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage1 ( & r , v ) return r . Error ( ) } 
func ( v Viewport ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage2 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * Viewport ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage2 ( & r , v ) return r . Error ( ) } 
func ( v StopScreencastParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage3 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StopScreencastParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage3 ( & r , v ) return r . Error ( ) } 
func ( v StopLoadingParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage4 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StopLoadingParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage4 ( & r , v ) return r . Error ( ) } 
func ( v StartScreencastParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage5 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * StartScreencastParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage5 ( & r , v ) return r . Error ( ) } 
func ( v SetWebLifecycleStateParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage6 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetWebLifecycleStateParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage6 ( & r , v ) return r . Error ( ) } 
func ( v SetProduceCompilationCacheParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage7 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetProduceCompilationCacheParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage7 ( & r , v ) return r . Error ( ) } 
func ( v SetLifecycleEventsEnabledParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage8 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetLifecycleEventsEnabledParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage8 ( & r , v ) return r . Error ( ) } 
func ( v SetFontSizesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage9 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetFontSizesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage9 ( & r , v ) return r . Error ( ) } 
func ( v SetFontFamiliesParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage10 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetFontFamiliesParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage10 ( & r , v ) return r . Error ( ) } 
func ( v SetDownloadBehaviorParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage11 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetDownloadBehaviorParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage11 ( & r , v ) return r . Error ( ) } 
func ( v SetDocumentContentParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage12 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetDocumentContentParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage12 ( & r , v ) return r . Error ( ) } 
func ( v SetBypassCSPParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage13 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetBypassCSPParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage13 ( & r , v ) return r . Error ( ) } 
func ( v SetAdBlockingEnabledParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage14 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SetAdBlockingEnabledParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage14 ( & r , v ) return r . Error ( ) } 
func ( v SearchInResourceReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage15 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SearchInResourceReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage15 ( & r , v ) return r . Error ( ) } 
func ( v SearchInResourceParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage16 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * SearchInResourceParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage16 ( & r , v ) return r . Error ( ) } 
func ( v ScreencastFrameMetadata ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage17 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ScreencastFrameMetadata ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage17 ( & r , v ) return r . Error ( ) } 
func ( v ScreencastFrameAckParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage18 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ScreencastFrameAckParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage18 ( & r , v ) return r . Error ( ) } 
func ( v ResetNavigationHistoryParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage19 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ResetNavigationHistoryParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage19 ( & r , v ) return r . Error ( ) } 
func ( v RemoveScriptToEvaluateOnNewDocumentParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage20 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * RemoveScriptToEvaluateOnNewDocumentParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage20 ( & r , v ) return r . Error ( ) } 
func ( v ReloadParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage21 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ReloadParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage21 ( & r , v ) return r . Error ( ) } 
func ( v PrintToPDFReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage22 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PrintToPDFReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage22 ( & r , v ) return r . Error ( ) } 
func ( v PrintToPDFParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage23 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * PrintToPDFParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage23 ( & r , v ) return r . Error ( ) } 
func ( v NavigationEntry ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage24 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * NavigationEntry ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage24 ( & r , v ) return r . Error ( ) } 
func ( v NavigateToHistoryEntryParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage25 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * NavigateToHistoryEntryParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage25 ( & r , v ) return r . Error ( ) } 
func ( v NavigateReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage26 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * NavigateReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage26 ( & r , v ) return r . Error ( ) } 
func ( v NavigateParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage27 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * NavigateParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage27 ( & r , v ) return r . Error ( ) } 
func ( v LayoutViewport ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage28 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * LayoutViewport ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage28 ( & r , v ) return r . Error ( ) } 
func ( v HandleJavaScriptDialogParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage29 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * HandleJavaScriptDialogParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage29 ( & r , v ) return r . Error ( ) } 
func ( v GetResourceTreeReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage30 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetResourceTreeReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage30 ( & r , v ) return r . Error ( ) } 
func ( v GetResourceTreeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage31 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetResourceTreeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage31 ( & r , v ) return r . Error ( ) } 
func ( v GetResourceContentReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage32 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetResourceContentReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage32 ( & r , v ) return r . Error ( ) } 
func ( v GetResourceContentParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage33 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetResourceContentParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage33 ( & r , v ) return r . Error ( ) } 
func ( v GetNavigationHistoryReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage34 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetNavigationHistoryReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage34 ( & r , v ) return r . Error ( ) } 
func ( v GetNavigationHistoryParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage35 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetNavigationHistoryParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage35 ( & r , v ) return r . Error ( ) } 
func ( v GetLayoutMetricsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage36 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetLayoutMetricsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage36 ( & r , v ) return r . Error ( ) } 
func ( v GetLayoutMetricsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage37 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetLayoutMetricsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage37 ( & r , v ) return r . Error ( ) } 
func ( v GetInstallabilityErrorsReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage38 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetInstallabilityErrorsReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage38 ( & r , v ) return r . Error ( ) } 
func ( v GetInstallabilityErrorsParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage39 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetInstallabilityErrorsParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage39 ( & r , v ) return r . Error ( ) } 
func ( v GetFrameTreeReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage40 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetFrameTreeReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage40 ( & r , v ) return r . Error ( ) } 
func ( v GetFrameTreeParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage41 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetFrameTreeParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage41 ( & r , v ) return r . Error ( ) } 
func ( v GetAppManifestReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage42 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetAppManifestReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage42 ( & r , v ) return r . Error ( ) } 
func ( v GetAppManifestParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage43 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GetAppManifestParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage43 ( & r , v ) return r . Error ( ) } 
func ( v GenerateTestReportParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage44 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * GenerateTestReportParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage44 ( & r , v ) return r . Error ( ) } 
func ( v FrameTree ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage45 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FrameTree ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage45 ( & r , v ) return r . Error ( ) } 
func ( v FrameResourceTree ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage46 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FrameResourceTree ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage46 ( & r , v ) return r . Error ( ) } 
func ( v FrameResource ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage47 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FrameResource ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage47 ( & r , v ) return r . Error ( ) } 
func ( v FontSizes ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage48 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FontSizes ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage48 ( & r , v ) return r . Error ( ) } 
func ( v FontFamilies ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage49 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * FontFamilies ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage49 ( & r , v ) return r . Error ( ) } 
func ( v EventWindowOpen ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage50 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventWindowOpen ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage50 ( & r , v ) return r . Error ( ) } 
func ( v EventScreencastVisibilityChanged ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage51 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventScreencastVisibilityChanged ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage51 ( & r , v ) return r . Error ( ) } 
func ( v EventScreencastFrame ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage52 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventScreencastFrame ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage52 ( & r , v ) return r . Error ( ) } 
func ( v EventNavigatedWithinDocument ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage53 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventNavigatedWithinDocument ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage53 ( & r , v ) return r . Error ( ) } 
func ( v EventLoadEventFired ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage54 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventLoadEventFired ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage54 ( & r , v ) return r . Error ( ) } 
func ( v EventLifecycleEvent ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage55 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventLifecycleEvent ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage55 ( & r , v ) return r . Error ( ) } 
func ( v EventJavascriptDialogOpening ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage56 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventJavascriptDialogOpening ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage56 ( & r , v ) return r . Error ( ) } 
func ( v EventJavascriptDialogClosed ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage57 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventJavascriptDialogClosed ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage57 ( & r , v ) return r . Error ( ) } 
func ( v EventInterstitialShown ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage58 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventInterstitialShown ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage58 ( & r , v ) return r . Error ( ) } 
func ( v EventInterstitialHidden ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage59 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventInterstitialHidden ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage59 ( & r , v ) return r . Error ( ) } 
func ( v EventFrameStoppedLoading ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage60 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFrameStoppedLoading ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage60 ( & r , v ) return r . Error ( ) } 
func ( v EventFrameStartedLoading ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage61 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFrameStartedLoading ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage61 ( & r , v ) return r . Error ( ) } 
func ( v EventFrameResized ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage62 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFrameResized ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage62 ( & r , v ) return r . Error ( ) } 
func ( v EventFrameRequestedNavigation ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage63 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFrameRequestedNavigation ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage63 ( & r , v ) return r . Error ( ) } 
func ( v EventFrameNavigated ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage64 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFrameNavigated ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage64 ( & r , v ) return r . Error ( ) } 
func ( v EventFrameDetached ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage65 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFrameDetached ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage65 ( & r , v ) return r . Error ( ) } 
func ( v EventFrameAttached ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage66 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventFrameAttached ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage66 ( & r , v ) return r . Error ( ) } 
func ( v EventDownloadWillBegin ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage67 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventDownloadWillBegin ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage67 ( & r , v ) return r . Error ( ) } 
func ( v EventDomContentEventFired ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage68 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventDomContentEventFired ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage68 ( & r , v ) return r . Error ( ) } 
func ( v EventCompilationCacheProduced ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage69 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * EventCompilationCacheProduced ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage69 ( & r , v ) return r . Error ( ) } 
func ( v CreateIsolatedWorldReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage72 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateIsolatedWorldReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage72 ( & r , v ) return r . Error ( ) } 
func ( v CreateIsolatedWorldParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage73 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CreateIsolatedWorldParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage73 ( & r , v ) return r . Error ( ) } 
func ( v CloseParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage75 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v ClearCompilationCacheParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage76 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * ClearCompilationCacheParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage76 ( & r , v ) return r . Error ( ) } 
func ( v CaptureSnapshotReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage77 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v CaptureSnapshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage78 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CaptureSnapshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage78 ( & r , v ) return r . Error ( ) } 
func ( v CaptureScreenshotReturns ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage79 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CaptureScreenshotReturns ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage79 ( & r , v ) return r . Error ( ) } 
func ( v CaptureScreenshotParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage80 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * CaptureScreenshotParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage80 ( & r , v ) return r . Error ( ) } 
func ( v BringToFrontParams ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage81 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * BringToFrontParams ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage81 ( & r , v ) return r . Error ( ) } 
func ( v AppManifestError ) MarshalJSON ( ) ( [ ] byte , error ) { w := jwriter . Writer { } easyjsonC5a4559bEncodeGithubComChromedpCdprotoPage82 ( & w , v ) return w . Buffer . BuildBytes ( ) , w . Error } 
func ( v * AppManifestError ) UnmarshalJSON ( data [ ] byte ) error { r := jlexer . Lexer { Data : data } easyjsonC5a4559bDecodeGithubComChromedpCdprotoPage82 ( & r , v ) return r . Error ( ) } 
